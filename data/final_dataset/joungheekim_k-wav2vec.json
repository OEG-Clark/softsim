{"home.repos.pwc.inspect_result.joungheekim_k-wav2vec.None.setup.NumpyExtension.__init__": [[31, 34], ["setuptools.Extension.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.None.setup.NumpyExtension.include_dirs": [[41, 44], ["None"], "methods", ["None"], ["", "@", "include_dirs", ".", "setter", "\n", "def", "include_dirs", "(", "self", ",", "dirs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "dirs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.main": [[46, 159], ["isinstance", "fairseq.utils.import_user_module", "fairseq.logging.metrics.reset", "numpy.random.seed", "fairseq.utils.set_torch_seed", "fairseq.distributed_utils.is_master", "logger.info", "fairseq.tasks.setup_task", "fairseq.dataclass.utils.convert_namespace_to_omegaconf.dataset.valid_subset.split", "tasks.setup_task.build_model", "tasks.setup_task.build_criterion", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "fairseq.checkpoint_utils.load_checkpoint", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.get_lr", "fairseq.logging.meters.StopwatchMeter", "meters.StopwatchMeter.start", "meters.StopwatchMeter.stop", "logger.info", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.distributed_utils.is_master", "logging.config.dictConfig", "fairseq.checkpoint_utils.verify_checkpoint_directory", "tasks.setup_task.load_dataset", "fairseq.quantization_utils.Quantizer", "fairseq.trainer.Trainer", "fairseq.model_parallel.megatron_trainer.MegatronTrainer", "train.train", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.lr_step", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.get_train_iterator", "omegaconf.OmegaConf.to_container", "sum", "sum", "tasks.setup_task.has_sharded_data", "logger.info", "tasks.setup_task.has_sharded_data", "tasks.setup_task.has_sharded_data", "p.numel", "p.numel", "task.build_model.parameters", "task.build_model.parameters"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.__init__.build_criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.verify_checkpoint_directory", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.load_dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.has_sharded_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.has_sharded_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.has_sharded_data"], ["def", "main", "(", "cfg", ":", "FairseqConfig", ")", "->", "None", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "argparse", ".", "Namespace", ")", ":", "\n", "        ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "utils", ".", "import_user_module", "(", "cfg", ".", "common", ")", "\n", "\n", "if", "is_master", "(", "cfg", ".", "distributed_training", ")", "and", "\"job_logging_cfg\"", "in", "cfg", ":", "\n", "# make hydra logging work with ddp (see # see https://github.com/facebookresearch/hydra/issues/1126)", "\n", "        ", "logging", ".", "config", ".", "dictConfig", "(", "OmegaConf", ".", "to_container", "(", "cfg", ".", "job_logging_cfg", ")", ")", "\n", "\n", "", "assert", "(", "\n", "cfg", ".", "dataset", ".", "max_tokens", "is", "not", "None", "or", "cfg", ".", "dataset", ".", "batch_size", "is", "not", "None", "\n", ")", ",", "\"Must specify batch size either with --max-tokens or --batch-size\"", "\n", "metrics", ".", "reset", "(", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "utils", ".", "set_torch_seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", ":", "\n", "        ", "checkpoint_utils", ".", "verify_checkpoint_directory", "(", "cfg", ".", "checkpoint", ".", "save_dir", ")", "\n", "\n", "# Print args", "\n", "", "logger", ".", "info", "(", "cfg", ")", "\n", "\n", "# Setup task, e.g., translation, language modeling, etc.", "\n", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "# Load valid dataset (we load training data below, based on the latest checkpoint)", "\n", "for", "valid_sub_split", "in", "cfg", ".", "dataset", ".", "valid_subset", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "task", ".", "load_dataset", "(", "valid_sub_split", ",", "combine", "=", "False", ",", "epoch", "=", "1", ")", "\n", "\n", "", "assert", "cfg", ".", "criterion", ",", "\"Please specify criterion to train a model\"", "\n", "\n", "# Build model and criterion", "\n", "model", "=", "task", ".", "build_model", "(", "cfg", ".", "model", ")", "\n", "criterion", "=", "task", ".", "build_criterion", "(", "cfg", ".", "criterion", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"task: {}\"", ".", "format", "(", "task", ".", "__class__", ".", "__name__", ")", ")", "\n", "logger", ".", "info", "(", "\"model: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ")", ")", "\n", "logger", ".", "info", "(", "\"criterion: {}\"", ".", "format", "(", "criterion", ".", "__class__", ".", "__name__", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"num. model params: {:,} (num. trained: {:,})\"", ".", "format", "(", "\n", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ",", "\n", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# (optionally) Configure quantization", "\n", "if", "cfg", ".", "common", ".", "quantization_config_path", "is", "not", "None", ":", "\n", "        ", "quantizer", "=", "quantization_utils", ".", "Quantizer", "(", "\n", "config_path", "=", "cfg", ".", "common", ".", "quantization_config_path", ",", "\n", "max_epoch", "=", "cfg", ".", "optimization", ".", "max_epoch", ",", "\n", "max_update", "=", "cfg", ".", "optimization", ".", "max_update", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "quantizer", "=", "None", "\n", "\n", "# Build trainer", "\n", "", "if", "cfg", ".", "common", ".", "model_parallel_size", "==", "1", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "cfg", ",", "task", ",", "model", ",", "criterion", ",", "quantizer", ")", "\n", "", "else", ":", "\n", "        ", "trainer", "=", "MegatronTrainer", "(", "cfg", ",", "task", ",", "model", ",", "criterion", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"training on {} devices (GPUs/TPUs)\"", ".", "format", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"max tokens per GPU = {} and batch size per GPU = {}\"", ".", "format", "(", "\n", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", ")", "\n", ")", "\n", "\n", "# Load the latest checkpoint if one is available and restore the", "\n", "# corresponding train iterator", "\n", "extra_state", ",", "epoch_itr", "=", "checkpoint_utils", ".", "load_checkpoint", "(", "\n", "cfg", ".", "checkpoint", ",", "\n", "trainer", ",", "\n", "# don't cache epoch iterators for sharded datasets", "\n", "disable_iterator_cache", "=", "task", ".", "has_sharded_data", "(", "\"train\"", ")", ",", "\n", ")", "\n", "\n", "max_epoch", "=", "cfg", ".", "optimization", ".", "max_epoch", "or", "math", ".", "inf", "\n", "lr", "=", "trainer", ".", "get_lr", "(", ")", "\n", "train_meter", "=", "meters", ".", "StopwatchMeter", "(", ")", "\n", "train_meter", ".", "start", "(", ")", "\n", "while", "epoch_itr", ".", "next_epoch_idx", "<=", "max_epoch", ":", "\n", "        ", "if", "lr", "<=", "cfg", ".", "optimization", ".", "stop_min_lr", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"stopping training because current learning rate ({lr}) is smaller \"", "\n", "\"than or equal to minimum learning rate \"", "\n", "f\"(--stop-min-lr={cfg.optimization.stop_min_lr})\"", "\n", ")", "\n", "break", "\n", "\n", "# train for one epoch", "\n", "", "valid_losses", ",", "should_stop", "=", "train", "(", "cfg", ",", "trainer", ",", "task", ",", "epoch_itr", ")", "\n", "if", "should_stop", ":", "\n", "            ", "break", "\n", "\n", "# only use first validation loss to update the learning rate", "\n", "", "lr", "=", "trainer", ".", "lr_step", "(", "epoch_itr", ".", "epoch", ",", "valid_losses", "[", "0", "]", ")", "\n", "\n", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch_itr", ".", "next_epoch_idx", ",", "\n", "# sharded data: get train iterator for next epoch", "\n", "load_dataset", "=", "task", ".", "has_sharded_data", "(", "\"train\"", ")", ",", "\n", "# don't cache epoch iterators for sharded datasets", "\n", "disable_iterator_cache", "=", "task", ".", "has_sharded_data", "(", "\"train\"", ")", ",", "\n", ")", "\n", "", "train_meter", ".", "stop", "(", ")", "\n", "logger", ".", "info", "(", "\"done training in {:.1f} seconds\"", ".", "format", "(", "train_meter", ".", "sum", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.should_stop_early": [[161, 187], ["getattr", "train.should_stop_early.is_better"], "function", ["None"], ["", "def", "should_stop_early", "(", "cfg", ":", "DictConfig", ",", "valid_loss", ":", "float", ")", "->", "bool", ":", "\n", "# skip check if no validation was done in the current epoch", "\n", "    ", "if", "valid_loss", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "if", "cfg", ".", "checkpoint", ".", "patience", "<=", "0", ":", "\n", "        ", "return", "False", "\n", "\n", "", "def", "is_better", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", ">", "b", "if", "cfg", ".", "checkpoint", ".", "maximize_best_checkpoint_metric", "else", "a", "<", "b", "\n", "\n", "", "prev_best", "=", "getattr", "(", "should_stop_early", ",", "\"best\"", ",", "None", ")", "\n", "if", "prev_best", "is", "None", "or", "is_better", "(", "valid_loss", ",", "prev_best", ")", ":", "\n", "        ", "should_stop_early", ".", "best", "=", "valid_loss", "\n", "should_stop_early", ".", "num_runs", "=", "0", "\n", "return", "False", "\n", "", "else", ":", "\n", "        ", "should_stop_early", ".", "num_runs", "+=", "1", "\n", "if", "should_stop_early", ".", "num_runs", ">=", "cfg", ".", "checkpoint", ".", "patience", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"early stop since valid performance hasn't improved for last {} runs\"", ".", "format", "(", "\n", "cfg", ".", "checkpoint", ".", "patience", "\n", ")", "\n", ")", "\n", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train": [[189, 272], ["fairseq.logging.metrics.aggregate", "epoch_itr.next_epoch_itr", "fairseq.data.iterators.GroupedIterator", "fairseq.logging.progress_bar.progress_bar", "progress_bar.progress_bar.update_config", "trainer.begin_epoch", "cfg.dataset.valid_subset.split", "trainer.get_num_updates", "enumerate", "logger.info", "train.get_training_stats", "progress_bar.progress_bar.print", "fairseq.logging.metrics.reset_meters", "fairseq.utils.tpu_data_loader", "train._flatten_config", "train.validate_and_save", "fairseq.logging.metrics.get_smoothed_values", "len", "os.environ.get", "fairseq.logging.metrics.aggregate", "torch.autograd.profiler.record_function", "trainer.train_step", "trainer.get_num_updates", "utils.tpu_data_loader.has_next", "fairseq.distributed_utils.is_master", "fairseq.distributed_utils.is_master", "os.path.basename", "fairseq.distributed_utils.is_master", "train.get_training_stats", "progress_bar.progress_bar.log", "fairseq.logging.metrics.reset_meters", "fairseq.logging.metrics.get_smoothed_values"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.update_config", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.get_training_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.reset_meters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.tpu_data_loader", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train._flatten_config", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.validate_and_save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.train_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.has_next", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.get_training_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.reset_meters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values"], ["", "", "", "@", "metrics", ".", "aggregate", "(", "\"train\"", ")", "\n", "def", "train", "(", "\n", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", ",", "task", ":", "tasks", ".", "FairseqTask", ",", "epoch_itr", "\n", ")", "->", "Tuple", "[", "List", "[", "Optional", "[", "float", "]", "]", ",", "bool", "]", ":", "\n", "    ", "\"\"\"Train the model for one epoch and return validation losses.\"\"\"", "\n", "# Initialize data iterator", "\n", "itr", "=", "epoch_itr", ".", "next_epoch_itr", "(", "\n", "fix_batches_to_gpus", "=", "cfg", ".", "distributed_training", ".", "fix_batches_to_gpus", ",", "\n", "shuffle", "=", "(", "epoch_itr", ".", "next_epoch_idx", ">", "cfg", ".", "dataset", ".", "curriculum", ")", ",", "\n", ")", "\n", "update_freq", "=", "(", "\n", "cfg", ".", "optimization", ".", "update_freq", "[", "epoch_itr", ".", "epoch", "-", "1", "]", "\n", "if", "epoch_itr", ".", "epoch", "<=", "len", "(", "cfg", ".", "optimization", ".", "update_freq", ")", "\n", "else", "cfg", ".", "optimization", ".", "update_freq", "[", "-", "1", "]", "\n", ")", "\n", "itr", "=", "iterators", ".", "GroupedIterator", "(", "itr", ",", "update_freq", ")", "\n", "if", "cfg", ".", "common", ".", "tpu", ":", "\n", "        ", "itr", "=", "utils", ".", "tpu_data_loader", "(", "itr", ")", "\n", "", "progress", "=", "progress_bar", ".", "progress_bar", "(", "\n", "itr", ",", "\n", "log_format", "=", "cfg", ".", "common", ".", "log_format", ",", "\n", "log_interval", "=", "cfg", ".", "common", ".", "log_interval", ",", "\n", "epoch", "=", "epoch_itr", ".", "epoch", ",", "\n", "tensorboard_logdir", "=", "(", "\n", "cfg", ".", "common", ".", "tensorboard_logdir", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", "\n", "else", "None", "\n", ")", ",", "\n", "default_log_format", "=", "(", "\"tqdm\"", "if", "not", "cfg", ".", "common", ".", "no_progress_bar", "else", "\"simple\"", ")", ",", "\n", "wandb_project", "=", "(", "\n", "cfg", ".", "common", ".", "wandb_project", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", "\n", "else", "None", "\n", ")", ",", "\n", "wandb_run_name", "=", "os", ".", "environ", ".", "get", "(", "\n", "\"WANDB_NAME\"", ",", "os", ".", "path", ".", "basename", "(", "cfg", ".", "checkpoint", ".", "save_dir", ")", "\n", ")", ",", "\n", "azureml_logging", "=", "(", "\n", "cfg", ".", "common", ".", "azureml_logging", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", "\n", "else", "False", "\n", ")", ",", "\n", ")", "\n", "progress", ".", "update_config", "(", "_flatten_config", "(", "cfg", ")", ")", "\n", "\n", "trainer", ".", "begin_epoch", "(", "epoch_itr", ".", "epoch", ")", "\n", "\n", "valid_subsets", "=", "cfg", ".", "dataset", ".", "valid_subset", ".", "split", "(", "\",\"", ")", "\n", "should_stop", "=", "False", "\n", "num_updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "for", "i", ",", "samples", "in", "enumerate", "(", "progress", ")", ":", "\n", "        ", "with", "metrics", ".", "aggregate", "(", "\"train_inner\"", ")", ",", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\n", "\"train_step-%d\"", "%", "i", "\n", ")", ":", "\n", "            ", "log_output", "=", "trainer", ".", "train_step", "(", "samples", ")", "\n", "\n", "", "if", "log_output", "is", "not", "None", ":", "# not OOM, overflow, ...", "\n", "# log mid-epoch stats", "\n", "            ", "num_updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "if", "num_updates", "%", "cfg", ".", "common", ".", "log_interval", "==", "0", ":", "\n", "                ", "stats", "=", "get_training_stats", "(", "metrics", ".", "get_smoothed_values", "(", "\"train_inner\"", ")", ")", "\n", "progress", ".", "log", "(", "stats", ",", "tag", "=", "\"train_inner\"", ",", "step", "=", "num_updates", ")", "\n", "\n", "# reset mid-epoch stats after each log interval", "\n", "# the end-of-epoch stats will still be preserved", "\n", "metrics", ".", "reset_meters", "(", "\"train_inner\"", ")", "\n", "\n", "", "", "end_of_epoch", "=", "not", "itr", ".", "has_next", "(", ")", "\n", "valid_losses", ",", "should_stop", "=", "validate_and_save", "(", "\n", "cfg", ",", "trainer", ",", "task", ",", "epoch_itr", ",", "valid_subsets", ",", "end_of_epoch", "\n", ")", "\n", "\n", "if", "should_stop", ":", "\n", "            ", "break", "\n", "\n", "# log end-of-epoch stats", "\n", "", "", "logger", ".", "info", "(", "\"end of epoch {} (average epoch stats below)\"", ".", "format", "(", "epoch_itr", ".", "epoch", ")", ")", "\n", "stats", "=", "get_training_stats", "(", "metrics", ".", "get_smoothed_values", "(", "\"train\"", ")", ")", "\n", "progress", ".", "print", "(", "stats", ",", "tag", "=", "\"train\"", ",", "step", "=", "num_updates", ")", "\n", "\n", "# reset epoch-level meters", "\n", "metrics", ".", "reset_meters", "(", "\"train\"", ")", "\n", "return", "valid_losses", ",", "should_stop", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train._flatten_config": [[274, 285], ["omegaconf.OmegaConf.to_container", "list", "OmegaConf.to_container.items", "isinstance", "vars"], "function", ["None"], ["", "def", "_flatten_config", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "    ", "config", "=", "OmegaConf", ".", "to_container", "(", "cfg", ")", "\n", "# remove any legacy Namespaces and replace with a single \"args\"", "\n", "namespace", "=", "None", "\n", "for", "k", ",", "v", "in", "list", "(", "config", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "argparse", ".", "Namespace", ")", ":", "\n", "            ", "namespace", "=", "v", "\n", "del", "config", "[", "k", "]", "\n", "", "", "if", "namespace", "is", "not", "None", ":", "\n", "        ", "config", "[", "\"args\"", "]", "=", "vars", "(", "namespace", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.validate_and_save": [[287, 355], ["trainer.get_num_updates", "train.should_stop_early", "logger.info", "trainer.cumulative_training_time", "logger.info", "train.validate", "fairseq.checkpoint_utils.save_checkpoint"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.should_stop_early", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.cumulative_training_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.validate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint"], ["", "def", "validate_and_save", "(", "\n", "cfg", ":", "DictConfig", ",", "\n", "trainer", ":", "Trainer", ",", "\n", "task", ":", "tasks", ".", "FairseqTask", ",", "\n", "epoch_itr", ",", "\n", "valid_subsets", ":", "List", "[", "str", "]", ",", "\n", "end_of_epoch", ":", "bool", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Optional", "[", "float", "]", "]", ",", "bool", "]", ":", "\n", "    ", "num_updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "max_update", "=", "cfg", ".", "optimization", ".", "max_update", "or", "math", ".", "inf", "\n", "\n", "# Stopping conditions (and an additional one based on validation loss later", "\n", "# on)", "\n", "should_stop", "=", "False", "\n", "if", "num_updates", ">=", "max_update", ":", "\n", "        ", "should_stop", "=", "True", "\n", "logger", ".", "info", "(", "\n", "f\"Stopping training due to \"", "\n", "f\"num_updates: {num_updates} >= max_update: {max_update}\"", "\n", ")", "\n", "\n", "", "training_time_hours", "=", "trainer", ".", "cumulative_training_time", "(", ")", "/", "(", "60", "*", "60", ")", "\n", "if", "(", "\n", "cfg", ".", "optimization", ".", "stop_time_hours", ">", "0", "\n", "and", "training_time_hours", ">", "cfg", ".", "optimization", ".", "stop_time_hours", "\n", ")", ":", "\n", "        ", "should_stop", "=", "True", "\n", "logger", ".", "info", "(", "\n", "f\"Stopping training due to \"", "\n", "f\"cumulative_training_time: {training_time_hours} > \"", "\n", "f\"stop_time_hours: {cfg.optimization.stop_time_hours} hour(s)\"", "\n", ")", "\n", "\n", "", "do_save", "=", "(", "\n", "(", "end_of_epoch", "and", "epoch_itr", ".", "epoch", "%", "cfg", ".", "checkpoint", ".", "save_interval", "==", "0", ")", "\n", "or", "should_stop", "\n", "or", "(", "\n", "cfg", ".", "checkpoint", ".", "save_interval_updates", ">", "0", "\n", "and", "num_updates", ">", "0", "\n", "and", "num_updates", "%", "cfg", ".", "checkpoint", ".", "save_interval_updates", "==", "0", "\n", "and", "num_updates", ">=", "cfg", ".", "dataset", ".", "validate_after_updates", "\n", ")", "\n", ")", "\n", "do_validate", "=", "(", "\n", "(", "not", "end_of_epoch", "and", "do_save", ")", "# validate during mid-epoch saves", "\n", "or", "(", "end_of_epoch", "and", "epoch_itr", ".", "epoch", "%", "cfg", ".", "dataset", ".", "validate_interval", "==", "0", ")", "\n", "or", "should_stop", "\n", "or", "(", "\n", "cfg", ".", "dataset", ".", "validate_interval_updates", ">", "0", "\n", "and", "num_updates", ">", "0", "\n", "and", "num_updates", "%", "cfg", ".", "dataset", ".", "validate_interval_updates", "==", "0", "\n", ")", "\n", ")", "and", "not", "cfg", ".", "dataset", ".", "disable_validation", "\n", "\n", "# Validate", "\n", "valid_losses", "=", "[", "None", "]", "\n", "if", "do_validate", ":", "\n", "        ", "valid_losses", "=", "validate", "(", "cfg", ",", "trainer", ",", "task", ",", "epoch_itr", ",", "valid_subsets", ")", "\n", "\n", "", "should_stop", "|=", "should_stop_early", "(", "cfg", ",", "valid_losses", "[", "0", "]", ")", "\n", "\n", "# Save checkpoint", "\n", "if", "do_save", "or", "should_stop", ":", "\n", "        ", "checkpoint_utils", ".", "save_checkpoint", "(", "\n", "cfg", ".", "checkpoint", ",", "trainer", ",", "epoch_itr", ",", "valid_losses", "[", "0", "]", "\n", ")", "\n", "\n", "", "return", "valid_losses", ",", "should_stop", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.get_training_stats": [[357, 360], ["round", "fairseq.logging.metrics.get_meter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter"], ["", "def", "get_training_stats", "(", "stats", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "stats", "[", "\"wall\"", "]", "=", "round", "(", "metrics", ".", "get_meter", "(", "\"default\"", ",", "\"wall\"", ")", ".", "elapsed_time", ",", "0", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.validate": [[362, 420], ["trainer.begin_valid_epoch", "fairseq.utils.set_torch_seed", "logger.info", "trainer.get_valid_iterator().next_epoch_itr", "fairseq.logging.progress_bar.progress_bar", "train.get_valid_stats", "progress_bar.progress_bar.print", "valid_losses.append", "fairseq.utils.tpu_data_loader", "fairseq.logging.metrics.aggregate", "agg.get_smoothed_values", "trainer.get_valid_iterator", "os.environ.get", "trainer.valid_step", "trainer.get_num_updates", "fairseq.distributed_utils.is_master", "fairseq.distributed_utils.is_master", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_valid_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.get_valid_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.tpu_data_loader", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_valid_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master"], ["", "def", "validate", "(", "\n", "cfg", ":", "DictConfig", ",", "\n", "trainer", ":", "Trainer", ",", "\n", "task", ":", "tasks", ".", "FairseqTask", ",", "\n", "epoch_itr", ",", "\n", "subsets", ":", "List", "[", "str", "]", ",", "\n", ")", "->", "List", "[", "Optional", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"Evaluate the model on the validation set(s) and return the losses.\"\"\"", "\n", "\n", "if", "cfg", ".", "dataset", ".", "fixed_validation_seed", "is", "not", "None", ":", "\n", "# set fixed seed for every validation", "\n", "        ", "utils", ".", "set_torch_seed", "(", "cfg", ".", "dataset", ".", "fixed_validation_seed", ")", "\n", "\n", "", "trainer", ".", "begin_valid_epoch", "(", "epoch_itr", ".", "epoch", ")", "\n", "valid_losses", "=", "[", "]", "\n", "for", "subset", "in", "subsets", ":", "\n", "        ", "logger", ".", "info", "(", "'begin validation on \"{}\" subset'", ".", "format", "(", "subset", ")", ")", "\n", "\n", "# Initialize data iterator", "\n", "itr", "=", "trainer", ".", "get_valid_iterator", "(", "subset", ")", ".", "next_epoch_itr", "(", "\n", "shuffle", "=", "False", ",", "set_dataset_epoch", "=", "False", "# use a fixed valid set", "\n", ")", "\n", "if", "cfg", ".", "common", ".", "tpu", ":", "\n", "            ", "itr", "=", "utils", ".", "tpu_data_loader", "(", "itr", ")", "\n", "", "progress", "=", "progress_bar", ".", "progress_bar", "(", "\n", "itr", ",", "\n", "log_format", "=", "cfg", ".", "common", ".", "log_format", ",", "\n", "log_interval", "=", "cfg", ".", "common", ".", "log_interval", ",", "\n", "epoch", "=", "epoch_itr", ".", "epoch", ",", "\n", "prefix", "=", "f\"valid on '{subset}' subset\"", ",", "\n", "tensorboard_logdir", "=", "(", "\n", "cfg", ".", "common", ".", "tensorboard_logdir", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", "\n", "else", "None", "\n", ")", ",", "\n", "default_log_format", "=", "(", "\"tqdm\"", "if", "not", "cfg", ".", "common", ".", "no_progress_bar", "else", "\"simple\"", ")", ",", "\n", "wandb_project", "=", "(", "\n", "cfg", ".", "common", ".", "wandb_project", "\n", "if", "distributed_utils", ".", "is_master", "(", "cfg", ".", "distributed_training", ")", "\n", "else", "None", "\n", ")", ",", "\n", "wandb_run_name", "=", "os", ".", "environ", ".", "get", "(", "\n", "\"WANDB_NAME\"", ",", "os", ".", "path", ".", "basename", "(", "cfg", ".", "checkpoint", ".", "save_dir", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "# create a new root metrics aggregator so validation metrics", "\n", "# don't pollute other aggregators (e.g., train meters)", "\n", "with", "metrics", ".", "aggregate", "(", "new_root", "=", "True", ")", "as", "agg", ":", "\n", "            ", "for", "sample", "in", "progress", ":", "\n", "                ", "trainer", ".", "valid_step", "(", "sample", ")", "\n", "\n", "# log validation stats", "\n", "", "", "stats", "=", "get_valid_stats", "(", "cfg", ",", "trainer", ",", "agg", ".", "get_smoothed_values", "(", ")", ")", "\n", "progress", ".", "print", "(", "stats", ",", "tag", "=", "subset", ",", "step", "=", "trainer", ".", "get_num_updates", "(", ")", ")", "\n", "\n", "valid_losses", ".", "append", "(", "stats", "[", "cfg", ".", "checkpoint", ".", "best_checkpoint_metric", "]", ")", "\n", "", "return", "valid_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.get_valid_stats": [[422, 434], ["trainer.get_num_updates", "hasattr", "best_function"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "get_valid_stats", "(", "\n", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", ",", "stats", ":", "Dict", "[", "str", ",", "Any", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "stats", "[", "\"num_updates\"", "]", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "if", "hasattr", "(", "checkpoint_utils", ".", "save_checkpoint", ",", "\"best\"", ")", ":", "\n", "        ", "key", "=", "\"best_{0}\"", ".", "format", "(", "cfg", ".", "checkpoint", ".", "best_checkpoint_metric", ")", "\n", "best_function", "=", "max", "if", "cfg", ".", "checkpoint", ".", "maximize_best_checkpoint_metric", "else", "min", "\n", "stats", "[", "key", "]", "=", "best_function", "(", "\n", "checkpoint_utils", ".", "save_checkpoint", ".", "best", ",", "\n", "stats", "[", "cfg", ".", "checkpoint", ".", "best_checkpoint_metric", "]", ",", "\n", ")", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.cli_main": [[436, 450], ["fairseq.options.get_training_parser", "fairseq.options.parse_args_and_arch", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.distributed_utils.call_main", "torch.cuda.profiler.profile", "torch.autograd.profiler.emit_nvtx", "fairseq.distributed_utils.call_main"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_training_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.call_main"], ["", "def", "cli_main", "(", "\n", "modify_parser", ":", "Optional", "[", "Callable", "[", "[", "argparse", ".", "ArgumentParser", "]", ",", "None", "]", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "    ", "parser", "=", "options", ".", "get_training_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ",", "modify_parser", "=", "modify_parser", ")", "\n", "\n", "cfg", "=", "convert_namespace_to_omegaconf", "(", "args", ")", "\n", "\n", "if", "args", ".", "profile", ":", "\n", "        ", "with", "torch", ".", "cuda", ".", "profiler", ".", "profile", "(", ")", ":", "\n", "            ", "with", "torch", ".", "autograd", ".", "profiler", ".", "emit_nvtx", "(", ")", ":", "\n", "                ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "main", ")", "\n", "", "", "", "else", ":", "\n", "        ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "main", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.hydra_train.hydra_main": [[25, 64], ["hydra.main", "fairseq.dataclass.initialize.add_defaults", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "hydra_train.reset_logging", "omegaconf.OmegaConf.to_container", "fairseq.metrics.get_smoothed_value", "float", "os.path.join", "omegaconf.open_dict", "omegaconf.OmegaConf.to_container", "fairseq.distributed_utils.call_main", "torch.cuda.profiler.profile", "logger.error", "hydra.core.hydra_config.HydraConfig.get", "torch.autograd.profiler.emit_nvtx", "fairseq.distributed_utils.call_main", "str"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.main", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.initialize.add_defaults", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.hydra_train.reset_logging", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_value", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.call_main"], ["@", "hydra", ".", "main", "(", "config_path", "=", "os", ".", "path", ".", "join", "(", "\"..\"", ",", "\"fairseq\"", ",", "\"config\"", ")", ",", "config_name", "=", "\"config\"", ")", "\n", "def", "hydra_main", "(", "cfg", ":", "FairseqConfig", ")", "->", "float", ":", "\n", "    ", "add_defaults", "(", "cfg", ")", "\n", "\n", "if", "cfg", ".", "common", ".", "reset_logging", ":", "\n", "        ", "reset_logging", "(", ")", "# Hydra hijacks logging, fix that", "\n", "", "else", ":", "\n", "        ", "with", "open_dict", "(", "cfg", ")", ":", "\n", "# make hydra logging work with ddp (see # see https://github.com/facebookresearch/hydra/issues/1126)", "\n", "            ", "cfg", ".", "job_logging_cfg", "=", "OmegaConf", ".", "to_container", "(", "HydraConfig", ".", "get", "(", ")", ".", "job_logging", ",", "resolve", "=", "True", ")", "\n", "\n", "", "", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ",", "enum_to_str", "=", "True", ")", ")", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "try", ":", "\n", "        ", "if", "cfg", ".", "common", ".", "profile", ":", "\n", "            ", "with", "torch", ".", "cuda", ".", "profiler", ".", "profile", "(", ")", ":", "\n", "                ", "with", "torch", ".", "autograd", ".", "profiler", ".", "emit_nvtx", "(", ")", ":", "\n", "                    ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "pre_main", ")", "\n", "", "", "", "else", ":", "\n", "            ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "pre_main", ")", "\n", "", "", "except", "BaseException", "as", "e", ":", "\n", "        ", "if", "not", "cfg", ".", "common", ".", "suppress_crashes", ":", "\n", "            ", "raise", "\n", "", "else", ":", "\n", "            ", "logger", ".", "error", "(", "\"Crashed! \"", "+", "str", "(", "e", ")", ")", "\n", "\n", "# get best val and return - useful for sweepers", "\n", "", "", "try", ":", "\n", "        ", "best_val", "=", "metrics", ".", "get_smoothed_value", "(", "\n", "\"valid\"", ",", "cfg", ".", "checkpoint", ".", "best_checkpoint_metric", "\n", ")", "\n", "", "except", ":", "\n", "        ", "best_val", "=", "None", "\n", "\n", "", "if", "best_val", "is", "None", ":", "\n", "        ", "best_val", "=", "float", "(", "\"inf\"", ")", "\n", "\n", "", "return", "best_val", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.hydra_train.reset_logging": [[66, 79], ["logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.removeHandler", "os.environ.get().upper", "logging.Formatter", "os.environ.get"], "function", ["None"], ["", "def", "reset_logging", "(", ")", ":", "\n", "    ", "root", "=", "logging", ".", "getLogger", "(", ")", "\n", "for", "handler", "in", "root", ".", "handlers", ":", "\n", "        ", "root", ".", "removeHandler", "(", "handler", ")", "\n", "", "root", ".", "setLevel", "(", "os", ".", "environ", ".", "get", "(", "\"LOGLEVEL\"", ",", "\"INFO\"", ")", ".", "upper", "(", ")", ")", "\n", "handler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "handler", ".", "setFormatter", "(", "\n", "logging", ".", "Formatter", "(", "\n", "fmt", "=", "\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\"", ",", "\n", "datefmt", "=", "\"%Y-%m-%d %H:%M:%S\"", ",", "\n", ")", "\n", ")", "\n", "root", ".", "addHandler", "(", "handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.hydra_train.cli_main": [[81, 92], ["fairseq.dataclass.initialize.hydra_init", "hydra_train.hydra_main", "logger.warning", "get_args"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.initialize.hydra_init", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.hydra_train.hydra_main"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "from", "hydra", ".", "_internal", ".", "utils", "import", "get_args", "\n", "\n", "cfg_name", "=", "get_args", "(", ")", ".", "config_name", "or", "\"config\"", "\n", "", "except", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Failed to get config name from hydra args\"", ")", "\n", "cfg_name", "=", "\"config\"", "\n", "\n", "", "hydra_init", "(", "cfg_name", ")", "\n", "hydra_main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.get_parser": [[16, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root\"", ",", "default", "=", "'/code/gitRepo/data/aihub/ksponspeech'", ",", "metavar", "=", "\"DIR\"", ",", "\n", "help", "=", "\"root directory containing flac files to index\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--info\"", ",", "default", "=", "None", ",", "metavar", "=", "\"DIR\"", ",", "\n", "help", "=", "\"\uc804\ucc98\ub9ac \ucd94\uac00\uc801\uc73c\ub85c \uc218\ud589\ud55c \uac83.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_info\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\uc804\ucc98\ub9ac \ucd94\uac00\uc801\uc73c\ub85c \uc218\ud589\ud560\uc9c0 \uc5ec\ubd80 \ud655\uc778\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_remove\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\ud55c\uae00 \uc74c\uc18c\uac00 \uc544\ub2cc \uc22b\uc790, \uc601\uc5b4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \ubaa8\ub4e0 \ub2e8\uc5b4\ub97c \uc0ad\uc81c\ud560\uc9c0 \uc5ec\ubd80 \ud655\uc778\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--token_limit\"", ",", "default", "=", "sys", ".", "maxsize", ",", "type", "=", "int", ",", "\n", "help", "=", "\"\ucd5c\ub300 \uae00\uc790\uc218 \uccb4\ud06c\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dest\"", ",", "default", "=", "'manifest_temp'", ",", "type", "=", "str", ",", "metavar", "=", "\"DIR\"", ",", "help", "=", "\"output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ext\"", ",", "default", "=", "\"pcm\"", ",", "type", "=", "str", ",", "metavar", "=", "\"EXT\"", ",", "help", "=", "\"extension to look for\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess_mode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'phonetic'", ",", "\n", "help", "=", "'Ex) (70%)/(\uce60 \uc2ed \ud37c\uc13c\ud2b8) \ud655\ub960\uc774\ub77c\ub2c8 (\ubb50 \ubb54)/(\ubaa8 \ubaac) \uc18c\ub9ac\uc57c \uc9c4\uc9dc (100%)/(\ubc31 \ud504\ub85c)\uac00 \uc65c \uc548\ub3fc?'", "\n", "'phonetic: \uce60 \uc2ed \ud37c\uc13c\ud2b8 \ud655\ub960\uc774\ub77c\ub2c8 \ubaa8 \ubaac \uc18c\ub9ac\uc57c \uc9c4\uc9dc \ubc31 \ud504\ub85c\uac00 \uc65c \uc548\ub3fc?'", "\n", "'spelling: 70% \ud655\ub960\uc774\ub77c\ub2c8 \ubb50 \ubb54 \uc18c\ub9ac\uc57c \uc9c4\uc9dc 100%\uac00 \uc65c \uc548\ub3fc?'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_unit'", ",", "type", "=", "str", ",", "\n", "default", "=", "'grapheme'", ",", "\n", "help", "=", "'character or subword or grapheme'", ")", "\n", "parser", ".", "add_argument", "(", "'--additional_output_unit'", ",", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'character or subword or grapheme'", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"random seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--time\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"MIN\"", ",", "\n", "help", "=", "\"set if you want make split manifest\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--script_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "\"/code/gitRepo/data/aihub/ksponspeech/KsponSpeech_scripts\"", ",", "\n", "help", "=", "'AIHUB\uc5d0\uc11c \uc81c\uacf5\ud574 \uc8fc\ub294 \uc2a4\ud06c\ub9bd\ud2b8 \ud3f4\ub354'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--del_silence\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\uc74c\uc131\uc774 \uc5c6\ub294 \uacf3\uc744 \uc0ad\uc81c\ud558\ub294 \uac74 \uc5b4\ub54c?\"", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.find_index": [[75, 80], ["range", "len", "len", "sum"], "function", ["None"], ["", "def", "find_index", "(", "durations", ",", "limit", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "durations", ")", ")", ":", "\n", "        ", "if", "sum", "(", "durations", "[", ":", "idx", "]", ")", ">", "limit", ":", "\n", "            ", "return", "idx", "\n", "", "", "return", "len", "(", "durations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.set_seed": [[81, 84], ["random.seed", "numpy.random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_yaml": [[86, 91], ["open", "yaml.load"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "def", "load_yaml", "(", "yaml_path", ")", ":", "\n", "# Read YAML file", "\n", "    ", "with", "open", "(", "yaml_path", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "data_loaded", "=", "yaml", ".", "load", "(", "stream", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "", "return", "data_loaded", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_info": [[93, 104], ["os.path.isdir", "os.path.join", "make_manifest.load_yaml", "info_data.update", "os.listdir"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_yaml", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "load_info", "(", "info_path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "info_path", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "info_files", "=", "[", "filename", "for", "filename", "in", "os", ".", "listdir", "(", "info_path", ")", "if", "'.yaml'", "in", "filename", "]", "\n", "info_data", "=", "{", "}", "\n", "for", "filename", "in", "info_files", ":", "\n", "        ", "file_path", "=", "os", ".", "path", ".", "join", "(", "info_path", ",", "filename", ")", "\n", "temp_data", "=", "load_yaml", "(", "file_path", ")", "\n", "info_data", ".", "update", "(", "temp_data", ")", "\n", "", "return", "info_data", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_converted_info": [[105, 112], ["len", "open", "yaml.dump", "sorted", "os.path.join", "converted_info.items", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "save_converted_info", "(", "args", ",", "name", ",", "converted_info", ")", ":", "\n", "    ", "if", "len", "(", "converted_info", ")", "==", "0", ":", "\n", "        ", "return", "\n", "\n", "", "yaml_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "sorted", "(", "converted_info", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "(", "len", "(", "item", "[", "0", "]", ")", ",", "item", "[", "0", "]", ")", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "'{}.yaml'", ".", "format", "(", "name", ")", ")", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "write_f", ":", "\n", "        ", "yaml", ".", "dump", "(", "yaml_dict", ",", "write_f", ",", "allow_unicode", "=", "True", ",", "default_style", "=", "None", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_wrong_script": [[114, 137], ["re.compile", "zip", "grapheme_transcript.split", "len", "open", "yaml.dump", "pathlib.Path().stem.split", "len", "sorted", "os.path.join", "grapheme.isdigit", "re.compile.match", "str", "yaml_dict.items", "raw_sentence.replace", "pathlib.Path", "len", "fileitem.split"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "", "def", "save_wrong_script", "(", "args", ",", "name", ",", "transcripts", ",", "fileinfo", ",", "raw_sentences", ",", "new_sentences", ")", ":", "\n", "## \ud2c0\ub9b0 \uac83 \uc800\uc7a5\ud558\uae30", "\n", "\n", "## \uc54c\ud30c\ubcb3 \ucd94\uac00", "\n", "    ", "reg", "=", "re", ".", "compile", "(", "r'[A-Z]'", ")", "\n", "yaml_dict", "=", "{", "}", "\n", "for", "grapheme_transcript", ",", "fileitem", ",", "raw_sentence", ",", "new_sentence", "in", "zip", "(", "transcripts", ",", "fileinfo", ",", "raw_sentences", ",", "\n", "new_sentences", ")", ":", "\n", "        ", "graphemes", "=", "grapheme_transcript", ".", "split", "(", ")", "\n", "file_num", "=", "Path", "(", "fileitem", ".", "split", "(", ")", "[", "0", "]", ")", ".", "stem", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "\n", "assert", "len", "(", "file_num", ")", "==", "6", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", ".", "isdigit", "(", ")", "or", "reg", ".", "match", "(", "grapheme", ")", ":", "\n", "                ", "yaml_dict", "[", "file_num", "]", "=", "str", "(", "raw_sentence", ".", "replace", "(", "'\\n'", ",", "''", ")", ")", "\n", "\n", "", "", "", "if", "len", "(", "yaml_dict", ")", "==", "0", ":", "\n", "        ", "return", "\n", "\n", "## Sorting", "\n", "", "yaml_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "sorted", "(", "yaml_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "(", "len", "(", "item", "[", "0", "]", ")", ",", "item", "[", "0", "]", ")", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "'{}.yaml'", ".", "format", "(", "name", ")", ")", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "write_f", ":", "\n", "        ", "yaml", ".", "dump", "(", "yaml_dict", ",", "write_f", ",", "allow_unicode", "=", "True", ",", "default_style", "=", "None", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_dict": [[139, 172], ["list", "list", "zip", "grapheme_transcript.split", "open", "enumerate", "open", "print", "print", "print", "print", "print", "print", "sorted", "os.path.join", "zip", "print", "os.path.join", "print", "list.append", "list.append", "zip", "list.index"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["", "", "def", "save_dict", "(", "args", ",", "transcripts", ",", "dict_name", "=", "'dict.ltr.txt'", ",", "alphabet_name", "=", "'alphabet.txt'", ")", ":", "\n", "    ", "vocab_list", "=", "list", "(", ")", "\n", "vocab_freq", "=", "list", "(", ")", "\n", "for", "grapheme_transcript", "in", "transcripts", ":", "\n", "        ", "graphemes", "=", "grapheme_transcript", ".", "split", "(", ")", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "vocab_list", ":", "\n", "                ", "vocab_list", ".", "append", "(", "grapheme", ")", "\n", "vocab_freq", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "vocab_freq", "[", "vocab_list", ".", "index", "(", "grapheme", ")", "]", "+=", "1", "\n", "\n", "## write ltr", "\n", "", "", "", "vocab_freq", ",", "vocab_list", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "vocab_freq", ",", "vocab_list", ")", ",", "reverse", "=", "True", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "dict_name", ")", ",", "'w'", ")", "as", "write_f", ":", "\n", "        ", "for", "idx", ",", "(", "grpm", ",", "freq", ")", "in", "enumerate", "(", "zip", "(", "vocab_list", ",", "vocab_freq", ")", ")", ":", "\n", "            ", "print", "(", "\"{} {}\"", ".", "format", "(", "grpm", ",", "freq", ")", ",", "file", "=", "write_f", ")", "\n", "\n", "## Write Vocab files", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "alphabet_name", ")", ",", "'w'", ",", "encoding", "=", "'UTF8'", ")", "as", "write_f", ":", "\n", "        ", "print", "(", "\"# Each line in this file represents the Unicode codepoint (UTF-8 encoded)\"", ",", "file", "=", "write_f", ")", "\n", "print", "(", "\"# associated with a numeric label.\"", ",", "file", "=", "write_f", ")", "\n", "print", "(", "\"# A line that starts with # is a comment. You can escape it with \\# if you wish\"", ",", "file", "=", "write_f", ")", "\n", "print", "(", "\"# to use '#' as a label.\"", ",", "file", "=", "write_f", ")", "\n", "for", "token", "in", "vocab_list", ":", "\n", "            ", "print", "(", "token", ",", "file", "=", "write_f", ")", "\n", "## final token must be \\n", "\n", "", "print", "(", "''", ",", "file", "=", "write_f", ")", "\n", "\n", "print", "(", "\"# The last (non-comment) line needs to end with a newline.\"", ",", "file", "=", "write_f", ",", "end", "=", "''", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_lexicon": [[173, 187], ["text.split", "open", "vocab_list.items", "sorted", "os.path.join", "print", "vocab_list.items"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "save_lexicon", "(", "args", ",", "texts", ",", "lexicon_name", "=", "'lexicon.lst'", ")", ":", "\n", "    ", "vocab_list", "=", "{", "}", "\n", "for", "text", "in", "texts", ":", "\n", "        ", "for", "word", "in", "text", ".", "split", "(", ")", ":", "\n", "            ", "new_word", "=", "word", "+", "\"|\"", "\n", "vocab_list", "[", "word", "]", "=", "\" \"", ".", "join", "(", "new_word", ")", "\n", "\n", "## Write Vocab files", "\n", "## Sorting", "\n", "", "", "vocab_list", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "sorted", "(", "vocab_list", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "0", "]", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "lexicon_name", ")", ",", "'w'", ",", "encoding", "=", "'UTF8'", ")", "as", "write_f", ":", "\n", "        ", "for", "k", ",", "v", "in", "vocab_list", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "\"{}\\t{}\"", ".", "format", "(", "k", ",", "v", ")", ",", "file", "=", "write_f", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files": [[191, 206], ["print", "open", "open", "open", "print", "zip", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "save_files", "(", "args", ",", "file_name", ",", "dir_path", ",", "fileinfo", ",", "texts", ",", "transcripts", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "file_name", "+", "\".tsv\"", ")", ",", "'w'", ")", "as", "tsv_out", ",", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "file_name", "+", "\".ltr\"", ")", ",", "\"w\"", "\n", ")", "as", "ltr_out", ",", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "file_name", "+", "\".wrd\"", ")", ",", "\"w\"", "\n", ")", "as", "wrd_out", ":", "\n", "\n", "        ", "print", "(", "dir_path", ",", "file", "=", "tsv_out", ")", "\n", "for", "tsv_item", ",", "wrd_item", ",", "ltr_item", "in", "zip", "(", "fileinfo", ",", "texts", ",", "transcripts", ")", ":", "\n", "            ", "print", "(", "tsv_item", ",", "file", "=", "tsv_out", ")", "\n", "print", "(", "wrd_item", ",", "file", "=", "wrd_out", ")", "\n", "print", "(", "ltr_item", "+", "\" |\"", ",", "file", "=", "ltr_out", ")", "\n", "\n", "", "", "print", "(", "\"save files [{}]\"", ".", "format", "(", "file_name", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.pcm2wav": [[209, 225], ["str", "pathlib.Path().with_suffix", "ValueError", "open", "opened_pcm_file.read", "wave.open", "obj2write.setnchannels", "obj2write.setsampwidth", "obj2write.setframerate", "obj2write.writeframes", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "pcm2wav", "(", "pcm_file", ",", "channels", "=", "1", ",", "bit_depth", "=", "16", ",", "sampling_rate", "=", "16000", ")", ":", "\n", "    ", "wav_file", "=", "str", "(", "Path", "(", "pcm_file", ")", ".", "with_suffix", "(", "'.wav'", ")", ")", "\n", "# Check if the options are valid.", "\n", "if", "bit_depth", "%", "8", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"bit_depth \"", "+", "str", "(", "bit_depth", ")", "+", "\" must be a multiple of 8.\"", ")", "\n", "\n", "# Read the .pcm file as a binary file and store the data to pcm_data", "\n", "", "with", "open", "(", "pcm_file", ",", "'rb'", ")", "as", "opened_pcm_file", ":", "\n", "        ", "pcm_data", "=", "opened_pcm_file", ".", "read", "(", ")", "\n", "with", "wave", ".", "open", "(", "wav_file", ",", "'wb'", ")", "as", "obj2write", ":", "\n", "            ", "obj2write", ".", "setnchannels", "(", "channels", ")", "\n", "obj2write", ".", "setsampwidth", "(", "bit_depth", "//", "8", ")", "\n", "obj2write", ".", "setframerate", "(", "sampling_rate", ")", "\n", "obj2write", ".", "writeframes", "(", "pcm_data", ")", "\n", "\n", "", "", "return", "wav_file", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_script": [[226, 331], ["os.path.isfile", "list", "list", "list", "list", "list", "list", "list", "list", "list", "re.compile", "print", "print", "print", "open", "tqdm.tqdm", "line.split", "os.path.join", "os.path.realpath", "str", "len", "list.append", "list.append", "list.append", "list.append", "list.append", "librosa.effects.split", "numpy.concatenate", "len", "preprocess.preprocess", "raw_sentence.replace", "len", "re.compile.match", "list.append", "list.append", "pathlib.Path().stem.split", "len", "librosa.load", "ValueError", "unicodedata.normalize().upper", "list.append", "list.append", "ValueError", "list.append", "list.append", "os.path.relpath", "numpy.memmap().astype", "make_manifest.pcm2wav", "librosa.load", "raw_sentence.replace.upper", "unicodedata.normalize().upper", "list.append", "list.append", "ValueError", "unicodedata.normalize", "list", "raw_sentence.replace.upper", "pathlib.Path", "numpy.memmap", "unicodedata.normalize().replace", "raw_sentence.replace.replace().upper", "unicodedata.normalize", "list", "unicodedata.normalize().replace", "raw_sentence.replace.replace().upper", "unicodedata.normalize", "raw_sentence.replace.replace", "unicodedata.normalize", "raw_sentence.replace.replace"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.preprocess", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.pcm2wav", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "def", "load_script", "(", "args", ",", "script_path", ",", "info_data", ",", "token_limit", "=", "sys", ".", "maxsize", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "isfile", "(", "script_path", ")", "\n", "\n", "fileinfo", "=", "list", "(", ")", "\n", "durations", "=", "list", "(", ")", "\n", "texts", "=", "list", "(", ")", "\n", "audio_nums", "=", "list", "(", ")", "\n", "transcripts", "=", "list", "(", ")", "\n", "\n", "additional_texts", "=", "list", "(", ")", "\n", "additional_transcripts", "=", "list", "(", ")", "\n", "\n", "raw_sentences", "=", "list", "(", ")", "\n", "new_sentences", "=", "list", "(", ")", "\n", "\n", "converted_info", "=", "{", "}", "\n", "\n", "reg", "=", "re", ".", "compile", "(", "r'.*[a-zA-Z0-9]'", ")", "\n", "limit_count", "=", "0", "\n", "remove_count", "=", "0", "\n", "with", "open", "(", "script_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "            ", "convert_flag", "=", "False", "\n", "\n", "items", "=", "line", ".", "split", "(", "\" :: \"", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "items", "[", "0", "]", ")", "\n", "file_path", "=", "os", ".", "path", ".", "realpath", "(", "file_path", ")", "\n", "audio_num", "=", "str", "(", "Path", "(", "file_path", ")", ".", "stem", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "raw_sentence", "=", "items", "[", "1", "]", "\n", "if", "len", "(", "audio_num", ")", "==", "6", "and", "audio_num", "in", "info_data", ":", "\n", "                ", "raw_sentence", "=", "info_data", "[", "audio_num", "]", "\n", "convert_flag", "=", "True", "\n", "\n", "## \ud655\uc7a5\uc790 \ud655\uc778", "\n", "", "if", "args", ".", "ext", "==", "'pcm'", ":", "\n", "                ", "try", ":", "\n", "                    ", "wav", "=", "np", ".", "memmap", "(", "file_path", ",", "dtype", "=", "'h'", ",", "mode", "=", "'r'", ")", ".", "astype", "(", "'float32'", ")", "/", "32767", "\n", "sr", "=", "16000", "\n", "", "except", "ValueError", ":", "\n", "# print('pcm load \uc5d0\ub7ec wave\ub85c \uad50\uccb4 [{}]'.format(file_path))", "\n", "                    ", "file_path", "=", "pcm2wav", "(", "file_path", ")", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "file_path", ",", "sr", "=", "16000", ")", "\n", "\n", "", "", "elif", "args", ".", "ext", "in", "[", "'flac'", ",", "'wav'", "]", ":", "\n", "                ", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "file_path", ",", "sr", "=", "16000", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported extention method : {0}\"", ".", "format", "(", "args", ".", "ext", ")", ")", "\n", "\n", "", "if", "args", ".", "del_silence", ":", "\n", "                ", "non_silence_indices", "=", "librosa", ".", "effects", ".", "split", "(", "wav", ",", "top_db", "=", "30", ")", "\n", "wav", "=", "np", ".", "concatenate", "(", "[", "wav", "[", "start", ":", "end", "]", "for", "start", ",", "end", "in", "non_silence_indices", "]", ")", "\n", "", "frames", "=", "len", "(", "wav", ")", "\n", "\n", "if", "len", "(", "audio_num", ")", "==", "6", ":", "\n", "                ", "new_sentence", "=", "preprocess", "(", "raw_sentence", "=", "raw_sentence", ",", "mode", "=", "args", ".", "preprocess_mode", ",", "audio_num", "=", "audio_num", ")", "\n", "", "else", ":", "\n", "                ", "new_sentence", "=", "raw_sentence", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "\n", "##################################", "\n", "", "if", "len", "(", "new_sentence", ")", ">", "token_limit", ":", "\n", "                ", "limit_count", "+=", "1", "\n", "continue", "\n", "\n", "", "if", "args", ".", "do_remove", "and", "reg", ".", "match", "(", "new_sentence", ")", "and", "args", ".", "preprocess_mode", "!=", "'spelling'", ":", "\n", "                ", "converted_info", "[", "audio_num", "]", "=", "new_sentence", "\n", "remove_count", "+=", "1", "\n", "continue", "\n", "#################################", "\n", "\n", "\n", "## \uc800\uc7a5 \ubaa8\ub4dc\ub294 \uc5ec\uae30\uc5d0 \ucd94\uac00\ud558\uae30.", "\n", "", "if", "args", ".", "output_unit", "==", "'grapheme'", ":", "\n", "                ", "texts", ".", "append", "(", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "new_sentence", ")", ".", "upper", "(", ")", ")", "\n", "transcripts", ".", "append", "(", "\" \"", ".", "join", "(", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "new_sentence", ")", ".", "replace", "(", "' '", ",", "'|'", ")", ")", ".", "upper", "(", ")", ")", "\n", "", "elif", "args", ".", "output_unit", "==", "'character'", ":", "\n", "                ", "texts", ".", "append", "(", "new_sentence", ".", "upper", "(", ")", ")", "\n", "transcripts", ".", "append", "(", "\" \"", ".", "join", "(", "list", "(", "new_sentence", ".", "replace", "(", "' '", ",", "'|'", ")", ".", "upper", "(", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported preprocess method : {0}\"", ".", "format", "(", "args", ".", "output_unit", ")", ")", "\n", "\n", "## \uc800\uc7a5 \ubaa8\ub4dc\ub294 \uc5ec\uae30\uc5d0 \ucd94\uac00\ud558\uae30.", "\n", "", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "                ", "if", "args", ".", "additional_output_unit", "==", "'grapheme'", ":", "\n", "                    ", "additional_texts", ".", "append", "(", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "new_sentence", ")", ".", "upper", "(", ")", ")", "\n", "additional_transcripts", ".", "append", "(", "\" \"", ".", "join", "(", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "new_sentence", ")", ".", "replace", "(", "' '", ",", "'|'", ")", ")", ".", "upper", "(", ")", ")", "\n", "", "elif", "args", ".", "additional_output_unit", "==", "'character'", ":", "\n", "                    ", "additional_texts", ".", "append", "(", "new_sentence", ".", "upper", "(", ")", ")", "\n", "additional_transcripts", ".", "append", "(", "\" \"", ".", "join", "(", "list", "(", "new_sentence", ".", "replace", "(", "' '", ",", "'|'", ")", ".", "upper", "(", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Unsupported preprocess method : {0}\"", ".", "format", "(", "args", ".", "output_unit", ")", ")", "\n", "\n", "", "", "if", "convert_flag", ":", "\n", "                ", "converted_info", "[", "audio_num", "]", "=", "new_sentence", "\n", "\n", "## \ub123\uae30", "\n", "", "fileinfo", ".", "append", "(", "\"{}\\t{}\"", ".", "format", "(", "os", ".", "path", ".", "relpath", "(", "file_path", ",", "args", ".", "root", ")", ",", "frames", ")", ")", "\n", "durations", ".", "append", "(", "frames", ")", "\n", "audio_nums", ".", "append", "(", "audio_num", ")", "\n", "raw_sentences", ".", "append", "(", "raw_sentence", ")", "\n", "new_sentences", ".", "append", "(", "new_sentence", ")", "\n", "", "", "print", "(", "\"\ucd1d \ubb34\uc2dc\ub41c \uc22b\uc790 : \"", ",", "limit_count", "+", "remove_count", ")", "\n", "print", "(", "\"\uae38\uc774\ub97c \ub118\uaca8\uc11c \ubb34\uc2dc\ub41c \uc22b\uc790 : \"", ",", "limit_count", ")", "\n", "print", "(", "\"\uc22b\uc790\ub4f1\uc774 \uc788\uc5b4\uc11c \ubb34\uc2dc\ub41c \uc22b\uc790 : \"", ",", "remove_count", ")", "\n", "\n", "return", "fileinfo", ",", "durations", ",", "texts", ",", "audio_nums", ",", "transcripts", ",", "raw_sentences", ",", "new_sentences", ",", "converted_info", ",", "additional_texts", ",", "additional_transcripts", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.main": [[334, 456], ["os.path.realpath", "os.path.isdir", "os.path.exists", "os.makedirs", "make_manifest.load_info", "len", "print", "make_manifest.load_script", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "make_manifest.save_lexicon", "make_manifest.save_dict", "make_manifest.save_converted_info", "len", "make_manifest.save_files", "print", "make_manifest.load_script", "make_manifest.save_files", "make_manifest.save_converted_info", "print", "make_manifest.load_script", "make_manifest.save_files", "make_manifest.save_converted_info", "print", "make_manifest.load_script", "make_manifest.save_files", "make_manifest.save_converted_info", "os.listdir", "os.path.join", "make_manifest.save_lexicon", "make_manifest.save_dict", "random.shuffle", "make_manifest.find_index", "make_manifest.save_files", "os.path.join", "make_manifest.save_files", "os.path.join", "make_manifest.save_files", "os.path.join", "make_manifest.save_files", "enumerate", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_info", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_lexicon", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_converted_info", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_converted_info", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_converted_info", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.load_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_converted_info", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_lexicon", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.shuffle", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.find_index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.make_manifest.save_files"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "dest", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "dest", ")", "\n", "", "args", ".", "root", "=", "os", ".", "path", ".", "realpath", "(", "args", ".", "root", ")", "\n", "\n", "## --dataset_path \uc5d0 \uc788\uc5b4\uc57c \ud558\ub294 \ud3f4\ub354\ub4e4", "\n", "#for folder in ['KsponSpeech_01','KsponSpeech_02','KsponSpeech_03','KsponSpeech_04','KsponSpeech_05','KsponSpeech_eval']:", "\n", "#    if folder not in os.listdir(args.root):", "\n", "#        assert os.path.isdir(folder), \"root \uc704\uce58\uc5d0 \ud574\ub2f9 \ud3f4\ub354\uac00 \ubc18\ub4dc\uc2dc \ud544\uc694\ud569\ub2c8\ub2e4. [{}]\".format(folder)", "\n", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "script_path", ")", ",", "\"aihub\uc5d0\uc11c \uc81c\uacf5\ud574\uc8fc\ub294 \uc2a4\ud06c\ub9bd\ud2b8 \ud3f4\ub354\ub97c \ub123\uc5b4\uc8fc\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. script_path : [{}]\"", ".", "format", "(", "args", ".", "script_path", ")", "\n", "\n", "## Info \ud30c\uc77c \ubd88\ub7ec\uc624\uae30", "\n", "info_data", "=", "{", "}", "\n", "if", "args", ".", "do_info", ":", "\n", "## info \ud30c\uc77c \ubd88\ub7ec\uc624\uae30", "\n", "        ", "info_data", "=", "load_info", "(", "args", ".", "info", ")", "\n", "\n", "## .trn \ud655\uc7a5\uc790\ub9cc \ud655\uc778\ud568", "\n", "", "file_list", "=", "[", "file", "for", "file", "in", "os", ".", "listdir", "(", "args", ".", "script_path", ")", "if", "Path", "(", "file", ")", ".", "suffix", "==", "'.trn'", "]", "\n", "assert", "len", "(", "file_list", ")", ">", "0", ",", "\"\uc2a4\ud06c\ub9bd\ud2b8 \ud30c\uc77c\uc774 \ud55c\uac1c\ub3c4 \uc5c6\ub124\uc694 [{}]\"", ".", "format", "(", "args", ".", "script_path", ")", "\n", "\n", "## \uc2a4\ud06c\ub9bd\ud2b8 \uc77d\uc5b4\uc624\uae30.", "\n", "script_name", "=", "'train.trn'", "\n", "if", "script_name", "in", "file_list", ":", "\n", "        ", "print", "(", "\"generate [{}]\"", ".", "format", "(", "script_name", ")", ")", "\n", "fileinfo", ",", "durations", ",", "texts", ",", "audio_nums", ",", "transcripts", ",", "raw_sentences", ",", "new_sentences", ",", "converted_info", ",", "additional_texts", ",", "additional_transcripts", "=", "load_script", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "script_path", ",", "script_name", ")", ",", "info_data", ",", "token_limit", "=", "args", ".", "token_limit", ")", "\n", "fileinfo", "=", "np", ".", "array", "(", "fileinfo", ")", "\n", "durations", "=", "np", ".", "array", "(", "durations", ")", "\n", "texts", "=", "np", ".", "array", "(", "texts", ")", "\n", "transcripts", "=", "np", ".", "array", "(", "transcripts", ")", "\n", "\n", "## \ucd94\uac00\uc6a9", "\n", "additional_texts", "=", "np", ".", "array", "(", "additional_texts", ")", "\n", "additional_transcripts", "=", "np", ".", "array", "(", "additional_transcripts", ")", "\n", "\n", "## lexicon \ub9cc\ub4e4\uae30", "\n", "save_lexicon", "(", "args", ",", "texts", ",", "lexicon_name", "=", "'lexicon.lst'", ")", "\n", "## dictionary \uc800\uc7a5", "\n", "save_dict", "(", "args", ",", "transcripts", ",", "dict_name", "=", "'dict.ltr.txt'", ",", "alphabet_name", "=", "'alphabet.txt'", ")", "\n", "\n", "## \ucd94\uac00\uc6a9 \ub9cc\ub4e4\uae30", "\n", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "## lexicon \ub9cc\ub4e4\uae30", "\n", "            ", "save_lexicon", "(", "args", ",", "additional_texts", ",", "lexicon_name", "=", "'add_lexicon.lst'", ")", "\n", "## dictionary \uc800\uc7a5", "\n", "save_dict", "(", "args", ",", "additional_transcripts", ",", "dict_name", "=", "'add_dict.ltr.txt'", ",", "alphabet_name", "=", "'add_alphabet.txt'", ")", "\n", "\n", "#save_wrong_script(args, 'train_wrong',transcripts, fileinfo, raw_sentences, new_sentences)", "\n", "", "save_converted_info", "(", "args", ",", "'train_converted'", ",", "converted_info", ")", "\n", "\n", "## train \uc774\ub791 dev \ub098\ub220\uc11c \uc800\uc7a5", "\n", "train_ids", "=", "[", "idx", "for", "idx", ",", "num", "in", "enumerate", "(", "audio_nums", ")", "]", "\n", "limit_idx", "=", "len", "(", "train_ids", ")", "\n", "if", "args", ".", "time", "is", "not", "None", ":", "\n", "            ", "random", ".", "shuffle", "(", "train_ids", ")", "\n", "assert", "args", ".", "time", "in", "[", "'10min'", ",", "'1hour'", ",", "'10hour'", ",", "'100hour'", "]", ",", "'\uc124\uc815 \uc7ac\ub300\ub85c \ud574\ub77c...'", "\n", "time_limit", "=", "0", "\n", "if", "args", ".", "time", "==", "'10min'", ":", "\n", "## 16000 hz * 60\ucd08 * 10\ubd84", "\n", "                ", "time_limit", "=", "16000", "*", "60", "*", "10", "\n", "", "if", "args", ".", "time", "==", "'1hour'", ":", "\n", "## 16000 hz * 60\ucd08 * 60\ubd84 * 1", "\n", "                ", "time_limit", "=", "16000", "*", "60", "*", "60", "*", "1", "\n", "", "if", "args", ".", "time", "==", "'10hour'", ":", "\n", "## 16000 hz * 60\ucd08 * 60\ubd84 * 10", "\n", "                ", "time_limit", "=", "16000", "*", "60", "*", "60", "*", "10", "\n", "", "if", "args", ".", "time", "==", "'100hour'", ":", "\n", "## 16000 hz * 60\ucd08 * 60\ubd84 * 100", "\n", "                ", "time_limit", "=", "16000", "*", "60", "*", "60", "*", "100", "\n", "\n", "", "limit_idx", "=", "find_index", "(", "durations", "[", "train_ids", "]", ",", "time_limit", ")", "\n", "\n", "", "save_files", "(", "args", ",", "'train'", ",", "args", ".", "root", ",", "fileinfo", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ",", "texts", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ",", "\n", "transcripts", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ")", "\n", "## \ucd94\uac00\uc6a9 \ub9cc\ub4e4\uae30", "\n", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "            ", "save_files", "(", "args", ",", "'add_train'", ",", "args", ".", "root", ",", "fileinfo", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ",", "additional_texts", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ",", "\n", "additional_transcripts", "[", "train_ids", "[", ":", "limit_idx", "]", "]", ")", "\n", "\n", "## \uc2a4\ud06c\ub9bd\ud2b8 \uc77d\uc5b4\uc624\uae30.", "\n", "", "", "script_name", "=", "'dev.trn'", "\n", "if", "script_name", "in", "file_list", ":", "\n", "        ", "print", "(", "\"generate [{}]\"", ".", "format", "(", "script_name", ")", ")", "\n", "fileinfo", ",", "durations", ",", "texts", ",", "audio_nums", ",", "transcripts", ",", "raw_sentences", ",", "new_sentences", ",", "converted_info", ",", "additional_texts", ",", "additional_transcripts", "=", "load_script", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "script_path", ",", "script_name", ")", ",", "info_data", ")", "\n", "save_files", "(", "args", ",", "'dev'", ",", "args", ".", "root", ",", "fileinfo", ",", "texts", ",", "transcripts", ")", "\n", "\n", "## \ucd94\uac00\uc6a9 \ub9cc\ub4e4\uae30", "\n", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "            ", "save_files", "(", "args", ",", "'add_dev'", ",", "args", ".", "root", ",", "fileinfo", ",", "additional_texts", ",", "additional_transcripts", ")", "\n", "\n", "#save_wrong_script(args, 'dev_wrong', transcripts, fileinfo, raw_sentences, new_sentences)", "\n", "", "save_converted_info", "(", "args", ",", "'dev_converted'", ",", "converted_info", ")", "\n", "\n", "## \uc2a4\ud06c\ub9bd\ud2b8 \uc77d\uc5b4\uc624\uae30.", "\n", "", "script_name", "=", "'eval_other.trn'", "\n", "if", "script_name", "in", "file_list", ":", "\n", "        ", "print", "(", "\"generate [{}]\"", ".", "format", "(", "script_name", ")", ")", "\n", "fileinfo", ",", "durations", ",", "texts", ",", "audio_nums", ",", "transcripts", ",", "raw_sentences", ",", "new_sentences", ",", "converted_info", ",", "additional_texts", ",", "additional_transcripts", "=", "load_script", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "script_path", ",", "\n", "script_name", ")", ",", "info_data", ")", "\n", "save_files", "(", "args", ",", "'eval_other'", ",", "args", ".", "root", ",", "fileinfo", ",", "texts", ",", "transcripts", ")", "\n", "\n", "## \ucd94\uac00\uc6a9 \ub9cc\ub4e4\uae30", "\n", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "            ", "save_files", "(", "args", ",", "'add_eval_other'", ",", "args", ".", "root", ",", "fileinfo", ",", "additional_texts", ",", "additional_transcripts", ")", "\n", "\n", "#save_wrong_script(args, 'eval_other_wrong', transcripts, fileinfo, raw_sentences, new_sentences)", "\n", "", "save_converted_info", "(", "args", ",", "'eval_other_converted'", ",", "converted_info", ")", "\n", "\n", "## \uc2a4\ud06c\ub9bd\ud2b8 \uc77d\uc5b4\uc624\uae30.", "\n", "", "script_name", "=", "'eval_clean.trn'", "\n", "if", "script_name", "in", "file_list", ":", "\n", "        ", "print", "(", "\"generate [{}]\"", ".", "format", "(", "script_name", ")", ")", "\n", "fileinfo", ",", "durations", ",", "texts", ",", "audio_nums", ",", "transcripts", ",", "raw_sentences", ",", "new_sentences", ",", "converted_info", ",", "additional_texts", ",", "additional_transcripts", "=", "load_script", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "script_path", ",", "\n", "script_name", ")", ",", "info_data", ")", "\n", "save_files", "(", "args", ",", "'eval_clean'", ",", "args", ".", "root", ",", "fileinfo", ",", "texts", ",", "transcripts", ")", "\n", "\n", "## \ucd94\uac00\uc6a9 \ub9cc\ub4e4\uae30", "\n", "if", "args", ".", "additional_output_unit", "is", "not", "None", ":", "\n", "            ", "save_files", "(", "args", ",", "'add_eval_clean'", ",", "args", ".", "root", ",", "fileinfo", ",", "additional_texts", ",", "additional_transcripts", ")", "\n", "#save_wrong_script(args, 'eval_clean_wrong', transcripts, fileinfo, raw_sentences, new_sentences)", "\n", "", "save_converted_info", "(", "args", ",", "'eval_clean_converted'", ",", "converted_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.bracket_filter": [[18, 56], ["str", "ValueError", "ValueError"], "function", ["None"], ["def", "bracket_filter", "(", "sentence", ",", "mode", "=", "'phonetic'", ")", ":", "\n", "    ", "new_sentence", "=", "str", "(", ")", "\n", "\n", "if", "mode", "==", "'phonetic'", ":", "\n", "        ", "flag", "=", "False", "\n", "\n", "for", "ch", "in", "sentence", ":", "\n", "            ", "if", "ch", "==", "'('", "and", "flag", "is", "False", ":", "\n", "                ", "flag", "=", "True", "\n", "continue", "\n", "", "if", "ch", "==", "'('", "and", "flag", "is", "True", ":", "\n", "                ", "flag", "=", "False", "\n", "continue", "\n", "", "if", "ch", "!=", "')'", "and", "flag", "is", "False", ":", "\n", "                ", "new_sentence", "+=", "ch", "\n", "", "", "if", "flag", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported mode : {0}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "", "", "elif", "mode", "==", "'spelling'", ":", "\n", "        ", "flag", "=", "True", "\n", "\n", "for", "ch", "in", "sentence", ":", "\n", "            ", "if", "ch", "==", "'('", ":", "\n", "                ", "continue", "\n", "", "if", "ch", "==", "')'", ":", "\n", "                ", "if", "flag", "is", "True", ":", "\n", "                    ", "flag", "=", "False", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "flag", "=", "True", "\n", "continue", "\n", "", "", "if", "ch", "!=", "')'", "and", "flag", "is", "True", ":", "\n", "                ", "new_sentence", "+=", "ch", "\n", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported mode : {0}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "return", "new_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.special_filter": [[58, 84], ["str", "enumerate", "re.compile", "re.sub", "re.sub.strip", "len"], "function", ["None"], ["", "def", "special_filter", "(", "sentence", ",", "mode", "=", "'phonetic'", ",", "replace", "=", "None", ")", ":", "\n", "    ", "SENTENCE_MARK", "=", "[", "'?'", ",", "'!'", ",", "'.'", "]", "\n", "NOISE", "=", "[", "'o'", ",", "'n'", ",", "'u'", ",", "'b'", ",", "'l'", "]", "\n", "EXCEPT", "=", "[", "'/'", ",", "'+'", ",", "'*'", ",", "'-'", ",", "'@'", ",", "'$'", ",", "'^'", ",", "'&'", ",", "'['", ",", "']'", ",", "'='", ",", "':'", ",", "';'", ",", "','", "]", "+", "SENTENCE_MARK", "\n", "\n", "new_sentence", "=", "str", "(", ")", "\n", "for", "idx", ",", "ch", "in", "enumerate", "(", "sentence", ")", ":", "\n", "        ", "if", "ch", "not", "in", "SENTENCE_MARK", ":", "\n", "            ", "if", "idx", "+", "1", "<", "len", "(", "sentence", ")", "and", "ch", "in", "NOISE", "and", "sentence", "[", "idx", "+", "1", "]", "==", "'/'", ":", "\n", "                ", "continue", "\n", "\n", "", "", "if", "ch", "==", "'#'", ":", "\n", "            ", "new_sentence", "+=", "'\uc0fe'", "\n", "\n", "", "elif", "ch", "==", "'%'", ":", "\n", "            ", "if", "mode", "==", "'phonetic'", ":", "\n", "                ", "new_sentence", "+=", "replace", "\n", "", "elif", "mode", "==", "'spelling'", ":", "\n", "                ", "new_sentence", "+=", "'%'", "\n", "\n", "", "", "elif", "ch", "not", "in", "EXCEPT", ":", "\n", "            ", "new_sentence", "+=", "ch", "\n", "\n", "", "", "pattern", "=", "re", ".", "compile", "(", "r'\\s\\s+'", ")", "\n", "new_sentence", "=", "re", ".", "sub", "(", "pattern", ",", "' '", ",", "new_sentence", ".", "strip", "(", ")", ")", "\n", "return", "new_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.sentence_filter": [[85, 87], ["preprocess.special_filter", "preprocess.bracket_filter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.special_filter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.bracket_filter"], ["", "def", "sentence_filter", "(", "raw_sentence", ",", "mode", ",", "replace", "=", "None", ")", ":", "\n", "    ", "return", "special_filter", "(", "bracket_filter", "(", "raw_sentence", ",", "mode", ")", ",", "mode", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.preprocess": [[88, 105], ["percent_files.keys", "preprocess.sentence_filter", "preprocess.sentence_filter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.sentence_filter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.preprocess.sentence_filter"], ["", "def", "preprocess", "(", "raw_sentence", ",", "mode", "=", "'phonetic'", ",", "audio_num", "=", "0", ")", ":", "\n", "    ", "percent_files", "=", "{", "\n", "'087797'", ":", "'\ud37c\uc13c\ud2b8'", ",", "\n", "'215401'", ":", "'\ud37c\uc13c\ud2b8'", ",", "\n", "'284574'", ":", "'\ud37c\uc13c\ud2b8'", ",", "\n", "'397184'", ":", "'\ud37c\uc13c\ud2b8'", ",", "\n", "'501006'", ":", "'\ud504\ub85c'", ",", "\n", "'502173'", ":", "'\ud504\ub85c'", ",", "\n", "'542363'", ":", "'\ud504\ub85c'", ",", "\n", "'581483'", ":", "'\ud37c\uc13c\ud2b8'", "\n", "}", "\n", "\n", "if", "audio_num", "in", "percent_files", ".", "keys", "(", ")", ":", "\n", "        ", "new_sentence", "=", "sentence_filter", "(", "raw_sentence", ",", "mode", ",", "percent_files", "[", "audio_num", "]", ")", "\n", "", "else", ":", "\n", "        ", "new_sentence", "=", "sentence_filter", "(", "raw_sentence", ",", "mode", "=", "mode", ")", "\n", "", "return", "new_sentence", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.load_json": [[13, 24], ["list", "list", "open", "json.load", "list.append", "list.append"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["def", "load_json", "(", "temp_path", ")", ":", "\n", "    ", "wav_list", "=", "list", "(", ")", "\n", "text_list", "=", "list", "(", ")", "\n", "with", "open", "(", "temp_path", ")", "as", "f", ":", "\n", "        ", "data_list", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "temp_data", "in", "data_list", ":", "\n", "            ", "wav", "=", "temp_data", "[", "'wav'", "]", "\n", "text", "=", "temp_data", "[", "'text'", "]", "\n", "wav_list", ".", "append", "(", "wav", ")", "\n", "text_list", ".", "append", "(", "text", ")", "\n", "", "", "return", "wav_list", ",", "text_list", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.get_parser": [[26, 41], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root\"", ",", "default", "=", "'/code/gitRepo/data/clovacall'", ",", "metavar", "=", "\"DIR\"", ",", "\n", "help", "=", "\"root directory containing flac files to index\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dest\"", ",", "default", "=", "'/code/gitRepo/data/clovacall/script'", ",", "type", "=", "str", ",", "metavar", "=", "\"DIR\"", ",", "\n", "help", "=", "\"output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dev_portion\"", ",", "default", "=", "600", ",", "type", "=", "int", ",", "\n", "help", "=", "\"dev portion\"", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.load_audio": [[43, 58], ["pathlib.Path", "librosa.load", "numpy.memmap().astype", "soundfile.read", "ValueError", "numpy.memmap", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "def", "load_audio", "(", "file_path", ")", ":", "\n", "    ", "ext", "=", "Path", "(", "file_path", ")", ".", "suffix", "\n", "\n", "if", "ext", "in", "[", "'.wav'", ",", "'.flac'", "]", ":", "\n", "        ", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "file_path", ",", "sr", "=", "16000", ")", "\n", "", "elif", "ext", "==", "'.pcm'", ":", "\n", "        ", "wav", "=", "np", ".", "memmap", "(", "file_path", ",", "dtype", "=", "'h'", ",", "mode", "=", "'r'", ")", ".", "astype", "(", "'float32'", ")", "/", "32767", "\n", "sr", "=", "16000", "\n", "", "elif", "ext", "in", "[", "'.raw'", ",", "'.RAW'", "]", ":", "\n", "        ", "wav", ",", "sr", "=", "sf", ".", "read", "(", "file_path", ",", "channels", "=", "1", ",", "samplerate", "=", "16000", ",", "\n", "format", "=", "'RAW'", ",", "subtype", "=", "'PCM_16'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported preprocess method : {0}\"", ".", "format", "(", "Path", "(", "file_path", ")", ".", "suffix", ")", ")", "\n", "\n", "", "return", "wav", ",", "sr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.make_script": [[61, 83], ["list", "list", "zip", "os.path.join", "os.path.realpath", "generate_script.load_audio", "re.sub().strip", "list.append", "list.append", "re.sub", "os.path.relpath"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.load_audio"], ["", "def", "make_script", "(", "args", ",", "dir_path", ",", "wav_list", ",", "text_list", ")", ":", "\n", "    ", "fileinfo", "=", "list", "(", ")", "\n", "except_files", "=", "list", "(", ")", "\n", "\n", "## \uc22b\uc790, \uc601\uc5b4, \ud55c\uae00\uc744 \uc81c\uc678\ud558\uace0 \ud2b9\uc218\ubb38\uc790 \uc804\uccb4 \uc81c\uac70(.?/)", "\n", "pattern", "=", "'[^\\w\\s]'", "\n", "\n", "for", "audio_path", ",", "raw_sentence", "in", "zip", "(", "wav_list", ",", "text_list", ")", ":", "\n", "        ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "audio_path", ")", "\n", "audio_path", "=", "os", ".", "path", ".", "realpath", "(", "audio_path", ")", "\n", "\n", "try", ":", "\n", "            ", "wav", ",", "sr", "=", "load_audio", "(", "audio_path", ")", "\n", "\n", "## \uae38\uc774", "\n", "new_sentence", "=", "re", ".", "sub", "(", "pattern", "=", "pattern", ",", "repl", "=", "''", ",", "string", "=", "raw_sentence", ")", ".", "strip", "(", ")", "\n", "fileinfo", ".", "append", "(", "\"{} :: {}\"", ".", "format", "(", "os", ".", "path", ".", "relpath", "(", "audio_path", ",", "args", ".", "root", ")", ",", "new_sentence", ")", ")", "\n", "\n", "", "except", ":", "\n", "            ", "except_files", ".", "append", "(", "audio_path", ")", "\n", "\n", "", "", "return", "fileinfo", ",", "except_files", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.save_trn": [[84, 90], ["print", "open", "os.path.join", "print"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "save_trn", "(", "args", ",", "fileinfo", ",", "file_name", "=", "'train'", ")", ":", "\n", "\n", "    ", "print", "(", "\"save files [{}]\"", ".", "format", "(", "file_name", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dest", ",", "\"{}.trn\"", ".", "format", "(", "file_name", ")", ")", ",", "'w'", ",", "encoding", "=", "'UTF8'", ")", "as", "trn_out", ":", "\n", "        ", "for", "trn_item", "in", "fileinfo", ":", "\n", "            ", "print", "(", "trn_item", ",", "file", "=", "trn_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.main": [[91, 141], ["os.path.isdir", "os.listdir", "os.makedirs", "generate_script.load_json", "sklearn.model_selection.train_test_split", "generate_script.load_json", "os.path.join", "generate_script.make_script", "generate_script.save_trn", "print", "print", "os.path.join", "generate_script.make_script", "generate_script.save_trn", "print", "print", "os.path.join", "generate_script.make_script", "generate_script.save_trn", "print", "print", "os.path.join", "os.path.join", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.load_json", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.load_json", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.make_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.save_trn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.make_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.save_trn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.make_script", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.preprocess.generate_script.save_trn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "## \ub370\uc774\ud130 \ud615\ud0dc\uac00 \ubc18\ub4dc\uc2dc \uc77c\uce58\ud574\uc57c \ud569\ub2c8\ub2e4.", "\n", "    ", "\"\"\"\n    |-clovacall\n         |------train_ClovaCall.json\n         |------test_ClovaCall.json\n         |------wavs_train\n                    |----------41_0514_688_0_07118_05.wav\n                    |----------41_0509_714_0_08568_02.wav\n         |------wavs_test\n                    |----------41_0514_301_0_07111_09.wav\n                    |----------41_0515_577_0_04088_07.wav\n    \"\"\"", "\n", "\n", "train_json_name", "=", "'train_ClovaCall.json'", "\n", "test_json_name", "=", "'test_ClovaCall.json'", "\n", "train_folder_name", "=", "'wavs_train'", "\n", "test_folder_name", "=", "'wavs_test'", "\n", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "root", ")", ",", "\"\ud3f4\ub354\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \ub2e4\uc2dc \ud55c\ubc88 \ud655\uc778\ud574 \uc8fc\uc138\uc694 [{}]\"", ".", "format", "(", "args", ".", "root", ")", "\n", "folder_list", "=", "os", ".", "listdir", "(", "args", ".", "root", ")", "\n", "for", "item", "in", "[", "train_json_name", ",", "test_json_name", ",", "train_folder_name", ",", "test_folder_name", "]", ":", "\n", "        ", "assert", "item", "in", "folder_list", ",", "\"\ud30c\uc77c\uc774 \uc5c6\uc2b5\ub2c8\ub2e4. \ub2e4\uc2dc \ud55c\ubc88 \ud655\uc778\ud574 \uc8fc\uc138\uc694. [{}]\"", ".", "format", "(", "item", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "args", ".", "dest", ",", "exist_ok", "=", "True", ")", "\n", "\n", "train_wav", ",", "train_text", "=", "load_json", "(", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "train_json_name", ")", ")", "\n", "train_wav", ",", "valid_wav", ",", "train_text", ",", "valid_text", "=", "train_test_split", "(", "train_wav", ",", "train_text", ",", "test_size", "=", "args", ".", "dev_portion", ")", "\n", "test_wav", ",", "test_text", "=", "load_json", "(", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "test_json_name", ")", ")", "\n", "\n", "\n", "train_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "train_folder_name", ")", "\n", "fileinfo", ",", "except_files", "=", "make_script", "(", "args", ",", "train_folder", ",", "train_wav", ",", "train_text", ")", "\n", "save_trn", "(", "args", ",", "fileinfo", ",", "'train'", ")", "\n", "print", "(", "\"\uc800\uc7a5\ub41c \ud30c\uc77c\"", ",", "len", "(", "fileinfo", ")", ")", "\n", "print", "(", "\"\uc81c\uc678\ub41c \ud30c\uc77c\"", ",", "len", "(", "except_files", ")", ")", "\n", "\n", "dev_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "train_folder_name", ")", "\n", "fileinfo", ",", "except_files", "=", "make_script", "(", "args", ",", "dev_folder", ",", "valid_wav", ",", "valid_text", ")", "\n", "save_trn", "(", "args", ",", "fileinfo", ",", "'dev'", ")", "\n", "print", "(", "\"\uc800\uc7a5\ub41c \ud30c\uc77c\"", ",", "len", "(", "fileinfo", ")", ")", "\n", "print", "(", "\"\uc81c\uc678\ub41c \ud30c\uc77c\"", ",", "len", "(", "except_files", ")", ")", "\n", "\n", "test_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "test_folder_name", ")", "\n", "fileinfo", ",", "except_files", "=", "make_script", "(", "args", ",", "test_folder", ",", "test_wav", ",", "test_text", ")", "\n", "save_trn", "(", "args", ",", "fileinfo", ",", "'eval_clean'", ")", "\n", "print", "(", "\"\uc800\uc7a5\ub41c \ud30c\uc77c\"", ",", "len", "(", "fileinfo", ")", ")", "\n", "print", "(", "\"\uc81c\uc678\ub41c \ud30c\uc77c\"", ",", "len", "(", "except_files", ")", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ExistingEmissionsDecoder.__init__": [[292, 295], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "decoder", ",", "emissions", ")", ":", "\n", "        ", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "emissions", "=", "emissions", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ExistingEmissionsDecoder.generate": [[296, 305], ["sample[].cpu().numpy", "torch.from_numpy", "beam_search.ExistingEmissionsDecoder.decoder.decode", "numpy.stack", "sample[].cpu", "print", "Exception"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "unused", ")", ":", "\n", "        ", "ids", "=", "sample", "[", "\"id\"", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "try", ":", "\n", "            ", "emissions", "=", "np", ".", "stack", "(", "self", ".", "emissions", "[", "ids", "]", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "[", "x", ".", "shape", "for", "x", "in", "self", ".", "emissions", "[", "ids", "]", "]", ")", "\n", "raise", "Exception", "(", "\"invalid sizes\"", ")", "\n", "", "emissions", "=", "torch", ".", "from_numpy", "(", "emissions", ")", "\n", "return", "self", ".", "decoder", ".", "decode", "(", "emissions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.__init__": [[307, 361], ["numpy.log", "list", "tgt_dict.index", "pyctcdecode.Alphabet.build_alphabet", "pyctcdecode.BeamSearchDecoderCTC", "numpy.log", "numpy.log", "print", "list", "add_tgt_dict.index", "pyctcdecode.Alphabet.build_alphabet", "pyctcdecode.BeamSearchDecoderCTC"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "criterion_type", "=", "None", "\n", "if", "args", ".", "criterion", "in", "[", "\"ctc\"", ",", "'multi_ctc'", "]", ":", "\n", "            ", "self", ".", "criterion_type", "=", "\"ctc\"", "\n", "self", ".", "space_token", "=", "'|'", "\n", "\n", "", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "add_tgt_dict", "=", "add_tgt_dict", "\n", "self", ".", "beam", "=", "args", ".", "beam", "\n", "\n", "\n", "## portion", "\n", "#self.add_weight = np.log(1.0)", "\n", "self", ".", "origin_weight", "=", "np", ".", "log", "(", "1.0", ")", "\n", "\n", "# make alphabet", "\n", "vocab_list", "=", "list", "(", "tgt_dict", ".", "symbols", ")", "\n", "blank_idx", "=", "tgt_dict", ".", "index", "(", "self", ".", "space_token", ")", "\n", "\n", "# convert ctc blank character representation", "\n", "vocab_list", "[", "0", "]", "=", "\"\"", "\n", "# replace special characters", "\n", "vocab_list", "[", "1", "]", "=", "\"\u2047\"", "\n", "vocab_list", "[", "2", "]", "=", "\"\u2047\"", "\n", "vocab_list", "[", "3", "]", "=", "\"\u2047\"", "\n", "# convert space character representation", "\n", "vocab_list", "[", "blank_idx", "]", "=", "\" \"", "\n", "# specify ctc blank char index, since conventionally it is the last entry of the logit matrix", "\n", "alphabet", "=", "Alphabet", ".", "build_alphabet", "(", "vocab_list", ",", "ctc_token_idx", "=", "0", ")", "\n", "\n", "# build the decoder and decode the logits", "\n", "self", ".", "decoder", "=", "BeamSearchDecoderCTC", "(", "alphabet", ")", "\n", "self", ".", "add_decoder", "=", "None", "\n", "if", "add_tgt_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "add_weight", "=", "np", ".", "log", "(", "args", ".", "add_weight", ")", "\n", "self", ".", "origin_weight", "=", "np", ".", "log", "(", "1.0", "-", "args", ".", "add_weight", ")", "\n", "print", "(", "\"add decoder \ucd94\uac00\"", ")", "\n", "# make alphabet", "\n", "add_vocab_list", "=", "list", "(", "add_tgt_dict", ".", "symbols", ")", "\n", "add_blank_idx", "=", "add_tgt_dict", ".", "index", "(", "self", ".", "space_token", ")", "\n", "# convert ctc blank character representation", "\n", "add_vocab_list", "[", "0", "]", "=", "\"\"", "\n", "# replace special characters", "\n", "add_vocab_list", "[", "1", "]", "=", "\"\u2047\"", "\n", "add_vocab_list", "[", "2", "]", "=", "\"\u2047\"", "\n", "add_vocab_list", "[", "3", "]", "=", "\"\u2047\"", "\n", "# convert space character representation", "\n", "add_vocab_list", "[", "add_blank_idx", "]", "=", "\" \"", "\n", "# specify ctc blank char index, since conventionally it is the last entry of the logit matrix", "\n", "add_alphabet", "=", "Alphabet", ".", "build_alphabet", "(", "add_vocab_list", ",", "ctc_token_idx", "=", "0", ")", "\n", "\n", "# build the decoder and decode the logits", "\n", "self", ".", "add_decoder", "=", "BeamSearchDecoderCTC", "(", "add_alphabet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.get_emissions": [[362, 384], ["model", "hasattr", "model.get_logits", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy", "model.get_normalized_probs", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy", "model.get_addlogits", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy", "model.get_normalized_addprobs", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float().cpu", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose().float", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose", "emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose", "add_emissions.transpose().float().cpu().detach().numpy.transpose().float().cpu().detach().numpy.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.get_logits", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_addlogits", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_normalized_addprobs"], ["", "", "def", "get_emissions", "(", "self", ",", "models", ",", "encoder_input", ")", ":", "\n", "        ", "\"\"\"Run encoder and normalize emissions\"\"\"", "\n", "model", "=", "models", "[", "0", "]", "\n", "encoder_out", "=", "model", "(", "**", "encoder_input", ")", "\n", "\n", "emissions", "=", "None", "\n", "add_emissions", "=", "None", "\n", "if", "self", ".", "criterion_type", "==", "\"ctc\"", ":", "\n", "            ", "if", "hasattr", "(", "model", ",", "\"get_logits\"", ")", ":", "\n", "                ", "emissions", "=", "model", ".", "get_logits", "(", "encoder_out", ")", "# no need to normalize emissions", "\n", "emissions", "=", "emissions", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "add_decoder", "is", "not", "None", ":", "\n", "                    ", "add_emissions", "=", "model", ".", "get_addlogits", "(", "encoder_out", ")", "# no need to normalize emissions", "\n", "add_emissions", "=", "add_emissions", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "emissions", "=", "model", ".", "get_normalized_probs", "(", "encoder_out", ",", "log_probs", "=", "True", ")", "\n", "emissions", "=", "emissions", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "add_decoder", "is", "not", "None", ":", "\n", "                    ", "add_emissions", "=", "model", ".", "get_normalized_addprobs", "(", "encoder_out", ",", "log_probs", "=", "True", ")", "\n", "add_emissions", "=", "add_emissions", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "", "return", "emissions", ",", "add_emissions", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.decode_batch": [[385, 431], ["multiprocessing.Pool", "beam_search.BeamDecoder.decoder.decode_beams_batch", "list", "zip", "multiprocessing.Pool", "beam_search.BeamDecoder.add_decoder.decode_beams_batch", "dict", "sorted", "list.append", "unicodedata.normalize", "unicodedata.normalize", "sorted.items", "[].split", "beam_search.sum_log_scores", "beam_search.sum_log_scores"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.sum_log_scores", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.sum_log_scores"], ["", "def", "decode_batch", "(", "self", ",", "emissions", ",", "add_emissions", ")", ":", "\n", "        ", "if", "add_emissions", "is", "None", ":", "\n", "            ", "add_emissions", "=", "emissions", "\n", "\n", "", "with", "multiprocessing", ".", "Pool", "(", ")", "as", "pool", ":", "\n", "            ", "beam_outputs_list", "=", "self", ".", "decoder", ".", "decode_beams_batch", "(", "pool", ",", "emissions", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "", "results", "=", "beam_outputs_list", "\n", "\n", "\n", "if", "self", ".", "add_decoder", "is", "not", "None", ":", "\n", "            ", "results", "=", "list", "(", ")", "\n", "with", "multiprocessing", ".", "Pool", "(", ")", "as", "pool", ":", "\n", "                ", "add_beam_outputs_list", "=", "self", ".", "add_decoder", ".", "decode_beams_batch", "(", "pool", ",", "add_emissions", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "\n", "", "for", "beam_outputs", ",", "add_beam_outputs", "in", "zip", "(", "beam_outputs_list", ",", "add_beam_outputs_list", ")", ":", "\n", "                ", "temp_results", "=", "dict", "(", ")", "\n", "for", "beam_output", "in", "beam_outputs", ":", "\n", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "sum_log_scores", "(", "(", "self", ".", "origin_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "origin_weight", "+", "temp_score", ")", "\n", "\n", "", "", "for", "beam_output", "in", "add_beam_outputs", ":", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "sum_log_scores", "(", "(", "self", ".", "add_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "add_weight", "+", "temp_score", ")", "\n", "\n", "## Sort", "\n", "", "", "temp_results", "=", "sorted", "(", "temp_results", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "results", ".", "append", "(", "temp_results", ")", "\n", "\n", "", "", "results", "=", "[", "[", "{", "\n", "\"tokens\"", ":", "result", "[", "0", "]", "[", "0", "]", ",", "\n", "\"words\"", ":", "result", "[", "0", "]", "[", "0", "]", ".", "split", "(", ")", ",", "\n", "\"score\"", ":", "result", "[", "0", "]", "[", "-", "1", "]", "\n", "}", "]", "for", "result", "in", "results", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.decode": [[433, 475], ["list", "zip", "beam_search.BeamDecoder.decoder.decode_beams", "list.append", "beam_search.BeamDecoder.add_decoder.decode_beams", "dict", "sorted", "unicodedata.normalize", "unicodedata.normalize", "sorted.items", "beam_search.sum_log_scores", "beam_search.sum_log_scores", "[].split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.sum_log_scores", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.sum_log_scores"], ["", "def", "decode", "(", "self", ",", "emissions", ",", "add_emissions", ")", ":", "\n", "        ", "if", "add_emissions", "is", "None", ":", "\n", "            ", "add_emissions", "=", "emissions", "\n", "\n", "", "results", "=", "list", "(", ")", "\n", "for", "emission", ",", "add_emission", "in", "zip", "(", "emissions", ",", "add_emissions", ")", ":", "\n", "            ", "beam_outputs", "=", "self", ".", "decoder", ".", "decode_beams", "(", "emission", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "temp_results", "=", "beam_outputs", "\n", "if", "self", ".", "add_decoder", "is", "not", "None", ":", "\n", "                ", "add_beam_outputs", "=", "self", ".", "add_decoder", ".", "decode_beams", "(", "add_emission", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "\n", "temp_results", "=", "dict", "(", ")", "\n", "for", "beam_output", "in", "beam_outputs", ":", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "sum_log_scores", "(", "(", "self", ".", "origin_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "origin_weight", "+", "temp_score", ")", "\n", "\n", "\n", "", "", "for", "beam_output", "in", "add_beam_outputs", ":", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "sum_log_scores", "(", "(", "self", ".", "add_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "add_weight", "+", "temp_score", ")", "\n", "\n", "## Sort", "\n", "", "", "temp_results", "=", "sorted", "(", "temp_results", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "#assert temp_results[0][0] == unicodedata.normalize(\"NFC\", beam_outputs[0][0]), print(temp_results[0][-1], beam_outputs[0][-1])", "\n", "\n", "", "results", ".", "append", "(", "[", "{", "\n", "\"tokens\"", ":", "temp_results", "[", "0", "]", "[", "0", "]", ",", "\n", "\"words\"", ":", "temp_results", "[", "0", "]", "[", "0", "]", ".", "split", "(", ")", ",", "\n", "\"score\"", ":", "temp_results", "[", "0", "]", "[", "-", "1", "]", "\n", "}", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.generate": [[478, 489], ["beam_search.BeamDecoder.get_emissions", "beam_search.BeamDecoder.decode", "sample[].items"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamDecoder.get_emissions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "unused", ")", ":", "\n", "        ", "\"\"\"Generate a batch of inferences.\"\"\"", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "sample", "[", "\"net_input\"", "]", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "emissions", ",", "add_emissions", "=", "self", ".", "get_emissions", "(", "models", ",", "encoder_input", ")", "\n", "\n", "#return self.decode_batch(emissions, add_emissions)", "\n", "return", "self", ".", "decode", "(", "emissions", ",", "add_emissions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamMaxDecoder.__init__": [[491, 493], ["beam_search.BeamDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.BeamMaxDecoder.decode_batch": [[494, 540], ["multiprocessing.Pool", "beam_search.BeamMaxDecoder.decoder.decode_beams_batch", "list", "zip", "multiprocessing.Pool", "beam_search.BeamMaxDecoder.add_decoder.decode_beams_batch", "dict", "sorted", "list.append", "unicodedata.normalize", "unicodedata.normalize", "sorted.items", "[].split", "max", "max"], "methods", ["None"], ["", "def", "decode_batch", "(", "self", ",", "emissions", ",", "add_emissions", ")", ":", "\n", "        ", "if", "add_emissions", "is", "None", ":", "\n", "            ", "add_emissions", "=", "emissions", "\n", "\n", "", "with", "multiprocessing", ".", "Pool", "(", ")", "as", "pool", ":", "\n", "            ", "beam_outputs_list", "=", "self", ".", "decoder", ".", "decode_beams_batch", "(", "pool", ",", "emissions", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "", "results", "=", "beam_outputs_list", "\n", "\n", "\n", "if", "self", ".", "add_decoder", "is", "not", "None", ":", "\n", "            ", "results", "=", "list", "(", ")", "\n", "with", "multiprocessing", ".", "Pool", "(", ")", "as", "pool", ":", "\n", "                ", "add_beam_outputs_list", "=", "self", ".", "add_decoder", ".", "decode_beams_batch", "(", "pool", ",", "add_emissions", ",", "beam_width", "=", "self", ".", "beam", ")", "\n", "\n", "", "for", "beam_outputs", ",", "add_beam_outputs", "in", "zip", "(", "beam_outputs_list", ",", "add_beam_outputs_list", ")", ":", "\n", "                ", "temp_results", "=", "dict", "(", ")", "\n", "for", "beam_output", "in", "beam_outputs", ":", "\n", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "max", "(", "(", "self", ".", "origin_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "origin_weight", "+", "temp_score", ")", "\n", "\n", "", "", "for", "beam_output", "in", "add_beam_outputs", ":", "\n", "                    ", "temp_sent", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "beam_output", "[", "0", "]", ")", "\n", "temp_score", "=", "beam_output", "[", "-", "2", "]", "\n", "\n", "if", "temp_sent", "in", "temp_results", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "max", "(", "(", "self", ".", "add_weight", "+", "temp_score", ")", ",", "temp_results", "[", "temp_sent", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_results", "[", "temp_sent", "]", "=", "(", "self", ".", "add_weight", "+", "temp_score", ")", "\n", "\n", "## Sort", "\n", "", "", "temp_results", "=", "sorted", "(", "temp_results", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "results", ".", "append", "(", "temp_results", ")", "\n", "\n", "", "", "results", "=", "[", "[", "{", "\n", "\"tokens\"", ":", "result", "[", "0", "]", "[", "0", "]", ",", "\n", "\"words\"", ":", "result", "[", "0", "]", "[", "0", "]", ".", "split", "(", ")", ",", "\n", "\"score\"", ":", "result", "[", "0", "]", "[", "-", "1", "]", "\n", "}", "]", "for", "result", "in", "results", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.__init__": [[854, 860], ["beam_search.ResultWriter.load", "dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["    ", "def", "__init__", "(", "self", ",", "directory", ")", ":", "\n", "\n", "        ", "self", ".", "dir", "=", "directory", "\n", "self", ".", "hparams", "=", "None", "\n", "self", ".", "load", "(", ")", "\n", "self", ".", "writer", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.remove_list": [[861, 871], ["beam_search.ResultWriter.writer.items", "beam_search.ResultWriter.writer.pop", "type", "remove_list.append", "remove_list.append"], "methods", ["None"], ["", "def", "remove_list", "(", "self", ")", ":", "\n", "        ", "remove_list", "=", "[", "]", "\n", "for", "key", ",", "item", "in", "self", ".", "writer", ".", "items", "(", ")", ":", "\n", "            ", "if", "type", "(", "item", ")", "==", "list", ":", "\n", "                ", "remove_list", ".", "append", "(", "key", ")", "\n", "", "elif", "item", "==", "None", "or", "item", "==", "''", ":", "\n", "                ", "remove_list", ".", "append", "(", "key", ")", "\n", "\n", "", "", "for", "key", "in", "remove_list", ":", "\n", "            ", "self", ".", "writer", ".", "pop", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.update": [[872, 885], ["datetime.datetime.datetime.now", "beam_search.ResultWriter.writer.update", "beam_search.ResultWriter.writer.update", "beam_search.ResultWriter.writer.update", "beam_search.ResultWriter.remove_list", "beam_search.ResultWriter.save", "vars", "pandas.DataFrame", "beam_search.ResultWriter.hparams.append"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.remove_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save"], ["", "", "def", "update", "(", "self", ",", "args", ",", "**", "results", ")", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "date", "=", "\"%s-%s %s:%s\"", "%", "(", "now", ".", "month", ",", "now", ".", "day", ",", "now", ".", "hour", ",", "now", ".", "minute", ")", "\n", "self", ".", "writer", ".", "update", "(", "{", "\"date\"", ":", "date", "}", ")", "\n", "self", ".", "writer", ".", "update", "(", "results", ")", "\n", "self", ".", "writer", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "self", ".", "remove_list", "(", ")", "\n", "\n", "if", "self", ".", "hparams", "is", "None", ":", "\n", "            ", "self", ".", "hparams", "=", "pd", ".", "DataFrame", "(", "self", ".", "writer", ",", "index", "=", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hparams", "=", "self", ".", "hparams", ".", "append", "(", "self", ".", "writer", ",", "ignore_index", "=", "True", ")", "\n", "", "self", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.save": [[886, 889], ["beam_search.ResultWriter.hparams.to_csv"], "methods", ["None"], ["", "def", "save", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "hparams", "is", "not", "None", "\n", "self", ".", "hparams", ".", "to_csv", "(", "self", ".", "dir", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.ResultWriter.load": [[890, 899], ["os.path.split", "os.path.exists", "os.makedirs", "os.path.exists", "pandas.read_csv"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "load", "(", "self", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "split", "(", "self", ".", "dir", ")", "[", "0", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "path", ")", "\n", "self", ".", "hparams", "=", "None", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "self", ".", "dir", ")", ":", "\n", "            ", "self", ".", "hparams", "=", "pd", ".", "read_csv", "(", "self", ".", "dir", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hparams", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.add_asr_eval_argument": [[40, 147], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "add_asr_eval_argument", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "## 1. task", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "default", "=", "'audio_pretraining'", ",", "type", "=", "str", ",", "help", "=", "\"fairseq task\"", ")", "\n", "\n", "## 2. decoding strategy", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder\"", ",", "\n", "choices", "=", "[", "\"beam\"", ",", "\"max\"", "]", ",", "\n", "help", "=", "\"decoder\"", ",", "\n", ")", "\n", "\n", "## 3. checkpoint_path", "\n", "parser", ".", "add_argument", "(", "\n", "\"--checkpoint-path\"", ",", "\n", "help", "=", "\"checkpoint paths\"", ",", "\n", ")", "\n", "\n", "## 4. subset", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gen-subset\"", ",", "\n", "help", "=", "\"choose subset name\"", ",", "\n", ")", "\n", "\n", "## 5. results-path", "\n", "parser", ".", "add_argument", "(", "\n", "\"--results-path\"", ",", "\n", "help", "=", "\"log path\"", ",", "\n", ")", "\n", "\n", "## 6. criterion", "\n", "parser", ".", "add_argument", "(", "\n", "\"--criterion\"", ",", "\n", "choices", "=", "[", "\"ctc\"", ",", "\"multi_ctc\"", "]", ",", "\n", "help", "=", "\"choose criterion\"", ",", "\n", ")", "\n", "\n", "## 7. labels", "\n", "parser", ".", "add_argument", "(", "\n", "\"--labels\"", ",", "\n", "default", "=", "'ltr'", ",", "\n", "help", "=", "\"label file name\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--post-process\"", ",", "\n", "default", "=", "'letter'", ",", "\n", "help", "=", "\"label file name\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add-weight\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "\"contribution weights for multi task model(single model use default:0.5)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "8", ",", "\n", "help", "=", "\"batch size per gpu\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-tokens\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "4000000", ",", "\n", "help", "=", "\"max-tokens\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--experiments-dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'/code/gitRepo/wav2vec_exp/experiments/experiments.csv'", ",", "\n", "help", "=", "\"if present, loads emissions from this file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--additional-output\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if present, loads emissions from this file\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cpu\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if ture, cpu is runnning instead gpu\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if you want to use fp16, check option\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log-format\"", ",", "\n", "default", "=", "\"tqdm\"", ",", "\n", "help", "=", "\"log format\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log-interval\"", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"log interval\"", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_dataset_itr": [[149, 161], ["task.get_batch_iterator().next_epoch_itr", "task.get_batch_iterator", "task.dataset"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.dataset"], ["", "def", "get_dataset_itr", "(", "args", ",", "task", ",", "models", ")", ":", "\n", "    ", "return", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "task", ".", "dataset", "(", "args", ".", "gen_subset", ")", ",", "\n", "max_tokens", "=", "args", ".", "max_tokens", ",", "\n", "max_sentences", "=", "args", ".", "batch_size", ",", "\n", "max_positions", "=", "(", "sys", ".", "maxsize", ",", "sys", ".", "maxsize", ")", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", "#num_shards=args.num_shards,", "\n", "#shard_id=args.shard_id,", "\n", "#num_workers=args.num_workers,", "\n", "#data_buffer_size=args.data_buffer_size,", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.sum_log_scores": [[163, 171], ["math.log", "math.log", "math.exp", "math.exp"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "sum_log_scores", "(", "s1", ":", "float", ",", "s2", ":", "float", ")", "->", "float", ":", "\n", "    ", "\"\"\"Sum log odds in a numerically stable way.\"\"\"", "\n", "# this is slightly faster than using max", "\n", "if", "s1", ">=", "s2", ":", "\n", "        ", "log_sum", "=", "s1", "+", "math", ".", "log", "(", "1", "+", "math", ".", "exp", "(", "s2", "-", "s1", ")", ")", "\n", "", "else", ":", "\n", "        ", "log_sum", "=", "s2", "+", "math", ".", "log", "(", "1", "+", "math", ".", "exp", "(", "s1", "-", "s2", ")", ")", "\n", "", "return", "log_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.process_predictions": [[173, 254], ["tgt_dict.string", "fairseq.data.data_utils.post_process", "unicodedata.normalize", "unicodedata.normalize", "beam_search.get_norm_text", "hyp_pieces.append", "tgt_pieces.append", "hyp_words.append", "tgt_words.append", "min", "fairseq.data.data_utils.post_process", "print", "print", "print", "print", "fairseq.data.data_utils.post_process.split", "unicodedata.normalize.split", "editdistance.eval", "len", "editdistance.eval", "len", "editdistance.eval", "len", "len", "fairseq.data.data_utils.post_process.split", "unicodedata.normalize.split", "unicodedata.normalize.split", "norm_hyp_word.split", "norm_tgt_word.split", "norm_tgt_word.split", "hyp_piece.replace"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_norm_text", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "process_predictions", "(", "\n", "args", ",", "hypos", ",", "sp", ",", "tgt_dict", ",", "target_tokens", ",", "res_files", ",", "speaker", ",", "id", "\n", ")", ":", "\n", "    ", "errs_wer", "=", "0", "\n", "lengths_wer", "=", "0", "\n", "\n", "errs_swer", "=", "0", "\n", "lengths_swer", "=", "0", "\n", "\n", "errs_cer", "=", "0", "\n", "lengths_cer", "=", "0", "\n", "\n", "hyp_pieces", ",", "tgt_pieces", ",", "hyp_words", ",", "tgt_words", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "for", "hypo", "in", "hypos", "[", ":", "min", "(", "len", "(", "hypos", ")", ",", "args", ".", "nbest", ")", "]", ":", "\n", "        ", "hyp_piece", "=", "hypo", "[", "\"tokens\"", "]", "\n", "\n", "if", "\"words\"", "in", "hypo", ":", "\n", "            ", "hyp_word", "=", "\" \"", ".", "join", "(", "hypo", "[", "\"words\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "hyp_word", "=", "post_process", "(", "hyp_piece", ",", "args", ".", "post_process", ")", "\n", "\n", "", "if", "res_files", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"{} ({}-{})\"", ".", "format", "(", "\" \"", ".", "join", "(", "hyp_piece", ".", "replace", "(", "' '", ",", "\"|\"", ")", "+", "\"|\"", ")", ",", "speaker", ",", "id", ")", ",", "\n", "file", "=", "res_files", "[", "\"hypo.units\"", "]", ",", "\n", ")", "\n", "print", "(", "\n", "\"{} ({}-{})\"", ".", "format", "(", "hyp_word", ",", "speaker", ",", "id", ")", ",", "\n", "file", "=", "res_files", "[", "\"hypo.words\"", "]", ",", "\n", ")", "\n", "\n", "", "tgt_piece", "=", "tgt_dict", ".", "string", "(", "target_tokens", ")", "\n", "tgt_word", "=", "post_process", "(", "tgt_piece", ",", "args", ".", "post_process", ")", "\n", "\n", "if", "res_files", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"{} ({}-{})\"", ".", "format", "(", "tgt_piece", ",", "speaker", ",", "id", ")", ",", "\n", "file", "=", "res_files", "[", "\"ref.units\"", "]", ",", "\n", ")", "\n", "print", "(", "\n", "\"{} ({}-{})\"", ".", "format", "(", "tgt_word", ",", "speaker", ",", "id", ")", ",", "file", "=", "res_files", "[", "\"ref.words\"", "]", "\n", ")", "\n", "# only score top hypothesis", "\n", "\n", "\n", "## normalize(\ud55c\uae00 NFKD \uc77c \uacbd\uc6b0 \uae00\uc790 \uac2f\uc218\uac00 \ub2e4\ub974\uac8c \uce21\uc815\ub418\ub294 \uac78 \ubc29\uc9c0\ud558\uae30 \uc704\ud558\uc5ec)", "\n", "", "hyp_word", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "hyp_word", ")", "\n", "tgt_word", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "tgt_word", ")", "\n", "\n", "hyp_word", "=", "\" \"", ".", "join", "(", "hyp_word", ".", "split", "(", ")", ")", "\n", "tgt_word", "=", "\" \"", ".", "join", "(", "tgt_word", ".", "split", "(", ")", ")", "\n", "\n", "err_w", ",", "length_w", "=", "editdistance", ".", "eval", "(", "hyp_word", ".", "split", "(", ")", ",", "tgt_word", ".", "split", "(", ")", ")", ",", "len", "(", "tgt_word", ".", "split", "(", ")", ")", "\n", "err_c", ",", "length_c", "=", "editdistance", ".", "eval", "(", "hyp_word", ",", "tgt_word", ")", ",", "len", "(", "tgt_word", ")", "\n", "\n", "##", "\n", "norm_hyp_word", ",", "norm_tgt_word", "=", "get_norm_text", "(", "hyp_word", ",", "tgt_word", ")", "\n", "err_sw", ",", "length_sw", "=", "editdistance", ".", "eval", "(", "norm_hyp_word", ".", "split", "(", ")", ",", "norm_tgt_word", ".", "split", "(", ")", ")", ",", "len", "(", "norm_tgt_word", ".", "split", "(", ")", ")", "\n", "\n", "errs_wer", "+=", "err_w", "\n", "lengths_wer", "+=", "length_w", "\n", "errs_cer", "+=", "err_c", "\n", "lengths_cer", "+=", "length_c", "\n", "errs_swer", "+=", "err_sw", "\n", "lengths_swer", "+=", "length_sw", "\n", "\n", "hyp_pieces", ".", "append", "(", "hyp_piece", ")", "\n", "tgt_pieces", ".", "append", "(", "tgt_piece", ")", "\n", "hyp_words", ".", "append", "(", "hyp_word", ")", "\n", "tgt_words", ".", "append", "(", "tgt_word", ")", "\n", "count", "+=", "1", "\n", "assert", "count", "<", "2", ",", "\"\uc5ec\uae30\ub85c \uc624\uba74 \uc548\ub418\ub294\ub370 \ud55c\uac1c\ub9cc \ubf51\uc544\uc57c \ub418\ub294\ub370? \uc6d0\ub798\ucf54\ub4dc\ub77c\uba74\"", "\n", "\n", "", "return", "{", "\n", "'errs_wer'", ":", "errs_wer", ",", "\n", "'lengths_wer'", ":", "lengths_wer", ",", "\n", "'errs_cer'", ":", "errs_cer", ",", "\n", "'lengths_cer'", ":", "lengths_cer", ",", "\n", "'errs_swer'", ":", "errs_swer", ",", "\n", "'lengths_swer'", ":", "lengths_swer", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.prepare_result_files": [[257, 275], ["os.path.join", "open", "beam_search.prepare_result_files.get_res_file"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "prepare_result_files", "(", "args", ")", ":", "\n", "    ", "def", "get_res_file", "(", "file_prefix", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "results_path", ",", "\n", "\"{}-{}-{}.txt\"", ".", "format", "(", "\n", "file_prefix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "checkpoint_path", ")", ",", "args", ".", "gen_subset", "\n", ")", ",", "\n", ")", "\n", "return", "open", "(", "path", ",", "\"w\"", ",", "buffering", "=", "1", ")", "\n", "\n", "", "if", "not", "args", ".", "results_path", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "{", "\n", "\"hypo.words\"", ":", "get_res_file", "(", "\"hypo.word\"", ")", ",", "\n", "\"hypo.units\"", ":", "get_res_file", "(", "\"hypo.units\"", ")", ",", "\n", "\"ref.words\"", ":", "get_res_file", "(", "\"ref.word\"", ")", ",", "\n", "\"ref.units\"", ":", "get_res_file", "(", "\"ref.units\"", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.optimize_models": [[278, 289], ["model.make_generation_fast_", "model.half", "model.cuda"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.make_generation_fast_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "optimize_models", "(", "args", ",", "use_cuda", ",", "models", ")", ":", "\n", "    ", "\"\"\"Optimize ensemble for generation\"\"\"", "\n", "for", "model", "in", "models", ":", "\n", "        ", "model", ".", "make_generation_fast_", "(", "\n", "beamable_mm_beam_size", "=", "None", "if", "args", ".", "no_beamable_mm", "else", "args", ".", "beam", ",", "\n", "need_attn", "=", "args", ".", "print_alignment", ",", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "", "if", "use_cuda", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_score": [[549, 555], ["None"], "function", ["None"], ["def", "get_score", "(", "a", ",", "b", ")", ":", "\n", "# get score for Levenshtein", "\n", "    ", "if", "a", "==", "b", ":", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space": [[557, 560], ["token.replace"], "function", ["None"], ["", "", "def", "norm_space", "(", "token", ")", ":", "\n", "# get normalized token", "\n", "    ", "return", "token", ".", "replace", "(", "space_sym", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_norm_text": [[564, 629], ["numpy.zeros", "range", "range", "hyp_norm.reverse", "ref_norm.reverse", "len", "len", "range", "min", "hyp_norm.append", "ref_norm.append", "beam_search.norm_space", "beam_search.norm_space", "beam_search.get_score", "beam_search.norm_space", "beam_search.norm_space", "beam_search.norm_space", "beam_search.norm_space", "beam_search.get_score", "min"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_score", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.norm_space", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_score"], ["", "def", "get_norm_text", "(", "hyps", ",", "refs", ")", ":", "\n", "# this implementation is modified from LevenshteinAlignment of the kaldi toolkit", "\n", "# - https://github.com/kaldi-asr/kaldi/blob/master/src/bin/align-text.cc", "\n", "\n", "# initialize variables", "\n", "    ", "hyp_norm", ",", "ref_norm", "=", "[", "]", ",", "[", "]", "\n", "\n", "# length of two sequences", "\n", "hlen", ",", "rlen", "=", "len", "(", "hyps", ")", ",", "len", "(", "refs", ")", "\n", "\n", "# initialization", "\n", "# - this is very memory-inefficiently implemented using a vector of vectors", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "hlen", "+", "1", ",", "rlen", "+", "1", ")", ")", "\n", "for", "r", "in", "range", "(", "0", ",", "rlen", "+", "1", ")", ":", "\n", "        ", "scores", "[", "0", "]", "[", "r", "]", "=", "r", "\n", "", "for", "h", "in", "range", "(", "1", ",", "hlen", "+", "1", ")", ":", "\n", "        ", "scores", "[", "h", "]", "[", "0", "]", "=", "scores", "[", "h", "-", "1", "]", "[", "0", "]", "+", "1", "\n", "for", "r", "in", "range", "(", "1", ",", "rlen", "+", "1", ")", ":", "\n", "            ", "hyp_nosp", ",", "ref_nosp", "=", "norm_space", "(", "hyps", "[", "h", "-", "1", "]", ")", ",", "norm_space", "(", "refs", "[", "r", "-", "1", "]", ")", "\n", "sub_or_cor", "=", "scores", "[", "h", "-", "1", "]", "[", "r", "-", "1", "]", "+", "get_score", "(", "hyp_nosp", ",", "ref_nosp", ")", "\n", "insert", ",", "delete", "=", "scores", "[", "h", "-", "1", "]", "[", "r", "]", "+", "1", ",", "scores", "[", "h", "]", "[", "r", "-", "1", "]", "+", "1", "\n", "scores", "[", "h", "]", "[", "r", "]", "=", "min", "(", "sub_or_cor", ",", "insert", ",", "delete", ")", "\n", "\n", "# traceback and compute the alignment", "\n", "", "", "h", ",", "r", "=", "hlen", ",", "rlen", "# start from the bottom", "\n", "while", "h", ">", "0", "or", "r", ">", "0", ":", "\n", "        ", "if", "h", "==", "0", ":", "\n", "            ", "last_h", ",", "last_r", "=", "h", ",", "r", "-", "1", "\n", "", "elif", "r", "==", "0", ":", "\n", "            ", "last_h", ",", "last_r", "=", "h", "-", "1", ",", "r", "\n", "", "else", ":", "\n", "# get score", "\n", "            ", "hyp_nosp", ",", "ref_nosp", "=", "norm_space", "(", "hyps", "[", "h", "-", "1", "]", ")", ",", "norm_space", "(", "refs", "[", "r", "-", "1", "]", ")", "\n", "sub_or_cor", "=", "scores", "[", "h", "-", "1", "]", "[", "r", "-", "1", "]", "+", "get_score", "(", "hyp_nosp", ",", "ref_nosp", ")", "\n", "insert", ",", "delete", "=", "scores", "[", "h", "-", "1", "]", "[", "r", "]", "+", "1", ",", "scores", "[", "h", "]", "[", "r", "-", "1", "]", "+", "1", "\n", "\n", "# choose sub_or_cor if all else equal", "\n", "if", "sub_or_cor", "<=", "min", "(", "insert", ",", "delete", ")", ":", "\n", "                ", "last_h", "=", "h", "-", "1", "\n", "last_r", "=", "r", "-", "1", "\n", "", "else", ":", "\n", "                ", "if", "insert", "<", "delete", ":", "\n", "                    ", "last_h", "=", "h", "-", "1", "\n", "last_r", "=", "r", "\n", "", "else", ":", "\n", "                    ", "last_h", "=", "h", "\n", "last_r", "=", "r", "-", "1", "\n", "\n", "", "", "", "c_hyp", "=", "hyps", "[", "last_h", "]", "if", "last_h", "!=", "h", "else", "\"\"", "\n", "c_ref", "=", "refs", "[", "last_r", "]", "if", "last_r", "!=", "r", "else", "\"\"", "\n", "h", ",", "r", "=", "last_h", ",", "last_r", "\n", "\n", "# do word-spacing normalization", "\n", "if", "c_hyp", "!=", "c_ref", "and", "norm_space", "(", "c_hyp", ")", "==", "norm_space", "(", "c_ref", ")", ":", "\n", "            ", "c_hyp", "=", "c_ref", "\n", "", "if", "c_hyp", "!=", "\"\"", ":", "\n", "            ", "hyp_norm", ".", "append", "(", "c_hyp", ")", "\n", "", "if", "c_ref", "!=", "\"\"", ":", "\n", "            ", "ref_norm", ".", "append", "(", "c_ref", ")", "\n", "\n", "# reverse list", "\n", "", "", "hyp_norm", ".", "reverse", "(", ")", "\n", "ref_norm", ".", "reverse", "(", ")", "\n", "\n", "return", "(", "\"\"", ".", "join", "(", "hyp_norm", ")", ",", "\"\"", ".", "join", "(", "ref_norm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.main": [[631, 826], ["logger.info", "logger.info", "fairseq.tasks.setup_task", "copy.deepcopy", "logger.info", "fairseq.checkpoint_utils.load_model_ensemble", "beam_search.optimize_models", "tasks.setup_task.load_dataset", "logger.info", "beam_search.get_dataset_itr", "fairseq.logging.meters.StopwatchMeter", "beam_search.main.build_generator"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.optimize_models", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.load_dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.get_dataset_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_generator"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "if", "args", ".", "max_tokens", "is", "None", "and", "args", ".", "batch_size", "is", "None", ":", "\n", "        ", "args", ".", "max_tokens", "=", "4000000", "\n", "", "logger", ".", "info", "(", "args", ")", "\n", "\n", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "cpu", "\n", "\n", "logger", ".", "info", "(", "\"| decoding with criterion {}\"", ".", "format", "(", "args", ".", "criterion", ")", ")", "\n", "\n", "task", "=", "tasks", ".", "setup_task", "(", "args", ")", "\n", "\n", "# Set dictionary", "\n", "import", "copy", "\n", "tgt_dict", "=", "copy", ".", "deepcopy", "(", "task", ".", "target_dictionary", ")", "\n", "add_tgt_dict", "=", "None", "\n", "\n", "# \uc2e4\ud5d8\uc6a9", "\n", "if", "hasattr", "(", "task", ",", "\"additional_dictionary\"", ")", "and", "task", ".", "additional_dictionary", "is", "not", "None", ":", "\n", "        ", "add_tgt_dict", "=", "copy", ".", "deepcopy", "(", "task", ".", "additional_dictionary", ")", "\n", "\n", "\n", "", "logger", ".", "info", "(", "\"| loading model(s) from {}\"", ".", "format", "(", "args", ".", "checkpoint_path", ")", ")", "\n", "models", ",", "saved_cfg", "=", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "utils", ".", "split_paths", "(", "args", ".", "checkpoint_path", ")", ",", "\n", "#arg_overrides=ast.literal_eval(args.model_overrides),", "\n", "task", "=", "task", ",", "\n", "#suffix=args.checkpoint_suffix,", "\n", "#strict=(args.checkpoint_shard_count == 1),", "\n", "#num_shards=args.checkpoint_shard_count,", "\n", "state", "=", "None", ",", "\n", ")", "\n", "\n", "optimize_models", "(", "args", ",", "use_cuda", ",", "models", ")", "\n", "\n", "## \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 \uc804 \uc138\ud305", "\n", "for", "token", "in", "UNK_ADD_TOKENS", ":", "\n", "        ", "task", ".", "target_dictionary", ".", "add_symbol", "(", "token", ")", "\n", "", "if", "hasattr", "(", "task", ",", "\"additional_dictionary\"", ")", "and", "task", ".", "additional_dictionary", "is", "not", "None", ":", "\n", "        ", "for", "token", "in", "UNK_ADD_TOKENS", ":", "\n", "            ", "task", ".", "additional_dictionary", ".", "add_symbol", "(", "token", ")", "\n", "\n", "", "", "task", ".", "load_dataset", "(", "args", ".", "gen_subset", ",", "task_cfg", "=", "saved_cfg", ".", "task", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\n", "\"| {} {} {} examples\"", ".", "format", "(", "\n", "args", ".", "data", ",", "args", ".", "gen_subset", ",", "len", "(", "task", ".", "dataset", "(", "args", ".", "gen_subset", ")", ")", "\n", ")", "\n", ")", "\n", "\n", "# hack to pass transitions to W2lDecoder", "\n", "if", "args", ".", "criterion", "==", "\"asg_loss\"", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"asg_loss is currently not supported\"", ")", "\n", "# trans = criterions[0].asg.trans.data", "\n", "# args.asg_transitions = torch.flatten(trans).tolist()", "\n", "\n", "# Load dataset (possibly sharded)", "\n", "", "itr", "=", "get_dataset_itr", "(", "args", ",", "task", ",", "models", ")", "\n", "\n", "# Initialize generator", "\n", "gen_timer", "=", "StopwatchMeter", "(", ")", "\n", "\n", "def", "build_generator", "(", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", ":", "\n", "        ", "w2l_decoder", "=", "getattr", "(", "args", ",", "\"decoder\"", ",", "None", ")", "\n", "if", "w2l_decoder", "==", "\"beam\"", ":", "\n", "            ", "return", "BeamDecoder", "(", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", "\n", "", "elif", "w2l_decoder", "==", "\"max\"", ":", "\n", "            ", "return", "BeamMaxDecoder", "(", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", "\n", "\n", "", "raise", "NotImplementedError", "(", "\"nothing is selected for decoding\"", ")", "\n", "\n", "# please do not touch this unless you test both generate.py and infer.py with audio_pretraining task", "\n", "", "generator", "=", "build_generator", "(", "args", ",", "tgt_dict", ",", "add_tgt_dict", ")", "\n", "\n", "num_sentences", "=", "0", "\n", "\n", "if", "args", ".", "results_path", "is", "not", "None", "and", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "results_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "results_path", ")", "\n", "\n", "", "max_source_pos", "=", "(", "\n", "utils", ".", "resolve_max_positions", "(", "\n", "task", ".", "max_positions", "(", ")", ",", "*", "[", "model", ".", "max_positions", "(", ")", "for", "model", "in", "models", "]", "\n", ")", ",", "\n", ")", "\n", "\n", "if", "max_source_pos", "is", "not", "None", ":", "\n", "        ", "max_source_pos", "=", "max_source_pos", "[", "0", "]", "\n", "if", "max_source_pos", "is", "not", "None", ":", "\n", "            ", "max_source_pos", "=", "max_source_pos", "[", "0", "]", "-", "1", "\n", "\n", "", "", "res_files", "=", "prepare_result_files", "(", "args", ")", "\n", "\n", "errs_wer", "=", "0", "\n", "lengths_wer", "=", "0", "\n", "\n", "errs_swer", "=", "0", "\n", "lengths_swer", "=", "0", "\n", "\n", "errs_cer", "=", "0", "\n", "lengths_cer", "=", "0", "\n", "\n", "with", "progress_bar", ".", "build_progress_bar", "(", "args", ",", "itr", ")", "as", "t", ":", "\n", "        ", "wps_meter", "=", "TimeMeter", "(", ")", "\n", "for", "sample", "in", "t", ":", "\n", "            ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "use_cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "sample", ":", "\n", "                ", "continue", "\n", "\n", "", "prefix_tokens", "=", "None", "\n", "if", "args", ".", "prefix_size", ">", "0", ":", "\n", "\n", "## \uc5ec\uae30 \ucd94\uac00", "\n", "                ", "if", "args", ".", "additional_output", ":", "\n", "                    ", "prefix_tokens", "=", "sample", "[", "\"add_target\"", "]", "[", ":", ",", ":", "args", ".", "prefix_size", "]", "\n", "", "else", ":", "\n", "                    ", "prefix_tokens", "=", "sample", "[", "\"target\"", "]", "[", ":", ",", ":", "args", ".", "prefix_size", "]", "\n", "\n", "", "", "gen_timer", ".", "start", "(", ")", "\n", "hypos", "=", "task", ".", "inference_step", "(", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", ")", "\n", "num_generated_tokens", "=", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", "\n", "gen_timer", ".", "stop", "(", "num_generated_tokens", ")", "\n", "\n", "for", "i", ",", "sample_id", "in", "enumerate", "(", "sample", "[", "\"id\"", "]", ".", "tolist", "(", ")", ")", ":", "\n", "                ", "speaker", "=", "None", "\n", "# id = task.dataset(args.gen_subset).ids[int(sample_id)]", "\n", "id", "=", "sample_id", "\n", "## \uc5ec\uae30 \ucd94\uac00", "\n", "if", "args", ".", "additional_output", ":", "\n", "                    ", "toks", "=", "(", "\n", "sample", "[", "\"add_target\"", "]", "[", "i", ",", ":", "]", "\n", "if", "\"add_target_label\"", "not", "in", "sample", "\n", "else", "sample", "[", "\"add_target_label\"", "]", "[", "i", ",", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "toks", "=", "(", "\n", "sample", "[", "\"target\"", "]", "[", "i", ",", ":", "]", "\n", "if", "\"target_label\"", "not", "in", "sample", "\n", "else", "sample", "[", "\"target_label\"", "]", "[", "i", ",", ":", "]", "\n", ")", "\n", "", "target_tokens", "=", "utils", ".", "strip_pad", "(", "toks", ",", "tgt_dict", ".", "pad", "(", ")", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "# Process top predictions", "\n", "postprocess_result", "=", "process_predictions", "(", "\n", "args", ",", "\n", "hypos", "[", "i", "]", ",", "\n", "None", ",", "\n", "#tgt_dict,", "\n", "task", ".", "target_dictionary", ",", "\n", "target_tokens", ",", "\n", "res_files", ",", "\n", "speaker", ",", "\n", "id", ",", "\n", ")", "\n", "\n", "errs_wer", "+=", "postprocess_result", "[", "'errs_wer'", "]", "\n", "lengths_wer", "+=", "postprocess_result", "[", "'lengths_wer'", "]", "\n", "errs_cer", "+=", "postprocess_result", "[", "'errs_cer'", "]", "\n", "lengths_cer", "+=", "postprocess_result", "[", "'lengths_cer'", "]", "\n", "errs_swer", "+=", "postprocess_result", "[", "'errs_swer'", "]", "\n", "lengths_swer", "+=", "postprocess_result", "[", "'lengths_swer'", "]", "\n", "\n", "", "wps_meter", ".", "update", "(", "num_generated_tokens", ")", "\n", "t", ".", "log", "(", "{", "\"wps\"", ":", "round", "(", "wps_meter", ".", "avg", ")", "}", ")", "\n", "num_sentences", "+=", "(", "\n", "sample", "[", "\"nsentences\"", "]", "if", "\"nsentences\"", "in", "sample", "else", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", "\n", ")", "\n", "\n", "", "", "wer", "=", "None", "\n", "cer", "=", "None", "\n", "swer", "=", "None", "\n", "\n", "if", "lengths_wer", ">", "0", ":", "\n", "        ", "wer", "=", "errs_wer", "*", "100.0", "/", "lengths_wer", "\n", "logger", ".", "info", "(", "f\"WER: {wer}\"", ")", "\n", "\n", "", "if", "lengths_cer", ">", "0", ":", "\n", "        ", "cer", "=", "errs_cer", "*", "100.0", "/", "lengths_cer", "\n", "logger", ".", "info", "(", "f\"CER: {cer}\"", ")", "\n", "\n", "", "if", "lengths_swer", ">", "0", ":", "\n", "        ", "swer", "=", "errs_swer", "*", "100.0", "/", "lengths_swer", "\n", "logger", ".", "info", "(", "f\"sWER: {swer}\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"| Processed {} sentences ({} tokens) in {:.1f}s ({:.2f}\"", "\n", "\"sentences/s, {:.2f} tokens/s)\"", ".", "format", "(", "\n", "num_sentences", ",", "\n", "gen_timer", ".", "n", ",", "\n", "gen_timer", ".", "sum", ",", "\n", "num_sentences", "/", "gen_timer", ".", "sum", ",", "\n", "1.0", "/", "gen_timer", ".", "avg", ",", "\n", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"| Generate {} with beam={}\"", ".", "format", "(", "args", ".", "gen_subset", ",", "args", ".", "beam", ")", ")", "\n", "return", "task", ",", "wer", ",", "cer", ",", "swer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.make_parser": [[828, 831], ["beam_search.add_asr_eval_argument"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.add_asr_eval_argument"], ["", "def", "make_parser", "(", ")", ":", "\n", "    ", "parser", "=", "add_asr_eval_argument", "(", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.cli_main": [[833, 847], ["beam_search.make_parser", "fairseq.options.parse_args_and_arch", "beam_search.main", "beam_search.ResultWriter", "beam_search.ResultWriter.update"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.make_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.main", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "make_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "task", ",", "wer", ",", "cer", ",", "swer", "=", "main", "(", "args", ")", "\n", "\n", "writer", "=", "ResultWriter", "(", "args", ".", "experiments_dir", ")", "\n", "results", "=", "{", "\n", "'cer'", ":", "cer", ",", "\n", "'wer'", ":", "wer", ",", "\n", "'swer'", ":", "swer", ",", "\n", "}", "\n", "writer", ".", "update", "(", "args", ",", "**", "results", ")", "\n", "\n", "return", "wer", ",", "cer", ",", "swer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_preprocessing_parser": [[29, 33], ["options.get_parser", "options.add_preprocess_args"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_preprocess_args"], ["def", "get_preprocessing_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Preprocessing\"", ",", "default_task", ")", "\n", "add_preprocess_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_training_parser": [[35, 43], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_model_args", "options.add_optimization_args", "options.add_checkpoint_args"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_model_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_optimization_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_checkpoint_args"], ["", "def", "get_training_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Trainer\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ")", "\n", "add_model_args", "(", "parser", ")", "\n", "add_optimization_args", "(", "parser", ")", "\n", "add_checkpoint_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_generation_parser": [[45, 54], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_generation_args", "options.add_checkpoint_args", "options.add_interactive_args"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_generation_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_checkpoint_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_interactive_args"], ["", "def", "get_generation_parser", "(", "interactive", "=", "False", ",", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Generation\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "gen", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "add_generation_args", "(", "parser", ")", "\n", "add_checkpoint_args", "(", "parser", ")", "\n", "if", "interactive", ":", "\n", "        ", "add_interactive_args", "(", "parser", ")", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_interactive_generation_parser": [[56, 58], ["options.get_generation_parser"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_generation_parser"], ["", "def", "get_interactive_generation_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "return", "get_generation_parser", "(", "interactive", "=", "True", ",", "default_task", "=", "default_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_eval_lm_parser": [[60, 66], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_eval_lm_args"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_eval_lm_args"], ["", "def", "get_eval_lm_parser", "(", "default_task", "=", "\"language_modeling\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Evaluate Language Model\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "gen", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "add_eval_lm_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_validation_parser": [[68, 75], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "get_parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CommonEvalConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "get_validation_parser", "(", "default_task", "=", "None", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Validation\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "\"Evaluation\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "CommonEvalConfig", "(", ")", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.parse_args_and_arch": [[77, 210], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "fairseq.utils.import_user_module", "parser.parse_known_args", "hasattr", "hasattr", "getattr", "REGISTRIES.items", "getattr", "getattr", "getattr", "getattr", "options.parse_args_and_arch", "argparse.ArgumentParser", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args", "argparse.Namespace", "modify_parser", "parser.add_argument_group", "TASK_REGISTRY[].add_args", "FairseqBMUF.add_args", "getattr", "modify_parser", "parser.parse_known_args", "parser.parse_args", "hasattr", "ValueError", "getattr", "hasattr", "ARCH_MODEL_REGISTRY[].add_args", "hasattr", "hasattr", "hasattr", "MODEL_REGISTRY[].add_args", "RuntimeError", "cls.add_args", "hasattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "vars().items", "vars().items", "cls.__dataclass", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "parse_args_and_arch", "(", "\n", "parser", ":", "argparse", ".", "ArgumentParser", ",", "\n", "input_args", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "parse_known", ":", "bool", "=", "False", ",", "\n", "suppress_defaults", ":", "bool", "=", "False", ",", "\n", "modify_parser", ":", "Optional", "[", "Callable", "[", "[", "argparse", ".", "ArgumentParser", "]", ",", "None", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        parser (ArgumentParser): the parser\n        input_args (List[str]): strings to parse, defaults to sys.argv\n        parse_known (bool): only parse known arguments, similar to\n            `ArgumentParser.parse_known_args`\n        suppress_defaults (bool): parse while ignoring all default values\n        modify_parser (Optional[Callable[[ArgumentParser], None]]):\n            function to modify the parser, e.g., to set default values\n    \"\"\"", "\n", "if", "suppress_defaults", ":", "\n", "# Parse args without any default values. This requires us to parse", "\n", "# twice, once to identify all the necessary task/model args, and a second", "\n", "# time with all defaults set to None.", "\n", "        ", "args", "=", "parse_args_and_arch", "(", "\n", "parser", ",", "\n", "input_args", "=", "input_args", ",", "\n", "parse_known", "=", "parse_known", ",", "\n", "suppress_defaults", "=", "False", ",", "\n", ")", "\n", "suppressed_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "parents", "=", "[", "parser", "]", ")", "\n", "suppressed_parser", ".", "set_defaults", "(", "**", "{", "k", ":", "None", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "}", ")", "\n", "args", "=", "suppressed_parser", ".", "parse_args", "(", "input_args", ")", "\n", "return", "argparse", ".", "Namespace", "(", "\n", "**", "{", "k", ":", "v", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", ")", "\n", "\n", "", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", ",", "ARCH_CONFIG_REGISTRY", ",", "MODEL_REGISTRY", "\n", "\n", "# Before creating the true parser, we need to import optional user module", "\n", "# in order to eagerly import custom tasks, optimizers, architectures, etc.", "\n", "usr_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "allow_abbrev", "=", "False", ")", "\n", "usr_parser", ".", "add_argument", "(", "\"--user-dir\"", ",", "default", "=", "None", ")", "\n", "usr_args", ",", "_", "=", "usr_parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "utils", ".", "import_user_module", "(", "usr_args", ")", "\n", "\n", "if", "modify_parser", "is", "not", "None", ":", "\n", "        ", "modify_parser", "(", "parser", ")", "\n", "\n", "# The parser doesn't know about model/criterion/optimizer-specific args, so", "\n", "# we parse twice. First we parse the model/criterion/optimizer, then we", "\n", "# parse a second time after adding the *-specific arguments.", "\n", "# If input_args is given, we will parse those args instead of sys.argv.", "\n", "", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "\n", "# Add model-specific args to parser.", "\n", "if", "hasattr", "(", "args", ",", "\"arch\"", ")", ":", "\n", "        ", "model_specific_group", "=", "parser", ".", "add_argument_group", "(", "\n", "\"Model-specific configuration\"", ",", "\n", "# Only include attributes which are explicitly given as command-line", "\n", "# arguments or which have default values.", "\n", "argument_default", "=", "argparse", ".", "SUPPRESS", ",", "\n", ")", "\n", "if", "args", ".", "arch", "in", "ARCH_MODEL_REGISTRY", ":", "\n", "            ", "ARCH_MODEL_REGISTRY", "[", "args", ".", "arch", "]", ".", "add_args", "(", "model_specific_group", ")", "\n", "", "elif", "args", ".", "arch", "in", "MODEL_REGISTRY", ":", "\n", "            ", "MODEL_REGISTRY", "[", "args", ".", "arch", "]", ".", "add_args", "(", "model_specific_group", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "", "if", "hasattr", "(", "args", ",", "\"task\"", ")", ":", "\n", "        ", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "\n", "TASK_REGISTRY", "[", "args", ".", "task", "]", ".", "add_args", "(", "parser", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"use_bmuf\"", ",", "False", ")", ":", "\n", "# hack to support extra args for block distributed data parallelism", "\n", "        ", "from", "fairseq", ".", "optim", ".", "bmuf", "import", "FairseqBMUF", "\n", "\n", "FairseqBMUF", ".", "add_args", "(", "parser", ")", "\n", "\n", "# Add *-specific args to parser.", "\n", "", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "\n", "        ", "choice", "=", "getattr", "(", "args", ",", "registry_name", ",", "None", ")", "\n", "\n", "if", "choice", "is", "not", "None", ":", "\n", "            ", "cls", "=", "REGISTRY", "[", "\"registry\"", "]", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "\"add_args\"", ")", ":", "\n", "                ", "cls", ".", "add_args", "(", "parser", ")", "\n", "", "elif", "hasattr", "(", "cls", ",", "\"__dataclass\"", ")", ":", "\n", "                ", "gen_parser_from_dataclass", "(", "parser", ",", "cls", ".", "__dataclass", "(", ")", ")", "\n", "\n", "# Modify the parser a second time, since defaults may have been reset", "\n", "", "", "", "if", "modify_parser", "is", "not", "None", ":", "\n", "        ", "modify_parser", "(", "parser", ")", "\n", "\n", "# Parse a second time.", "\n", "", "if", "parse_known", ":", "\n", "        ", "args", ",", "extra", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "", "else", ":", "\n", "        ", "args", "=", "parser", ".", "parse_args", "(", "input_args", ")", "\n", "extra", "=", "None", "\n", "# Post-process args.", "\n", "", "if", "(", "\n", "hasattr", "(", "args", ",", "\"batch_size_valid\"", ")", "and", "args", ".", "batch_size_valid", "is", "None", "\n", ")", "or", "not", "hasattr", "(", "args", ",", "\"batch_size_valid\"", ")", ":", "\n", "        ", "args", ".", "batch_size_valid", "=", "args", ".", "batch_size", "\n", "", "if", "hasattr", "(", "args", ",", "\"max_tokens_valid\"", ")", "and", "args", ".", "max_tokens_valid", "is", "None", ":", "\n", "        ", "args", ".", "max_tokens_valid", "=", "args", ".", "max_tokens", "\n", "", "if", "getattr", "(", "args", ",", "\"memory_efficient_fp16\"", ",", "False", ")", ":", "\n", "        ", "args", ".", "fp16", "=", "True", "\n", "", "if", "getattr", "(", "args", ",", "\"memory_efficient_bf16\"", ",", "False", ")", ":", "\n", "        ", "args", ".", "bf16", "=", "True", "\n", "", "args", ".", "tpu", "=", "getattr", "(", "args", ",", "\"tpu\"", ",", "False", ")", "\n", "args", ".", "bf16", "=", "getattr", "(", "args", ",", "\"bf16\"", ",", "False", ")", "\n", "if", "args", ".", "bf16", ":", "\n", "        ", "args", ".", "tpu", "=", "True", "\n", "", "if", "args", ".", "tpu", "and", "args", ".", "fp16", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot combine --fp16 and --tpu, use --bf16 on TPUs\"", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"seed\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "args", ".", "seed", "=", "1", "# default seed for training", "\n", "args", ".", "no_seed_provided", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "no_seed_provided", "=", "False", "\n", "\n", "# Apply architecture configuration.", "\n", "", "if", "hasattr", "(", "args", ",", "\"arch\"", ")", "and", "args", ".", "arch", "in", "ARCH_CONFIG_REGISTRY", ":", "\n", "        ", "ARCH_CONFIG_REGISTRY", "[", "args", ".", "arch", "]", "(", "args", ")", "\n", "\n", "", "if", "parse_known", ":", "\n", "        ", "return", "args", ",", "extra", "\n", "", "else", ":", "\n", "        ", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.get_parser": [[212, 244], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "fairseq.utils.import_user_module", "argparse.ArgumentParser", "fairseq.dataclass.utils.gen_parser_from_dataclass", "REGISTRIES.items", "argparse.ArgumentParser.add_argument", "fairseq.dataclass.configs.CommonConfig", "argparse.ArgumentParser.add_argument", "TASK_REGISTRY.keys", "registry_name.replace", "REGISTRY[].keys"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "", "def", "get_parser", "(", "desc", ",", "default_task", "=", "\"translation\"", ")", ":", "\n", "# Before creating the true parser, we need to import optional user module", "\n", "# in order to eagerly import custom tasks, optimizers, architectures, etc.", "\n", "    ", "usr_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "allow_abbrev", "=", "False", ")", "\n", "usr_parser", ".", "add_argument", "(", "\"--user-dir\"", ",", "default", "=", "None", ")", "\n", "usr_args", ",", "_", "=", "usr_parser", ".", "parse_known_args", "(", ")", "\n", "utils", ".", "import_user_module", "(", "usr_args", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "allow_abbrev", "=", "False", ")", "\n", "gen_parser_from_dataclass", "(", "parser", ",", "CommonConfig", "(", ")", ")", "\n", "\n", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--\"", "+", "registry_name", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", ",", "\n", "default", "=", "REGISTRY", "[", "\"default\"", "]", ",", "\n", "choices", "=", "REGISTRY", "[", "\"registry\"", "]", ".", "keys", "(", ")", ",", "\n", ")", "\n", "\n", "# Task definitions can be found under fairseq/tasks/", "\n", "", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "\n", "metavar", "=", "\"TASK\"", ",", "\n", "default", "=", "default_task", ",", "\n", "choices", "=", "TASK_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "\"task\"", ",", "\n", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_preprocess_args": [[246, 292], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "fairseq.data.indexed_dataset.get_available_dataset_impl"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.get_available_dataset_impl"], ["", "def", "add_preprocess_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Preprocessing\"", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "\"-s\"", ",", "\"--source-lang\"", ",", "default", "=", "None", ",", "metavar", "=", "\"SRC\"", ",", "\n", "help", "=", "\"source language\"", ")", "\n", "group", ".", "add_argument", "(", "\"-t\"", ",", "\"--target-lang\"", ",", "default", "=", "None", ",", "metavar", "=", "\"TARGET\"", ",", "\n", "help", "=", "\"target language\"", ")", "\n", "group", ".", "add_argument", "(", "\"--trainpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"train file prefix (also used to build dictionaries)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--validpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"comma separated, valid file prefixes \"", "\n", "\"(words missing from train set are replaced with <unk>)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--testpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"comma separated, test file prefixes \"", "\n", "\"(words missing from train set are replaced with <unk>)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--align-suffix\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"alignment file suffix\"", ")", "\n", "group", ".", "add_argument", "(", "\"--destdir\"", ",", "metavar", "=", "\"DIR\"", ",", "default", "=", "\"data-bin\"", ",", "\n", "help", "=", "\"destination dir\"", ")", "\n", "group", ".", "add_argument", "(", "\"--thresholdtgt\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"map words appearing less than threshold times to unknown\"", ")", "\n", "group", ".", "add_argument", "(", "\"--thresholdsrc\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"map words appearing less than threshold times to unknown\"", ")", "\n", "group", ".", "add_argument", "(", "\"--tgtdict\"", ",", "metavar", "=", "\"FP\"", ",", "\n", "help", "=", "\"reuse given target dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--srcdict\"", ",", "metavar", "=", "\"FP\"", ",", "\n", "help", "=", "\"reuse given source dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--nwordstgt\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of target words to retain\"", ")", "\n", "group", ".", "add_argument", "(", "\"--nwordssrc\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of source words to retain\"", ")", "\n", "group", ".", "add_argument", "(", "\"--alignfile\"", ",", "metavar", "=", "\"ALIGN\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"an alignment file (optional)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset-impl'", ",", "metavar", "=", "'FORMAT'", ",", "default", "=", "'mmap'", ",", "\n", "choices", "=", "get_available_dataset_impl", "(", ")", ",", "\n", "help", "=", "'output dataset implementation'", ")", "\n", "group", ".", "add_argument", "(", "\"--joined-dictionary\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Generate joined dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--only-source\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Only process the source language\"", ")", "\n", "group", ".", "add_argument", "(", "\"--padding-factor\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Pad dictionary size to be multiple of N\"", ")", "\n", "group", ".", "add_argument", "(", "\"--workers\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of parallel workers\"", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_dataset_args": [[294, 299], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.DatasetConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_dataset_args", "(", "parser", ",", "train", "=", "False", ",", "gen", "=", "False", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"dataset_data_loading\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "DatasetConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_distributed_training_args": [[301, 309], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "max", "fairseq.dataclass.configs.DistributedTrainingConfig", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "None", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"distributed_training\"", ")", "\n", "if", "default_world_size", "is", "None", ":", "\n", "        ", "default_world_size", "=", "max", "(", "1", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "", "gen_parser_from_dataclass", "(", "\n", "group", ",", "DistributedTrainingConfig", "(", "distributed_world_size", "=", "default_world_size", ")", "\n", ")", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_optimization_args": [[311, 317], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.OptimizationConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_optimization_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"optimization\"", ")", "\n", "# fmt: off", "\n", "gen_parser_from_dataclass", "(", "group", ",", "OptimizationConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_checkpoint_args": [[319, 325], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CheckpointConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_checkpoint_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"checkpoint\"", ")", "\n", "# fmt: off", "\n", "gen_parser_from_dataclass", "(", "group", ",", "CheckpointConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_common_eval_args": [[327, 329], ["fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CommonEvalConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_common_eval_args", "(", "group", ")", ":", "\n", "    ", "gen_parser_from_dataclass", "(", "group", ",", "CommonEvalConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_eval_lm_args": [[331, 335], ["parser.add_argument_group", "options.add_common_eval_args", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.EvalLMConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_common_eval_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_eval_lm_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"LM Evaluation\"", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "EvalLMConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_generation_args": [[337, 342], ["parser.add_argument_group", "options.add_common_eval_args", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.GenerationConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_common_eval_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_generation_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Generation\"", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "GenerationConfig", "(", ")", ")", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_interactive_args": [[344, 347], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.InteractiveConfig"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_interactive_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Interactive\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "InteractiveConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.options.add_model_args": [[349, 366], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "ARCH_MODEL_REGISTRY.keys"], "function", ["None"], ["", "def", "add_model_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Model configuration\"", ")", "\n", "# fmt: off", "\n", "\n", "# Model definitions can be found under fairseq/models/", "\n", "#", "\n", "# The model architecture can be specified in several ways.", "\n", "# In increasing order of priority:", "\n", "# 1) model defaults (lowest priority)", "\n", "# 2) --arch argument", "\n", "# 3) --encoder/decoder-* arguments (highest priority)", "\n", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", "\n", "group", ".", "add_argument", "(", "'--arch'", ",", "'-a'", ",", "metavar", "=", "'ARCH'", ",", "\n", "choices", "=", "ARCH_MODEL_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "'model architecture'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master": [[43, 45], ["None"], "function", ["None"], ["def", "is_master", "(", "cfg", ":", "DistributedTrainingConfig", ")", ":", "\n", "    ", "return", "cfg", ".", "distributed_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.infer_init_method": [[47, 214], ["all", "fairseq.utils.eval_str_list", "torch.cuda.device_count", "torch.cuda.device_count", "int", "int", "ValueError", "ValueError", "fairseq.utils.eval_str_list", "len", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "len", "os.environ.get", "logger.debug", "torch.cuda.set_device", "torch.cuda.set_device", "logger.info", "set", "set", "os.environ.get", "random.randint", "omegaconf.open_dict", "omegaconf.open_dict", "omegaconf.open_dict", "min", "subprocess.check_output", "int", "os.environ.get", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "os.environ.get", "int", "int", "int", "int", "torch.cuda.device_count", "torch.cuda.device_count", "int", "torch.cuda.device_count", "torch.cuda.device_count", "[].decode", "os.environ.get", "os.environ.get", "os.environ.get", "int", "int", "int", "int", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "subprocess.check_output.split"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "infer_init_method", "(", "cfg", ":", "DistributedTrainingConfig", ",", "force_distributed", "=", "False", ")", ":", "\n", "    ", "if", "cfg", ".", "distributed_init_method", "is", "not", "None", "or", "cfg", ".", "tpu", ":", "\n", "        ", "return", "\n", "\n", "", "if", "cfg", ".", "pipeline_model_parallel", ":", "\n", "        ", "balance_exists", "=", "(", "\n", "cfg", ".", "pipeline_balance", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_encoder_balance", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_decoder_balance", "is", "not", "None", "\n", ")", "\n", "devices_exist", "=", "(", "\n", "cfg", ".", "pipeline_devices", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_encoder_devices", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_decoder_devices", "is", "not", "None", "\n", ")", "\n", "if", "not", "balance_exists", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--pipeline-balance is currently required for pipeline model parallelism\"", "\n", ")", "\n", "", "if", "not", "devices_exist", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--pipeline-devices is currently required for pipeline model parallelism\"", "\n", ")", "\n", "\n", "", "cfg", ".", "pipeline_balance", "=", "utils", ".", "eval_str_list", "(", "cfg", ".", "pipeline_balance", ",", "type", "=", "int", ")", "\n", "if", "cfg", ".", "pipeline_devices", "is", "not", "None", ":", "\n", "            ", "cfg", ".", "pipeline_devices", "=", "utils", ".", "eval_str_list", "(", "cfg", ".", "pipeline_devices", ",", "type", "=", "int", ")", "\n", "num_pipeline_devices", "=", "len", "(", "set", "(", "cfg", ".", "pipeline_devices", ")", ")", "\n", "", "else", ":", "\n", "            ", "cfg", ".", "pipeline_encoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "cfg", ".", "pipeline_encoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "cfg", ".", "pipeline_decoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "cfg", ".", "pipeline_decoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "num_pipeline_devices", "=", "len", "(", "\n", "set", "(", "cfg", ".", "pipeline_encoder_devices", "+", "cfg", ".", "pipeline_decoder_devices", ")", "\n", ")", "\n", "", "gpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "assert", "(", "\n", "gpus_per_node", ">=", "num_pipeline_devices", "\n", "and", "gpus_per_node", "%", "num_pipeline_devices", "==", "0", "\n", ")", ",", "(", "\n", "\"the number of unique device IDs in --pipeline-devices must evenly divide \"", "\n", "\"the number of GPUs per node (multi-node pipelining is not yet supported)\"", "\n", ")", "\n", "num_pipelines_per_node", "=", "gpus_per_node", "//", "num_pipeline_devices", "\n", "\n", "# support torch.distributed.launch", "\n", "", "if", "all", "(", "\n", "key", "in", "os", ".", "environ", "\n", "for", "key", "in", "[", "\"MASTER_ADDR\"", ",", "\"MASTER_PORT\"", ",", "\"WORLD_SIZE\"", ",", "\"RANK\"", "]", "\n", ")", ":", "\n", "        ", "cfg", ".", "distributed_init_method", "=", "\"env://\"", "\n", "cfg", ".", "distributed_world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "cfg", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "# processes are created by torch.distributed.launch", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "\n", "# we can determine the init method automatically for Slurm", "\n", "", "elif", "cfg", ".", "distributed_port", ">", "0", ":", "\n", "        ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_STEP_NODELIST\"", ")", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_JOB_NODELIST\"", ")", "\n", "", "if", "node_list", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "hostnames", "=", "subprocess", ".", "check_output", "(", "\n", "[", "\"scontrol\"", ",", "\"show\"", ",", "\"hostnames\"", ",", "node_list", "]", "\n", ")", "\n", "cfg", ".", "distributed_init_method", "=", "\"tcp://{host}:{port}\"", ".", "format", "(", "\n", "host", "=", "hostnames", ".", "split", "(", ")", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "port", "=", "cfg", ".", "distributed_port", ",", "\n", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NNODES\"", ")", ")", "\n", "ntasks_per_node", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_NTASKS_PER_NODE\"", ")", "\n", "if", "ntasks_per_node", "is", "not", "None", ":", "\n", "                    ", "ntasks_per_node", "=", "int", "(", "ntasks_per_node", ")", "\n", "", "else", ":", "\n", "                    ", "ntasks", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NTASKS\"", ")", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NNODES\"", ")", ")", "\n", "assert", "ntasks", "%", "nnodes", "==", "0", "\n", "ntasks_per_node", "=", "int", "(", "ntasks", "/", "nnodes", ")", "\n", "", "if", "ntasks_per_node", "==", "1", ":", "\n", "                    ", "gpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "node_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NODEID\"", ")", ")", "\n", "cfg", ".", "distributed_rank", "=", "node_id", "*", "gpus_per_node", "\n", "cfg", ".", "distributed_world_size", "=", "nnodes", "*", "gpus_per_node", "\n", "", "elif", "cfg", ".", "pipeline_model_parallel", ":", "\n", "                    ", "assert", "ntasks_per_node", "==", "num_pipelines_per_node", ",", "(", "\n", "\"SLURM --ntasks-per-node must match number of pipelines per \"", "\n", "\"node (={})\"", ".", "format", "(", "num_pipelines_per_node", ")", "\n", ")", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "# For 4-way MP on nodes with 8 GPUs, ranks will be [0, 1] on", "\n", "# the first node, [1, 2] on the second node, etc. This", "\n", "# matches torch.distributed.launch.", "\n", "node_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NODEID\"", ")", ")", "\n", "local_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_LOCALID\"", ")", ")", "\n", "cfg", ".", "distributed_rank", "=", "node_id", "*", "num_pipelines_per_node", "+", "local_id", "\n", "# In the above example, device_id will always be in [0, 1],", "\n", "# which also matches torch.distributed.launch.", "\n", "cfg", ".", "device_id", "=", "local_id", "\n", "# We also want to set distributed_world_size to be the total", "\n", "# number of pipelines across all nodes.", "\n", "cfg", ".", "distributed_world_size", "=", "nnodes", "*", "num_pipelines_per_node", "\n", "", "else", ":", "\n", "                    ", "assert", "ntasks_per_node", "==", "cfg", ".", "distributed_world_size", "//", "nnodes", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "cfg", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_PROCID\"", ")", ")", "\n", "cfg", ".", "device_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_LOCALID\"", ")", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "# scontrol failed", "\n", "                ", "raise", "e", "\n", "", "except", "FileNotFoundError", ":", "# Slurm is not installed", "\n", "                ", "pass", "\n", "\n", "", "", "", "elif", "cfg", ".", "distributed_world_size", ">", "1", "or", "force_distributed", ":", "\n", "# fallback for single node with multiple GPUs", "\n", "        ", "assert", "(", "\n", "cfg", ".", "distributed_world_size", "<=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", ")", ",", "f\"world size is {cfg.distributed_world_size} but have {torch.cuda.device_count()} available devices\"", "\n", "port", "=", "random", ".", "randint", "(", "10000", ",", "20000", ")", "\n", "cfg", ".", "distributed_init_method", "=", "\"tcp://localhost:{port}\"", ".", "format", "(", "port", "=", "port", ")", "\n", "\n", "", "if", "cfg", ".", "pipeline_model_parallel", ":", "\n", "        ", "if", "not", "cfg", ".", "distributed_no_spawn", ":", "\n", "# When distributed_no_spawn is False, we expect distributed_rank and", "\n", "# distributed_world_size to be based on the total number of GPUs, so", "\n", "# we need to correct them to be based on the number of pipelines.", "\n", "            ", "assert", "cfg", ".", "distributed_world_size", "%", "num_pipeline_devices", "==", "0", "\n", "cfg", ".", "distributed_world_size", "=", "(", "\n", "cfg", ".", "distributed_world_size", "//", "num_pipeline_devices", "\n", ")", "\n", "# In the case of 4-way MP on nodes with 8 GPUs, we want", "\n", "# distributed_rank to be the starting GPU index for each pipeline", "\n", "# i.e., 0, 2, ...", "\n", "assert", "cfg", ".", "distributed_rank", "%", "gpus_per_node", "==", "0", "\n", "assert", "cfg", ".", "distributed_rank", "%", "num_pipeline_devices", "==", "0", "\n", "\n", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "distributed_rank", "=", "cfg", ".", "distributed_rank", "//", "num_pipeline_devices", "\n", "# launch one process per pipeline", "\n", "cfg", ".", "distributed_num_procs", "=", "num_pipelines_per_node", "\n", "\n", "# if we have 4-way MP on a node with 8 GPUs, we want device_ids to be 0", "\n", "# and 4, indicating the starting device IDs for each pipeline", "\n", "", "", "cfg", ".", "device_id", "*=", "num_pipeline_devices", "\n", "\n", "if", "cfg", ".", "device_id", ">", "0", ":", "\n", "# if there's multiple pipelines on a node (e.g., 4-way MP on an 8", "\n", "# GPU node), we need to adjust pipeline_devices accordingly", "\n", "            ", "logger", ".", "debug", "(", "\n", "\"setting CUDA device={} on rank {}\"", ".", "format", "(", "\n", "cfg", ".", "device_id", ",", "cfg", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "device_id", ")", "\n", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "pipeline_devices", "=", "[", "cfg", ".", "device_id", "+", "d", "for", "d", "in", "cfg", ".", "pipeline_devices", "]", "\n", "", "logger", ".", "info", "(", "\n", "\"setting pipeline_devices={} on rank {}\"", ".", "format", "(", "\n", "cfg", ".", "pipeline_devices", ",", "cfg", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "", "", "elif", "not", "cfg", ".", "distributed_no_spawn", ":", "\n", "        ", "with", "open_dict", "(", "cfg", ")", ":", "\n", "            ", "cfg", ".", "distributed_num_procs", "=", "min", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "cfg", ".", "distributed_world_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.distributed_init": [[217, 287], ["isinstance", "distributed_utils.is_master", "convert_namespace_to_omegaconf", "torch.distributed.get_rank", "torch.distributed.get_rank", "xm.get_local_ordinal", "xm.get_ordinal", "xm.rendezvous", "xm.mark_step", "logging.getLogger().setLevel", "logging.getLogger().setLevel", "initialize_model_parallel", "model_parallel_cuda_manual_seed", "distributed_utils.get_model_parallel_rank", "torch.distributed.is_available", "torch.distributed.is_available", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "warnings.warn", "logger.info", "torch.init_process_group", "logger.info", "torch.cuda.is_available", "torch.cuda.is_available", "xm.xrt_world_size", "torch.all_reduce", "logging.getLogger", "logging.getLogger", "ImportError", "socket.gethostname", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "", "", "def", "distributed_init", "(", "cfg", ":", "FairseqConfig", ")", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "from", "fairseq", ".", "dataclass", ".", "utils", "import", "convert_namespace_to_omegaconf", "\n", "\n", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "if", "not", "cfg", ".", "common", ".", "tpu", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Distributed is already initialized, cannot initialize twice!\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"distributed init (rank {}): {}\"", ".", "format", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_init_method", ",", "\n", ")", "\n", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "cfg", ".", "distributed_training", ".", "distributed_backend", ",", "\n", "init_method", "=", "cfg", ".", "distributed_training", ".", "distributed_init_method", ",", "\n", "world_size", "=", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", "rank", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"initialized host {} as rank {}\"", ".", "format", "(", "\n", "socket", ".", "gethostname", "(", ")", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", ")", "\n", ")", "\n", "\n", "# perform a dummy all-reduce to initialize the NCCL communicator", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "dist", ".", "all_reduce", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "", "", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "xm", ".", "xrt_world_size", "(", ")", "==", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "global", "_USE_XLA", "\n", "_USE_XLA", "=", "True", "\n", "cfg", ".", "distributed_training", ".", "device_id", "=", "xm", ".", "get_local_ordinal", "(", ")", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "xm", ".", "get_ordinal", "(", ")", "\n", "xm", ".", "rendezvous", "(", "\"distributed_init\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "if", "is_master", "(", "cfg", ".", "distributed_training", ")", ":", "\n", "        ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "logging", ".", "WARNING", ")", "\n", "\n", "", "if", "cfg", ".", "common", ".", "model_parallel_size", ">", "1", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "model_parallel", ".", "megatron", ".", "mpu", "import", "(", "\n", "initialize_model_parallel", ",", "\n", "model_parallel_cuda_manual_seed", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "", "global", "_USE_MEGATRON", "\n", "_USE_MEGATRON", "=", "True", "\n", "initialize_model_parallel", "(", "cfg", ".", "common", ".", "model_parallel_size", ")", "\n", "model_parallel_cuda_manual_seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "model_part_number", "=", "get_model_parallel_rank", "(", ")", "\n", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", "+=", "\"-model_part-{0}\"", ".", "format", "(", "model_part_number", ")", "\n", "\n", "", "return", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.distributed_main": [[289, 303], ["distributed_utils.distributed_init", "kwargs.pop", "main", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.set_device", "torch.cuda.set_device", "kwargs.pop.", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.distributed_init", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.main"], ["", "def", "distributed_main", "(", "i", ",", "main", ",", "cfg", ":", "FairseqConfig", ",", "kwargs", ")", ":", "\n", "    ", "cfg", ".", "distributed_training", ".", "device_id", "=", "i", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "and", "not", "cfg", ".", "common", ".", "tpu", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "distributed_training", ".", "device_id", ")", "\n", "", "if", "cfg", ".", "distributed_training", ".", "distributed_rank", "is", "None", ":", "# torch.multiprocessing.spawn", "\n", "        ", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "kwargs", ".", "pop", "(", "\"start_rank\"", ",", "0", ")", "+", "i", "\n", "\n", "", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "distributed_init", "(", "cfg", ")", "\n", "\n", "after_distributed_init_fn", "=", "kwargs", ".", "pop", "(", "\"after_distributed_init_fn\"", ",", "None", ")", "\n", "if", "after_distributed_init_fn", ":", "\n", "        ", "cfg", "=", "after_distributed_init_fn", "(", "cfg", ")", "\n", "\n", "", "main", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.call_main": [[305, 338], ["distributed_utils.infer_init_method", "torch.multiprocessing.spawn", "torch.multiprocessing.spawn", "distributed_utils.distributed_main", "torch.multiprocessing.set_sharing_strategy", "torch.multiprocessing.set_sharing_strategy", "xmp.spawn", "main", "min", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.infer_init_method", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.distributed_main", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.inference.beam_search.main"], ["", "def", "call_main", "(", "cfg", ":", "FairseqConfig", ",", "main", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "cfg", ".", "distributed_training", ".", "distributed_init_method", "is", "None", ":", "\n", "        ", "infer_init_method", "(", "cfg", ".", "distributed_training", ")", "\n", "\n", "", "if", "cfg", ".", "distributed_training", ".", "distributed_init_method", "is", "not", "None", ":", "\n", "# distributed training", "\n", "        ", "if", "not", "cfg", ".", "distributed_training", ".", "distributed_no_spawn", ":", "\n", "            ", "start_rank", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "None", "# assign automatically", "\n", "kwargs", "[", "\"start_rank\"", "]", "=", "start_rank", "\n", "torch", ".", "multiprocessing", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "main", ",", "cfg", ",", "kwargs", ")", ",", "\n", "nprocs", "=", "min", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", ")", ",", "\n", "join", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "distributed_main", "(", "cfg", ".", "distributed_training", ".", "device_id", ",", "main", ",", "cfg", ",", "kwargs", ")", "\n", "", "", "elif", "cfg", ".", "common", ".", "tpu", "and", "cfg", ".", "distributed_training", ".", "distributed_world_size", ">", "1", ":", "\n", "        ", "import", "torch_xla", ".", "distributed", ".", "xla_multiprocessing", "as", "xmp", "\n", "\n", "torch", ".", "multiprocessing", ".", "set_sharing_strategy", "(", "\"file_system\"", ")", "\n", "xmp", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "main", ",", "cfg", ",", "kwargs", ")", ",", "\n", "nprocs", "=", "8", ",", "# use all 8 TPU cores", "\n", ")", "\n", "", "else", ":", "\n", "# single GPU main", "\n", "        ", "main", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla": [[340, 343], ["None"], "function", ["None"], ["", "", "def", "use_xla", "(", ")", ":", "\n", "    ", "global", "_USE_XLA", "\n", "return", "_USE_XLA", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.new_groups": [[345, 352], ["distributed_utils.use_xla", "distributed_utils._find_my_group_index", "torch.new_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group_index"], ["", "def", "new_groups", "(", "grouped_ranks", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "(", "\"tpu\"", ",", "grouped_ranks", ")", "\n", "", "else", ":", "\n", "        ", "groups", "=", "[", "dist", ".", "new_group", "(", "g", ")", "for", "g", "in", "grouped_ranks", "]", "\n", "my_group_idx", "=", "_find_my_group_index", "(", "grouped_ranks", ")", "\n", "return", "groups", "[", "my_group_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group_index": [[354, 360], ["distributed_utils.get_global_rank", "enumerate"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_rank"], ["", "", "def", "_find_my_group_index", "(", "grouped_ranks", ")", ":", "\n", "    ", "my_rank", "=", "get_global_rank", "(", ")", "\n", "for", "i", ",", "group", "in", "enumerate", "(", "grouped_ranks", ")", ":", "\n", "        ", "if", "my_rank", "in", "group", ":", "\n", "            ", "return", "i", "\n", "", "", "raise", "RuntimeError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group": [[362, 365], ["distributed_utils._find_my_group_index"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group_index"], ["", "def", "_find_my_group", "(", "grouped_ranks", ")", ":", "\n", "    ", "index", "=", "_find_my_group_index", "(", "grouped_ranks", ")", "\n", "return", "grouped_ranks", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank": [[367, 374], ["distributed_utils.use_xla", "distributed_utils._find_my_group", "_find_my_group.index", "torch.get_rank", "distributed_utils.get_global_rank"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_rank"], ["", "def", "get_rank", "(", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "my_group", "=", "_find_my_group", "(", "group", "[", "1", "]", ")", "\n", "return", "my_group", ".", "index", "(", "get_global_rank", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size": [[376, 385], ["distributed_utils.use_xla", "distributed_utils._find_my_group", "len", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._find_my_group", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size"], ["", "", "def", "get_world_size", "(", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "my_group", "=", "_find_my_group", "(", "group", "[", "1", "]", ")", "\n", "return", "len", "(", "my_group", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_group": [[387, 398], ["distributed_utils.use_xla", "distributed_utils.new_groups", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "list", "hasattr", "torch.new_group", "range", "distributed_utils.get_global_world_size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.new_groups", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_world_size"], ["", "", "def", "get_global_group", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "new_groups", "(", "[", "list", "(", "range", "(", "get_global_world_size", "(", ")", ")", ")", "]", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "get_global_group", ",", "\"_global_group\"", ")", ":", "\n", "# ideally we could use torch.distributed.group.WORLD, but it seems", "\n", "# to cause random NCCL hangs in some cases", "\n", "            ", "get_global_group", ".", "_global_group", "=", "dist", ".", "new_group", "(", ")", "\n", "", "return", "get_global_group", ".", "_global_group", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_rank": [[400, 407], ["distributed_utils.use_xla", "xm.get_ordinal", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.get_rank", "torch.distributed.get_rank"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank"], ["", "", "def", "get_global_rank", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "xm", ".", "get_ordinal", "(", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_world_size": [[409, 416], ["distributed_utils.use_xla", "xm.xrt_world_size", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size"], ["", "", "def", "get_global_world_size", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "xm", ".", "xrt_world_size", "(", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_group": [[418, 427], ["mpu.get_data_parallel_group", "distributed_utils.get_global_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_group", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_group"], ["", "", "def", "get_data_parallel_group", "(", ")", ":", "\n", "    ", "\"\"\"Get the data parallel group the caller rank belongs to.\"\"\"", "\n", "global", "_USE_MEGATRON", "\n", "if", "_USE_MEGATRON", ":", "\n", "        ", "from", "fairseq", ".", "model_parallel", ".", "megatron", "import", "mpu", "\n", "\n", "return", "mpu", ".", "get_data_parallel_group", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "get_global_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_rank": [[429, 432], ["distributed_utils.get_rank", "distributed_utils.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_group"], ["", "", "def", "get_data_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the data parallel group.\"\"\"", "\n", "return", "get_rank", "(", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_world_size": [[434, 437], ["distributed_utils.get_world_size", "distributed_utils.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_group"], ["", "def", "get_data_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the data parallel group.\"\"\"", "\n", "return", "get_world_size", "(", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_group": [[439, 447], ["mpu.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "get_model_parallel_group", "(", ")", ":", "\n", "    ", "global", "_USE_MEGATRON", "\n", "if", "_USE_MEGATRON", ":", "\n", "        ", "from", "fairseq", ".", "model_parallel", ".", "megatron", "import", "mpu", "\n", "\n", "return", "mpu", ".", "get_model_parallel_group", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_rank": [[449, 452], ["distributed_utils.get_rank", "distributed_utils.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_group"], ["", "", "def", "get_model_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the model parallel group.\"\"\"", "\n", "return", "get_rank", "(", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_world_size": [[454, 457], ["distributed_utils.get_world_size", "distributed_utils.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "get_model_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the model parallel group.\"\"\"", "\n", "return", "get_world_size", "(", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce": [[459, 473], ["distributed_utils.use_xla", "torch.all_reduce", "isinstance", "xm.all_reduce"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce"], ["", "def", "all_reduce", "(", "tensor", ",", "group", ",", "op", "=", "\"sum\"", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "isinstance", "(", "group", ",", "tuple", ")", "and", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "tensor", "=", "[", "tensor", "]", "# wrap in a list to make xm.all_reduce in-place", "\n", "return", "xm", ".", "all_reduce", "(", "op", ",", "tensor", ",", "groups", "=", "group", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "if", "op", "==", "\"sum\"", ":", "\n", "            ", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", "\n", "", "elif", "op", "==", "\"max\"", ":", "\n", "            ", "op", "=", "dist", ".", "ReduceOp", ".", "MAX", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "dist", ".", "all_reduce", "(", "tensor", ",", "op", "=", "op", ",", "group", "=", "group", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast": [[475, 483], ["distributed_utils.use_xla", "distributed_utils.all_reduce", "torch.broadcast", "distributed_utils.get_rank", "tensor.zero_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank"], ["", "", "def", "broadcast", "(", "tensor", ",", "src", ",", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "# XLA doesn't support broadcast, hack it with all_reduce", "\n", "        ", "if", "get_rank", "(", "group", ")", "!=", "src", ":", "\n", "            ", "tensor", ".", "zero_", "(", ")", "\n", "", "all_reduce", "(", "tensor", ",", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "broadcast", "(", "tensor", ",", "src", "=", "src", ",", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_to_all": [[485, 503], ["distributed_utils.get_world_size", "distributed_utils.use_xla", "tensor.dim", "xm.all_to_all", "torch.zeros_like", "torch.zeros_like", "torch.all_to_all_single", "tensor.numel", "isinstance"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_to_all"], ["", "", "def", "all_to_all", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"Perform an all-to-all operation on a 1D Tensor.\"\"\"", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "1", "\n", "split_count", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "tensor", ".", "numel", "(", ")", "%", "split_count", "==", "0", "\n", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "isinstance", "(", "group", ",", "tuple", ")", "and", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "return", "xm", ".", "all_to_all", "(", "\n", "tensor", ",", "\n", "split_dimension", "=", "0", ",", "\n", "concat_dimension", "=", "0", ",", "\n", "split_count", "=", "split_count", ",", "\n", "groups", "=", "group", "[", "1", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "torch", ".", "zeros_like", "(", "tensor", ")", "\n", "dist", ".", "all_to_all_single", "(", "output", ",", "tensor", ",", "group", "=", "group", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather": [[505, 526], ["distributed_utils.use_xla", "xm.all_gather", "distributed_utils.get_world_size", "result.view.view", "distributed_utils.get_world_size", "distributed_utils.get_rank", "torch.all_gather", "torch.stack", "torch.stack", "tensor.size", "torch.empty_like", "torch.empty_like", "range", "range"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "all_gather", "(", "tensor", ",", "group", ",", "return_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"Perform an all-gather operation.\"\"\"", "\n", "if", "use_xla", "(", ")", ":", "\n", "        ", "result", "=", "xm", ".", "all_gather", "(", "tensor", ",", "groups", "=", "group", "[", "1", "]", ")", "\n", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "result", "=", "result", ".", "view", "(", "world_size", ",", "*", "tensor", ".", "size", "(", ")", ")", "\n", "if", "return_tensor", ":", "\n", "            ", "return", "result", "\n", "", "else", ":", "\n", "            ", "return", "[", "result", "[", "i", "]", "for", "i", "in", "range", "(", "world_size", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "rank", "=", "get_rank", "(", "group", "=", "group", ")", "\n", "tensor_list", "=", "[", "\n", "tensor", "if", "i", "==", "rank", "else", "torch", ".", "empty_like", "(", "tensor", ")", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "if", "return_tensor", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "tensor_list", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "tensor_list", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather_list": [[528, 589], ["distributed_utils.get_rank", "distributed_utils.get_world_size", "buffer.cpu.zero_", "fairseq.utils.move_to_cpu", "pickle.dumps", "len", "struct.pack", "torch.ByteTensor", "torch.ByteTensor", "buffer[].copy_", "distributed_utils.all_reduce", "buffer.cpu.cpu", "distributed_utils.get_global_group", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.ByteTensor().pin_memory", "torch.ByteTensor().pin_memory", "ValueError", "list", "range", "hasattr", "all_gather_list._buffer.numel", "struct.unpack", "Exception", "torch.ByteTensor", "torch.ByteTensor", "bytes", "result.append", "out_buffer[].tolist", "pickle.loads", "bytes", "out_buffer[].tolist"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_group"], ["", "", "", "def", "all_gather_list", "(", "data", ",", "group", "=", "None", ",", "max_size", "=", "16384", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\n\n    Similar to :func:`~torch.distributed.all_gather` but for arbitrary Python\n    data. Note that *data* must be picklable.\n\n    Args:\n        data (Any): data from the local worker to be gathered on other workers\n        group: group of the collective\n        max_size (int, optional): maximum size of the data to be gathered\n            across workers\n    \"\"\"", "\n", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "get_global_group", "(", ")", "\n", "", "rank", "=", "get_rank", "(", "group", "=", "group", ")", "\n", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "\n", "buffer_size", "=", "max_size", "*", "world_size", "\n", "if", "(", "\n", "not", "hasattr", "(", "all_gather_list", ",", "\"_buffer\"", ")", "\n", "or", "all_gather_list", ".", "_buffer", ".", "numel", "(", ")", "<", "buffer_size", "\n", ")", ":", "\n", "        ", "all_gather_list", ".", "_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "buffer_size", ")", "\n", "all_gather_list", ".", "_cpu_buffer", "=", "torch", ".", "ByteTensor", "(", "max_size", ")", ".", "pin_memory", "(", ")", "\n", "", "buffer", "=", "all_gather_list", ".", "_buffer", "\n", "buffer", ".", "zero_", "(", ")", "\n", "cpu_buffer", "=", "all_gather_list", ".", "_cpu_buffer", "\n", "\n", "data", "=", "utils", ".", "move_to_cpu", "(", "data", ")", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "header_size", "=", "4", "# size of header that contains the length of the encoded data", "\n", "size", "=", "header_size", "+", "enc_size", "\n", "if", "size", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"encoded data size ({}) exceeds max_size ({})\"", ".", "format", "(", "size", ",", "max_size", ")", "\n", ")", "\n", "\n", "", "header", "=", "struct", ".", "pack", "(", "\">I\"", ",", "enc_size", ")", "\n", "cpu_buffer", "[", ":", "size", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "header", "+", "enc", ")", ")", "\n", "start", "=", "rank", "*", "max_size", "\n", "buffer", "[", "start", ":", "start", "+", "size", "]", ".", "copy_", "(", "cpu_buffer", "[", ":", "size", "]", ")", "\n", "\n", "all_reduce", "(", "buffer", ",", "group", "=", "group", ")", "\n", "\n", "buffer", "=", "buffer", ".", "cpu", "(", ")", "\n", "try", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "            ", "out_buffer", "=", "buffer", "[", "i", "*", "max_size", ":", "(", "i", "+", "1", ")", "*", "max_size", "]", "\n", "(", "enc_size", ",", ")", "=", "struct", ".", "unpack", "(", "\">I\"", ",", "bytes", "(", "out_buffer", "[", ":", "header_size", "]", ".", "tolist", "(", ")", ")", ")", "\n", "if", "enc_size", ">", "0", ":", "\n", "                ", "result", ".", "append", "(", "\n", "pickle", ".", "loads", "(", "\n", "bytes", "(", "out_buffer", "[", "header_size", ":", "header_size", "+", "enc_size", "]", ".", "tolist", "(", ")", ")", "\n", ")", "\n", ")", "\n", "", "", "return", "result", "\n", "", "except", "pickle", ".", "UnpicklingError", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Unable to unpickle data from other workers. all_gather_list requires all \"", "\n", "\"workers to enter the function together, so this error usually indicates \"", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce_dict": [[598, 645], ["list", "collections.OrderedDict", "collections.OrderedDict", "distributed_utils.all_reduce_dict._all_reduce_dict"], "function", ["None"], ["", "", "def", "all_reduce_dict", "(", "data", ":", "Mapping", "[", "str", ",", "Any", "]", ",", "device", ",", "group", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    AllReduce a dictionary of values across workers. We separately\n    reduce items that are already on the device and items on CPU for\n    better performance.\n\n    Args:\n        data (Mapping[str, Any]): dictionary of data to all-reduce, but\n            cannot be a nested dictionary\n        device (torch.device): device for the reduction\n        group: group of the collective\n    \"\"\"", "\n", "data_keys", "=", "list", "(", "data", ".", "keys", "(", ")", ")", "\n", "\n", "# We want to separately reduce items that are already on the", "\n", "# device and items on CPU for performance reasons.", "\n", "cpu_data", "=", "OrderedDict", "(", ")", "\n", "device_data", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "data_keys", ":", "\n", "        ", "t", "=", "data", "[", "k", "]", "\n", "if", "not", "torch", ".", "is_tensor", "(", "t", ")", ":", "\n", "            ", "cpu_data", "[", "k", "]", "=", "torch", ".", "tensor", "(", "t", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "", "elif", "t", ".", "device", ".", "type", "!=", "device", ".", "type", ":", "\n", "            ", "cpu_data", "[", "k", "]", "=", "t", ".", "to", "(", "dtype", "=", "torch", ".", "double", ")", "\n", "", "else", ":", "\n", "            ", "device_data", "[", "k", "]", "=", "t", ".", "to", "(", "dtype", "=", "torch", ".", "double", ")", "\n", "\n", "", "", "def", "_all_reduce_dict", "(", "data", ":", "OrderedDict", ")", ":", "\n", "        ", "if", "len", "(", "data", ")", "==", "0", ":", "\n", "            ", "return", "data", "\n", "", "buf", "=", "torch", ".", "cat", "(", "[", "t", ".", "view", "(", "-", "1", ")", "for", "t", "in", "data", ".", "values", "(", ")", "]", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "all_reduce", "(", "buf", ",", "group", "=", "group", ")", "\n", "split_buf", "=", "torch", ".", "split", "(", "buf", ",", "[", "t", ".", "numel", "(", ")", "for", "t", "in", "data", ".", "values", "(", ")", "]", ")", "\n", "reduced_data", "=", "[", "t", ".", "view_as", "(", "orig", ")", "for", "t", ",", "orig", "in", "zip", "(", "split_buf", ",", "data", ".", "values", "(", ")", ")", "]", "\n", "return", "OrderedDict", "(", "zip", "(", "data", ".", "keys", "(", ")", ",", "reduced_data", ")", ")", "\n", "\n", "", "cpu_data", "=", "_all_reduce_dict", "(", "cpu_data", ")", "\n", "device_data", "=", "_all_reduce_dict", "(", "device_data", ")", "\n", "\n", "def", "get_from_stack", "(", "key", ")", ":", "\n", "        ", "if", "key", "in", "cpu_data", ":", "\n", "            ", "return", "cpu_data", "[", "key", "]", "\n", "", "elif", "key", "in", "device_data", ":", "\n", "            ", "return", "device_data", "[", "key", "]", "\n", "", "raise", "KeyError", "\n", "\n", "", "return", "OrderedDict", "(", "[", "(", "key", ",", "get_from_stack", "(", "key", ")", ")", "for", "key", "in", "data_keys", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_tensors": [[647, 686], ["enumerate", "distributed_utils.get_rank", "distributed_utils._broadcast_object_slow", "distributed_utils._broadcast_object_slow", "torch.zeros.view().to", "out_tensors.append", "torch.distributed.get_backend", "torch.distributed.get_backend", "torch.device", "torch.device", "torch.device", "torch.device", "distributed_utils.broadcast", "torch.zeros", "torch.zeros", "distributed_utils.broadcast", "t.size", "tensors[].to", "torch.zeros.view", "meta[].numel"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._broadcast_object_slow", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._broadcast_object_slow", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "broadcast_tensors", "(", "\n", "tensors", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ",", "\n", "src_rank", ":", "int", ",", "\n", "group", ":", "object", ",", "\n", "dist_device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Broadcasts a list of tensors without other (non-src) ranks needing to know\n    the dtypes/shapes of the tensors.\n    \"\"\"", "\n", "if", "dist_device", "is", "None", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_backend", "(", "group", ")", "==", "\"nccl\"", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# share metadata first to simplify transfer", "\n", "", "", "is_src_rank", "=", "(", "get_rank", "(", "group", ")", "==", "src_rank", ")", "\n", "if", "is_src_rank", ":", "\n", "        ", "metadata", "=", "[", "\n", "{", "\"size\"", ":", "t", ".", "size", "(", ")", ",", "\"dtype\"", ":", "t", ".", "dtype", ",", "\"device\"", ":", "t", ".", "device", "}", "for", "t", "in", "tensors", "\n", "]", "\n", "metadata", "=", "_broadcast_object_slow", "(", "metadata", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "", "else", ":", "\n", "        ", "metadata", "=", "_broadcast_object_slow", "(", "None", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "\n", "", "out_tensors", "=", "[", "]", "\n", "for", "i", ",", "meta", "in", "enumerate", "(", "metadata", ")", ":", "\n", "        ", "if", "is_src_rank", ":", "\n", "            ", "tensor", "=", "tensors", "[", "i", "]", "\n", "broadcast", "(", "tensors", "[", "i", "]", ".", "to", "(", "dist_device", ")", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "torch", ".", "zeros", "(", "\n", "[", "meta", "[", "\"size\"", "]", ".", "numel", "(", ")", "]", ",", "dtype", "=", "meta", "[", "\"dtype\"", "]", ",", "device", "=", "dist_device", "\n", ")", "\n", "broadcast", "(", "tensor", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "", "tensor", "=", "tensor", ".", "view", "(", "meta", "[", "\"size\"", "]", ")", ".", "to", "(", "meta", "[", "\"device\"", "]", ")", "\n", "out_tensors", ".", "append", "(", "tensor", ")", "\n", "", "return", "out_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_object": [[688, 712], ["distributed_utils._put_tensors_in_obj", "distributed_utils.get_rank", "distributed_utils._split_tensors_from_obj", "distributed_utils._broadcast_object_slow", "distributed_utils.broadcast_tensors", "distributed_utils._broadcast_object_slow", "distributed_utils.broadcast_tensors", "torch.distributed.get_backend", "torch.distributed.get_backend", "torch.device", "torch.device", "torch.device", "torch.device"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._broadcast_object_slow", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_tensors", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._broadcast_object_slow", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_tensors", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device"], ["", "def", "broadcast_object", "(", "\n", "obj", ":", "Any", ",", "\n", "src_rank", ":", "int", ",", "\n", "group", ":", "object", ",", "\n", "dist_device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", "->", "Any", ":", "\n", "    ", "\"\"\"Broadcast an arbitrary Python object to other workers.\"\"\"", "\n", "if", "dist_device", "is", "None", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_backend", "(", "group", ")", "==", "\"nccl\"", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "", "if", "get_rank", "(", "group", ")", "==", "src_rank", ":", "\n", "# split the tensors from the non-tensors so we can broadcast them", "\n", "# directly, avoiding unnecessary serialization/deserialization", "\n", "        ", "tensors", "=", "[", "]", "\n", "obj", "=", "_split_tensors_from_obj", "(", "obj", ",", "tensors", ")", "\n", "obj", "=", "_broadcast_object_slow", "(", "obj", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "tensors", "=", "broadcast_tensors", "(", "tensors", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "", "else", ":", "\n", "        ", "obj", "=", "_broadcast_object_slow", "(", "None", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "tensors", "=", "broadcast_tensors", "(", "None", ",", "src_rank", ",", "group", ",", "dist_device", ")", "\n", "", "return", "_put_tensors_in_obj", "(", "obj", ",", "tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._broadcast_object_slow": [[714, 734], ["distributed_utils.get_rank", "io.BytesIO", "torch.save", "torch.save", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "distributed_utils.broadcast", "distributed_utils.broadcast", "torch.LongTensor().to", "torch.LongTensor().to", "distributed_utils.broadcast", "torch.ByteTensor().to", "torch.ByteTensor().to", "distributed_utils.broadcast", "io.BytesIO", "torch.load", "torch.load", "io.BytesIO.cpu().numpy", "torch.ByteTensor", "torch.ByteTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.ByteTensor", "torch.ByteTensor", "io.BytesIO.getbuffer", "int", "io.BytesIO.cpu", "len", "torch.LongTensor().to.item"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "_broadcast_object_slow", "(", "\n", "obj", ":", "Any", ",", "src_rank", ":", "int", ",", "group", ":", "object", ",", "dist_device", ":", "torch", ".", "device", ",", "\n", ")", "->", "Any", ":", "\n", "    ", "if", "get_rank", "(", "group", ")", "==", "src_rank", ":", "\n", "# Emit data", "\n", "        ", "buffer", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "obj", ",", "buffer", ")", "\n", "buffer", "=", "torch", ".", "ByteTensor", "(", "buffer", ".", "getbuffer", "(", ")", ")", ".", "to", "(", "dist_device", ")", "\n", "length", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "buffer", ")", "]", ")", ".", "to", "(", "dist_device", ")", "\n", "broadcast", "(", "length", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "broadcast", "(", "buffer", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "# Fetch from the source", "\n", "        ", "length", "=", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", ".", "to", "(", "dist_device", ")", "\n", "broadcast", "(", "length", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "buffer", "=", "torch", ".", "ByteTensor", "(", "int", "(", "length", ".", "item", "(", ")", ")", ")", ".", "to", "(", "dist_device", ")", "\n", "broadcast", "(", "buffer", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "buffer", "=", "io", ".", "BytesIO", "(", "buffer", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "obj", "=", "torch", ".", "load", "(", "buffer", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj": [[741, 756], ["torch.is_tensor", "torch.is_tensor", "distributed_utils._TensorPlaceholder", "tensors.append", "isinstance", "isinstance", "len", "distributed_utils._split_tensors_from_obj", "isinstance", "obj.items", "distributed_utils._split_tensors_from_obj", "tuple", "isinstance", "distributed_utils._split_tensors_from_obj", "distributed_utils._split_tensors_from_obj"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._split_tensors_from_obj"], ["", "def", "_split_tensors_from_obj", "(", "obj", ":", "Any", ",", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "Any", ":", "\n", "    ", "if", "torch", ".", "is_tensor", "(", "obj", ")", ":", "\n", "        ", "placeholder", "=", "_TensorPlaceholder", "(", "index", "=", "len", "(", "tensors", ")", ")", "\n", "tensors", ".", "append", "(", "obj", ")", "\n", "return", "placeholder", "\n", "", "elif", "isinstance", "(", "obj", ",", "dict", ")", ":", "\n", "        ", "return", "{", "k", ":", "_split_tensors_from_obj", "(", "v", ",", "tensors", ")", "for", "k", ",", "v", "in", "obj", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "obj", ",", "list", ")", ":", "\n", "        ", "return", "[", "_split_tensors_from_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", "]", "\n", "", "elif", "isinstance", "(", "obj", ",", "tuple", ")", ":", "\n", "        ", "return", "tuple", "(", "_split_tensors_from_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "set", ")", ":", "\n", "        ", "return", "{", "_split_tensors_from_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", "}", "\n", "", "else", ":", "\n", "        ", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj": [[758, 771], ["isinstance", "isinstance", "isinstance", "distributed_utils._put_tensors_in_obj", "isinstance", "obj.items", "distributed_utils._put_tensors_in_obj", "tuple", "isinstance", "distributed_utils._put_tensors_in_obj", "distributed_utils._put_tensors_in_obj"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils._put_tensors_in_obj"], ["", "", "def", "_put_tensors_in_obj", "(", "obj", ":", "Any", ",", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "Any", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "_TensorPlaceholder", ")", ":", "\n", "        ", "return", "tensors", "[", "obj", ".", "index", "]", "\n", "", "elif", "isinstance", "(", "obj", ",", "dict", ")", ":", "\n", "        ", "return", "{", "k", ":", "_put_tensors_in_obj", "(", "v", ",", "tensors", ")", "for", "k", ",", "v", "in", "obj", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "obj", ",", "list", ")", ":", "\n", "        ", "return", "[", "_put_tensors_in_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", "]", "\n", "", "elif", "isinstance", "(", "obj", ",", "tuple", ")", ":", "\n", "        ", "return", "tuple", "(", "_put_tensors_in_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "set", ")", ":", "\n", "        ", "return", "{", "_put_tensors_in_obj", "(", "v", ",", "tensors", ")", "for", "v", "in", "obj", "}", "\n", "", "else", ":", "\n", "        ", "return", "obj", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__init__": [[43, 66], ["torch.nn.Module.__init__", "distributed_utils.get_world_size", "min", "collections.OrderedDict", "legacy_distributed_data_parallel.LegacyDistributedDataParallel.module.parameters", "list", "sum", "collections.OrderedDict.values", "collections.OrderedDict.get", "p.numel", "module.parameters"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size"], ["def", "__init__", "(", "self", ",", "module", ",", "process_group", ",", "buffer_size", "=", "2", "**", "28", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "process_group", "=", "process_group", "\n", "self", ".", "world_size", "=", "distributed_utils", ".", "get_world_size", "(", "self", ".", "process_group", ")", "\n", "\n", "# Never use a bigger buffer than the number of model params", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", ")", ")", "\n", "self", ".", "buffer", "=", "None", "\n", "\n", "# We can also forcibly accumulate grads locally and only do the", "\n", "# all-reduce at some later time", "\n", "self", ".", "accumulate_grads", "=", "False", "\n", "\n", "# make per-device lists of parameters", "\n", "paramlists", "=", "OrderedDict", "(", ")", "\n", "for", "param", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "device", "=", "param", ".", "device", "\n", "if", "paramlists", ".", "get", "(", "device", ")", "is", "None", ":", "\n", "                ", "paramlists", "[", "device", "]", "=", "[", "]", "\n", "", "paramlists", "[", "device", "]", "+=", "[", "param", "]", "\n", "", "self", ".", "per_device_params", "=", "list", "(", "paramlists", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__getstate__": [[67, 70], ["copy.copy"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "attrs", "=", "copy", ".", "copy", "(", "self", ".", "__dict__", ")", "\n", "return", "attrs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__setstate__": [[71, 73], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync": [[74, 81], ["None"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "no_sync", "(", "self", ")", ":", "\n", "        ", "\"\"\"A context manager to disable gradient synchronization.\"\"\"", "\n", "old_accumulate_grads", "=", "self", ".", "accumulate_grads", "\n", "self", ".", "accumulate_grads", "=", "True", "\n", "yield", "\n", "self", ".", "accumulate_grads", "=", "old_accumulate_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.forward": [[82, 84], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce_grads": [[85, 170], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce_grads.reduction_fn"], "methods", ["None"], ["", "def", "all_reduce_grads", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function must be called explicitly after backward to reduce\n        gradients. There is no automatic hook like c10d.\n        \"\"\"", "\n", "\n", "def", "all_reduce_params", "(", "params", ")", ":", "\n", "            ", "buffer", "=", "self", ".", "buffer", "\n", "nonzero_buffer", "=", "False", "\n", "if", "len", "(", "params", ")", ">", "1", ":", "\n", "                ", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                    ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "copy_", "(", "p", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "nonzero_buffer", "=", "True", "\n", "", "else", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "zero_", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "", "", "else", ":", "\n", "# we only have a single grad to all-reduce", "\n", "                ", "p", "=", "params", "[", "0", "]", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "buffer", "=", "p", ".", "grad", ".", "data", "\n", "nonzero_buffer", "=", "True", "\n", "", "elif", "p", ".", "numel", "(", ")", "<=", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                    ", "buffer", "=", "buffer", "[", ":", "p", ".", "numel", "(", ")", "]", "\n", "buffer", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "buffer", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "\n", "", "", "if", "nonzero_buffer", ":", "\n", "                ", "buffer", ".", "div_", "(", "self", ".", "world_size", ")", "\n", "\n", "", "distributed_utils", ".", "all_reduce", "(", "buffer", ",", "self", ".", "process_group", ")", "\n", "\n", "# copy all-reduced grads back into their original place", "\n", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", ".", "grad", ".", "data", ".", "copy_", "(", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "grad", "=", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ".", "clone", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "\n", "", "", "def", "reduction_fn", "(", ")", ":", "\n", "# This function only needs to be called once", "\n", "            ", "if", "self", ".", "accumulate_grads", ":", "\n", "                ", "return", "\n", "\n", "", "if", "self", ".", "buffer", "is", "None", ":", "\n", "                ", "self", ".", "buffer", "=", "next", "(", "self", ".", "module", ".", "parameters", "(", ")", ")", ".", "new", "(", "self", ".", "buffer_size", ")", "\n", "\n", "", "for", "params", "in", "self", ".", "per_device_params", ":", "\n", "# All-reduce the gradients in buckets", "\n", "                ", "offset", "=", "0", "\n", "buffered_params", "=", "[", "]", "\n", "for", "param", "in", "params", ":", "\n", "                    ", "if", "not", "param", ".", "requires_grad", ":", "\n", "                        ", "continue", "\n", "", "if", "param", ".", "grad", "is", "None", ":", "\n", "                        ", "param", ".", "grad", "=", "torch", ".", "zeros_like", "(", "param", ")", "\n", "", "if", "param", ".", "grad", ".", "requires_grad", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\n", "\"DistributedDataParallel only works \"", "\n", "\"with gradients that don't require \"", "\n", "\"grad\"", "\n", ")", "\n", "", "sz", "=", "param", ".", "numel", "(", ")", "\n", "if", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "# all-reduce big params directly", "\n", "                        ", "all_reduce_params", "(", "[", "param", "]", ")", "\n", "", "else", ":", "\n", "                        ", "if", "offset", "+", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                            ", "all_reduce_params", "(", "buffered_params", ")", "\n", "offset", "=", "0", "\n", "buffered_params", ".", "clear", "(", ")", "\n", "", "buffered_params", ".", "append", "(", "param", ")", "\n", "offset", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffered_params", ")", ">", "0", ":", "\n", "                    ", "all_reduce_params", "(", "buffered_params", ")", "\n", "\n", "", "", "", "reduction_fn", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintState.__init__": [[37, 39], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.__init__": [[116, 129], ["int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "token", ":", "int", "=", "None", ",", "parent", "=", "None", ")", ":", "\n", "# The token associate with this node (None for the root)", "\n", "        ", "self", ".", "token", "=", "int", "(", "token", ")", "if", "token", "is", "not", "None", "else", "None", "\n", "# The parent (None at the root)", "\n", "self", ".", "parent", "=", "parent", "\n", "# Whether this node is a completed constraint", "\n", "self", ".", "terminal", "=", "0", "\n", "# List of child nodes", "\n", "self", ".", "children", "=", "{", "}", "\n", "\n", "# The cumulative number of constraints from this point in the", "\n", "# trie forward", "\n", "self", ".", "num_constraints", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.id": [[130, 133], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.__str__": [[134, 137], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "term", "=", "self", ".", "terminal", "!=", "0", "\n", "return", "f\"[{self.token}].{term}#{self.num_constraints}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.__getitem__": [[138, 140], ["token_generation_constraints.ConstraintNode.children.get"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "children", ".", "get", "(", "key", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.next_tokens": [[141, 144], ["set", "token_generation_constraints.ConstraintNode.children.keys"], "methods", ["None"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"The set of child labels.\"\"\"", "\n", "return", "set", "(", "self", ".", "children", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.create": [[145, 152], ["token_generation_constraints.ConstraintNode", "token_generation_constraints.ConstraintNode.add_sequence"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.add_sequence"], ["", "@", "staticmethod", "\n", "def", "create", "(", "constraints", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "root", "=", "ConstraintNode", "(", ")", "\n", "for", "sequence", "in", "constraints", ":", "\n", "            ", "root", ".", "add_sequence", "(", "sequence", ")", "\n", "\n", "", "return", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.print_graph": [[153, 163], ["len", "str", "node.children.values", "token_generation_constraints.ConstraintNode.print_graph"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.print_graph"], ["", "@", "staticmethod", "\n", "def", "print_graph", "(", "node", ":", "\"ConstraintNode\"", ")", ":", "\n", "        ", "if", "len", "(", "node", ".", "children", ")", "==", "0", ":", "\n", "            ", "return", "str", "(", "node", ")", "\n", "", "else", ":", "\n", "            ", "s", "=", "f\"({node}\"", "\n", "for", "child", "in", "node", ".", "children", ".", "values", "(", ")", ":", "\n", "                ", "s", "+=", "\" \"", "+", "ConstraintNode", ".", "print_graph", "(", "child", ")", "\n", "", "s", "+=", "\")\"", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.token_counts": [[164, 176], ["collections.Counter", "list", "token_generation_constraints.ConstraintNode.children.values", "len", "list.pop", "list", "list.pop.children.values"], "methods", ["None"], ["", "", "def", "token_counts", "(", "self", ")", "->", "Counter", ":", "\n", "        ", "\"\"\"Returns a counter of the number of times each token is used\n        in a constraint.\n        \"\"\"", "\n", "token_counts", "=", "Counter", "(", ")", "\n", "kids", "=", "list", "(", "self", ".", "children", ".", "values", "(", ")", ")", "\n", "while", "len", "(", "kids", ")", ">", "0", ":", "\n", "            ", "kid", "=", "kids", ".", "pop", "(", ")", "\n", "token_counts", "[", "kid", ".", "id", "]", "+=", "kid", ".", "num_constraints", "\n", "kids", "+=", "list", "(", "kid", ".", "children", ".", "values", "(", ")", ")", "\n", "\n", "", "return", "token_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.tokens": [[177, 180], ["set", "token_generation_constraints.ConstraintNode.token_counts().keys", "token_generation_constraints.ConstraintNode.token_counts"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "def", "tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the set of tokens in constraints.\"\"\"", "\n", "return", "set", "(", "self", ".", "token_counts", "(", ")", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.add_sequence": [[181, 200], ["int", "len", "token_generation_constraints.ConstraintNode", "len", "node.add_sequence"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintNode.add_sequence"], ["", "def", "add_sequence", "(", "self", ",", "sequence", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "\"\"\"Adds a constraint, represented as a list of integers, to\n        the trie.\"\"\"", "\n", "assert", "len", "(", "sequence", ")", ">", "0", "\n", "\n", "token", "=", "int", "(", "sequence", "[", "0", "]", ")", "\n", "if", "token", "not", "in", "self", ".", "children", ":", "\n", "            ", "self", ".", "children", "[", "token", "]", "=", "ConstraintNode", "(", "token", ",", "parent", "=", "self", ")", "\n", "\n", "", "node", "=", "self", ".", "children", "[", "token", "]", "\n", "if", "len", "(", "sequence", ")", "==", "1", ":", "\n", "            ", "node", ".", "terminal", "+=", "1", "\n", "node", ".", "num_constraints", "+=", "1", "\n", "parent", "=", "node", ".", "parent", "\n", "while", "parent", "is", "not", "None", ":", "\n", "                ", "parent", ".", "num_constraints", "+=", "1", "\n", "parent", "=", "parent", ".", "parent", "\n", "", "", "else", ":", "\n", "            ", "node", ".", "add_sequence", "(", "sequence", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.__init__": [[208, 228], ["collections.Counter", "collections.Counter", "token_generation_constraints.UnorderedConstraintState.root.tokens", "collections.Counter", "collections.Counter"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.tokens"], ["def", "__init__", "(", "self", ",", "node", ":", "ConstraintNode", ",", "copy_from", ":", "\"ConstraintState\"", "=", "None", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "\n", "if", "copy_from", "is", "None", ":", "\n", "# The root node", "\n", "            ", "self", ".", "root", "=", "node", "\n", "# The set of states in the graph that have been completed", "\n", "self", ".", "completed", "=", "Counter", "(", ")", "\n", "# The...", "\n", "self", ".", "generated", "=", "Counter", "(", ")", "\n", "# The list of tokens we need to generate", "\n", "self", ".", "needed_tokens", "=", "self", ".", "root", ".", "tokens", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "completed", "=", "Counter", "(", "copy_from", ".", "completed", ")", "\n", "self", ".", "generated", "=", "Counter", "(", "copy_from", ".", "generated", ")", "\n", "self", ".", "root", "=", "copy_from", ".", "root", "\n", "\n", "# Mark the node as generated", "\n", "", "if", "self", ".", "node", "!=", "self", ".", "root", ":", "\n", "            ", "self", ".", "generated", "[", "node", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.create": [[229, 234], ["token_generation_constraints.unpack_constraints", "token_generation_constraints.ConstraintNode.create", "token_generation_constraints.UnorderedConstraintState"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.unpack_constraints", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create"], ["", "", "@", "staticmethod", "\n", "def", "create", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "constraint_list", "=", "unpack_constraints", "(", "constraint_tensor", ")", "\n", "constraint_trie_root", "=", "ConstraintNode", ".", "create", "(", "constraint_list", ")", "\n", "return", "UnorderedConstraintState", "(", "constraint_trie_root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.__str__": [[235, 238], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "gen_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "node", ")", "for", "node", "in", "self", ".", "generated", "]", ")", "\n", "return", "f\"{self.name}/{self.bank}({gen_str})x{self.num_completed}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.__copy__": [[239, 242], ["token_generation_constraints.UnorderedConstraintState"], "methods", ["None"], ["", "def", "__copy__", "(", "self", ")", ":", "\n", "        ", "copied_state", "=", "UnorderedConstraintState", "(", "self", ".", "node", ",", "copy_from", "=", "self", ")", "\n", "return", "copied_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.copy": [[243, 245], ["token_generation_constraints.UnorderedConstraintState.__copy__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.__copy__"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__copy__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.name": [[246, 252], ["str"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "node", ".", "id", "is", "None", ":", "\n", "            ", "return", "\"ROOT\"", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "self", ".", "node", ".", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.is_root": [[253, 256], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "is_root", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "node", "==", "self", ".", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.bank": [[257, 260], ["sum", "token_generation_constraints.UnorderedConstraintState.generated.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "bank", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "generated", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.num_completed": [[261, 270], ["sum", "token_generation_constraints.UnorderedConstraintState.completed.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_completed", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of constraints (not constraint tokens) that are completed.\n        In addition to the already-completed states, we need to account for the\n        current state, which might get marked as completed when another token\n        is generated.\n        \"\"\"", "\n", "in_final", "=", "self", ".", "node", ".", "terminal", "and", "self", ".", "completed", "[", "self", ".", "node", "]", "<", "self", ".", "node", ".", "terminal", "\n", "return", "sum", "(", "self", ".", "completed", ".", "values", "(", ")", ")", "+", "in_final", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.finished": [[271, 274], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "finished", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "num_constraints", "-", "self", ".", "num_completed", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.token_counts": [[275, 278], ["token_generation_constraints.UnorderedConstraintState.root.token_counts"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "@", "property", "\n", "def", "token_counts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "token_counts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.tokens": [[279, 282], ["token_generation_constraints.UnorderedConstraintState.root.tokens"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.tokens"], ["", "@", "property", "\n", "def", "tokens", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "tokens", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.num_constraint_tokens": [[283, 286], ["sum", "token_generation_constraints.UnorderedConstraintState.token_counts.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_constraint_tokens", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "token_counts", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.next_tokens": [[287, 297], ["token_generation_constraints.UnorderedConstraintState.root.next_tokens().union", "token_generation_constraints.UnorderedConstraintState.root.next_tokens", "token_generation_constraints.UnorderedConstraintState.node.next_tokens", "token_generation_constraints.UnorderedConstraintState.root.next_tokens"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the list of tokens that could come next.\n        These are (a) all tokens extending the root state and, for\n        non-root states, additionally all tokens extending the current\n        state.\"\"\"", "\n", "\n", "if", "self", ".", "node", "!=", "self", ".", "root", ":", "\n", "            ", "return", "self", ".", "root", ".", "next_tokens", "(", ")", ".", "union", "(", "self", ".", "node", ".", "next_tokens", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "root", ".", "next_tokens", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.UnorderedConstraintState.advance": [[298, 359], ["int", "token_generation_constraints.UnorderedConstraintState", "token_generation_constraints.UnorderedConstraintState.advance.rewind"], "methods", ["None"], ["", "", "def", "advance", "(", "self", ",", "token", ":", "int", ")", ":", "\n", "        ", "\"\"\"Reads in a token and advances the state. Here's how it works.\n\n        We can advance to the next state if:\n        - there is a matching child\n        - its path isn't blocked\n\n        A path is blocked when all constraints that are descendants of\n        that node have already been generated, in the current state.\n\n        If we are not able to advance from the current state, we \"fall\n        off the graph\" and return to the root state. There, we again\n        try to advance, checking the same criteria.\n\n        In any case, when falling off the graph, we need to do some\n        bookkeeping. We:\n        - check whether any constraints were met (all prefixes of\n          current state)\n        - if one is found, mark it as completed\n        - adjust visited nodes accordingly\n        \"\"\"", "\n", "token", "=", "int", "(", "token", ")", "\n", "\n", "next_state", "=", "None", "\n", "child", "=", "self", ".", "node", "[", "token", "]", "\n", "if", "child", "is", "not", "None", "and", "self", ".", "generated", "[", "child", "]", "<", "child", ".", "num_constraints", ":", "\n", "            ", "next_state", "=", "UnorderedConstraintState", "(", "child", ",", "copy_from", "=", "self", ")", "\n", "\n", "", "def", "rewind", "(", ")", ":", "\n", "            ", "\"\"\"If we're mid-trie and an \"illegal\" token is chosen next, we need\n            to reset our state to the root state. However, along the way, we need\n            to check whether a prefix of the current trie state represents a state\n            we could mark as completed.\n            \"\"\"", "\n", "node", "=", "self", ".", "node", "\n", "while", "node", "!=", "self", ".", "root", ":", "\n", "                ", "if", "node", ".", "terminal", "and", "self", ".", "completed", "[", "node", "]", "<", "node", ".", "terminal", ":", "\n", "                    ", "next_state", ".", "completed", "[", "node", "]", "+=", "1", "\n", "return", "\n", "\n", "", "next_state", ".", "generated", "[", "node", "]", "-=", "1", "\n", "node", "=", "node", ".", "parent", "\n", "\n", "# Fall off the graph, check the root", "\n", "", "", "if", "next_state", "is", "None", "and", "token", "in", "self", ".", "root", ".", "next_tokens", "(", ")", ":", "\n", "            ", "child", "=", "self", ".", "root", "[", "token", "]", "\n", "# We can only traverse this edge if it's not saturated", "\n", "if", "self", ".", "generated", "[", "child", "]", "<", "child", ".", "num_constraints", ":", "\n", "                ", "next_state", "=", "UnorderedConstraintState", "(", "child", ",", "copy_from", "=", "self", ")", "\n", "", "else", ":", "\n", "                ", "next_state", "=", "UnorderedConstraintState", "(", "self", ".", "root", ",", "copy_from", "=", "self", ")", "\n", "\n", "# Rewind", "\n", "", "rewind", "(", ")", "\n", "\n", "", "elif", "next_state", "is", "None", ":", "\n", "            ", "next_state", "=", "UnorderedConstraintState", "(", "self", ".", "root", ",", "copy_from", "=", "self", ")", "\n", "# Rewind", "\n", "rewind", "(", ")", "\n", "\n", "", "return", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintSequence.__init__": [[362, 376], ["set", "len", "token_generation_constraints.ConstraintSequence.tokens.add", "range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sequences", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"Represents a set of possibly multitoken constraints by\n        concatenating them and internally recording the end points.\n        \"\"\"", "\n", "self", ".", "sequences", "=", "[", "]", "\n", "self", ".", "endpoints", "=", "[", "]", "\n", "self", ".", "num_tokens", "=", "0", "\n", "self", ".", "tokens", "=", "set", "(", ")", "\n", "for", "sequence", "in", "sequences", ":", "\n", "            ", "for", "token", "in", "sequence", ":", "\n", "                ", "self", ".", "tokens", ".", "add", "(", "token", ")", "\n", "", "self", ".", "num_tokens", "+=", "len", "(", "sequence", ")", "\n", "self", ".", "endpoints", "+=", "[", "False", "for", "x", "in", "range", "(", "len", "(", "sequence", ")", "-", "1", ")", "]", "+", "[", "True", "]", "\n", "self", ".", "sequences", "+=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintSequence.__getitem__": [[377, 379], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "key", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "sequences", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintSequence.__len__": [[380, 382], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.ConstraintSequence.__str__": [[383, 385], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.__init__": [[392, 395], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sequence", ":", "ConstraintSequence", ",", "state", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "sequence", "=", "sequence", "\n", "self", ".", "state", "=", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create": [[396, 400], ["token_generation_constraints.unpack_constraints", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.ConstraintSequence"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.unpack_constraints"], ["", "@", "staticmethod", "\n", "def", "create", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "constraint_list", "=", "unpack_constraints", "(", "constraint_tensor", ")", "\n", "return", "OrderedConstraintState", "(", "ConstraintSequence", "(", "constraint_list", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.__str__": [[401, 403], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.state}/{self.bank}x{self.num_completed}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.__copy__": [[404, 406], ["token_generation_constraints.OrderedConstraintState"], "methods", ["None"], ["", "def", "__copy__", "(", "self", ")", ":", "\n", "        ", "return", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.copy": [[407, 409], ["token_generation_constraints.OrderedConstraintState.__copy__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.__copy__"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__copy__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.num_completed": [[410, 418], ["len", "list", "filter"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_completed", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "state", "==", "-", "1", ":", "\n", "            ", "return", "0", "\n", "", "count", "=", "len", "(", "\n", "list", "(", "filter", "(", "lambda", "x", ":", "x", ",", "self", ".", "sequence", ".", "endpoints", "[", "0", ":", "self", ".", "state", "+", "1", "]", ")", ")", "\n", ")", "\n", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.is_root": [[419, 422], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_root", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "==", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.name": [[423, 429], ["str"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "state", "==", "-", "1", ":", "\n", "            ", "return", "\"ROOT\"", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "self", ".", "sequence", "[", "self", ".", "state", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.bank": [[430, 433], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "bank", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "state", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.finished": [[434, 437], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "finished", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "+", "1", "==", "len", "(", "self", ".", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.token_counts": [[438, 441], ["token_generation_constraints.OrderedConstraintState.sequence.token_counts"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "@", "property", "\n", "def", "token_counts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sequence", ".", "token_counts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.tokens": [[442, 445], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tokens", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sequence", ".", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.num_constraint_tokens": [[446, 449], ["sum", "token_generation_constraints.OrderedConstraintState.token_counts.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_constraint_tokens", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "token_counts", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens": [[450, 462], ["set", "set.add", "set.add"], "methods", ["None"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the list of tokens that could come next.\n        These are (a) all tokens extending the root state and, for\n        non-root states, additionally all tokens extending the current\n        state.\"\"\"", "\n", "\n", "tokens", "=", "set", "(", ")", "\n", "if", "self", ".", "state", ">", "0", ":", "\n", "            ", "tokens", ".", "add", "(", "self", ".", "sequence", "[", "0", "]", ")", "\n", "", "if", "not", "self", ".", "finished", ":", "\n", "            ", "tokens", ".", "add", "(", "self", ".", "sequence", "[", "self", ".", "state", "+", "1", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.advance": [[463, 507], ["int", "token_generation_constraints.OrderedConstraintState.copy", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.OrderedConstraintState.copy", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.OrderedConstraintState"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy"], ["", "def", "advance", "(", "self", ",", "token", ":", "int", ")", ":", "\n", "        ", "\"\"\"Reads in a token and advances the state. Here's how it works.\n\n        We can advance to the next state if:\n        - there is a matching child\n        - its path isn't blocked\n\n        A path is blocked when all constraints that are descendants of\n        that node have already been generated, in the current state.\n\n        If we are not able to advance from the current state, we \"fall\n        off the graph\" and return to the root state. There, we again\n        try to advance, checking the same criteria.\n\n        In any case, when falling off the graph, we need to do some\n        bookkeeping. We:\n        - check whether any constraints were met (all prefixes of\n          current state)\n        - if one is found, mark it as completed\n        - adjust visited nodes accordingly\n        \"\"\"", "\n", "token", "=", "int", "(", "token", ")", "\n", "# print(f\"{self} ADVANCE({token}) {self.sequence} -> \", end=\"\")", "\n", "\n", "if", "self", ".", "finished", ":", "\n", "# Accept anything", "\n", "            ", "next_state", "=", "self", ".", "copy", "(", ")", "\n", "\n", "", "elif", "self", ".", "sequence", "[", "self", ".", "state", "+", "1", "]", "==", "token", ":", "\n", "# Advance to the next token", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "self", ".", "state", "+", "1", ")", "\n", "\n", "", "elif", "self", ".", "sequence", ".", "endpoints", "[", "self", ".", "state", "]", ":", "\n", "# Accept anything between constraints (*)", "\n", "            ", "next_state", "=", "self", ".", "copy", "(", ")", "\n", "\n", "", "elif", "token", "==", "self", ".", "sequence", "[", "0", "]", ":", "\n", "# Start over having generated the first token", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "0", ")", "\n", "", "else", ":", "\n", "# Start over from the root", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "-", "1", ")", "\n", "\n", "", "return", "next_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.pack_constraints": [[41, 92], ["len", "torch.zeros().long", "enumerate", "torch.zeros().long.long", "len", "len", "enumerate", "max", "torch.zeros", "constraint.size", "len", "sum", "c.size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "pack_constraints", "(", "batch_constraints", ":", "List", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Takes a list of list of constraints in tensor form (a list of\n    tensor constraints for each sentence) and transforms it into a\n    packed Tensor. For example, here is a batch of size 3 with 3, 0,\n    and 1 constraints:\n\n        [ [ [3 1 2], [3], [4 5 6 7], ]\n          [],\n          [ [1 8 9 10 1 4 11 12], ]\n        ]\n\n    Its corresponding packed structure is:\n\n        [ [ 3  3  1  2  0  3  0  4  5  6  7  0],\n          [ 0  0  0  0  0  0  0  0  0  0  0  0],\n          [ 1  1  8  9 10  1  4 11 12  0  0  0] ]\n\n    The packed tensor has shape (batch size, maxlen), where\n    maxlen is defined below. Each row contains concatenated\n    constraint tokens for that sentence, with 0 appended after\n    each constraint. The first item in each row is the number\n    of constraints for that sentence. So maxlen is the maximum\n    of\n\n    (number of constraints) + (sum length of constraints) + 1.\n\n    across all sentences in the batch.\n    \"\"\"", "\n", "# The maximum word length of concatenated constraints for any sentence", "\n", "max_constraints_len", "=", "1", "\n", "for", "sentence_constraints", "in", "batch_constraints", ":", "\n", "        ", "if", "len", "(", "sentence_constraints", ")", ":", "\n", "# number of constraints, plus sum of constrain lens, plus a zero after each", "\n", "            ", "constraints_len", "=", "(", "\n", "1", "\n", "+", "sum", "(", "[", "c", ".", "size", "(", "0", ")", "for", "c", "in", "sentence_constraints", "]", ")", "\n", "+", "len", "(", "sentence_constraints", ")", "\n", ")", "\n", "max_constraints_len", "=", "max", "(", "max_constraints_len", ",", "constraints_len", ")", "\n", "\n", "", "", "batch_size", "=", "len", "(", "batch_constraints", ")", "\n", "constraints_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_constraints_len", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sentence_constraints", "in", "enumerate", "(", "batch_constraints", ")", ":", "\n", "        ", "constraints_tensor", "[", "i", ",", "0", "]", "=", "len", "(", "sentence_constraints", ")", "\n", "offset", "=", "1", "\n", "for", "j", ",", "constraint", "in", "enumerate", "(", "sentence_constraints", ")", ":", "\n", "            ", "this_len", "=", "constraint", ".", "size", "(", "0", ")", "\n", "constraints_tensor", "[", "i", ",", "offset", ":", "offset", "+", "this_len", "]", "=", "constraint", "\n", "offset", "+=", "this_len", "+", "1", "\n", "\n", "", "", "return", "constraints_tensor", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.unpack_constraints": [[94, 109], ["constraint_tensor.tolist", "range", "constraint_tensor.tolist.index", "constraint_list.append"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["", "def", "unpack_constraints", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Transforms *one row* of a packed constraint tensor (e.g., for one\n    sentence in the batch) into a list of constraint tensors.\n    \"\"\"", "\n", "constraint_list", "=", "[", "]", "\n", "num_constraints", "=", "constraint_tensor", "[", "0", "]", "\n", "constraints", "=", "constraint_tensor", ".", "tolist", "(", ")", "\n", "offset", "=", "1", "\n", "for", "i", "in", "range", "(", "num_constraints", ")", ":", "\n", "        ", "where", "=", "constraints", ".", "index", "(", "0", ",", "offset", ")", "\n", "constraint_list", ".", "append", "(", "constraint_tensor", "[", "offset", ":", "where", "]", ")", "\n", "offset", "=", "where", "+", "1", "\n", "\n", "", "return", "constraint_list", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.__init__": [[19, 30], ["list", "nan_detector.NanDetector.reset", "model.named_modules", "model.named_parameters", "nan_detector.NanDetector.add_hooks"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.add_hooks"], ["def", "__init__", "(", "self", ",", "model", ",", "forward", "=", "True", ",", "backward", "=", "True", ")", ":", "\n", "        ", "self", ".", "bhooks", "=", "[", "]", "\n", "self", ".", "fhooks", "=", "[", "]", "\n", "self", ".", "forward", "=", "forward", "\n", "self", ".", "backward", "=", "backward", "\n", "self", ".", "named_parameters", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "for", "name", ",", "mod", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "mod", ".", "__module_name", "=", "name", "\n", "self", ".", "add_hooks", "(", "mod", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.__enter__": [[31, 33], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.__exit__": [[34, 50], ["nan_detector.NanDetector.close", "len", "logger.info", "logger.info", "logger.info", "torch.norm", "torch.norm.item", "torch.isnan().any", "torch.isinf().any", "torch.isnan", "torch.isinf"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", ":", "\n", "# Dump out all model gnorms to enable better debugging", "\n", "        ", "norm", "=", "{", "}", "\n", "gradients", "=", "{", "}", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "grad_norm", "=", "torch", ".", "norm", "(", "param", ".", "grad", ".", "data", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "norm", "[", "name", "]", "=", "grad_norm", ".", "item", "(", ")", "\n", "if", "torch", ".", "isnan", "(", "grad_norm", ")", ".", "any", "(", ")", "or", "torch", ".", "isinf", "(", "grad_norm", ")", ".", "any", "(", ")", ":", "\n", "                    ", "gradients", "[", "name", "]", "=", "param", ".", "grad", ".", "data", "\n", "", "", "", "if", "len", "(", "gradients", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Detected nan/inf grad norm, dumping norms...\"", ")", "\n", "logger", ".", "info", "(", "f\"norms: {norm}\"", ")", "\n", "logger", ".", "info", "(", "f\"gradients: {gradients}\"", ")", "\n", "\n", "", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.add_hooks": [[51, 56], ["nan_detector.NanDetector.fhooks.append", "nan_detector.NanDetector.bhooks.append", "module.register_forward_hook", "module.register_backward_hook"], "methods", ["None"], ["", "def", "add_hooks", "(", "self", ",", "module", ")", ":", "\n", "        ", "if", "self", ".", "forward", ":", "\n", "            ", "self", ".", "fhooks", ".", "append", "(", "module", ".", "register_forward_hook", "(", "self", ".", "fhook_fn", ")", ")", "\n", "", "if", "self", ".", "backward", ":", "\n", "            ", "self", ".", "bhooks", ".", "append", "(", "module", ".", "register_backward_hook", "(", "self", ".", "bhook_fn", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.reset": [[57, 60], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "has_printed_f", "=", "False", "\n", "self", ".", "has_printed_b", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._detect": [[61, 76], ["torch.is_floating_point", "tensor.numel", "torch.no_grad", "torch.isnan().any", "torch.isinf().any", "torch.isnan", "torch.isinf"], "methods", ["None"], ["", "def", "_detect", "(", "self", ",", "tensor", ",", "name", ",", "backward", ")", ":", "\n", "        ", "err", "=", "None", "\n", "if", "(", "\n", "torch", ".", "is_floating_point", "(", "tensor", ")", "\n", "# single value tensors (like the loss) will not provide much info", "\n", "and", "tensor", ".", "numel", "(", ")", ">=", "2", "\n", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "torch", ".", "isnan", "(", "tensor", ")", ".", "any", "(", ")", ":", "\n", "                    ", "err", "=", "\"NaN\"", "\n", "", "elif", "torch", ".", "isinf", "(", "tensor", ")", ".", "any", "(", ")", ":", "\n", "                    ", "err", "=", "\"Inf\"", "\n", "", "", "", "if", "err", "is", "not", "None", ":", "\n", "            ", "err", "=", "f\"{err} detected in output of {name}, shape: {tensor.shape}, {'backward' if backward else 'forward'}\"", "\n", "", "return", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply": [[77, 97], ["torch.is_tensor", "nan_detector.NanDetector._detect", "isinstance", "isinstance", "logger.warning", "setattr", "x.values", "len", "torch.is_tensor", "nan_detector.NanDetector._apply", "isinstance", "isinstance", "nan_detector.NanDetector._apply", "inp.max().item", "inp.min().item", "inp.max", "inp.min"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._detect", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "_apply", "(", "self", ",", "module", ",", "inp", ",", "x", ",", "backward", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "if", "isinstance", "(", "inp", ",", "tuple", ")", "and", "len", "(", "inp", ")", ">", "0", ":", "\n", "                ", "inp", "=", "inp", "[", "0", "]", "\n", "", "err", "=", "self", ".", "_detect", "(", "x", ",", "module", ".", "__module_name", ",", "backward", ")", "\n", "if", "err", "is", "not", "None", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "inp", ")", "and", "not", "backward", ":", "\n", "                    ", "err", "+=", "(", "\n", "f\" input max: {inp.max().item()}, input min: {inp.min().item()}\"", "\n", ")", "\n", "\n", "", "has_printed_attr", "=", "\"has_printed_b\"", "if", "backward", "else", "\"has_printed_f\"", "\n", "logger", ".", "warning", "(", "err", ")", "\n", "setattr", "(", "self", ",", "has_printed_attr", ",", "True", ")", "\n", "", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "for", "v", "in", "x", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "v", ",", "backward", ")", "\n", "", "", "elif", "isinstance", "(", "x", ",", "list", ")", "or", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "for", "v", "in", "x", ":", "\n", "                ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "v", ",", "backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.fhook_fn": [[98, 101], ["nan_detector.NanDetector._apply"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply"], ["", "", "", "def", "fhook_fn", "(", "self", ",", "module", ",", "inp", ",", "output", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_printed_f", ":", "\n", "            ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "output", ",", "backward", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.bhook_fn": [[102, 105], ["nan_detector.NanDetector._apply"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply"], ["", "", "def", "bhook_fn", "(", "self", ",", "module", ",", "inp", ",", "output", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_printed_b", ":", "\n", "            ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "output", ",", "backward", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close": [[106, 109], ["hook.remove"], "methods", ["None"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "hook", "in", "self", ".", "fhooks", "+", "self", ".", "bhooks", ":", "\n", "            ", "hook", ".", "remove", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.__init__": [[91, 116], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "fairseq.utils.load_align_dict", "fairseq.data.encoders.build_tokenizer", "fairseq.data.encoders.build_bpe", "fairseq.utils.resolve_max_positions", "hub_utils.GeneratorHubInterface.register_buffer", "model.prepare_for_inference_", "hub_utils.GeneratorHubInterface.task.max_positions", "torch.tensor", "model.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.load_align_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_bpe", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["def", "__init__", "(", "self", ",", "cfg", ",", "task", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "src_dict", "=", "task", ".", "source_dictionary", "\n", "self", ".", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "# optimize model for generation", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "prepare_for_inference_", "(", "cfg", ")", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "self", ".", "align_dict", "=", "utils", ".", "load_align_dict", "(", "cfg", ".", "generation", ".", "replace_unk", ")", "\n", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "cfg", ".", "tokenizer", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "cfg", ".", "bpe", ")", "\n", "\n", "self", ".", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "*", "[", "model", ".", "max_positions", "(", ")", "for", "model", "in", "models", "]", "\n", ")", "\n", "\n", "# this is useful for determining the device", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device": [[117, 120], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.translate": [[121, 125], ["hub_utils.GeneratorHubInterface.sample"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.sample"], ["", "def", "translate", "(", "\n", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "5", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "self", ".", "sample", "(", "sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.sample": [[126, 134], ["isinstance", "hub_utils.GeneratorHubInterface.generate", "hub_utils.GeneratorHubInterface.encode", "hub_utils.GeneratorHubInterface.decode", "hub_utils.GeneratorHubInterface.sample"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.sample"], ["", "def", "sample", "(", "\n", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "isinstance", "(", "sentences", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "sample", "(", "[", "sentences", "]", ",", "beam", "=", "beam", ",", "verbose", "=", "verbose", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "", "tokenized_sentences", "=", "[", "self", ".", "encode", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "batched_hypos", "=", "self", ".", "generate", "(", "tokenized_sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "return", "[", "self", ".", "decode", "(", "hypos", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "hypos", "in", "batched_hypos", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.score": [[135, 144], ["isinstance", "hub_utils.GeneratorHubInterface.encode", "hub_utils.GeneratorHubInterface.score", "hub_utils.GeneratorHubInterface.generate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.score", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate"], ["", "def", "score", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "sentences", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "score", "(", "[", "sentences", "]", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "# NOTE: this doesn't support translation tasks currently", "\n", "", "tokenized_sentences", "=", "[", "self", ".", "encode", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "return", "[", "\n", "hypos", "[", "0", "]", "\n", "for", "hypos", "in", "self", ".", "generate", "(", "\n", "tokenized_sentences", ",", "score_reference", "=", "True", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.generate": [[147, 217], ["copy.deepcopy", "hub_utils.GeneratorHubInterface.task.build_generator", "hub_utils.GeneratorHubInterface._build_batches", "torch.is_tensor", "omegaconf.open_dict", "kwargs.items", "fairseq.utils.apply_to_sample", "hub_utils.GeneratorHubInterface.task.inference_step", "zip", "zip", "tokenized_sentences.dim", "hub_utils.GeneratorHubInterface.generate", "setattr", "batch[].tolist", "results.append", "sorted", "getattr", "hub_utils.GeneratorHubInterface.string", "logger.info", "tokenized_sentences.unsqueeze", "t.to", "getattr", "hub_utils.GeneratorHubInterface.decode", "logger.info", "logger.info", "hub_utils.GeneratorHubInterface.generate.getarg"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_generator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface._build_batches", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.inference_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "tokenized_sentences", ":", "List", "[", "torch", ".", "LongTensor", "]", ",", "\n", "beam", ":", "int", "=", "5", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", "skip_invalid_size_inputs", "=", "False", ",", "\n", "inference_step_args", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "tokenized_sentences", ")", "and", "tokenized_sentences", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "generate", "(", "\n", "tokenized_sentences", ".", "unsqueeze", "(", "0", ")", ",", "beam", "=", "beam", ",", "verbose", "=", "verbose", ",", "**", "kwargs", "\n", ")", "[", "0", "]", "\n", "\n", "# build generator using current args as well as any kwargs", "\n", "", "gen_args", "=", "copy", ".", "deepcopy", "(", "self", ".", "cfg", ".", "generation", ")", "\n", "with", "open_dict", "(", "gen_args", ")", ":", "\n", "            ", "gen_args", ".", "beam", "=", "beam", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "                ", "setattr", "(", "gen_args", ",", "k", ",", "v", ")", "\n", "", "", "generator", "=", "self", ".", "task", ".", "build_generator", "(", "self", ".", "models", ",", "gen_args", ")", "\n", "\n", "inference_step_args", "=", "inference_step_args", "or", "{", "}", "\n", "results", "=", "[", "]", "\n", "for", "batch", "in", "self", ".", "_build_batches", "(", "tokenized_sentences", ",", "skip_invalid_size_inputs", ")", ":", "\n", "            ", "batch", "=", "utils", ".", "apply_to_sample", "(", "lambda", "t", ":", "t", ".", "to", "(", "self", ".", "device", ")", ",", "batch", ")", "\n", "translations", "=", "self", ".", "task", ".", "inference_step", "(", "\n", "generator", ",", "self", ".", "models", ",", "batch", ",", "**", "inference_step_args", "\n", ")", "\n", "for", "id", ",", "hypos", "in", "zip", "(", "batch", "[", "\"id\"", "]", ".", "tolist", "(", ")", ",", "translations", ")", ":", "\n", "                ", "results", ".", "append", "(", "(", "id", ",", "hypos", ")", ")", "\n", "\n", "# sort output to match input order", "\n", "", "", "outputs", "=", "[", "hypos", "for", "_", ",", "hypos", "in", "sorted", "(", "results", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "\n", "if", "verbose", ":", "\n", "\n", "            ", "def", "getarg", "(", "name", ",", "default", ")", ":", "\n", "                ", "return", "getattr", "(", "gen_args", ",", "name", ",", "getattr", "(", "self", ".", "cfg", ",", "name", ",", "default", ")", ")", "\n", "\n", "", "for", "source_tokens", ",", "target_hypotheses", "in", "zip", "(", "tokenized_sentences", ",", "outputs", ")", ":", "\n", "                ", "src_str_with_unk", "=", "self", ".", "string", "(", "source_tokens", ")", "\n", "logger", ".", "info", "(", "\"S\\t{}\"", ".", "format", "(", "src_str_with_unk", ")", ")", "\n", "for", "hypo", "in", "target_hypotheses", ":", "\n", "                    ", "hypo_str", "=", "self", ".", "decode", "(", "hypo", "[", "\"tokens\"", "]", ")", "\n", "logger", ".", "info", "(", "\"H\\t{}\\t{}\"", ".", "format", "(", "hypo", "[", "\"score\"", "]", ",", "hypo_str", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"P\\t{}\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "\"{:.4f}\"", ".", "format", "(", "x", ")", ",", "\n", "hypo", "[", "\"positional_scores\"", "]", ".", "tolist", "(", ")", ",", "\n", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "if", "hypo", "[", "\"alignment\"", "]", "is", "not", "None", "and", "getarg", "(", "\n", "\"print_alignment\"", ",", "False", "\n", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\n", "\"A\\t{}\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "\n", "[", "\n", "\"{}-{}\"", ".", "format", "(", "src_idx", ",", "tgt_idx", ")", "\n", "for", "src_idx", ",", "tgt_idx", "in", "hypo", "[", "\"alignment\"", "]", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.encode": [[218, 222], ["hub_utils.GeneratorHubInterface.tokenize", "hub_utils.GeneratorHubInterface.apply_bpe", "hub_utils.GeneratorHubInterface.binarize"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.apply_bpe", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.Binarizer.binarize"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "sentence", "=", "self", ".", "tokenize", "(", "sentence", ")", "\n", "sentence", "=", "self", ".", "apply_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "binarize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.decode": [[223, 227], ["hub_utils.GeneratorHubInterface.string", "hub_utils.GeneratorHubInterface.remove_bpe", "hub_utils.GeneratorHubInterface.detokenize"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.remove_bpe", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.detokenize"], ["", "def", "decode", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "sentence", "=", "self", ".", "string", "(", "tokens", ")", "\n", "sentence", "=", "self", ".", "remove_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "detokenize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.tokenize": [[228, 232], ["hub_utils.GeneratorHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "tokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.detokenize": [[233, 237], ["hub_utils.GeneratorHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "detokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.apply_bpe": [[238, 242], ["hub_utils.GeneratorHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "apply_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.remove_bpe": [[243, 247], ["hub_utils.GeneratorHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "remove_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.binarize": [[248, 250], ["hub_utils.GeneratorHubInterface.src_dict.encode_line().long", "hub_utils.GeneratorHubInterface.src_dict.encode_line"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "binarize", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "return", "self", ".", "src_dict", ".", "encode_line", "(", "sentence", ",", "add_if_not_exist", "=", "False", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.string": [[251, 253], ["hub_utils.GeneratorHubInterface.tgt_dict.string"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string"], ["", "def", "string", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tgt_dict", ".", "string", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface._build_batches": [[254, 267], ["torch.LongTensor", "hub_utils.GeneratorHubInterface.task.get_batch_iterator().next_epoch_itr", "t.numel", "hub_utils.GeneratorHubInterface.task.get_batch_iterator", "hub_utils.GeneratorHubInterface.task.build_dataset_for_inference"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_dataset_for_inference"], ["", "def", "_build_batches", "(", "\n", "self", ",", "tokens", ":", "List", "[", "List", "[", "int", "]", "]", ",", "skip_invalid_size_inputs", ":", "bool", "\n", ")", "->", "Iterator", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "lengths", "=", "torch", ".", "LongTensor", "(", "[", "t", ".", "numel", "(", ")", "for", "t", "in", "tokens", "]", ")", "\n", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "build_dataset_for_inference", "(", "tokens", ",", "lengths", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "self", ".", "max_positions", ",", "\n", "ignore_invalid_inputs", "=", "skip_invalid_size_inputs", ",", "\n", "disable_iterator_cache", "=", "True", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.BPEHubInterface.__init__": [[272, 277], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_bpe"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_bpe"], ["def", "__init__", "(", "self", ",", "bpe", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "bpe", "=", "bpe", ",", "**", "kwargs", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "assert", "self", ".", "bpe", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.BPEHubInterface.encode": [[278, 280], ["hub_utils.BPEHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.BPEHubInterface.decode": [[281, 283], ["hub_utils.BPEHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.TokenizerHubInterface.__init__": [[288, 293], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "tokenizer", "=", "tokenizer", ",", "**", "kwargs", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "assert", "self", ".", "tokenizer", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.TokenizerHubInterface.encode": [[294, 296], ["hub_utils.TokenizerHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.TokenizerHubInterface.decode": [[297, 299], ["hub_utils.TokenizerHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.from_pretrained": [[23, 82], ["file_utils.load_archive_file", "data_name_or_path.startswith", "checkpoint_utils.load_model_ensemble_and_task", "isinstance", "os.path.abspath", "file_utils.load_archive_file", "os.path.join", "os.path.exists", "fairseq.utils.import_user_module", "model_name_or_path.items", "os.path.join", "argparse.Namespace", "os.path.join", "checkpoint_file.split"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble_and_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.import_user_module"], ["def", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "archive_map", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", ",", "file_utils", "\n", "\n", "if", "archive_map", "is", "not", "None", ":", "\n", "        ", "if", "model_name_or_path", "in", "archive_map", ":", "\n", "            ", "model_name_or_path", "=", "archive_map", "[", "model_name_or_path", "]", "\n", "", "if", "data_name_or_path", "is", "not", "None", "and", "data_name_or_path", "in", "archive_map", ":", "\n", "            ", "data_name_or_path", "=", "archive_map", "[", "data_name_or_path", "]", "\n", "\n", "# allow archive_map to set default arg_overrides (e.g., tokenizer, bpe)", "\n", "# for each model", "\n", "", "if", "isinstance", "(", "model_name_or_path", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "model_name_or_path", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "==", "\"checkpoint_file\"", ":", "\n", "                    ", "checkpoint_file", "=", "v", "\n", "", "elif", "(", "\n", "k", "!=", "\"path\"", "\n", "# only set kwargs that don't already have overrides", "\n", "and", "k", "not", "in", "kwargs", "\n", ")", ":", "\n", "                    ", "kwargs", "[", "k", "]", "=", "v", "\n", "", "", "model_name_or_path", "=", "model_name_or_path", "[", "\"path\"", "]", "\n", "\n", "", "", "model_path", "=", "file_utils", ".", "load_archive_file", "(", "model_name_or_path", ")", "\n", "\n", "# convenience hack for loading data and BPE codes from model archive", "\n", "if", "data_name_or_path", ".", "startswith", "(", "\".\"", ")", ":", "\n", "        ", "kwargs", "[", "\"data\"", "]", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "data_name_or_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "kwargs", "[", "\"data\"", "]", "=", "file_utils", ".", "load_archive_file", "(", "data_name_or_path", ")", "\n", "", "for", "file", ",", "arg", "in", "{", "\n", "\"code\"", ":", "\"bpe_codes\"", ",", "\n", "\"bpecodes\"", ":", "\"bpe_codes\"", ",", "\n", "\"sentencepiece.bpe.model\"", ":", "\"sentencepiece_model\"", ",", "\n", "\"merges.txt\"", ":", "\"bpe_merges\"", ",", "\n", "\"vocab.json\"", ":", "\"bpe_vocab\"", ",", "\n", "}", ".", "items", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "kwargs", "[", "arg", "]", "=", "path", "\n", "\n", "", "", "if", "\"user_dir\"", "in", "kwargs", ":", "\n", "        ", "utils", ".", "import_user_module", "(", "argparse", ".", "Namespace", "(", "user_dir", "=", "kwargs", "[", "\"user_dir\"", "]", ")", ")", "\n", "\n", "", "models", ",", "args", ",", "task", "=", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "os", ".", "path", ".", "join", "(", "model_path", ",", "cpt", ")", "for", "cpt", "in", "checkpoint_file", ".", "split", "(", "os", ".", "pathsep", ")", "]", ",", "\n", "arg_overrides", "=", "kwargs", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "\"args\"", ":", "args", ",", "\n", "\"task\"", ":", "task", ",", "\n", "\"models\"", ":", "models", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_scorer.SequenceScorer.__init__": [[15, 32], ["tgt_dict.pad", "tgt_dict.eos", "symbols_to_strip_from_output.union"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dict", ",", "\n", "softmax_batch", "=", "None", ",", "\n", "compute_alignment", "=", "False", ",", "\n", "eos", "=", "None", ",", "\n", "symbols_to_strip_from_output", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "softmax_batch", "=", "softmax_batch", "or", "sys", ".", "maxsize", "\n", "assert", "self", ".", "softmax_batch", ">", "0", "\n", "self", ".", "compute_alignment", "=", "compute_alignment", "\n", "self", ".", "symbols_to_strip_from_output", "=", "(", "\n", "symbols_to_strip_from_output", ".", "union", "(", "{", "self", ".", "eos", "}", ")", "\n", "if", "symbols_to_strip_from_output", "is", "not", "None", "\n", "else", "{", "self", ".", "eos", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_scorer.SequenceScorer.generate": [[34, 154], ["torch.no_grad", "avg_probs.size", "range", "curr_prob.new.gather", "model.eval", "model", "sequence_scorer.SequenceScorer.generate.batch_for_softmax"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Score a batch of translations.\"\"\"", "\n", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "\n", "def", "batch_for_softmax", "(", "dec_out", ",", "target", ")", ":", "\n", "# assumes decoder_out[0] is the only thing needed (may not be correct for future models!)", "\n", "            ", "first", ",", "rest", "=", "dec_out", "[", "0", "]", ",", "dec_out", "[", "1", ":", "]", "\n", "bsz", ",", "tsz", ",", "dim", "=", "first", ".", "shape", "\n", "if", "bsz", "*", "tsz", "<", "self", ".", "softmax_batch", ":", "\n", "                ", "yield", "dec_out", ",", "target", ",", "True", "\n", "", "else", ":", "\n", "                ", "flat", "=", "first", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "dim", ")", "\n", "flat_tgt", "=", "target", ".", "contiguous", "(", ")", ".", "view", "(", "flat", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "s", "=", "0", "\n", "while", "s", "<", "flat", ".", "size", "(", "1", ")", ":", "\n", "                    ", "e", "=", "s", "+", "self", ".", "softmax_batch", "\n", "yield", "(", "flat", "[", ":", ",", "s", ":", "e", "]", ",", ")", "+", "rest", ",", "flat_tgt", "[", ":", ",", "s", ":", "e", "]", ",", "False", "\n", "s", "=", "e", "\n", "\n", "", "", "", "def", "gather_target_probs", "(", "probs", ",", "target", ")", ":", "\n", "            ", "probs", "=", "probs", ".", "gather", "(", "\n", "dim", "=", "2", ",", "\n", "index", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", "\n", "return", "probs", "\n", "\n", "", "orig_target", "=", "sample", "[", "\"target\"", "]", "\n", "\n", "# compute scores for each model in the ensemble", "\n", "avg_probs", "=", "None", "\n", "avg_attn", "=", "None", "\n", "for", "model", "in", "models", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "decoder_out", "=", "model", "(", "**", "net_input", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "if", "len", "(", "decoder_out", ")", ">", "1", "else", "None", "\n", "if", "type", "(", "attn", ")", "is", "dict", ":", "\n", "                ", "attn", "=", "attn", ".", "get", "(", "\"attn\"", ",", "None", ")", "\n", "\n", "", "batched", "=", "batch_for_softmax", "(", "decoder_out", ",", "orig_target", ")", "\n", "probs", ",", "idx", "=", "None", ",", "0", "\n", "for", "bd", ",", "tgt", ",", "is_single", "in", "batched", ":", "\n", "                ", "sample", "[", "\"target\"", "]", "=", "tgt", "\n", "curr_prob", "=", "model", ".", "get_normalized_probs", "(", "\n", "bd", ",", "log_probs", "=", "len", "(", "models", ")", "==", "1", ",", "sample", "=", "sample", "\n", ")", ".", "data", "\n", "if", "is_single", ":", "\n", "                    ", "probs", "=", "gather_target_probs", "(", "curr_prob", ",", "orig_target", ")", "\n", "", "else", ":", "\n", "                    ", "if", "probs", "is", "None", ":", "\n", "                        ", "probs", "=", "curr_prob", ".", "new", "(", "orig_target", ".", "numel", "(", ")", ")", "\n", "", "step", "=", "curr_prob", ".", "size", "(", "0", ")", "*", "curr_prob", ".", "size", "(", "1", ")", "\n", "end", "=", "step", "+", "idx", "\n", "tgt_probs", "=", "gather_target_probs", "(", "\n", "curr_prob", ".", "view", "(", "tgt", ".", "shape", "+", "(", "curr_prob", ".", "size", "(", "-", "1", ")", ",", ")", ")", ",", "tgt", "\n", ")", "\n", "probs", "[", "idx", ":", "end", "]", "=", "tgt_probs", ".", "view", "(", "-", "1", ")", "\n", "idx", "=", "end", "\n", "", "sample", "[", "\"target\"", "]", "=", "orig_target", "\n", "\n", "", "probs", "=", "probs", ".", "view", "(", "sample", "[", "\"target\"", "]", ".", "shape", ")", "\n", "\n", "if", "avg_probs", "is", "None", ":", "\n", "                ", "avg_probs", "=", "probs", "\n", "", "else", ":", "\n", "                ", "avg_probs", ".", "add_", "(", "probs", ")", "\n", "", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "attn", ")", ":", "\n", "                    ", "attn", "=", "attn", ".", "data", "\n", "", "else", ":", "\n", "                    ", "attn", "=", "attn", "[", "0", "]", "\n", "", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "if", "len", "(", "models", ")", ">", "1", ":", "\n", "            ", "avg_probs", ".", "div_", "(", "len", "(", "models", ")", ")", "\n", "avg_probs", ".", "log_", "(", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "                ", "avg_attn", ".", "div_", "(", "len", "(", "models", ")", ")", "\n", "\n", "", "", "bsz", "=", "avg_probs", ".", "size", "(", "0", ")", "\n", "hypos", "=", "[", "]", "\n", "start_idxs", "=", "sample", "[", "\"start_indices\"", "]", "if", "\"start_indices\"", "in", "sample", "else", "[", "0", "]", "*", "bsz", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "# remove padding from ref", "\n", "            ", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", ",", "start_idxs", "[", "i", "]", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "sample", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "tgt_len", "=", "ref", ".", "numel", "(", ")", "\n", "avg_probs_i", "=", "avg_probs", "[", "i", "]", "[", "start_idxs", "[", "i", "]", ":", "start_idxs", "[", "i", "]", "+", "tgt_len", "]", "\n", "score_i", "=", "avg_probs_i", ".", "sum", "(", ")", "/", "tgt_len", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "                ", "avg_attn_i", "=", "avg_attn", "[", "i", "]", "\n", "if", "self", ".", "compute_alignment", ":", "\n", "                    ", "alignment", "=", "utils", ".", "extract_hard_alignment", "(", "\n", "avg_attn_i", ",", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "i", "]", ",", "\n", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "alignment", "=", "None", "\n", "", "", "else", ":", "\n", "                ", "avg_attn_i", "=", "alignment", "=", "None", "\n", "", "hypos", ".", "append", "(", "\n", "[", "\n", "{", "\n", "\"tokens\"", ":", "ref", ",", "\n", "\"score\"", ":", "score_i", ",", "\n", "\"attention\"", ":", "avg_attn_i", ",", "\n", "\"alignment\"", ":", "alignment", ",", "\n", "\"positional_scores\"", ":", "avg_probs_i", ",", "\n", "}", "\n", "]", "\n", ")", "\n", "", "return", "hypos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.tokenizer.tokenize_line": [[12, 16], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.load_archive_file": [[54, 96], ["file_utils.cached_path", "logger.info", "logger.info", "os.path.isdir", "tempfile.mkdtemp", "logger.info", "os.remove", "shutil.move", "shutil.rmtree", "logger.info", "tarfile.open", "os.path.commonprefix", "archive.extractall", "os.path.join", "os.path.splitext", "archive.getnames"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["def", "load_archive_file", "(", "archive_file", ")", ":", "\n", "# redirect to the cache, if necessary", "\n", "    ", "try", ":", "\n", "        ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "None", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Archive name '{}' was not found in archive name list. \"", "\n", "\"We assumed '{}' was a path or URL but couldn't find any file \"", "\n", "\"associated to this path or URL.\"", ".", "format", "(", "\n", "archive_file", ",", "\n", "archive_file", ",", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", "\n", ")", "\n", ")", "\n", "\n", "# Extract archive to temp dir and replace .tar.bz2 if necessary", "\n", "", "tempdir", "=", "None", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "        ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\n", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", "\n", ")", "\n", ")", "\n", "ext", "=", "os", ".", "path", ".", "splitext", "(", "archive_file", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "\"r:\"", "+", "ext", ")", "as", "archive", ":", "\n", "            ", "top_dir", "=", "os", ".", "path", ".", "commonprefix", "(", "archive", ".", "getnames", "(", ")", ")", "\n", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "os", ".", "remove", "(", "resolved_archive_file", ")", "\n", "shutil", ".", "move", "(", "os", ".", "path", ".", "join", "(", "tempdir", ",", "top_dir", ")", ",", "resolved_archive_file", ")", "\n", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "\n", "", "return", "resolved_archive_file", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.url_to_filename": [[98, 114], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the URL's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.filename_to_url": [[116, 140], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path": [[142, 171], ["isinstance", "isinstance", "urlparse", "str", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.get_from_cache", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\n", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.split_s3_path": [[174, 185], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.s3_request": [[187, 206], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "botocore", ".", "exceptions", "import", "ClientError", "\n", "\n", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.s3_etag": [[208, 217], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "import", "boto3", "\n", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.s3_get": [[219, 227], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "import", "boto3", "\n", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.request_wrap_timeout": [[229, 245], ["enumerate", "RuntimeError", "func", "logger.warning"], "function", ["None"], ["", "def", "request_wrap_timeout", "(", "func", ",", "url", ")", ":", "\n", "    ", "import", "requests", "\n", "\n", "for", "attempt", ",", "timeout", "in", "enumerate", "(", "[", "10", ",", "20", ",", "40", ",", "60", ",", "60", "]", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "timeout", "=", "timeout", ")", "\n", "", "except", "requests", ".", "exceptions", ".", "Timeout", "as", "e", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Request for %s timed-out (attempt %d). Retrying with a timeout of %d secs\"", ",", "\n", "url", ",", "\n", "attempt", ",", "\n", "timeout", ",", "\n", "exc_info", "=", "e", ",", "\n", ")", "\n", "continue", "\n", "", "", "raise", "RuntimeError", "(", "f\"Unable to fetch file {url}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.http_get": [[247, 260], ["file_utils.request_wrap_timeout", "request_wrap_timeout.headers.get", "tqdm", "request_wrap_timeout.iter_content", "tqdm.close", "functools.partial", "int", "tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.request_wrap_timeout", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "import", "requests", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "req", "=", "request_wrap_timeout", "(", "partial", "(", "requests", ".", "get", ",", "url", ",", "stream", "=", "True", ")", ",", "url", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.get_from_cache": [[262, 336], ["isinstance", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "fnmatch.filter", "list", "os.path.exists", "file_utils.request_wrap_timeout", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "functools.partial", "request_wrap_timeout.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "s.endswith"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.url_to_filename", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.s3_etag", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.request_wrap_timeout", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.s3_get", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.http_get", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "requests", "\n", "\n", "response", "=", "request_wrap_timeout", "(", "\n", "partial", "(", "requests", ".", "head", ",", "url", ",", "allow_redirects", "=", "True", ")", ",", "url", "\n", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "RuntimeError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "\".json\"", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "\"wb\"", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.read_set_from_file": [[338, 348], ["set", "io.open", "set.add", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    \"\"\"", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.get_file_extension": [[350, 354], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.__init__": [[24, 70], ["len", "fairseq.modules.quantization.quantization_options.parse_config_yaml", "ImportError", "open", "fairseq.modules.quantization.quantization_options.parse_config_yaml", "yaml.safe_load"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.parse_config_yaml", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.parse_config_yaml"], ["    ", "def", "__init__", "(", "self", ",", "config_path", ",", "max_epoch", ",", "max_update", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install yaml with: pip install yaml\"", ")", "\n", "\n", "# parse config", "\n", "", "if", "config_path", ":", "\n", "            ", "with", "open", "(", "config_path", ")", "as", "config_file", ":", "\n", "                ", "config", "=", "quantization_options", ".", "parse_config_yaml", "(", "\n", "yaml", ".", "safe_load", "(", "config_file", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "config", "=", "quantization_options", ".", "parse_config_yaml", "(", "{", "}", ")", "\n", "\n", "", "self", ".", "n_centroids_config", "=", "config", "[", "\"n_centroids\"", "]", "\n", "self", ".", "block_sizes_config", "=", "config", "[", "\"block_sizes\"", "]", "\n", "self", ".", "layers_to_quantize", "=", "config", "[", "\"layers_to_quantize\"", "]", "\n", "\n", "# We assume that training will run for a fixed number of epochs", "\n", "# (or updates) and that we should train for equal durations", "\n", "# between iterations of PQ.", "\n", "num_iterations", "=", "len", "(", "self", ".", "layers_to_quantize", ")", "\n", "if", "max_epoch", ">", "0", ":", "\n", "            ", "assert", "max_epoch", "%", "num_iterations", "==", "0", ",", "(", "\n", "\"for iterative PQ, --max-epoch (={}) must be evenly divisible by \"", "\n", "\"len(layers_to_quantize) (={})\"", ".", "format", "(", "max_epoch", ",", "num_iterations", ")", "\n", ")", "\n", "self", ".", "epoch_schedule", "=", "max_epoch", "//", "num_iterations", "\n", "", "else", ":", "\n", "            ", "self", ".", "epoch_schedule", "=", "None", "\n", "", "if", "max_update", ">", "0", ":", "\n", "            ", "assert", "max_update", "%", "num_iterations", "==", "0", ",", "(", "\n", "\"for iterative PQ, --max-update (={}) must be evenly divisible by \"", "\n", "\"len(layers_to_quantize) (={})\"", ".", "format", "(", "max_update", ",", "num_iterations", ")", "\n", ")", "\n", "self", ".", "update_schedule", "=", "max_update", "//", "num_iterations", "\n", "", "else", ":", "\n", "            ", "self", ".", "update_schedule", "=", "None", "\n", "", "assert", "(", "self", ".", "epoch_schedule", "is", "not", "None", ")", "^", "(", "\n", "self", ".", "update_schedule", "is", "not", "None", "\n", ")", ",", "\"for iterative PQ, cannot specify both --max-update and --max-epoch\"", "\n", "\n", "# 0 is a special value for quantization step, which will force", "\n", "# the first call to begin_epoch() to call step()", "\n", "self", ".", "quantization_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.set_trainer": [[71, 74], ["fairseq.modules.quantization.pq.SizeTracker", "quantization_utils.Quantizer.trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model"], ["", "def", "set_trainer", "(", "self", ",", "trainer", ")", ":", "\n", "        ", "self", ".", "trainer", "=", "trainer", "\n", "self", ".", "size_tracker", "=", "pq", ".", "SizeTracker", "(", "self", ".", "trainer", ".", "get_model", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.step": [[75, 103], ["logger.info", "fairseq.modules.quantization.pq.quantize_model_", "logger.info", "logger.info", "quantization_utils.Quantizer.trainer.reinitialize", "len", "quantization_utils.Quantizer.trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.quantize_model_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.reinitialize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move to the next stage of quantization.\"\"\"", "\n", "if", "self", ".", "quantization_step", ">=", "len", "(", "self", ".", "layers_to_quantize", ")", ":", "\n", "# Maybe we just finished the last training step or we loaded", "\n", "# a checkpoint for an iterative PQ model which previously", "\n", "# finished training. Either way, don't quantize again.", "\n", "            ", "return", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"quantizing model (step={}; layers_to_quantize[step]={})\"", ".", "format", "(", "\n", "self", ".", "quantization_step", ",", "self", ".", "layers_to_quantize", "[", "self", ".", "quantization_step", "]", "\n", ")", "\n", ")", "\n", "quantized_layers", "=", "pq", ".", "quantize_model_", "(", "\n", "self", ".", "trainer", ".", "get_model", "(", ")", ",", "\n", "self", ".", "size_tracker", ",", "\n", "self", ".", "layers_to_quantize", ",", "\n", "self", ".", "block_sizes_config", ",", "\n", "self", ".", "n_centroids_config", ",", "\n", "step", "=", "self", ".", "quantization_step", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"quantized layers: {}\"", ".", "format", "(", "quantized_layers", ")", ")", "\n", "logger", ".", "info", "(", "self", ".", "size_tracker", ")", "\n", "\n", "self", ".", "quantization_step", "+=", "1", "\n", "\n", "# reintialize the Trainer since model parameters have changed", "\n", "self", ".", "trainer", ".", "reinitialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.begin_epoch": [[104, 117], ["quantization_utils.Quantizer.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "def", "begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each epoch (epochs start at 1).\"\"\"", "\n", "if", "(", "\n", "(", "\n", "self", ".", "epoch_schedule", "is", "not", "None", "\n", "and", "epoch", ">", "0", "\n", "and", "(", "epoch", "-", "1", ")", "%", "self", ".", "epoch_schedule", "==", "0", "\n", ")", "\n", "# we always step once in the beginning, even if using", "\n", "# update-based quantization", "\n", "or", "self", ".", "quantization_step", "==", "0", "\n", ")", ":", "\n", "            ", "self", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.step_update": [[118, 126], ["quantization_utils.Quantizer.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Called at the end of each step.\"\"\"", "\n", "if", "(", "\n", "self", ".", "update_schedule", "is", "not", "None", "\n", "and", "num_updates", ">", "0", "\n", "and", "num_updates", "%", "self", ".", "update_schedule", "==", "0", "\n", ")", ":", "\n", "            ", "self", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.state_dict": [[127, 135], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"n_centroids_config\"", ":", "self", ".", "n_centroids_config", ",", "\n", "\"block_sizes_config\"", ":", "self", ".", "block_sizes_config", ",", "\n", "\"layers_to_quantize\"", ":", "self", ".", "layers_to_quantize", ",", "\n", "\"epoch_schedule\"", ":", "self", ".", "epoch_schedule", ",", "\n", "\"update_schedule\"", ":", "self", ".", "update_schedule", ",", "\n", "\"quantization_step\"", ":", "self", ".", "quantization_step", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.load_state_dict": [[137, 144], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "n_centroids_config", "=", "state_dict", "[", "\"n_centroids_config\"", "]", "\n", "self", ".", "block_sizes_config", "=", "state_dict", "[", "\"block_sizes_config\"", "]", "\n", "self", ".", "layers_to_quantize", "=", "state_dict", "[", "\"layers_to_quantize\"", "]", "\n", "self", ".", "epoch_schedule", "=", "state_dict", "[", "\"epoch_schedule\"", "]", "\n", "self", ".", "update_schedule", "=", "state_dict", "[", "\"update_schedule\"", "]", "\n", "self", ".", "quantization_step", "=", "state_dict", "[", "\"quantization_step\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.quantize_model_scalar": [[15, 21], ["getattr", "fairseq.modules.quantization.scalar.quantize_model_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.quantize_model_"], ["def", "quantize_model_scalar", "(", "model", ",", "model_cfg", ":", "DictConfig", ")", ":", "\n", "    ", "quant_noise_scalar", "=", "getattr", "(", "model_cfg", ",", "\"quant_noise_scalar\"", ",", "0", ")", "or", "0", "\n", "if", "quant_noise_scalar", ">", "0", ":", "\n", "# quantize_model edits the model in place", "\n", "        ", "scalar", ".", "quantize_model_", "(", "model", ",", "p", "=", "quant_noise_scalar", ",", "bits", "=", "8", ",", "update_step", "=", "1000", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.__init__": [[41, 131], ["isinstance", "trainer._catalog_shared_params", "set", "fairseq.logging.metrics.log_start_time", "time.time", "logger.warning", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "torch.cuda.is_available", "torch.device", "trainer.Trainer._criterion.half", "trainer.Trainer._model.half", "trainer.Trainer._criterion.to", "trainer.Trainer._model.to", "torch.device", "trainer._get_module_by_path", "torch.cuda.DoubleTensor", "trainer.Trainer.quantizer.set_trainer", "fairseq.utils.CudaEnvironment", "fairseq.utils.get_tpu_device", "torch.device", "trainer.Trainer._criterion.to", "trainer.Trainer._model.to", "logger.info", "trainer._set_module_by_path", "fairseq.distributed_utils.all_gather_list", "fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list", "fairseq.distributed_utils.get_global_group"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._catalog_shared_params", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_start_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._get_module_by_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.Quantizer.set_trainer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_tpu_device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._set_module_by_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_global_group"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqConfig", ",", "task", ",", "model", ",", "criterion", ",", "quantizer", "=", "None", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"argparse.Namespace configuration is deprecated! Automatically converting to OmegaConf\"", "\n", ")", "\n", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "task", "=", "task", "\n", "\n", "# catalog shared parameters", "\n", "shared_params", "=", "_catalog_shared_params", "(", "model", ")", "\n", "self", ".", "tpu", "=", "cfg", ".", "common", ".", "tpu", "\n", "self", ".", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "and", "not", "self", ".", "tpu", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "elif", "self", ".", "tpu", ":", "\n", "            ", "self", ".", "device", "=", "utils", ".", "get_tpu_device", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# copy model and criterion to current device/dtype", "\n", "", "self", ".", "_criterion", "=", "criterion", "\n", "self", ".", "_model", "=", "model", "\n", "if", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "half", "(", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "half", "(", ")", "\n", "", "elif", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "", "if", "not", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "self", ".", "pipeline_model_parallel", "=", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", "\n", "self", ".", "last_device", "=", "None", "\n", "if", "self", ".", "cuda", "and", "self", ".", "pipeline_model_parallel", ":", "\n", "            ", "self", ".", "last_device", "=", "torch", ".", "device", "(", "\n", "cfg", ".", "distributed_training", ".", "pipeline_devices", "[", "-", "1", "]", "\n", ")", "\n", "\n", "# check that shared parameters are preserved after device transfer", "\n", "", "for", "shared_param", "in", "shared_params", ":", "\n", "            ", "ref", "=", "_get_module_by_path", "(", "self", ".", "_model", ",", "shared_param", "[", "0", "]", ")", "\n", "for", "path", "in", "shared_param", "[", "1", ":", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"detected shared parameter: {} <- {}\"", ".", "format", "(", "shared_param", "[", "0", "]", ",", "path", ")", "\n", ")", "\n", "_set_module_by_path", "(", "self", ".", "_model", ",", "path", ",", "ref", ")", "\n", "\n", "", "", "self", ".", "_dummy_batch", "=", "None", "# indicates we don't have a dummy batch at first", "\n", "self", ".", "_lr_scheduler", "=", "None", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "_num_xla_compiles", "=", "0", "# for TPUs", "\n", "self", ".", "_optim_history", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_warn_once", "=", "set", "(", ")", "\n", "self", ".", "_wrapped_criterion", "=", "None", "\n", "self", ".", "_wrapped_model", "=", "None", "\n", "\n", "# TODO(myleott): support tpu", "\n", "if", "self", ".", "cuda", "and", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "            ", "self", ".", "_grad_norm_buf", "=", "torch", ".", "cuda", ".", "DoubleTensor", "(", "self", ".", "data_parallel_world_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_grad_norm_buf", "=", "None", "\n", "\n", "", "self", ".", "quantizer", "=", "quantizer", "\n", "if", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "quantizer", ".", "set_trainer", "(", "self", ")", "\n", "\n", "# get detailed cuda environment", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "cuda_env", "=", "utils", ".", "CudaEnvironment", "(", ")", "\n", "if", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "                ", "self", ".", "cuda_env_arr", "=", "distributed_utils", ".", "all_gather_list", "(", "\n", "self", ".", "cuda_env", ",", "group", "=", "distributed_utils", ".", "get_global_group", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "cuda_env_arr", "=", "[", "self", ".", "cuda_env", "]", "\n", "", "if", "self", ".", "data_parallel_rank", "==", "0", ":", "\n", "                ", "utils", ".", "CudaEnvironment", ".", "pretty_print_cuda_env_list", "(", "self", ".", "cuda_env_arr", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "cuda_env", "=", "None", "\n", "self", ".", "cuda_env_arr", "=", "None", "\n", "\n", "", "metrics", ".", "log_start_time", "(", "\"wall\"", ",", "priority", "=", "790", ",", "round", "=", "0", ")", "\n", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_previous_training_time", "=", "0", "\n", "self", ".", "_cumulative_training_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.reinitialize": [[132, 138], ["None"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reinitialize the Trainer, typically after model params change.\"\"\"", "\n", "self", ".", "_lr_scheduler", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_wrapped_criterion", "=", "None", "\n", "self", ".", "_wrapped_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.data_parallel_world_size": [[139, 144], ["fairseq.distributed_utils.get_data_parallel_world_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_world_size"], ["", "@", "property", "\n", "def", "data_parallel_world_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "            ", "return", "1", "\n", "", "return", "distributed_utils", ".", "get_data_parallel_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.data_parallel_process_group": [[145, 148], ["fairseq.distributed_utils.get_data_parallel_group"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_group"], ["", "@", "property", "\n", "def", "data_parallel_process_group", "(", "self", ")", ":", "\n", "        ", "return", "distributed_utils", ".", "get_data_parallel_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.data_parallel_rank": [[149, 154], ["fairseq.distributed_utils.get_data_parallel_rank"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_data_parallel_rank"], ["", "@", "property", "\n", "def", "data_parallel_rank", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "            ", "return", "0", "\n", "", "return", "distributed_utils", ".", "get_data_parallel_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.is_data_parallel_master": [[155, 160], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_data_parallel_master", "(", "self", ")", ":", "\n", "# NOTE: this returns true for all model parallel replicas with data", "\n", "# parallel rank 0", "\n", "        ", "return", "self", ".", "data_parallel_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.criterion": [[161, 177], ["fairseq.utils.has_parameters", "fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "criterion", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_criterion", "is", "None", ":", "\n", "            ", "if", "(", "\n", "utils", ".", "has_parameters", "(", "self", ".", "_criterion", ")", "\n", "and", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "\n", ")", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ",", "\n", "self", ".", "_criterion", ",", "\n", "process_group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "self", ".", "_criterion", "\n", "", "", "return", "self", ".", "_wrapped_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model": [[178, 190], ["fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_model", "is", "None", ":", "\n", "            ", "if", "self", ".", "data_parallel_world_size", ">", "1", "and", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ",", "\n", "self", ".", "_model", ",", "\n", "process_group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "self", ".", "_model", "\n", "", "", "return", "self", ".", "_wrapped_model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.optimizer": [[191, 196], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_optimizer", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "", "return", "self", ".", "_optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_scheduler": [[197, 202], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "lr_scheduler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "# this will initialize self._lr_scheduler", "\n", "", "return", "self", ".", "_lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._build_optimizer": [[203, 257], ["list", "fairseq.optim.lr_scheduler.build_lr_scheduler", "trainer.Trainer._lr_scheduler.step_update", "filter", "fairseq.optim.build_optimizer", "fairseq.optim.FairseqBMUF", "itertools.chain", "logger.info", "fairseq.optim.MemoryEfficientFP16Optimizer.build_optimizer", "fairseq.optim.FP16Optimizer.build_optimizer", "logger.info", "ValueError", "fairseq.optim.shard_", "trainer.Trainer.model.parameters", "trainer.Trainer.criterion.parameters", "torch.cuda.get_device_capability", "torch.cuda.get_device_capability"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.__init__.build_lr_scheduler", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.shard.shard_"], ["", "def", "_build_optimizer", "(", "self", ")", ":", "\n", "        ", "params", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "p", ":", "p", ".", "requires_grad", ",", "\n", "chain", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "criterion", ".", "parameters", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "common", ".", "fp16", "or", "self", ".", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", "<", "7", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"NOTE: your device does NOT support faster training with --fp16, \"", "\n", "\"please switch to FP32 which is likely to be faster\"", "\n", ")", "\n", "", "if", "(", "\n", "self", ".", "cfg", ".", "common", ".", "memory_efficient_fp16", "\n", "or", "self", ".", "cfg", ".", "common", ".", "memory_efficient_bf16", "\n", ")", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "MemoryEfficientFP16Optimizer", ".", "build_optimizer", "(", "\n", "self", ".", "cfg", ",", "params", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "FP16Optimizer", ".", "build_optimizer", "(", "self", ".", "cfg", ",", "params", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", ">=", "7", ":", "\n", "                ", "logger", ".", "info", "(", "\"NOTE: your device may support faster training with --fp16\"", ")", "\n", "", "self", ".", "_optimizer", "=", "optim", ".", "build_optimizer", "(", "self", ".", "cfg", ".", "optimizer", ",", "params", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "            ", "self", ".", "_optimizer", "=", "optim", ".", "FairseqBMUF", "(", "\n", "self", ".", "cfg", ".", "bmuf", ",", "\n", "self", ".", "_optimizer", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "distributed_training", ".", "zero_sharding", "==", "\"os\"", ":", "\n", "            ", "if", "(", "\n", "self", ".", "cfg", ".", "common", ".", "fp16", "\n", "and", "not", "self", ".", "cfg", ".", "common", ".", "memory_efficient_fp16", "\n", "and", "not", "self", ".", "cfg", ".", "common", ".", "memory_efficient_bf16", "\n", ")", "and", "not", "self", ".", "cfg", ".", "common", ".", "fp16_no_flatten_grads", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"ZeRO is incomptabile with fp16 and flattened grads. \"", "\n", "\"Please use --fp16-no-flatten-grads\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "optim", ".", "shard_", "(", "self", ".", "_optimizer", ",", "self", ".", "data_parallel_process_group", ")", "\n", "\n", "# We should initialize the learning rate scheduler immediately after", "\n", "# building the optimizer, so that the initial learning rate is set.", "\n", "", "", "self", ".", "_lr_scheduler", "=", "lr_scheduler", ".", "build_lr_scheduler", "(", "\n", "self", ".", "cfg", ".", "lr_scheduler", ",", "\n", "self", ".", "optimizer", ",", "\n", ")", "\n", "self", ".", "_lr_scheduler", ".", "step_update", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.consolidate_optimizer": [[258, 262], ["hasattr", "trainer.Trainer.optimizer.optimizer.consolidate_state_dict"], "methods", ["None"], ["", "def", "consolidate_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"For OSS, we need to consolidate the state dict.\"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ".", "optimizer", ",", "\"consolidate_state_dict\"", ")", ":", "\n", "            ", "self", ".", "optimizer", ".", "optimizer", ".", "consolidate_state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.save_checkpoint": [[263, 280], ["fairseq.logging.metrics.state_dict", "trainer.Trainer.cumulative_training_time", "fairseq.checkpoint_utils.save_state", "logger.info", "trainer.Trainer.get_model().state_dict", "trainer.Trainer.get_criterion", "trainer.Trainer.get_num_updates", "trainer.Trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.cumulative_training_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.save_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model"], ["", "", "def", "save_checkpoint", "(", "self", ",", "filename", ",", "extra_state", ")", ":", "\n", "        ", "\"\"\"Save all training state in a checkpoint file.\"\"\"", "\n", "if", "self", ".", "is_data_parallel_master", ":", "# only save one checkpoint", "\n", "            ", "extra_state", "[", "\"metrics\"", "]", "=", "metrics", ".", "state_dict", "(", ")", "\n", "extra_state", "[", "\"previous_training_time\"", "]", "=", "self", ".", "cumulative_training_time", "(", ")", "\n", "checkpoint_utils", ".", "save_state", "(", "\n", "filename", ",", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "get_model", "(", ")", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "get_criterion", "(", ")", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "lr_scheduler", ",", "\n", "self", ".", "get_num_updates", "(", ")", ",", "\n", "self", ".", "_optim_history", ",", "\n", "extra_state", ",", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Finished saving checkpoint to {filename}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.load_checkpoint": [[281, 410], ["logger.info", "fairseq.file_io.PathManager.isfile", "trainer.Trainer._build_optimizer", "trainer.Trainer.optimizer.load_state_dict", "trainer.Trainer.set_num_updates", "trainer.Trainer.lr_step", "logger.info", "logger.info", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.distributed_utils.broadcast_object.get", "fairseq.distributed_utils.broadcast_object", "trainer.Trainer.get_model().load_state_dict", "fairseq.utils.has_parameters", "trainer.Trainer.lr_scheduler.load_state_dict", "trainer.Trainer.optimizer.broadcast_global_state_dict", "time.time", "fairseq.logging.metrics.load_state_dict", "fairseq.logging.metrics.get_meters", "fairseq.distributed_utils.broadcast_object.get", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion().load_state_dict", "Exception", "itr_state.get", "isinstance", "trainer.Trainer.get_num_updates", "trainer.Trainer.get_model", "trainer.Trainer.get_criterion", "meter.reset", "trainer.Trainer.get_criterion"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._build_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_object", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.broadcast_global_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion"], ["", "", "def", "load_checkpoint", "(", "\n", "self", ",", "\n", "filename", ",", "\n", "reset_optimizer", "=", "False", ",", "\n", "reset_lr_scheduler", "=", "False", ",", "\n", "optimizer_overrides", "=", "None", ",", "\n", "reset_meters", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Load all training state from a checkpoint file.\n        rank = 0 will load the checkpoint, and then broadcast it to all\n        other ranks.\n        \"\"\"", "\n", "extra_state", ",", "self", ".", "_optim_history", ",", "last_optim_state", "=", "None", ",", "[", "]", ",", "None", "\n", "\n", "logger", ".", "info", "(", "f\"Preparing to load checkpoint {filename}\"", ")", "\n", "is_distributed", "=", "self", ".", "data_parallel_world_size", ">", "1", "\n", "bexists", "=", "PathManager", ".", "isfile", "(", "filename", ")", "\n", "if", "bexists", ":", "\n", "            ", "load_on_all_ranks", "=", "(", "\n", "self", ".", "cfg", ".", "checkpoint", ".", "load_checkpoint_on_all_dp_ranks", "\n", "# TPUs don't support broadcast yet, so load checkpoints", "\n", "# on every worker for now", "\n", "or", "self", ".", "tpu", "\n", ")", "\n", "\n", "if", "load_on_all_ranks", "or", "self", ".", "data_parallel_rank", "==", "0", ":", "\n", "                ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "\n", "filename", ",", "load_on_all_ranks", "=", "load_on_all_ranks", "\n", ")", "\n", "last_optim_state", "=", "state", ".", "get", "(", "\"last_optimizer_state\"", ",", "None", ")", "\n", "\n", "# If doing zero_sharding, do not broadcast global optimizer", "\n", "# state. Later we will broadcast sharded states to each rank", "\n", "# to avoid memory from exploding.", "\n", "if", "(", "\n", "not", "load_on_all_ranks", "\n", "and", "self", ".", "cfg", ".", "distributed_training", ".", "zero_sharding", "==", "\"os\"", "\n", "and", "\"last_optimizer_state\"", "in", "state", "\n", "and", "is_distributed", "\n", ")", ":", "\n", "                    ", "state", "[", "\"last_optimizer_state\"", "]", "=", "\"SHARDED\"", "\n", "", "", "else", ":", "\n", "                ", "last_optim_state", "=", "None", "\n", "state", "=", "None", "\n", "\n", "", "if", "is_distributed", "and", "not", "load_on_all_ranks", ":", "\n", "                ", "state", "=", "distributed_utils", ".", "broadcast_object", "(", "\n", "state", ",", "\n", "src_rank", "=", "0", ",", "\n", "group", "=", "self", ".", "data_parallel_process_group", ",", "\n", "dist_device", "=", "self", ".", "device", ",", "\n", ")", "\n", "if", "self", ".", "data_parallel_rank", ">", "0", ":", "\n", "                    ", "last_optim_state", "=", "state", ".", "get", "(", "\"last_optimizer_state\"", ",", "None", ")", "\n", "\n", "# load model parameters", "\n", "", "", "try", ":", "\n", "                ", "self", ".", "get_model", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ",", "model_cfg", "=", "self", ".", "cfg", ".", "model", "\n", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "                    ", "self", ".", "get_criterion", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"criterion\"", "]", ",", "strict", "=", "True", "\n", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Cannot load model parameters from checkpoint {}; \"", "\n", "\"please ensure that the architectures match.\"", ".", "format", "(", "filename", ")", "\n", ")", "\n", "", "extra_state", "=", "state", "[", "\"extra_state\"", "]", "\n", "self", ".", "_optim_history", "=", "state", "[", "\"optimizer_history\"", "]", "\n", "\n", "", "if", "last_optim_state", "is", "not", "None", "and", "not", "reset_optimizer", ":", "\n", "# rebuild optimizer after loading model, since params may have changed", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "\n", "# only reload optimizer and lr_scheduler if they match", "\n", "last_optim", "=", "self", ".", "_optim_history", "[", "-", "1", "]", "\n", "assert", "(", "\n", "last_optim", "[", "\"criterion_name\"", "]", "==", "self", ".", "get_criterion", "(", ")", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Criterion does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "assert", "(", "\n", "last_optim", "[", "\"optimizer_name\"", "]", "==", "self", ".", "optimizer", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Optimizer does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "\n", "if", "not", "reset_lr_scheduler", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "load_state_dict", "(", "last_optim", "[", "\"lr_scheduler_state\"", "]", ")", "\n", "\n", "", "if", "not", "load_on_all_ranks", "and", "is_distributed", ":", "\n", "                ", "last_optim_state", "=", "self", ".", "optimizer", ".", "broadcast_global_state_dict", "(", "\n", "last_optim_state", "\n", ")", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "last_optim_state", ",", "optimizer_overrides", ")", "\n", "\n", "self", ".", "set_num_updates", "(", "last_optim", "[", "\"num_updates\"", "]", ")", "\n", "\n", "", "if", "extra_state", "is", "not", "None", ":", "\n", "            ", "itr_state", "=", "extra_state", "[", "\"train_iterator\"", "]", "\n", "epoch", "=", "itr_state", "[", "\"epoch\"", "]", "\n", "\n", "if", "\"previous_training_time\"", "in", "extra_state", ":", "\n", "                ", "self", ".", "_previous_training_time", "=", "extra_state", "[", "\"previous_training_time\"", "]", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "self", ".", "lr_step", "(", "epoch", ")", "\n", "\n", "if", "itr_state", ".", "get", "(", "\"version\"", ",", "1", ")", ">=", "2", "and", "itr_state", "[", "\"iterations_in_epoch\"", "]", "==", "0", ":", "\n", "# reset meters at start of epoch", "\n", "                ", "reset_meters", "=", "True", "\n", "\n", "", "if", "\"metrics\"", "in", "extra_state", "and", "not", "reset_meters", ":", "\n", "                ", "metrics", ".", "load_state_dict", "(", "extra_state", "[", "\"metrics\"", "]", ")", "\n", "\n", "# reset TimeMeters, since their start times don't make sense anymore", "\n", "for", "meter", "in", "metrics", ".", "get_meters", "(", "\"default\"", ")", ":", "\n", "                    ", "if", "isinstance", "(", "meter", ",", "meters", ".", "TimeMeter", ")", ":", "\n", "                        ", "meter", ".", "reset", "(", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "\n", "\"Loaded checkpoint {} (epoch {} @ {} updates)\"", ".", "format", "(", "\n", "filename", ",", "epoch", ",", "self", ".", "get_num_updates", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"No existing checkpoint found {}\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "", "return", "extra_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_train_iterator": [[411, 450], ["trainer.Trainer.task.get_batch_iterator", "trainer.Trainer.reset_dummy_batch", "logger.info", "trainer.Trainer.task.load_dataset", "trainer.Trainer.task.dataset", "fairseq.utils.resolve_max_positions", "trainer.Trainer.task.max_positions", "trainer.Trainer.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.reset_dummy_batch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.load_dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "get_train_iterator", "(", "\n", "self", ",", "\n", "epoch", ",", "\n", "combine", "=", "True", ",", "\n", "load_dataset", "=", "True", ",", "\n", "data_selector", "=", "None", ",", "\n", "shard_batch_itr", "=", "True", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return an EpochBatchIterator over the training set for a given epoch.\"\"\"", "\n", "if", "load_dataset", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading train data for epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "task", ".", "load_dataset", "(", "\n", "self", ".", "cfg", ".", "dataset", ".", "train_subset", ",", "\n", "epoch", "=", "epoch", ",", "\n", "combine", "=", "combine", ",", "\n", "data_selector", "=", "data_selector", ",", "\n", ")", "\n", "", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "dataset", "(", "self", ".", "cfg", ".", "dataset", ".", "train_subset", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "model", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "True", ",", "\n", "required_batch_size_multiple", "=", "self", ".", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "self", ".", "data_parallel_world_size", "if", "shard_batch_itr", "else", "1", ",", "\n", "shard_id", "=", "self", ".", "data_parallel_rank", "if", "shard_batch_itr", "else", "0", ",", "\n", "num_workers", "=", "self", ".", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "data_buffer_size", "=", "self", ".", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", "disable_iterator_cache", "=", "disable_iterator_cache", ",", "\n", ")", "\n", "self", ".", "reset_dummy_batch", "(", "batch_iterator", ".", "first_batch", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_valid_iterator": [[451, 479], ["trainer.Trainer.task.get_batch_iterator", "trainer.Trainer.reset_dummy_batch", "trainer.Trainer.task.dataset", "fairseq.utils.resolve_max_positions", "trainer.Trainer.task.max_positions", "trainer.Trainer.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.get_batch_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.reset_dummy_batch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "get_valid_iterator", "(", "\n", "self", ",", "\n", "subset", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return an EpochBatchIterator over given validation subset for a given epoch.\"\"\"", "\n", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "dataset", "(", "subset", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens_valid", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size_valid", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "model", ".", "max_positions", "(", ")", ",", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "self", ".", "cfg", ".", "dataset", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", "required_batch_size_multiple", "=", "self", ".", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "self", ".", "data_parallel_world_size", ",", "\n", "shard_id", "=", "self", ".", "data_parallel_rank", ",", "\n", "num_workers", "=", "self", ".", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "# always pass a fixed \"epoch\" to keep validation data consistent", "\n", "# across training epochs", "\n", "epoch", "=", "1", ",", "\n", "data_buffer_size", "=", "self", ".", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", "disable_iterator_cache", "=", "disable_iterator_cache", ",", "\n", ")", "\n", "self", ".", "reset_dummy_batch", "(", "batch_iterator", ".", "first_batch", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.begin_epoch": [[480, 497], ["logger.info", "trainer.Trainer.lr_step_begin_epoch", "trainer.Trainer.task.begin_epoch", "trainer.Trainer.quantizer.begin_epoch", "trainer.Trainer.get_model", "xm.rendezvous", "xm.mark_step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_begin_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model"], ["", "def", "begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each epoch.\"\"\"", "\n", "logger", ".", "info", "(", "\"begin training epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "self", ".", "lr_step_begin_epoch", "(", "epoch", ")", "\n", "\n", "if", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "quantizer", ".", "begin_epoch", "(", "epoch", ")", "\n", "\n", "# task specific setup per epoch", "\n", "", "self", ".", "task", ".", "begin_epoch", "(", "epoch", ",", "self", ".", "get_model", "(", ")", ")", "\n", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "rendezvous", "(", "\"begin_epoch\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.begin_valid_epoch": [[498, 503], ["trainer.Trainer.task.begin_valid_epoch", "trainer.Trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_valid_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model"], ["", "", "def", "begin_valid_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each validation epoch.\"\"\"", "\n", "\n", "# task specific setup per validation epoch", "\n", "self", ".", "task", ".", "begin_valid_epoch", "(", "epoch", ",", "self", ".", "get_model", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.reset_dummy_batch": [[504, 506], ["None"], "methods", ["None"], ["", "def", "reset_dummy_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "_dummy_batch", "=", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.train_step": [[507, 777], ["fairseq.logging.metrics.aggregate", "trainer.Trainer._set_seed", "trainer.Trainer.model.train", "trainer.Trainer.criterion.train", "trainer.Trainer.zero_grad", "fairseq.logging.metrics.log_start_time", "enumerate", "torch.is_tensor", "trainer.Trainer._sync_stats", "hasattr", "fairseq.logging.metrics.log_stop_time", "trainer.Trainer._prepare_sample", "torch.is_tensor", "float.float", "float", "trainer.Trainer._local_cumulative_training_time", "trainer.Trainer._aggregate_logging_outputs", "hasattr", "trainer.Trainer.set_num_updates", "fairseq.logging.metrics.log_scalar", "logging_outputs.append", "xm.mark_step", "float.zero_", "torch.autograd.profiler.record_function", "trainer.Trainer.optimizer.all_reduce_grads", "fairseq.utils.has_parameters", "torch.autograd.profiler.record_function", "trainer.Trainer.optimizer.multiply_grads", "torch.autograd.profiler.record_function", "trainer.Trainer.clip_grad_norm", "torch.autograd.profiler.record_function", "trainer.Trainer.task.optimizer_step", "trainer.Trainer.zero_grad", "logger.info", "torch.tensor().cuda", "trainer.Trainer.zero_grad", "trainer.Trainer.model.perform_additional_optimizer_actions", "trainer.Trainer.model.perform_additional_optimizer_actions", "xm.mark_step", "trainer.Trainer._check_xla_compilation", "trainer.Trainer._reduce_and_log_stats", "hasattr", "trainer.Trainer.model.no_sync", "contextlib.ExitStack", "trainer.Trainer.train_step.maybe_no_sync"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._set_seed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_start_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._sync_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_stop_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._local_cumulative_training_time", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._aggregate_logging_outputs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.optimizer_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._check_xla_compilation", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._reduce_and_log_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync"], ["", "@", "metrics", ".", "aggregate", "(", "\"train\"", ")", "\n", "def", "train_step", "(", "self", ",", "samples", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward, backward and parameter update.\"\"\"", "\n", "self", ".", "_set_seed", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "criterion", ".", "train", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "\n", "metrics", ".", "log_start_time", "(", "\"train_wall\"", ",", "priority", "=", "800", ",", "round", "=", "0", ")", "\n", "\n", "# forward and backward pass", "\n", "logging_outputs", ",", "sample_size", ",", "ooms", "=", "[", "]", ",", "0", ",", "0", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "# delayed update loop", "\n", "            ", "sample", ",", "is_dummy_batch", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "\n", "def", "maybe_no_sync", "(", ")", ":", "\n", "                ", "\"\"\"\n                Whenever *samples* contains more than one mini-batch, we\n                want to accumulate gradients locally and only call\n                all-reduce in the last backwards pass.\n                \"\"\"", "\n", "if", "(", "\n", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "hasattr", "(", "self", ".", "model", ",", "\"no_sync\"", ")", "\n", "and", "i", "<", "len", "(", "samples", ")", "-", "1", "\n", ")", ":", "\n", "                    ", "return", "self", ".", "model", ".", "no_sync", "(", ")", "\n", "", "else", ":", "\n", "                    ", "return", "contextlib", ".", "ExitStack", "(", ")", "# dummy contextmanager", "\n", "\n", "", "", "try", ":", "\n", "                ", "with", "maybe_no_sync", "(", ")", ":", "\n", "# forward and backward", "\n", "                    ", "loss", ",", "sample_size_i", ",", "logging_output", "=", "self", ".", "task", ".", "train_step", "(", "\n", "sample", "=", "sample", ",", "\n", "model", "=", "self", ".", "model", ",", "\n", "criterion", "=", "self", ".", "criterion", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "update_num", "=", "self", ".", "get_num_updates", "(", ")", ",", "\n", "ignore_grad", "=", "is_dummy_batch", ",", "\n", ")", "\n", "del", "loss", "\n", "\n", "", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "sample_size", "+=", "sample_size_i", "\n", "\n", "# emptying the CUDA cache after the first step can", "\n", "# reduce the chance of OOM", "\n", "if", "self", ".", "cuda", "and", "self", ".", "get_num_updates", "(", ")", "==", "0", ":", "\n", "                    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "raise_oom", ":", "\n", "                        ", "raise", "e", "\n", "", "logger", ".", "warning", "(", "\n", "\"attempting to recover from OOM in forward/backward pass\"", "\n", ")", "\n", "ooms", "+=", "1", "\n", "self", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                        ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "                        ", "return", "None", "\n", "", "", "else", ":", "\n", "                    ", "raise", "e", "\n", "\n", "", "", "if", "self", ".", "tpu", "and", "i", "<", "len", "(", "samples", ")", "-", "1", ":", "\n", "# tpu-comment: every XLA operation before marking step is", "\n", "# appended to the IR graph, and processing too many batches", "\n", "# before marking step can lead to OOM errors.", "\n", "# To handle gradient accumulation use case, we explicitly", "\n", "# mark step here for every forward pass without a backward pass", "\n", "                ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "", "if", "is_dummy_batch", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "                ", "sample_size", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "sample_size", "*=", "0.0", "\n", "\n", "", "", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "            ", "sample_size", "=", "sample_size", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "sample_size", "=", "float", "(", "sample_size", ")", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "if", "self", ".", "_sync_stats", "(", ")", ":", "\n", "            ", "train_time", "=", "self", ".", "_local_cumulative_training_time", "(", ")", "\n", "logging_outputs", ",", "(", "\n", "sample_size", ",", "\n", "ooms", ",", "\n", "total_train_time", ",", "\n", ")", "=", "self", ".", "_aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "ooms", ",", "\n", "train_time", ",", "\n", "ignore", "=", "is_dummy_batch", ",", "\n", ")", "\n", "self", ".", "_cumulative_training_time", "=", "(", "\n", "total_train_time", "/", "self", ".", "data_parallel_world_size", "\n", ")", "\n", "\n", "", "overflow", "=", "False", "\n", "try", ":", "\n", "            ", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"reduce-grads\"", ")", ":", "\n", "# reduce gradients across workers", "\n", "                ", "self", ".", "optimizer", ".", "all_reduce_grads", "(", "self", ".", "model", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "criterion", ")", ":", "\n", "                    ", "self", ".", "optimizer", ".", "all_reduce_grads", "(", "self", ".", "criterion", ")", "\n", "\n", "", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"multiply-grads\"", ")", ":", "\n", "# multiply gradients by (data_parallel_size / sample_size) since", "\n", "# DDP normalizes by the number of data parallel workers for", "\n", "# improved fp16 precision.", "\n", "# Thus we get (sum_of_gradients / sample_size) at the end.", "\n", "# In case of fp16, this step also undoes loss scaling.", "\n", "# (Debugging note: Some optimizers perform this scaling on the", "\n", "# fly, so inspecting model.parameters() or optimizer.params may", "\n", "# still show the original, unscaled gradients.)", "\n", "                ", "numer", "=", "(", "\n", "self", ".", "data_parallel_world_size", "\n", "if", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "or", "self", ".", "_sync_stats", "(", ")", "\n", "else", "1", "\n", ")", "\n", "self", ".", "optimizer", ".", "multiply_grads", "(", "numer", "/", "(", "sample_size", "or", "1.0", ")", ")", "\n", "# Note: (sample_size or 1.0) handles the case of a zero gradient, in a", "\n", "# way that avoids CPU/device transfers in case sample_size is a GPU or", "\n", "# TPU object. The assumption is that the gradient itself is also 0.", "\n", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"clip-grads\"", ")", ":", "\n", "# clip grads", "\n", "                ", "grad_norm", "=", "self", ".", "clip_grad_norm", "(", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ")", "\n", "\n", "# check that grad norms are consistent across workers", "\n", "# on tpu check tensor is slow", "\n", "", "if", "not", "self", ".", "tpu", ":", "\n", "                ", "if", "(", "\n", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "\n", "and", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_wrapper", "!=", "\"SlowMo\"", "\n", ")", ":", "\n", "                    ", "self", ".", "_check_grad_norms", "(", "grad_norm", ")", "\n", "", "if", "not", "torch", ".", "isfinite", "(", "grad_norm", ")", ".", "all", "(", ")", ":", "\n", "# check local gradnorm single GPU case, trigger NanDetector", "\n", "                    ", "raise", "FloatingPointError", "(", "\"gradients are Nan/Inf\"", ")", "\n", "\n", "", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"optimizer\"", ")", ":", "\n", "# take an optimization step", "\n", "                ", "self", ".", "task", ".", "optimizer_step", "(", "\n", "self", ".", "optimizer", ",", "model", "=", "self", ".", "model", ",", "update_num", "=", "self", ".", "get_num_updates", "(", ")", "\n", ")", "\n", "\n", "", "", "except", "FloatingPointError", ":", "\n", "# re-run the forward and backward pass with hooks attached to print", "\n", "# out where it fails", "\n", "            ", "self", ".", "zero_grad", "(", ")", "\n", "with", "NanDetector", "(", "self", ".", "get_model", "(", ")", ")", ":", "\n", "                ", "for", "_", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "                    ", "sample", ",", "_", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "self", ".", "task", ".", "train_step", "(", "\n", "sample", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "criterion", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "get_num_updates", "(", ")", ",", "\n", "ignore_grad", "=", "False", ",", "\n", ")", "\n", "", "", "raise", "\n", "", "except", "OverflowError", "as", "e", ":", "\n", "            ", "overflow", "=", "True", "\n", "logger", ".", "info", "(", "f\"NOTE: gradient overflow detected, ignoring gradient, {str(e)}\"", ")", "\n", "grad_norm", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "cuda", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                ", "self", ".", "_log_oom", "(", "e", ")", "\n", "logger", ".", "error", "(", "\"OOM during optimization, irrecoverable\"", ")", "\n", "", "raise", "e", "\n", "\n", "# Some distributed wrappers (e.g., SlowMo) need access to the optimizer after the step", "\n", "", "if", "hasattr", "(", "self", ".", "model", ",", "\"perform_additional_optimizer_actions\"", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"fp32_params\"", ")", ":", "\n", "                ", "self", ".", "model", ".", "perform_additional_optimizer_actions", "(", "\n", "self", ".", "optimizer", ".", "optimizer", ",", "self", ".", "optimizer", ".", "fp32_params", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "model", ".", "perform_additional_optimizer_actions", "(", "\n", "self", ".", "optimizer", ".", "optimizer", "\n", ")", "\n", "\n", "", "", "logging_output", "=", "None", "\n", "if", "(", "\n", "not", "overflow", "\n", "or", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_wrapper", "==", "\"SlowMo\"", "\n", ")", ":", "\n", "            ", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "\n", "if", "self", ".", "tpu", ":", "\n", "# mark step on TPUs", "\n", "                ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "# only log stats every log_interval steps", "\n", "# this causes wps to be misreported when log_interval > 1", "\n", "logging_output", "=", "{", "}", "\n", "if", "self", ".", "get_num_updates", "(", ")", "%", "self", ".", "cfg", ".", "common", ".", "log_interval", "==", "0", ":", "\n", "# log memory usage", "\n", "                    ", "mem_info", "=", "xm", ".", "get_memory_info", "(", "self", ".", "device", ")", "\n", "gb_free", "=", "mem_info", "[", "\"kb_free\"", "]", "/", "1024", "/", "1024", "\n", "gb_total", "=", "mem_info", "[", "\"kb_total\"", "]", "/", "1024", "/", "1024", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"gb_free\"", ",", "\n", "gb_free", ",", "\n", "priority", "=", "1500", ",", "\n", "round", "=", "1", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"gb_total\"", ",", "\n", "gb_total", ",", "\n", "priority", "=", "1600", ",", "\n", "round", "=", "1", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "\n", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "grad_norm", ",", "\n", ")", "\n", "\n", "# log whenever there's an XLA compilation, since these", "\n", "# slow down training and may indicate opportunities for", "\n", "# optimization", "\n", "", "self", ".", "_check_xla_compilation", "(", ")", "\n", "", "else", ":", "\n", "# log stats", "\n", "                ", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "grad_norm", ",", "\n", ")", "\n", "\n", "# clear CUDA cache to reduce memory fragmentation", "\n", "if", "(", "\n", "self", ".", "cuda", "\n", "and", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", ">", "0", "\n", "and", "(", "\n", "(", "self", ".", "get_num_updates", "(", ")", "+", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", "-", "1", ")", "\n", "%", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", "\n", ")", "\n", "==", "0", "\n", ")", ":", "\n", "                    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"loss_scale\"", ",", "\n", "self", ".", "optimizer", ".", "scaler", ".", "loss_scale", ",", "\n", "priority", "=", "700", ",", "\n", "round", "=", "4", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "\n", "", "metrics", ".", "log_stop_time", "(", "\"train_wall\"", ")", "\n", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.valid_step": [[778, 831], ["fairseq.logging.metrics.aggregate", "trainer.Trainer._reduce_and_log_stats", "xm.rendezvous", "xm.mark_step", "torch.no_grad", "trainer.Trainer.model.eval", "trainer.Trainer.criterion.eval", "trainer.Trainer._prepare_sample", "trainer.Trainer._aggregate_logging_outputs", "trainer.Trainer.task.valid_step", "torch.is_tensor", "sample_size.zero_", "str", "trainer.Trainer._log_oom", "logger.warning", "trainer.Trainer.model.parameters", "trainer.Trainer.valid_step", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._reduce_and_log_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._aggregate_logging_outputs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._log_oom", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step"], ["", "@", "metrics", ".", "aggregate", "(", "\"valid\"", ")", "\n", "def", "valid_step", "(", "self", ",", "sample", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward pass in evaluation mode.\"\"\"", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "rendezvous", "(", "\"valid_step\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "criterion", ".", "eval", "(", ")", "\n", "\n", "sample", ",", "is_dummy_batch", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "\n", "try", ":", "\n", "                ", "_loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "task", ".", "valid_step", "(", "\n", "sample", ",", "self", ".", "model", ",", "self", ".", "criterion", "\n", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "not", "raise_oom", ":", "\n", "                        ", "logger", ".", "warning", "(", "\n", "\"ran out of memory in validation step, retrying batch\"", "\n", ")", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                                ", "p", ".", "grad", "=", "None", "# free some memory", "\n", "", "", "if", "self", ".", "cuda", ":", "\n", "                            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "return", "self", ".", "valid_step", "(", "sample", ",", "raise_oom", "=", "True", ")", "\n", "", "", "raise", "e", "\n", "\n", "", "logging_outputs", "=", "[", "logging_output", "]", "\n", "if", "is_dummy_batch", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "                    ", "sample_size", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_size", "*=", "0.0", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "", "", "if", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "            ", "logging_outputs", ",", "(", "sample_size", ",", ")", "=", "self", ".", "_aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "ignore", "=", "is_dummy_batch", ",", "\n", ")", "\n", "\n", "# log validation stats", "\n", "", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "logging_outputs", ",", "sample_size", ")", "\n", "\n", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.zero_grad": [[832, 834], ["trainer.Trainer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_begin_epoch": [[835, 840], ["trainer.Trainer.lr_scheduler.step_begin_epoch", "trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_begin_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "lr_step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Adjust the learning rate at the beginning of the epoch.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "step_begin_epoch", "(", "epoch", ")", "\n", "# prefer updating the LR based on the number of steps", "\n", "return", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step": [[841, 846], ["trainer.Trainer.lr_scheduler.step", "trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "lr_step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adjust the learning rate at the end of the epoch.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# prefer updating the LR based on the number of steps", "\n", "return", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_update": [[847, 857], ["trainer.Trainer.lr_scheduler.step_update", "isinstance", "trainer.Trainer.get_num_updates", "new_lr.get.get.items", "new_lr.get.get.get", "fairseq.logging.metrics.log_scalar", "fairseq.logging.metrics.log_scalar", "next", "iter", "new_lr.get.get.values"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar"], ["", "def", "lr_step_update", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "new_lr", "=", "self", ".", "lr_scheduler", ".", "step_update", "(", "self", ".", "get_num_updates", "(", ")", ")", "\n", "if", "isinstance", "(", "new_lr", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "new_lr", ".", "items", "(", ")", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "f\"lr_{k}\"", ",", "v", ",", "weight", "=", "0", ",", "priority", "=", "300", ")", "\n", "", "new_lr", "=", "new_lr", ".", "get", "(", "\"default\"", ",", "next", "(", "iter", "(", "new_lr", ".", "values", "(", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\"lr\"", ",", "new_lr", ",", "weight", "=", "0", ",", "priority", "=", "300", ")", "\n", "", "return", "new_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_lr": [[858, 861], ["trainer.Trainer.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the current learning rate.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_model": [[862, 865], ["None"], "methods", ["None"], ["", "def", "get_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) model instance.\"\"\"", "\n", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion": [[866, 869], ["None"], "methods", ["None"], ["", "def", "get_criterion", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) criterion instance.\"\"\"", "\n", "return", "self", ".", "_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_meter": [[870, 910], ["fairseq.logging.metrics.get_meters", "trainer.Trainer._warn_once.add", "fairseq.utils.deprecation_warning", "fairseq.logging.metrics.get_meters.get", "fairseq.logging.meters.AverageMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.TimeMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.TimeMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.AverageMeter", "fairseq.logging.meters.AverageMeter", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter"], ["", "def", "get_meter", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"[deprecated] Get a specific meter by name.\"\"\"", "\n", "from", "fairseq", "import", "meters", "\n", "\n", "if", "\"get_meter\"", "not", "in", "self", ".", "_warn_once", ":", "\n", "            ", "self", ".", "_warn_once", ".", "add", "(", "\"get_meter\"", ")", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Trainer.get_meter is deprecated. Please use fairseq.metrics instead.\"", "\n", ")", "\n", "\n", "", "train_meters", "=", "metrics", ".", "get_meters", "(", "\"train\"", ")", "\n", "if", "train_meters", "is", "None", ":", "\n", "            ", "train_meters", "=", "{", "}", "\n", "\n", "", "if", "name", "==", "\"train_loss\"", "and", "\"loss\"", "in", "train_meters", ":", "\n", "            ", "return", "train_meters", "[", "\"loss\"", "]", "\n", "", "elif", "name", "==", "\"train_nll_loss\"", ":", "\n", "# support for legacy train.py, which assumed this meter is", "\n", "# always initialized", "\n", "            ", "m", "=", "train_meters", ".", "get", "(", "\"nll_loss\"", ",", "None", ")", "\n", "return", "m", "or", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "==", "\"wall\"", ":", "\n", "# support for legacy train.py, which assumed this meter is", "\n", "# always initialized", "\n", "            ", "m", "=", "metrics", ".", "get_meter", "(", "\"default\"", ",", "\"wall\"", ")", "\n", "return", "m", "or", "meters", ".", "TimeMeter", "(", ")", "\n", "", "elif", "name", "==", "\"wps\"", ":", "\n", "            ", "m", "=", "metrics", ".", "get_meter", "(", "\"train\"", ",", "\"wps\"", ")", "\n", "return", "m", "or", "meters", ".", "TimeMeter", "(", ")", "\n", "", "elif", "name", "in", "{", "\"valid_loss\"", ",", "\"valid_nll_loss\"", "}", ":", "\n", "# support for legacy train.py, which assumed these meters", "\n", "# are always initialized", "\n", "            ", "k", "=", "name", "[", "len", "(", "\"valid_\"", ")", ":", "]", "\n", "m", "=", "metrics", ".", "get_meter", "(", "\"valid\"", ",", "k", ")", "\n", "return", "m", "or", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "==", "\"oom\"", ":", "\n", "            ", "return", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "in", "train_meters", ":", "\n", "            ", "return", "train_meters", "[", "name", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_num_updates": [[911, 914], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.set_num_updates": [[915, 922], ["trainer.Trainer.lr_step_update", "fairseq.logging.metrics.log_scalar", "trainer.Trainer.quantizer.step_update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step_update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_update"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "self", ".", "lr_step_update", "(", ")", "\n", "if", "self", ".", "quantizer", ":", "\n", "            ", "self", ".", "quantizer", ".", "step_update", "(", "self", ".", "_num_updates", ")", "\n", "", "metrics", ".", "log_scalar", "(", "\"num_updates\"", ",", "self", ".", "_num_updates", ",", "weight", "=", "0", ",", "priority", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.clip_grad_norm": [[923, 925], ["trainer.Trainer.optimizer.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm"], ["", "def", "clip_grad_norm", "(", "self", ",", "clip_norm", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "clip_norm", ",", "aggregate_norm_fn", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.cumulative_training_time": [[926, 932], ["trainer.Trainer._local_cumulative_training_time"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._local_cumulative_training_time"], ["", "def", "cumulative_training_time", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_cumulative_training_time", "is", "None", ":", "\n", "# single GPU", "\n", "            ", "return", "self", ".", "_local_cumulative_training_time", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_cumulative_training_time", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._local_cumulative_training_time": [[933, 936], ["time.time"], "methods", ["None"], ["", "", "def", "_local_cumulative_training_time", "(", "self", ")", ":", "\n", "        ", "\"\"\"Aggregate training time in seconds.\"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "_start_time", "+", "self", ".", "_previous_training_time", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._prepare_sample": [[937, 984], ["Exception", "trainer.Trainer._prepare_sample", "fairseq.utils.apply_to_sample", "fairseq.utils.apply_to_sample", "len", "fairseq.utils.move_to_cuda", "fairseq.utils.move_to_cuda", "t.half", "t.to", "len", "fairseq.utils.move_to_cuda"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cuda"], ["", "def", "_prepare_sample", "(", "self", ",", "sample", ",", "is_dummy", "=", "False", ")", ":", "\n", "        ", "if", "sample", "==", "\"DUMMY\"", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"Trying to use an uninitialized 'dummy' batch. This usually indicates \"", "\n", "\"that the total number of batches is smaller than the number of \"", "\n", "\"participating GPUs. Try reducing the batch size or using fewer GPUs.\"", "\n", ")", "\n", "\n", "", "if", "sample", "is", "None", "or", "len", "(", "sample", ")", "==", "0", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "_dummy_batch", "is", "not", "None", "and", "len", "(", "self", ".", "_dummy_batch", ")", ">", "0", "\n", ")", ",", "\"Invalid dummy batch: {}\"", ".", "format", "(", "self", ".", "_dummy_batch", ")", "\n", "sample", ",", "_", "=", "self", ".", "_prepare_sample", "(", "self", ".", "_dummy_batch", ",", "is_dummy", "=", "True", ")", "\n", "return", "sample", ",", "True", "\n", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "if", "self", ".", "pipeline_model_parallel", ":", "\n", "                ", "if", "\"target\"", "in", "sample", ":", "\n", "                    ", "sample", "[", "\"target\"", "]", "=", "utils", ".", "move_to_cuda", "(", "\n", "sample", "[", "\"target\"", "]", ",", "device", "=", "self", ".", "last_device", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "\n", "", "", "elif", "self", ".", "tpu", "and", "is_dummy", ":", "\n", "# the dummy batch may not be on the appropriate device", "\n", "            ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "def", "apply_half", "(", "t", ")", ":", "\n", "            ", "if", "t", ".", "dtype", "is", "torch", ".", "float32", ":", "\n", "                ", "return", "t", ".", "half", "(", ")", "\n", "", "return", "t", "\n", "\n", "", "def", "apply_bfloat16", "(", "t", ")", ":", "\n", "            ", "if", "t", ".", "dtype", "is", "torch", ".", "float32", ":", "\n", "                ", "return", "t", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "", "return", "t", "\n", "\n", "", "if", "self", ".", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "sample", "=", "utils", ".", "apply_to_sample", "(", "apply_half", ",", "sample", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "sample", "=", "utils", ".", "apply_to_sample", "(", "apply_bfloat16", ",", "sample", ")", "\n", "\n", "", "if", "self", ".", "_dummy_batch", "==", "\"DUMMY\"", ":", "\n", "            ", "self", ".", "_dummy_batch", "=", "sample", "\n", "\n", "", "return", "sample", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._set_seed": [[985, 990], ["fairseq.utils.set_torch_seed", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_set_seed", "(", "self", ")", ":", "\n", "# Set seed based on args.seed and the update number so that we get", "\n", "# reproducible results when resuming from checkpoints", "\n", "        ", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", "+", "self", ".", "get_num_updates", "(", ")", "\n", "utils", ".", "set_torch_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._sync_stats": [[991, 1004], ["trainer.Trainer.get_num_updates", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_sync_stats", "(", "self", ")", ":", "\n", "# Return True if it's using multiple GPUs and DDP or multiple GPUs with", "\n", "# BMUF and it's a bmuf sync with warmup iterations completed before.", "\n", "        ", "if", "self", ".", "data_parallel_world_size", "==", "1", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "            ", "return", "(", "\n", "self", ".", "get_num_updates", "(", ")", "+", "1", "\n", ")", "%", "self", ".", "cfg", ".", "bmuf", ".", "global_sync_iter", "==", "0", "and", "(", "\n", "self", ".", "get_num_updates", "(", ")", "+", "1", "\n", ")", ">", "self", ".", "cfg", ".", "bmuf", ".", "warmup_iterations", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._log_oom": [[1005, 1012], ["logger.warning", "sys.stderr.flush", "torch.cuda.is_available", "hasattr", "range", "torch.cuda.device_count", "logger.warning", "torch.cuda.memory_summary"], "methods", ["None"], ["", "", "def", "_log_oom", "(", "self", ",", "exc", ")", ":", "\n", "        ", "msg", "=", "\"OOM: Ran out of memory with exception: {}\"", ".", "format", "(", "exc", ")", "\n", "logger", ".", "warning", "(", "msg", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "hasattr", "(", "torch", ".", "cuda", ",", "\"memory_summary\"", ")", ":", "\n", "            ", "for", "device_idx", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "torch", ".", "cuda", ".", "memory_summary", "(", "device", "=", "device_idx", ")", ")", "\n", "", "", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._aggregate_logging_outputs": [[1013, 1026], ["trainer.Trainer.task.__class__.logging_outputs_can_be_summed", "trainer.Trainer.get_criterion", "trainer.Trainer._fast_stat_sync_sum", "trainer.Trainer._all_gather_list_sync"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.logging_outputs_can_be_summed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._fast_stat_sync_sum", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._all_gather_list_sync"], ["", "def", "_aggregate_logging_outputs", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "task", ".", "__class__", ".", "logging_outputs_can_be_summed", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "            ", "return", "self", ".", "_fast_stat_sync_sum", "(", "\n", "logging_outputs", ",", "*", "extra_stats_to_sum", ",", "ignore", "=", "ignore", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_all_gather_list_sync", "(", "\n", "logging_outputs", ",", "*", "extra_stats_to_sum", ",", "ignore", "=", "ignore", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._all_gather_list_sync": [[1028, 1055], ["list", "list", "zip", "itertools.chain.from_iterable", "sum", "fairseq.distributed_utils.all_gather_list", "list", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_gather_list"], ["", "", "def", "_all_gather_list_sync", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Sync logging outputs across workers. all_gather_list_sync is\n        suitable when logging outputs are complex types.\n        \"\"\"", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "ignore", ":", "\n", "            ", "logging_outputs", "=", "[", "]", "\n", "", "results", "=", "list", "(", "\n", "zip", "(", "\n", "*", "distributed_utils", ".", "all_gather_list", "(", "\n", "[", "logging_outputs", "]", "+", "list", "(", "extra_stats_to_sum", ")", ",", "\n", "max_size", "=", "getattr", "(", "self", ".", "cfg", ".", "common", ",", "\"all_gather_list_size\"", ",", "16384", ")", ",", "\n", "group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "logging_outputs", ",", "extra_stats_to_sum", "=", "results", "[", "0", "]", ",", "results", "[", "1", ":", "]", "\n", "logging_outputs", "=", "list", "(", "chain", ".", "from_iterable", "(", "logging_outputs", ")", ")", "\n", "extra_stats_to_sum", "=", "[", "sum", "(", "s", ")", "for", "s", "in", "extra_stats_to_sum", "]", "\n", "return", "logging_outputs", ",", "extra_stats_to_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._fast_stat_sync_sum": [[1056, 1095], ["enumerate", "fairseq.distributed_utils.all_reduce_dict", "len", "list", "logging_outputs[].keys", "range", "sum", "len", "str", "torch.is_tensor", "torch.zeros_like", "str"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce_dict"], ["", "def", "_fast_stat_sync_sum", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Sync logging outputs across workers. fast_stat_sync_sum is\n        faster than all_gather_list_sync, but is only suitable when\n        logging outputs are scalars and can be summed. Note that\n        *logging_outputs* cannot contain any nested dicts/lists.\n        \"\"\"", "\n", "data", "=", "{", "}", "\n", "for", "i", ",", "stat", "in", "enumerate", "(", "extra_stats_to_sum", ")", ":", "\n", "            ", "data", "[", "\"extra_stats_\"", "+", "str", "(", "i", ")", "]", "=", "stat", "\n", "", "if", "len", "(", "logging_outputs", ")", ">", "0", ":", "\n", "            ", "log_keys", "=", "list", "(", "logging_outputs", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "log_keys", ":", "\n", "                ", "if", "not", "ignore", ":", "\n", "                    ", "v", "=", "sum", "(", "log", "[", "k", "]", "for", "log", "in", "logging_outputs", "if", "k", "in", "log", ")", "\n", "", "else", ":", "\n", "                    ", "v", "=", "logging_outputs", "[", "0", "]", "[", "k", "]", "\n", "v", "=", "torch", ".", "zeros_like", "(", "v", ")", "if", "torch", ".", "is_tensor", "(", "v", ")", "else", "0", "\n", "", "data", "[", "\"logging_outputs_\"", "+", "k", "]", "=", "v", "\n", "", "", "else", ":", "\n", "            ", "log_keys", "=", "None", "\n", "\n", "", "data", "=", "distributed_utils", ".", "all_reduce_dict", "(", "\n", "data", ",", "device", "=", "self", ".", "device", ",", "group", "=", "self", ".", "data_parallel_process_group", "\n", ")", "\n", "\n", "extra_stats_to_sum", "=", "[", "\n", "data", "[", "\"extra_stats_\"", "+", "str", "(", "i", ")", "]", "for", "i", "in", "range", "(", "len", "(", "extra_stats_to_sum", ")", ")", "\n", "]", "\n", "if", "log_keys", "is", "not", "None", ":", "\n", "            ", "logging_outputs", "=", "[", "{", "k", ":", "data", "[", "\"logging_outputs_\"", "+", "k", "]", "for", "k", "in", "log_keys", "}", "]", "\n", "", "else", ":", "\n", "            ", "logging_outputs", "=", "[", "]", "\n", "", "return", "logging_outputs", ",", "extra_stats_to_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._check_grad_norms": [[1096, 1129], ["trainer.Trainer._grad_norm_buf.zero_", "fairseq.distributed_utils.all_reduce", "torch.max", "trainer.Trainer._check_grad_norms.is_consistent"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce"], ["", "def", "_check_grad_norms", "(", "self", ",", "grad_norm", ")", ":", "\n", "        ", "\"\"\"Check that grad norms are consistent across workers.\"\"\"", "\n", "if", "self", ".", "_grad_norm_buf", "is", "not", "None", ":", "\n", "            ", "self", ".", "_grad_norm_buf", ".", "zero_", "(", ")", "\n", "self", ".", "_grad_norm_buf", "[", "self", ".", "data_parallel_rank", "]", "=", "grad_norm", "\n", "distributed_utils", ".", "all_reduce", "(", "\n", "self", ".", "_grad_norm_buf", ",", "group", "=", "self", ".", "data_parallel_process_group", "\n", ")", "\n", "\n", "def", "is_consistent", "(", "tensor", ")", ":", "\n", "                ", "max_abs_diff", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "tensor", "-", "tensor", "[", "0", "]", ")", ")", "\n", "return", "(", "\n", "torch", ".", "isfinite", "(", "tensor", ")", ".", "all", "(", ")", "\n", "or", "(", "max_abs_diff", "/", "(", "tensor", "[", "0", "]", "+", "1e-6", ")", "<", "1e-6", ")", ".", "all", "(", ")", "\n", ")", "\n", "\n", "", "if", "not", "is_consistent", "(", "self", ".", "_grad_norm_buf", ")", ":", "\n", "                ", "pretty_detail", "=", "\"\\n\"", ".", "join", "(", "\n", "\"rank {:3d} = {:.8f}\"", ".", "format", "(", "r", ",", "n", ")", "\n", "for", "r", ",", "n", "in", "enumerate", "(", "self", ".", "_grad_norm_buf", ".", "tolist", "(", ")", ")", "\n", ")", "\n", "error_detail", "=", "\"grad_norm across the workers:\\n{}\\n\"", ".", "format", "(", "\n", "pretty_detail", "\n", ")", "\n", "# use FloatingPointError to trigger NanDetector", "\n", "raise", "FloatingPointError", "(", "\n", "\"Fatal error: gradients are inconsistent between workers. \"", "\n", "\"Try --ddp-backend=no_c10d. \"", "\n", "\"Or are you mixing up different generation of GPUs in training?\"", "\n", "+", "\"\\n\"", "\n", "+", "\"-\"", "*", "80", "\n", "+", "\"\\n{}\\n\"", ".", "format", "(", "error_detail", ")", "\n", "+", "\"-\"", "*", "80", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._reduce_and_log_stats": [[1131, 1174], ["fairseq.logging.metrics.log_speed", "fairseq.logging.metrics.log_scalar", "fairseq.logging.metrics.aggregate", "torch.isfinite", "fairseq.logging.metrics.log_scalar", "trainer.Trainer.task.reduce_metrics", "fairseq.logging.metrics.log_scalar", "agg.get_smoothed_values", "torch.is_tensor", "torch.where", "trainer.Trainer.get_criterion", "trainer.Trainer._warn_once.add", "logger.warning", "grad_norm.new_tensor", "grad_norm.new_tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_speed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_criterion"], ["", "", "", "def", "_reduce_and_log_stats", "(", "self", ",", "logging_outputs", ",", "sample_size", ",", "grad_norm", "=", "None", ")", ":", "\n", "        ", "if", "grad_norm", "is", "not", "None", "and", "(", "\n", "not", "torch", ".", "is_tensor", "(", "grad_norm", ")", "or", "torch", ".", "isfinite", "(", "grad_norm", ")", "\n", ")", ":", "\n", "            ", "metrics", ".", "log_speed", "(", "\"ups\"", ",", "1.0", ",", "priority", "=", "100", ",", "round", "=", "2", ")", "\n", "metrics", ".", "log_scalar", "(", "\"gnorm\"", ",", "grad_norm", ",", "priority", "=", "400", ",", "round", "=", "3", ")", "\n", "if", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ">", "0", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "\n", "\"clip\"", ",", "\n", "torch", ".", "where", "(", "\n", "grad_norm", ">", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ",", "\n", "grad_norm", ".", "new_tensor", "(", "100", ")", ",", "\n", "grad_norm", ".", "new_tensor", "(", "0", ")", ",", "\n", ")", ",", "\n", "priority", "=", "500", ",", "\n", "round", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "with", "metrics", ".", "aggregate", "(", ")", "as", "agg", ":", "\n", "            ", "if", "logging_outputs", "is", "not", "None", ":", "\n", "                ", "self", ".", "task", ".", "reduce_metrics", "(", "logging_outputs", ",", "self", ".", "get_criterion", "(", ")", ")", "\n", "del", "logging_outputs", "\n", "\n", "# extra warning for criterions that don't properly log a loss value", "\n", "", "if", "\"loss\"", "not", "in", "agg", ":", "\n", "                ", "if", "\"loss\"", "not", "in", "self", ".", "_warn_once", ":", "\n", "                    ", "self", ".", "_warn_once", ".", "add", "(", "\"loss\"", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Criterion.reduce_metrics did not log a 'loss' value, \"", "\n", "\"which may break some functionality\"", "\n", ")", "\n", "", "metrics", ".", "log_scalar", "(", "\"loss\"", ",", "-", "1", ")", "\n", "\n", "# support legacy interface", "\n", "", "if", "self", ".", "tpu", ":", "\n", "                ", "logging_output", "=", "{", "}", "\n", "", "else", ":", "\n", "                ", "logging_output", "=", "agg", ".", "get_smoothed_values", "(", ")", "\n", "logging_output", "[", "\"sample_size\"", "]", "=", "sample_size", "\n", "for", "key_to_delete", "in", "[", "\"ppl\"", ",", "\"wps\"", ",", "\"wpb\"", ",", "\"bsz\"", "]", ":", "\n", "                    ", "if", "key_to_delete", "in", "logging_output", ":", "\n", "                        ", "del", "logging_output", "[", "key_to_delete", "]", "\n", "", "", "", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._check_xla_compilation": [[1175, 1190], ["met.metric_data", "logger.warning"], "methods", ["None"], ["", "", "def", "_check_xla_compilation", "(", "self", ")", ":", "\n", "        ", "import", "torch_xla", ".", "debug", ".", "metrics", "as", "met", "\n", "\n", "compile_stats", "=", "met", ".", "metric_data", "(", "\"CompileTime\"", ")", "\n", "if", "compile_stats", "is", "None", ":", "\n", "            ", "return", "\n", "", "num_xla_compiles", "=", "compile_stats", "[", "0", "]", "\n", "if", "num_xla_compiles", ">", "self", ".", "_num_xla_compiles", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"XLA compilation detected on device #{}; too many of these can lead \"", "\n", "\"to slow training, but we expect a few in the beginning\"", ".", "format", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "", "self", ".", "_num_xla_compiles", "=", "num_xla_compiles", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._catalog_shared_params": [[1192, 1210], ["module._parameters.items", "module._modules.items", "memo[].append", "trainer._catalog_shared_params", "memo.values", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._catalog_shared_params"], ["", "", "def", "_catalog_shared_params", "(", "module", ",", "memo", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "memo", "is", "None", ":", "\n", "        ", "first_call", "=", "True", "\n", "memo", "=", "{", "}", "\n", "", "else", ":", "\n", "        ", "first_call", "=", "False", "\n", "", "for", "name", ",", "param", "in", "module", ".", "_parameters", ".", "items", "(", ")", ":", "\n", "        ", "param_prefix", "=", "prefix", "+", "(", "\".\"", "if", "prefix", "else", "\"\"", ")", "+", "name", "\n", "if", "param", "not", "in", "memo", ":", "\n", "            ", "memo", "[", "param", "]", "=", "[", "]", "\n", "", "memo", "[", "param", "]", ".", "append", "(", "param_prefix", ")", "\n", "", "for", "name", ",", "m", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "        ", "if", "m", "is", "None", ":", "\n", "            ", "continue", "\n", "", "submodule_prefix", "=", "prefix", "+", "(", "\".\"", "if", "prefix", "else", "\"\"", ")", "+", "name", "\n", "_catalog_shared_params", "(", "m", ",", "memo", ",", "submodule_prefix", ")", "\n", "", "if", "first_call", ":", "\n", "        ", "return", "[", "x", "for", "x", "in", "memo", ".", "values", "(", ")", "if", "len", "(", "x", ")", ">", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._get_module_by_path": [[1212, 1217], ["path.split.split", "getattr"], "function", ["None"], ["", "", "def", "_get_module_by_path", "(", "module", ",", "path", ")", ":", "\n", "    ", "path", "=", "path", ".", "split", "(", "\".\"", ")", "\n", "for", "name", "in", "path", ":", "\n", "        ", "module", "=", "getattr", "(", "module", ",", "name", ")", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer._set_module_by_path": [[1219, 1224], ["path.split.split", "setattr", "getattr"], "function", ["None"], ["", "def", "_set_module_by_path", "(", "module", ",", "path", ",", "value", ")", ":", "\n", "    ", "path", "=", "path", ".", "split", "(", "\".\"", ")", "\n", "for", "name", "in", "path", "[", ":", "-", "1", "]", ":", "\n", "        ", "module", "=", "getattr", "(", "module", ",", "name", ")", "\n", "", "setattr", "(", "module", ",", "path", "[", "-", "1", "]", ",", "value", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.pdb.MultiprocessingPdb.__init__": [[29, 31], ["pdb.Pdb.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pdb", ".", "Pdb", ".", "__init__", "(", "self", ",", "nosigint", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.pdb.MultiprocessingPdb._cmdloop": [[32, 43], ["pdb.MultiprocessingPdb.cmdloop", "os.fdopen"], "methods", ["None"], ["", "def", "_cmdloop", "(", "self", ")", ":", "\n", "        ", "stdin_bak", "=", "sys", ".", "stdin", "\n", "with", "_stdin_lock", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "_stdin_fd", "is", "not", "None", ":", "\n", "                    ", "if", "not", "_stdin", "[", "0", "]", ":", "\n", "                        ", "_stdin", "[", "0", "]", "=", "os", ".", "fdopen", "(", "_stdin_fd", ")", "\n", "", "sys", ".", "stdin", "=", "_stdin", "[", "0", "]", "\n", "", "self", ".", "cmdloop", "(", ")", "\n", "", "finally", ":", "\n", "                ", "sys", ".", "stdin", "=", "stdin_bak", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.pdb.set_trace": [[45, 48], ["pdb.MultiprocessingPdb", "MultiprocessingPdb.set_trace", "sys._getframe"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.pdb.set_trace"], ["", "", "", "", "def", "set_trace", "(", ")", ":", "\n", "    ", "pdb", "=", "MultiprocessingPdb", "(", ")", "\n", "pdb", ".", "set_trace", "(", "sys", ".", "_getframe", "(", ")", ".", "f_back", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.registry.setup_registry": [[17, 101], ["registry_name[].replace.startswith", "registry_name[].replace", "set", "isinstance", "hasattr", "getattr.", "isinstance", "getattr", "fairseq.dataclass.utils.merge_with_parent", "getattr", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "dc", "fairseq.dataclass.utils.populate_dataclass", "issubclass", "issubclass"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.merge_with_parent", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.populate_dataclass"], ["def", "setup_registry", "(", "registry_name", ":", "str", ",", "base_class", "=", "None", ",", "default", "=", "None", ",", "required", "=", "False", ")", ":", "\n", "    ", "assert", "registry_name", ".", "startswith", "(", "\"--\"", ")", "\n", "registry_name", "=", "registry_name", "[", "2", ":", "]", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "\n", "REGISTRY", "=", "{", "}", "\n", "REGISTRY_CLASS_NAMES", "=", "set", "(", ")", "\n", "DATACLASS_REGISTRY", "=", "{", "}", "\n", "\n", "# maintain a registry of all registries", "\n", "if", "registry_name", "in", "REGISTRIES", ":", "\n", "        ", "return", "# registry already exists", "\n", "", "REGISTRIES", "[", "registry_name", "]", "=", "{", "\n", "\"registry\"", ":", "REGISTRY", ",", "\n", "\"default\"", ":", "default", ",", "\n", "\"dataclass_registry\"", ":", "DATACLASS_REGISTRY", ",", "\n", "}", "\n", "\n", "def", "build_x", "(", "cfg", ":", "Union", "[", "DictConfig", ",", "str", ",", "Namespace", "]", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "            ", "choice", "=", "cfg", ".", "_name", "\n", "\n", "if", "choice", "and", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "dc", "=", "DATACLASS_REGISTRY", "[", "choice", "]", "\n", "cfg", "=", "merge_with_parent", "(", "dc", "(", ")", ",", "cfg", ")", "\n", "", "", "elif", "isinstance", "(", "cfg", ",", "str", ")", ":", "\n", "            ", "choice", "=", "cfg", "\n", "if", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "cfg", "=", "DATACLASS_REGISTRY", "[", "choice", "]", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "choice", "=", "getattr", "(", "cfg", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "cfg", "=", "populate_dataclass", "(", "DATACLASS_REGISTRY", "[", "choice", "]", "(", ")", ",", "cfg", ")", "\n", "\n", "", "", "if", "choice", "is", "None", ":", "\n", "            ", "if", "required", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} is required!\"", ".", "format", "(", "registry_name", ")", ")", "\n", "", "return", "None", "\n", "\n", "", "cls", "=", "REGISTRY", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "\"build_\"", "+", "registry_name", ")", ":", "\n", "            ", "builder", "=", "getattr", "(", "cls", ",", "\"build_\"", "+", "registry_name", ")", "\n", "", "else", ":", "\n", "            ", "builder", "=", "cls", "\n", "\n", "", "return", "builder", "(", "cfg", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", "\n", "\n", "", "def", "register_x", "(", "name", ",", "dataclass", "=", "None", ")", ":", "\n", "        ", "def", "register_x_cls", "(", "cls", ")", ":", "\n", "            ", "if", "name", "in", "REGISTRY", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot register duplicate {} ({})\"", ".", "format", "(", "registry_name", ",", "name", ")", "\n", ")", "\n", "", "if", "cls", ".", "__name__", "in", "REGISTRY_CLASS_NAMES", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot register {} with duplicate class name ({})\"", ".", "format", "(", "\n", "registry_name", ",", "cls", ".", "__name__", "\n", ")", "\n", ")", "\n", "", "if", "base_class", "is", "not", "None", "and", "not", "issubclass", "(", "cls", ",", "base_class", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"{} must extend {}\"", ".", "format", "(", "cls", ".", "__name__", ",", "base_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "if", "dataclass", "is", "not", "None", "and", "not", "issubclass", "(", "dataclass", ",", "FairseqDataclass", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Dataclass {} must extend FairseqDataclass\"", ".", "format", "(", "dataclass", ")", "\n", ")", "\n", "\n", "", "cls", ".", "__dataclass", "=", "dataclass", "\n", "if", "cls", ".", "__dataclass", "is", "not", "None", ":", "\n", "                ", "DATACLASS_REGISTRY", "[", "name", "]", "=", "cls", ".", "__dataclass", "\n", "\n", "cs", "=", "ConfigStore", ".", "instance", "(", ")", "\n", "node", "=", "dataclass", "(", ")", "\n", "node", ".", "_name", "=", "name", "\n", "cs", ".", "store", "(", "name", "=", "name", ",", "group", "=", "registry_name", ",", "node", "=", "node", ",", "provider", "=", "\"fairseq\"", ")", "\n", "\n", "", "REGISTRY", "[", "name", "]", "=", "cls", "\n", "\n", "return", "cls", "\n", "\n", "", "return", "register_x_cls", "\n", "\n", "", "return", "build_x", ",", "register_x", ",", "REGISTRY", ",", "DATACLASS_REGISTRY", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.__init__": [[42, 46], ["torch.nn.Module.__init__", "ngram_repeat_block.is_cuda_extension_usable"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.is_cuda_extension_usable"], ["def", "__init__", "(", "self", ",", "no_repeat_ngram_size", ":", "int", ",", "use_extension", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_extension", "=", "is_cuda_extension_usable", "(", ")", "if", "use_extension", "else", "False", "\n", "self", ".", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.reset_parameters": [[47, 49], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.call_cuda_extension": [[50, 61], ["ngram_repeat_block_cuda.forward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "call_cuda_extension", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "lprobs", ",", "\n", "bsz", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", "step", ":", "int", ",", "\n", ")", ":", "\n", "        ", "return", "ngram_repeat_block_cuda", ".", "forward", "(", "\n", "tokens", ",", "lprobs", ",", "bsz", ",", "step", ",", "beam_size", ",", "self", ".", "no_repeat_ngram_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.forward": [[63, 94], ["tokens.size", "lprobs.size", "ngram_repeat_block.NGramRepeatBlock.call_cuda_extension", "ngram_repeat_block.NGramRepeatBlock._no_repeat_ngram", "tokens.size", "lprobs.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.call_cuda_extension", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock._no_repeat_ngram", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "lprobs", ",", "\n", "bsz", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", "step", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokens(Tensor): Input tokens(Bsz*beam, seq_len)\n            lprobs(Tensor): likelihood probability,\n            Expected to be updated in place.(Bsz*beam, vocab_size)\n            bsz(int): batch size\n            step(int): current step\n            beam_size(int): beam size\n            no_repeat_ngram_size(int): Ngram size\n        \"\"\"", "\n", "msg", "=", "f\"expected {bsz *beam_size} got\"", "\n", "assert", "tokens", ".", "size", "(", "0", ")", "==", "bsz", "*", "beam_size", ",", "f\"{msg} {tokens.size(0)}\"", "\n", "assert", "lprobs", ".", "size", "(", "0", ")", "==", "bsz", "*", "beam_size", ",", "f\"{msg} {lprobs.size(0)}\"", "\n", "if", "self", ".", "use_extension", ":", "\n", "            ", "return", "self", ".", "call_cuda_extension", "(", "tokens", ",", "lprobs", ",", "bsz", ",", "beam_size", ",", "step", ")", "\n", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_no_repeat_ngram", "(", "\n", "tokens", ",", "\n", "lprobs", ",", "\n", "bsz", ",", "\n", "beam_size", ",", "\n", "step", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock._no_repeat_ngram": [[96, 129], ["tokens.cpu", "range", "range", "torch.jit.annotate", "cpu_tokens[].tolist", "ngram_repeat_block.NGramRepeatBlock.transpose_list", "torch.tensor().to", "range", "ngram_repeat_block.NGramRepeatBlock.calculate_banned_tokens", "torch.jit.annotate", "gen_ngrams[].get", "range", "range", "torch.tensor().long", "torch.tensor", "range", "str", "torch.jit.annotate", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.transpose_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.calculate_banned_tokens"], ["", "", "def", "_no_repeat_ngram", "(", "self", ",", "tokens", ",", "lprobs", ",", "bsz", ":", "int", ",", "beam_size", ":", "int", ",", "step", ":", "int", ")", ":", "\n", "        ", "\"\"\"For each hypothesis generate a list of previous ngrams and set associated lprobs to -inf\"\"\"", "\n", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "{", "}", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "cpu_tokens", "=", "tokens", ".", "cpu", "(", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "gen_tokens", ":", "List", "[", "int", "]", "=", "cpu_tokens", "[", "bbsz_idx", "]", ".", "tolist", "(", ")", "\n", "for", "ngram", "in", "self", ".", "transpose_list", "(", "\n", "[", "gen_tokens", "[", "i", ":", "]", "for", "i", "in", "range", "(", "self", ".", "no_repeat_ngram_size", ")", "]", "\n", ")", ":", "\n", "                ", "key", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "ngram", "[", ":", "-", "1", "]", "]", ")", "\n", "gen_ngrams", "[", "bbsz_idx", "]", "[", "key", "]", "=", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "\n", "key", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "\n", ")", "+", "[", "ngram", "[", "-", "1", "]", "]", "\n", "", "", "if", "step", "+", "2", "-", "self", ".", "no_repeat_ngram_size", ">=", "0", ":", "\n", "# no banned tokens if we haven't generated no_repeat_ngram_size tokens yet", "\n", "            ", "banned_tokens", "=", "[", "\n", "self", ".", "calculate_banned_tokens", "(", "\n", "tokens", ",", "step", ",", "gen_ngrams", ",", "self", ".", "no_repeat_ngram_size", ",", "bbsz_idx", "\n", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "banned_tokens", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "lprobs", "[", "bbsz_idx", "]", "[", "\n", "torch", ".", "tensor", "(", "banned_tokens", "[", "bbsz_idx", "]", ")", ".", "long", "(", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.calculate_banned_tokens": [[130, 144], ["tokens[].tolist", "gen_ngrams[].get", "torch.jit.annotate", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "calculate_banned_tokens", "(", "\n", "tokens", ",", "\n", "step", ":", "int", ",", "\n", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "no_repeat_ngram_size", ":", "int", ",", "\n", "bbsz_idx", ":", "int", ",", "\n", ")", ":", "\n", "        ", "tokens_list", ":", "List", "[", "int", "]", "=", "tokens", "[", "\n", "bbsz_idx", ",", "step", "+", "2", "-", "no_repeat_ngram_size", ":", "step", "+", "1", "\n", "]", ".", "tolist", "(", ")", "\n", "# before decoding the next token, prevent decoding of ngrams that have already appeared", "\n", "ngram_index", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens_list", "]", ")", "\n", "return", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "ngram_index", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.NGramRepeatBlock.transpose_list": [[145, 151], ["min", "len", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "transpose_list", "(", "l", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "# GeneratorExp aren't supported in TS so ignoring the lint", "\n", "        ", "min_len", "=", "min", "(", "[", "len", "(", "x", ")", "for", "x", "in", "l", "]", ")", "# noqa", "\n", "l2", "=", "[", "[", "row", "[", "i", "]", "for", "row", "in", "l", "]", "for", "i", "in", "range", "(", "min_len", ")", "]", "\n", "return", "l2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.ngram_repeat_block.is_cuda_extension_usable": [[20, 37], ["torch.tensor", "torch.rand", "ngram_repeat_block_cuda.forward", "torch.cuda.is_available", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "def", "is_cuda_extension_usable", "(", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check whether ngram_repeat_block_cuda is built properly\"\"\"", "\n", "if", "not", "EXTENSION_BUILT", "or", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "bsz", "=", "2", "\n", "tokens", "=", "torch", ".", "tensor", "(", "[", "[", "4", ",", "4", ",", "3", ",", "2", "]", ",", "[", "1", ",", "2", ",", "3", ",", "4", "]", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", "\n", "lprobs", "=", "torch", ".", "rand", "(", "(", "8", ",", "12", ")", ",", "device", "=", "\"cuda\"", ")", "\n", "try", ":", "\n", "        ", "outputs", "=", "ngram_repeat_block_cuda", ".", "forward", "(", "tokens", ",", "lprobs", ",", "bsz", ",", "3", ",", "4", ",", "3", ")", "\n", "outputs", "=", "outputs", "+", "4", "# This line breaks if the extension is built incorrectly.", "\n", "return", "True", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"NGramRepeatBlock extension must be rebuilt.\"", "\n", "'Run TORCH_CUDA_ARCH_LIST=\"6.0;6.1;7.0\" python setup.py build_ext --inplace'", "\n", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.Binarizer.binarize": [[26, 84], ["collections.Counter", "open", "f.seek", "binarizer.safe_readline", "sum", "collections.Counter.update", "fairseq.file_io.PathManager.get_local_path", "len", "consumer", "f.readline", "collections.Counter.values", "f.readline.strip().split", "torch.IntTensor", "dict.encode_line", "f.tell", "f.tell", "int", "id_list.reverse", "id_list.append", "f.readline.strip", "dict.eos"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["    ", "@", "staticmethod", "\n", "def", "binarize", "(", "\n", "filename", ",", "\n", "dict", ",", "\n", "consumer", ",", "\n", "tokenize", "=", "tokenize_line", ",", "\n", "append_eos", "=", "True", ",", "\n", "reverse_order", "=", "False", ",", "\n", "offset", "=", "0", ",", "\n", "end", "=", "-", "1", ",", "\n", "already_numberized", "=", "False", ",", "\n", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "nseq", ",", "ntok", "=", "0", ",", "0", "\n", "replaced", "=", "Counter", "(", ")", "\n", "\n", "def", "replaced_consumer", "(", "word", ",", "idx", ")", ":", "\n", "            ", "if", "idx", "==", "dict", ".", "unk_index", "and", "word", "!=", "dict", ".", "unk_word", ":", "\n", "                ", "replaced", ".", "update", "(", "[", "word", "]", ")", "\n", "\n", "", "", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "seek", "(", "offset", ")", "\n", "# next(f) breaks f.tell(), hence readline() must be used", "\n", "line", "=", "safe_readline", "(", "f", ")", "\n", "while", "line", ":", "\n", "# f.tell() does not always give the byte position in the file", "\n", "# sometimes it skips to a very large number", "\n", "# it is unlikely that through a normal read we go from", "\n", "# end bytes to end + 2**32 bytes (4 GB) and this makes it unlikely", "\n", "# that the procedure breaks by the undeterministic behavior of", "\n", "# f.tell()", "\n", "                ", "if", "end", ">", "0", "and", "f", ".", "tell", "(", ")", ">", "end", "and", "f", ".", "tell", "(", ")", "<", "end", "+", "2", "**", "32", ":", "\n", "                    ", "break", "\n", "", "if", "already_numberized", ":", "\n", "                    ", "id_strings", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "id_list", "=", "[", "int", "(", "id_string", ")", "for", "id_string", "in", "id_strings", "]", "\n", "if", "reverse_order", ":", "\n", "                        ", "id_list", ".", "reverse", "(", ")", "\n", "", "if", "append_eos", ":", "\n", "                        ", "id_list", ".", "append", "(", "dict", ".", "eos", "(", ")", ")", "\n", "", "ids", "=", "torch", ".", "IntTensor", "(", "id_list", ")", "\n", "", "else", ":", "\n", "                    ", "ids", "=", "dict", ".", "encode_line", "(", "\n", "line", "=", "line", ",", "\n", "line_tokenizer", "=", "tokenize", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", "consumer", "=", "replaced_consumer", ",", "\n", "append_eos", "=", "append_eos", ",", "\n", "reverse_order", "=", "reverse_order", ",", "\n", ")", "\n", "", "nseq", "+=", "1", "\n", "ntok", "+=", "len", "(", "ids", ")", "\n", "consumer", "(", "ids", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "{", "\n", "\"nseq\"", ":", "nseq", ",", "\n", "\"nunk\"", ":", "sum", "(", "replaced", ".", "values", "(", ")", ")", ",", "\n", "\"ntok\"", ":", "ntok", ",", "\n", "\"replaced\"", ":", "replaced", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.Binarizer.binarize_alignments": [[86, 103], ["open", "f.seek", "binarizer.safe_readline", "fairseq.file_io.PathManager.get_local_path", "alignment_parser", "consumer", "f.readline", "f.tell"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path"], ["", "@", "staticmethod", "\n", "def", "binarize_alignments", "(", "\n", "filename", ",", "alignment_parser", ",", "consumer", ",", "offset", "=", "0", ",", "end", "=", "-", "1", "\n", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "nseq", "=", "0", "\n", "\n", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "seek", "(", "offset", ")", "\n", "line", "=", "safe_readline", "(", "f", ")", "\n", "while", "line", ":", "\n", "                ", "if", "end", ">", "0", "and", "f", ".", "tell", "(", ")", ">", "end", ":", "\n", "                    ", "break", "\n", "", "ids", "=", "alignment_parser", "(", "line", ")", "\n", "nseq", "+=", "1", "\n", "consumer", "(", "ids", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "{", "\"nseq\"", ":", "nseq", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.Binarizer.find_offsets": [[104, 115], ["open", "range", "fairseq.file_io.PathManager.get_local_path", "os.fstat", "f.seek", "binarizer.safe_readline", "f.tell", "f.fileno", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.safe_readline"], ["", "@", "staticmethod", "\n", "def", "find_offsets", "(", "filename", ",", "num_chunks", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "size", "=", "os", ".", "fstat", "(", "f", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "chunk_size", "=", "size", "//", "num_chunks", "\n", "offsets", "=", "[", "0", "for", "_", "in", "range", "(", "num_chunks", "+", "1", ")", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "num_chunks", ")", ":", "\n", "                ", "f", ".", "seek", "(", "chunk_size", "*", "i", ")", "\n", "safe_readline", "(", "f", ")", "\n", "offsets", "[", "i", "]", "=", "f", ".", "tell", "(", ")", "\n", "", "return", "offsets", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.safe_readline": [[15, 23], ["f.tell", "f.readline", "f.seek"], "function", ["None"], ["def", "safe_readline", "(", "f", ")", ":", "\n", "    ", "pos", "=", "f", ".", "tell", "(", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "f", ".", "readline", "(", ")", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "            ", "pos", "-=", "1", "\n", "f", ".", "seek", "(", "pos", ")", "# search where this character begins", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.__init__": [[20, 29], ["torch.Module.__init__", "tgt_dict.pad", "tgt_dict.unk", "tgt_dict.eos", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "src_lengths", "=", "torch", ".", "tensor", "(", "-", "1", ")", "\n", "self", ".", "supports_constraints", "=", "False", "\n", "self", ".", "stop_on_max_len", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.step": [[30, 59], ["None"], "methods", ["None"], ["", "def", "step", "(", "\n", "self", ",", "step", ",", "lprobs", ",", "scores", ",", "prev_output_tokens", "=", "None", ",", "original_batch_idxs", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"Take a single search step.\n\n        Args:\n            step: the current search step, starting at 0\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n            scores: (bsz x input_beam_size x step)\n                the historical model scores of each hypothesis up to this point\n            prev_output_tokens: (bsz x step)\n                the previously generated oputput tokens\n            original_batch_idxs: (bsz)\n                the tensor with the batch indices, in the range [0, bsz)\n                this is useful in case there has been applied a re-ordering\n                and we need to know the orignal indices\n\n        Return: A tuple of (scores, indices, beams) where:\n            scores: (bsz x output_beam_size)\n                the scores of the chosen elements; output_beam_size can be\n                larger than input_beam_size, e.g., we may return\n                2*input_beam_size to account for EOS\n            indices: (bsz x output_beam_size)\n                the indices of the chosen elements\n            beams: (bsz x output_beam_size)\n                the hypothesis ids of the chosen elements, in the range [0, input_beam_size)\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.set_src_lengths": [[60, 63], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "set_src_lengths", "(", "self", ",", "src_lengths", ")", ":", "\n", "        ", "self", ".", "src_lengths", "=", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.init_constraints": [[64, 77], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "init_constraints", "(", "self", ",", "batch_constraints", ":", "Optional", "[", "Tensor", "]", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Initialize constraint states for constrained decoding (if supported).\n\n        Args:\n            batch_constraints: (torch.Tensor, optional)\n                the list of constraints, in packed form\n            beam_size: (int)\n                the beam size\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.prune_sentences": [[78, 88], ["None"], "methods", ["None"], ["", "def", "prune_sentences", "(", "self", ",", "batch_idxs", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Removes constraint states for completed sentences (if supported).\n        This is called from sequence_generator._generate() when sentences are\n        deleted from the batch.\n\n        Args:\n            batch_idxs: Indices of *sentences* whose constraint state should be *kept*.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.update_constraints": [[89, 101], ["None"], "methods", ["None"], ["", "def", "update_constraints", "(", "self", ",", "active_hypos", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Updates the constraint states by selecting the beam items that are retained.\n        This is called at each time step of sequence_generator._generate() when\n        the set of 2 * {beam_size} candidate hypotheses are reduced to the beam size.\n\n        Args:\n            active_hypos: (batch size, beam size)\n              list of integers denoting, for each sentence, which beam candidate items\n              should be kept.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.BeamSearch.__init__": [[104, 107], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "constraint_states", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.BeamSearch.step": [[108, 145], ["lprobs[].contiguous.size", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.view", "scores[].unsqueeze", "min", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "# Project back into relative indices and beams", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# At this point, beams_buf and indices_buf are single-dim and contain relative indices", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.PrefixConstrainedBeamSearch.__init__": [[148, 152], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "prefix_allowed_tokens_fn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "prefix_allowed_tokens_fn", "=", "prefix_allowed_tokens_fn", "\n", "self", ".", "stop_on_max_len", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.PrefixConstrainedBeamSearch.apply_mask": [[153, 167], ["original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "enumerate", "zip", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat", "search.PrefixConstrainedBeamSearch.prefix_allowed_tokens_fn", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "apply_mask", "(", "self", ",", "x", ",", "prev_output_tokens", ",", "original_batch_idxs", ")", ":", "\n", "        ", "beam_size", "=", "x", ".", "shape", "[", "0", "]", "//", "original_batch_idxs", ".", "shape", "[", "0", "]", "\n", "original_batch_idxs", "=", "(", "\n", "original_batch_idxs", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "(", "1", ",", "beam_size", ")", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", ")", "\n", "\n", "mask", "=", "torch", ".", "full_like", "(", "x", ",", "-", "math", ".", "inf", ")", "\n", "for", "sent_i", ",", "(", "sent", ",", "batch_i", ")", "in", "enumerate", "(", "\n", "zip", "(", "prev_output_tokens", ",", "original_batch_idxs", ")", "\n", ")", ":", "\n", "            ", "mask", "[", "sent_i", ",", ":", ",", "self", ".", "prefix_allowed_tokens_fn", "(", "batch_i", ",", "sent", ")", "]", "=", "0", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.PrefixConstrainedBeamSearch.step": [[168, 208], ["lprobs[].contiguous.size", "search.PrefixConstrainedBeamSearch.apply_mask().view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.view", "search.PrefixConstrainedBeamSearch.apply_mask", "scores[].unsqueeze", "min", "lprobs[].contiguous.view", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.apply_mask", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "scores", ":", "Tensor", ",", "\n", "prev_output_tokens", ":", "Tensor", ",", "\n", "original_batch_idxs", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "lprobs", "+=", "self", ".", "apply_mask", "(", "\n", "lprobs", ".", "view", "(", "bsz", "*", "beam_size", ",", "1", ",", "vocab_size", ")", ",", "\n", "prev_output_tokens", ",", "\n", "original_batch_idxs", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ",", "vocab_size", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.__init__": [[229, 235], ["search.Search.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "representation", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "representation", "=", "representation", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "num_cands", "=", "0", "\n", "self", ".", "supports_constraints", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.init_constraints": [[236, 246], ["search.LexicallyConstrainedBeamSearch.constraint_states.append", "fairseq.token_generation_constraints.OrderedConstraintState.create", "fairseq.token_generation_constraints.UnorderedConstraintState.create", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "init_constraints", "(", "self", ",", "batch_constraints", ":", "Optional", "[", "Tensor", "]", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "self", ".", "constraint_states", "=", "[", "]", "\n", "for", "constraint_tensor", "in", "batch_constraints", ":", "\n", "            ", "if", "self", ".", "representation", "==", "\"ordered\"", ":", "\n", "                ", "constraint_state", "=", "OrderedConstraintState", ".", "create", "(", "constraint_tensor", ")", "\n", "", "elif", "self", ".", "representation", "==", "\"unordered\"", ":", "\n", "                ", "constraint_state", "=", "UnorderedConstraintState", ".", "create", "(", "constraint_tensor", ")", "\n", "\n", "", "self", ".", "constraint_states", ".", "append", "(", "[", "constraint_state", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.prune_sentences": [[247, 251], ["batch_idxs.tolist"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "export", "\n", "def", "prune_sentences", "(", "self", ",", "batch_idxs", ":", "Tensor", ")", ":", "\n", "        ", "self", ".", "constraint_states", "=", "[", "\n", "self", ".", "constraint_states", "[", "i", "]", "for", "i", "in", "batch_idxs", ".", "tolist", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.update_constraints": [[253, 260], ["active_hypos.size", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "update_constraints", "(", "self", ",", "active_hypos", ":", "Tensor", ")", ":", "\n", "        ", "if", "self", ".", "constraint_states", ":", "\n", "            ", "batch_size", "=", "active_hypos", ".", "size", "(", "0", ")", "\n", "for", "sentid", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "self", ".", "constraint_states", "[", "sentid", "]", "=", "[", "\n", "self", ".", "constraint_states", "[", "sentid", "]", "[", "i", "]", "for", "i", "in", "active_hypos", "[", "sentid", "]", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.step": [[262, 379], ["lprobs[].contiguous.size", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.cat.fmod", "torch.cat.fmod", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "lprobs[].contiguous", "lprobs[].contiguous.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "top_scores.view.view.view", "top_indices.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "search.LexicallyConstrainedBeamSearch.step_sentence", "lprobs[].contiguous.view().size", "enumerate", "torch.tensor.numel", "torch.tensor.numel", "scores[].unsqueeze", "lprobs[].contiguous.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beams_buf[].clone", "indices_buf[].clone", "scores_buf[].clone", "lprobs[].contiguous.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "lprobs[].contiguous.view", "torch.tensor.append", "torch.tensor.append"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.step_sentence", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "scores", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        A constrained step builds a large candidates list from the following:\n        - the top 2 * {beam_size} items over the whole beam\n        - for each item in the beam\n          - the top {each_k} (default 1)\n          - all next constraints\n        We then compute the constrained state of each beam item, and assign\n        stripe codes: 0 to the best in each bank, 1 to the 2nd-best, and so\n        on. We then sort by (stripe, score), and truncate the list at\n        2 * beam size.\n\n        Args:\n            step: the decoder step\n            lprobs: (batch size, beam size, target vocab)\n                the target-vocab distributions for each item in the beam.\n        Retrun: A tuple of (scores, indices, beams, constraints) where:\n            scores: (batch, output beam size)\n                the scores of the chosen elements\n            indices: (batch, output beam size)\n                the target vocab indices of the chosen elements\n            beams: (batch, output beam size)\n                the 0-indexed hypothesis ids of the chosen elements\n            constraints: (batch, output beam size)\n                the new constraint states\n        \"\"\"", "\n", "each_k", "=", "1", "\n", "device", "=", "lprobs", ".", "device", "\n", "\n", "batch_size", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "self", ".", "num_cands", "=", "min", "(", "\n", "# Just take the k-best. We'll get another k from the 1-best from each", "\n", "# row, plus more from the constraints", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", "\n", "\n", "# STEP 0: Preliminary. Prevent EOS for unfinished hyps across all batch items", "\n", "constraint_states", "=", "self", ".", "constraint_states", "\n", "if", "constraint_states", "and", "step", ">", "0", ":", "\n", "            ", "not_finished_indices", "=", "[", "]", "\n", "for", "sentno", ",", "sent_constraints", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "                ", "for", "beamno", ",", "state", "in", "enumerate", "(", "sent_constraints", ")", ":", "\n", "                    ", "index", "=", "sentno", "*", "beam_size", "+", "beamno", "\n", "if", "not", "state", ".", "finished", ":", "\n", "                        ", "not_finished_indices", ".", "append", "(", "index", ")", "\n", "", "", "", "not_finished_indices", "=", "torch", ".", "tensor", "(", "not_finished_indices", ")", "\n", "if", "not_finished_indices", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "lprobs", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "[", "\n", "not_finished_indices", ",", "self", ".", "eos", "\n", "]", "=", "-", "math", ".", "inf", "\n", "\n", "", "", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam entry for each batch item", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ",", "\n", "self", ".", "num_cands", ",", "\n", ")", "\n", "scores_buf", ",", "indices_buf", "=", "top_prediction", "\n", "# Project back into relative indices and beams", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# Short circuit if there are no constraints in this batch", "\n", "if", "not", "constraint_states", ":", "\n", "            ", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n", "# STEP 1: get top-1 from each hypothesis across all sentences in the batch", "\n", "", "if", "step", ">", "0", ":", "\n", "            ", "top_scores", ",", "top_indices", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", ",", "\n", "k", "=", "each_k", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "top_scores", "=", "top_scores", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "top_indices", "=", "top_indices", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "scores_buf", "=", "torch", ".", "cat", "(", "(", "scores_buf", ",", "top_scores", ")", ",", "dim", "=", "1", ")", "\n", "indices_buf", "=", "torch", ".", "cat", "(", "(", "indices_buf", ",", "top_indices", ")", ",", "dim", "=", "1", ")", "\n", "new_beams", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ",", "device", "=", "device", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "beams_buf", "=", "torch", ".", "cat", "(", "(", "beams_buf", ",", "new_beams", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Now, process sentences in the batch one by one.", "\n", "", "new_scores_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", "\n", "new_indices_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "new_beams_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "for", "sentno", ",", "states", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "            ", "scores", ",", "indices", ",", "beams", ",", "new_states", "=", "self", ".", "step_sentence", "(", "\n", "step", ",", "\n", "sentno", ",", "\n", "lprobs", "[", "sentno", "]", ",", "\n", "constraint_states", "[", "sentno", "]", ",", "\n", "beams_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", "indices_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", "scores_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", ")", "\n", "new_scores_buf", "[", "sentno", "]", "=", "scores", "\n", "new_indices_buf", "[", "sentno", "]", "=", "indices", "\n", "new_beams_buf", "[", "sentno", "]", "=", "beams", "\n", "self", ".", "constraint_states", "[", "sentno", "]", "=", "new_states", "\n", "\n", "", "return", "new_scores_buf", ",", "new_indices_buf", ",", "new_beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.step_sentence": [[380, 524], ["enumerate", "torch.cat.size", "torch.cat.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "sort_key.sort", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.zeros_like.sort", "torch.zeros_like.sort", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "constraint_states[].advance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "search.LexicallyConstrainedBeamSearch.step_sentence.roll"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.advance"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step_sentence", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "sentno", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "constraint_states", ":", "List", "[", "List", "[", "ConstraintState", "]", "]", ",", "\n", "beams_buf", ":", "Tensor", ",", "\n", "indices_buf", ":", "Tensor", ",", "\n", "scores_buf", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Does per-sentence processing. Adds all constraints for each\n        hypothesis to the list of candidates; then removes duplicates,\n        sorts, and dynamically stripes across the banks. All tensor inputs\n        are collapsed to those pertaining to a single input sentence.\n        \"\"\"", "\n", "device", "=", "lprobs", ".", "device", "\n", "\n", "# STEP 2: Add all constraints for each beam item", "\n", "for", "beamno", ",", "state", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "            ", "next_tokens", "=", "torch", ".", "tensor", "(", "list", "(", "state", ".", "next_tokens", "(", ")", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "if", "next_tokens", ".", "numel", "(", ")", "!=", "0", ":", "\n", "                ", "indices_buf", "=", "torch", ".", "cat", "(", "(", "indices_buf", ",", "next_tokens", ")", ")", "\n", "next_beams", "=", "(", "\n", "torch", ".", "tensor", "(", "beamno", ",", "device", "=", "device", ")", "\n", ".", "repeat", "(", "next_tokens", ".", "size", "(", "0", ")", ")", "\n", ".", "long", "(", ")", "\n", ")", "\n", "beams_buf", "=", "torch", ".", "cat", "(", "(", "beams_buf", ",", "next_beams", ")", ")", "\n", "next_values", "=", "lprobs", "[", "beamno", "]", ".", "take", "(", "next_tokens", ".", "view", "(", "-", "1", ")", ")", "\n", "scores_buf", "=", "torch", ".", "cat", "(", "(", "scores_buf", ",", "next_values", ")", ")", "\n", "\n", "# At the 0th time step, there is just one beam item", "\n", "", "if", "step", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# STEP 3: Compute the \"bank\" for each candidate. This is the", "\n", "# number of constraints it's generated. We need this so that", "\n", "# we can do round-robin allocation of the beam across these", "\n", "# banks. If C is the number of constraints, we select the best", "\n", "# item in bank C, then the best in bank C-1, etc, followed by", "\n", "# the 2nd-best in bank C, the 2nd-best in bank C-1, etc, and so", "\n", "# on, until the maximum beam size. We accomplish this by", "\n", "# creating a sort key and striping across the banks.", "\n", "\n", "# Compute the new states for all candidates", "\n", "", "", "cands_size", "=", "indices_buf", ".", "size", "(", "0", ")", "\n", "constraint_states", "=", "[", "\n", "constraint_states", "[", "beams_buf", "[", "i", "]", "]", ".", "advance", "(", "indices_buf", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "cands_size", ")", "\n", "]", "\n", "\n", "banks", "=", "torch", ".", "tensor", "(", "[", "state", ".", "bank", "for", "state", "in", "constraint_states", "]", ",", "device", "=", "device", ")", "\n", "\n", "# STEP 4: Sort", "\n", "num_constraint_tokens", "=", "len", "(", "state", ".", "tokens", ")", "\n", "\n", "# Sort by keys (bank, score) (i.e., sort banks together, and scores", "\n", "# within banks). AFAIK pytorch doesn't support either stable sort or", "\n", "# multi-key sorting, so we have to hack this.", "\n", "MAX_SCORE", "=", "-", "100", "\n", "sort_key", "=", "(", "num_constraint_tokens", "-", "banks", ")", "*", "MAX_SCORE", "+", "scores_buf", "\n", "sort_values", ",", "sort_indices", "=", "sort_key", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "scores_buf", "=", "scores_buf", "[", "sort_indices", "]", "\n", "indices_buf", "=", "indices_buf", "[", "sort_indices", "]", "\n", "beams_buf", "=", "beams_buf", "[", "sort_indices", "]", "\n", "banks", "=", "banks", "[", "sort_indices", "]", "\n", "\n", "# Sort the constraints to follow suit", "\n", "constraint_states", "=", "[", "constraint_states", "[", "i", "]", "for", "i", "in", "sort_indices", "]", "\n", "\n", "# STEP 5: Remove duplicates. The topk calls (overall and", "\n", "# per-row) plus the per-row generation of constraints will", "\n", "# produce duplicates. Here we remove them.", "\n", "\n", "def", "roll", "(", "t", ")", ":", "\n", "            ", "\"\"\"Rolls a 1d tensor left by 1.\n\n            [0, 1, 2, 3, 4] becomes [4, 0, 1, 2, 3]\n            \"\"\"", "\n", "return", "torch", ".", "cat", "(", "(", "t", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", ",", "t", "[", "0", ":", "-", "1", "]", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# We map candidates (beam, token_id) to a single dimension.", "\n", "# This is then shifted by 1. We can then easily identify", "\n", "# duplicates and create a mask that identifies unique", "\n", "# extensions.", "\n", "", "uniques_mask", "=", "beams_buf", "*", "(", "self", ".", "vocab_size", "+", "1", ")", "+", "indices_buf", "\n", "uniques_mask", "=", "roll", "(", "uniques_mask", ")", "!=", "uniques_mask", "\n", "\n", "# Use the mask to pare down the data structures", "\n", "scores_buf", "=", "torch", ".", "masked_select", "(", "scores_buf", ",", "uniques_mask", ")", "\n", "indices_buf", "=", "torch", ".", "masked_select", "(", "indices_buf", ",", "uniques_mask", ")", "\n", "beams_buf", "=", "torch", ".", "masked_select", "(", "beams_buf", ",", "uniques_mask", ")", "\n", "banks", "=", "torch", ".", "masked_select", "(", "banks", ",", "uniques_mask", ")", "\n", "i", "=", "1", "\n", "for", "mask", "in", "uniques_mask", "[", "1", ":", "]", ":", "\n", "            ", "if", "not", "mask", ":", "\n", "                ", "constraint_states", ".", "pop", "(", "i", ")", "\n", "", "i", "+=", "mask", "\n", "\n", "# STEP 6: Assign IDs round-robin across banks, sort, and", "\n", "# truncate. Now that the candidates are sorted by (bank,", "\n", "# score) and uniqed, we dynamically allocate the {beam_size}", "\n", "# beam by striping across the candidates. These stripes will", "\n", "# be used as sort keys to do round-robin selection. This is", "\n", "# accomplished in a single pass with offsets. Sorting by", "\n", "# highest-banks (furthest-along hypotheses) first ensures", "\n", "# progress through the constraints.", "\n", "#", "\n", "# e.g., BANKS: 3 3 3 2 2 2 2 1 1 1 0 0", "\n", "# OLD STRIPES: 0 1 2 0 1 2 3 0 1 2 0 1", "\n", "# NEW STRIPES: 0 1+4 2+8 0+1 1+5 2+9 3+11 0+2 1+6 2+10 0+3 1+7", "\n", "#            = 0 5 10 1 6 11 13 2 7 12 3 8", "\n", "#", "\n", "# Sorting by this then gives the following banks:", "\n", "#", "\n", "#             3 2 1 0 3 2 1 0 3 2 1 2", "\n", "#", "\n", "# We'll take the top {beam_size} of these.", "\n", "", "stripe_offsets", "=", "[", "offset", "*", "(", "len", "(", "banks", ")", "+", "1", ")", "for", "offset", "in", "range", "(", "len", "(", "banks", ")", "+", "1", ")", "]", "\n", "stripes", "=", "torch", ".", "zeros_like", "(", "banks", ")", "\n", "cur_bank_count", "=", "-", "1", "\n", "cur_bank", "=", "banks", "[", "0", "]", "\n", "for", "i", ",", "bank", "in", "enumerate", "(", "banks", ")", ":", "\n", "            ", "if", "bank", "!=", "cur_bank", ":", "\n", "                ", "cur_bank_count", "=", "0", "\n", "cur_bank", "=", "bank", "\n", "", "else", ":", "\n", "                ", "cur_bank_count", "+=", "1", "\n", "", "stripes", "[", "i", "]", "=", "num_constraint_tokens", "-", "bank", "+", "stripe_offsets", "[", "cur_bank_count", "]", "\n", "\n", "# STEP 7: Sort by the stripes values", "\n", "", "sort_values", ",", "sort_indices", "=", "stripes", ".", "sort", "(", "dim", "=", "0", ")", "\n", "scores_buf", "=", "scores_buf", "[", "sort_indices", "]", "\n", "indices_buf", "=", "indices_buf", "[", "sort_indices", "]", "\n", "beams_buf", "=", "beams_buf", "[", "sort_indices", "]", "\n", "constraint_states", "=", "[", "constraint_states", "[", "i", "]", "for", "i", "in", "sort_indices", "]", "\n", "\n", "# STEP 8: Truncate to the candidates size!", "\n", "scores_buf", "=", "scores_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "indices_buf", "=", "indices_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "beams_buf", "=", "beams_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", ",", "constraint_states", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LengthConstrainedBeamSearch.__init__": [[527, 535], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "min_len_a", ",", "min_len_b", ",", "max_len_a", ",", "max_len_b", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "min_len_a", "=", "min_len_a", "\n", "self", ".", "min_len_b", "=", "min_len_b", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "self", ".", "needs_src_lengths", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LengthConstrainedBeamSearch.step": [[536, 549], ["search.LengthConstrainedBeamSearch.beam.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "min_lens", "=", "self", ".", "min_len_a", "*", "self", ".", "src_lengths", "+", "self", ".", "min_len_b", "\n", "max_lens", "=", "self", ".", "max_len_a", "*", "self", ".", "src_lengths", "+", "self", ".", "max_len_b", "\n", "lprobs", "[", "step", "<", "min_lens", ",", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", "step", ">=", "max_lens", ",", ":", ",", "self", ".", "eos", "]", "=", "0", "\n", "return", "self", ".", "beam", ".", "step", "(", "step", ",", "lprobs", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.DiverseBeamSearch.__init__": [[561, 566], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "num_groups", ",", "diversity_strength", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "num_groups", "=", "num_groups", "\n", "self", ".", "diversity_strength", "=", "-", "diversity_strength", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.DiverseBeamSearch.step": [[567, 619], ["lprobs.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "ValueError", "search.DiverseBeamSearch.beam.step", "torch.stack().view.mul_().add_", "torch.stack().view.mul_().add_", "scores_G.append", "indices_G.append", "beams_G.append", "torch.zeros().to.scatter_add_", "torch.zeros().to.scatter_add_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.add", "torch.add", "torch.add", "torch.add", "lprobs_g.contiguous.contiguous.contiguous", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lprobs[].size", "torch.stack().view.mul_", "torch.stack().view.mul_", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.stack().view.size", "torch.stack().view.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "if", "beam_size", "%", "self", ".", "num_groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"DiverseBeamSearch requires --beam to be divisible by the number of groups\"", "\n", ")", "\n", "\n", "# initialize diversity penalty", "\n", "", "diversity_buf", "=", "torch", ".", "zeros", "(", "lprobs", "[", ":", ",", "0", ",", ":", "]", ".", "size", "(", ")", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "scores_G", ",", "indices_G", ",", "beams_G", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "g", "in", "range", "(", "self", ".", "num_groups", ")", ":", "\n", "            ", "lprobs_g", "=", "lprobs", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "\n", "scores_g", "=", "scores", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "if", "step", ">", "0", "else", "None", "\n", "\n", "# apply diversity penalty", "\n", "if", "g", ">", "0", ":", "\n", "                ", "lprobs_g", "=", "torch", ".", "add", "(", "\n", "lprobs_g", ",", "\n", "other", "=", "diversity_buf", ".", "unsqueeze", "(", "1", ")", ",", "\n", "alpha", "=", "self", ".", "diversity_strength", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "lprobs_g", "=", "lprobs_g", ".", "contiguous", "(", ")", "\n", "\n", "", "scores_buf", ",", "indices_buf", ",", "beams_buf", "=", "self", ".", "beam", ".", "step", "(", "\n", "step", ",", "lprobs_g", ",", "scores_g", "\n", ")", "\n", "beams_buf", ".", "mul_", "(", "self", ".", "num_groups", ")", ".", "add_", "(", "g", ")", "\n", "\n", "scores_G", ".", "append", "(", "scores_buf", ".", "clone", "(", ")", ")", "\n", "indices_G", ".", "append", "(", "indices_buf", ".", "clone", "(", ")", ")", "\n", "beams_G", ".", "append", "(", "beams_buf", ".", "clone", "(", ")", ")", "\n", "\n", "# update diversity penalty", "\n", "diversity_buf", ".", "scatter_add_", "(", "\n", "1", ",", "indices_buf", ",", "torch", ".", "ones", "(", "indices_buf", ".", "size", "(", ")", ")", ".", "to", "(", "diversity_buf", ")", "\n", ")", "\n", "\n", "# interleave results from different groups", "\n", "", "scores_buf", "=", "torch", ".", "stack", "(", "scores_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "indices_buf", "=", "torch", ".", "stack", "(", "indices_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "beams_buf", "=", "torch", ".", "stack", "(", "beams_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Sampling.__init__": [[625, 629], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "sampling_topk", "=", "-", "1", ",", "sampling_topp", "=", "-", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_topp", "=", "sampling_topp", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Sampling._sample_topp": [[630, 674], ["lprobs.exp_", "lprobs.exp_.sort", "sorted_probs.cumsum", "sorted_probs.cumsum.lt", "mask.scatter_.scatter_.cumsum", "last_included.clamp_", "mask.scatter_.scatter_.scatter_", "last_included.max", "truncated_probs.masked_fill_", "mask.scatter_.scatter_.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_sample_topp", "(", "self", ",", "lprobs", ")", ":", "\n", "        ", "\"\"\"Sample among the smallest set of elements whose cumulative probability mass exceeds p.\n\n        See `\"The Curious Case of Neural Text Degeneration\"\n        (Holtzman et al., 2019) <https://arxiv.org/abs/1904.09751>`_.\n\n        Args:\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n\n        Return: A tuple of (trimed_probs, truncated_indices) where:\n            trimed_probs: (bsz x input_beam_size x ?)\n                the model's probabilities over the elements selected to sample from. The\n                width of the third dimension is determined by top-P.\n            truncated_indices: (bsz x input_beam_size x ?)\n                the indices of the chosen elements.\n        \"\"\"", "\n", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "\n", "# sort the last dimension (vocab dimension) in descending order", "\n", "sorted_probs", ",", "sorted_indices", "=", "probs", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "# compute a mask to indicate the words to be included in the top-P set.", "\n", "cumsum_probs", "=", "sorted_probs", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "mask", "=", "cumsum_probs", ".", "lt", "(", "self", ".", "sampling_topp", ")", "\n", "\n", "# note that mask was computed by 'lt'. One more word needs to be included", "\n", "# so that the cumulative probability mass can exceed p.", "\n", "cumsum_mask", "=", "mask", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "last_included", "=", "cumsum_mask", "[", ":", ",", ":", ",", "-", "1", ":", "]", "\n", "last_included", ".", "clamp_", "(", "0", ",", "mask", ".", "size", "(", ")", "[", "2", "]", "-", "1", ")", "\n", "mask", "=", "mask", ".", "scatter_", "(", "2", ",", "last_included", ",", "1", ")", "\n", "\n", "# truncate unnecessary dims.", "\n", "max_dim", "=", "last_included", ".", "max", "(", ")", "\n", "truncated_mask", "=", "mask", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_probs", "=", "sorted_probs", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_indices", "=", "sorted_indices", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "\n", "# trim the words that are not in top-P by setting their probabilities", "\n", "# to 0, so that they would not be sampled later.", "\n", "trim_mask", "=", "~", "truncated_mask", "\n", "trimed_probs", "=", "truncated_probs", ".", "masked_fill_", "(", "trim_mask", ",", "0", ")", "\n", "return", "trimed_probs", ",", "truncated_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Sampling.step": [[675, 743], ["lprobs[].contiguous.size", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scores_buf.log_().view.log_().view.log_().view", "lprobs[].contiguous", "search.Sampling._sample_topp", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "lprobs[].contiguous.exp_.expand", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze.new_zeros", "torch.gather().squeeze.new_zeros", "torch.arange().to().repeat", "torch.arange().to().repeat", "torch.arange().to().repeat", "torch.arange().to().repeat", "scores_buf.log_().view.log_().view.add_", "lprobs[].contiguous.topk", "lprobs[].contiguous.exp_", "lprobs[].contiguous.exp_", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.gather().squeeze.unsqueeze", "torch.gather().squeeze.unsqueeze", "scores_buf.log_().view.log_().view.log_", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "lprobs[].contiguous.exp_.view", "lprobs[].contiguous.exp_.view", "torch.empty().to.expand", "torch.empty().to.expand", "torch.gather().squeeze.unsqueeze", "torch.gather().squeeze.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Sampling._sample_topp"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "self", ".", "sampling_topp", ">", "0", ":", "\n", "# only sample from the smallest set of words whose cumulative probability mass exceeds p", "\n", "            ", "probs", ",", "top_indices", "=", "self", ".", "_sample_topp", "(", "lprobs", ")", "\n", "", "elif", "self", ".", "sampling_topk", ">", "0", ":", "\n", "# only sample from top-k candidates", "\n", "            ", "lprobs", ",", "top_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "", "else", ":", "\n", "            ", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "\n", "# dummy data to be consistent with true branch for type check", "\n", "top_indices", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "probs", ")", "\n", "# sample", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "beam_size", ",", "\n", "replacement", "=", "True", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs", ".", "view", "(", "bsz", "*", "beam_size", ",", "-", "1", ")", ",", "\n", "1", ",", "\n", "replacement", "=", "True", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "# expand to beam size", "\n", "            ", "probs", "=", "probs", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "\n", "\n", "# gather scores", "\n", "", "scores_buf", "=", "torch", ".", "gather", "(", "probs", ",", "dim", "=", "2", ",", "index", "=", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "scores_buf", "=", "scores_buf", ".", "log_", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "\n", "# remap indices if using top-k or top-P sampling", "\n", "if", "self", ".", "sampling_topk", ">", "0", "or", "self", ".", "sampling_topp", ">", "0", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "gather", "(", "\n", "top_indices", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", ",", "\n", "dim", "=", "2", ",", "\n", "index", "=", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "beams_buf", "=", "indices_buf", ".", "new_zeros", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "beams_buf", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ")", ".", "to", "(", "indices_buf", ")", ".", "repeat", "(", "bsz", ",", "1", ")", "\n", "# make scores cumulative", "\n", "scores_buf", ".", "add_", "(", "\n", "torch", ".", "gather", "(", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ",", "dim", "=", "1", ",", "index", "=", "beams_buf", ")", "\n", ")", "\n", "\n", "", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.DiverseSiblingsSearch.__init__": [[760, 764], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "diversity_rate", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "diversity_rate", "=", "diversity_rate", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.DiverseSiblingsSearch.step": [[765, 815], ["lprobs.size", "min", "lprobs.add_", "range", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "range", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "search.DiverseSiblingsSearch.beam.step", "scores[].unsqueeze", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "i_list[].fmod_", "s_list[].sub_", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "lprobs.view().size", "range", "range", "lprobs[].view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lprobs.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", "\n", "s_list", ":", "List", "[", "Tensor", "]", "\n", "i_list", ":", "List", "[", "Tensor", "]", "\n", "s_list", "=", "[", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "lprobs", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", "\n", "i_list", "=", "[", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", "\n", "sibling_score", "=", "torch", ".", "arange", "(", "1", ",", "k", "+", "1", ")", ".", "to", "(", "lprobs", ")", "*", "self", ".", "diversity_rate", "\n", "\n", "if", "step", "==", "0", ":", "\n", "            ", "return", "self", ".", "beam", ".", "step", "(", "step", ",", "lprobs", ",", "scores", ")", "\n", "", "lprobs", ".", "add_", "(", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "# 1/ Calculate hypotheses for each beam", "\n", "for", "i", "in", "range", "(", "beam_size", ")", ":", "\n", "            ", "torch", ".", "topk", "(", "lprobs", "[", ":", ",", "i", ",", ":", "]", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "k", ",", "out", "=", "(", "s_list", "[", "i", "]", ",", "i_list", "[", "i", "]", ")", ")", "\n", "i_list", "[", "i", "]", ".", "fmod_", "(", "vocab_size", ")", "\n", "\n", "# 2/ Intra-sibling ordering by default from topk + 3/ Rewrite scores", "\n", "s_list", "[", "i", "]", ".", "sub_", "(", "sibling_score", ")", "\n", "\n", "# 4/ Choose top K hypotheses", "\n", "", "indices", "=", "torch", ".", "stack", "(", "i_list", ",", "dim", "=", "1", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "\n", "final_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "lprobs", ")", "\n", "final_indices", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "\n", "final_beams", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "\n", "(", "final_scores", ",", "final_indices", ")", "=", "torch", ".", "topk", "(", "\n", "torch", ".", "stack", "(", "s_list", ",", "dim", "=", "1", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", ",", "\n", ")", "\n", "\n", "final_beams", "=", "final_indices", "//", "k", "\n", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "final_indices", "[", "i", "]", "=", "indices", "[", "i", "]", "[", "final_indices", "[", "i", "]", "]", "\n", "\n", "", "return", "final_scores", ",", "final_indices", ",", "final_beams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.__init__": [[20, 61], ["tgt_dict.bos", "tgt_dict.pad", "tgt_dict.unk", "tgt_dict.eos", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dict", ",", "\n", "models", "=", "None", ",", "\n", "eos_penalty", "=", "0.0", ",", "\n", "max_iter", "=", "10", ",", "\n", "max_ratio", "=", "2", ",", "\n", "beam_size", "=", "1", ",", "\n", "decoding_format", "=", "None", ",", "\n", "retain_dropout", "=", "False", ",", "\n", "adaptive", "=", "True", ",", "\n", "retain_history", "=", "False", ",", "\n", "reranking", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Generates translations based on iterative refinement.\n\n        Args:\n            tgt_dict: target dictionary\n            eos_penalty: if > 0.0, it penalized early-stopping in decoding\n            max_iter: maximum number of refinement iterations\n            max_ratio: generate sequences of maximum length ax, where x is the source length\n            decoding_format: decoding mode in {'unigram', 'ensemble', 'vote', 'dp', 'bs'}\n            retain_dropout: retaining dropout in the inference\n            adaptive: decoding with early stop\n        \"\"\"", "\n", "self", ".", "bos", "=", "tgt_dict", ".", "bos", "(", ")", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "eos_penalty", "=", "eos_penalty", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "max_ratio", "=", "max_ratio", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "reranking", "=", "reranking", "\n", "self", ".", "decoding_format", "=", "decoding_format", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "retain_history", "=", "retain_history", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "models", "=", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.generate_batched_itr": [[62, 100], ["enumerate", "timer.start", "torch.no_grad", "iterative_refinement_generator.IterativeRefinementGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "fairseq.utils.strip_pad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.strip_pad"], ["", "def", "generate_batched_itr", "(", "\n", "self", ",", "\n", "data_itr", ",", "\n", "maxlen_a", "=", "None", ",", "\n", "maxlen_b", "=", "None", ",", "\n", "cuda", "=", "False", ",", "\n", "timer", "=", "None", ",", "\n", "prefix_size", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n\n        Args:\n            maxlen_a/b: generate sequences of maximum length ax + b,\n                where x is the source sentence length.\n            cuda: use GPU for generation\n            timer: StopwatchMeter for timing generations.\n        \"\"\"", "\n", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "if", "\"net_input\"", "not", "in", "sample", ":", "\n", "                ", "continue", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "\n", "self", ".", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "sample", "[", "\"target\"", "]", "[", ":", ",", ":", "prefix_size", "]", "\n", "if", "prefix_size", ">", "0", "\n", "else", "None", ",", "\n", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sample", "[", "\"ntokens\"", "]", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "sample", "[", "\"id\"", "]", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.generate": [[101, 312], ["torch.no_grad", "src_tokens.size", "model.forward_encoder", "model.initialize_output_tokens", "torch.arange", "decoder_out._replace._replace.output_tokens.clone", "range", "NotImplementedError", "hasattr", "model.enable_ensemble", "fairseq.utils.new_arange().t().reshape", "model.encoder.reorder_encoder_out", "model.regenerate_length_beam", "decoder_out._replace._replace._replace", "prev_out_token.ne", "decoder_out._replace._replace._replace", "model.forward_decoder", "range", "decoder_out._replace._replace._replace", "model.encoder.reorder_encoder_out", "decoder_out._replace._replace.output_tokens.clone", "model.eval", "len", "len", "range", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "scores.mean", "iterative_refinement_generator.IterativeRefinementGenerator.generate.is_a_loop"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.forward_decoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "if", "constraints", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the IterativeRefinementGenerator is not supported\"", "\n", ")", "\n", "\n", "# TODO: iterative refinement generator does not support ensemble for now.", "\n", "", "if", "not", "self", ".", "retain_dropout", ":", "\n", "            ", "for", "model", "in", "models", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "\n", "", "", "model", ",", "reranker", "=", "models", "[", "0", "]", ",", "None", "\n", "if", "self", ".", "reranking", ":", "\n", "            ", "assert", "len", "(", "models", ")", ">", "1", ",", "\"Assuming the last checkpoint is the reranker\"", "\n", "assert", "(", "\n", "self", ".", "beam_size", ">", "1", "\n", ")", ",", "\"Reranking requires multiple translation for each example\"", "\n", "\n", "reranker", "=", "models", "[", "-", "1", "]", "\n", "models", "=", "models", "[", ":", "-", "1", "]", "\n", "\n", "", "if", "len", "(", "models", ")", ">", "1", "and", "hasattr", "(", "model", ",", "\"enable_ensemble\"", ")", ":", "\n", "            ", "assert", "model", ".", "allow_ensemble", ",", "\"{} does not support ensembling\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", "\n", ")", "\n", "model", ".", "enable_ensemble", "(", "models", ")", "\n", "\n", "# TODO: better encoder inputs?", "\n", "", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "bsz", ",", "src_len", "=", "src_tokens", ".", "size", "(", ")", "\n", "\n", "# initialize", "\n", "encoder_out", "=", "model", ".", "forward_encoder", "(", "[", "src_tokens", ",", "src_lengths", "]", ")", "\n", "prev_decoder_out", "=", "model", ".", "initialize_output_tokens", "(", "encoder_out", ",", "src_tokens", ")", "\n", "\n", "if", "self", ".", "beam_size", ">", "1", ":", "\n", "            ", "assert", "(", "\n", "model", ".", "allow_length_beam", "\n", ")", ",", "\"{} does not support decoding with length beam.\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "# regenerate data based on length-beam", "\n", "length_beam_order", "=", "(", "\n", "utils", ".", "new_arange", "(", "src_tokens", ",", "self", ".", "beam_size", ",", "bsz", ")", ".", "t", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", ")", "\n", "encoder_out", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "encoder_out", ",", "length_beam_order", "\n", ")", "\n", "prev_decoder_out", "=", "model", ".", "regenerate_length_beam", "(", "\n", "prev_decoder_out", ",", "self", ".", "beam_size", "\n", ")", "\n", "bsz", "=", "bsz", "*", "self", ".", "beam_size", "\n", "\n", "", "sent_idxs", "=", "torch", ".", "arange", "(", "bsz", ")", "\n", "prev_output_tokens", "=", "prev_decoder_out", ".", "output_tokens", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "            ", "prev_decoder_out", "=", "prev_decoder_out", ".", "_replace", "(", "history", "=", "[", "prev_output_tokens", "]", ")", "\n", "\n", "", "finalized", "=", "[", "[", "]", "for", "_", "in", "range", "(", "bsz", ")", "]", "\n", "\n", "def", "is_a_loop", "(", "x", ",", "y", ",", "s", ",", "a", ")", ":", "\n", "            ", "b", ",", "l_x", ",", "l_y", "=", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "y", ".", "size", "(", "1", ")", "\n", "if", "l_x", ">", "l_y", ":", "\n", "                ", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "x", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ")", ".", "fill_", "(", "self", ".", "pad", ")", "]", ",", "1", ")", "\n", "s", "=", "torch", ".", "cat", "(", "[", "s", ",", "s", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ")", "]", ",", "1", ")", "\n", "if", "a", "is", "not", "None", ":", "\n", "                    ", "a", "=", "torch", ".", "cat", "(", "[", "a", ",", "a", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ",", "a", ".", "size", "(", "2", ")", ")", "]", ",", "1", ")", "\n", "", "", "elif", "l_x", "<", "l_y", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "y", ".", "new_zeros", "(", "b", ",", "l_y", "-", "l_x", ")", ".", "fill_", "(", "self", ".", "pad", ")", "]", ",", "1", ")", "\n", "", "return", "(", "x", "==", "y", ")", ".", "all", "(", "1", ")", ",", "y", ",", "s", ",", "a", "\n", "\n", "", "def", "finalized_hypos", "(", "step", ",", "prev_out_token", ",", "prev_out_score", ",", "prev_out_attn", ")", ":", "\n", "            ", "cutoff", "=", "prev_out_token", ".", "ne", "(", "self", ".", "pad", ")", "\n", "tokens", "=", "prev_out_token", "[", "cutoff", "]", "\n", "if", "prev_out_score", "is", "None", ":", "\n", "                ", "scores", ",", "score", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "                ", "scores", "=", "prev_out_score", "[", "cutoff", "]", "\n", "score", "=", "scores", ".", "mean", "(", ")", "\n", "\n", "", "if", "prev_out_attn", "is", "None", ":", "\n", "                ", "hypo_attn", ",", "alignment", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "                ", "hypo_attn", "=", "prev_out_attn", "[", "cutoff", "]", "\n", "alignment", "=", "hypo_attn", ".", "max", "(", "dim", "=", "1", ")", "[", "1", "]", "\n", "", "return", "{", "\n", "\"steps\"", ":", "step", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"positional_scores\"", ":", "scores", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"hypo_attn\"", ":", "hypo_attn", ",", "\n", "\"alignment\"", ":", "alignment", ",", "\n", "}", "\n", "\n", "", "for", "step", "in", "range", "(", "self", ".", "max_iter", "+", "1", ")", ":", "\n", "\n", "            ", "decoder_options", "=", "{", "\n", "\"eos_penalty\"", ":", "self", ".", "eos_penalty", ",", "\n", "\"max_ratio\"", ":", "self", ".", "max_ratio", ",", "\n", "\"decoding_format\"", ":", "self", ".", "decoding_format", ",", "\n", "}", "\n", "prev_decoder_out", "=", "prev_decoder_out", ".", "_replace", "(", "\n", "step", "=", "step", ",", "\n", "max_step", "=", "self", ".", "max_iter", "+", "1", ",", "\n", ")", "\n", "\n", "decoder_out", "=", "model", ".", "forward_decoder", "(", "\n", "prev_decoder_out", ",", "encoder_out", ",", "**", "decoder_options", "\n", ")", "\n", "\n", "if", "self", ".", "adaptive", ":", "\n", "# terminate if there is a loop", "\n", "                ", "terminated", ",", "out_tokens", ",", "out_scores", ",", "out_attn", "=", "is_a_loop", "(", "\n", "prev_output_tokens", ",", "\n", "decoder_out", ".", "output_tokens", ",", "\n", "decoder_out", ".", "output_scores", ",", "\n", "decoder_out", ".", "attn", ",", "\n", ")", "\n", "decoder_out", "=", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "out_tokens", ",", "\n", "output_scores", "=", "out_scores", ",", "\n", "attn", "=", "out_attn", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "terminated", "=", "decoder_out", ".", "output_tokens", ".", "new_zeros", "(", "\n", "decoder_out", ".", "output_tokens", ".", "size", "(", "0", ")", "\n", ")", ".", "bool", "(", ")", "\n", "\n", "", "if", "step", "==", "self", ".", "max_iter", ":", "# reach last iteration, terminate", "\n", "                ", "terminated", ".", "fill_", "(", "1", ")", "\n", "\n", "# collect finalized sentences", "\n", "", "finalized_idxs", "=", "sent_idxs", "[", "terminated", "]", "\n", "finalized_tokens", "=", "decoder_out", ".", "output_tokens", "[", "terminated", "]", "\n", "finalized_scores", "=", "decoder_out", ".", "output_scores", "[", "terminated", "]", "\n", "finalized_attn", "=", "(", "\n", "None", "\n", "if", "(", "decoder_out", ".", "attn", "is", "None", "or", "decoder_out", ".", "attn", ".", "size", "(", "0", ")", "==", "0", ")", "\n", "else", "decoder_out", ".", "attn", "[", "terminated", "]", "\n", ")", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "                ", "finalized_history_tokens", "=", "[", "h", "[", "terminated", "]", "for", "h", "in", "decoder_out", ".", "history", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "finalized_idxs", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "=", "[", "\n", "finalized_hypos", "(", "\n", "step", ",", "\n", "finalized_tokens", "[", "i", "]", ",", "\n", "finalized_scores", "[", "i", "]", ",", "\n", "None", "if", "finalized_attn", "is", "None", "else", "finalized_attn", "[", "i", "]", ",", "\n", ")", "\n", "]", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "                    ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "[", "0", "]", "[", "\"history\"", "]", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "finalized_history_tokens", ")", ")", ":", "\n", "                        ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "[", "0", "]", "[", "\"history\"", "]", ".", "append", "(", "\n", "finalized_hypos", "(", "\n", "step", ",", "finalized_history_tokens", "[", "j", "]", "[", "i", "]", ",", "None", ",", "None", "\n", ")", "\n", ")", "\n", "\n", "# check if all terminated", "\n", "", "", "", "if", "terminated", ".", "sum", "(", ")", "==", "terminated", ".", "size", "(", "0", ")", ":", "\n", "                ", "break", "\n", "\n", "# for next step", "\n", "", "not_terminated", "=", "~", "terminated", "\n", "prev_decoder_out", "=", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "decoder_out", ".", "output_tokens", "[", "not_terminated", "]", ",", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "[", "not_terminated", "]", ",", "\n", "attn", "=", "decoder_out", ".", "attn", "[", "not_terminated", "]", "\n", "if", "(", "decoder_out", ".", "attn", "is", "not", "None", "and", "decoder_out", ".", "attn", ".", "size", "(", "0", ")", ">", "0", ")", "\n", "else", "None", ",", "\n", "history", "=", "[", "h", "[", "not_terminated", "]", "for", "h", "in", "decoder_out", ".", "history", "]", "\n", "if", "decoder_out", ".", "history", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "encoder_out", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "encoder_out", ",", "not_terminated", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", ")", "\n", ")", "\n", "sent_idxs", "=", "sent_idxs", "[", "not_terminated", "]", "\n", "prev_output_tokens", "=", "prev_decoder_out", ".", "output_tokens", ".", "clone", "(", ")", "\n", "\n", "", "if", "self", ".", "beam_size", ">", "1", ":", "\n", "            ", "if", "reranker", "is", "not", "None", ":", "\n", "                ", "finalized", "=", "self", ".", "rerank", "(", "\n", "reranker", ",", "finalized", ",", "[", "src_tokens", ",", "src_lengths", "]", ",", "self", ".", "beam_size", "\n", ")", "\n", "\n", "# aggregate information from length beam", "\n", "", "finalized", "=", "[", "\n", "finalized", "[", "\n", "np", ".", "argmax", "(", "\n", "[", "\n", "finalized", "[", "self", ".", "beam_size", "*", "i", "+", "j", "]", "[", "0", "]", "[", "\"score\"", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "beam_size", ")", "\n", "]", "\n", ")", "\n", "+", "self", ".", "beam_size", "*", "i", "\n", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "finalized", ")", "//", "self", ".", "beam_size", ")", "\n", "]", "\n", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.rerank": [[313, 360], ["iterative_refinement_generator.IterativeRefinementGenerator.rerank.rebuild_batch"], "methods", ["None"], ["", "def", "rerank", "(", "self", ",", "reranker", ",", "finalized", ",", "encoder_input", ",", "beam_size", ")", ":", "\n", "        ", "def", "rebuild_batch", "(", "finalized", ")", ":", "\n", "            ", "finalized_tokens", "=", "[", "f", "[", "0", "]", "[", "\"tokens\"", "]", "for", "f", "in", "finalized", "]", "\n", "finalized_maxlen", "=", "max", "(", "f", ".", "size", "(", "0", ")", "for", "f", "in", "finalized_tokens", ")", "\n", "final_output_tokens", "=", "(", "\n", "finalized_tokens", "[", "0", "]", "\n", ".", "new_zeros", "(", "len", "(", "finalized_tokens", ")", ",", "finalized_maxlen", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "finalized_tokens", ")", ":", "\n", "                ", "final_output_tokens", "[", "i", ",", ":", "f", ".", "size", "(", "0", ")", "]", "=", "f", "\n", "", "return", "final_output_tokens", "\n", "\n", "", "final_output_tokens", "=", "rebuild_batch", "(", "finalized", ")", "\n", "final_output_tokens", "[", "\n", ":", ",", "0", "\n", "]", "=", "self", ".", "eos", "# autoregressive model assumes starting with EOS", "\n", "\n", "reranker_encoder_out", "=", "reranker", ".", "encoder", "(", "*", "encoder_input", ")", "\n", "length_beam_order", "=", "(", "\n", "utils", ".", "new_arange", "(", "\n", "final_output_tokens", ",", "beam_size", ",", "reranker_encoder_out", ".", "encoder_out", ".", "size", "(", "1", ")", "\n", ")", "\n", ".", "t", "(", ")", "\n", ".", "reshape", "(", "-", "1", ")", "\n", ")", "\n", "reranker_encoder_out", "=", "reranker", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "reranker_encoder_out", ",", "length_beam_order", "\n", ")", "\n", "reranking_scores", "=", "reranker", ".", "get_normalized_probs", "(", "\n", "reranker", ".", "decoder", "(", "final_output_tokens", "[", ":", ",", ":", "-", "1", "]", ",", "reranker_encoder_out", ")", ",", "\n", "True", ",", "\n", "None", ",", "\n", ")", "\n", "reranking_scores", "=", "reranking_scores", ".", "gather", "(", "2", ",", "final_output_tokens", "[", ":", ",", "1", ":", ",", "None", "]", ")", "\n", "reranking_masks", "=", "final_output_tokens", "[", ":", ",", "1", ":", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "reranking_scores", "=", "(", "\n", "reranking_scores", "[", ":", ",", ":", ",", "0", "]", ".", "masked_fill_", "(", "~", "reranking_masks", ",", "0", ")", ".", "sum", "(", "1", ")", "\n", ")", "\n", "reranking_scores", "=", "reranking_scores", "/", "reranking_masks", ".", "sum", "(", "1", ")", ".", "type_as", "(", "\n", "reranking_scores", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "finalized", "[", "i", "]", "[", "0", "]", "[", "\"score\"", "]", "=", "reranking_scores", "[", "i", "]", "\n", "\n", "", "return", "finalized", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState.__init__": [[13, 16], ["object.__init__", "incremental_decoding_utils.FairseqIncrementalState.init_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState.init_incremental_state"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "init_incremental_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState.init_incremental_state": [[17, 19], ["str", "uuid.uuid4"], "methods", ["None"], ["", "def", "init_incremental_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "_incremental_state_id", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key": [[20, 22], ["None"], "methods", ["None"], ["", "def", "_get_full_incremental_state_key", "(", "self", ",", "key", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\"{}.{}\"", ".", "format", "(", "self", ".", "_incremental_state_id", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState.get_incremental_state": [[23, 33], ["incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], ["", "def", "get_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "full_key", "=", "self", ".", "_get_full_incremental_state_key", "(", "key", ")", "\n", "if", "incremental_state", "is", "None", "or", "full_key", "not", "in", "incremental_state", ":", "\n", "            ", "return", "None", "\n", "", "return", "incremental_state", "[", "full_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState.set_incremental_state": [[34, 45], ["incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], ["", "def", "set_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "        ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "full_key", "=", "self", ".", "_get_full_incremental_state_key", "(", "key", ")", "\n", "incremental_state", "[", "full_key", "]", "=", "value", "\n", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.incremental_decoding_utils.with_incremental_state": [[47, 52], ["tuple"], "function", ["None"], ["", "", "def", "with_incremental_state", "(", "cls", ")", ":", "\n", "    ", "cls", ".", "__bases__", "=", "(", "FairseqIncrementalState", ",", ")", "+", "tuple", "(", "\n", "b", "for", "b", "in", "cls", ".", "__bases__", "if", "b", "!=", "FairseqIncrementalState", "\n", ")", "\n", "return", "cls", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open": [[43, 68], ["file_io.PathManager.open"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["@", "staticmethod", "\n", "def", "open", "(", "\n", "path", ":", "str", ",", "\n", "mode", ":", "str", "=", "\"r\"", ",", "\n", "buffering", ":", "int", "=", "-", "1", ",", "\n", "encoding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "errors", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "newline", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "open", "(", "\n", "path", "=", "path", ",", "\n", "mode", "=", "mode", ",", "\n", "buffering", "=", "buffering", ",", "\n", "encoding", "=", "encoding", ",", "\n", "errors", "=", "errors", ",", "\n", "newline", "=", "newline", ",", "\n", ")", "\n", "", "return", "open", "(", "\n", "path", ",", "\n", "mode", "=", "mode", ",", "\n", "buffering", "=", "buffering", ",", "\n", "encoding", "=", "encoding", ",", "\n", "errors", "=", "errors", ",", "\n", "newline", "=", "newline", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy": [[70, 77], ["shutil.copyfile", "FVCorePathManager.copy"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy"], ["", "@", "staticmethod", "\n", "def", "copy", "(", "src_path", ":", "str", ",", "dst_path", ":", "str", ",", "overwrite", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "copy", "(", "\n", "src_path", "=", "src_path", ",", "dst_path", "=", "dst_path", ",", "overwrite", "=", "overwrite", "\n", ")", "\n", "", "return", "shutil", ".", "copyfile", "(", "src_path", ",", "dst_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path": [[78, 83], ["FVCorePathManager.get_local_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path"], ["", "@", "staticmethod", "\n", "def", "get_local_path", "(", "path", ":", "str", ",", "**", "kwargs", ")", "->", "str", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "get_local_path", "(", "path", ",", "**", "kwargs", ")", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.exists": [[84, 89], ["os.path.exists", "FVCorePathManager.exists"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "exists", "(", "path", ")", "\n", "", "return", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile": [[90, 95], ["os.path.isfile", "FVCorePathManager.isfile"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile"], ["", "@", "staticmethod", "\n", "def", "isfile", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "isfile", "(", "path", ")", "\n", "", "return", "os", ".", "path", ".", "isfile", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.ls": [[96, 101], ["os.listdir", "FVCorePathManager.ls"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.ls"], ["", "@", "staticmethod", "\n", "def", "ls", "(", "path", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "ls", "(", "path", ")", "\n", "", "return", "os", ".", "listdir", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.mkdirs": [[102, 107], ["os.makedirs", "FVCorePathManager.mkdirs"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.mkdirs"], ["", "@", "staticmethod", "\n", "def", "mkdirs", "(", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "mkdirs", "(", "path", ")", "\n", "", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.rm": [[108, 113], ["os.remove", "FVCorePathManager.rm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.rm"], ["", "@", "staticmethod", "\n", "def", "rm", "(", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "rm", "(", "path", ")", "\n", "", "os", ".", "remove", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.chmod": [[114, 118], ["file_io.PathManager.path_requires_pathmanager", "os.chmod"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.path_requires_pathmanager", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.chmod"], ["", "@", "staticmethod", "\n", "def", "chmod", "(", "path", ":", "str", ",", "mode", ":", "int", ")", "->", "None", ":", "\n", "        ", "if", "not", "PathManager", ".", "path_requires_pathmanager", "(", "path", ")", ":", "\n", "            ", "os", ".", "chmod", "(", "path", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.register_handler": [[119, 123], ["FVCorePathManager.register_handler"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.register_handler"], ["", "", "@", "staticmethod", "\n", "def", "register_handler", "(", "handler", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "register_handler", "(", "handler", "=", "handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy_from_local": [[124, 133], ["shutil.copyfile", "FVCorePathManager.copy_from_local"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy_from_local"], ["", "", "@", "staticmethod", "\n", "def", "copy_from_local", "(", "\n", "local_path", ":", "str", ",", "dst_path", ":", "str", ",", "overwrite", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "copy_from_local", "(", "\n", "local_path", "=", "local_path", ",", "dst_path", "=", "dst_path", ",", "overwrite", "=", "overwrite", ",", "**", "kwargs", "\n", ")", "\n", "", "return", "shutil", ".", "copyfile", "(", "local_path", ",", "dst_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.path_requires_pathmanager": [[134, 142], ["FVCorePathManager._path_handlers.keys", "path.startswith"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "path_requires_pathmanager", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Do we require PathManager to access given path?\"\"\"", "\n", "if", "FVCorePathManager", ":", "\n", "            ", "for", "p", "in", "FVCorePathManager", ".", "_path_handlers", ".", "keys", "(", ")", ":", "\n", "                ", "if", "path", ".", "startswith", "(", "p", ")", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.supports_rename": [[143, 147], ["file_io.PathManager.path_requires_pathmanager"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.path_requires_pathmanager"], ["", "@", "staticmethod", "\n", "def", "supports_rename", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "# PathManager doesn't yet support renames", "\n", "        ", "return", "not", "PathManager", ".", "path_requires_pathmanager", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.rename": [[148, 151], ["os.rename"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.rename"], ["", "@", "staticmethod", "\n", "def", "rename", "(", "src", ":", "str", ",", "dst", ":", "str", ")", ":", "\n", "        ", "os", ".", "rename", "(", "src", ",", "dst", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.save_checkpoint": [[30, 136], ["getattr", "trainer.consolidate_optimizer", "meters.StopwatchMeter", "meters.StopwatchMeter.start", "epoch_itr.end_of_epoch", "trainer.get_num_updates", "logger.info", "collections.OrderedDict", "hasattr", "os.makedirs", "best_function", "epoch_itr.state_dict", "extra_state.update", "os.path.join", "len", "trainer.save_checkpoint", "meters.StopwatchMeter.stop", "logger.info", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.save_checkpoint.is_better"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.consolidate_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.end_of_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.checkpoint_paths"], ["def", "save_checkpoint", "(", "cfg", ":", "CheckpointConfig", ",", "trainer", ",", "epoch_itr", ",", "val_loss", ")", ":", "\n", "    ", "from", "fairseq", "import", "meters", "\n", "\n", "# only one worker should attempt to create the required dir", "\n", "if", "cfg", ".", "distributed_rank", "==", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "cfg", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "prev_best", "=", "getattr", "(", "save_checkpoint", ",", "\"best\"", ",", "val_loss", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "        ", "best_function", "=", "max", "if", "cfg", ".", "maximize_best_checkpoint_metric", "else", "min", "\n", "save_checkpoint", ".", "best", "=", "best_function", "(", "val_loss", ",", "prev_best", ")", "\n", "\n", "", "if", "cfg", ".", "no_save", ":", "\n", "        ", "return", "\n", "\n", "", "trainer", ".", "consolidate_optimizer", "(", ")", "\n", "\n", "if", "not", "trainer", ".", "is_data_parallel_master", ":", "\n", "        ", "return", "\n", "\n", "", "write_timer", "=", "meters", ".", "StopwatchMeter", "(", ")", "\n", "write_timer", ".", "start", "(", ")", "\n", "\n", "epoch", "=", "epoch_itr", ".", "epoch", "\n", "end_of_epoch", "=", "epoch_itr", ".", "end_of_epoch", "(", ")", "\n", "updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Preparing to save checkpoint for epoch {epoch} @ {updates} updates\"", ")", "\n", "\n", "def", "is_better", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", ">=", "b", "if", "cfg", ".", "maximize_best_checkpoint_metric", "else", "a", "<=", "b", "\n", "\n", "", "suffix", "=", "cfg", ".", "checkpoint_suffix", "or", "\"\"", "\n", "checkpoint_conds", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "checkpoint_conds", "[", "\"checkpoint{}{}.pt\"", ".", "format", "(", "epoch", ",", "suffix", ")", "]", "=", "(", "\n", "end_of_epoch", "and", "not", "cfg", ".", "no_epoch_checkpoints", "and", "epoch", "%", "cfg", ".", "save_interval", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_{}_{}{}.pt\"", ".", "format", "(", "epoch", ",", "updates", ",", "suffix", ")", "]", "=", "(", "\n", "not", "end_of_epoch", "\n", "and", "cfg", ".", "save_interval_updates", ">", "0", "\n", "and", "updates", "%", "cfg", ".", "save_interval_updates", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_best{}.pt\"", ".", "format", "(", "suffix", ")", "]", "=", "val_loss", "is", "not", "None", "and", "(", "\n", "not", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", "\n", "or", "is_better", "(", "val_loss", ",", "save_checkpoint", ".", "best", ")", "\n", ")", "\n", "if", "val_loss", "is", "not", "None", "and", "cfg", ".", "keep_best_checkpoints", ">", "0", ":", "\n", "        ", "checkpoint_conds", "[", "\n", "\"checkpoint.best_{}_{:.2f}.pt\"", ".", "format", "(", "cfg", ".", "best_checkpoint_metric", ",", "val_loss", ")", "\n", "]", "=", "not", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", "or", "is_better", "(", "\n", "val_loss", ",", "save_checkpoint", ".", "best", "\n", ")", "\n", "", "checkpoint_conds", "[", "\n", "\"checkpoint_last{}.pt\"", ".", "format", "(", "suffix", ")", "\n", "]", "=", "not", "cfg", ".", "no_last_checkpoints", "\n", "\n", "extra_state", "=", "{", "\"train_iterator\"", ":", "epoch_itr", ".", "state_dict", "(", ")", ",", "\"val_loss\"", ":", "val_loss", "}", "\n", "if", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", ":", "\n", "        ", "extra_state", ".", "update", "(", "{", "\"best\"", ":", "save_checkpoint", ".", "best", "}", ")", "\n", "\n", "", "checkpoints", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "cfg", ".", "save_dir", ",", "fn", ")", "for", "fn", ",", "cond", "in", "checkpoint_conds", ".", "items", "(", ")", "if", "cond", "\n", "]", "\n", "if", "len", "(", "checkpoints", ")", ">", "0", ":", "\n", "        ", "trainer", ".", "save_checkpoint", "(", "checkpoints", "[", "0", "]", ",", "extra_state", ")", "\n", "for", "cp", "in", "checkpoints", "[", "1", ":", "]", ":", "\n", "            ", "assert", "PathManager", ".", "copy", "(", "\n", "checkpoints", "[", "0", "]", ",", "cp", ",", "overwrite", "=", "True", "\n", ")", ",", "f\"Failed to copy {checkpoints[0]} to {cp}\"", "\n", "\n", "", "write_timer", ".", "stop", "(", ")", "\n", "logger", ".", "info", "(", "\n", "\"Saved checkpoint {} (epoch {} @ {} updates, score {}) (writing took {} seconds)\"", ".", "format", "(", "\n", "checkpoints", "[", "0", "]", ",", "epoch", ",", "updates", ",", "val_loss", ",", "write_timer", ".", "sum", "\n", ")", "\n", ")", "\n", "\n", "", "if", "not", "end_of_epoch", "and", "cfg", ".", "keep_interval_updates", ">", "0", ":", "\n", "# remove old checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "\n", "cfg", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint_\\d+_(\\d+)\\.pt\"", "\n", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_interval_updates", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n", "", "", "", "if", "cfg", ".", "keep_last_epochs", ">", "0", ":", "\n", "# remove old epoch checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "cfg", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_last_epochs", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n", "", "", "", "if", "cfg", ".", "keep_best_checkpoints", ">", "0", ":", "\n", "# only keep the best N checkpoints according to validation metric", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "\n", "cfg", ".", "save_dir", ",", "\n", "pattern", "=", "r\"checkpoint\\.best_{}_(\\d+\\.?\\d*)\\.pt\"", ".", "format", "(", "\n", "cfg", ".", "best_checkpoint_metric", "\n", ")", ",", "\n", ")", "\n", "if", "not", "cfg", ".", "maximize_best_checkpoint_metric", ":", "\n", "            ", "checkpoints", "=", "checkpoints", "[", ":", ":", "-", "1", "]", "\n", "", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_best_checkpoints", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint": [[138, 227], ["ast.literal_eval", "trainer.load_checkpoint", "trainer.lr_step", "ValueError", "os.path.join", "ValueError", "trainer.get_train_iterator", "trainer.get_train_iterator.load_state_dict", "trainer.get_train_iterator", "fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "cfg.restore_file.replace", "logger.info", "ValueError", "str"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "", "", "def", "load_checkpoint", "(", "cfg", ":", "CheckpointConfig", ",", "trainer", ",", "**", "passthrough_args", ")", ":", "\n", "    ", "\"\"\"\n    Load a checkpoint and restore the training iterator.\n\n    *passthrough_args* will be passed through to\n    ``trainer.get_train_iterator``.\n    \"\"\"", "\n", "\n", "reset_optimizer", "=", "cfg", ".", "reset_optimizer", "\n", "reset_lr_scheduler", "=", "cfg", ".", "reset_lr_scheduler", "\n", "optimizer_overrides", "=", "ast", ".", "literal_eval", "(", "cfg", ".", "optimizer_overrides", ")", "\n", "reset_meters", "=", "cfg", ".", "reset_meters", "\n", "reset_dataloader", "=", "cfg", ".", "reset_dataloader", "\n", "\n", "if", "cfg", ".", "finetune_from_model", "is", "not", "None", "and", "(", "\n", "reset_optimizer", "or", "reset_lr_scheduler", "or", "reset_meters", "or", "reset_dataloader", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--finetune-from-model can not be set together with either --reset-optimizer\"", "\n", "\" or reset_lr_scheduler or reset_meters or reset_dataloader\"", "\n", ")", "\n", "\n", "", "suffix", "=", "cfg", ".", "checkpoint_suffix", "\n", "if", "(", "\n", "cfg", ".", "restore_file", "==", "\"checkpoint_last.pt\"", "\n", ")", ":", "# default value of restore_file is 'checkpoint_last.pt'", "\n", "        ", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "\n", "cfg", ".", "save_dir", ",", "\"checkpoint_last{}.pt\"", ".", "format", "(", "suffix", ")", "\n", ")", "\n", "first_launch", "=", "not", "PathManager", ".", "exists", "(", "checkpoint_path", ")", "\n", "if", "cfg", ".", "finetune_from_model", "is", "not", "None", "and", "first_launch", ":", "\n", "# if there is no last checkpoint to restore, start the finetune from pretrained model", "\n", "# else just use usual logic to load checkpoint, e.g. restart from last checkpoint and etc.", "\n", "            ", "if", "PathManager", ".", "exists", "(", "cfg", ".", "finetune_from_model", ")", ":", "\n", "                ", "checkpoint_path", "=", "cfg", ".", "finetune_from_model", "\n", "reset_optimizer", "=", "True", "\n", "reset_lr_scheduler", "=", "True", "\n", "reset_meters", "=", "True", "\n", "reset_dataloader", "=", "True", "\n", "logger", ".", "info", "(", "\n", "f\"loading pretrained model from {checkpoint_path}: \"", "\n", "\"optimizer, lr scheduler, meters, dataloader will be reset\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"--funetune-from-model {cfg.finetune_from_model} does not exist\"", "\n", ")", "\n", "", "", "", "elif", "cfg", ".", "model_parallel_size", ">", "1", ":", "\n", "        ", "checkpoint_path", "=", "cfg", ".", "restore_file", ".", "replace", "(", "\".pt\"", ",", "suffix", "+", "\".pt\"", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint_path", "=", "cfg", ".", "restore_file", "\n", "\n", "", "if", "cfg", ".", "restore_file", "!=", "\"checkpoint_last.pt\"", "and", "cfg", ".", "finetune_from_model", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--finetune-from-model and --restore-file (non-default value) \"", "\n", "\"can not be specified together: \"", "+", "str", "(", "cfg", ")", "\n", ")", "\n", "\n", "", "extra_state", "=", "trainer", ".", "load_checkpoint", "(", "\n", "checkpoint_path", ",", "\n", "reset_optimizer", ",", "\n", "reset_lr_scheduler", ",", "\n", "optimizer_overrides", ",", "\n", "reset_meters", "=", "reset_meters", ",", "\n", ")", "\n", "\n", "if", "(", "\n", "extra_state", "is", "not", "None", "\n", "and", "\"best\"", "in", "extra_state", "\n", "and", "not", "reset_optimizer", "\n", "and", "not", "reset_meters", "\n", ")", ":", "\n", "        ", "save_checkpoint", ".", "best", "=", "extra_state", "[", "\"best\"", "]", "\n", "\n", "", "if", "extra_state", "is", "not", "None", "and", "not", "reset_dataloader", ":", "\n", "# restore iterator from checkpoint", "\n", "        ", "itr_state", "=", "extra_state", "[", "\"train_iterator\"", "]", "\n", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "itr_state", "[", "\"epoch\"", "]", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "epoch_itr", ".", "load_state_dict", "(", "itr_state", ")", "\n", "", "else", ":", "\n", "        ", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "1", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "\n", "", "trainer", ".", "lr_step", "(", "epoch_itr", ".", "epoch", ")", "\n", "\n", "return", "extra_state", ",", "epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu": [[229, 275], ["fairseq.file_io.PathManager.get_local_path", "checkpoint_utils._upgrade_state_dict", "fairseq.file_io.PathManager.path_requires_pathmanager", "fairseq.file_io.PathManager.get_local_path", "open", "torch.load", "arg_overrides.items", "fairseq.dataclass.utils.overwrite_args_by_name", "os.remove", "torch.distributed.barrier", "setattr", "torch.device"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils._upgrade_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.path_requires_pathmanager", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.overwrite_args_by_name", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device"], ["", "def", "load_checkpoint_to_cpu", "(", "path", ",", "arg_overrides", "=", "None", ",", "load_on_all_ranks", "=", "False", ")", ":", "\n", "    ", "\"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\n\n    If doing single-GPU training or if the checkpoint is only being loaded by at\n    most one process on each node (current default behavior is for only rank 0\n    to read the checkpoint from disk), load_on_all_ranks should be False to\n    avoid errors from torch.distributed not having been initialized or\n    torch.distributed.barrier() hanging.\n\n    If all processes on each node may be loading the checkpoint\n    simultaneously, load_on_all_ranks should be set to True to avoid I/O\n    conflicts.\n\n    There's currently no support for > 1 but < all processes loading the\n    checkpoint on each node.\n    \"\"\"", "\n", "local_path", "=", "PathManager", ".", "get_local_path", "(", "path", ")", "\n", "# The locally cached file returned by get_local_path() may be stale for", "\n", "# remote files that are periodically updated/overwritten (ex:", "\n", "# checkpoint_last.pt) - so we remove the local copy, sync across processes", "\n", "# (if needed), and then download a fresh copy.", "\n", "if", "local_path", "!=", "path", "and", "PathManager", ".", "path_requires_pathmanager", "(", "path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "remove", "(", "local_path", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "# With potentially multiple processes removing the same file, the", "\n", "# file being missing is benign (missing_ok isn't available until", "\n", "# Python 3.8).", "\n", "            ", "pass", "\n", "", "if", "load_on_all_ranks", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "local_path", "=", "PathManager", ".", "get_local_path", "(", "path", ")", "\n", "\n", "", "with", "open", "(", "local_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "state", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", "and", "arg_overrides", "is", "not", "None", ":", "\n", "        ", "args", "=", "state", "[", "\"args\"", "]", "\n", "for", "arg_name", ",", "arg_val", "in", "arg_overrides", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "arg_name", ",", "arg_val", ")", "\n", "\n", "", "", "if", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", "and", "arg_overrides", "is", "not", "None", ":", "\n", "        ", "overwrite_args_by_name", "(", "state", "[", "\"cfg\"", "]", ",", "arg_overrides", ")", "\n", "\n", "", "state", "=", "_upgrade_state_dict", "(", "state", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble": [[277, 307], ["checkpoint_utils.load_model_ensemble_and_task"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble_and_task"], ["", "def", "load_model_ensemble", "(", "\n", "filenames", ",", "\n", "arg_overrides", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "task", "=", "None", ",", "\n", "strict", "=", "True", ",", "\n", "suffix", "=", "\"\"", ",", "\n", "num_shards", "=", "1", ",", "\n", "state", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads an ensemble of models.\n\n    Args:\n        filenames (List[str]): checkpoint files to load\n        arg_overrides (Dict[str,Any], optional): override model args that\n            were used during model training\n        task (fairseq.tasks.FairseqTask, optional): task to use for loading\n    \"\"\"", "\n", "assert", "not", "(", "\n", "strict", "and", "num_shards", ">", "1", "\n", ")", ",", "\"Cannot load state dict with strict=True and checkpoint shards > 1\"", "\n", "ensemble", ",", "args", ",", "_task", "=", "load_model_ensemble_and_task", "(", "\n", "filenames", ",", "\n", "arg_overrides", ",", "\n", "task", ",", "\n", "strict", ",", "\n", "suffix", ",", "\n", "num_shards", ",", "\n", "state", ",", "\n", ")", "\n", "return", "ensemble", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble_and_task": [[309, 362], ["range", "ensemble.append", "len", "tasks.setup_task.build_model", "task.build_model.load_state_dict", "filename.replace.replace", "fairseq.file_io.PathManager.exists", "IOError", "checkpoint_utils.load_checkpoint_to_cpu", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "tasks.setup_task", "RuntimeError", "load_checkpoint_to_cpu.keys"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task"], ["", "def", "load_model_ensemble_and_task", "(", "\n", "filenames", ",", "\n", "arg_overrides", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "task", "=", "None", ",", "\n", "strict", "=", "True", ",", "\n", "suffix", "=", "\"\"", ",", "\n", "num_shards", "=", "1", ",", "\n", "state", "=", "None", ",", "\n", ")", ":", "\n", "    ", "assert", "state", "is", "None", "or", "len", "(", "filenames", ")", "==", "1", "\n", "\n", "from", "fairseq", "import", "tasks", "\n", "\n", "assert", "not", "(", "\n", "strict", "and", "num_shards", ">", "1", "\n", ")", ",", "\"Cannot load state dict with strict=True and checkpoint shards > 1\"", "\n", "ensemble", "=", "[", "]", "\n", "cfg", "=", "None", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "orig_filename", "=", "filename", "\n", "assert", "num_shards", ">", "0", "\n", "for", "shard_idx", "in", "range", "(", "num_shards", ")", ":", "\n", "            ", "if", "num_shards", "==", "1", ":", "\n", "                ", "filename", "=", "filename", ".", "replace", "(", "\".pt\"", ",", "suffix", "+", "\".pt\"", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "orig_filename", "[", ":", "-", "3", "]", "+", "f\"_part{shard_idx}.pt\"", "\n", "\n", "", "if", "not", "PathManager", ".", "exists", "(", "filename", ")", ":", "\n", "                ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "filename", ")", ")", "\n", "", "if", "state", "is", "None", ":", "\n", "                ", "state", "=", "load_checkpoint_to_cpu", "(", "filename", ",", "arg_overrides", ")", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", ":", "\n", "                ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "elif", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", ":", "\n", "                ", "cfg", "=", "state", "[", "\"cfg\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "f\"Neither args nor cfg exist in state keys = {state.keys()}\"", "\n", ")", "\n", "\n", "", "if", "task", "is", "None", ":", "\n", "                ", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "\n", "# build model for ensemble", "\n", "", "model", "=", "task", ".", "build_model", "(", "cfg", ".", "model", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "strict", ",", "model_cfg", "=", "cfg", ".", "model", ")", "\n", "\n", "# reset state so it gets loaded for the next model in ensemble", "\n", "state", "=", "None", "\n", "\n", "", "ensemble", ".", "append", "(", "model", ")", "\n", "", "return", "ensemble", ",", "cfg", ",", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.checkpoint_paths": [[364, 381], ["re.compile", "os.listdir", "enumerate", "re.compile.fullmatch", "os.path.join", "entries.append", "sorted", "float", "len", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.groups"], "function", ["None"], ["", "def", "checkpoint_paths", "(", "path", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", ":", "\n", "    ", "\"\"\"Retrieves all checkpoints found in `path` directory.\n\n    Checkpoints are identified by matching filename to the specified pattern. If\n    the pattern contains groups, the result will be sorted by the first group in\n    descending order.\n    \"\"\"", "\n", "pt_regexp", "=", "re", ".", "compile", "(", "pattern", ")", "\n", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "m", "=", "pt_regexp", ".", "fullmatch", "(", "f", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "idx", "=", "float", "(", "m", ".", "group", "(", "1", ")", ")", "if", "len", "(", "m", ".", "groups", "(", ")", ")", ">", "0", "else", "i", "\n", "entries", ".", "append", "(", "(", "idx", ",", "m", ".", "group", "(", "0", ")", ")", ")", "\n", "", "", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "x", "[", "1", "]", ")", "for", "x", "in", "sorted", "(", "entries", ",", "reverse", "=", "True", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.torch_persistent_save": [[383, 394], ["isinstance", "range", "fairseq.file_io.PathManager.open", "checkpoint_utils.torch_persistent_save", "torch.save", "logger.error", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save"], ["", "def", "torch_persistent_save", "(", "obj", ",", "f", ")", ":", "\n", "    ", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "f", ",", "\"wb\"", ")", "as", "h", ":", "\n", "            ", "torch_persistent_save", "(", "obj", ",", "h", ")", "\n", "", "return", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "torch", ".", "save", "(", "obj", ",", "f", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "if", "i", "==", "2", ":", "\n", "                ", "logger", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.save_state": [[396, 455], ["utils.has_parameters", "isinstance", "utils.move_to_cpu", "fairseq.file_io.PathManager.supports_rename", "kwargs.get", "criterion.state_dict", "optimizer.state_dict", "fairseq.file_io.PathManager.rename", "fairseq.file_io.PathManager.open", "checkpoint_utils.torch_persistent_save", "fairseq.file_io.PathManager.open", "checkpoint_utils.torch_persistent_save", "lr_scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.supports_rename", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.rename", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "", "", "", "def", "save_state", "(", "\n", "filename", ",", "\n", "cfg", ":", "FairseqConfig", ",", "\n", "model_state_dict", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "num_updates", ",", "\n", "optim_history", "=", "None", ",", "\n", "extra_state", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "utils", "\n", "\n", "if", "optim_history", "is", "None", ":", "\n", "        ", "optim_history", "=", "[", "]", "\n", "", "if", "extra_state", "is", "None", ":", "\n", "        ", "extra_state", "=", "{", "}", "\n", "", "state_dict", "=", "{", "\n", "\"cfg\"", ":", "cfg", ",", "\n", "\"args\"", ":", "kwargs", ".", "get", "(", "\"args\"", ",", "None", ")", ",", "\n", "\"model\"", ":", "model_state_dict", "or", "{", "}", ",", "\n", "\"optimizer_history\"", ":", "optim_history", "\n", "+", "[", "\n", "{", "\n", "\"criterion_name\"", ":", "criterion", ".", "__class__", ".", "__name__", ",", "\n", "\"optimizer_name\"", ":", "optimizer", ".", "__class__", ".", "__name__", ",", "\n", "\"lr_scheduler_state\"", ":", "lr_scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"num_updates\"", ":", "num_updates", ",", "\n", "}", "\n", "]", ",", "\n", "\"extra_state\"", ":", "extra_state", ",", "\n", "}", "\n", "if", "utils", ".", "has_parameters", "(", "criterion", ")", ":", "\n", "        ", "state_dict", "[", "\"criterion\"", "]", "=", "criterion", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "cfg", "is", "None", ":", "\n", "        ", "cfg", "=", "state_dict", "[", "\"args\"", "]", "\n", "assert", "cfg", "is", "not", "None", ",", "\"must provide cfg or args\"", "\n", "\n", "", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "no_save_optimizer_state", "=", "cfg", ".", "checkpoint", ".", "no_save_optimizer_state", "\n", "", "else", ":", "\n", "        ", "no_save_optimizer_state", "=", "cfg", ".", "no_save_optimizer_state", "\n", "", "if", "not", "no_save_optimizer_state", ":", "\n", "        ", "state_dict", "[", "\"last_optimizer_state\"", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "# keep everything on CPU", "\n", "", "state_dict", "=", "utils", ".", "move_to_cpu", "(", "state_dict", ")", "\n", "\n", "if", "PathManager", ".", "supports_rename", "(", "filename", ")", ":", "\n", "# do atomic save", "\n", "        ", "with", "PathManager", ".", "open", "(", "filename", "+", "\".tmp\"", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch_persistent_save", "(", "state_dict", ",", "f", ")", "\n", "", "PathManager", ".", "rename", "(", "filename", "+", "\".tmp\"", ",", "filename", ")", "\n", "", "else", ":", "\n", "# fallback to non-atomic save", "\n", "        ", "with", "PathManager", ".", "open", "(", "filename", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch_persistent_save", "(", "state_dict", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils._upgrade_state_dict": [[457, 558], ["hasattr", "getattr", "hasattr", "hasattr", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "hasattr", "state[].get", "hasattr", "getattr", "max", "hasattr", "hasattr", "hasattr", "hasattr", "isinstance", "omegaconf.open_dict", "[].get"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf"], ["", "", "", "def", "_upgrade_state_dict", "(", "state", ")", ":", "\n", "    ", "\"\"\"Helper for upgrading old model checkpoints.\"\"\"", "\n", "from", "fairseq", "import", "models", ",", "registry", ",", "tasks", "\n", "\n", "# add optimizer_history", "\n", "if", "\"optimizer_history\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "=", "[", "\n", "{", "\"criterion_name\"", ":", "\"CrossEntropyCriterion\"", ",", "\"best_loss\"", ":", "state", "[", "\"best_loss\"", "]", "}", "\n", "]", "\n", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"best_loss\"", "]", "\n", "# move extra_state into sub-dictionary", "\n", "", "if", "\"epoch\"", "in", "state", "and", "\"extra_state\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"epoch\"", "]", ",", "\n", "\"batch_offset\"", ":", "state", "[", "\"batch_offset\"", "]", ",", "\n", "\"val_loss\"", ":", "state", "[", "\"val_loss\"", "]", ",", "\n", "}", "\n", "del", "state", "[", "\"epoch\"", "]", "\n", "del", "state", "[", "\"batch_offset\"", "]", "\n", "del", "state", "[", "\"val_loss\"", "]", "\n", "# reduce optimizer history's memory usage (only keep the last state)", "\n", "", "if", "\"optimizer\"", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer\"", "]", "\n", "for", "optim_hist", "in", "state", "[", "\"optimizer_history\"", "]", ":", "\n", "            ", "del", "optim_hist", "[", "\"optimizer\"", "]", "\n", "# record the optimizer class name", "\n", "", "", "if", "\"optimizer_name\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer_name\"", "]", "=", "\"FairseqNAG\"", "\n", "# move best_loss into lr_scheduler_state", "\n", "", "if", "\"lr_scheduler_state\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"lr_scheduler_state\"", "]", "=", "{", "\n", "\"best\"", ":", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "}", "\n", "del", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "# keep track of number of updates", "\n", "", "if", "\"num_updates\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"num_updates\"", "]", "=", "0", "\n", "# old model checkpoints may not have separate source/target positions", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"max_positions\"", ")", "and", "not", "hasattr", "(", "\n", "state", "[", "\"args\"", "]", ",", "\"max_source_positions\"", "\n", ")", ":", "\n", "        ", "state", "[", "\"args\"", "]", ".", "max_source_positions", "=", "state", "[", "\"args\"", "]", ".", "max_positions", "\n", "state", "[", "\"args\"", "]", ".", "max_target_positions", "=", "state", "[", "\"args\"", "]", ".", "max_positions", "\n", "# use stateful training data iterator", "\n", "", "if", "\"train_iterator\"", "not", "in", "state", "[", "\"extra_state\"", "]", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"extra_state\"", "]", "[", "\"epoch\"", "]", ",", "\n", "\"iterations_in_epoch\"", ":", "state", "[", "\"extra_state\"", "]", ".", "get", "(", "\"batch_offset\"", ",", "0", ")", ",", "\n", "}", "\n", "\n", "# backward compatibility, cfg updates", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", ":", "\n", "# default to translation task", "\n", "        ", "if", "not", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"task\"", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "task", "=", "\"translation\"", "\n", "# --raw-text and --lazy-load are deprecated", "\n", "", "if", "getattr", "(", "state", "[", "\"args\"", "]", ",", "\"raw_text\"", ",", "False", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "dataset_impl", "=", "\"raw\"", "\n", "", "elif", "getattr", "(", "state", "[", "\"args\"", "]", ",", "\"lazy_load\"", ",", "False", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "dataset_impl", "=", "\"lazy\"", "\n", "# epochs start at 1", "\n", "", "if", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "is", "not", "None", ":", "\n", "            ", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "[", "\"epoch\"", "]", "=", "max", "(", "\n", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", ".", "get", "(", "\"epoch\"", ",", "1", ")", ",", "1", "\n", ")", "\n", "# --remove-bpe ==> --postprocess", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"remove_bpe\"", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "post_process", "=", "state", "[", "\"args\"", "]", ".", "remove_bpe", "\n", "# --min-lr ==> --stop-min-lr", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"min_lr\"", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "stop_min_lr", "=", "state", "[", "\"args\"", "]", ".", "min_lr", "\n", "del", "state", "[", "\"args\"", "]", ".", "min_lr", "\n", "# binary_cross_entropy => wav2vec criterion", "\n", "", "if", "(", "\n", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"criterion\"", ")", "\n", "and", "state", "[", "\"args\"", "]", ".", "criterion", "==", "\"binary_cross_entropy\"", "\n", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "criterion", "=", "\"wav2vec\"", "\n", "# speech_pretraining => audio pretraining", "\n", "", "if", "(", "\n", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"task\"", ")", "\n", "and", "state", "[", "\"args\"", "]", ".", "task", "==", "\"speech_pretraining\"", "\n", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "task", "=", "\"audio_pretraining\"", "\n", "# audio_cpc => wav2vec", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"arch\"", ")", "and", "state", "[", "\"args\"", "]", ".", "arch", "==", "\"audio_cpc\"", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "arch", "=", "\"wav2vec\"", "\n", "# convert legacy float learning rate to List[float]", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"lr\"", ")", "and", "isinstance", "(", "state", "[", "\"args\"", "]", ".", "lr", ",", "float", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "lr", "=", "[", "state", "[", "\"args\"", "]", ".", "lr", "]", "\n", "\n", "", "state", "[", "\"cfg\"", "]", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "\n", "", "if", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", ":", "\n", "        ", "with", "open_dict", "(", "state", "[", "\"cfg\"", "]", ")", ":", "\n", "# any upgrades for Hydra-based configs", "\n", "            ", "pass", "\n", "\n", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.prune_state_dict": [[560, 651], ["getattr", "getattr", "logger.info", "state_dict.keys", "isinstance", "sorted", "range", "re.compile", "pruning_passes.append", "pruning_passes.append", "re.search", "re.search.group", "omegaconf.open_dict", "contextlib.ExitStack", "hasattr", "hasattr", "isinstance", "getattr", "len", "str", "checkpoint_utils.prune_state_dict.create_pruning_pass"], "function", ["None"], ["", "def", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ":", "Optional", "[", "DictConfig", "]", ")", ":", "\n", "    ", "\"\"\"Prune the given state_dict if desired for LayerDrop\n    (https://arxiv.org/abs/1909.11556).\n\n    Training with LayerDrop allows models to be robust to pruning at inference\n    time. This function prunes state_dict to allow smaller models to be loaded\n    from a larger model and re-maps the existing state_dict for this to occur.\n\n    It's called by functions that load models from checkpoints and does not\n    need to be called directly.\n    \"\"\"", "\n", "arch", "=", "None", "\n", "if", "model_cfg", "is", "not", "None", ":", "\n", "        ", "arch", "=", "(", "\n", "model_cfg", ".", "_name", "\n", "if", "isinstance", "(", "model_cfg", ",", "DictConfig", ")", "\n", "else", "getattr", "(", "model_cfg", ",", "\"arch\"", ",", "None", ")", "\n", ")", "\n", "\n", "", "if", "not", "model_cfg", "or", "arch", "is", "None", "or", "arch", "==", "\"ptt_transformer\"", ":", "\n", "# args should not be none, but don't crash if it is.", "\n", "        ", "return", "state_dict", "\n", "\n", "", "encoder_layers_to_keep", "=", "getattr", "(", "model_cfg", ",", "\"encoder_layers_to_keep\"", ",", "None", ")", "\n", "decoder_layers_to_keep", "=", "getattr", "(", "model_cfg", ",", "\"decoder_layers_to_keep\"", ",", "None", ")", "\n", "\n", "if", "not", "encoder_layers_to_keep", "and", "not", "decoder_layers_to_keep", ":", "\n", "        ", "return", "state_dict", "\n", "\n", "# apply pruning", "\n", "", "logger", ".", "info", "(", "\n", "\"Pruning model to specified layer configuration - this works best if the model was trained with LayerDrop\"", "\n", ")", "\n", "\n", "def", "create_pruning_pass", "(", "layers_to_keep", ",", "layer_name", ")", ":", "\n", "        ", "keep_layers", "=", "sorted", "(", "\n", "int", "(", "layer_string", ")", "for", "layer_string", "in", "layers_to_keep", ".", "split", "(", "\",\"", ")", "\n", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "keep_layers", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "str", "(", "keep_layers", "[", "i", "]", ")", "]", "=", "str", "(", "i", ")", "\n", "\n", "", "regex", "=", "re", ".", "compile", "(", "r\"^{layer}.*\\.layers\\.(\\d+)\"", ".", "format", "(", "layer", "=", "layer_name", ")", ")", "\n", "return", "{", "\"substitution_regex\"", ":", "regex", ",", "\"mapping_dict\"", ":", "mapping_dict", "}", "\n", "\n", "", "pruning_passes", "=", "[", "]", "\n", "if", "encoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "encoder_layers_to_keep", ",", "\"encoder\"", ")", ")", "\n", "", "if", "decoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "decoder_layers_to_keep", ",", "\"decoder\"", ")", ")", "\n", "\n", "", "new_state_dict", "=", "{", "}", "\n", "for", "layer_name", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "match", "=", "re", ".", "search", "(", "r\"\\.layers\\.(\\d+)\\.\"", ",", "layer_name", ")", "\n", "# if layer has no number in it, it is a supporting layer, such as an", "\n", "# embedding", "\n", "if", "not", "match", ":", "\n", "            ", "new_state_dict", "[", "layer_name", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "continue", "\n", "\n", "# otherwise, layer should be pruned.", "\n", "", "original_layer_number", "=", "match", ".", "group", "(", "1", ")", "\n", "# figure out which mapping dict to replace from", "\n", "for", "pruning_pass", "in", "pruning_passes", ":", "\n", "            ", "if", "original_layer_number", "in", "pruning_pass", "[", "\"mapping_dict\"", "]", "and", "pruning_pass", "[", "\n", "\"substitution_regex\"", "\n", "]", ".", "search", "(", "layer_name", ")", ":", "\n", "                ", "new_layer_number", "=", "pruning_pass", "[", "\"mapping_dict\"", "]", "[", "original_layer_number", "]", "\n", "substitution_match", "=", "pruning_pass", "[", "\"substitution_regex\"", "]", ".", "search", "(", "\n", "layer_name", "\n", ")", "\n", "new_state_key", "=", "(", "\n", "layer_name", "[", ":", "substitution_match", ".", "start", "(", "1", ")", "]", "\n", "+", "new_layer_number", "\n", "+", "layer_name", "[", "substitution_match", ".", "end", "(", "1", ")", ":", "]", "\n", ")", "\n", "new_state_dict", "[", "new_state_key", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "\n", "# Since layers are now pruned, *_layers_to_keep are no longer needed.", "\n", "# This is more of \"It would make it work fix\" rather than a proper fix.", "\n", "", "", "", "if", "isinstance", "(", "model_cfg", ",", "DictConfig", ")", ":", "\n", "        ", "context", "=", "open_dict", "(", "model_cfg", ")", "\n", "", "else", ":", "\n", "        ", "context", "=", "contextlib", ".", "ExitStack", "(", ")", "\n", "", "with", "context", ":", "\n", "        ", "if", "hasattr", "(", "model_cfg", ",", "\"encoder_layers_to_keep\"", ")", ":", "\n", "            ", "model_cfg", ".", "encoder_layers_to_keep", "=", "None", "\n", "", "if", "hasattr", "(", "model_cfg", ",", "\"decoder_layers_to_keep\"", ")", ":", "\n", "            ", "model_cfg", ".", "decoder_layers_to_keep", "=", "None", "\n", "\n", "", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_pretrained_component_from_model": [[653, 682], ["checkpoint_utils.load_checkpoint_to_cpu", "isinstance", "collections.OrderedDict", "state[].keys", "component.load_state_dict", "fairseq.file_io.PathManager.exists", "IOError", "isinstance", "key.startswith", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "load_pretrained_component_from_model", "(", "\n", "component", ":", "Union", "[", "FairseqEncoder", ",", "FairseqDecoder", "]", ",", "checkpoint", ":", "str", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Load a pretrained FairseqEncoder or FairseqDecoder from checkpoint into the\n    provided `component` object. If state_dict fails to load, there may be a\n    mismatch in the architecture of the corresponding `component` found in the\n    `checkpoint` file.\n    \"\"\"", "\n", "if", "not", "PathManager", ".", "exists", "(", "checkpoint", ")", ":", "\n", "        ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "", "state", "=", "load_checkpoint_to_cpu", "(", "checkpoint", ")", "\n", "if", "isinstance", "(", "component", ",", "FairseqEncoder", ")", ":", "\n", "        ", "component_type", "=", "\"encoder\"", "\n", "", "elif", "isinstance", "(", "component", ",", "FairseqDecoder", ")", ":", "\n", "        ", "component_type", "=", "\"decoder\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"component to load must be either a FairseqEncoder or \"", "\n", "\"FairseqDecoder. Loading other component types are not supported.\"", "\n", ")", "\n", "", "component_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "state", "[", "\"model\"", "]", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "component_type", ")", ":", "\n", "# encoder.input_layers.0.0.weight --> input_layers.0.0.weight", "\n", "            ", "component_subkey", "=", "key", "[", "len", "(", "component_type", ")", "+", "1", ":", "]", "\n", "component_state_dict", "[", "component_subkey", "]", "=", "state", "[", "\"model\"", "]", "[", "key", "]", "\n", "", "", "component", ".", "load_state_dict", "(", "component_state_dict", ",", "strict", "=", "True", ")", "\n", "return", "component", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.verify_checkpoint_directory": [[684, 698], ["os.path.join", "os.path.exists", "os.makedirs", "os.remove", "open", "logger.warning"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "verify_checkpoint_directory", "(", "save_dir", ":", "str", ")", "->", "None", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "", "temp_file_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"dummy\"", ")", "\n", "try", ":", "\n", "        ", "with", "open", "(", "temp_file_path", ",", "\"w\"", ")", ":", "\n", "            ", "pass", "\n", "", "", "except", "OSError", "as", "e", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Unable to access checkpoint save directory: {}\"", ".", "format", "(", "save_dir", ")", "\n", ")", "\n", "raise", "e", "\n", "", "else", ":", "\n", "        ", "os", ".", "remove", "(", "temp_file_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.__init__": [[19, 112], ["torch.Module.__init__", "isinstance", "tgt_dict.pad", "tgt_dict.unk", "len", "min", "sequence_generator.SequenceGenerator.model.eval", "sequence_generator.EnsembleModel", "tgt_dict.eos", "symbols_to_strip_from_output.union", "fairseq.ngram_repeat_block.NGramRepeatBlock", "fairseq.search.BeamSearch", "hasattr", "sequence_generator.SequenceGenerator.lm_model.eval"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "models", ",", "\n", "tgt_dict", ",", "\n", "beam_size", "=", "1", ",", "\n", "max_len_a", "=", "0", ",", "\n", "max_len_b", "=", "200", ",", "\n", "min_len", "=", "1", ",", "\n", "normalize_scores", "=", "True", ",", "\n", "len_penalty", "=", "1.0", ",", "\n", "unk_penalty", "=", "0.0", ",", "\n", "temperature", "=", "1.0", ",", "\n", "match_source_len", "=", "False", ",", "\n", "no_repeat_ngram_size", "=", "0", ",", "\n", "search_strategy", "=", "None", ",", "\n", "eos", "=", "None", ",", "\n", "symbols_to_strip_from_output", "=", "None", ",", "\n", "lm_model", "=", "None", ",", "\n", "lm_weight", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models,\n                currently support fairseq.models.TransformerModel for scripting\n            beam_size (int, optional): beam width (default: 1)\n            max_len_a/b (int, optional): generate sequences of maximum length\n                ax + b, where x is the source length\n            min_len (int, optional): the minimum length of the generated output\n                (not including end-of-sentence)\n            normalize_scores (bool, optional): normalize scores by the length\n                of the output (default: True)\n            len_penalty (float, optional): length penalty, where <1.0 favors\n                shorter, >1.0 favors longer sentences (default: 1.0)\n            unk_penalty (float, optional): unknown word penalty, where <0\n                produces more unks, >0 produces fewer (default: 0.0)\n            temperature (float, optional): temperature, where values\n                >1.0 produce more uniform samples and values <1.0 produce\n                sharper samples (default: 1.0)\n            match_source_len (bool, optional): outputs should match the source\n                length (default: False)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "models", ",", "EnsembleModel", ")", ":", "\n", "            ", "self", ".", "model", "=", "models", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "EnsembleModel", "(", "models", ")", "\n", "", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "symbols_to_strip_from_output", "=", "(", "\n", "symbols_to_strip_from_output", ".", "union", "(", "{", "self", ".", "eos", "}", ")", "\n", "if", "symbols_to_strip_from_output", "is", "not", "None", "\n", "else", "{", "self", ".", "eos", "}", "\n", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "self", ".", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "min_len", "=", "min_len", "\n", "\n", "self", ".", "normalize_scores", "=", "normalize_scores", "\n", "self", ".", "len_penalty", "=", "len_penalty", "\n", "self", ".", "unk_penalty", "=", "unk_penalty", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "match_source_len", "=", "match_source_len", "\n", "\n", "if", "no_repeat_ngram_size", ">", "0", ":", "\n", "            ", "self", ".", "repeat_ngram_blocker", "=", "NGramRepeatBlock", "(", "no_repeat_ngram_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "repeat_ngram_blocker", "=", "None", "\n", "\n", "", "assert", "temperature", ">", "0", ",", "\"--temperature must be greater than 0\"", "\n", "\n", "self", ".", "search", "=", "(", "\n", "search", ".", "BeamSearch", "(", "tgt_dict", ")", "if", "search_strategy", "is", "None", "else", "search_strategy", "\n", ")", "\n", "# We only need to set src_lengths in LengthConstrainedBeamSearch.", "\n", "# As a module attribute, setting it would break in multithread", "\n", "# settings when the model is shared.", "\n", "self", ".", "should_set_src_lengths", "=", "(", "\n", "hasattr", "(", "self", ".", "search", ",", "\"needs_src_lengths\"", ")", "and", "self", ".", "search", ".", "needs_src_lengths", "\n", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "lm_model", "=", "lm_model", "\n", "self", ".", "lm_weight", "=", "lm_weight", "\n", "if", "self", ".", "lm_model", "is", "not", "None", ":", "\n", "            ", "self", ".", "lm_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda": [[113, 116], ["sequence_generator.SequenceGenerator.model.cuda"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.forward": [[117, 134], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._generate"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\n\n        Args:\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "prefix_tokens", ",", "bos_token", "=", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.generate_batched_itr": [[136, 167], ["enumerate", "fairseq.utils.move_to_cuda", "timer.start", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "input.items", "sum", "fairseq.utils.strip_pad", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.strip_pad"], ["", "def", "generate_batched_itr", "(", "self", ",", "data_itr", ",", "beam_size", "=", "None", ",", "cuda", "=", "False", ",", "timer", "=", "None", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n        Args:\n            cuda (bool, optional): use GPU for generation\n            timer (StopwatchMeter, optional): time generations\n        \"\"\"", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "s", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "s", ":", "\n", "                ", "continue", "\n", "", "input", "=", "s", "[", "\"net_input\"", "]", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "encoder_input", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "s", "[", "\"id\"", "]", ".", "data", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "input", "[", "\"src_tokens\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "s", "[", "\"target\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "s", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.generate": [[168, 183], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._generate"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generate translations. Match the api of other fairseq generators.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            constraints (torch.LongTensor, optional): force decoder to include\n                the list of constraints\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._generate": [[184, 554], ["torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "sequence_generator.SequenceGenerator.search.init_constraints", "sequence_generator.SequenceGenerator.model.forward_encoder", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "new_order.to().long.to().long.to().long", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.arange().type_as().to", "torch.arange().type_as().to", "torch.arange().type_as().to", "torch.arange().type_as().to", "range", "range", "src_tokens.size", "NotImplementedError", "src_lengths.max().item", "min", "isinstance", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "sequence_generator.SequenceGenerator.model.forward_decoder", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "[].view.type_as", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "sequence_generator.SequenceGenerator.search.step", "cand_beams.add", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.add", "torch.add", "torch.add", "torch.add", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "active_bbsz_idx.view.view.view", "active_scores.view.view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "sequence_generator.SequenceGenerator.search.update_constraints", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "Exception", "int", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "new_order.to().long.to().long.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "sequence_generator.SequenceGenerator.model.reorder_incremental_state", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "sequence_generator.SequenceGenerator.lm_model", "sequence_generator.SequenceGenerator.lm_model.get_normalized_probs", "sequence_generator.SequenceGenerator._prefix_tokens", "attn[].copy_", "sequence_generator.SequenceGenerator.search.set_src_lengths", "sequence_generator.SequenceGenerator.repeat_ngram_blocker", "sequence_generator.SequenceGenerator.view", "cand_indices.eq", "cand_scores.ne", "torch.masked_select.numel", "torch.masked_select.numel", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "sequence_generator.SequenceGenerator.finalize_hypos", "len", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange().masked_select", "torch.arange().masked_select", "torch.arange().masked_select", "torch.arange().masked_select", "sequence_generator.SequenceGenerator.search.prune_sentences", "bbsz_offsets.resize_", "cand_beams.add", "[].view", "[].view", "new_cands_to_ignore.ge", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "range", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "src_lengths.max", "sequence_generator.SequenceGenerator.model.max_decoder_positions", "range", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "reorder_state.view().add_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "prefix_tokens.size", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "[].view", "eos_mask.type_as", "float", "net_input[].size", "net_input[].sum", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "[].view.size", "eos_mask.size", "elem[].item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "reorder_state.view", "corr.unsqueeze", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "[].view.view", "src_tokens.ne", "src_tokens.ne", "src_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "avg_attn_scores.size", "[].view.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().masked_select.numel", "torch.arange().masked_select.numel"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.init_constraints", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.forward_decoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.update_constraints", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._prefix_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.Search.set_src_lengths", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.finalize_hypos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.search.LexicallyConstrainedBeamSearch.prune_sentences", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_generate", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "constraints", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "model", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "\n", "if", "\"src_tokens\"", "in", "net_input", ":", "\n", "            ", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "# length of the source text being the character length except EndOfSentence and pad", "\n", "src_lengths", "=", "(", "\n", "(", "src_tokens", ".", "ne", "(", "self", ".", "eos", ")", "&", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", ")", "\n", "", "elif", "\"source\"", "in", "net_input", ":", "\n", "            ", "src_tokens", "=", "net_input", "[", "\"source\"", "]", "\n", "src_lengths", "=", "(", "\n", "net_input", "[", "\"padding_mask\"", "]", ".", "size", "(", "-", "1", ")", "-", "net_input", "[", "\"padding_mask\"", "]", ".", "sum", "(", "-", "1", ")", "\n", "if", "net_input", "[", "\"padding_mask\"", "]", "is", "not", "None", "\n", "else", "torch", ".", "tensor", "(", "src_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "to", "(", "src_tokens", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"expected src_tokens or source in net input\"", ")", "\n", "\n", "# bsz: total number of sentences in beam", "\n", "# Note that src_tokens may have more than 2 dimenions (i.e. audio features)", "\n", "", "bsz", ",", "src_len", "=", "src_tokens", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "if", "constraints", "is", "not", "None", "and", "not", "self", ".", "search", ".", "supports_constraints", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Target-side constraints were provided, but search method doesn't support them\"", "\n", ")", "\n", "\n", "# Initialize constraints, when active", "\n", "", "self", ".", "search", ".", "init_constraints", "(", "constraints", ",", "beam_size", ")", "\n", "\n", "max_len", ":", "int", "=", "-", "1", "\n", "if", "self", ".", "match_source_len", ":", "\n", "            ", "max_len", "=", "src_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_a", "*", "src_len", "+", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "", "assert", "(", "\n", "self", ".", "min_len", "<=", "max_len", "\n", ")", ",", "\"min_len cannot be larger than max_len, please adjust these!\"", "\n", "# compute the encoder output for each beam", "\n", "encoder_outs", "=", "self", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "\n", "# placeholder of indices for bsz * beam_size to hold tokens and accumulative scores", "\n", "new_order", "=", "torch", ".", "arange", "(", "bsz", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "new_order", "=", "new_order", ".", "to", "(", "src_tokens", ".", "device", ")", ".", "long", "(", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "new_order", ")", "\n", "# ensure encoder_outs is a List.", "\n", "assert", "encoder_outs", "is", "not", "None", "\n", "\n", "# initialize buffers", "\n", "scores", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "1", ")", ".", "to", "(", "src_tokens", ")", ".", "float", "(", ")", "\n", ")", "# +1 for eos; pad is never chosen for scoring", "\n", "tokens", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "2", ")", "\n", ".", "to", "(", "src_tokens", ")", "\n", ".", "long", "(", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "# +2 for eos and pad", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "# A list that indicates candidates that should be ignored.", "\n", "# For example, suppose we're sampling and have already finalized 2/5", "\n", "# samples. Then cands_to_ignore would mark 2 positions as being ignored,", "\n", "# so that we only finalize the remaining 3 samples.", "\n", "cands_to_ignore", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", ",", "beam_size", ")", ".", "to", "(", "src_tokens", ")", ".", "eq", "(", "-", "1", ")", "\n", ")", "# forward and backward-compatible False mask", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "[", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", ",", "\n", ")", "# contains lists of dictionaries of infomation about the hypothesis being finalized at each step", "\n", "\n", "finished", "=", "[", "\n", "False", "for", "i", "in", "range", "(", "bsz", ")", "\n", "]", "# a boolean array indicating if the sentence at the index is finished or not", "\n", "num_remaining_sent", "=", "bsz", "# number of sentences remaining", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "\n", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "type_as", "(", "tokens", ")", "\n", ".", "to", "(", "src_tokens", ".", "device", ")", "\n", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", ".", "to", "(", "src_tokens", ".", "device", ")", "\n", "\n", "reorder_state", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "\"id\"", "in", "sample", "and", "isinstance", "(", "sample", "[", "\"id\"", "]", ",", "Tensor", ")", ":", "\n", "            ", "original_batch_idxs", "=", "sample", "[", "\"id\"", "]", "\n", "", "else", ":", "\n", "            ", "original_batch_idxs", "=", "torch", ".", "arange", "(", "0", ",", "bsz", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "", "for", "step", "in", "range", "(", "max_len", "+", "1", ")", ":", "# one extra step for EOS marker", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "            ", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "\n", "batch_idxs", "\n", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "\n", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", "\n", ")", "\n", "original_batch_idxs", "=", "original_batch_idxs", "[", "batch_idxs", "]", "\n", "", "self", ".", "model", ".", "reorder_incremental_state", "(", "incremental_states", ",", "reorder_state", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "\n", "encoder_outs", ",", "reorder_state", "\n", ")", "\n", "\n", "", "lprobs", ",", "avg_attn_scores", "=", "self", ".", "model", ".", "forward_decoder", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", "encoder_outs", ",", "\n", "incremental_states", ",", "\n", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "if", "self", ".", "lm_model", "is", "not", "None", ":", "\n", "                ", "lm_out", "=", "self", ".", "lm_model", "(", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ")", "\n", "probs", "=", "self", ".", "lm_model", ".", "get_normalized_probs", "(", "\n", "lm_out", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "*", "self", ".", "lm_weight", "\n", "lprobs", "+=", "probs", "\n", "\n", "", "lprobs", "[", "lprobs", "!=", "lprobs", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "lprobs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# handle max length constraint", "\n", "if", "step", ">=", "max_len", ":", "\n", "                ", "lprobs", "[", ":", ",", ":", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", ":", ",", "self", ".", "eos", "+", "1", ":", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# handle prefix tokens (possibly with different lengths)", "\n", "", "if", "(", "\n", "prefix_tokens", "is", "not", "None", "\n", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", "\n", "and", "step", "<", "max_len", "\n", ")", ":", "\n", "                ", "lprobs", ",", "tokens", ",", "scores", "=", "self", ".", "_prefix_tokens", "(", "\n", "step", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", "\n", ")", "\n", "", "elif", "step", "<", "self", ".", "min_len", ":", "\n", "# minimum length constraint (does not apply if using prefix_tokens)", "\n", "                ", "lprobs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# Record attention scores, only support avg_attn_scores is a Tensor", "\n", "", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "torch", ".", "empty", "(", "\n", "bsz", "*", "beam_size", ",", "avg_attn_scores", ".", "size", "(", "1", ")", ",", "max_len", "+", "2", "\n", ")", ".", "to", "(", "scores", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "\n", "", "scores", "=", "scores", ".", "type_as", "(", "lprobs", ")", "\n", "eos_bbsz_idx", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "tokens", "\n", ")", "# indices of hypothesis ending with eos (finished sentences)", "\n", "eos_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "scores", "\n", ")", "# scores of hypothesis ending with eos (finished sentences)", "\n", "\n", "if", "self", ".", "should_set_src_lengths", ":", "\n", "                ", "self", ".", "search", ".", "set_src_lengths", "(", "src_lengths", ")", "\n", "\n", "", "if", "self", ".", "repeat_ngram_blocker", "is", "not", "None", ":", "\n", "                ", "lprobs", "=", "self", ".", "repeat_ngram_blocker", "(", "\n", "tokens", ",", "lprobs", ",", "bsz", ",", "beam_size", ",", "step", "\n", ")", "\n", "\n", "# Shape: (batch, cand_size)", "\n", "", "cand_scores", ",", "cand_indices", ",", "cand_beams", "=", "self", ".", "search", ".", "step", "(", "\n", "step", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", "step", "]", ",", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", "original_batch_idxs", ",", "\n", ")", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "# Shape of eos_mask: (batch size, beam size)", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "&", "cand_scores", ".", "ne", "(", "-", "math", ".", "inf", ")", "\n", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "[", "cands_to_ignore", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "eos_mask", ")", "\n", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "# Now we know what beam item(s) to finish", "\n", "# Shape: 1d list of absolute-numbered", "\n", "eos_bbsz_idx", "=", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "eos_scores", "=", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", "=", "self", ".", "finalize_hypos", "(", "\n", "step", ",", "\n", "eos_bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ",", "\n", "finished", ",", "\n", "beam_size", ",", "\n", "attn", ",", "\n", "src_lengths", ",", "\n", "max_len", ",", "\n", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "\n", "", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "if", "self", ".", "search", ".", "stop_on_max_len", "and", "step", ">=", "max_len", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "max_len", ",", "f\"{step} < {max_len}\"", "\n", "\n", "# Remove finalized sentences (ones for which {beam_size}", "\n", "# finished hypotheses have been generated) from the batch.", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "\n", "bsz", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "cand_indices", ".", "device", "\n", ")", "\n", "batch_mask", "[", "finalized_sents", "]", "=", "False", "\n", "# TODO replace `nonzero(as_tuple=False)` after TorchScript supports it", "\n", "batch_idxs", "=", "torch", ".", "arange", "(", "\n", "bsz", ",", "device", "=", "cand_indices", ".", "device", "\n", ")", ".", "masked_select", "(", "batch_mask", ")", "\n", "\n", "# Choose the subset of the hypothesized constraints that will continue", "\n", "self", ".", "search", ".", "prune_sentences", "(", "batch_idxs", ")", "\n", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "", "src_lengths", "=", "src_lengths", "[", "batch_idxs", "]", "\n", "cands_to_ignore", "=", "cands_to_ignore", "[", "batch_idxs", "]", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "\n", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "\n", "", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "\n", "# Set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "\n", "# Rewrite the operator since the element wise or is not supported in torchscript.", "\n", "\n", "", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "=", "~", "(", "(", "~", "cands_to_ignore", ")", "&", "(", "~", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ")", ")", "\n", "active_mask", "=", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", ")", "\n", "\n", "# get the top beam_size active hypotheses, which are just", "\n", "# the hypos with the smallest values in active_mask.", "\n", "# {active_hypos} indicates which {beam_size} hypotheses", "\n", "# from the list of {2 * beam_size} candidates were", "\n", "# selected. Shapes: (batch size, beam size)", "\n", "new_cands_to_ignore", ",", "active_hypos", "=", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", "\n", ")", "\n", "\n", "# update cands_to_ignore to ignore any finalized hypos.", "\n", "cands_to_ignore", "=", "new_cands_to_ignore", ".", "ge", "(", "cand_size", ")", "[", ":", ",", ":", "beam_size", "]", "\n", "# Make sure there is at least one active item for each sentence in the batch.", "\n", "assert", "(", "~", "cands_to_ignore", ")", ".", "any", "(", "dim", "=", "1", ")", ".", "all", "(", ")", "\n", "\n", "# update cands_to_ignore to ignore any finalized hypos", "\n", "\n", "# {active_bbsz_idx} denotes which beam number is continued for each new hypothesis (a beam", "\n", "# can be selected more than once).", "\n", "active_bbsz_idx", "=", "torch", ".", "gather", "(", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "\n", "# Set the tokens for each beam (can select the same row more than once)", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", "=", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "# Select the next token for each of them", "\n", "tokens", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", "=", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "scores", "[", ":", ",", ":", "step", "]", "=", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "\n", "# Update constraints based on which candidates were selected for the next beam", "\n", "self", ".", "search", ".", "update_constraints", "(", "active_hypos", ")", "\n", "\n", "# copy attention for active hypotheses", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", "=", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "\n", "# reorder incremental state in decoder", "\n", "", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "scores", "=", "torch", ".", "tensor", "(", "\n", "[", "float", "(", "elem", "[", "\"score\"", "]", ".", "item", "(", ")", ")", "for", "elem", "in", "finalized", "[", "sent", "]", "]", "\n", ")", "\n", "_", ",", "sorted_scores_indices", "=", "torch", ".", "sort", "(", "scores", ",", "descending", "=", "True", ")", "\n", "finalized", "[", "sent", "]", "=", "[", "finalized", "[", "sent", "]", "[", "ssi", "]", "for", "ssi", "in", "sorted_scores_indices", "]", "\n", "finalized", "[", "sent", "]", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "finalized", "[", "sent", "]", "\n", ")", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._prefix_tokens": [[555, 583], ["prefix_tokens[].unsqueeze().repeat().view", "sequence_generator.SequenceGenerator.gather", "prefix_tokens[].unsqueeze().repeat().view.ne", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lprobs[].scatter", "prefix_tokens[].unsqueeze().repeat().view.eq", "prefix_tokens[].unsqueeze().repeat().view.eq.any", "prefix_tokens[].unsqueeze().repeat().view.unsqueeze", "prefix_toks[].unsqueeze", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "prefix_tokens[].unsqueeze().repeat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tokens[].view", "prefix_tokens[].unsqueeze().repeat().view.eq.view", "sequence_generator.SequenceGenerator.size", "prefix_tokens[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_prefix_tokens", "(", "\n", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"Handle prefix tokens\"\"\"", "\n", "prefix_toks", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "prefix_lprobs", "=", "lprobs", ".", "gather", "(", "-", "1", ",", "prefix_toks", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "prefix_mask", "=", "prefix_toks", ".", "ne", "(", "self", ".", "pad", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "lprobs", "[", "prefix_mask", "]", ".", "scatter", "(", "\n", "-", "1", ",", "prefix_toks", "[", "prefix_mask", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "prefix_lprobs", "[", "prefix_mask", "]", "\n", ")", "\n", "# if prefix includes eos, then we should make sure tokens and", "\n", "# scores are the same across all beams", "\n", "eos_mask", "=", "prefix_toks", ".", "eq", "(", "self", ".", "eos", ")", "\n", "if", "eos_mask", ".", "any", "(", ")", ":", "\n", "# validate that the first beam matches the prefix", "\n", "            ", "first_beam", "=", "tokens", "[", "eos_mask", "]", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tokens", ".", "size", "(", "-", "1", ")", ")", "[", "\n", ":", ",", "0", ",", "1", ":", "step", "+", "1", "\n", "]", "\n", "eos_mask_batch_dim", "=", "eos_mask", ".", "view", "(", "-", "1", ",", "beam_size", ")", "[", ":", ",", "0", "]", "\n", "target_prefix", "=", "prefix_tokens", "[", "eos_mask_batch_dim", "]", "[", ":", ",", ":", "step", "]", "\n", "assert", "(", "first_beam", "==", "target_prefix", ")", ".", "all", "(", ")", "\n", "\n", "# copy tokens, scores and lprobs from the first beam to all beams", "\n", "tokens", "=", "self", ".", "replicate_first_beam", "(", "tokens", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "scores", "=", "self", ".", "replicate_first_beam", "(", "scores", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "lprobs", "=", "self", ".", "replicate_first_beam", "(", "lprobs", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "", "return", "lprobs", ",", "tokens", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam": [[584, 588], ["tensor.view.view.view", "tensor.view.view.view", "tensor.view.view.size", "tensor.view.view.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "replicate_first_beam", "(", "self", ",", "tensor", ",", "mask", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "tensor", "=", "tensor", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "tensor", "[", "mask", "]", "=", "tensor", "[", "mask", "]", "[", ":", ",", ":", "1", ",", ":", "]", "\n", "return", "tensor", ".", "view", "(", "-", "1", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.finalize_hypos": [[589, 706], ["range", "sents_seen.keys", "bbsz_idx.numel", "eos_scores.numel", "tokens.index_select", "scores.index_select", "int", "int", "attn.index_select", "cum_unfin.append", "bbsz_idx.size", "str", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "len", "finalized[].append", "float", "float", "sequence_generator.SequenceGenerator.is_finished", "newly_finished.append", "str", "unfin_idx.item", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len", "sent.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "seen.split", "seen.split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.is_finished", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "finalize_hypos", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ":", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "finished", ":", "List", "[", "bool", "]", ",", "\n", "beam_size", ":", "int", ",", "\n", "attn", ":", "Optional", "[", "Tensor", "]", ",", "\n", "src_lengths", ",", "\n", "max_len", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Finalize hypothesis, store finalized information in `finalized`, and change `finished` accordingly.\n        A sentence is finalized when {beam_size} finished items have been collected for it.\n\n        Returns number of sentences (not beam items) being finalized.\n        These will be removed from the batch and not processed further.\n        Args:\n            bbsz_idx (Tensor):\n        \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors.", "\n", "# tokens is (batch * beam, max_len). So the index_select", "\n", "# gets the newly EOS rows, then selects cols 1..{step + 2}", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", "\n", ":", ",", "1", ":", "step", "+", "2", "\n", "]", "# skip the first index, which is EOS", "\n", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "(", "\n", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "if", "attn", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "            ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "# cum_unfin records which sentences in the batch are finished.", "\n", "# It helps match indexing between (a) the original sentences", "\n", "# in the batch and (b) the current, possibly-reduced set of", "\n", "# sentences.", "\n", "", "cum_unfin", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "            ", "if", "f", ":", "\n", "                ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "# The keys here are of the form \"{sent}_{unfin_idx}\", where", "\n", "# \"unfin_idx\" is the index in the current (possibly reduced)", "\n", "# list of sentences, and \"sent\" is the index in the original,", "\n", "# unreduced batch", "\n", "# set() is not supported in script export", "\n", "", "", "sents_seen", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "\n", "# For every finished beam item", "\n", "for", "i", "in", "range", "(", "bbsz_idx", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "idx", "=", "bbsz_idx", "[", "i", "]", "\n", "score", "=", "eos_scores", "[", "i", "]", "\n", "# sentence index in the current (possibly reduced) batch", "\n", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "# sentence index in the original (unreduced) batch", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "# Cannot create dict for key type '(int, int)' in torchscript.", "\n", "# The workaround is to cast int to string", "\n", "seen", "=", "str", "(", "sent", ".", "item", "(", ")", ")", "+", "\"_\"", "+", "str", "(", "unfin_idx", ".", "item", "(", ")", ")", "\n", "if", "seen", "not", "in", "sents_seen", ":", "\n", "                ", "sents_seen", "[", "seen", "]", "=", "None", "\n", "\n", "", "if", "self", ".", "match_source_len", "and", "step", ">", "src_lengths", "[", "unfin_idx", "]", ":", "\n", "                ", "score", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "score", ")", "\n", "\n", "# An input sentence (among those in a batch) is finished when", "\n", "# beam_size hypotheses have been collected for it", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                ", "if", "attn_clone", "is", "not", "None", ":", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "hypo_attn", "=", "attn_clone", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "hypo_attn", "=", "torch", ".", "empty", "(", "0", ")", "\n", "\n", "", "finalized", "[", "sent", "]", ".", "append", "(", "\n", "{", "\n", "\"tokens\"", ":", "tokens_clone", "[", "i", "]", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"attention\"", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "\"alignment\"", ":", "torch", ".", "empty", "(", "0", ")", ",", "\n", "\"positional_scores\"", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "", "", "newly_finished", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\n", "for", "seen", "in", "sents_seen", ".", "keys", "(", ")", ":", "\n", "# check termination conditions for this sentence", "\n", "            ", "sent", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", ")", "\n", "unfin_idx", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", ")", "\n", "\n", "if", "not", "finished", "[", "sent", "]", "and", "self", ".", "is_finished", "(", "\n", "step", ",", "unfin_idx", ",", "max_len", ",", "len", "(", "finalized", "[", "sent", "]", ")", ",", "beam_size", "\n", ")", ":", "\n", "                ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "\n", "", "", "return", "newly_finished", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.is_finished": [[707, 724], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "unfin_idx", ":", "int", ",", "\n", "max_len", ":", "int", ",", "\n", "finalized_sent_len", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Check whether decoding for a sentence is finished, which\n        occurs when the list of finalized sentences has reached the\n        beam size, or when we reach the maximum length.\n        \"\"\"", "\n", "assert", "finalized_sent_len", "<=", "beam_size", "\n", "if", "finalized_sent_len", "==", "beam_size", "or", "step", "==", "max_len", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.__init__": [[729, 742], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "all", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models_size", "=", "len", "(", "models", ")", "\n", "# method '__len__' is not supported in ModuleList for torch script", "\n", "self", ".", "single_model", "=", "models", "[", "0", "]", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n", "self", ".", "has_incremental", ":", "bool", "=", "False", "\n", "if", "all", "(", "\n", "hasattr", "(", "m", ",", "\"decoder\"", ")", "and", "isinstance", "(", "m", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", "\n", "for", "m", "in", "models", "\n", ")", ":", "\n", "            ", "self", ".", "has_incremental", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.forward": [[743, 745], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_encoder": [[746, 748], ["hasattr"], "methods", ["None"], ["", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "single_model", ",", "\"encoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_incremental_states": [[749, 751], ["None"], "methods", ["None"], ["", "def", "has_incremental_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "has_incremental", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.max_decoder_positions": [[752, 754], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "[", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.forward_encoder": [[755, 760], ["sequence_generator.EnsembleModel.has_encoder", "model.encoder.forward_torchscript"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.forward_torchscript"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_encoder", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "model", ".", "encoder", ".", "forward_torchscript", "(", "net_input", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.forward_decoder": [[761, 825], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "sequence_generator.EnsembleModel.has_incremental_states", "len", "model.get_normalized_probs", "log_probs.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "avg_attn.div_", "model.decoder.forward", "model.decoder.forward", "isinstance", "[].div_", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_decoder", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "encoder_outs", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "Tensor", "]", "]", "]", ",", "\n", "incremental_states", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "log_probs", "=", "[", "]", "\n", "avg_attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "encoder_out", ":", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Tensor", "]", "]", "]", "=", "None", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "if", "self", ".", "has_encoder", "(", ")", ":", "\n", "                ", "encoder_out", "=", "encoder_outs", "[", "i", "]", "\n", "# decode each model", "\n", "", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "\n", "tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "incremental_states", "[", "i", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "tokens", ",", "encoder_out", "=", "encoder_out", ")", "\n", "\n", "", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "decoder_len", "=", "len", "(", "decoder_out", ")", "\n", "if", "decoder_len", ">", "1", "and", "decoder_out", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "decoder_out", "[", "1", "]", ",", "Tensor", ")", ":", "\n", "                    ", "attn", "=", "decoder_out", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "attn_holder", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "isinstance", "(", "attn_holder", ",", "Tensor", ")", ":", "\n", "                        ", "attn", "=", "attn_holder", "\n", "", "elif", "attn_holder", "is", "not", "None", ":", "\n", "                        ", "attn", "=", "attn_holder", "[", "0", "]", "\n", "", "", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "", "", "decoder_out_tuple", "=", "(", "\n", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", ",", ":", "]", ".", "div_", "(", "temperature", ")", ",", "\n", "None", "if", "decoder_len", "<=", "1", "else", "decoder_out", "[", "1", "]", ",", "\n", ")", "\n", "\n", "probs", "=", "model", ".", "get_normalized_probs", "(", "\n", "decoder_out_tuple", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "if", "self", ".", "models_size", "==", "1", ":", "\n", "                ", "return", "probs", ",", "attn", "\n", "\n", "", "log_probs", ".", "append", "(", "probs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "\n", "", "", "", "avg_probs", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "log_probs", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "-", "math", ".", "log", "(", "\n", "self", ".", "models_size", "\n", ")", "\n", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "self", ".", "models_size", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.reorder_encoder_out": [[826, 849], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "new_outs.append", "model.encoder.reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "\n", "self", ",", "encoder_outs", ":", "Optional", "[", "List", "[", "Dict", "[", "str", ",", "List", "[", "Tensor", "]", "]", "]", "]", ",", "new_order", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "new_outs", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "Tensor", "]", "]", "]", "=", "[", "]", "\n", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "new_outs", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "assert", "encoder_outs", "is", "not", "None", "\n", "new_outs", ".", "append", "(", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "new_order", ")", "\n", ")", "\n", "", "return", "new_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.reorder_incremental_state": [[850, 861], ["enumerate", "sequence_generator.EnsembleModel.has_incremental_states", "model.decoder.reorder_incremental_state_scripting"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state_scripting"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_states", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "new_order", ",", "\n", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "return", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "reorder_incremental_state_scripting", "(", "\n", "incremental_states", "[", "i", "]", ",", "new_order", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.__init__": [[865, 885], ["sequence_generator.SequenceGenerator.__init__", "sequence_generator.EnsembleModelWithAlignment"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "models", ",", "tgt_dict", ",", "left_pad_target", "=", "False", ",", "print_alignment", "=", "\"hard\"", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Produces alignments following \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            left_pad_target (bool, optional): Whether or not the\n                hypothesis should be left padded or not when they are\n                teacher forced for generating alignments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "EnsembleModelWithAlignment", "(", "models", ")", ",", "tgt_dict", ",", "**", "kwargs", ")", "\n", "self", ".", "left_pad_target", "=", "left_pad_target", "\n", "\n", "if", "print_alignment", "==", "\"hard\"", ":", "\n", "            ", "self", ".", "extract_alignment", "=", "utils", ".", "extract_hard_alignment", "\n", "", "elif", "print_alignment", "==", "\"soft\"", ":", "\n", "            ", "self", ".", "extract_alignment", "=", "utils", ".", "extract_soft_alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate": [[886, 919], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate", "sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "any", "range", "sequence_generator.SequenceGeneratorWithAlignment.model.forward_align", "src_tokens.to.to.to", "tgt_tokens.to.to.to", "sequence_generator.SequenceGeneratorWithAlignment.extract_alignment", "getattr", "[].transpose", "i.to", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator._generate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModelWithAlignment.forward_align"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "finalized", "=", "super", "(", ")", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "tgt_tokens", ",", "\n", ")", "=", "self", ".", "_prepare_batch_for_alignment", "(", "sample", ",", "finalized", ")", "\n", "if", "any", "(", "getattr", "(", "m", ",", "\"full_context_alignment\"", ",", "False", ")", "for", "m", "in", "self", ".", "model", ".", "models", ")", ":", "\n", "            ", "attn", "=", "self", ".", "model", ".", "forward_align", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "[", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"attention\"", "]", ".", "transpose", "(", "1", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "\n", "", "if", "src_tokens", ".", "device", "!=", "\"cpu\"", ":", "\n", "            ", "src_tokens", "=", "src_tokens", ".", "to", "(", "\"cpu\"", ")", "\n", "tgt_tokens", "=", "tgt_tokens", ".", "to", "(", "\"cpu\"", ")", "\n", "attn", "=", "[", "i", ".", "to", "(", "\"cpu\"", ")", "for", "i", "in", "attn", "]", "\n", "\n", "# Process the attn matrix to extract hard alignments.", "\n", "", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "alignment", "=", "self", ".", "extract_alignment", "(", "\n", "attn", "[", "i", "]", ",", "src_tokens", "[", "i", "]", ",", "tgt_tokens", "[", "i", "]", ",", "self", ".", "pad", ",", "self", ".", "eos", "\n", ")", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"alignment\"", "]", "=", "alignment", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment": [[920, 951], ["src_tokens[].expand().contiguous().view", "src_lengths[].expand().contiguous().view", "fairseq.data.data_utils.collate_tokens", "fairseq.data.data_utils.collate_tokens", "src_tokens[].expand().contiguous", "src_lengths[].expand().contiguous", "src_tokens[].expand", "src_lengths[].expand"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens"], ["", "def", "_prepare_batch_for_alignment", "(", "self", ",", "sample", ",", "hypothesis", ")", ":", "\n", "        ", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "src_tokens", "=", "(", "\n", "src_tokens", "[", ":", ",", "None", ",", ":", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ")", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "src_lengths", "=", "(", "\n", "src_lengths", "[", ":", ",", "None", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ")", "\n", ")", "\n", "prev_output_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "tgt_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "return", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModelWithAlignment.__init__": [[956, 958], ["sequence_generator.EnsembleModel.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.EnsembleModelWithAlignment.forward_align": [[959, 971], ["model", "len", "avg_attn.div_", "avg_attn.add_", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model"], ["", "def", "forward_align", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "avg_attn", "=", "None", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "decoder_out", "=", "model", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "[", "0", "]", "\n", "if", "avg_attn", "is", "None", ":", "\n", "                ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "if", "len", "(", "self", ".", "models", ")", ">", "1", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.FileContentsAction.__init__": [[48, 52], ["argparse.Action.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.FileContentsAction.__call__": [[53, 60], ["fairseq.file_io.PathManager.isfile", "setattr", "fairseq.file_io.PathManager.open", "f.read().strip", "f.read"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_torch_seed.__init__": [[564, 573], ["isinstance", "utils.get_rng_state", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "xm.set_rng_state", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state"], ["    ", "def", "__init__", "(", "self", ",", "seed", ")", ":", "\n", "        ", "assert", "isinstance", "(", "seed", ",", "int", ")", "\n", "self", ".", "rng_state", "=", "get_rng_state", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "xm", "is", "not", "None", ":", "\n", "            ", "xm", ".", "set_rng_state", "(", "seed", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_torch_seed.__enter__": [[574, 576], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_torch_seed.__exit__": [[577, 579], ["utils.set_rng_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "set_rng_state", "(", "self", ".", "rng_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.CudaEnvironment.__init__": [[680, 687], ["torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "cur_device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "prop", "=", "torch", ".", "cuda", ".", "get_device_properties", "(", "\"cuda:{}\"", ".", "format", "(", "cur_device", ")", ")", "\n", "self", ".", "name", "=", "prop", ".", "name", "\n", "self", ".", "major", "=", "prop", ".", "major", "\n", "self", ".", "minor", "=", "prop", ".", "minor", "\n", "self", ".", "total_memory_in_GB", "=", "prop", ".", "total_memory", "/", "1024", "/", "1024", "/", "1024", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list": [[688, 706], ["len", "logger.info", "enumerate", "logger.info", "logger.info", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pretty_print_cuda_env_list", "(", "cuda_env_list", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of CudaEnviorments, pretty print them\n        \"\"\"", "\n", "num_workers", "=", "len", "(", "cuda_env_list", ")", "\n", "center", "=", "\"CUDA enviroments for all {} workers\"", ".", "format", "(", "num_workers", ")", "\n", "banner_len", "=", "40", "-", "len", "(", "center", ")", "//", "2", "\n", "first_line", "=", "\"*\"", "*", "banner_len", "+", "center", "+", "\"*\"", "*", "banner_len", "\n", "logger", ".", "info", "(", "first_line", ")", "\n", "for", "r", ",", "env", "in", "enumerate", "(", "cuda_env_list", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"rank {:3d}: \"", ".", "format", "(", "r", ")", "\n", "+", "\"capabilities = {:2d}.{:<2d} ; \"", ".", "format", "(", "env", ".", "major", ",", "env", ".", "minor", ")", "\n", "+", "\"total memory = {:.3f} GB ; \"", ".", "format", "(", "env", ".", "total_memory_in_GB", ")", "\n", "+", "\"name = {:40s}\"", ".", "format", "(", "env", ".", "name", ")", "\n", ")", "\n", "", "logger", ".", "info", "(", "first_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.split_paths": [[62, 67], ["paths.split", "paths.split"], "function", ["None"], ["", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.load_ensemble_for_inference": [[70, 79], ["utils.deprecation_warning", "checkpoint_utils.load_model_ensemble"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_model_ensemble"], ["", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample": [[82, 101], ["utils.apply_to_sample._apply"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply"], ["", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cuda": [[103, 112], ["utils.apply_to_sample", "torch.cuda.current_device", "torch.cuda.current_device", "tensor.to"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample"], ["", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.move_to_cpu": [[114, 123], ["utils.apply_to_sample", "tensor.to.cpu", "tensor.to.to"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.apply_to_sample"], ["", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state": [[125, 132], ["module.get_incremental_state"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state": [[134, 146], ["module.set_incremental_state"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.load_align_dict": [[148, 163], ["isinstance", "len", "open", "line.split"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "with", "open", "(", "replace_unk", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.print_embed_overlap": [[165, 170], ["set", "set", "len", "logger.info", "embed_dict.keys", "len"], "function", ["None"], ["", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.parse_embedding": [[172, 192], ["open", "next", "line.rstrip().split", "torch.Tensor", "torch.Tensor", "line.rstrip", "float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n", "", "", "return", "embed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.load_embedding": [[194, 200], ["range", "len"], "function", ["None"], ["", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.replace_unk": [[202, 215], ["tokenizer.tokenize_line", "enumerate", "tokenizer.tokenize_line", "align_dict.get"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.tokenizer.tokenize_line", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.tokenizer.tokenize_line"], ["", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.post_process_prediction": [[217, 238], ["tgt_dict.string", "utils.replace_unk", "tgt_dict.encode_line", "tgt_dict.unk_string"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.replace_unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk_string"], ["", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.make_positions": [[240, 251], ["tensor.ne().int", "tensor.ne", "torch.cumsum().type_as", "torch.cumsum().type_as", "torch.cumsum", "torch.cumsum"], "function", ["None"], ["", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "return", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "long", "(", ")", "+", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.strip_pad": [[253, 255], ["tensor.ne"], "function", ["None"], ["", "def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.buffered_arange": [[257, 264], ["hasattr", "torch.LongTensor", "torch.LongTensor", "buffered_arange.buf.numel", "buffered_arange.buf.resize_", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "buffered_arange", "(", "max", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "buffered_arange", ",", "\"buf\"", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", "=", "torch", ".", "LongTensor", "(", ")", "\n", "", "if", "max", ">", "buffered_arange", ".", "buf", ".", "numel", "(", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", ".", "resize_", "(", "max", ")", "\n", "torch", ".", "arange", "(", "max", ",", "out", "=", "buffered_arange", ".", "buf", ")", "\n", "", "return", "buffered_arange", ".", "buf", "[", ":", "max", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.convert_padding_direction": [[266, 291], ["src_tokens.eq", "src_tokens.size", "torch.empty().long", "torch.empty().long", "torch.empty().long.type_as().expand_as", "src_tokens.eq.long().sum", "src_tokens.gather", "src_tokens.eq.any", "torch.arange", "torch.arange", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "pad_mask[].any", "pad_mask[].any", "torch.empty", "torch.empty", "torch.empty().long.type_as", "src_tokens.eq.long"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "convert_padding_direction", "(", "\n", "src_tokens", ",", "padding_idx", ",", "right_to_left", ":", "bool", "=", "False", ",", "left_to_right", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n", "", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item": [[293, 299], ["hasattr", "hasattr", "tensor.item"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.multi_tensor_total_norm": [[301, 325], ["per_device_grads.keys", "torch.norm", "torch.norm", "per_device_grads.get", "per_device_grads.get.append", "torch.stack", "torch.stack", "torch.zeros", "torch.zeros", "norms.append", "torch.cuda.device", "torch.cuda.device", "multi_tensor_l2norm", "norm[].to", "torch.norm", "torch.norm", "torch.cuda.current_device", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device"], ["", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n", "            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "device", ")", ":", "\n", "                ", "norm", "=", "multi_tensor_l2norm", "(", "\n", "chunk_size", ",", "has_inf", ",", "[", "cur_device_grads", "]", ",", "False", "\n", ")", "\n", "", "norms", ".", "append", "(", "norm", "[", "0", "]", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n", "", "", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "norms", ")", ")", "\n", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.clip_grad_norm_": [[327, 370], ["torch.no_grad", "torch.no_grad", "isinstance", "list", "p.grad.detach", "len", "len", "torch.norm", "torch.norm", "aggregate_norm_fn", "float", "filter", "len", "params[].new_tensor", "torch.tensor", "torch.tensor", "utils.multi_tensor_total_norm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.norm", "torch.norm", "g.mul_", "warnings.warn", "torch.cuda.current_device", "torch.cuda.current_device", "torch.stack", "torch.stack", "torch.device", "torch.device", "torch.norm().to", "torch.norm().to", "torch.norm", "torch.norm"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.multi_tensor_total_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n", "", "", "if", "len", "(", "grads", ")", "==", "1", ":", "\n", "        ", "total_norm", "=", "torch", ".", "norm", "(", "grads", "[", "0", "]", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "if", "multi_tensor_l2norm_available", ":", "\n", "            ", "total_norm", "=", "multi_tensor_total_norm", "(", "grads", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"", "\n", "\"you may get better performance by installing NVIDIA's apex library\"", "\n", ")", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "", "elif", "grads", "[", "0", "]", ".", "device", ".", "type", "==", "\"xla\"", ":", "\n", "                ", "device", "=", "grads", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "total_norm", "=", "torch", ".", "norm", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "for", "g", "in", "grads", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "aggregate_norm_fn", "is", "not", "None", ":", "\n", "        ", "total_norm", "=", "aggregate_norm_fn", "(", "total_norm", ")", "\n", "\n", "", "if", "max_norm", ">", "0", ":", "\n", "        ", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "clip_coef", "=", "(", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "for", "g", "in", "grads", ":", "\n", "            ", "g", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.fill_with_neg_inf": [[372, 375], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils._match_types": [[377, 397], ["isinstance", "isinstance", "isinstance", "tuple", "isinstance", "utils._match_types.upgrade"], "function", ["None"], ["", "def", "_match_types", "(", "arg1", ",", "arg2", ")", ":", "\n", "    ", "\"\"\"Convert the numerical argument to the same type as the other argument\"\"\"", "\n", "\n", "def", "upgrade", "(", "arg_number", ",", "arg_structure", ")", ":", "\n", "        ", "if", "isinstance", "(", "arg_structure", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "[", "arg_number", "]", "*", "len", "(", "arg_structure", ")", ")", "\n", "", "elif", "isinstance", "(", "arg_structure", ",", "dict", ")", ":", "\n", "            ", "arg", "=", "copy", ".", "deepcopy", "(", "arg_structure", ")", "\n", "for", "k", "in", "arg", ":", "\n", "                ", "arg", "[", "k", "]", "=", "upgrade", "(", "arg_number", ",", "arg_structure", "[", "k", "]", ")", "\n", "", "return", "arg", "\n", "", "else", ":", "\n", "            ", "return", "arg_number", "\n", "\n", "", "", "if", "isinstance", "(", "arg1", ",", "float", ")", "or", "isinstance", "(", "arg1", ",", "int", ")", ":", "\n", "        ", "return", "upgrade", "(", "arg1", ",", "arg2", ")", ",", "arg2", "\n", "", "elif", "isinstance", "(", "arg2", ",", "float", ")", "or", "isinstance", "(", "arg2", ",", "int", ")", ":", "\n", "        ", "return", "arg1", ",", "upgrade", "(", "arg2", ",", "arg1", ")", "\n", "\n", "", "return", "arg1", ",", "arg2", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.resolve_max_positions": [[399, 434], ["copy.deepcopy", "min", "utils._match_types", "isinstance", "isinstance", "min", "isinstance", "utils.resolve_max_positions.map_value_update"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils._match_types"], ["", "def", "resolve_max_positions", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Resolve max position constraints from multiple sources.\"\"\"", "\n", "\n", "def", "map_value_update", "(", "d1", ",", "d2", ")", ":", "\n", "        ", "updated_value", "=", "copy", ".", "deepcopy", "(", "d1", ")", "\n", "for", "key", "in", "d2", ":", "\n", "            ", "if", "key", "not", "in", "updated_value", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "d2", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "min", "(", "d1", "[", "key", "]", ",", "d2", "[", "key", "]", ")", "\n", "", "", "return", "updated_value", "\n", "\n", "", "def", "nullsafe_min", "(", "l", ")", ":", "\n", "        ", "minim", "=", "None", "\n", "for", "item", "in", "l", ":", "\n", "            ", "if", "minim", "is", "None", ":", "\n", "                ", "minim", "=", "item", "\n", "", "elif", "item", "is", "not", "None", "and", "item", "<", "minim", ":", "\n", "                ", "minim", "=", "item", "\n", "", "", "return", "minim", "\n", "\n", "", "max_positions", "=", "None", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "max_positions", "is", "None", ":", "\n", "            ", "max_positions", "=", "arg", "\n", "", "elif", "arg", "is", "not", "None", ":", "\n", "            ", "max_positions", ",", "arg", "=", "_match_types", "(", "max_positions", ",", "arg", ")", "\n", "if", "isinstance", "(", "arg", ",", "float", ")", "or", "isinstance", "(", "arg", ",", "int", ")", ":", "\n", "                ", "max_positions", "=", "min", "(", "max_positions", ",", "arg", ")", "\n", "", "elif", "isinstance", "(", "arg", ",", "dict", ")", ":", "\n", "                ", "max_positions", "=", "map_value_update", "(", "max_positions", ",", "arg", ")", "\n", "", "else", ":", "\n", "                ", "max_positions", "=", "tuple", "(", "map", "(", "nullsafe_min", ",", "zip", "(", "max_positions", ",", "arg", ")", ")", ")", "\n", "\n", "", "", "", "return", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.import_user_module": [[436, 467], ["getattr", "os.path.abspath", "getattr", "os.path.join", "os.path.exists", "set", "import_user_module.memo.add", "os.path.split", "os.path.exists", "os.path.isfile", "os.path.dirname", "os.path.join", "os.path.exists", "sys.path.insert", "importlib.import_module", "ImportError", "os.path.dirname", "os.path.dirname", "FileNotFoundError"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "import_user_module", "(", "args", ")", ":", "\n", "    ", "module_path", "=", "getattr", "(", "args", ",", "\"user_dir\"", ",", "None", ")", "\n", "if", "module_path", "is", "not", "None", ":", "\n", "        ", "module_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "user_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "module_path", ")", "and", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "dirname", "(", "module_path", ")", ")", ":", "\n", "            ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "args", ".", "user_dir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"..\"", ",", "args", ".", "user_dir", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                    ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "module_path", ")", "\n", "\n", "# ensure that user modules are only imported once", "\n", "", "", "", "import_user_module", ".", "memo", "=", "getattr", "(", "import_user_module", ",", "\"memo\"", ",", "set", "(", ")", ")", "\n", "if", "module_path", "not", "in", "import_user_module", ".", "memo", ":", "\n", "            ", "import_user_module", ".", "memo", ".", "add", "(", "module_path", ")", "\n", "\n", "module_parent", ",", "module_name", "=", "os", ".", "path", ".", "split", "(", "module_path", ")", "\n", "if", "module_name", "not", "in", "sys", ".", "modules", ":", "\n", "                ", "sys", ".", "path", ".", "insert", "(", "0", ",", "module_parent", ")", "\n", "importlib", ".", "import_module", "(", "module_name", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ImportError", "(", "\n", "\"Failed to import --user-dir={} because the corresponding module name \"", "\n", "\"({}) is not globally unique. Please rename the directory to \"", "\n", "\"something unique and try again.\"", ".", "format", "(", "module_path", ",", "module_name", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax": [[470, 475], ["torch.softmax", "torch.softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "", "", "", "def", "softmax", "(", "x", ",", "dim", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "onnx_trace", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "dim", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax": [[477, 482], ["torch.log_softmax", "torch.log_softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax"], ["", "", "def", "log_softmax", "(", "x", ",", "dim", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "onnx_trace", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "dim", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_perplexity": [[484, 491], ["fairseq.logging.meters.safe_round", "float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "", "def", "get_perplexity", "(", "loss", ",", "round", "=", "2", ",", "base", "=", "2", ")", ":", "\n", "    ", "if", "loss", "is", "None", ":", "\n", "        ", "return", "0.0", "\n", "", "try", ":", "\n", "        ", "return", "safe_round", "(", "base", "**", "loss", ",", "round", ")", "\n", "", "except", "OverflowError", ":", "\n", "        ", "return", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning": [[493, 496], ["warnings.warn"], "function", ["None"], ["", "", "def", "deprecation_warning", "(", "message", ",", "stacklevel", "=", "3", ")", ":", "\n", "# don't use DeprecationWarning, since it's ignored by default", "\n", "    ", "warnings", ".", "warn", "(", "message", ",", "stacklevel", "=", "stacklevel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn": [[498, 517], ["utils.deprecation_warning", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning"], ["", "def", "get_activation_fn", "(", "activation", ":", "str", ")", "->", "Callable", ":", "\n", "    ", "\"\"\" Returns the activation function corresponding to `activation` \"\"\"", "\n", "if", "activation", "==", "\"relu\"", ":", "\n", "        ", "return", "F", ".", "relu", "\n", "", "elif", "activation", "==", "\"gelu\"", ":", "\n", "        ", "return", "gelu", "\n", "", "elif", "activation", "==", "\"gelu_fast\"", ":", "\n", "        ", "deprecation_warning", "(", "\n", "\"--activation-fn=gelu_fast has been renamed to gelu_accurate\"", "\n", ")", "\n", "return", "gelu_accurate", "\n", "", "elif", "activation", "==", "\"gelu_accurate\"", ":", "\n", "        ", "return", "gelu_accurate", "\n", "", "elif", "activation", "==", "\"tanh\"", ":", "\n", "        ", "return", "torch", ".", "tanh", "\n", "", "elif", "activation", "==", "\"linear\"", ":", "\n", "        ", "return", "lambda", "x", ":", "x", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"--activation-fn {} not supported\"", ".", "format", "(", "activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_available_activation_fns": [[519, 527], ["None"], "function", ["None"], ["", "", "def", "get_available_activation_fns", "(", ")", "->", "List", ":", "\n", "    ", "return", "[", "\n", "\"relu\"", ",", "\n", "\"gelu\"", ",", "\n", "\"gelu_fast\"", ",", "# deprecated", "\n", "\"gelu_accurate\"", ",", "\n", "\"tanh\"", ",", "\n", "\"linear\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.model_eval": [[530, 536], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "model_eval", "(", "model", ")", ":", "\n", "    ", "is_training", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.has_parameters": [[538, 544], ["next", "module.parameters"], "function", ["None"], ["", "def", "has_parameters", "(", "module", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "next", "(", "module", ".", "parameters", "(", ")", ")", "\n", "return", "True", "\n", "", "except", "StopIteration", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state": [[546, 553], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.get_rng_state", "torch.get_rng_state", "xm.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state"], ["", "", "def", "get_rng_state", "(", ")", ":", "\n", "    ", "state", "=", "{", "\"torch_rng_state\"", ":", "torch", ".", "get_rng_state", "(", ")", "}", "\n", "if", "xm", "is", "not", "None", ":", "\n", "        ", "state", "[", "\"xla_rng_state\"", "]", "=", "xm", ".", "get_rng_state", "(", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "state", "[", "\"cuda_rng_state\"", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state": [[555, 561], ["torch.set_rng_state", "torch.set_rng_state", "torch.cuda.is_available", "torch.cuda.is_available", "xm.set_rng_state", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state"], ["", "def", "set_rng_state", "(", "state", ")", ":", "\n", "    ", "torch", ".", "set_rng_state", "(", "state", "[", "\"torch_rng_state\"", "]", ")", "\n", "if", "xm", "is", "not", "None", ":", "\n", "        ", "xm", ".", "set_rng_state", "(", "state", "[", "\"xla_rng_state\"", "]", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_rng_state", "(", "state", "[", "\"cuda_rng_state\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.parse_alignment": [[581, 600], ["line.strip().split", "torch.IntTensor", "torch.IntTensor", "enumerate", "alignment.split", "int", "int", "line.strip", "len"], "function", ["None"], ["", "", "def", "parse_alignment", "(", "line", ")", ":", "\n", "    ", "\"\"\"\n    Parses a single line from the alingment file.\n\n    Args:\n        line (str): String containing the alignment of the format:\n            <src_idx_1>-<tgt_idx_1> <src_idx_2>-<tgt_idx_2> ..\n            <src_idx_m>-<tgt_idx_m>. All indices are 0 indexed.\n\n    Returns:\n        torch.IntTensor: packed alignments of shape (2 * m).\n    \"\"\"", "\n", "alignments", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "parsed_alignment", "=", "torch", ".", "IntTensor", "(", "2", "*", "len", "(", "alignments", ")", ")", "\n", "for", "idx", ",", "alignment", "in", "enumerate", "(", "alignments", ")", ":", "\n", "        ", "src_idx", ",", "tgt_idx", "=", "alignment", ".", "split", "(", "\"-\"", ")", "\n", "parsed_alignment", "[", "2", "*", "idx", "]", "=", "int", "(", "src_idx", ")", "\n", "parsed_alignment", "[", "2", "*", "idx", "+", "1", "]", "=", "int", "(", "tgt_idx", ")", "\n", "", "return", "parsed_alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_token_to_word_mapping": [[602, 608], ["len", "list", "int", "itertools.accumulate", "range"], "function", ["None"], ["", "def", "get_token_to_word_mapping", "(", "tokens", ",", "exclude_list", ")", ":", "\n", "    ", "n", "=", "len", "(", "tokens", ")", "\n", "word_start", "=", "[", "int", "(", "token", "not", "in", "exclude_list", ")", "for", "token", "in", "tokens", "]", "\n", "word_idx", "=", "list", "(", "accumulate", "(", "word_start", ")", ")", "\n", "token_to_word", "=", "{", "i", ":", "word_idx", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "}", "\n", "return", "token_to_word", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.extract_hard_alignment": [[610, 632], ["utils.get_token_to_word_mapping", "utils.get_token_to_word_mapping", "float", "attn_valid.max", "zip", "len", "len", "len", "alignment.append", "src_idx.item", "tgt_idx.item"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_token_to_word_mapping", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_token_to_word_mapping", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "extract_hard_alignment", "(", "attn", ",", "src_sent", ",", "tgt_sent", ",", "pad", ",", "eos", ")", ":", "\n", "    ", "tgt_valid", "=", "(", "\n", "(", "(", "tgt_sent", "!=", "pad", ")", "&", "(", "tgt_sent", "!=", "eos", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", ")", "\n", "src_invalid", "=", "(", "\n", "(", "(", "src_sent", "==", "pad", ")", "|", "(", "src_sent", "==", "eos", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", ")", "\n", "src_token_to_word", "=", "get_token_to_word_mapping", "(", "src_sent", ",", "[", "eos", ",", "pad", "]", ")", "\n", "tgt_token_to_word", "=", "get_token_to_word_mapping", "(", "tgt_sent", ",", "[", "eos", ",", "pad", "]", ")", "\n", "alignment", "=", "[", "]", "\n", "if", "len", "(", "tgt_valid", ")", "!=", "0", "and", "len", "(", "src_invalid", ")", "<", "len", "(", "src_sent", ")", ":", "\n", "        ", "attn_valid", "=", "attn", "[", "tgt_valid", "]", "\n", "attn_valid", "[", ":", ",", "src_invalid", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "_", ",", "src_indices", "=", "attn_valid", ".", "max", "(", "dim", "=", "1", ")", "\n", "for", "tgt_idx", ",", "src_idx", "in", "zip", "(", "tgt_valid", ",", "src_indices", ")", ":", "\n", "            ", "alignment", ".", "append", "(", "\n", "(", "\n", "src_token_to_word", "[", "src_idx", ".", "item", "(", ")", "]", "-", "1", ",", "\n", "tgt_token_to_word", "[", "tgt_idx", ".", "item", "(", ")", "]", "-", "1", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.extract_soft_alignment": [[634, 649], ["len", "len", "src_probs.tolist"], "function", ["None"], ["", "def", "extract_soft_alignment", "(", "attn", ",", "src_sent", ",", "tgt_sent", ",", "pad", ",", "eos", ")", ":", "\n", "    ", "tgt_valid", "=", "(", "\n", "(", "(", "tgt_sent", "!=", "pad", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", ")", "\n", "src_valid", "=", "(", "\n", "(", "(", "src_sent", "!=", "pad", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", ")", "\n", "alignment", "=", "[", "]", "\n", "if", "len", "(", "tgt_valid", ")", "!=", "0", "and", "len", "(", "src_valid", ")", "!=", "0", ":", "\n", "        ", "attn_valid", "=", "attn", "[", "tgt_valid", ",", "src_valid", "]", "\n", "alignment", "=", "[", "\n", "[", "\"{:.6f}\"", ".", "format", "(", "p", ")", "for", "p", "in", "src_probs", ".", "tolist", "(", ")", "]", "\n", "for", "src_probs", "in", "attn_valid", "\n", "]", "\n", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.new_arange": [[651, 659], ["torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "len", "x.size", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "new_arange", "(", "x", ",", "*", "size", ")", ":", "\n", "    ", "\"\"\"\n    Return a Tensor of `size` filled with a range function on the device of x.\n    If size is empty, using the size of the variable x.\n    \"\"\"", "\n", "if", "len", "(", "size", ")", "==", "0", ":", "\n", "        ", "size", "=", "x", ".", "size", "(", ")", "\n", "", "return", "torch", ".", "arange", "(", "size", "[", "-", "1", "]", ",", "device", "=", "x", ".", "device", ")", ".", "expand", "(", "*", "size", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_tpu_device": [[661, 663], ["xm.xla_device"], "function", ["None"], ["", "def", "get_tpu_device", "(", ")", ":", "\n", "    ", "return", "xm", ".", "xla_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.tpu_data_loader": [[665, 676], ["xm.rendezvous", "xm.mark_step", "xm.xla_device", "fairseq.data.iterators.CountingIterator", "pl.ParallelLoader().per_device_loader", "getattr", "len", "pl.ParallelLoader"], "function", ["None"], ["", "def", "tpu_data_loader", "(", "itr", ")", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "import", "torch_xla", ".", "distributed", ".", "parallel_loader", "as", "pl", "\n", "\n", "xm", ".", "rendezvous", "(", "\"tpu_data_loader\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "device", "=", "xm", ".", "xla_device", "(", ")", "\n", "return", "iterators", ".", "CountingIterator", "(", "\n", "pl", ".", "ParallelLoader", "(", "itr", ",", "[", "device", "]", ")", ".", "per_device_loader", "(", "device", ")", ",", "\n", "start", "=", "getattr", "(", "itr", ",", "\"n\"", ",", "0", ")", ",", "\n", "total", "=", "len", "(", "itr", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.csv_str_list": [[708, 710], ["x.split"], "function", ["None"], ["", "", "def", "csv_str_list", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "split", "(", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.eval_str_list": [[712, 721], ["isinstance", "eval", "list", "map", "type"], "function", ["None"], ["", "def", "eval_str_list", "(", "x", ",", "type", "=", "float", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "try", ":", "\n", "        ", "return", "list", "(", "map", "(", "type", ",", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "[", "type", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.eval_str_dict": [[723, 729], ["isinstance", "eval"], "function", ["None"], ["", "", "def", "eval_str_dict", "(", "x", ",", "type", "=", "dict", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.eval_bool": [[731, 738], ["bool", "eval"], "function", ["None"], ["", "def", "eval_bool", "(", "x", ",", "default", "=", "False", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "try", ":", "\n", "        ", "return", "bool", "(", "eval", "(", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "default", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.StrEnumMeta.__instancecheck__": [[13, 16], ["str", "type"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "__instancecheck__", "(", "cls", ",", "other", ")", ":", "\n", "        ", "return", "\"enum\"", "in", "str", "(", "type", "(", "other", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.StrEnum.__str__": [[19, 21], ["None"], "methods", ["None"], ["    ", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.StrEnum.__eq__": [[22, 24], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ":", "str", ")", ":", "\n", "        ", "return", "self", ".", "value", "==", "other", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.StrEnum.__repr__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.StrEnum.__hash__": [[28, 30], ["hash", "str"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.constants.ChoiceEnum": [[32, 35], ["constants.StrEnum"], "function", ["None"], ["", "", "def", "ChoiceEnum", "(", "choices", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "\"\"\"return the Enum class used to enforce list of choices\"\"\"", "\n", "return", "StrEnum", "(", "\"Choices\"", ",", "{", "k", ":", "k", "for", "k", "in", "choices", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.initialize.hydra_init": [[16, 28], ["hydra.core.config_store.ConfigStore.instance", "ConfigStore.instance.store", "ConfigStore.instance.store", "logger.error"], "function", ["None"], ["def", "hydra_init", "(", "cfg_name", "=", "\"config\"", ")", "->", "None", ":", "\n", "\n", "    ", "cs", "=", "ConfigStore", ".", "instance", "(", ")", "\n", "cs", ".", "store", "(", "name", "=", "cfg_name", ",", "node", "=", "FairseqConfig", ")", "\n", "\n", "for", "k", "in", "FairseqConfig", ".", "__dataclass_fields__", ":", "\n", "        ", "v", "=", "FairseqConfig", ".", "__dataclass_fields__", "[", "k", "]", ".", "default", "\n", "try", ":", "\n", "            ", "cs", ".", "store", "(", "name", "=", "k", ",", "node", "=", "v", ")", "\n", "", "except", "BaseException", ":", "\n", "            ", "logger", ".", "error", "(", "f\"{k} - {v}\"", ")", "\n", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.initialize.add_defaults": [[30, 62], ["omegaconf.OmegaConf.set_struct", "fairseq.dataclass.configs.FairseqConfig.__dataclass_fields__.items", "cfg.get", "isinstance", "omegaconf.DictConfig.get", "omegaconf.DictConfig", "TASK_DATACLASS_REGISTRY.get", "merge_with_parent", "ARCH_MODEL_NAME_REGISTRY.get", "MODEL_DATACLASS_REGISTRY.get", "[].get"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.merge_with_parent"], ["", "", "", "def", "add_defaults", "(", "cfg", ":", "DictConfig", ")", "->", "None", ":", "\n", "    ", "\"\"\"This function adds default values that are stored in dataclasses that hydra doesn't know about \"\"\"", "\n", "\n", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "from", "fairseq", ".", "tasks", "import", "TASK_DATACLASS_REGISTRY", "\n", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_NAME_REGISTRY", ",", "MODEL_DATACLASS_REGISTRY", "\n", "from", "fairseq", ".", "dataclass", ".", "utils", "import", "merge_with_parent", "\n", "from", "typing", "import", "Any", "\n", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "False", ")", "\n", "\n", "for", "k", ",", "v", "in", "FairseqConfig", ".", "__dataclass_fields__", ".", "items", "(", ")", ":", "\n", "        ", "field_cfg", "=", "cfg", ".", "get", "(", "k", ")", "\n", "if", "field_cfg", "is", "not", "None", "and", "v", ".", "type", "==", "Any", ":", "\n", "            ", "dc", "=", "None", "\n", "\n", "if", "isinstance", "(", "field_cfg", ",", "str", ")", ":", "\n", "                ", "field_cfg", "=", "DictConfig", "(", "{", "\"_name\"", ":", "field_cfg", "}", ")", "\n", "field_cfg", ".", "__dict__", "[", "\"_parent\"", "]", "=", "field_cfg", ".", "__dict__", "[", "\"_parent\"", "]", "\n", "\n", "", "name", "=", "field_cfg", ".", "get", "(", "\"_name\"", ")", "\n", "\n", "if", "k", "==", "\"task\"", ":", "\n", "                ", "dc", "=", "TASK_DATACLASS_REGISTRY", ".", "get", "(", "name", ")", "\n", "", "elif", "k", "==", "\"model\"", ":", "\n", "                ", "name", "=", "ARCH_MODEL_NAME_REGISTRY", ".", "get", "(", "name", ",", "name", ")", "\n", "dc", "=", "MODEL_DATACLASS_REGISTRY", ".", "get", "(", "name", ")", "\n", "", "elif", "k", "in", "REGISTRIES", ":", "\n", "                ", "dc", "=", "REGISTRIES", "[", "k", "]", "[", "\"dataclass_registry\"", "]", ".", "get", "(", "name", ")", "\n", "\n", "", "if", "dc", "is", "not", "None", ":", "\n", "                ", "cfg", "[", "k", "]", "=", "merge_with_parent", "(", "dc", ",", "field_cfg", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list": [[25, 36], ["isinstance", "ast.literal_eval", "list", "len", "map", "x_type"], "function", ["None"], ["from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.interpret_dc_type": [[38, 49], ["isinstance", "str", "RuntimeError", "re.match", "str.startswith"], "function", ["None"], ["    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass": [[51, 171], ["dataclass_instance._get_all_attributes", "dataclass_instance._get_type", "utils.interpret_dc_type", "dataclass_instance._get_default", "dataclass_instance._get_help", "dataclass_instance._get_argparse_const", "utils.gen_parser_from_dataclass.argparse_name"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_all_attributes", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_type", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.interpret_dc_type", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_default", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_help", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_argparse_const"], ["", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n", "\n", "\n", "", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n", "\n", "", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n", "\n", "", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n", "\n", "", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "with", "open", "(", "replace_unk", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n", "\n", "", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults": [[173, 194], ["argparse.ArgumentParser", "cls.add_args", "argparse.Namespace", "vars().items", "hasattr", "vars", "hasattr", "setattr", "hasattr", "setattr"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args"], ["    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n", "", "", "return", "embed_dict", "\n", "\n", "\n", "", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._override_attr": [[196, 265], ["data_class.__dataclass_fields__.items", "k.startswith", "utils.interpret_dc_type", "isinstance", "getattr", "inspect.isclass", "issubclass", "isinstance", "f.default_factory", "utils._override_attr.get_default", "fairseq.dataclass.configs.FairseqConfig.__dataclass_fields__[].type"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.interpret_dc_type"], ["        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n", "\n", "", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n", "\n", "", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n", "\n", "", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "return", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "long", "(", ")", "+", "padding_idx", "\n", "\n", "\n", "", "def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n", "\n", "", "def", "buffered_arange", "(", "max", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "buffered_arange", ",", "\"buf\"", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", "=", "torch", ".", "LongTensor", "(", ")", "\n", "", "if", "max", ">", "buffered_arange", ".", "buf", ".", "numel", "(", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", ".", "resize_", "(", "max", ")", "\n", "torch", ".", "arange", "(", "max", ",", "out", "=", "buffered_arange", ".", "buf", ")", "\n", "", "return", "buffered_arange", ".", "buf", "[", ":", "max", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.migrate_registry": [[267, 278], ["overrides.append", "overrides.append", "overrides.extend", "utils._override_attr", "overrides.append", "deletes.append"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._override_attr"], ["src_tokens", ",", "padding_idx", ",", "right_to_left", ":", "bool", "=", "False", ",", "left_to_right", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n", "", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.override_module_args": [[280, 338], ["fairseq.dataclass.configs.FairseqConfig.__dataclass_fields__.keys", "overrides.extend", "hasattr", "REGISTRIES.items", "hasattr", "utils._override_attr", "utils.migrate_registry", "deletes.append", "hasattr", "deletes.append", "utils.migrate_registry", "deletes.append", "getattr", "getattr", "overrides.append", "overrides.append", "overrides.extend", "utils._override_attr"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._override_attr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.migrate_registry", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.migrate_registry", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._override_attr"], ["", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n", "\n", "", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n", "\n", "", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n", "            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "device", ")", ":", "\n", "                ", "norm", "=", "multi_tensor_l2norm", "(", "\n", "chunk_size", ",", "has_inf", ",", "[", "cur_device_grads", "]", ",", "False", "\n", ")", "\n", "", "norms", ".", "append", "(", "norm", "[", "0", "]", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n", "", "", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "norms", ")", ")", "\n", "return", "total_norm", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf": [[340, 406], ["utils.override_module_args", "os.path.join", "hydra.core.global_hydra.GlobalHydra.instance().clear", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "hydra.experimental.initialize", "omegaconf.OmegaConf.to_container", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "hydra.core.global_hydra.GlobalHydra.instance", "hydra.experimental.compose", "logger.error", "vars", "vars", "vars", "vars", "vars", "str"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.override_module_args", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils._set_legacy_defaults"], ["        ", "total_norm", "=", "torch", ".", "norm", "(", "grads", "[", "0", "]", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "if", "multi_tensor_l2norm_available", ":", "\n", "            ", "total_norm", "=", "multi_tensor_total_norm", "(", "grads", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"", "\n", "\"you may get better performance by installing NVIDIA's apex library\"", "\n", ")", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "", "elif", "grads", "[", "0", "]", ".", "device", ".", "type", "==", "\"xla\"", ":", "\n", "                ", "device", "=", "grads", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "total_norm", "=", "torch", ".", "norm", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "for", "g", "in", "grads", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "aggregate_norm_fn", "is", "not", "None", ":", "\n", "        ", "total_norm", "=", "aggregate_norm_fn", "(", "total_norm", ")", "\n", "\n", "", "if", "max_norm", ">", "0", ":", "\n", "        ", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "clip_coef", "=", "(", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "for", "g", "in", "grads", ":", "\n", "            ", "g", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "return", "total_norm", "\n", "\n", "\n", "", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n", "\n", "", "def", "_match_types", "(", "arg1", ",", "arg2", ")", ":", "\n", "    ", "\"\"\"Convert the numerical argument to the same type as the other argument\"\"\"", "\n", "\n", "def", "upgrade", "(", "arg_number", ",", "arg_structure", ")", ":", "\n", "        ", "if", "isinstance", "(", "arg_structure", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "[", "arg_number", "]", "*", "len", "(", "arg_structure", ")", ")", "\n", "", "elif", "isinstance", "(", "arg_structure", ",", "dict", ")", ":", "\n", "            ", "arg", "=", "copy", ".", "deepcopy", "(", "arg_structure", ")", "\n", "for", "k", "in", "arg", ":", "\n", "                ", "arg", "[", "k", "]", "=", "upgrade", "(", "arg_number", ",", "arg_structure", "[", "k", "]", ")", "\n", "", "return", "arg", "\n", "", "else", ":", "\n", "            ", "return", "arg_number", "\n", "\n", "", "", "if", "isinstance", "(", "arg1", ",", "float", ")", "or", "isinstance", "(", "arg1", ",", "int", ")", ":", "\n", "        ", "return", "upgrade", "(", "arg1", ",", "arg2", ")", ",", "arg2", "\n", "", "elif", "isinstance", "(", "arg2", ",", "float", ")", "or", "isinstance", "(", "arg2", ",", "int", ")", ":", "\n", "        ", "return", "arg1", ",", "upgrade", "(", "arg2", ",", "arg1", ")", "\n", "\n", "", "return", "arg1", ",", "arg2", "\n", "\n", "\n", "", "def", "resolve_max_positions", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Resolve max position constraints from multiple sources.\"\"\"", "\n", "\n", "def", "map_value_update", "(", "d1", ",", "d2", ")", ":", "\n", "        ", "updated_value", "=", "copy", ".", "deepcopy", "(", "d1", ")", "\n", "for", "key", "in", "d2", ":", "\n", "            ", "if", "key", "not", "in", "updated_value", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "d2", "[", "key", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.populate_dataclass": [[408, 420], ["dataclass.__dataclass_fields__.keys", "k.startswith", "hasattr", "setattr", "getattr"], "function", ["None"], ["                ", "updated_value", "[", "key", "]", "=", "min", "(", "d1", "[", "key", "]", ",", "d2", "[", "key", "]", ")", "\n", "", "", "return", "updated_value", "\n", "\n", "", "def", "nullsafe_min", "(", "l", ")", ":", "\n", "        ", "minim", "=", "None", "\n", "for", "item", "in", "l", ":", "\n", "            ", "if", "minim", "is", "None", ":", "\n", "                ", "minim", "=", "item", "\n", "", "elif", "item", "is", "not", "None", "and", "item", "<", "minim", ":", "\n", "                ", "minim", "=", "item", "\n", "", "", "return", "minim", "\n", "\n", "", "max_positions", "=", "None", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.overwrite_args_by_name": [[422, 454], ["omegaconf.open_dict", "cfg.keys", "isinstance", "isinstance", "overrides[].items", "utils.overwrite_args_by_name", "isinstance", "overrides.items", "isinstance", "setattr", "utils.overwrite_args_by_name", "omegaconf.DictConfig", "utils.overwrite_args_by_name"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.overwrite_args_by_name", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.overwrite_args_by_name", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.overwrite_args_by_name"], ["        ", "if", "max_positions", "is", "None", ":", "\n", "            ", "max_positions", "=", "arg", "\n", "", "elif", "arg", "is", "not", "None", ":", "\n", "            ", "max_positions", ",", "arg", "=", "_match_types", "(", "max_positions", ",", "arg", ")", "\n", "if", "isinstance", "(", "arg", ",", "float", ")", "or", "isinstance", "(", "arg", ",", "int", ")", ":", "\n", "                ", "max_positions", "=", "min", "(", "max_positions", ",", "arg", ")", "\n", "", "elif", "isinstance", "(", "arg", ",", "dict", ")", ":", "\n", "                ", "max_positions", "=", "map_value_update", "(", "max_positions", ",", "arg", ")", "\n", "", "else", ":", "\n", "                ", "max_positions", "=", "tuple", "(", "map", "(", "nullsafe_min", ",", "zip", "(", "max_positions", ",", "arg", ")", ")", ")", "\n", "\n", "", "", "", "return", "max_positions", "\n", "\n", "\n", "", "def", "import_user_module", "(", "args", ")", ":", "\n", "    ", "module_path", "=", "getattr", "(", "args", ",", "\"user_dir\"", ",", "None", ")", "\n", "if", "module_path", "is", "not", "None", ":", "\n", "        ", "module_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "user_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "module_path", ")", "and", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "dirname", "(", "module_path", ")", ")", ":", "\n", "            ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "args", ".", "user_dir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"..\"", ",", "args", ".", "user_dir", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                    ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "module_path", ")", "\n", "\n", "# ensure that user modules are only imported once", "\n", "", "", "", "import_user_module", ".", "memo", "=", "getattr", "(", "import_user_module", ",", "\"memo\"", ",", "set", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.merge_with_parent": [[456, 461], ["omegaconf.OmegaConf.merge", "omegaconf.OmegaConf.set_struct"], "function", ["None"], ["            ", "import_user_module", ".", "memo", ".", "add", "(", "module_path", ")", "\n", "\n", "module_parent", ",", "module_name", "=", "os", ".", "path", ".", "split", "(", "module_path", ")", "\n", "if", "module_name", "not", "in", "sys", ".", "modules", ":", "\n", "                ", "sys", ".", "path", ".", "insert", "(", "0", ",", "module_parent", ")", "\n", "importlib", ".", "import_module", "(", "module_name", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass.name": [[33, 36], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "name", "(", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_all_attributes": [[37, 39], ["configs.FairseqDataclass.__dataclass_fields__.keys"], "methods", ["None"], ["", "def", "_get_all_attributes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "k", "for", "k", "in", "self", ".", "__dataclass_fields__", ".", "keys", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_meta": [[40, 44], ["configs.FairseqDataclass.__dataclass_fields__[].metadata.get"], "methods", ["None"], ["", "def", "_get_meta", "(", "\n", "self", ",", "attribute_name", ":", "str", ",", "meta", ":", "str", ",", "default", ":", "Optional", "[", "Any", "]", "=", "None", "\n", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "metadata", ".", "get", "(", "meta", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_name": [[45, 47], ["None"], "methods", ["None"], ["", "def", "_get_name", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_default": [[48, 66], ["hasattr", "str().startswith", "isinstance", "f.default_factory", "str", "str().startswith", "str", "getattr", "str", "getattr", "str", "getattr", "getattr"], "methods", ["None"], ["", "def", "_get_default", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "attribute_name", ")", ":", "\n", "            ", "if", "str", "(", "getattr", "(", "self", ",", "attribute_name", ")", ")", ".", "startswith", "(", "\"${\"", ")", ":", "\n", "                ", "return", "str", "(", "getattr", "(", "self", ",", "attribute_name", ")", ")", "\n", "", "elif", "str", "(", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", ")", ".", "startswith", "(", "\n", "\"${\"", "\n", ")", ":", "\n", "                ", "return", "str", "(", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", ")", "\n", "", "elif", "(", "\n", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "!=", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", "\n", ")", ":", "\n", "                ", "return", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "\n", "", "", "f", "=", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", "\n", "if", "not", "isinstance", "(", "f", ".", "default_factory", ",", "_MISSING_TYPE", ")", ":", "\n", "            ", "return", "f", ".", "default_factory", "(", ")", "\n", "", "return", "f", ".", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_type": [[67, 69], ["None"], "methods", ["None"], ["", "def", "_get_type", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_help": [[70, 72], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_help", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"help\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_argparse_const": [[73, 75], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_argparse_const", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"argparse_const\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_argparse_alias": [[76, 78], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_argparse_alias", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"argparse_alias\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.configs.FairseqDataclass._get_choices": [[79, 81], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_choices", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"choices\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.__init__": [[12, 15], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.add_args": [[16, 22], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.optimizer": [[32, 40], ["hasattr", "isinstance", "ValueError"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Reset optimizer instance.\"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"_optimizer\"", ")", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "not", "isinstance", "(", "self", ".", "_optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"_optimizer must be an instance of torch.optim.Optimizer\"", ")", "\n", "", "self", ".", "_optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.optimizer_config": [[41, 50], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.params": [[51, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an iterable of the parameters held by the optimizer.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "param_group", "[", "\"params\"", "]", ":", "\n", "                ", "yield", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.param_groups": [[58, 61], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "param_groups", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.__getstate__": [[62, 64], ["fairseq_optimizer.FairseqOptimizer._optimizer.__getstate__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__getstate__"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "__getstate__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.get_lr": [[65, 68], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the current learning rate.\"\"\"", "\n", "return", "self", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.set_lr": [[69, 73], ["None"], "methods", ["None"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "\"\"\"Set the learning rate.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "\"lr\"", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.state_dict": [[74, 77], ["fairseq_optimizer.FairseqOptimizer.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.load_state_dict": [[78, 92], ["fairseq_optimizer.FairseqOptimizer.optimizer.load_state_dict", "len", "group.update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "if", "optimizer_overrides", "is", "not", "None", "and", "len", "(", "optimizer_overrides", ")", ">", "0", ":", "\n", "# override learning rate, momentum, etc. with latest values", "\n", "            ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "                ", "group", ".", "update", "(", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.backward": [[93, 96], ["loss.backward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\"\"\"", "\n", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.all_reduce_grads": [[97, 101], ["hasattr", "module.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Manually all-reduce gradients (if required).\"\"\"", "\n", "if", "hasattr", "(", "module", ",", "\"all_reduce_grads\"", ")", ":", "\n", "            ", "module", ".", "all_reduce_grads", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.multiply_grads": [[102, 107], ["p.grad.data.mul_"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.clip_grad_norm": [[108, 111], ["fairseq.utils.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.clip_grad_norm_"], ["", "", "", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "return", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "max_norm", ",", "aggregate_norm_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.step": [[112, 126], ["fairseq_optimizer.FairseqOptimizer.optimizer.step", "fairseq_optimizer.FairseqOptimizer.optimizer.step", "fairseq_optimizer.FairseqOptimizer.multiply_grads", "fairseq_optimizer.FairseqOptimizer.optimizer.step", "fairseq_optimizer.FairseqOptimizer.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "scale", "=", "1.0", ",", "groups", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "if", "self", ".", "supports_step_with_scale", ":", "\n", "            ", "if", "self", ".", "supports_groups", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", "closure", ",", "scale", "=", "scale", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", "closure", ",", "scale", "=", "scale", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "scale", "!=", "1.0", ":", "\n", "                ", "self", ".", "multiply_grads", "(", "1.0", "/", "scale", ")", "\n", "", "if", "self", ".", "supports_groups", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", "closure", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.zero_grad": [[127, 132], ["fairseq_optimizer.FairseqOptimizer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.supports_memory_efficient_fp16": [[133, 138], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_memory_efficient_fp16\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_memory_efficient_fp16", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.supports_step_with_scale": [[139, 144], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_step_with_scale", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_step_with_scale\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_step_with_scale", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.supports_groups": [[145, 150], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_groups", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_groups\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_groups", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.supports_flat_params": [[151, 160], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Whether the optimizer supports collapsing of the model\n        parameters/gradients into a single contiguous Tensor.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_flat_params\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_flat_params", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.average_params": [[161, 163], ["None"], "methods", ["None"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.broadcast_global_state_dict": [[164, 173], ["hasattr", "fairseq_optimizer.FairseqOptimizer.optimizer.broadcast_global_state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.FairseqOptimizer.broadcast_global_state_dict"], ["", "def", "broadcast_global_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"\n        Broadcasts a global state dict to all ranks.\n        Useful for optimizers that shard state between ranks.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"broadcast_global_state_dict\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "broadcast_global_state_dict", "(", "state_dict", ")", "\n", "", "else", ":", "\n", "            ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fairseq_optimizer.LegacyFairseqOptimizer.__init__": [[176, 178], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.__init__": [[25, 38], ["fairseq.optim.fairseq_optimizer.FairseqOptimizer.__init__", "bmuf.FairseqBMUF._reset_local_data", "bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqBMUFConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "sync_iter", "=", "cfg", ".", "global_sync_iter", "\n", "self", ".", "block_momentum", "=", "cfg", ".", "block_momentum", "\n", "self", ".", "block_lr", "=", "cfg", ".", "block_lr", "\n", "self", ".", "_reset_local_data", "(", ")", "\n", "self", ".", "warmup_iteration", "=", "cfg", ".", "warmup_iterations", "\n", "self", ".", "use_nbm", "=", "cfg", ".", "use_nbm", "\n", "self", ".", "initial_state", "=", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "self", ".", "average_sync", "=", "self", ".", "cfg", ".", "average_sync", "\n", "self", ".", "world_size", "=", "self", ".", "cfg", ".", "distributed_world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.add_args": [[39, 43], ["fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.FairseqBMUFConfig"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "gen_parser_from_dataclass", "(", "parser", ",", "FairseqBMUFConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.optimizer": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.optimizer_config": [[48, 51], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_lr": [[52, 54], ["bmuf.FairseqBMUF._optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.set_lr": [[55, 57], ["bmuf.FairseqBMUF._optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.state_dict": [[58, 60], ["bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.load_state_dict": [[61, 64], ["bmuf.FairseqBMUF._optimizer.load_state_dict", "bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "self", ".", "initial_state", "=", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.multiply_grads": [[65, 68], ["bmuf.FairseqBMUF._optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "self", ".", "_optimizer", ".", "multiply_grads", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.clip_grad_norm": [[69, 72], ["bmuf.FairseqBMUF._optimizer.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "return", "self", ".", "_optimizer", ".", "clip_grad_norm", "(", "max_norm", ",", "aggregate_norm_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.average_params": [[73, 75], ["bmuf.FairseqBMUF._optimizer.average_params"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.average_params"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._block_sync": [[76, 95], ["bmuf.FairseqBMUF._avg_grad_from_all_gpus", "bmuf.FairseqBMUF._calc_grad", "bmuf.FairseqBMUF._update_global_model", "bmuf.FairseqBMUF.average_params"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._calc_grad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._update_global_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.average_params"], ["", "def", "_block_sync", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "world_size", "<=", "1", ":", "\n", "            ", "return", "\n", "# Update the global model using local models from all GPUs", "\n", "# (Step-1) Calculate grad between previously synced model and", "\n", "# currrent local model", "\n", "", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_calc_grad", "(", ")", "\n", "\n", "# (Step-2) Average gradient from all GPUs", "\n", "", "self", ".", "_avg_grad_from_all_gpus", "(", ")", "\n", "\n", "# (Step-3) Calculate global momentum and update the global model", "\n", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_update_global_model", "(", ")", "\n", "\n", "# (Step-4) Average local optimizer params", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._is_warmup_end": [[96, 101], ["bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "", "def", "_is_warmup_end", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to warmup iter", "\n", "        ", "if", "self", ".", "get_num_updates", "(", ")", "==", "self", ".", "warmup_iteration", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._is_bmuf_iter": [[102, 109], ["bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_is_bmuf_iter", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to bmuf sync iter", "\n", "        ", "if", "(", "self", ".", "get_num_updates", "(", ")", ">", "self", ".", "warmup_iteration", ")", "and", "(", "\n", "self", ".", "get_num_updates", "(", ")", "%", "self", ".", "sync_iter", "==", "0", "\n", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._warmup_sync": [[110, 124], ["bmuf.FairseqBMUF._reset_local_data", "torch.broadcast", "torch.broadcast", "bmuf.FairseqBMUF._optimizer.average_params", "bmuf.FairseqBMUF._optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.average_params", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "_warmup_sync", "(", "self", ",", "root_rank", "=", "0", ")", ":", "\n", "        ", "if", "self", ".", "world_size", "<=", "1", ":", "\n", "            ", "return", "\n", "# Broadcast the local model to all gpus", "\n", "", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "dist", ".", "broadcast", "(", "param", ".", "data", ",", "src", "=", "root_rank", ")", "\n", "\n", "# Update local optimizer state", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "self", ".", "initial_state", ")", "\n", "\n", "", "self", ".", "_reset_local_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.step": [[125, 133], ["bmuf.FairseqBMUF._optimizer.step", "bmuf.FairseqBMUF.set_num_updates", "bmuf.FairseqBMUF._is_warmup_end", "bmuf.FairseqBMUF._warmup_sync", "bmuf.FairseqBMUF._is_bmuf_iter", "bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF._block_sync"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._is_warmup_end", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._warmup_sync", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._is_bmuf_iter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._block_sync"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_optimizer", ".", "step", "(", "closure", ")", "\n", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "if", "self", ".", "_is_warmup_end", "(", ")", ":", "\n", "            ", "self", ".", "_warmup_sync", "(", ")", "\n", "", "elif", "self", ".", "_is_bmuf_iter", "(", ")", ":", "\n", "            ", "self", ".", "_block_sync", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.zero_grad": [[134, 137], ["bmuf.FairseqBMUF._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.get_num_updates": [[138, 141], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF.set_num_updates": [[142, 145], ["None"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._reset_local_data": [[146, 156], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "p.data.new_zeros", "p.data.new_zeros", "global_param.copy_", "p.data.size", "p.data.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_reset_local_data", "(", "self", ")", ":", "\n", "# (Step-0) Initialize global momentum parameters and store global copy on each gpu", "\n", "        ", "self", ".", "global_params", "=", "[", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "smoothed_grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "\n", "# saving the global model locally for calculating gradient during bmuf sync", "\n", "for", "param", ",", "global_param", "in", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", ":", "\n", "            ", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._calc_grad": [[157, 167], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_calc_grad", "(", "self", ")", ":", "\n", "# global_params is basically the global copy from the previously finished", "\n", "# synchronisation. param.data is local parameter after block_sync_freq", "\n", "# for the local gpu. so grad is difference between previously synced", "\n", "# model and currrent local model.", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ")", "in", "enumerate", "(", "\n", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", "\n", ")", ":", "\n", "            ", "self", ".", "grads", "[", "index", "]", "=", "global_param", "-", "param", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus": [[168, 173], ["enumerate", "float", "torch.all_reduce", "torch.all_reduce", "torch.get_world_size", "torch.get_world_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size"], ["", "", "def", "_avg_grad_from_all_gpus", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "param", "in", "enumerate", "(", "self", ".", "params", ")", ":", "\n", "            ", "sync_para", "=", "param", ".", "data", "if", "self", ".", "block_momentum", "==", "0", "else", "self", ".", "grads", "[", "index", "]", "\n", "sync_para", "/=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "dist", ".", "all_reduce", "(", "sync_para", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.bmuf.FairseqBMUF._update_global_model": [[174, 201], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip", "param.data.copy_", "global_param.copy_", "param.data.copy_"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_global_model", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ",", "smoothed_grad", ",", "grad", ")", "in", "enumerate", "(", "\n", "zip", "(", "\n", "self", ".", "params", ",", "\n", "self", ".", "global_params", ",", "\n", "self", ".", "smoothed_grads", ",", "\n", "# all gpus would share the same value of smoothed_grad, since it is", "\n", "# always computed on synchronized gradients.", "\n", "self", ".", "grads", ",", "\n", ")", "\n", ")", ":", "\n", "# global_param is basically last syncrhornized parameter. though", "\n", "# smoothed_grad is local, all processes will have same value of", "\n", "# smoothed_grad and hence param is globally synchronized copy.", "\n", "# smoothed_grad(t) = BM * smoothed_grad(t-1) + BM_lr * grad(t)", "\n", "            ", "smoothed_grad", "=", "self", ".", "block_momentum", "*", "smoothed_grad", "+", "self", ".", "block_lr", "*", "grad", "\n", "param", ".", "data", ".", "copy_", "(", "global_param", "-", "smoothed_grad", ")", "\n", "\n", "# A Nesterov momentum here is to do a partial weight update before", "\n", "# calculating the gradient", "\n", "if", "self", ".", "use_nbm", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "param", ".", "data", "-", "self", ".", "block_momentum", "*", "smoothed_grad", ")", "\n", "\n", "# backup for the next synchronization.", "\n", "", "self", ".", "smoothed_grads", "[", "index", "]", "=", "smoothed_grad", "\n", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.shard.shard_": [[19, 97], ["type", "FairseqOSS", "ImportError", "AttributeError", "name.startswith", "hasattr", "getattr", "range", "torch.tensor", "range", "send_state.update", "utils.broadcast_object", "utils.broadcast_object"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_object", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast_object"], ["", "def", "shard_", "(", "optimizer", ",", "group", ")", ":", "\n", "    ", "if", "not", "_has_fairscale", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the fairscale package:\"", "\"\\n\\n  pip install fairscale\"", "\n", ")", "\n", "\n", "", "class", "FairseqOSS", "(", "OSS", ")", ":", "\n", "        ", "@", "property", "\n", "def", "disable_mem_eff_fp16_loading_hack", "(", "self", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"supports\"", ")", "and", "hasattr", "(", "self", ".", "optim", ",", "name", ")", ":", "\n", "                ", "return", "getattr", "(", "self", ".", "optim", ",", "name", ")", "\n", "", "raise", "AttributeError", "(", "\n", "\"'FairseqOSS' object has no attribute {0!r}\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "\n", "", "def", "broadcast_global_state_dict", "(", "\n", "self", ",", "state_dict", ":", "Dict", "[", "str", ",", "Any", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "            ", "\"\"\"\n            Broadcasts the relevant parts of a global state dict from rank 0 to\n            all other ranks.\n            \"\"\"", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "\n", "# Create template state dict for all other keys not related to sharding", "\n", "                ", "template_state_dict", "=", "{", "\n", "key", ":", "state_dict", "[", "key", "]", "\n", "for", "key", "in", "state_dict", "\n", "if", "key", "not", "in", "(", "\"param_groups\"", ",", "\"state\"", ")", "\n", "}", "\n", "template_state_dict", "[", "\"local_state_dict\"", "]", "=", "True", "\n", "\n", "for", "dst_rank", "in", "range", "(", "self", ".", "world_size", ")", ":", "\n", "# Get the dst_rank's param_groups shard", "\n", "                    ", "send_state", "=", "{", "\n", "\"param_groups\"", ":", "state_dict", "[", "\"param_groups\"", "]", "[", "\n", "state_dict", "[", "\"partition\"", "]", "[", "dst_rank", "]", "[", "0", "]", ":", "state_dict", "[", "\n", "\"partition\"", "\n", "]", "[", "dst_rank", "]", "[", "1", "]", "\n", "]", ",", "\n", "\"state\"", ":", "state_dict", "[", "\"state\"", "]", "[", "dst_rank", "]", ",", "\n", "}", "\n", "send_state", ".", "update", "(", "template_state_dict", ")", "\n", "\n", "if", "dst_rank", "==", "0", ":", "\n", "                        ", "recv_state", "=", "send_state", "\n", "", "else", ":", "\n", "                        ", "utils", ".", "broadcast_object", "(", "\n", "send_state", ",", "\n", "src_rank", "=", "0", ",", "\n", "group", "=", "self", ".", "group", ",", "\n", "dist_device", "=", "self", ".", "_device", ",", "\n", ")", "\n", "", "", "", "else", ":", "\n", "                ", "empty_buffer", "=", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "self", ".", "_device", ")", "\n", "for", "dst_rank", "in", "range", "(", "1", ",", "self", ".", "world_size", ")", ":", "\n", "                    ", "state", "=", "utils", ".", "broadcast_object", "(", "\n", "empty_buffer", ",", "\n", "src_rank", "=", "0", ",", "\n", "group", "=", "self", ".", "group", ",", "\n", "dist_device", "=", "self", ".", "_device", ",", "\n", ")", "\n", "if", "dst_rank", "==", "self", ".", "rank", ":", "\n", "                        ", "recv_state", "=", "state", "\n", "\n", "", "", "", "return", "recv_state", "\n", "\n", "", "", "torch_optimizer", "=", "optimizer", ".", "optimizer", "\n", "optim_cls", "=", "type", "(", "torch_optimizer", ")", "\n", "\n", "optimizer", ".", "optimizer", "=", "FairseqOSS", "(", "\n", "torch_optimizer", ".", "param_groups", ",", "\n", "optim_cls", ",", "\n", "group", "=", "group", ",", "\n", "**", "optimizer", ".", "optimizer_config", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.__init__": [[17, 21], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in mro(method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.has_flat_params": [[22, 27], ["torch.is_tensor", "isinstance", "all", "torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_params.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "is_tensor", "(", "self", ".", "fp32_params", ")", "or", "(", "\n", "isinstance", "(", "self", ".", "fp32_params", ",", "dict", ")", "\n", "and", "all", "(", "torch", ".", "is_tensor", "(", "t", ")", "for", "t", "in", "self", ".", "fp32_params", ".", "values", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params": [[29, 72], ["sum", "getattr", "getattr", "torch.cuda.current_device", "list", "device_params[].new().float().new", "torch.nn.Parameter", "fp32_params[].data.new", "torch.nn.Parameter", "torch.zeros_like", "hasattr", "fp32_params.append", "p.data.numel", "set", "sum", "p.data.numel", "[].copy_", "p.data.float", "device_params[].new().float", "p.data.view", "p.data.numel", "device_params[].new"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_fp32_params", "(", "cls", ",", "args", ",", "params", ",", "flatten", "=", "True", ")", ":", "\n", "# create FP32 copy of parameters and grads", "\n", "        ", "if", "flatten", ":", "\n", "            ", "is_pipeline_parallel", "=", "getattr", "(", "\n", "args", ",", "\"pipeline_model_parallel\"", ",", "False", "\n", ")", "and", "getattr", "(", "args", ",", "\"distributed_no_spawn\"", ",", "False", ")", "\n", "total_param_size", "=", "sum", "(", "p", ".", "data", ".", "numel", "(", ")", "for", "p", "in", "params", ")", "\n", "devices", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", "\n", "if", "is_pipeline_parallel", ":", "\n", "                ", "devices", "=", "list", "(", "set", "(", "args", ".", "pipeline_devices", ")", ")", "\n", "", "fp32_params", "=", "{", "}", "\n", "for", "device", "in", "devices", ":", "\n", "                ", "if", "is_pipeline_parallel", ":", "\n", "                    ", "device_param_size", "=", "sum", "(", "\n", "p", ".", "data", ".", "numel", "(", ")", "for", "p", "in", "params", "if", "p", ".", "device", ".", "index", "==", "device", "\n", ")", "\n", "device_params", "=", "[", "p", "for", "p", "in", "params", "if", "p", ".", "device", ".", "index", "==", "device", "]", "\n", "", "else", ":", "\n", "                    ", "device_param_size", "=", "total_param_size", "\n", "device_params", "=", "params", "\n", "", "fp32_params", "[", "device", "]", "=", "(", "\n", "device_params", "[", "0", "]", ".", "new", "(", "0", ")", ".", "float", "(", ")", ".", "new", "(", "device_param_size", ")", "\n", ")", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                    ", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "fp32_params", "[", "device", "]", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "p", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "", "fp32_params", "[", "device", "]", "=", "torch", ".", "nn", ".", "Parameter", "(", "fp32_params", "[", "device", "]", ")", "\n", "fp32_params", "[", "device", "]", ".", "grad", "=", "fp32_params", "[", "device", "]", ".", "data", ".", "new", "(", "\n", "device_param_size", "\n", ")", "\n", "", "return", "fp32_params", "\n", "", "else", ":", "\n", "            ", "fp32_params", "=", "[", "]", "\n", "for", "p", "in", "params", ":", "\n", "                ", "p32", "=", "torch", ".", "nn", ".", "Parameter", "(", "p", ".", "data", ".", "float", "(", ")", ")", "\n", "p32", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p32", ".", "data", ")", "\n", "if", "hasattr", "(", "p", ",", "\"param_group\"", ")", ":", "\n", "                    ", "p32", ".", "param_group", "=", "p", ".", "param_group", "\n", "", "fp32_params", ".", "append", "(", "p32", ")", "\n", "", "return", "fp32_params", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.state_dict": [[73, 79], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "fp32_optimizer", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "state_dict", "[", "\"loss_scale\"", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.load_state_dict": [[80, 91], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "\"loss_scale\"", "in", "state_dict", "and", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "\"loss_scale\"", "]", "\n", "", "self", ".", "fp32_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.backward": [[92, 103], ["fp16_optimizer._FP16OptimizerMixin.backward", "fp16_optimizer._FP16OptimizerMixin.scaler.scale"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.scale"], ["", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "scaler", ".", "scale", "(", "loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_needs_sync", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32": [[104, 140], ["list", "collections.defaultdict", "zip", "fp16_optimizer._FP16OptimizerMixin.fp32_params.keys", "device_params_dict[].append", "grad_data.numel", "fp16_optimizer._FP16OptimizerMixin.fp32_params[].grad.data[].copy_", "torch.zeros_like", "p.data.new_zeros", "grad_data.view", "p.grad.data.float", "p32.grad.data.copy_"], "methods", ["None"], ["", "def", "_sync_fp16_grads_to_fp32", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_needs_sync", ":", "\n", "# copy FP16 grads to FP32", "\n", "            ", "if", "self", ".", "has_flat_params", ":", "\n", "                ", "devices", "=", "list", "(", "self", ".", "fp32_params", ".", "keys", "(", ")", ")", "\n", "device_params_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "                    ", "if", "p", ".", "requires_grad", ":", "\n", "                        ", "device_params_dict", "[", "p", ".", "device", ".", "index", "]", ".", "append", "(", "p", ")", "\n", "", "", "for", "device", "in", "devices", ":", "\n", "                    ", "device_params", "=", "device_params_dict", "[", "device", "]", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                        ", "grad_data", "=", "(", "\n", "p", ".", "grad", ".", "data", "\n", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "shape", ")", "\n", ")", "\n", "numel", "=", "grad_data", ".", "numel", "(", ")", "\n", "self", ".", "fp32_params", "[", "device", "]", ".", "grad", ".", "data", "[", "\n", "offset", ":", "offset", "+", "numel", "\n", "]", ".", "copy_", "(", "grad_data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "", "", "", "else", ":", "\n", "                ", "for", "p", ",", "p32", "in", "zip", "(", "self", ".", "fp16_params", ",", "self", ".", "fp32_params", ")", ":", "\n", "                    ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                        ", "continue", "\n", "", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "p32", ".", "grad", "is", "None", ":", "\n", "                            ", "p32", ".", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                            ", "p32", ".", "grad", ".", "data", ".", "copy_", "(", "p", ".", "grad", ".", "data", ")", "\n", "", "", "else", ":", "\n", "                        ", "p32", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "", "", "self", ".", "_needs_sync", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16": [[141, 164], ["list", "collections.defaultdict", "zip", "fp16_optimizer._FP16OptimizerMixin.fp32_params.keys", "device_params_dict[].append", "p.data.copy_", "p.data.numel", "p.data.copy_", "fp16_optimizer._FP16OptimizerMixin.fp32_params[].data[].view_as"], "methods", ["None"], ["", "", "def", "_sync_fp32_params_to_fp16", "(", "self", ")", ":", "\n", "# copy FP32 params back into FP16 model", "\n", "        ", "if", "self", ".", "has_flat_params", ":", "\n", "            ", "devices", "=", "list", "(", "self", ".", "fp32_params", ".", "keys", "(", ")", ")", "\n", "device_params_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "                ", "device_params_dict", "[", "p", ".", "device", ".", "index", "]", ".", "append", "(", "p", ")", "\n", "", "for", "device", "in", "devices", ":", "\n", "                ", "device_params", "=", "device_params_dict", "[", "device", "]", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                    ", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "p", ".", "data", ".", "copy_", "(", "\n", "self", ".", "fp32_params", "[", "device", "]", "\n", ".", "data", "[", "offset", ":", "offset", "+", "numel", "]", "\n", ".", "view_as", "(", "p", ".", "data", ")", "\n", ")", "\n", "offset", "+=", "numel", "\n", "", "", "", "else", ":", "\n", "            ", "for", "p", ",", "p32", "in", "zip", "(", "self", ".", "fp16_params", ",", "self", ".", "fp32_params", ")", ":", "\n", "                ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                    ", "continue", "\n", "", "p", ".", "data", ".", "copy_", "(", "p32", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._unscale_grads": [[165, 179], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "", "", "def", "_unscale_grads", "(", "self", ")", ":", "\n", "        ", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "if", "(", "\n", "# Skip the multiplication if it's a no-op (i.e., if _multiply_factor", "\n", "# is 1.0). At the same time, we want to avoid the device-to-host", "\n", "# transfer by comparing it to 1.0. Since _multiply_factor starts as", "\n", "# a Python float, we roughly assume that if it's a tensor then it's", "\n", "# probably not =1.0 anymore and we do the multiplication. Otherwise", "\n", "# we can safely check the value without a D2H transfer.", "\n", "torch", ".", "is_tensor", "(", "self", ".", "_multiply_factor", ")", "\n", "or", "self", ".", "_multiply_factor", "!=", "1.0", "\n", ")", ":", "\n", "            ", "self", ".", "fp32_optimizer", ".", "multiply_grads", "(", "self", ".", "_multiply_factor", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.multiply_grads": [[180, 183], ["None"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant ``c``.\"\"\"", "\n", "self", ".", "_multiply_factor", "*=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.clip_grad_norm": [[184, 202], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.clip_grad_norm", "fp16_optimizer._FP16OptimizerMixin.scaler.check_overflow"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "\n", "grad_norm", "=", "self", ".", "_multiply_factor", "*", "self", ".", "fp32_optimizer", ".", "clip_grad_norm", "(", "\n", "0", ",", "aggregate_norm_fn", "\n", ")", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "if", "grad_norm", ">", "max_norm", ">", "0.0", ":", "\n", "                ", "self", ".", "_multiply_factor", "*=", "max_norm", "/", "grad_norm", "\n", "\n", "", "self", ".", "scaler", ".", "check_overflow", "(", "grad_norm", ")", "\n", "", "elif", "max_norm", ">", "0.0", ":", "\n", "            ", "clip_coef", "=", "(", "max_norm", "/", "(", "grad_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "self", ".", "_multiply_factor", "*=", "clip_coef", "\n", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.step": [[203, 217], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "getattr", "fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.step", "fp16_optimizer._FP16OptimizerMixin._unscale_grads", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.step", "fp16_optimizer._FP16OptimizerMixin.scaler.update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "groups", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "\n", "if", "getattr", "(", "self", ",", "\"supports_step_with_scale\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "fp32_optimizer", ".", "step", "(", "closure", ",", "scale", "=", "(", "1.0", "/", "self", ".", "_multiply_factor", ")", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_unscale_grads", "(", ")", "\n", "self", ".", "fp32_optimizer", ".", "step", "(", "closure", ",", "groups", "=", "groups", ")", "\n", "\n", "", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "update", "(", ")", "\n", "\n", "", "self", ".", "_sync_fp32_params_to_fp16", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.zero_grad": [[218, 238], ["torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_params.grad.zero_", "isinstance", "float", "fp16_optimizer._FP16OptimizerMixin.fp32_params.values", "RuntimeError", "p32.grad.zero_", "fp32_params.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "if", "self", ".", "has_flat_params", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "self", ".", "fp32_params", ")", ":", "\n", "                ", "self", ".", "fp32_params", ".", "grad", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "fp32_params", ",", "dict", ")", ":", "\n", "                ", "for", "fp32_params", "in", "self", ".", "fp32_params", ".", "values", "(", ")", ":", "\n", "                    ", "fp32_params", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"self.fp32_params must be a tensor or dict\"", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "p32", "in", "self", ".", "fp32_params", ":", "\n", "                ", "if", "p32", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p32", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "self", ".", "_needs_sync", "=", "False", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "/", "float", "(", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.__init__": [[245, 278], ["super().__init__", "getattr", "int", "int", "getattr", "dynamic_loss_scaler.DynamicLossScaler", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ".", "optimizer", ")", "\n", "self", ".", "fp16_params", "=", "params", "\n", "self", ".", "fp32_optimizer", "=", "fp32_optimizer", "\n", "self", ".", "fp32_params", "=", "fp32_params", "\n", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_scale_window\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "cfg", ".", "optimization", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--fp16-scale-window must be given explicitly when using a \"", "\n", "\"custom --update-freq schedule\"", "\n", ")", "\n", "", "data_parallel_size", "=", "int", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "/", "cfg", ".", "common", ".", "model_parallel_size", "\n", ")", "\n", "scale_window", "=", "int", "(", "\n", "2", "**", "14", "/", "data_parallel_size", "/", "cfg", ".", "optimization", ".", "update_freq", "[", "0", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "cfg", ".", "common", ".", "fp16_scale_window", "\n", "\n", "", "if", "not", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "cfg", ".", "common", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "cfg", ".", "common", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "cfg", ".", "common", ".", "threshold_loss_scale", ",", "\n", "min_loss_scale", "=", "cfg", ".", "common", ".", "min_loss_scale", ",", "\n", ")", "\n", "", "else", ":", "\n", "# disable loss scaling for bfloat16", "\n", "            ", "self", ".", "scaler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.build_optimizer": [[279, 299], ["getattr", "cls.build_fp32_params", "cls", "getattr", "fairseq.optim.build_optimizer", "fairseq.optim.build_optimizer", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer"], ["", "", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "params", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (omegaconf.DictConfig): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "flatten", "=", "not", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_no_flatten_grads\"", ",", "False", ")", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "flatten", "=", "False", "# mixed precision is faster on TPUs without flat grads", "\n", "", "fp32_params", "=", "cls", ".", "build_fp32_params", "(", "cfg", ".", "optimizer", ",", "params", ",", "flatten", "=", "flatten", ")", "\n", "if", "flatten", ":", "\n", "            ", "fp32_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "[", "fp32_params", "]", ")", "\n", "", "else", ":", "\n", "            ", "fp32_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "fp32_params", ")", "\n", "", "if", "flatten", "and", "not", "fp32_optimizer", ".", "supports_flat_params", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"chosen optimizer {fp32_optimizer.__class__.__name__} does not support flat params, please set --fp16-no-flatten-grads\"", "\n", ")", "\n", "", "return", "cls", "(", "cfg", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.optimizer": [[304, 307], ["None"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.lr_scheduler": [[308, 311], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "lr_scheduler", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "fp32_optimizer", ",", "\"lr_scheduler\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.optimizer_config": [[312, 315], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.get_lr": [[316, 318], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.set_lr": [[319, 321], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.FP16Optimizer.all_reduce_grads": [[322, 324], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "all_reduce_grads", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.__init__": [[327, 331], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in MRO (method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.has_flat_params": [[332, 335], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.state_dict": [[336, 342], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "wrapped_optimizer", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "state_dict", "[", "\"loss_scale\"", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.load_state_dict": [[343, 375], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.load_state_dict", "getattr", "state_dict[].items", "zip", "itertools.chain", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "\"loss_scale\"", "in", "state_dict", "and", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "\"loss_scale\"", "]", "\n", "\n", "", "self", ".", "wrapped_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n", "# Hack: PyTorch automatically casts the optimizer state to match the", "\n", "# type of the current parameters. But with --memory-efficient-fp16 the", "\n", "# params are FP16 while the optimizer state is FP32 and we don't want", "\n", "# to cast. A workaround is to manually copy back the original state", "\n", "# after the optimizer has been loaded.", "\n", "if", "not", "getattr", "(", "self", ".", "optimizer", ",", "\"disable_mem_eff_fp16_loading_hack\"", ",", "False", ")", ":", "\n", "            ", "groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "saved_groups", "=", "state_dict", "[", "\"param_groups\"", "]", "\n", "id_map", "=", "{", "\n", "old_id", ":", "p", "\n", "for", "old_id", ",", "p", "in", "zip", "(", "\n", "chain", "(", "*", "(", "g", "[", "\"params\"", "]", "for", "g", "in", "saved_groups", ")", ")", ",", "\n", "chain", "(", "*", "(", "g", "[", "\"params\"", "]", "for", "g", "in", "groups", ")", ")", ",", "\n", ")", "\n", "}", "\n", "for", "k", ",", "v", "in", "state_dict", "[", "\"state\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "id_map", ":", "\n", "                    ", "param", "=", "id_map", "[", "k", "]", "\n", "self", ".", "optimizer", ".", "state", "[", "param", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward": [[376, 386], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.scale"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.scale"], ["", "", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "scaler", ".", "scale", "(", "loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads": [[387, 400], ["torch.is_tensor", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "_unscale_grads", "(", "self", ")", ":", "\n", "        ", "if", "(", "\n", "# Skip the multiplication if it's a no-op (i.e., if _multiply_factor", "\n", "# is 1.0). At the same time, we want to avoid the device-to-host", "\n", "# transfer by comparing it to 1.0. Since _multiply_factor starts as", "\n", "# a Python float, we roughly assume that if it's a tensor then it's", "\n", "# probably not =1.0 anymore and we do the multiplication. Otherwise", "\n", "# we can safely check the value without a D2H transfer.", "\n", "torch", ".", "is_tensor", "(", "self", ".", "_multiply_factor", ")", "\n", "or", "self", ".", "_multiply_factor", "!=", "1.0", "\n", ")", ":", "\n", "            ", "self", ".", "wrapped_optimizer", ".", "multiply_grads", "(", "self", ".", "_multiply_factor", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads": [[401, 404], ["None"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "self", ".", "_multiply_factor", "*=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm": [[405, 424], ["float", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.clip_grad_norm", "float", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.check_overflow"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "grad_norm", "=", "self", ".", "_multiply_factor", "*", "self", ".", "wrapped_optimizer", ".", "clip_grad_norm", "(", "\n", "0", ",", "aggregate_norm_fn", "\n", ")", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "grad_norm_cpu", "=", "float", "(", "grad_norm", ")", "\n", "if", "grad_norm_cpu", ">", "max_norm", ">", "0.0", ":", "\n", "                ", "self", ".", "_multiply_factor", "*=", "max_norm", "/", "grad_norm_cpu", "\n", "\n", "# detect overflow and adjust loss scale", "\n", "", "self", ".", "scaler", ".", "check_overflow", "(", "grad_norm_cpu", ")", "\n", "", "elif", "max_norm", ">", "0.0", ":", "\n", "            ", "clip_coef", "=", "(", "max_norm", "/", "(", "grad_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "self", ".", "_multiply_factor", "*=", "clip_coef", "\n", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.step": [[425, 436], ["getattr", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.step", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.step", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "groups", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"supports_step_with_scale\"", ",", "False", ")", ":", "\n", "# NOTE(msb) optimizer divides by scale factor", "\n", "            ", "self", ".", "wrapped_optimizer", ".", "step", "(", "closure", ",", "scale", "=", "(", "1.0", "/", "self", ".", "_multiply_factor", ")", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_unscale_grads", "(", ")", "\n", "self", ".", "wrapped_optimizer", ".", "step", "(", "closure", ",", "groups", "=", "groups", ")", "\n", "\n", "", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad": [[437, 444], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.zero_grad", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "wrapped_optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "/", "float", "(", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.__init__": [[464, 500], ["super().__init__", "ValueError", "getattr", "int", "int", "getattr", "dynamic_loss_scaler.DynamicLossScaler", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "optimizer", ".", "supports_memory_efficient_fp16", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unsupported optimizer: {}\"", ".", "format", "(", "optimizer", ".", "__class__", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "cfg", ".", "optimizer", ")", "\n", "self", ".", "wrapped_optimizer", "=", "optimizer", "\n", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_scale_window\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "cfg", ".", "optimization", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--fp16-scale-window must be given explicitly when using a \"", "\n", "\"custom --update-freq schedule\"", "\n", ")", "\n", "", "data_parallel_size", "=", "int", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "/", "cfg", ".", "common", ".", "model_parallel_size", "\n", ")", "\n", "scale_window", "=", "int", "(", "\n", "2", "**", "14", "/", "data_parallel_size", "/", "cfg", ".", "optimization", ".", "update_freq", "[", "0", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "cfg", ".", "common", ".", "fp16_scale_window", "\n", "\n", "", "if", "not", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "cfg", ".", "common", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "cfg", ".", "common", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "cfg", ".", "common", ".", "threshold_loss_scale", ",", "\n", "min_loss_scale", "=", "cfg", ".", "common", ".", "min_loss_scale", ",", "\n", ")", "\n", "", "else", ":", "\n", "# disable loss scaling for bfloat16", "\n", "            ", "self", ".", "scaler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer": [[501, 510], ["fairseq.optim.build_optimizer", "cls"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer"], ["", "", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "params", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args (argparse.Namespace): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "fp16_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "params", ")", "\n", "return", "cls", "(", "cfg", ",", "params", ",", "fp16_optimizer", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer": [[515, 518], ["None"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer_config": [[519, 522], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.lr_scheduler": [[523, 526], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "lr_scheduler", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "wrapped_optimizer", ",", "\"lr_scheduler\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr": [[527, 529], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr": [[530, 532], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.all_reduce_grads": [[533, 535], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "all_reduce_grads", "(", "module", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.__init__": [[50, 67], ["fairseq.optim.FairseqOptimizer.__init__", "fairseq.optim.fused_adam.get_fused_adam_class", "getattr", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "adam.Adam", "getattr", "logger.info", "fairseq.optim.fused_adam.get_fused_adam_class.", "adam.Adam"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.get_fused_adam_class"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "fused_adam_cls", "=", "get_fused_adam_class", "(", ")", "\n", "use_fused_adam", "=", "(", "\n", "not", "getattr", "(", "cfg", ",", "\"use_old_adam\"", ",", "False", ")", "\n", "and", "fused_adam_cls", "is", "not", "None", "\n", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", ")", "\n", "if", "getattr", "(", "cfg", ",", "\"tpu\"", ",", "False", ")", ":", "\n", "# on TPUs we use the Adam defined here, since it", "\n", "# automatically casts gradients to FP32", "\n", "            ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "elif", "use_fused_adam", ":", "\n", "            ", "logger", ".", "info", "(", "\"using FusedAdam\"", ")", "\n", "self", ".", "_optimizer", "=", "fused_adam_cls", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.optimizer_config": [[68, 83], ["eval", "isinstance"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "isinstance", "(", "self", ".", "cfg", ".", "lr", ",", "Collection", ")", "\n", "else", "self", ".", "cfg", ".", "lr", ",", "\n", "\"betas\"", ":", "eval", "(", "self", ".", "cfg", ".", "adam_betas", ")", ",", "\n", "\"eps\"", ":", "self", ".", "cfg", ".", "adam_eps", ",", "\n", "\"weight_decay\"", ":", "self", ".", "cfg", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.FairseqAdam.average_params": [[85, 95], ["adam.FairseqAdam.optimizer.state_dict", "float", "state_dict[].items", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reduce Params is only used during BMUF distributed training.\"\"\"", "\n", "state_dict", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "total_gpus", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "\n", "for", "_", ",", "value", "in", "state_dict", "[", "\"state\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "value", "[", "\"exp_avg\"", "]", "/=", "total_gpus", "\n", "value", "[", "\"exp_avg_sq\"", "]", "/=", "total_gpus", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg_sq\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.Adam.__init__": [[124, 137], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-3", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "\n", "amsgrad", "=", "False", ",", "\n", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", "\n", ")", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.Adam.supports_memory_efficient_fp16": [[138, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.Adam.supports_flat_params": [[142, 145], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.adam.Adam.step": [[146, 227], ["closure", "group.get", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p_data_fp32.float.float.addcdiv_", "grad.float.float.float", "RuntimeError", "p_data_fp32.float.float.float", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "p_data_fp32.float.float.add_", "p.data.copy_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "exp_avg.mul_", "exp_avg_sq.mul_", "math.sqrt", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Args:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "grad", "=", "grad", ".", "float", "(", ")", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Adam does not support sparse gradients, please consider SparseAdam instead\"", "\n", ")", "\n", "", "amsgrad", "=", "group", ".", "get", "(", "\"amsgrad\"", ",", "False", ")", "\n", "\n", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "\"max_exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "", "else", ":", "\n", "                    ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "                        ", "state", "[", "\"max_exp_avg_sq\"", "]", "=", "state", "[", "\"max_exp_avg_sq\"", "]", ".", "to", "(", "\n", "p_data_fp32", "\n", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "\"max_exp_avg_sq\"", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1", "-", "beta1", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1", "-", "beta2", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "\n", "p_data_fp32", ",", "alpha", "=", "-", "group", "[", "\"weight_decay\"", "]", "*", "group", "[", "\"lr\"", "]", "\n", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "exp_avg", ",", "denom", ",", "value", "=", "-", "step_size", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.__init__.build_optimizer": [[35, 40], ["all", "list", "_build_optimizer", "filter", "isinstance", "p.values"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer._build_optimizer"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.__init__": [[8, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "init_scale", "=", "2.0", "**", "15", ",", "\n", "scale_factor", "=", "2.0", ",", "\n", "scale_window", "=", "2000", ",", "\n", "tolerance", "=", "0.05", ",", "\n", "threshold", "=", "None", ",", "\n", "min_loss_scale", "=", "1e-4", ",", "\n", ")", ":", "\n", "        ", "self", ".", "loss_scale", "=", "init_scale", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "scale_window", "=", "scale_window", "\n", "self", ".", "tolerance", "=", "tolerance", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "_iter", "=", "0", "\n", "self", ".", "_last_overflow_iter", "=", "-", "1", "\n", "self", ".", "_last_rescale_iter", "=", "-", "1", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "self", ".", "min_loss_scale", "=", "min_loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.scale": [[28, 30], ["None"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "loss_scale", "*", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.update": [[31, 36], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "_iter", "-", "self", ".", "_last_overflow_iter", ")", "%", "self", ".", "scale_window", "==", "0", ":", "\n", "            ", "self", ".", "loss_scale", "*=", "self", ".", "scale_factor", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale": [[37, 41], ["max"], "methods", ["None"], ["", "def", "_decrease_loss_scale", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_scale", "/=", "self", ".", "scale_factor", "\n", "if", "self", ".", "threshold", "is", "not", "None", ":", "\n", "            ", "self", ".", "loss_scale", "=", "max", "(", "self", ".", "loss_scale", ",", "self", ".", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow": [[42, 71], ["OverflowError", "float", "float", "dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale", "FloatingPointError", "str"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale"], ["", "", "def", "check_overflow", "(", "self", ",", "grad_norm", ")", ":", "\n", "# detect inf and nan", "\n", "        ", "if", "grad_norm", "==", "float", "(", "\"inf\"", ")", "or", "grad_norm", "!=", "grad_norm", ":", "\n", "# overflow has occured", "\n", "            ", "prev_scale", "=", "self", ".", "loss_scale", "\n", "iter_since_rescale", "=", "self", ".", "_iter", "-", "self", ".", "_last_rescale_iter", "\n", "\n", "self", ".", "_last_overflow_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "+=", "1", "\n", "pct_overflow", "=", "self", ".", "_overflows_since_rescale", "/", "float", "(", "iter_since_rescale", ")", "\n", "if", "pct_overflow", ">=", "self", ".", "tolerance", ":", "\n", "                ", "self", ".", "_decrease_loss_scale", "(", ")", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "\n", "", "if", "self", ".", "loss_scale", "<=", "self", ".", "min_loss_scale", ":", "\n", "# Use FloatingPointError as an uncommon error that parent", "\n", "# functions can safely catch to stop training.", "\n", "                ", "self", ".", "loss_scale", "=", "prev_scale", "\n", "raise", "FloatingPointError", "(", "\n", "(", "\n", "\"Minimum loss scale reached ({}). Your loss is probably exploding. \"", "\n", "\"Try lowering the learning rate, using gradient clipping or \"", "\n", "\"increasing the batch size.\"", "\n", ")", ".", "format", "(", "self", ".", "min_loss_scale", ")", "\n", ")", "\n", "\n", "", "self", ".", "_iter", "+=", "1", "\n", "raise", "OverflowError", "(", "\"setting loss scale to: \"", "+", "str", "(", "self", ".", "loss_scale", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.FusedAdamV1.__init__": [[72, 101], ["importlib.import_module", "super().__init__", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-3", ",", "\n", "bias_correction", "=", "True", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "eps_inside_sqrt", "=", "False", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "max_grad_norm", "=", "0.0", ",", "\n", "amsgrad", "=", "False", ",", "\n", ")", ":", "\n", "        ", "global", "fused_adam_cuda", "\n", "import", "importlib", "\n", "\n", "fused_adam_cuda", "=", "importlib", ".", "import_module", "(", "\"fused_adam_cuda\"", ")", "\n", "\n", "if", "amsgrad", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"FusedAdam does not support the AMSGrad variant.\"", ")", "\n", "", "defaults", "=", "{", "\n", "\"lr\"", ":", "lr", ",", "\n", "\"bias_correction\"", ":", "bias_correction", ",", "\n", "\"betas\"", ":", "betas", ",", "\n", "\"eps\"", ":", "eps", ",", "\n", "\"weight_decay\"", ":", "weight_decay", ",", "\n", "\"max_grad_norm\"", ":", "max_grad_norm", ",", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "self", ".", "eps_mode", "=", "0", "if", "eps_inside_sqrt", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.FusedAdamV1.supports_memory_efficient_fp16": [[102, 105], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.FusedAdamV1.supports_flat_params": [[106, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.FusedAdamV1.supports_step_with_scale": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_step_with_scale", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.FusedAdamV1.step": [[114, 217], ["zip", "closure", "isinstance", "zip", "len", "len", "group.get", "group.get", "p.data.float", "type", "len", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "torch.cuda.device", "fused_adam_cuda.adam"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.device"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "grads", "=", "None", ",", "scale", "=", "1.0", ",", "grad_norms", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Args:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n            grads (list of tensors, optional): weight gradient to use for the\n                optimizer update. If gradients have type torch.half, parameters\n                are expected to be in type torch.float. (default: None)\n            output params (list of tensors, optional): A reduced precision copy\n                of the updated weights written out in addition to the regular\n                updated weights. Have to be of same type as gradients. (default: None)\n            scale (float, optional): factor to divide gradient tensor values\n                by before applying to weights. (default: 1)\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "if", "grads", "is", "None", ":", "\n", "            ", "grads_group", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "# backward compatibility", "\n", "# assuming a list/generator of parameter means single group", "\n", "", "elif", "isinstance", "(", "grads", ",", "types", ".", "GeneratorType", ")", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "elif", "type", "(", "grads", "[", "0", "]", ")", "!=", "list", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "else", ":", "\n", "            ", "grads_group", "=", "grads", "\n", "\n", "", "if", "grad_norms", "is", "None", ":", "\n", "            ", "grad_norms", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "\n", "", "for", "group", ",", "grads_this_group", ",", "grad_norm", "in", "zip", "(", "\n", "self", ".", "param_groups", ",", "grads_group", ",", "grad_norms", "\n", ")", ":", "\n", "            ", "if", "grads_this_group", "is", "None", ":", "\n", "                ", "grads_this_group", "=", "[", "None", "]", "*", "len", "(", "group", "[", "\"params\"", "]", ")", "\n", "\n", "# compute combined scale factor for this group", "\n", "", "combined_scale", "=", "scale", "\n", "if", "group", ".", "get", "(", "\"max_grad_norm\"", ",", "0", ")", ">", "0", ":", "\n", "# norm is in fact norm*scale", "\n", "                ", "clip", "=", "(", "(", "grad_norm", "/", "scale", ")", "+", "1e-6", ")", "/", "group", "[", "\"max_grad_norm\"", "]", "\n", "if", "clip", ">", "1", ":", "\n", "                    ", "combined_scale", "=", "clip", "*", "scale", "\n", "\n", "", "", "bias_correction", "=", "1", "if", "group", ".", "get", "(", "\"bias_correction\"", ",", "1", ")", "else", "0", "\n", "\n", "for", "p", ",", "grad", "in", "zip", "(", "group", "[", "\"params\"", "]", ",", "grads_this_group", ")", ":", "\n", "# note: p.grad should not ever be set for correct", "\n", "# operation of mixed precision optimizer that sometimes", "\n", "# sends None gradients", "\n", "                ", "if", "p", ".", "grad", "is", "None", "and", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "if", "grad", "is", "None", ":", "\n", "                    ", "grad", "=", "p", ".", "grad", ".", "data", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"FusedAdam does not support sparse gradients, \"", "\n", "\"please consider SparseAdam instead\"", "\n", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", "=", "state", "[", "\"exp_avg\"", "]", "\n", "exp_avg_sq", "=", "state", "[", "\"exp_avg_sq\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "out_p", "=", "p", ".", "data", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "p", ".", "device", ")", ":", "\n", "                    ", "fused_adam_cuda", ".", "adam", "(", "\n", "p_data_fp32", ",", "\n", "out_p", ",", "\n", "exp_avg", ",", "\n", "exp_avg_sq", ",", "\n", "grad", ",", "\n", "group", "[", "\"lr\"", "]", ",", "\n", "beta1", ",", "\n", "beta2", ",", "\n", "group", "[", "\"eps\"", "]", ",", "\n", "combined_scale", ",", "\n", "state", "[", "\"step\"", "]", ",", "\n", "self", ".", "eps_mode", ",", "\n", "bias_correction", ",", "\n", "group", "[", "\"weight_decay\"", "]", ",", "\n", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fused_adam.get_fused_adam_class": [[11, 38], ["importlib.import_module"], "function", ["None"], ["def", "get_fused_adam_class", "(", ")", ":", "\n", "    ", "\"\"\"\n    Look for the FusedAdam optimizer from apex. We first try to load the\n    \"contrib\" interface, which is a bit faster than the main interface,\n    but is technically deprecated.\n    \"\"\"", "\n", "try", ":", "\n", "# The \"deprecated\" interface in recent versions of apex is a bit", "\n", "# faster than the main interface, since we don't use the apex", "\n", "# optimizer. This can be installed by passing the", "\n", "# `--deprecated_fused_adam` option when building apex.", "\n", "        ", "global", "fused_adam_cuda", "\n", "import", "importlib", "\n", "\n", "fused_adam_cuda", "=", "importlib", ".", "import_module", "(", "\"fused_adam_cuda\"", ")", "\n", "return", "FusedAdamV1", "\n", "", "except", "ImportError", ":", "\n", "        ", "try", ":", "\n", "# fallback to the newer interface", "\n", "            ", "from", "apex", ".", "optimizers", "import", "FusedAdam", "as", "_FusedAdam", "# noqa", "\n", "from", "apex", ".", "multi_tensor_apply", "import", "multi_tensor_applier", "\n", "\n", "if", "multi_tensor_applier", ".", "available", ":", "\n", "                ", "return", "FusedAdamV2", "\n", "", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.sgd.SGD.__init__": [[13, 16], ["LegacyFairseqOptimizer.__init__", "torch.optim.SGD"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.sgd.SGD.add_args": [[17, 25], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'momentum factor'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.sgd.SGD.optimizer_config": [[27, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"momentum\"", ":", "self", ".", "args", ".", "momentum", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.sgd.SGD.supports_flat_params": [[41, 44], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.__init__": [[13, 20], ["object.__init__", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "optimizer", "is", "not", "None", "and", "not", "isinstance", "(", "optimizer", ",", "FairseqOptimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"optimizer must be an instance of FairseqOptimizer\"", ")", "\n", "", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "best", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.add_args": [[21, 27], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.state_dict": [[28, 31], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the LR scheduler state dict.\"\"\"", "\n", "return", "{", "\"best\"", ":", "self", ".", "best", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.load_state_dict": [[32, 35], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an LR scheduler state dict.\"\"\"", "\n", "self", ".", "best", "=", "state_dict", "[", "\"best\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step_begin_epoch": [[36, 39], ["None"], "methods", ["None"], ["", "def", "step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the beginning of the given epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step": [[40, 47], ["min"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "best", "is", "None", ":", "\n", "                ", "self", ".", "best", "=", "val_loss", "\n", "", "else", ":", "\n", "                ", "self", ".", "best", "=", "min", "(", "self", ".", "best", ",", "val_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step_update": [[48, 51], ["fairseq_lr_scheduler.FairseqLRScheduler.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "", "", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.fairseq_lr_scheduler.LegacyFairseqLRScheduler.__init__": [[54, 60], ["isinstance", "ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "Namespace", ",", "optimizer", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "optimizer", ",", "FairseqOptimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"optimizer must be an instance of FairseqOptimizer\"", ")", "\n", "", "self", ".", "args", "=", "args", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "best", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.__init__.build_lr_scheduler": [[28, 30], ["build_lr_scheduler_"], "function", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.tri_stage_lr_scheduler.TriStageLRSchedule.__init__": [[89, 127], ["fairseq.optim.lr_scheduler.FairseqLRScheduler.__init__", "tri_stage_lr_scheduler.TriStageLRSchedule.optimizer.set_lr", "len", "ValueError", "int", "int", "int", "sum", "math.log"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["def", "__init__", "(", "self", ",", "cfg", ":", "TriStageLRScheduleConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "optimizer", ")", "\n", "if", "len", "(", "cfg", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with tri-stage lr.\"", "\n", "\" Consider --lr-scheduler=fixed instead.\"", "\n", ")", "\n", "\n", "# calculate LR at each point", "\n", "", "self", ".", "peak_lr", "=", "cfg", ".", "lr", "[", "0", "]", "\n", "self", ".", "init_lr", "=", "cfg", ".", "init_lr_scale", "*", "cfg", ".", "lr", "[", "0", "]", "\n", "self", ".", "final_lr", "=", "cfg", ".", "final_lr_scale", "*", "cfg", ".", "lr", "[", "0", "]", "\n", "\n", "if", "cfg", ".", "phase_ratio", "is", "not", "None", ":", "\n", "            ", "assert", "cfg", ".", "max_update", ">", "0", "\n", "assert", "sum", "(", "cfg", ".", "phase_ratio", ")", "==", "1", ",", "\"phase ratios must add up to 1\"", "\n", "self", ".", "warmup_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "0", "]", ")", "\n", "self", ".", "hold_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "1", "]", ")", "\n", "self", ".", "decay_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "cfg", ".", "warmup_steps", "\n", "self", ".", "hold_steps", "=", "cfg", ".", "hold_steps", "\n", "self", ".", "decay_steps", "=", "cfg", ".", "decay_steps", "\n", "\n", "", "assert", "(", "\n", "self", ".", "warmup_steps", "+", "self", ".", "hold_steps", "+", "self", ".", "decay_steps", ">", "0", "\n", ")", ",", "\"please specify steps or phase_ratio\"", "\n", "\n", "self", ".", "warmup_rate", "=", "(", "\n", "(", "self", ".", "peak_lr", "-", "self", ".", "init_lr", ")", "/", "self", ".", "warmup_steps", "\n", "if", "self", ".", "warmup_steps", "!=", "0", "\n", "else", "0", "\n", ")", "\n", "self", ".", "decay_factor", "=", "-", "math", ".", "log", "(", "cfg", ".", "final_lr_scale", ")", "/", "self", ".", "decay_steps", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "self", ".", "init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.tri_stage_lr_scheduler.TriStageLRSchedule._decide_stage": [[128, 152], ["None"], "methods", ["None"], ["", "def", "_decide_stage", "(", "self", ",", "update_step", ")", ":", "\n", "        ", "\"\"\"\n        return stage, and the corresponding steps within the current stage\n        \"\"\"", "\n", "if", "update_step", "<", "self", ".", "warmup_steps", ":", "\n", "# warmup state", "\n", "            ", "return", "0", ",", "update_step", "\n", "\n", "", "offset", "=", "self", ".", "warmup_steps", "\n", "\n", "if", "update_step", "<", "offset", "+", "self", ".", "hold_steps", ":", "\n", "# hold stage", "\n", "            ", "return", "1", ",", "update_step", "-", "offset", "\n", "\n", "", "offset", "+=", "self", ".", "hold_steps", "\n", "\n", "if", "update_step", "<=", "offset", "+", "self", ".", "decay_steps", ":", "\n", "# decay stage", "\n", "            ", "return", "2", ",", "update_step", "-", "offset", "\n", "\n", "", "offset", "+=", "self", ".", "decay_steps", "\n", "\n", "# still here ? constant lr stage", "\n", "return", "3", ",", "update_step", "-", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.tri_stage_lr_scheduler.TriStageLRSchedule.step": [[153, 158], ["super().step", "tri_stage_lr_scheduler.TriStageLRSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.tri_stage_lr_scheduler.TriStageLRSchedule.step_update": [[159, 176], ["tri_stage_lr_scheduler.TriStageLRSchedule._decide_stage", "tri_stage_lr_scheduler.TriStageLRSchedule.optimizer.set_lr", "math.exp", "ValueError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.tri_stage_lr_scheduler.TriStageLRSchedule._decide_stage", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "stage", ",", "steps_in_stage", "=", "self", ".", "_decide_stage", "(", "num_updates", ")", "\n", "if", "stage", "==", "0", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "init_lr", "+", "self", ".", "warmup_rate", "*", "steps_in_stage", "\n", "", "elif", "stage", "==", "1", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "peak_lr", "\n", "", "elif", "stage", "==", "2", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "peak_lr", "*", "math", ".", "exp", "(", "-", "self", ".", "decay_factor", "*", "steps_in_stage", ")", "\n", "", "elif", "stage", "==", "3", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "final_lr", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Undefined stage\"", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.__init__": [[43, 57], ["fairseq.optim.lr_scheduler.FairseqLRScheduler.__init__", "polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "cfg", ":", "PolynomialDecayLRScheduleConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "assert", "cfg", ".", "total_num_update", ">", "0", "\n", "\n", "self", ".", "lr", "=", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "cfg", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1.0", "/", "cfg", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1", "\n", "", "self", ".", "end_learning_rate", "=", "cfg", ".", "end_learning_rate", "\n", "self", ".", "total_num_update", "=", "cfg", ".", "total_num_update", "\n", "self", ".", "power", "=", "cfg", ".", "power", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.get_next_lr": [[58, 67], ["polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.get_lr", "min", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_next_lr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "lrs", "=", "self", ".", "cfg", ".", "lr", "\n", "if", "self", ".", "cfg", ".", "force_anneal", "is", "None", "or", "epoch", "<", "self", ".", "cfg", ".", "force_anneal", ":", "\n", "# use fixed LR schedule", "\n", "            ", "next_lr", "=", "lrs", "[", "min", "(", "epoch", ",", "len", "(", "lrs", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "# annneal based on lr_shrink", "\n", "            ", "next_lr", "=", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "return", "next_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_begin_epoch": [[68, 73], ["polynomial_decay_schedule.PolynomialDecayLRSchedule.get_next_lr", "polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.get_next_lr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the beginning of the given epoch.\"\"\"", "\n", "self", ".", "lr", "=", "self", ".", "get_next_lr", "(", "epoch", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lr_scheduler.polynomial_decay_schedule.PolynomialDecayLRSchedule.step_update": [[74, 90], ["polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecayLRSchedule.optimizer.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "self", ".", "cfg", ".", "warmup_updates", ">", "0", "and", "num_updates", "<=", "self", ".", "cfg", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "num_updates", "/", "float", "(", "self", ".", "cfg", ".", "warmup_updates", ")", "\n", "lr", "=", "self", ".", "warmup_factor", "*", "self", ".", "lr", "\n", "", "elif", "num_updates", ">=", "self", ".", "total_num_update", ":", "\n", "            ", "lr", "=", "self", ".", "end_learning_rate", "\n", "", "else", ":", "\n", "            ", "warmup", "=", "self", ".", "cfg", ".", "warmup_updates", "\n", "lr_range", "=", "self", ".", "lr", "-", "self", ".", "end_learning_rate", "\n", "pct_remaining", "=", "1", "-", "(", "num_updates", "-", "warmup", ")", "/", "(", "\n", "self", ".", "total_num_update", "-", "warmup", "\n", ")", "\n", "lr", "=", "lr_range", "*", "pct_remaining", "**", "(", "self", ".", "power", ")", "+", "self", ".", "end_learning_rate", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.__init__": [[29, 43], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.remove_punctuation": [[44, 51], ["cls.SPACE.join", "sent.split", "all", "unicodedata.category"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize": [[53, 68], ["tokenizer.EvaluationTokenizer.tokenizer", "tokenizer.EvaluationTokenizer.remove_punctuation", "tokenizer.EvaluationTokenizer.SPACE.join", "tokenized.lower.lower.lower", "list", "tokenized.lower.lower.replace"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.remove_punctuation"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.wer.WerScorer.__init__": [[29, 42], ["fairseq.scoring.BaseScorer.__init__", "wer.WerScorer.reset", "fairseq.scoring.tokenizer.EvaluationTokenizer", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "import", "editdistance", "as", "ed", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install editdistance to use WER scorer\"", ")", "\n", "", "self", ".", "ed", "=", "ed", "\n", "self", ".", "tokenizer", "=", "EvaluationTokenizer", "(", "\n", "tokenizer_type", "=", "self", ".", "cfg", ".", "wer_tokenizer", ",", "\n", "lowercase", "=", "self", ".", "cfg", ".", "wer_lowercase", ",", "\n", "punctuation_removal", "=", "self", ".", "cfg", ".", "wer_remove_punct", ",", "\n", "character_tokenization", "=", "self", ".", "cfg", ".", "wer_char_level", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.wer.WerScorer.reset": [[44, 47], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "distance", "=", "0", "\n", "self", ".", "ref_length", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.wer.WerScorer.add_string": [[48, 53], ["wer.WerScorer.tokenizer.tokenize().split", "wer.WerScorer.tokenizer.tokenize().split", "wer.WerScorer.ed.eval", "len", "wer.WerScorer.tokenizer.tokenize", "wer.WerScorer.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "def", "add_string", "(", "self", ",", "ref", ",", "pred", ")", ":", "\n", "        ", "ref_items", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "ref", ")", ".", "split", "(", ")", "\n", "pred_items", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "pred", ")", ".", "split", "(", ")", "\n", "self", ".", "distance", "+=", "self", ".", "ed", ".", "eval", "(", "ref_items", ",", "pred_items", ")", "\n", "self", ".", "ref_length", "+=", "len", "(", "ref_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.wer.WerScorer.result_string": [[54, 56], ["wer.WerScorer.score"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.score"], ["", "def", "result_string", "(", "self", ")", ":", "\n", "        ", "return", "f\"WER: {self.score():.2f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.wer.WerScorer.score": [[57, 59], ["None"], "methods", ["None"], ["", "def", "score", "(", "self", ")", ":", "\n", "        ", "return", "100.0", "*", "self", ".", "distance", "/", "self", ".", "ref_length", "if", "self", ".", "ref_length", ">", "0", "else", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.__init__": [[16, 20], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.add_string": [[21, 24], ["__init__.BaseScorer.ref.append", "__init__.BaseScorer.pred.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.score": [[25, 28], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.BaseScorer.result_string": [[29, 32], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.__init__.build_scorer": [[39, 49], ["_build_scorer", "isinstance", "bleu.Scorer", "bleu.BleuConfig", "tgt_dict.pad", "tgt_dict.eos", "tgt_dict.unk"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.__init__": [[118, 127], ["getattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "n", "=", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "prefix", "=", "\"\"", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "\"epoch {:03d}\"", ".", "format", "(", "epoch", ")", "\n", "", "if", "prefix", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "\" | {}\"", ".", "format", "(", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.__len__": [[128, 130], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.__enter__": [[131, 133], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.__exit__": [[134, 136], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.__iter__": [[137, 139], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.log": [[140, 143], ["None"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.print": [[144, 147], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar.update_config": [[148, 151], ["None"], "methods", ["None"], ["", "def", "update_config", "(", "self", ",", "config", ")", ":", "\n", "        ", "\"\"\"Log latest configuration.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._str_commas": [[152, 154], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_commas", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "\", \"", ".", "join", "(", "key", "+", "\"=\"", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._str_pipes": [[155, 157], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_pipes", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "\" | \"", ".", "join", "(", "key", "+", "\" \"", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._format_stats": [[158, 164], ["collections.OrderedDict", "collections.OrderedDict.keys", "str", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.format_stat"], ["", "def", "_format_stats", "(", "self", ",", "stats", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", "stats", ")", "\n", "# Preprocess stats according to datatype", "\n", "for", "key", "in", "postfix", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "str", "(", "format_stat", "(", "postfix", "[", "key", "]", ")", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar.__init__": [[178, 183], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "i", "=", "None", "\n", "self", ".", "size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar.__iter__": [[184, 189], ["len", "enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "size", "=", "len", "(", "self", ".", "iterable", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "n", ")", ":", "\n", "            ", "self", ".", "i", "=", "i", "\n", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar.log": [[190, 202], ["progress_bar.JsonProgressBar._format_stats", "progress_bar.rename_logger", "logger.info", "json.dumps", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "step", "=", "step", "or", "self", ".", "i", "or", "0", "\n", "if", "step", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "step", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "            ", "update", "=", "(", "\n", "self", ".", "epoch", "-", "1", "+", "(", "self", ".", "i", "+", "1", ")", "/", "float", "(", "self", ".", "size", ")", "\n", "if", "self", ".", "epoch", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "stats", "=", "self", ".", "_format_stats", "(", "stats", ",", "epoch", "=", "self", ".", "epoch", ",", "update", "=", "update", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "                ", "logger", ".", "info", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar.print": [[203, 213], ["progress_bar.JsonProgressBar._format_stats", "collections.OrderedDict", "progress_bar.rename_logger", "logger.info", "json.dumps", "progress_bar.JsonProgressBar.stats.items"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger"], ["", "", "", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "stats", "=", "stats", "\n", "if", "tag", "is", "not", "None", ":", "\n", "            ", "self", ".", "stats", "=", "OrderedDict", "(", "\n", "[", "(", "tag", "+", "\"_\"", "+", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "stats", ".", "items", "(", ")", "]", "\n", ")", "\n", "", "stats", "=", "self", ".", "_format_stats", "(", "self", ".", "stats", ",", "epoch", "=", "self", ".", "epoch", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats": [[214, 224], ["collections.OrderedDict", "stats.keys", "round", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.format_stat"], ["", "", "def", "_format_stats", "(", "self", ",", "stats", ",", "epoch", "=", "None", ",", "update", "=", "None", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", ")", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "\"epoch\"", "]", "=", "epoch", "\n", "", "if", "update", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "\"update\"", "]", "=", "round", "(", "update", ",", "3", ")", "\n", "# Preprocess stats according to datatype", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "format_stat", "(", "stats", "[", "key", "]", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.NoopProgressBar.__init__": [[229, 231], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.NoopProgressBar.__iter__": [[232, 235], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "obj", "in", "self", ".", "iterable", ":", "\n", "            ", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.NoopProgressBar.log": [[236, 239], ["None"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.NoopProgressBar.print": [[240, 243], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.SimpleProgressBar.__init__": [[248, 253], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "i", "=", "None", "\n", "self", ".", "size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.SimpleProgressBar.__iter__": [[254, 259], ["len", "enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "size", "=", "len", "(", "self", ".", "iterable", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "n", ")", ":", "\n", "            ", "self", ".", "i", "=", "i", "\n", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.SimpleProgressBar.log": [[260, 270], ["progress_bar.SimpleProgressBar._format_stats", "progress_bar.SimpleProgressBar._str_commas", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._str_commas", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "step", "=", "step", "or", "self", ".", "i", "or", "0", "\n", "if", "step", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "step", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "            ", "stats", "=", "self", ".", "_format_stats", "(", "stats", ")", "\n", "postfix", "=", "self", ".", "_str_commas", "(", "stats", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"{}:  {:5d} / {:d} {}\"", ".", "format", "(", "\n", "self", ".", "prefix", ",", "self", ".", "i", "+", "1", ",", "self", ".", "size", ",", "postfix", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.SimpleProgressBar.print": [[273, 278], ["progress_bar.SimpleProgressBar._str_pipes", "progress_bar.SimpleProgressBar._format_stats", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._str_pipes", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger"], ["", "", "", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} | {}\"", ".", "format", "(", "self", ".", "prefix", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TqdmProgressBar.__init__": [[283, 292], ["progress_bar.BaseProgressBar.__init__", "tqdm", "logger.getEffectiveLevel"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "self", ".", "tqdm", "=", "tqdm", "(", "\n", "iterable", ",", "\n", "self", ".", "prefix", ",", "\n", "leave", "=", "False", ",", "\n", "disable", "=", "(", "logger", ".", "getEffectiveLevel", "(", ")", ">", "logging", ".", "INFO", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TqdmProgressBar.__iter__": [[294, 296], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "tqdm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TqdmProgressBar.log": [[297, 300], ["progress_bar.TqdmProgressBar.tqdm.set_postfix", "progress_bar.TqdmProgressBar._format_stats"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "self", ".", "tqdm", ".", "set_postfix", "(", "self", ".", "_format_stats", "(", "stats", ")", ",", "refresh", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TqdmProgressBar.print": [[301, 306], ["progress_bar.TqdmProgressBar._str_pipes", "progress_bar.TqdmProgressBar._format_stats", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.BaseProgressBar._str_pipes", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} | {}\"", ".", "format", "(", "self", ".", "prefix", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper.__init__": [[329, 336], ["logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ",", "tensorboard_logdir", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "self", ".", "tensorboard_logdir", "=", "tensorboard_logdir", "\n", "\n", "if", "SummaryWriter", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"tensorboard not found, please install with: pip install tensorboard\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper._writer": [[338, 346], ["SummaryWriter", "_writers[].add_text", "os.path.join"], "methods", ["None"], ["", "", "def", "_writer", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "SummaryWriter", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "_writers", "=", "_tensorboard_writers", "\n", "if", "key", "not", "in", "_writers", ":", "\n", "            ", "_writers", "[", "key", "]", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "tensorboard_logdir", ",", "key", ")", ")", "\n", "_writers", "[", "key", "]", ".", "add_text", "(", "\"sys.argv\"", ",", "\" \"", ".", "join", "(", "sys", ".", "argv", ")", ")", "\n", "", "return", "_writers", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper.__iter__": [[347, 349], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper.log": [[350, 354], ["progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "progress_bar.TensorboardProgressBarWrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to tensorboard.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper.print": [[355, 359], ["progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "progress_bar.TensorboardProgressBarWrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper.update_config": [[360, 364], ["progress_bar.TensorboardProgressBarWrapper.wrapped_bar.update_config"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.update_config"], ["", "def", "update_config", "(", "self", ",", "config", ")", ":", "\n", "        ", "\"\"\"Log latest configuration.\"\"\"", "\n", "# TODO add hparams to Tensorboard", "\n", "self", ".", "wrapped_bar", ".", "update_config", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard": [[365, 379], ["progress_bar.TensorboardProgressBarWrapper._writer", "progress_bar.TensorboardProgressBarWrapper.flush", "stats.keys", "isinstance", "progress_bar.TensorboardProgressBarWrapper.add_scalar", "isinstance", "progress_bar.TensorboardProgressBarWrapper.add_scalar", "torch.is_tensor", "progress_bar.TensorboardProgressBarWrapper.add_scalar", "stats[].numel", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.TensorboardProgressBarWrapper._writer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "_log_to_tensorboard", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "writer", "=", "self", ".", "_writer", "(", "tag", "or", "\"\"", ")", "\n", "if", "writer", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "\"num_updates\"", "]", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "\"num_updates\"", "}", ":", "\n", "            ", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ".", "val", ",", "step", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ",", "step", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "stats", "[", "key", "]", ")", "and", "stats", "[", "key", "]", ".", "numel", "(", ")", "==", "1", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ".", "item", "(", ")", ",", "step", ")", "\n", "", "", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper.__init__": [[390, 399], ["wandb.init", "logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ",", "wandb_project", ",", "run_name", "=", "None", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "if", "wandb", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"wandb not found, pip install wandb\"", ")", "\n", "return", "\n", "\n", "# reinit=False to ensure if wandb.init() is called multiple times", "\n", "# within one process it still references the same run", "\n", "", "wandb", ".", "init", "(", "project", "=", "wandb_project", ",", "reinit", "=", "False", ",", "name", "=", "run_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper.__iter__": [[400, 402], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper.log": [[403, 407], ["progress_bar.WandBProgressBarWrapper._log_to_wandb", "progress_bar.WandBProgressBarWrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to tensorboard.\"\"\"", "\n", "self", ".", "_log_to_wandb", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper.print": [[408, 412], ["progress_bar.WandBProgressBarWrapper._log_to_wandb", "progress_bar.WandBProgressBarWrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "_log_to_wandb", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper.update_config": [[413, 418], ["progress_bar.WandBProgressBarWrapper.wrapped_bar.update_config", "wandb.config.update"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.update_config", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "def", "update_config", "(", "self", ",", "config", ")", ":", "\n", "        ", "\"\"\"Log latest configuration.\"\"\"", "\n", "if", "wandb", "is", "not", "None", ":", "\n", "            ", "wandb", ".", "config", ".", "update", "(", "config", ")", "\n", "", "self", ".", "wrapped_bar", ".", "update_config", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb": [[419, 432], ["stats.keys", "isinstance", "wandb.log", "isinstance", "wandb.log"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "_log_to_wandb", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "wandb", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "\"num_updates\"", "]", "\n", "\n", "", "prefix", "=", "\"\"", "if", "tag", "is", "None", "else", "tag", "+", "\"/\"", "\n", "\n", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "\"num_updates\"", "}", ":", "\n", "            ", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "prefix", "+", "key", ":", "stats", "[", "key", "]", ".", "val", "}", ",", "step", "=", "step", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "prefix", "+", "key", ":", "stats", "[", "key", "]", "}", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.__init__": [[443, 449], ["Run.get_context", "logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "if", "Run", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"azureml.core not found, pip install azureml-core\"", ")", "\n", "return", "\n", "", "self", ".", "run", "=", "Run", ".", "get_context", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.__exit__": [[450, 454], ["progress_bar.AzureMLProgressBarWrapper.run.complete"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "if", "Run", "is", "not", "None", ":", "\n", "            ", "self", ".", "run", ".", "complete", "(", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.__iter__": [[455, 457], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log": [[458, 462], ["progress_bar.AzureMLProgressBarWrapper._log_to_azureml", "progress_bar.AzureMLProgressBarWrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper._log_to_azureml", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to AzureML\"\"\"", "\n", "self", ".", "_log_to_azureml", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print": [[463, 467], ["progress_bar.AzureMLProgressBarWrapper._log_to_azureml", "progress_bar.AzureMLProgressBarWrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper._log_to_azureml", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats\"\"\"", "\n", "self", ".", "_log_to_azureml", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.update_config": [[468, 471], ["progress_bar.AzureMLProgressBarWrapper.wrapped_bar.update_config"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.update_config"], ["", "def", "update_config", "(", "self", ",", "config", ")", ":", "\n", "        ", "\"\"\"Log latest configuration.\"\"\"", "\n", "self", ".", "wrapped_bar", ".", "update_config", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper._log_to_azureml": [[472, 486], ["stats.keys", "isinstance", "progress_bar.AzureMLProgressBarWrapper.run.log_row", "isinstance", "progress_bar.AzureMLProgressBarWrapper.run.log_row"], "methods", ["None"], ["", "def", "_log_to_azureml", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "Run", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "'num_updates'", "]", "\n", "\n", "", "prefix", "=", "''", "if", "tag", "is", "None", "else", "tag", "+", "'/'", "\n", "\n", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "'num_updates'", "}", ":", "\n", "            ", "name", "=", "prefix", "+", "key", "\n", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "self", ".", "run", ".", "log_row", "(", "name", "=", "name", ",", "**", "{", "'step'", ":", "step", ",", "key", ":", "stats", "[", "key", "]", ".", "val", "}", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "self", ".", "run", ".", "log_row", "(", "name", "=", "name", ",", "**", "{", "'step'", ":", "step", ",", "key", ":", "stats", "[", "key", "]", "}", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.progress_bar": [[28, 73], ["progress_bar.JsonProgressBar", "progress_bar.WandBProgressBarWrapper", "progress_bar.AzureMLProgressBarWrapper", "sys.stderr.isatty", "progress_bar.NoopProgressBar", "FbTbmfWrapper", "progress_bar.SimpleProgressBar", "progress_bar.TensorboardProgressBarWrapper", "progress_bar.TqdmProgressBar", "ValueError"], "function", ["None"], ["def", "progress_bar", "(", "\n", "iterator", ",", "\n", "log_format", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "log_interval", ":", "int", "=", "100", ",", "\n", "epoch", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "tensorboard_logdir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "default_log_format", ":", "str", "=", "\"tqdm\"", ",", "\n", "wandb_project", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "wandb_run_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "azureml_logging", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "log_format", "is", "None", ":", "\n", "        ", "log_format", "=", "default_log_format", "\n", "", "if", "log_format", "==", "\"tqdm\"", "and", "not", "sys", ".", "stderr", ".", "isatty", "(", ")", ":", "\n", "        ", "log_format", "=", "\"simple\"", "\n", "\n", "", "if", "log_format", "==", "\"json\"", ":", "\n", "        ", "bar", "=", "JsonProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "log_interval", ")", "\n", "", "elif", "log_format", "==", "\"none\"", ":", "\n", "        ", "bar", "=", "NoopProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "elif", "log_format", "==", "\"simple\"", ":", "\n", "        ", "bar", "=", "SimpleProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "log_interval", ")", "\n", "", "elif", "log_format", "==", "\"tqdm\"", ":", "\n", "        ", "bar", "=", "TqdmProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown log format: {}\"", ".", "format", "(", "log_format", ")", ")", "\n", "\n", "", "if", "tensorboard_logdir", ":", "\n", "        ", "try", ":", "\n", "# [FB only] custom wrapper for TensorBoard", "\n", "            ", "import", "palaas", "# noqa", "\n", "from", ".", "fb_tbmf_wrapper", "import", "FbTbmfWrapper", "\n", "\n", "bar", "=", "FbTbmfWrapper", "(", "bar", ",", "log_interval", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "bar", "=", "TensorboardProgressBarWrapper", "(", "bar", ",", "tensorboard_logdir", ")", "\n", "\n", "", "", "if", "wandb_project", ":", "\n", "        ", "bar", "=", "WandBProgressBarWrapper", "(", "bar", ",", "wandb_project", ",", "run_name", "=", "wandb_run_name", ")", "\n", "\n", "", "if", "azureml_logging", ":", "\n", "        ", "bar", "=", "AzureMLProgressBarWrapper", "(", "bar", ")", "\n", "\n", "", "return", "bar", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.build_progress_bar": [[75, 98], ["getattr", "progress_bar.progress_bar", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.progress_bar"], ["", "def", "build_progress_bar", "(", "\n", "args", ",", "\n", "iterator", ",", "\n", "epoch", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "default", ":", "str", "=", "\"tqdm\"", ",", "\n", "no_progress_bar", ":", "str", "=", "\"none\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Legacy wrapper that takes an argparse.Namespace.\"\"\"", "\n", "if", "getattr", "(", "args", ",", "\"no_progress_bar\"", ",", "False", ")", ":", "\n", "        ", "default", "=", "no_progress_bar", "\n", "", "if", "getattr", "(", "args", ",", "\"distributed_rank\"", ",", "0", ")", "==", "0", ":", "\n", "        ", "tensorboard_logdir", "=", "getattr", "(", "args", ",", "\"tensorboard_logdir\"", ",", "None", ")", "\n", "", "else", ":", "\n", "        ", "tensorboard_logdir", "=", "None", "\n", "", "return", "progress_bar", "(", "\n", "iterator", ",", "\n", "log_format", "=", "args", ".", "log_format", ",", "\n", "log_interval", "=", "args", ".", "log_interval", ",", "\n", "epoch", "=", "epoch", ",", "\n", "prefix", "=", "prefix", ",", "\n", "tensorboard_logdir", "=", "tensorboard_logdir", ",", "\n", "default_log_format", "=", "default", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.format_stat": [[101, 113], ["isinstance", "isinstance", "isinstance", "isinstance", "round", "torch.is_tensor", "round", "stat.tolist.tolist"], "function", ["None"], ["", "def", "format_stat", "(", "stat", ")", ":", "\n", "    ", "if", "isinstance", "(", "stat", ",", "Number", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "stat", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "AverageMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:.3f}\"", ".", "format", "(", "stat", ".", "avg", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "TimeMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "round", "(", "stat", ".", "avg", ")", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "StopwatchMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "round", "(", "stat", ".", "sum", ")", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "stat", ")", ":", "\n", "        ", "stat", "=", "stat", ".", "tolist", "(", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.rename_logger": [[166, 173], ["None"], "function", ["None"], ["", "", "@", "contextmanager", "\n", "def", "rename_logger", "(", "logger", ",", "new_name", ")", ":", "\n", "    ", "old_name", "=", "logger", ".", "name", "\n", "if", "new_name", "is", "not", "None", ":", "\n", "        ", "logger", ".", "name", "=", "new_name", "\n", "", "yield", "logger", "\n", "logger", ".", "name", "=", "old_name", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar._close_writers": [[318, 321], ["_tensorboard_writers.values", "w.close"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "", "def", "_close_writers", "(", ")", ":", "\n", "    ", "for", "w", "in", "_tensorboard_writers", ".", "values", "(", ")", ":", "\n", "        ", "w", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.reset": [[30, 40], ["_aggregators.clear", "_active_aggregators.clear", "_active_aggregators_cnt.clear", "meters.MetersDict"], "function", ["None"], ["def", "reset", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset all metrics aggregators.\"\"\"", "\n", "_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "\n", "# The \"default\" aggregator observes all logged values.", "\n", "_aggregators", "[", "\"default\"", "]", "=", "MetersDict", "(", ")", "\n", "_active_aggregators", "[", "\"default\"", "]", "=", "_aggregators", "[", "\"default\"", "]", "\n", "_active_aggregators_cnt", "[", "\"default\"", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate": [[45, 106], ["str", "meters.MetersDict", "_aggregators.setdefault", "_active_aggregators.copy", "_active_aggregators.clear", "_active_aggregators_cnt.copy", "_active_aggregators_cnt.clear", "_active_aggregators.clear", "_active_aggregators.update", "_active_aggregators_cnt.clear", "_active_aggregators_cnt.update", "uuid.uuid4", "meters.MetersDict"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "aggregate", "(", "name", ":", "Optional", "[", "str", "]", "=", "None", ",", "new_root", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Context manager to aggregate metrics under a given name.\n\n    Aggregations can be nested. If *new_root* is ``False``, then logged\n    metrics will be recorded along the entire stack of nested\n    aggregators, including a global \"default\" aggregator. If *new_root*\n    is ``True``, then this aggregator will be the root of a new\n    aggregation stack, thus bypassing any parent aggregators.\n\n    Note that aggregation contexts are uniquely identified by their\n    *name* (e.g., train, valid). Creating a context with an existing\n    name will reuse the corresponding :class:`MetersDict` instance.\n    If no name is given, then a temporary aggregator will be created.\n\n    Usage::\n\n        with metrics.aggregate(\"train\"):\n            for step, batch in enumerate(epoch):\n                with metrics.aggregate(\"train_inner\") as agg:\n                    metrics.log_scalar(\"loss\", get_loss(batch))\n                    if step % log_interval == 0:\n                        print(agg.get_smoothed_value(\"loss\"))\n                        agg.reset()\n        print(metrics.get_smoothed_values(\"train\")[\"loss\"])\n\n    Args:\n        name (str): name of the aggregation. Defaults to a\n            random/temporary name if not given explicitly.\n        new_root (bool): make this aggregation the root of a new\n            aggregation stack.\n    \"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "# generate a temporary name", "\n", "        ", "name", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "assert", "name", "not", "in", "_aggregators", "\n", "agg", "=", "MetersDict", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "name", "!=", "\"default\"", "\n", "agg", "=", "_aggregators", ".", "setdefault", "(", "name", ",", "MetersDict", "(", ")", ")", "\n", "\n", "", "if", "new_root", ":", "\n", "        ", "backup_aggregators", "=", "_active_aggregators", ".", "copy", "(", ")", "\n", "_active_aggregators", ".", "clear", "(", ")", "\n", "backup_aggregators_cnt", "=", "_active_aggregators_cnt", ".", "copy", "(", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "\n", "", "_active_aggregators", "[", "name", "]", "=", "agg", "\n", "_active_aggregators_cnt", "[", "name", "]", "+=", "1", "\n", "\n", "yield", "agg", "\n", "\n", "_active_aggregators_cnt", "[", "name", "]", "-=", "1", "\n", "if", "_active_aggregators_cnt", "[", "name", "]", "==", "0", "and", "name", "in", "_active_aggregators", ":", "\n", "        ", "del", "_active_aggregators", "[", "name", "]", "\n", "\n", "", "if", "new_root", ":", "\n", "        ", "_active_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators", ".", "update", "(", "backup_aggregators", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "_active_aggregators_cnt", ".", "update", "(", "backup_aggregators_cnt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators": [[108, 110], ["list", "_active_aggregators.values"], "function", ["None"], ["", "", "def", "get_active_aggregators", "(", ")", "->", "List", "[", "MetersDict", "]", ":", "\n", "    ", "return", "list", "(", "_active_aggregators", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar": [[112, 133], ["metrics.get_active_aggregators", "agg[].update", "agg.add_meter", "meters.AverageMeter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter"], ["", "def", "log_scalar", "(", "\n", "key", ":", "str", ",", "\n", "value", ":", "float", ",", "\n", "weight", ":", "float", "=", "1", ",", "\n", "priority", ":", "int", "=", "10", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log a scalar value.\n\n    Args:\n        key (str): name of the field to log\n        value (float): value to log\n        weight (float): weight that this value contributes to the average.\n            A weight of 0 will always log the latest value.\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "AverageMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "update", "(", "value", ",", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived": [[135, 147], ["metrics.get_active_aggregators", "agg.add_meter", "meters.MetersDict._DerivedMeter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter"], ["", "", "def", "log_derived", "(", "key", ":", "str", ",", "fn", ":", "Callable", "[", "[", "MetersDict", "]", ",", "float", "]", ",", "priority", ":", "int", "=", "20", ")", ":", "\n", "    ", "\"\"\"Log a scalar value derived from other meters.\n\n    Args:\n        key (str): name of the field to log\n        fn (Callable[[MetersDict], float]): function that takes a single\n            argument *meters* and returns the derived value\n        priority (int): smaller values are logged earlier in the output\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "MetersDict", ".", "_DerivedMeter", "(", "fn", ")", ",", "priority", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_speed": [[149, 169], ["metrics.get_active_aggregators", "agg.add_meter", "agg[].reset", "agg[].update", "meters.TimeMeter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "", "", "def", "log_speed", "(", "\n", "key", ":", "str", ",", "\n", "value", ":", "float", ",", "\n", "priority", ":", "int", "=", "30", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log the rate of some quantity per second.\n\n    Args:\n        key (str): name of the field to log\n        value (float): value to log\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "TimeMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "agg", "[", "key", "]", ".", "reset", "(", ")", "# reset meter on the first call", "\n", "", "else", ":", "\n", "            ", "agg", "[", "key", "]", ".", "update", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_start_time": [[171, 185], ["metrics.get_active_aggregators", "agg[].start", "agg.add_meter", "meters.StopwatchMeter"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter"], ["", "", "", "def", "log_start_time", "(", "key", ":", "str", ",", "priority", ":", "int", "=", "40", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"Log the duration of some event in seconds.\n\n    The duration will be computed once :func:`log_stop_time` is called.\n\n    Args:\n        key (str): name of the field to log\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "StopwatchMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_stop_time": [[187, 203], ["metrics.get_active_aggregators", "agg[].stop"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop"], ["", "", "def", "log_stop_time", "(", "key", ":", "str", ",", "weight", ":", "float", "=", "0.0", ",", "prehook", "=", "None", ")", ":", "\n", "    ", "\"\"\"Log the duration of some event in seconds.\n\n    The duration will be computed since :func:`log_start_time` was called.\n    Set weight > 0 to report the average time instead of the sum.\n\n    Args:\n        key (str): name of the field to log\n        weight (float): weight that this time contributes to the average\n        prehook (function, no arguments): will be called before the timer\n        is stopped. For example, use prehook=torch.cuda.synchronize to\n        make sure all gpu operations are done before timer is stopped.\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "in", "agg", ":", "\n", "            ", "agg", "[", "key", "]", ".", "stop", "(", "weight", ",", "prehook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_custom": [[205, 227], ["metrics.get_active_aggregators", "agg[].update", "agg.add_meter", "new_meter_fn"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter"], ["", "", "", "def", "log_custom", "(", "\n", "new_meter_fn", ":", "Callable", "[", "[", "]", ",", "Meter", "]", ",", "\n", "key", ":", "str", ",", "\n", "*", "args", ",", "\n", "priority", ":", "int", "=", "50", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log using a custom Meter.\n\n    Any extra *args* or *kwargs* will be passed through to the Meter's\n    *update* method.\n\n    Args:\n        new_meter_fn (Callable[[], Meter]): function that returns a new\n            Meter instance\n        key (str): name of the field to log\n        priority (int): smaller values are logged earlier in the output\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "new_meter_fn", "(", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "update", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.reset_meter": [[229, 234], ["metrics.get_meter", "get_meter.reset"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["", "", "def", "reset_meter", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset Meter instance aggregated under a given *name* and *key*.\"\"\"", "\n", "meter", "=", "get_meter", "(", "name", ",", "key", ")", "\n", "if", "meter", "is", "not", "None", ":", "\n", "        ", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.reset_meters": [[236, 241], ["metrics.get_meters", "get_meters.reset"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["", "", "def", "reset_meters", "(", "name", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset Meter instances aggregated under a given *name*.\"\"\"", "\n", "meters", "=", "get_meters", "(", "name", ")", "\n", "if", "meters", "is", "not", "None", ":", "\n", "        ", "meters", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meter": [[243, 252], ["_aggregators[].get"], "function", ["None"], ["", "", "def", "get_meter", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "Meter", ":", "\n", "    ", "\"\"\"Get a single Meter instance aggregated under *name* and *key*.\n\n    Returns:\n        Meter or None if no metrics have been logged under *name* and *key*.\n    \"\"\"", "\n", "if", "name", "not", "in", "_aggregators", ":", "\n", "        ", "return", "None", "\n", "", "return", "_aggregators", "[", "name", "]", ".", "get", "(", "key", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_meters": [[254, 261], ["_aggregators.get"], "function", ["None"], ["", "def", "get_meters", "(", "name", ":", "str", ")", "->", "MetersDict", ":", "\n", "    ", "\"\"\"Get Meter instances aggregated under a given *name*.\n\n    Returns:\n        MetersDict or None if no metrics have been logged under *name*.\n    \"\"\"", "\n", "return", "_aggregators", ".", "get", "(", "name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_smoothed_value": [[263, 270], ["_aggregators[].get_smoothed_value"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_value"], ["", "def", "get_smoothed_value", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "float", ":", "\n", "    ", "\"\"\"Get a single smoothed value.\n\n    Raises:\n        KeyError: if no metrics have been logged under *name* and *key*.\n    \"\"\"", "\n", "return", "_aggregators", "[", "name", "]", ".", "get_smoothed_value", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.get_smoothed_values": [[272, 279], ["_aggregators[].get_smoothed_values"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values"], ["", "def", "get_smoothed_values", "(", "name", ":", "str", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"Get smoothed values aggregated under a given *name*.\n\n    Raises:\n        KeyError: if no metrics have been logged under *name*.\n    \"\"\"", "\n", "return", "_aggregators", "[", "name", "]", ".", "get_smoothed_values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.state_dict": [[281, 283], ["collections.OrderedDict", "agg.state_dict", "_aggregators.items"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", ")", ":", "\n", "    ", "return", "OrderedDict", "(", "[", "(", "name", ",", "agg", ".", "state_dict", "(", ")", ")", "for", "name", ",", "agg", "in", "_aggregators", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.load_state_dict": [[285, 289], ["state_dict.items", "meters.MetersDict", "_aggregators[].load_state_dict"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "state_dict", ")", ":", "\n", "    ", "for", "name", ",", "agg_state", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "_aggregators", "[", "name", "]", "=", "MetersDict", "(", ")", "\n", "_aggregators", "[", "name", "]", ".", "load_state_dict", "(", "agg_state", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.Meter.__init__": [[38, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.Meter.state_dict": [[41, 43], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.Meter.load_state_dict": [[44, 46], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.Meter.reset": [[47, 49], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.Meter.smoothed_value": [[50, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"Smoothed value used for logging.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.__init__": [[70, 73], ["meters.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["def", "__init__", "(", "self", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.reset": [[74, 78], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "None", "# most recent update", "\n", "self", ".", "sum", "=", "0", "# sum from all updates", "\n", "self", ".", "count", "=", "0", "# total n from all updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.update": [[79, 85], ["type_as", "type_as"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "if", "val", "is", "not", "None", ":", "\n", "            ", "self", ".", "val", "=", "val", "\n", "if", "n", ">", "0", ":", "\n", "                ", "self", ".", "sum", "=", "type_as", "(", "self", ".", "sum", ",", "val", ")", "+", "(", "val", "*", "n", ")", "\n", "self", ".", "count", "=", "type_as", "(", "self", ".", "count", ",", "n", ")", "+", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.state_dict": [[86, 92], ["None"], "methods", ["None"], ["", "", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"val\"", ":", "self", ".", "val", ",", "\n", "\"sum\"", ":", "self", ".", "sum", ",", "\n", "\"count\"", ":", "self", ".", "count", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.load_state_dict": [[94, 99], ["state_dict.get"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "val", "=", "state_dict", "[", "\"val\"", "]", "\n", "self", ".", "sum", "=", "state_dict", "[", "\"sum\"", "]", "\n", "self", ".", "count", "=", "state_dict", "[", "\"count\"", "]", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.avg": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sum", "/", "self", ".", "count", "if", "self", ".", "count", ">", "0", "else", "self", ".", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.AverageMeter.smoothed_value": [[104, 110], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.__init__": [[115, 123], ["meters.TimeMeter.reset"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["def", "__init__", "(", "\n", "self", ",", "\n", "init", ":", "int", "=", "0", ",", "\n", "n", ":", "int", "=", "0", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "reset", "(", "init", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.reset": [[124, 129], ["time.perf_counter"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "init", "=", "0", ",", "n", "=", "0", ")", ":", "\n", "        ", "self", ".", "init", "=", "init", "\n", "self", ".", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.update": [[130, 133], ["type_as"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", "=", "1", ")", ":", "\n", "        ", "self", ".", "n", "=", "type_as", "(", "self", ".", "n", ",", "val", ")", "+", "val", "\n", "self", ".", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.state_dict": [[134, 139], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"init\"", ":", "self", ".", "elapsed_time", ",", "\n", "\"n\"", ":", "self", ".", "n", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.load_state_dict": [[141, 148], ["meters.TimeMeter.reset", "meters.TimeMeter.reset", "state_dict.get"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "\"start\"", "in", "state_dict", ":", "\n", "# backwards compatibility for old state_dicts", "\n", "            ", "self", ".", "reset", "(", "init", "=", "state_dict", "[", "\"init\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reset", "(", "init", "=", "state_dict", "[", "\"init\"", "]", ",", "n", "=", "state_dict", "[", "\"n\"", "]", ")", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.avg": [[149, 152], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n", "/", "self", ".", "elapsed_time", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.elapsed_time": [[153, 156], ["time.perf_counter"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "init", "+", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.TimeMeter.smoothed_value": [[157, 163], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.__init__": [[168, 173], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "n", "=", "0", "\n", "self", ".", "start_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start": [[174, 176], ["time.perf_counter"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.stop": [[177, 184], ["prehook", "time.perf_counter", "type_as"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "n", "=", "1", ",", "prehook", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "start_time", "is", "not", "None", ":", "\n", "            ", "if", "prehook", "is", "not", "None", ":", "\n", "                ", "prehook", "(", ")", "\n", "", "delta", "=", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "sum", "=", "self", ".", "sum", "+", "delta", "\n", "self", ".", "n", "=", "type_as", "(", "self", ".", "n", ",", "n", ")", "+", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.reset": [[185, 189], ["meters.StopwatchMeter.start"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "sum", "=", "0", "# cumulative time during which stopwatch was active", "\n", "self", ".", "n", "=", "0", "# total n across all start/stop", "\n", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.state_dict": [[190, 195], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"sum\"", ":", "self", ".", "sum", ",", "\n", "\"n\"", ":", "self", ".", "n", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.load_state_dict": [[197, 202], ["state_dict.get"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "sum", "=", "state_dict", "[", "\"sum\"", "]", "\n", "self", ".", "n", "=", "state_dict", "[", "\"n\"", "]", "\n", "self", ".", "start_time", "=", "None", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.avg": [[203, 206], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sum", "/", "self", ".", "n", "if", "self", ".", "n", ">", "0", "else", "self", ".", "sum", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.elapsed_time": [[207, 212], ["time.perf_counter"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "start_time", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.smoothed_value": [[213, 219], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "if", "self", ".", "sum", ">", "0", "else", "self", ".", "elapsed_time", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.__init__": [[228, 231], ["collections.OrderedDict.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "priorities", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.__setitem__": [[232, 239], ["bisect.insort", "super().__setitem__", "meters.MetersDict.move_to_end", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.__setitem__"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "assert", "key", "not", "in", "self", ",", "\"MetersDict doesn't support reassignment\"", "\n", "priority", ",", "value", "=", "value", "\n", "bisect", ".", "insort", "(", "self", ".", "priorities", ",", "(", "priority", ",", "len", "(", "self", ".", "priorities", ")", ",", "key", ")", ")", "\n", "super", "(", ")", ".", "__setitem__", "(", "key", ",", "value", ")", "\n", "for", "_", ",", "_", ",", "key", "in", "self", ".", "priorities", ":", "# reorder dict to match priorities", "\n", "            ", "self", ".", "move_to_end", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter": [[240, 242], ["meters.MetersDict.__setitem__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.__setitem__"], ["", "", "def", "add_meter", "(", "self", ",", "key", ",", "meter", ",", "priority", ")", ":", "\n", "        ", "self", ".", "__setitem__", "(", "key", ",", "(", "priority", ",", "meter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.state_dict": [[243, 249], ["meters.MetersDict.state_dict", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "(", "pri", ",", "key", ",", "self", "[", "key", "]", ".", "__class__", ".", "__name__", ",", "self", "[", "key", "]", ".", "state_dict", "(", ")", ")", "\n", "for", "pri", ",", "_", ",", "key", "in", "self", ".", "priorities", "\n", "# can't serialize DerivedMeter instances", "\n", "if", "not", "isinstance", "(", "self", "[", "key", "]", ",", "MetersDict", ".", "_DerivedMeter", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.load_state_dict": [[251, 258], ["meters.MetersDict.clear", "meters.MetersDict.priorities.clear", "meter.load_state_dict", "meters.MetersDict.add_meter", "globals"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.add_meter"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "clear", "(", ")", "\n", "self", ".", "priorities", ".", "clear", "(", ")", "\n", "for", "pri", ",", "key", ",", "meter_cls", ",", "meter_state", "in", "state_dict", ":", "\n", "            ", "meter", "=", "globals", "(", ")", "[", "meter_cls", "]", "(", ")", "\n", "meter", ".", "load_state_dict", "(", "meter_state", ")", "\n", "self", ".", "add_meter", "(", "key", ",", "meter", ",", "pri", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_value": [[259, 266], ["isinstance", "meter.fn"], "methods", ["None"], ["", "", "def", "get_smoothed_value", "(", "self", ",", "key", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"Get a single smoothed value.\"\"\"", "\n", "meter", "=", "self", "[", "key", "]", "\n", "if", "isinstance", "(", "meter", ",", "MetersDict", ".", "_DerivedMeter", ")", ":", "\n", "            ", "return", "meter", ".", "fn", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "meter", ".", "smoothed_value", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values": [[267, 274], ["collections.OrderedDict", "meters.MetersDict.get_smoothed_value", "meters.MetersDict.keys", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_value"], ["", "", "def", "get_smoothed_values", "(", "self", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"Get all smoothed values.\"\"\"", "\n", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "self", ".", "get_smoothed_value", "(", "key", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", "(", ")", "\n", "if", "not", "key", ".", "startswith", "(", "\"_\"", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset": [[277, 283], ["meters.MetersDict.values", "isinstance", "meter.reset"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset Meter instances.\"\"\"", "\n", "for", "meter", "in", "self", ".", "values", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "meter", ",", "MetersDict", ".", "_DerivedMeter", ")", ":", "\n", "                ", "continue", "\n", "", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round": [[56, 65], ["hasattr", "round", "torch.is_tensor", "meters.safe_round", "number.numel", "number.item", "hasattr", "meters.safe_round", "np.ndim", "number.item"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "", "def", "safe_round", "(", "number", ",", "ndigits", ")", ":", "\n", "    ", "if", "hasattr", "(", "number", ",", "\"__round__\"", ")", ":", "\n", "        ", "return", "round", "(", "number", ",", "ndigits", ")", "\n", "", "elif", "torch", "is", "not", "None", "and", "torch", ".", "is_tensor", "(", "number", ")", "and", "number", ".", "numel", "(", ")", "==", "1", ":", "\n", "        ", "return", "safe_round", "(", "number", ".", "item", "(", ")", ",", "ndigits", ")", "\n", "", "elif", "np", "is", "not", "None", "and", "np", ".", "ndim", "(", "number", ")", "==", "0", "and", "hasattr", "(", "number", ",", "\"item\"", ")", ":", "\n", "        ", "return", "safe_round", "(", "number", ".", "item", "(", ")", ",", "ndigits", ")", "\n", "", "else", ":", "\n", "        ", "return", "number", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.positional_embedding.PositionalEmbedding": [[12, 36], ["learned_positional_embedding.LearnedPositionalEmbedding", "torch.init.normal_", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding", "torch.init.constant_"], "function", ["None"], ["def", "PositionalEmbedding", "(", "\n", "num_embeddings", ":", "int", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", "learned", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "learned", ":", "\n", "# if padding_idx is specified then offset the embedding ids by", "\n", "# this index and adjust num_embeddings appropriately", "\n", "# TODO: The right place for this offset would be inside", "\n", "# LearnedPositionalEmbedding. Move this there for a cleaner implementation.", "\n", "        ", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "num_embeddings", "=", "num_embeddings", "+", "padding_idx", "+", "1", "\n", "", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "", "else", ":", "\n", "        ", "m", "=", "SinusoidalPositionalEmbedding", "(", "\n", "embedding_dim", ",", "\n", "padding_idx", ",", "\n", "init_size", "=", "num_embeddings", "+", "padding_idx", "+", "1", ",", "\n", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.__init__": [[22, 84], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.utils.get_activation_fn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_self_attention", "fairseq.modules.LayerNorm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc1", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc2", "fairseq.modules.LayerNorm", "init_fn"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "q_noise", ":", "float", "=", "0.0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", "init_fn", ":", "Callable", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "init_fn", "is", "not", "None", ":", "\n", "            ", "init_fn", "(", ")", "\n", "\n", "# Initialize parameters", "\n", "", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "q_noise", "=", "q_noise", "\n", "self", ".", "qn_block_size", "=", "qn_block_size", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "activation_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "# Initialize blocks", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the self attention layer", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "ffn_embedding_dim", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the position wise feed-forward NN", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc1": [[85, 87], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc2": [[88, 90], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_self_attention": [[91, 107], ["fairseq.modules.MultiheadAttention"], "methods", ["None"], ["", "def", "build_self_attention", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "self_attention", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.forward": [[109, 140], ["transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.self_attn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.self_attn_layer_norm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.activation_fn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.activation_dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.fc2", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.final_layer_norm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "self_attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        LayerNorm is applied either before or after the self-attention/ffn\n        modules similar to the original Transformer implementation.\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "return", "x", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_drop.LayerDropModuleList.__init__": [[36, 39], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "p", ",", "modules", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "modules", ")", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_drop.LayerDropModuleList.__iter__": [[40, 45], ["torch.empty().uniform_", "torch.empty().uniform_", "torch.empty().uniform_", "torch.empty().uniform_", "enumerate", "torch.ModuleList.__iter__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dropout_probs", "=", "torch", ".", "empty", "(", "len", "(", "self", ")", ")", ".", "uniform_", "(", ")", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "super", "(", ")", ".", "__iter__", "(", ")", ")", ":", "\n", "            ", "if", "not", "self", ".", "training", "or", "(", "dropout_probs", "[", "i", "]", ">", "self", ".", "p", ")", ":", "\n", "                ", "yield", "m", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_input.AdaptiveInput.__init__": [[15, 65], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "range", "adaptive_input.AdaptiveInput.apply", "adaptive_input.AdaptiveInput.register_buffer", "len", "int", "torch.nn.Sequential", "adaptive_input.AdaptiveInput.embeddings.append", "isinstance", "torch.FloatTensor", "torch.nn.Embedding", "fairseq.modules.quant_noise.quant_noise", "torch.nn.init.normal_", "torch.nn.init.constant_", "hasattr", "torch.nn.Linear", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", "initial_dim", ":", "int", ",", "\n", "factor", ":", "float", ",", "\n", "output_dim", ":", "int", ",", "\n", "cutoff", ":", "List", "[", "int", "]", ",", "\n", "q_noise", ":", "float", "=", "0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", "=", "cutoff", "+", "[", "vocab_size", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "vocab_size", "==", "cutoff", "[", "-", "1", "]", "\n", ")", ",", "\"cannot specify cutoff larger than vocab size\"", "\n", "\n", "", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "embedding_dim", "=", "output_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "self", ".", "embeddings", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "prev", "=", "self", ".", "cutoff", "[", "i", "-", "1", "]", "if", "i", ">", "0", "else", "0", "\n", "size", "=", "self", ".", "cutoff", "[", "i", "]", "-", "prev", "\n", "dim", "=", "int", "(", "initial_dim", "//", "(", "factor", "**", "i", ")", ")", "\n", "seq", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Embedding", "(", "size", ",", "dim", ",", "self", ".", "padding_idx", ")", ",", "\n", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "dim", ",", "output_dim", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", ",", "\n", ")", "\n", "\n", "self", ".", "embeddings", ".", "append", "(", "seq", ")", "\n", "self", ".", "padding_idx", "=", "None", "\n", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Embedding", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "m", ".", "weight", ".", "shape", "[", "1", "]", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "elif", "hasattr", "(", "m", ",", "\"weight\"", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_input.AdaptiveInput.weights_for_band": [[66, 68], ["None"], "methods", ["None"], ["", "def", "weights_for_band", "(", "self", ",", "band", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "[", "band", "]", "[", "0", "]", ".", "weight", ",", "self", ".", "embeddings", "[", "band", "]", "[", "1", "]", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_input.AdaptiveInput.forward": [[69, 81], ["adaptive_input.AdaptiveInput._float_tensor.new", "range", "len", "input.lt", "input.lt.any", "input.lt.mul_", "input.ge"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "result", "=", "self", ".", "_float_tensor", ".", "new", "(", "input", ".", "shape", "+", "(", "self", ".", "embedding_dim", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "mask", "=", "input", ".", "lt", "(", "self", ".", "cutoff", "[", "i", "]", ")", "\n", "if", "i", ">", "0", ":", "\n", "                ", "mask", ".", "mul_", "(", "input", ".", "ge", "(", "self", ".", "cutoff", "[", "i", "-", "1", "]", ")", ")", "\n", "chunk_input", "=", "input", "[", "mask", "]", "-", "self", ".", "cutoff", "[", "i", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "chunk_input", "=", "input", "[", "mask", "]", "\n", "", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "result", "[", "mask", "]", "=", "self", ".", "embeddings", "[", "i", "]", "(", "chunk_input", ")", "\n", "", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.grad_multiply.GradMultiply.forward": [[10, 15], ["x.new"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "scale", ")", ":", "\n", "        ", "ctx", ".", "scale", "=", "scale", "\n", "res", "=", "x", ".", "new", "(", "x", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.grad_multiply.GradMultiply.backward": [[16, 19], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "grad", "*", "ctx", ".", "scale", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.learned_positional_embedding.LearnedPositionalEmbedding.__init__": [[23, 30], ["torch.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "max_positions", "=", "self", ".", "num_embeddings", "-", "self", ".", "padding_idx", "-", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "max_positions", "=", "self", ".", "num_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.learned_positional_embedding.LearnedPositionalEmbedding.forward": [[31, 61], ["torch.embedding", "torch.embedding", "torch.embedding", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "fairseq.utils.make_positions", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "input.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input", ":", "Tensor", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "positions", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "assert", "(", "positions", "is", "None", ")", "or", "(", "\n", "self", ".", "padding_idx", "is", "None", "\n", ")", ",", "\"If positions is pre-computed then padding_idx should not be set.\"", "\n", "\n", "if", "positions", "is", "None", ":", "\n", "            ", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "# Without the int() cast, it doesn't work in some cases when exporting to ONNX", "\n", "                ", "positions", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "1", ")", ",", "device", "=", "input", ".", "device", ",", "dtype", "=", "input", ".", "dtype", "\n", ")", ".", "fill_", "(", "int", "(", "self", ".", "padding_idx", "+", "input", ".", "size", "(", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "positions", "=", "utils", ".", "make_positions", "(", "\n", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "", "", "return", "F", ".", "embedding", "(", "\n", "positions", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "padding_idx", ",", "\n", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "\n", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.__init__": [[26, 90], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "multihead_attention.MultiheadAttention.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "\n", "q_noise", "=", "0.0", ",", "\n", "qn_block_size", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "assert", "not", "self", ".", "self_attention", "or", "self", ".", "qkv_same_dim", ",", "(", "\n", "\"Self-attention requires query, key and \"", "\"value to be of the same size\"", "\n", ")", "\n", "\n", "self", ".", "k_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "v_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "q_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "self", ".", "out_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.prepare_for_onnx_export_": [[91, 93], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.reset_parameters": [[94, 113], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "# Empirically observed the convergence to be much better with", "\n", "# the scaled initialization", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ")", "\n", "\n", "", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "out_proj", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.0", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.forward": [[114, 378], ["query.size", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "torch.cat.size", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.apply_sparse_mask", "fairseq.utils.softmax", "fairseq.utils.softmax.type_as", "multihead_attention.MultiheadAttention.dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.out_proj", "list", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "multihead_attention.MultiheadAttention._append_prev_key_padding_mask", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "multihead_attention.MultiheadAttention._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose", "torch.cat.transpose", "list", "attn_mask.repeat.repeat.unsqueeze", "attn_weights.mean.mean.view", "attn_weights.mean.mean.view", "list", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "fairseq.utils.softmax.view().transpose", "query.size", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.contiguous().view", "_prev_key.view", "_prev_value.view", "torch.cat.dim", "torch.cat.dim", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_weights.mean.mean.size", "attn_mask.repeat.repeat.repeat", "attn_weights.mean.mean.masked_fill", "attn_weights.mean.mean.transpose", "attn_weights.mean.mean.masked_fill", "attn_weights.mean.mean.transpose", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn_weights.mean.mean.mean", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "multihead_attention.MultiheadAttention.bias_k.repeat", "multihead_attention.MultiheadAttention.bias_v.repeat", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "attn_weights.mean.mean.size", "torch.cat.unsqueeze().unsqueeze().to", "torch.cat.unsqueeze().unsqueeze().to", "float", "float", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "fairseq.utils.softmax.view", "attn_mask.repeat.repeat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "multihead_attention.MultiheadAttention.contiguous", "attn_mask.repeat.repeat.new_zeros", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "attn_mask.repeat.repeat.size", "torch.cat.size", "torch.cat.size", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "attn_mask.repeat.repeat.size", "torch.cat.unsqueeze().unsqueeze", "torch.cat.unsqueeze().unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.apply_sparse_mask", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "value", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "True", ",", "\n", "static_kv", ":", "bool", "=", "False", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "before_softmax", ":", "bool", "=", "False", ",", "\n", "need_head_weights", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n\n        Args:\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n            before_softmax (bool, optional): return the raw attention\n                weights and values before the attention softmax.\n            need_head_weights (bool, optional): return the attention\n                weights for each head. Implies *need_weights*. Default:\n                return the average attention weights over all heads.\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_weights", "=", "True", "\n", "\n", "", "is_tpu", "=", "query", ".", "device", ".", "type", "==", "\"xla\"", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "\n", "if", "(", "\n", "not", "self", ".", "onnx_trace", "\n", "and", "not", "is_tpu", "# don't use PyTorch version on TPUs", "\n", "and", "incremental_state", "is", "None", "\n", "and", "not", "static_kv", "\n", "# A workaround for quantization to work. Otherwise JIT compilation", "\n", "# treats bias in linear module as method.", "\n", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "\n", ")", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "return", "F", ".", "multi_head_attention_forward", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "num_heads", ",", "\n", "torch", ".", "empty", "(", "[", "0", "]", ")", ",", "\n", "torch", ".", "cat", "(", "(", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", ")", ")", ",", "\n", "self", ".", "bias_k", ",", "\n", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "\n", "self", ".", "dropout_module", ".", "p", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "\n", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", "or", "self", ".", "dropout_module", ".", "apply_during_inference", ",", "\n", "key_padding_mask", ",", "\n", "need_weights", ",", "\n", "attn_mask", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "saved_state", "is", "not", "None", "and", "\"prev_key\"", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "and", "not", "self", ".", "self_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attention", ":", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "", "elif", "self", ".", "encoder_decoder_attention", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "key_padding_mask", ".", "new_zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "q", "=", "(", "\n", "q", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "(", "\n", "k", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "(", "\n", "v", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "            ", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "                ", "_prev_key", "=", "saved_state", "[", "\"prev_key\"", "]", "\n", "assert", "_prev_key", "is", "not", "None", "\n", "prev_key", "=", "_prev_key", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                    ", "assert", "k", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "k", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "\"prev_value\"", "in", "saved_state", ":", "\n", "                ", "_prev_value", "=", "saved_state", "[", "\"prev_value\"", "]", "\n", "assert", "_prev_value", "is", "not", "None", "\n", "prev_value", "=", "_prev_value", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                    ", "assert", "v", "is", "not", "None", "\n", "v", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "v", "]", ",", "dim", "=", "1", ")", "\n", "", "", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "\"prev_key_padding_mask\"", "in", "saved_state", ":", "\n", "                ", "prev_key_padding_mask", "=", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "\n", "", "assert", "k", "is", "not", "None", "and", "v", "is", "not", "None", "\n", "key_padding_mask", "=", "MultiheadAttention", ".", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "\n", "prev_key_padding_mask", "=", "prev_key_padding_mask", ",", "\n", "batch_size", "=", "bsz", ",", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", ",", "\n", "static_kv", "=", "static_kv", ",", "\n", ")", "\n", "\n", "saved_state", "[", "\"prev_key\"", "]", "=", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_value\"", "]", "=", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "key_padding_mask", "\n", "# In this branch incremental_state is never None", "\n", "assert", "incremental_state", "is", "not", "None", "\n", "incremental_state", "=", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "assert", "k", "is", "not", "None", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism", "\n", "# not supporting Optional types.", "\n", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "add_zero_attn", ":", "\n", "            ", "assert", "v", "is", "not", "None", "\n", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "torch", ".", "zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "type_as", "(", "\n", "key_padding_mask", "\n", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn_weights", "=", "self", ".", "apply_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", "\n", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "attn_weights", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "", "attn_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "not", "is_tpu", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "to", "(", "torch", ".", "bool", ")", ",", "\n", "float", "(", "\"-inf\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "key_padding_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "before_softmax", ":", "\n", "            ", "return", "attn_weights", ",", "v", "\n", "\n", "", "attn_weights_float", "=", "utils", ".", "softmax", "(", "\n", "attn_weights", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "self", ".", "dropout_module", "(", "attn_weights", ")", "\n", "\n", "assert", "v", "is", "not", "None", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "if", "self", ".", "onnx_trace", "and", "attn", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "# when ONNX tracing a single decoder step (sequence length == 1)", "\n", "# the transpose is a no-op copy before view, thus unnecessary", "\n", "            ", "attn", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "attn_weights", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "need_weights", ":", "\n", "            ", "attn_weights", "=", "attn_weights_float", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "if", "not", "need_head_weights", ":", "\n", "# average attention weights over heads", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention._append_prev_key_padding_mask": [[379, 416], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "key_padding_mask.float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "torch.zeros.float", "torch.zeros.float", "prev_key_padding_mask.size", "torch.zeros.float", "torch.zeros.float", "key_padding_mask.float", "key_padding_mask.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "staticmethod", "\n", "def", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "src_len", ":", "int", ",", "\n", "static_kv", ":", "bool", ",", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "# saved key padding masks have shape (bsz, seq_len)", "\n", "        ", "if", "prev_key_padding_mask", "is", "not", "None", "and", "static_kv", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", "and", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "# During incremental decoding, as the padding token enters and", "\n", "# leaves the frame, there will be a time when prev or current", "\n", "# is None", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "\n", "(", "batch_size", ",", "src_len", "-", "prev_key_padding_mask", ".", "size", "(", "1", ")", ")", ",", "\n", "device", "=", "prev_key_padding_mask", ".", "device", ",", "\n", ")", "\n", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "filler", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "elif", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "\n", "(", "batch_size", ",", "src_len", "-", "key_padding_mask", ".", "size", "(", "1", ")", ")", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ",", "\n", ")", "\n", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "filler", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "return", "new_key_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.reorder_incremental_state": [[417, 436], ["multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.keys", "multihead_attention.MultiheadAttention._set_input_buffer", "input_buffer_k.index_select", "input_buffer_k.size", "new_order.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Reorder buffered internal state (for incremental generation).\"\"\"", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "input_buffer", ".", "keys", "(", ")", ":", "\n", "                ", "input_buffer_k", "=", "input_buffer", "[", "k", "]", "\n", "if", "input_buffer_k", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "encoder_decoder_attention", "and", "input_buffer_k", ".", "size", "(", "\n", "0", "\n", ")", "==", "new_order", ".", "size", "(", "0", ")", ":", "\n", "                        ", "break", "\n", "", "input_buffer", "[", "k", "]", "=", "input_buffer_k", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "", "incremental_state", "=", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention._get_input_buffer": [[437, 446], ["multihead_attention.MultiheadAttention.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "def", "_get_input_buffer", "(", "\n", "self", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "result", "=", "self", ".", "get_incremental_state", "(", "incremental_state", ",", "\"attn_state\"", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "return", "result", "\n", "", "else", ":", "\n", "            ", "empty_result", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "return", "empty_result", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention._set_input_buffer": [[447, 453], ["multihead_attention.MultiheadAttention.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "", "def", "_set_input_buffer", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "buffer", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", ":", "\n", "        ", "return", "self", ".", "set_incremental_state", "(", "incremental_state", ",", "\"attn_state\"", ",", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.apply_sparse_mask": [[454, 456], ["None"], "methods", ["None"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ":", "int", ",", "src_len", ":", "int", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "return", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.multihead_attention.MultiheadAttention.upgrade_state_dict_named": [[457, 487], ["state_dict.keys", "items_to_add.items", "k.endswith", "int", "keys_to_remove.append", "state_dict.keys", "int", "keys_to_remove.append"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "items_to_add", "=", "{", "}", "\n", "keys_to_remove", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "prefix", "+", "\"in_proj_weight\"", ")", ":", "\n", "# in_proj_weight used to be q + k + v with same dimensions", "\n", "                ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "\"q_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"k_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", "dim", ":", "2", "*", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"v_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "k", ")", "\n", "\n", "k_bias", "=", "prefix", "+", "\"in_proj_bias\"", "\n", "if", "k_bias", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "\"q_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"k_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", "\n", "dim", ":", "2", "*", "dim", "\n", "]", "\n", "items_to_add", "[", "prefix", "+", "\"v_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "prefix", "+", "\"in_proj_bias\"", ")", "\n", "\n", "", "", "", "for", "k", "in", "keys_to_remove", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "for", "key", ",", "value", "in", "items_to_add", ".", "items", "(", ")", ":", "\n", "            ", "state_dict", "[", "key", "]", "=", "value", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.fp32_group_norm.Fp32GroupNorm.__init__": [[14, 16], ["torch.GroupNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.fp32_group_norm.Fp32GroupNorm.forward": [[17, 26], ["torch.group_norm", "torch.group_norm", "torch.group_norm.type_as", "input.float", "fp32_group_norm.Fp32GroupNorm.weight.float", "fp32_group_norm.Fp32GroupNorm.bias.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "F", ".", "group_norm", "(", "\n", "input", ".", "float", "(", ")", ",", "\n", "self", ".", "num_groups", ",", "\n", "self", ".", "weight", ".", "float", "(", ")", "if", "self", ".", "weight", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "bias", ".", "float", "(", ")", "if", "self", ".", "bias", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "eps", ",", "\n", ")", "\n", "return", "output", ".", "type_as", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF.__init__": [[42, 51], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["def", "__init__", "(", "self", ",", "num_embedding", ",", "low_rank", "=", "32", ",", "beam_size", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "E1", "=", "nn", ".", "Embedding", "(", "num_embedding", ",", "low_rank", ")", "\n", "self", ".", "E2", "=", "nn", ".", "Embedding", "(", "num_embedding", ",", "low_rank", ")", "\n", "\n", "self", ".", "vocb", "=", "num_embedding", "\n", "self", ".", "rank", "=", "low_rank", "\n", "self", ".", "beam", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF.extra_repr": [[52, 55], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"vocab_size={}, low_rank={}, beam_size={}\"", ".", "format", "(", "\n", "self", ".", "vocb", ",", "self", ".", "rank", ",", "self", ".", "beam", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF.forward": [[57, 74], ["dynamic_crf_layer.DynamicCRF._compute_score", "dynamic_crf_layer.DynamicCRF._compute_normalizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._compute_score", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._compute_normalizer"], ["", "def", "forward", "(", "self", ",", "emissions", ",", "targets", ",", "masks", ",", "beam", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the conditional log-likelihood of a sequence of target tokens given emission scores\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score are usually the unnormalized decoder output\n                ``(batch_size, seq_len, vocab_size)``. We assume batch-first\n            targets (`~torch.LongTensor`): Sequence of target token indices\n                ``(batch_size, seq_len)\n            masks (`~torch.ByteTensor`): Mask tensor with the same size as targets\n\n        Returns:\n            `~torch.Tensor`: approximated log-likelihood\n        \"\"\"", "\n", "numerator", "=", "self", ".", "_compute_score", "(", "emissions", ",", "targets", ",", "masks", ")", "\n", "denominator", "=", "self", ".", "_compute_normalizer", "(", "emissions", ",", "targets", ",", "masks", ",", "beam", ")", "\n", "return", "numerator", "-", "denominator", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF.forward_decoder": [[75, 88], ["dynamic_crf_layer.DynamicCRF._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._viterbi_decode"], ["", "def", "forward_decoder", "(", "self", ",", "emissions", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Find the most likely output sequence using Viterbi algorithm.\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score are usually the unnormalized decoder output\n                ``(batch_size, seq_len, vocab_size)``. We assume batch-first\n            masks (`~torch.ByteTensor`): Mask tensor with the same size as targets\n\n        Returns:\n            `~torch.LongTensor`: decoded sequence from the CRF model\n        \"\"\"", "\n", "return", "self", ".", "_viterbi_decode", "(", "emissions", ",", "masks", ",", "beam", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._compute_score": [[89, 100], ["targets.size", "scores.sum", "emissions.gather", "masks.type_as", "dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_compute_score", "(", "self", ",", "emissions", ",", "targets", ",", "masks", "=", "None", ")", ":", "\n", "        ", "batch_size", ",", "seq_len", "=", "targets", ".", "size", "(", ")", "\n", "emission_scores", "=", "emissions", ".", "gather", "(", "2", ",", "targets", "[", ":", ",", ":", ",", "None", "]", ")", "[", ":", ",", ":", ",", "0", "]", "# B x T", "\n", "transition_scores", "=", "(", "self", ".", "E1", "(", "targets", "[", ":", ",", ":", "-", "1", "]", ")", "*", "self", ".", "E2", "(", "targets", "[", ":", ",", "1", ":", "]", ")", ")", ".", "sum", "(", "2", ")", "\n", "\n", "scores", "=", "emission_scores", "\n", "scores", "[", ":", ",", "1", ":", "]", "+=", "transition_scores", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "            ", "scores", "=", "scores", "*", "masks", ".", "type_as", "(", "scores", ")", "\n", "", "return", "scores", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._compute_normalizer": [[101, 134], ["dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "beam_transition_matrix.view.view.view", "range", "dynamic_crf_layer.logsumexp", "emissions.size", "emissions.scatter", "emissions.gather", "emissions.topk", "dynamic_crf_layer.DynamicCRF.view", "dynamic_crf_layer.DynamicCRF.view().transpose", "numpy.float", "emissions.scatter.topk", "dynamic_crf_layer.logsumexp", "torch.where", "torch.where", "torch.where", "torch.where", "dynamic_crf_layer.DynamicCRF.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp"], ["", "def", "_compute_normalizer", "(", "self", ",", "emissions", ",", "targets", "=", "None", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "# HACK: we include \"target\" which is a hueristic for training", "\n", "# HACK: we use a beam of tokens to approximate the normalizing factor (which is bad?)", "\n", "\n", "        ", "beam", "=", "beam", "if", "beam", "is", "not", "None", "else", "self", ".", "beam", "\n", "batch_size", ",", "seq_len", "=", "emissions", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "if", "targets", "is", "not", "None", ":", "\n", "            ", "_emissions", "=", "emissions", ".", "scatter", "(", "2", ",", "targets", "[", ":", ",", ":", ",", "None", "]", ",", "np", ".", "float", "(", "\"inf\"", ")", ")", "\n", "beam_targets", "=", "_emissions", ".", "topk", "(", "beam", ",", "2", ")", "[", "1", "]", "\n", "beam_emission_scores", "=", "emissions", ".", "gather", "(", "2", ",", "beam_targets", ")", "\n", "", "else", ":", "\n", "            ", "beam_emission_scores", ",", "beam_targets", "=", "emissions", ".", "topk", "(", "beam", ",", "2", ")", "\n", "", "beam_transition_score1", "=", "self", ".", "E1", "(", "beam_targets", "[", ":", ",", ":", "-", "1", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_score2", "=", "self", ".", "E2", "(", "beam_targets", "[", ":", ",", "1", ":", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_matrix", "=", "torch", ".", "bmm", "(", "\n", "beam_transition_score1", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ",", "\n", "beam_transition_score2", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", ")", "\n", "beam_transition_matrix", "=", "beam_transition_matrix", ".", "view", "(", "batch_size", ",", "-", "1", ",", "beam", ",", "beam", ")", "\n", "\n", "# compute the normalizer in the log-space", "\n", "score", "=", "beam_emission_scores", "[", ":", ",", "0", "]", "# B x K", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "            ", "next_score", "=", "score", "[", ":", ",", ":", ",", "None", "]", "+", "beam_transition_matrix", "[", ":", ",", "i", "-", "1", "]", "\n", "next_score", "=", "logsumexp", "(", "next_score", ",", "dim", "=", "1", ")", "+", "beam_emission_scores", "[", ":", ",", "i", "]", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "                ", "score", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "next_score", ",", "score", ")", "\n", "", "else", ":", "\n", "                ", "score", "=", "next_score", "\n", "\n", "# Sum (log-sum-exp) over all possible tags", "\n", "", "", "return", "logsumexp", "(", "score", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.DynamicCRF._viterbi_decode": [[135, 190], ["emissions.topk", "dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "beam_transition_matrix.view.view.view", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "range", "torch.where.max", "torch.where.max", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "zip", "torch.cat.reverse", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.reverse", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "emissions.size", "dynamic_crf_layer.DynamicCRF.view", "dynamic_crf_layer.DynamicCRF.view().transpose", "traj_scores.append", "_score.max", "traj_tokens.append", "reversed", "reversed", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "beam_targets.gather", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "idx.gather", "scs.gather", "dynamic_crf_layer.DynamicCRF.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.where.size", "torch.where.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_viterbi_decode", "(", "self", ",", "emissions", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "# HACK: we use a beam of tokens to approximate the normalizing factor (which is bad?)", "\n", "\n", "        ", "beam", "=", "beam", "if", "beam", "is", "not", "None", "else", "self", ".", "beam", "\n", "batch_size", ",", "seq_len", "=", "emissions", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "beam_emission_scores", ",", "beam_targets", "=", "emissions", ".", "topk", "(", "beam", ",", "2", ")", "\n", "beam_transition_score1", "=", "self", ".", "E1", "(", "beam_targets", "[", ":", ",", ":", "-", "1", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_score2", "=", "self", ".", "E2", "(", "beam_targets", "[", ":", ",", "1", ":", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_matrix", "=", "torch", ".", "bmm", "(", "\n", "beam_transition_score1", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ",", "\n", "beam_transition_score2", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", ")", "\n", "beam_transition_matrix", "=", "beam_transition_matrix", ".", "view", "(", "batch_size", ",", "-", "1", ",", "beam", ",", "beam", ")", "\n", "\n", "traj_tokens", ",", "traj_scores", "=", "[", "]", ",", "[", "]", "\n", "finalized_tokens", ",", "finalized_scores", "=", "[", "]", ",", "[", "]", "\n", "\n", "# compute the normalizer in the log-space", "\n", "score", "=", "beam_emission_scores", "[", ":", ",", "0", "]", "# B x K", "\n", "dummy", "=", "(", "\n", "torch", ".", "arange", "(", "beam", ",", "device", "=", "score", ".", "device", ")", ".", "expand", "(", "*", "score", ".", "size", "(", ")", ")", ".", "contiguous", "(", ")", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "            ", "traj_scores", ".", "append", "(", "score", ")", "\n", "_score", "=", "score", "[", ":", ",", ":", ",", "None", "]", "+", "beam_transition_matrix", "[", ":", ",", "i", "-", "1", "]", "\n", "_score", ",", "_index", "=", "_score", ".", "max", "(", "dim", "=", "1", ")", "\n", "_score", "=", "_score", "+", "beam_emission_scores", "[", ":", ",", "i", "]", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "                ", "score", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "_score", ",", "score", ")", "\n", "index", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "_index", ",", "dummy", ")", "\n", "", "else", ":", "\n", "                ", "score", ",", "index", "=", "_score", ",", "_index", "\n", "", "traj_tokens", ".", "append", "(", "index", ")", "\n", "\n", "# now running the back-tracing and find the best", "\n", "", "best_score", ",", "best_index", "=", "score", ".", "max", "(", "dim", "=", "1", ")", "\n", "finalized_tokens", ".", "append", "(", "best_index", "[", ":", ",", "None", "]", ")", "\n", "finalized_scores", ".", "append", "(", "best_score", "[", ":", ",", "None", "]", ")", "\n", "\n", "for", "idx", ",", "scs", "in", "zip", "(", "reversed", "(", "traj_tokens", ")", ",", "reversed", "(", "traj_scores", ")", ")", ":", "\n", "            ", "previous_index", "=", "finalized_tokens", "[", "-", "1", "]", "\n", "finalized_tokens", ".", "append", "(", "idx", ".", "gather", "(", "1", ",", "previous_index", ")", ")", "\n", "finalized_scores", ".", "append", "(", "scs", ".", "gather", "(", "1", ",", "previous_index", ")", ")", "\n", "\n", "", "finalized_tokens", ".", "reverse", "(", ")", "\n", "finalized_tokens", "=", "torch", ".", "cat", "(", "finalized_tokens", ",", "1", ")", "\n", "finalized_tokens", "=", "beam_targets", ".", "gather", "(", "2", ",", "finalized_tokens", "[", ":", ",", ":", ",", "None", "]", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "finalized_scores", ".", "reverse", "(", ")", "\n", "finalized_scores", "=", "torch", ".", "cat", "(", "finalized_scores", ",", "1", ")", "\n", "finalized_scores", "[", ":", ",", "1", ":", "]", "=", "finalized_scores", "[", ":", ",", "1", ":", "]", "-", "finalized_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "return", "finalized_scores", ",", "finalized_tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp": [[24, 26], ["torch.logsumexp().type_as", "torch.logsumexp().type_as", "torch.logsumexp", "torch.logsumexp", "x.float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_crf_layer.logsumexp"], ["def", "logsumexp", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "return", "torch", ".", "logsumexp", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", ".", "type_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.CheckpointFunction.forward": [[134, 168], ["torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "fairseq.utils.get_rng_state", "checkpoint_activations.split_non_tensors", "ctx.save_for_backward", "isinstance", "torch.check_backward_validity", "torch.check_backward_validity", "tuple", "tuple", "tuple", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "checkpoint_activations.unpack_kwargs", "run_function", "checkpoint_activations.split_non_tensors", "x.cpu"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.split_non_tensors", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_kwargs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.split_non_tensors"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "run_function", ",", "parent_ctx_dict", ",", "kwarg_keys", ",", "*", "args", ")", ":", "\n", "        ", "if", "torch", ".", "is_grad_enabled", "(", ")", ":", "# grad may be disabled, e.g., during validation", "\n", "            ", "checkpoint", ".", "check_backward_validity", "(", "args", ")", "\n", "\n", "", "ctx", ".", "run_function", "=", "run_function", "\n", "ctx", ".", "kwarg_keys", "=", "kwarg_keys", "\n", "ctx", ".", "fwd_rng_state", "=", "utils", ".", "get_rng_state", "(", ")", "\n", "\n", "tensor_inputs", ",", "packed_non_tensor_inputs", "=", "split_non_tensors", "(", "args", ")", "\n", "if", "parent_ctx_dict", "[", "\"offload\"", "]", ":", "\n", "            ", "ctx", ".", "fwd_device", "=", "tuple", "(", "x", ".", "device", "for", "x", "in", "tensor_inputs", ")", "\n", "ctx", ".", "grad_requirements", "=", "tuple", "(", "x", ".", "requires_grad", "for", "x", "in", "tensor_inputs", ")", "\n", "tensor_inputs", "=", "tuple", "(", "x", ".", "cpu", "(", ")", "for", "x", "in", "tensor_inputs", ")", "\n", "\n", "", "else", ":", "\n", "            ", "ctx", ".", "fwd_device", ",", "ctx", ".", "grad_requirements", "=", "None", ",", "None", "\n", "\n", "", "ctx", ".", "save_for_backward", "(", "*", "tensor_inputs", ")", "\n", "ctx", ".", "packed_non_tensor_inputs", "=", "packed_non_tensor_inputs", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "unpacked_args", ",", "unpacked_kwargs", "=", "unpack_kwargs", "(", "kwarg_keys", ",", "args", ")", "\n", "outputs", "=", "run_function", "(", "*", "unpacked_args", ",", "**", "unpacked_kwargs", ")", "\n", "\n", "", "if", "isinstance", "(", "outputs", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "else", ":", "\n", "# Autograd Functions don't like non-Tensor outputs. We can split the", "\n", "# non-Tensor and Tensor outputs, returning the former by reference", "\n", "# through *parent_ctx_dict* and returning the latter directly.", "\n", "            ", "outputs", ",", "packed_non_tensor_outputs", "=", "split_non_tensors", "(", "outputs", ")", "\n", "parent_ctx_dict", "[", "\"packed_non_tensor_outputs\"", "]", "=", "packed_non_tensor_outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.CheckpointFunction.backward": [[169, 218], ["torch.detach_variable", "torch.detach_variable", "checkpoint_activations.unpack_non_tensors", "fairseq.utils.get_rng_state", "fairseq.utils.set_rng_state", "fairseq.utils.set_rng_state", "range", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "tuple", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "RuntimeError", "enumerate", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "checkpoint_activations.unpack_kwargs", "ctx.run_function", "checkpoint_activations.split_non_tensors", "len", "len", "RuntimeError", "t.to", "outputs_with_grad.append", "args_with_grad.append", "enumerate", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_non_tensors", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_kwargs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.split_non_tensors"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "args", ")", ":", "\n", "        ", "if", "not", "torch", ".", "autograd", ".", "_is_checkpoint_valid", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Checkpointing is not compatible with .grad(), please use .backward() if possible\"", "\n", ")", "\n", "\n", "", "tensor_inputs", ":", "Tuple", "=", "ctx", ".", "saved_tensors", "\n", "tensor_inputs", "=", "checkpoint", ".", "detach_variable", "(", "tensor_inputs", ")", "\n", "if", "ctx", ".", "fwd_device", "is", "not", "None", ":", "\n", "            ", "tensor_inputs", "=", "[", "\n", "t", ".", "to", "(", "ctx", ".", "fwd_device", "[", "i", "]", ")", "for", "i", ",", "t", "in", "enumerate", "(", "tensor_inputs", ")", "\n", "]", "\n", "for", "i", ",", "need_grad", "in", "enumerate", "(", "ctx", ".", "grad_requirements", ")", ":", "\n", "                ", "tensor_inputs", "[", "i", "]", ".", "requires_grad", "=", "need_grad", "\n", "", "", "inputs", "=", "unpack_non_tensors", "(", "tensor_inputs", ",", "ctx", ".", "packed_non_tensor_inputs", ")", "\n", "\n", "# Store the current states.", "\n", "bwd_rng_state", "=", "utils", ".", "get_rng_state", "(", ")", "\n", "\n", "# Set the states to what it used to be before the forward pass.", "\n", "utils", ".", "set_rng_state", "(", "ctx", ".", "fwd_rng_state", ")", "\n", "\n", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "unpacked_args", ",", "unpacked_kwargs", "=", "unpack_kwargs", "(", "ctx", ".", "kwarg_keys", ",", "inputs", ")", "\n", "outputs", "=", "ctx", ".", "run_function", "(", "*", "unpacked_args", ",", "**", "unpacked_kwargs", ")", "\n", "tensor_outputs", ",", "_", "=", "split_non_tensors", "(", "outputs", ")", "\n", "# Set the states back to what it was at the start of this function.", "\n", "", "utils", ".", "set_rng_state", "(", "bwd_rng_state", ")", "\n", "\n", "# Run backward() with only Tensors that require grad", "\n", "outputs_with_grad", "=", "[", "]", "\n", "args_with_grad", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tensor_outputs", ")", ")", ":", "\n", "            ", "if", "tensor_outputs", "[", "i", "]", ".", "requires_grad", ":", "\n", "                ", "outputs_with_grad", ".", "append", "(", "tensor_outputs", "[", "i", "]", ")", "\n", "args_with_grad", ".", "append", "(", "args", "[", "i", "]", ")", "\n", "", "", "if", "len", "(", "outputs_with_grad", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"None of the outputs have requires_grad=True, \"", "\n", "\"this checkpoint() is not necessary\"", "\n", ")", "\n", "\n", "", "torch", ".", "autograd", ".", "backward", "(", "outputs_with_grad", ",", "args_with_grad", ")", "\n", "\n", "grads", "=", "tuple", "(", "\n", "inp", ".", "grad", "if", "isinstance", "(", "inp", ",", "torch", ".", "Tensor", ")", "else", "None", "for", "inp", "in", "inputs", "\n", ")", "\n", "return", "(", "None", ",", "None", ",", "None", ")", "+", "grads", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.checkpoint_wrapper": [[14, 49], ["checkpoint_activations.pack_kwargs", "CheckpointFunction.apply", "isinstance", "checkpoint_activations.unpack_non_tensors"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.pack_kwargs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_non_tensors"], ["def", "checkpoint_wrapper", "(", "m", ",", "offload_to_cpu", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A friendlier wrapper for performing activation checkpointing.\n\n    Compared to the PyTorch version, this version:\n    - wraps an nn.Module, so that all subsequent calls will use checkpointing\n    - handles keyword arguments in the forward\n    - handles non-Tensor outputs from the forward\n\n    Usage::\n\n        checkpointed_module = checkpoint_wrapper(my_module, offload_to_cpu=True)\n        a, b = checkpointed_module(x, y=3, z=torch.Tensor([1]))\n    \"\"\"", "\n", "original_forward", "=", "m", ".", "forward", "\n", "\n", "def", "_checkpointed_forward", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Autograd Functions in PyTorch work best with positional args, since", "\n", "# the backward must return gradients (or None) for every input argument.", "\n", "# We can flatten keyword arguments to make this easier.", "\n", "        ", "kwarg_keys", ",", "flat_args", "=", "pack_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "parent_ctx_dict", "=", "{", "\"offload\"", ":", "offload_to_cpu", "}", "\n", "output", "=", "CheckpointFunction", ".", "apply", "(", "\n", "original_forward", ",", "parent_ctx_dict", ",", "kwarg_keys", ",", "*", "flat_args", "\n", ")", "\n", "if", "isinstance", "(", "output", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "output", "\n", "", "else", ":", "\n", "            ", "packed_non_tensor_outputs", "=", "parent_ctx_dict", "[", "\"packed_non_tensor_outputs\"", "]", "\n", "if", "packed_non_tensor_outputs", ":", "\n", "                ", "output", "=", "unpack_non_tensors", "(", "output", ",", "packed_non_tensor_outputs", ")", "\n", "", "return", "output", "\n", "\n", "", "", "m", ".", "forward", "=", "_checkpointed_forward", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.pack_kwargs": [[51, 66], ["list", "kwargs.items", "kwarg_keys.append", "list.append"], "function", ["None"], ["", "def", "pack_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Usage::\n\n        kwarg_keys, flat_args = pack_kwargs(1, 2, a=3, b=4)\n        args, kwargs = unpack_kwargs(kwarg_keys, flat_args)\n        assert args == [1, 2]\n        assert kwargs == {\"a\": 3, \"b\": 4}\n    \"\"\"", "\n", "kwarg_keys", "=", "[", "]", "\n", "flat_args", "=", "list", "(", "args", ")", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "kwarg_keys", ".", "append", "(", "k", ")", "\n", "flat_args", ".", "append", "(", "v", ")", "\n", "", "return", "kwarg_keys", ",", "flat_args", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_kwargs": [[68, 76], ["len", "zip", "len", "len"], "function", ["None"], ["", "def", "unpack_kwargs", "(", "\n", "kwarg_keys", ":", "List", "[", "str", "]", ",", "flat_args", ":", "List", "[", "Any", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "    ", "if", "len", "(", "kwarg_keys", ")", "==", "0", ":", "\n", "        ", "return", "flat_args", ",", "{", "}", "\n", "", "args", "=", "flat_args", "[", ":", "-", "len", "(", "kwarg_keys", ")", "]", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "kwarg_keys", ",", "flat_args", "[", "-", "len", "(", "kwarg_keys", ")", ":", "]", ")", "}", "\n", "return", "args", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.split_non_tensors": [[78, 102], ["isinstance", "isinstance", "tuple", "packed_non_tensors[].append", "tensors.append", "packed_non_tensors[].append", "packed_non_tensors[].append"], "function", ["None"], ["", "def", "split_non_tensors", "(", "\n", "mixed", ":", "Union", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "Any", "]", "]", "\n", ")", "->", "Tuple", "[", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "List", "[", "Any", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Usage::\n\n        x = torch.Tensor([1])\n        y = torch.Tensor([2])\n        tensors, packed_non_tensors = split_non_tensors((x, y, None, 3))\n        recon = unpack_non_tensors(tensors, packed_non_tensors)\n        assert recon == (x, y, None, 3)\n    \"\"\"", "\n", "if", "isinstance", "(", "mixed", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "(", "mixed", ",", ")", ",", "None", "\n", "", "tensors", "=", "[", "]", "\n", "packed_non_tensors", "=", "{", "\"is_tensor\"", ":", "[", "]", ",", "\"objects\"", ":", "[", "]", "}", "\n", "for", "o", "in", "mixed", ":", "\n", "        ", "if", "isinstance", "(", "o", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "packed_non_tensors", "[", "\"is_tensor\"", "]", ".", "append", "(", "True", ")", "\n", "tensors", ".", "append", "(", "o", ")", "\n", "", "else", ":", "\n", "            ", "packed_non_tensors", "[", "\"is_tensor\"", "]", ".", "append", "(", "False", ")", "\n", "packed_non_tensors", "[", "\"objects\"", "]", ".", "append", "(", "o", ")", "\n", "", "", "return", "tuple", "(", "tensors", ")", ",", "packed_non_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.checkpoint_activations.unpack_non_tensors": [[104, 124], ["isinstance", "tuple", "len", "len", "len", "mixed.append", "mixed.append"], "function", ["None"], ["", "def", "unpack_non_tensors", "(", "\n", "tensors", ":", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "\n", "packed_non_tensors", ":", "Dict", "[", "str", ",", "List", "[", "Any", "]", "]", ",", "\n", ")", "->", "Tuple", "[", "Any", "]", ":", "\n", "    ", "if", "packed_non_tensors", "is", "None", ":", "\n", "        ", "return", "tensors", "\n", "", "assert", "isinstance", "(", "packed_non_tensors", ",", "dict", ")", "\n", "mixed", "=", "[", "]", "\n", "is_tensor_list", "=", "packed_non_tensors", "[", "\"is_tensor\"", "]", "\n", "objects", "=", "packed_non_tensors", "[", "\"objects\"", "]", "\n", "assert", "len", "(", "tensors", ")", "+", "len", "(", "objects", ")", "==", "len", "(", "is_tensor_list", ")", "\n", "obj_i", "=", "tnsr_i", "=", "0", "\n", "for", "is_tensor", "in", "is_tensor_list", ":", "\n", "        ", "if", "is_tensor", ":", "\n", "            ", "mixed", ".", "append", "(", "tensors", "[", "tnsr_i", "]", ")", "\n", "tnsr_i", "+=", "1", "\n", "", "else", ":", "\n", "            ", "mixed", ".", "append", "(", "objects", "[", "obj_i", "]", ")", "\n", "obj_i", "+=", "1", "\n", "", "", "return", "tuple", "(", "mixed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.__init__": [[95, 134], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "dynamic_convolution.DynamicConv1dTBC.reset_parameters", "dynamic_convolution.Linear", "dynamic_convolution.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", "in_proj", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "query_size", "=", "input_size", "if", "query_size", "is", "None", "else", "query_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "renorm_padding", "=", "renorm_padding", "\n", "\n", "if", "in_proj", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "input_size", ",", "self", ".", "input_size", "+", "num_heads", "*", "kernel_size", "*", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "query_size", ",", "num_heads", "*", "kernel_size", "*", "1", ",", "bias", "=", "bias", "\n", ")", "\n", "", "if", "conv_bias", ":", "\n", "            ", "self", ".", "conv_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.in_proj": [[135, 140], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_proj", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "weight_linear", ".", "out_features", "\n", "==", "self", ".", "input_size", "+", "self", ".", "num_heads", "*", "self", ".", "kernel_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.reset_parameters": [[142, 146], ["dynamic_convolution.DynamicConv1dTBC.weight_linear.reset_parameters", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight_linear", ".", "reset_parameters", "(", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv_bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.forward": [[147, 171], ["dynamic_convolution.DynamicConv1dTBC._forward_unfolded", "dynamic_convolution.DynamicConv1dTBC._forward_expanded", "x.size", "dynamic_convolution.DynamicConv1dTBC.conv_bias.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "query", "=", "None", ",", "unfold", "=", "None", ")", ":", "\n", "        ", "\"\"\"Assuming the input, x, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            x: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n            query: use the specified query to predict the conv filters\n        \"\"\"", "\n", "unfold", "=", "(", "\n", "x", ".", "size", "(", "0", ")", ">", "512", "if", "unfold", "is", "None", "else", "unfold", "\n", ")", "# use unfold mode as default for long sequence to save memory", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "assert", "query", "is", "None", "or", "not", "self", ".", "in_proj", "\n", "\n", "if", "query", "is", "None", ":", "\n", "            ", "query", "=", "x", "\n", "", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "\n", "", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC._forward_unfolded": [[172, 227], ["dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear().view", "dynamic_convolution.DynamicConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "unfold.unfold1d", "x_unfold.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.size", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.unsqueeze", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.new", "dynamic_convolution.DynamicConv1dTBC._set_input_buffer", "weight.narrow.narrow.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.unsqueeze", "dynamic_convolution.DynamicConv1dTBC.narrow", "x_unfold.view.view.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "x", ")", "\n", "x", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "(", "\n", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "", "assert", "not", "self", ".", "renorm_padding", "or", "incremental_state", "is", "not", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "", "x_unfold", "=", "unfold1d", "(", "x", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ".", "unsqueeze", "(", "2", ")", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC._forward_expanded": [[228, 279], ["dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow().contiguous", "weight.narrow.narrow.view().transpose", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear().view", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "weight.narrow.narrow.new().fill_", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "weight.narrow.narrow.new_zeros", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.view", "float", "weight.narrow.narrow.narrow", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "weight.narrow.narrow.new", "weight_expanded.narrow.narrow.as_strided", "weight_expanded.narrow.narrow.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose", "dynamic_convolution.DynamicConv1dTBC.narrow"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_stat", ",", "query", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "x", ")", "\n", "x", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "(", "\n", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "# turn the convolution filters into band matrices", "\n", "            ", "weight_expanded", "=", "weight", ".", "new", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "self", ".", "padding_l", ",", "T", ")", "\n", "# normalize the weight over valid positions like self-attention", "\n", "weight_expanded", "=", "F", ".", "softmax", "(", "weight_expanded", ",", "dim", "=", "2", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ",", "inplace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "P", "=", "self", ".", "padding_l", "\n", "# For efficieny, we cut the kernel size and reduce the padding when the kernel is larger than the length", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "# B*H x T x T", "\n", "", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.reorder_incremental_state": [[280, 285], ["dynamic_convolution.DynamicConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "dynamic_convolution.DynamicConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC._get_input_buffer": [[286, 288], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC._set_input_buffer": [[289, 292], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv1dTBC.extra_repr": [[294, 311], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, conv_bias={}, renorm_padding={}, in_proj={}\"", ".", "format", "(", "\n", "self", ".", "input_size", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "\n", "self", ".", "weight_softmax", ",", "\n", "self", ".", "conv_bias", "is", "not", "None", ",", "\n", "self", ".", "renorm_padding", ",", "\n", "self", ".", "in_proj", ",", "\n", ")", "\n", "\n", "if", "self", ".", "query_size", "!=", "self", ".", "input_size", ":", "\n", "            ", "s", "+=", "\", query_size={}\"", ".", "format", "(", "self", ".", "query_size", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ">", "0.0", ":", "\n", "            ", "s", "+=", "\", weight_dropout={}\"", ".", "format", "(", "self", ".", "weight_dropout_module", ".", "p", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.DynamicConv": [[16, 58], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "dynamic_convolution.DynamicConv1dTBC", "DynamicconvLayer", "print"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["def", "DynamicConv", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", "in_proj", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "modules", ".", "dynamicconv_layer", "import", "DynamicconvLayer", "\n", "\n", "return", "DynamicconvLayer", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "renorm_padding", "=", "renorm_padding", ",", "\n", "bias", "=", "bias", ",", "\n", "conv_bias", "=", "conv_bias", ",", "\n", "query_size", "=", "query_size", ",", "\n", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "", "", "return", "DynamicConv1dTBC", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "renorm_padding", "=", "renorm_padding", ",", "\n", "bias", "=", "bias", ",", "\n", "conv_bias", "=", "conv_bias", ",", "\n", "query_size", "=", "query_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.dynamic_convolution.Linear": [[61, 67], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.TiedLinear.__init__": [[17, 21], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "weight", ",", "transpose", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "transpose", "=", "transpose", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.TiedLinear.forward": [[22, 24], ["torch.linear", "torch.linear", "adaptive_softmax.TiedLinear.weight.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", ".", "t", "(", ")", "if", "self", ".", "transpose", "else", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.TiedHeadModule.__init__": [[27, 49], ["torch.nn.Module.__init__", "tied_emb.size", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "adaptive_softmax.TiedHeadModule.register_buffer", "adaptive_softmax.TiedLinear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "weights", ",", "input_dim", ",", "num_classes", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "tied_emb", ",", "_", "=", "weights", "\n", "self", ".", "num_words", ",", "emb_dim", "=", "tied_emb", ".", "size", "(", ")", "\n", "\n", "self", ".", "word_proj", "=", "quant_noise", "(", "\n", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "if", "input_dim", "!=", "emb_dim", ":", "\n", "            ", "self", ".", "word_proj", "=", "nn", ".", "Sequential", "(", "\n", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "emb_dim", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", ",", "\n", "self", ".", "word_proj", ",", "\n", ")", "\n", "\n", "", "self", ".", "class_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "num_classes", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "out_dim", "=", "self", ".", "num_words", "+", "num_classes", "\n", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.TiedHeadModule.forward": [[50, 56], ["functools.reduce", "adaptive_softmax.TiedHeadModule._float_tensor.new", "adaptive_softmax.TiedHeadModule.word_proj", "adaptive_softmax.TiedHeadModule.class_proj", "input.view", "input.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "inp_sz", "=", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "input", ".", "shape", "[", ":", "-", "1", "]", ",", "1", ")", "\n", "out", "=", "self", ".", "_float_tensor", ".", "new", "(", "inp_sz", ",", "self", ".", "out_dim", ")", "\n", "out", "[", ":", ",", ":", "self", ".", "num_words", "]", "=", "self", ".", "word_proj", "(", "input", ".", "view", "(", "inp_sz", ",", "-", "1", ")", ")", "\n", "out", "[", ":", ",", "self", ".", "num_words", ":", "]", "=", "self", ".", "class_proj", "(", "input", ".", "view", "(", "inp_sz", ",", "-", "1", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.__init__": [[65, 128], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "adaptive_softmax.AdaptiveSoftmax._make_tail", "adaptive_softmax.AdaptiveSoftmax.apply", "adaptive_softmax.AdaptiveSoftmax.register_buffer", "adaptive_softmax.TiedHeadModule", "fairseq.modules.quant_noise.quant_noise", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "adaptive_inputs.weights_for_band", "torch.nn.Linear", "torch.nn.Linear", "hasattr", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "len", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax._make_tail", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_input.AdaptiveInput.weights_for_band", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", ",", "\n", "input_dim", ",", "\n", "cutoff", ",", "\n", "dropout", ",", "\n", "factor", "=", "4.0", ",", "\n", "adaptive_inputs", "=", "None", ",", "\n", "tie_proj", "=", "False", ",", "\n", "q_noise", "=", "0", ",", "\n", "qn_block_size", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", "=", "cutoff", "+", "[", "vocab_size", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "vocab_size", "==", "cutoff", "[", "-", "1", "]", "\n", ")", ",", "\"cannot specify cutoff larger than vocab size\"", "\n", "\n", "", "output_dim", "=", "cutoff", "[", "0", "]", "+", "len", "(", "cutoff", ")", "-", "1", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "q_noise", "=", "q_noise", "\n", "self", ".", "qn_block_size", "=", "qn_block_size", "\n", "\n", "self", ".", "lsm", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "if", "adaptive_inputs", "is", "not", "None", ":", "\n", "            ", "self", ".", "head", "=", "TiedHeadModule", "(", "\n", "adaptive_inputs", ".", "weights_for_band", "(", "0", ")", ",", "\n", "input_dim", ",", "\n", "len", "(", "cutoff", ")", "-", "1", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "\n", "", "self", ".", "_make_tail", "(", "adaptive_inputs", ",", "tie_proj", ")", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "(", "\n", "hasattr", "(", "m", ",", "\"weight\"", ")", "\n", "and", "not", "isinstance", "(", "m", ",", "TiedLinear", ")", "\n", "and", "not", "isinstance", "(", "m", ",", "TiedHeadModule", ")", "\n", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "LongTensor", "(", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax._make_tail": [[129, 174], ["torch.nn.ModuleList", "torch.nn.ModuleList", "range", "int", "torch.nn.Sequential", "torch.nn.Sequential", "adaptive_softmax.AdaptiveSoftmax.tail.append", "len", "adaptive_inputs.weights_for_band", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear", "adaptive_softmax.TiedLinear", "torch.nn.Dropout", "torch.nn.Dropout", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear", "adaptive_softmax.TiedLinear", "torch.nn.Linear", "torch.nn.Linear", "tied_proj.size", "tied_proj.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_input.AdaptiveInput.weights_for_band", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_make_tail", "(", "self", ",", "adaptive_inputs", "=", "None", ",", "tie_proj", "=", "False", ")", ":", "\n", "        ", "self", ".", "tail", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "dim", "=", "int", "(", "self", ".", "input_dim", "//", "self", ".", "factor", "**", "(", "i", "+", "1", ")", ")", "\n", "\n", "tied_emb", ",", "tied_proj", "=", "(", "\n", "adaptive_inputs", ".", "weights_for_band", "(", "i", "+", "1", ")", "\n", "if", "adaptive_inputs", "is", "not", "None", "\n", "else", "(", "None", ",", "None", ")", "\n", ")", "\n", "\n", "if", "tied_proj", "is", "not", "None", ":", "\n", "                ", "if", "tie_proj", ":", "\n", "                    ", "proj", "=", "quant_noise", "(", "\n", "TiedLinear", "(", "tied_proj", ",", "transpose", "=", "True", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "tied_proj", ".", "size", "(", "0", ")", ",", "tied_proj", ".", "size", "(", "1", ")", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "dim", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "\n", "", "if", "tied_emb", "is", "None", ":", "\n", "                ", "out_proj", "=", "nn", ".", "Linear", "(", "\n", "dim", ",", "self", ".", "cutoff", "[", "i", "+", "1", "]", "-", "self", ".", "cutoff", "[", "i", "]", ",", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out_proj", "=", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", "\n", "\n", "", "m", "=", "nn", ".", "Sequential", "(", "\n", "proj", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "dropout_module", ".", "p", ")", ",", "\n", "quant_noise", "(", "out_proj", ",", "self", ".", "q_noise", ",", "self", ".", "qn_block_size", ")", ",", "\n", ")", "\n", "\n", "self", ".", "tail", ".", "append", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.upgrade_state_dict_named": [[175, 179], ["Exception"], "methods", ["None"], ["", "", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "version_name", "=", "name", "+", "\".version\"", "\n", "if", "version_name", "not", "in", "state_dict", ":", "\n", "            ", "raise", "Exception", "(", "\"This version of the model is no longer supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target": [[180, 204], ["target.view.view.view", "range", "target.view.view.clone", "target.view.view.ge().mul", "target.view.ge().mul.any", "len", "target.view.view.lt", "target_idxs.append", "new_target.append", "target_idxs.append", "new_target.append", "target.view.view.ge", "target.view.ge().mul.nonzero().squeeze", "target[].add", "target.view.ge().mul.nonzero"], "methods", ["None"], ["", "", "def", "adapt_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        In order to be efficient, the AdaptiveSoftMax does not compute the\n        scores for all the word of the vocabulary for all the examples. It is\n        thus necessary to call the method adapt_target of the AdaptiveSoftMax\n        layer inside each forward pass.\n        \"\"\"", "\n", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "new_target", "=", "[", "target", ".", "clone", "(", ")", "]", "\n", "target_idxs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "mask", "=", "target", ".", "ge", "(", "self", ".", "cutoff", "[", "i", "]", ")", ".", "mul", "(", "target", ".", "lt", "(", "self", ".", "cutoff", "[", "i", "+", "1", "]", ")", ")", "\n", "new_target", "[", "0", "]", "[", "mask", "]", "=", "self", ".", "cutoff", "[", "0", "]", "+", "i", "\n", "\n", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "target_idxs", ".", "append", "(", "mask", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "new_target", ".", "append", "(", "target", "[", "mask", "]", ".", "add", "(", "-", "self", ".", "cutoff", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "target_idxs", ".", "append", "(", "None", ")", "\n", "new_target", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "new_target", ",", "target_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.forward": [[205, 227], ["adaptive_softmax.AdaptiveSoftmax.contiguous().view", "adaptive_softmax.AdaptiveSoftmax.dropout_module", "adaptive_softmax.AdaptiveSoftmax.adapt_target", "range", "adaptive_softmax.AdaptiveSoftmax.size", "adaptive_softmax.AdaptiveSoftmax.head", "len", "adaptive_softmax.AdaptiveSoftmax.contiguous", "output.append", "output.append", "adaptive_softmax.AdaptiveSoftmax.index_select"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: (b x t x d)\n            target: (b x t)\n        Returns:\n            2 lists: output for each cutoff section and new targets by cut off\n        \"\"\"", "\n", "\n", "input", "=", "input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "input", ".", "size", "(", "-", "1", ")", ")", "\n", "input", "=", "self", ".", "dropout_module", "(", "input", ")", "\n", "\n", "new_target", ",", "target_idxs", "=", "self", ".", "adapt_target", "(", "target", ")", "\n", "output", "=", "[", "self", ".", "head", "(", "input", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "target_idxs", ")", ")", ":", "\n", "            ", "if", "target_idxs", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "output", ".", "append", "(", "self", ".", "tail", "[", "i", "]", "(", "input", ".", "index_select", "(", "0", ",", "target_idxs", "[", "i", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "output", ",", "new_target", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob": [[228, 269], ["input.contiguous().view.contiguous().view.size", "input.contiguous().view.contiguous().view.contiguous().view", "adaptive_softmax.AdaptiveSoftmax.head", "adaptive_softmax.AdaptiveSoftmax.new_zeros", "adaptive_softmax.AdaptiveSoftmax.lsm", "log_probs[].clone", "range", "log_probs.view.view.view", "adaptive_softmax.AdaptiveSoftmax.adapt_target", "input.contiguous().view.contiguous().view.size", "len", "len", "input.contiguous().view.contiguous().view.contiguous", "tail_out.copy_", "adaptive_softmax.AdaptiveSoftmax.lsm().add_", "tail_out.copy_", "adaptive_softmax.AdaptiveSoftmax.lsm().add_", "adaptive_softmax.AdaptiveSoftmax.lsm", "adaptive_softmax.AdaptiveSoftmax.lsm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "get_log_prob", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Computes the log probabilities for all the words of the vocabulary,\n        given a 2D tensor of hidden vectors.\n        \"\"\"", "\n", "\n", "bsz", ",", "length", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "input", "=", "input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "_", ",", "target_idxs", "=", "self", ".", "adapt_target", "(", "target", ")", "\n", "", "else", ":", "\n", "            ", "target_idxs", "=", "None", "\n", "\n", "", "head_y", "=", "self", ".", "head", "(", "input", ")", "\n", "log_probs", "=", "head_y", ".", "new_zeros", "(", "input", ".", "size", "(", "0", ")", ",", "self", ".", "vocab_size", ")", "\n", "\n", "head_sz", "=", "self", ".", "cutoff", "[", "0", "]", "+", "len", "(", "self", ".", "tail", ")", "\n", "log_probs", "[", ":", ",", ":", "head_sz", "]", "=", "self", ".", "lsm", "(", "head_y", ")", "\n", "tail_priors", "=", "log_probs", "[", ":", ",", "self", ".", "cutoff", "[", "0", "]", ":", "head_sz", "]", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "tail", ")", ")", ":", "\n", "            ", "start", "=", "self", ".", "cutoff", "[", "i", "]", "\n", "end", "=", "self", ".", "cutoff", "[", "i", "+", "1", "]", "\n", "\n", "if", "target_idxs", "is", "None", ":", "\n", "                ", "tail_out", "=", "log_probs", "[", ":", ",", "start", ":", "end", "]", "\n", "tail_out", ".", "copy_", "(", "self", ".", "tail", "[", "i", "]", "(", "input", ")", ")", "\n", "log_probs", "[", ":", ",", "start", ":", "end", "]", "=", "self", ".", "lsm", "(", "tail_out", ")", ".", "add_", "(", "\n", "tail_priors", "[", ":", ",", "i", ",", "None", "]", "\n", ")", "\n", "", "elif", "target_idxs", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "idxs", "=", "target_idxs", "[", "i", "]", "\n", "tail_out", "=", "log_probs", "[", "idxs", ",", "start", ":", "end", "]", "\n", "tail_out", ".", "copy_", "(", "self", ".", "tail", "[", "i", "]", "(", "input", "[", "idxs", "]", ")", ")", "\n", "log_probs", "[", "idxs", ",", "start", ":", "end", "]", "=", "self", ".", "lsm", "(", "tail_out", ")", ".", "add_", "(", "\n", "tail_priors", "[", "idxs", ",", "i", ",", "None", "]", "\n", ")", "\n", "\n", "", "", "log_probs", "=", "log_probs", ".", "view", "(", "bsz", ",", "length", ",", "-", "1", ")", "\n", "return", "log_probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.cross_entropy._cross_entropy_pytorch": [[15, 22], ["torch.log_softmax", "torch.nll_loss"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax"], ["def", "_cross_entropy_pytorch", "(", "logits", ",", "target", ",", "ignore_index", "=", "None", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "    ", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "F", ".", "nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "ignore_index", "=", "ignore_index", ",", "\n", "reduction", "=", "reduction", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.beamable_mm.BeamableMM.__init__": [[19, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "BeamableMM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.beamable_mm.BeamableMM.forward": [[23, 47], ["input1[].unfold().transpose", "input1[].unfold().transpose.bmm.view", "input1[].unfold().transpose.bmm", "input1[].unfold().transpose.dim", "input1[].unfold().transpose.size", "input1[].unfold().transpose.size", "input2.unfold", "input1[].unfold().transpose.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "input1[].unfold().transpose.bmm", "input1[].unfold"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "if", "(", "\n", "not", "self", ".", "training", "\n", "and", "self", ".", "beam_size", "is", "not", "None", "# test mode", "\n", "and", "input1", ".", "dim", "(", ")", "==", "3", "# beam size is set", "\n", "and", "input1", ".", "size", "(", "1", ")", "# only support batched input", "\n", "==", "1", "# single time step update", "\n", ")", ":", "\n", "            ", "bsz", ",", "beam", "=", "input1", ".", "size", "(", "0", ")", ",", "self", ".", "beam_size", "\n", "\n", "# bsz x 1 x nhu --> bsz/beam x beam x nhu", "\n", "input1", "=", "input1", "[", ":", ",", "0", ",", ":", "]", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# bsz x sz2 x nhu --> bsz/beam x sz2 x nhu", "\n", "input2", "=", "input2", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "\n", "# use non batched operation if bsz = beam", "\n", "if", "input1", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "output", "=", "torch", ".", "mm", "(", "input1", "[", "0", ",", ":", ",", ":", "]", ",", "input2", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "input1", ".", "bmm", "(", "input2", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "input1", ".", "bmm", "(", "input2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.beamable_mm.BeamableMM.set_beam_size": [[48, 50], ["None"], "methods", ["None"], ["", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.same_pad.SamePad.__init__": [[11, 17], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "causal", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "causal", ":", "\n", "            ", "self", ".", "remove", "=", "kernel_size", "-", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "remove", "=", "1", "if", "kernel_size", "%", "2", "==", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.same_pad.SamePad.forward": [[18, 22], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "remove", ">", "0", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "-", "self", ".", "remove", "]", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.__init__": [[18, 29], ["super().__init__", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConvTBC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_single", "(", "kernel_size", ")", "\n", "self", ".", "padding", "=", "_single", "(", "padding", ")", "\n", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "self", ".", "kernel_size", "[", "0", "]", ",", "in_channels", ",", "out_channels", ")", "\n", ")", "\n", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.conv_tbc": [[30, 33], ["torch.conv_tbc", "input.contiguous"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.conv_tbc"], ["", "def", "conv_tbc", "(", "self", ",", "input", ":", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "conv_tbc", "(", "\n", "input", ".", "contiguous", "(", ")", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "padding", "[", "0", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.forward": [[35, 37], ["conv_tbc.ConvTBC.conv_tbc"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.conv_tbc"], ["", "def", "forward", "(", "self", ",", "input", ":", "Tensor", ")", ":", "\n", "        ", "return", "self", ".", "conv_tbc", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.__repr__": [[38, 47], ["s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "(", "\n", "\"{name}({in_channels}, {out_channels}, kernel_size={kernel_size}\"", "\n", "\", padding={padding}\"", "\n", ")", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "\", bias=False\"", "\n", "", "s", "+=", "\")\"", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.__init__": [[23, 63], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.ModuleList", "sum", "torch.nn.Linear", "torch.nn.Linear", "character_token_embedder.CharacterTokenEmbedder.reset_parameters", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "character_token_embedder.CharacterTokenEmbedder.convolutions.append", "character_token_embedder.Highway", "character_token_embedder.CharacterTokenEmbedder.set_vocab", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.set_vocab"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Dictionary", ",", "\n", "filters", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "char_embed_dim", ":", "int", ",", "\n", "word_embed_dim", ":", "int", ",", "\n", "highway_layers", ":", "int", ",", "\n", "max_char_len", ":", "int", "=", "50", ",", "\n", "char_inputs", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "CharacterTokenEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "embedding_dim", "=", "word_embed_dim", "\n", "self", ".", "max_char_len", "=", "max_char_len", "\n", "self", ".", "char_embeddings", "=", "nn", ".", "Embedding", "(", "257", ",", "char_embed_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "symbol_embeddings", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "word_embed_dim", ")", ")", "\n", "self", ".", "eos_idx", ",", "self", ".", "unk_idx", "=", "0", ",", "1", "\n", "self", ".", "char_inputs", "=", "char_inputs", "\n", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "width", ",", "out_c", "in", "filters", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "char_embed_dim", ",", "out_c", ",", "kernel_size", "=", "width", ")", "\n", ")", "\n", "\n", "", "last_dim", "=", "sum", "(", "f", "[", "1", "]", "for", "f", "in", "filters", ")", "\n", "\n", "self", ".", "highway", "=", "Highway", "(", "last_dim", ",", "highway_layers", ")", "if", "highway_layers", ">", "0", "else", "None", "\n", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "last_dim", ",", "word_embed_dim", ")", "\n", "\n", "assert", "(", "\n", "vocab", "is", "not", "None", "or", "char_inputs", "\n", ")", ",", "\"vocab must be set if not using char inputs\"", "\n", "self", ".", "vocab", "=", "None", "\n", "if", "vocab", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_vocab", "(", "vocab", ",", "max_char_len", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.prepare_for_onnx_export_": [[64, 66], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.set_vocab": [[67, 92], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "len", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "logger.info", "vocab[].encode", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "set_vocab", "(", "self", ",", "vocab", ",", "max_char_len", ")", ":", "\n", "        ", "word_to_char", "=", "torch", ".", "LongTensor", "(", "len", "(", "vocab", ")", ",", "max_char_len", ")", "\n", "\n", "truncated", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "            ", "if", "i", "<", "vocab", ".", "nspecial", ":", "\n", "                ", "char_idxs", "=", "[", "0", "]", "*", "max_char_len", "\n", "", "else", ":", "\n", "                ", "chars", "=", "vocab", "[", "i", "]", ".", "encode", "(", ")", "\n", "# +1 for padding", "\n", "char_idxs", "=", "[", "c", "+", "1", "for", "c", "in", "chars", "]", "+", "[", "0", "]", "*", "(", "max_char_len", "-", "len", "(", "chars", ")", ")", "\n", "", "if", "len", "(", "char_idxs", ")", ">", "max_char_len", ":", "\n", "                ", "truncated", "+=", "1", "\n", "char_idxs", "=", "char_idxs", "[", ":", "max_char_len", "]", "\n", "", "word_to_char", "[", "i", "]", "=", "torch", ".", "LongTensor", "(", "char_idxs", ")", "\n", "\n", "", "if", "truncated", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"truncated {} words longer than {} characters\"", ".", "format", "(", "\n", "truncated", ",", "max_char_len", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "word_to_char", "=", "word_to_char", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.padding_idx": [[93, 96], ["fairseq.data.Dictionary().pad", "character_token_embedder.CharacterTokenEmbedder.vocab.pad", "fairseq.data.Dictionary"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "Dictionary", "(", ")", ".", "pad", "(", ")", "if", "self", ".", "vocab", "is", "None", "else", "self", ".", "vocab", ".", "pad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.reset_parameters": [[97, 106], ["torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "char_embeddings", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "symbol_embeddings", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "projection", ".", "weight", ")", "\n", "\n", "nn", ".", "init", ".", "constant_", "(", "\n", "self", ".", "char_embeddings", ".", "weight", "[", "self", ".", "char_embeddings", ".", "padding_idx", "]", ",", "0.0", "\n", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "projection", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder.forward": [[107, 154], ["character_token_embedder.CharacterTokenEmbedder._convolve", "torch.where.view", "torch.where.view", "input.view", "chars[].eq", "chars[].eq", "input.view.eq.any", "input.view", "character_token_embedder.CharacterTokenEmbedder.word_to_char[].type_as", "input.view.eq", "input.view.eq", "input.view.eq", "input.view.eq.any", "input.view.eq.any", "input.view.eq.any", "input.view.eq.any", "character_token_embedder.CharacterTokenEmbedder.vocab.pad", "character_token_embedder.CharacterTokenEmbedder.vocab.eos", "character_token_embedder.CharacterTokenEmbedder.vocab.unk", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.any", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.any", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.unsqueeze", "torch.where.new_zeros", "torch.where.new_zeros", "input.view.eq.unsqueeze", "input.view.eq.unsqueeze", "input.size", "input.view.eq.unsqueeze", "torch.where.new_zeros", "torch.where.new_zeros", "input.view.type_as"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder._convolve", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "char_inputs", ":", "\n", "            ", "chars", "=", "input", ".", "view", "(", "-", "1", ",", "self", ".", "max_char_len", ")", "\n", "pads", "=", "chars", "[", ":", ",", "0", "]", ".", "eq", "(", "CHAR_PAD_IDX", ")", "\n", "eos", "=", "chars", "[", ":", ",", "0", "]", ".", "eq", "(", "CHAR_EOS_IDX", ")", "\n", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "if", "self", ".", "onnx_trace", ":", "\n", "                    ", "chars", "=", "torch", ".", "where", "(", "eos", ".", "unsqueeze", "(", "1", ")", ",", "chars", ".", "new_zeros", "(", "1", ")", ",", "chars", ")", "\n", "", "else", ":", "\n", "                    ", "chars", "[", "eos", "]", "=", "0", "\n", "\n", "", "", "unk", "=", "None", "\n", "", "else", ":", "\n", "            ", "flat_words", "=", "input", ".", "view", "(", "-", "1", ")", "\n", "chars", "=", "self", ".", "word_to_char", "[", "flat_words", ".", "type_as", "(", "self", ".", "word_to_char", ")", "]", ".", "type_as", "(", "\n", "input", "\n", ")", "\n", "pads", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "pad", "(", ")", ")", "\n", "eos", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "eos", "(", ")", ")", "\n", "unk", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "unk", "(", ")", ")", "\n", "\n", "", "word_embs", "=", "self", ".", "_convolve", "(", "chars", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "            ", "if", "pads", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "pads", ".", "unsqueeze", "(", "1", ")", ",", "word_embs", ".", "new_zeros", "(", "1", ")", ",", "word_embs", "\n", ")", "\n", "", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "eos", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "symbol_embeddings", "[", "self", ".", "eos_idx", "]", ",", "word_embs", "\n", ")", "\n", "", "if", "unk", "is", "not", "None", "and", "unk", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "unk", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "symbol_embeddings", "[", "self", ".", "unk_idx", "]", ",", "word_embs", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "pads", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "pads", "]", "=", "0", "\n", "", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "eos", "]", "=", "self", ".", "symbol_embeddings", "[", "self", ".", "eos_idx", "]", "\n", "", "if", "unk", "is", "not", "None", "and", "unk", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "unk", "]", "=", "self", ".", "symbol_embeddings", "[", "self", ".", "unk_idx", "]", "\n", "\n", "", "", "return", "word_embs", ".", "view", "(", "input", ".", "size", "(", ")", "[", ":", "2", "]", "+", "(", "-", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.CharacterTokenEmbedder._convolve": [[155, 177], ["character_token_embedder.CharacterTokenEmbedder.char_embeddings", "char_embs.transpose.transpose.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "character_token_embedder.CharacterTokenEmbedder.projection", "conv", "torch.max", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "conv_result.append", "character_token_embedder.CharacterTokenEmbedder.highway"], "methods", ["None"], ["", "def", "_convolve", "(", "\n", "self", ",", "\n", "char_idxs", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "char_embs", "=", "self", ".", "char_embeddings", "(", "char_idxs", ")", "\n", "char_embs", "=", "char_embs", ".", "transpose", "(", "1", ",", "2", ")", "# BTC -> BCT", "\n", "\n", "conv_result", "=", "[", "]", "\n", "\n", "for", "conv", "in", "self", ".", "convolutions", ":", "\n", "            ", "x", "=", "conv", "(", "char_embs", ")", "\n", "x", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "conv_result", ".", "append", "(", "x", ")", "\n", "\n", "", "x", "=", "torch", ".", "cat", "(", "conv_result", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "highway", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "highway", "(", "x", ")", "\n", "", "x", "=", "self", ".", "projection", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.Highway.__init__": [[185, 194], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ReLU", "torch.nn.ReLU", "character_token_embedder.Highway.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "num_layers", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", "Highway", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", "*", "2", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.Highway.reset_parameters": [[195, 206], ["torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "# As per comment in AllenNLP:", "\n", "# We should bias the highway layer to just carry its input forward.  We do that by", "\n", "# setting the bias on `B(x)` to be positive, because that means `g` will be biased to", "\n", "# be high, so we will carry the input forward.  The bias on `B(x)` is the second half", "\n", "# of the bias vector in each Linear layer.", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", "self", ".", "input_dim", ":", "]", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", ":", "self", ".", "input_dim", "]", ",", "0", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "layer", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.character_token_embedder.Highway.forward": [[207, 215], ["layer", "layer.chunk", "character_token_embedder.Highway.activation", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.new_tensor", "torch.sigmoid.new_tensor"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "projection", "=", "layer", "(", "x", ")", "\n", "proj_x", ",", "gate", "=", "projection", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "proj_x", "=", "self", ".", "activation", "(", "proj_x", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "x", "=", "gate", "*", "x", "+", "(", "gate", ".", "new_tensor", "(", "[", "1", "]", ")", "-", "gate", ")", "*", "proj_x", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.__init__": [[24, 58], ["multihead_attention.MultiheadAttention.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "\n", "stride", "=", "32", ",", "\n", "expressivity", "=", "8", ",", "\n", "is_bidirectional", "=", "True", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", ",", "\n", "vdim", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "add_bias_kv", ",", "\n", "add_zero_attn", ",", "\n", "self_attention", ",", "\n", "encoder_decoder_attention", ",", "\n", ")", "\n", "\n", "self", ".", "is_bidirectional", "=", "is_bidirectional", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "expressivity", "=", "expressivity", "\n", "assert", "self", ".", "stride", ">", "0", "and", "self", ".", "stride", ">=", "self", ".", "expressivity", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint": [[60, 70], ["math.floor"], "methods", ["None"], ["", "def", "compute_checkpoint", "(", "self", ",", "word_index", ")", ":", "\n", "        ", "if", "word_index", "%", "self", ".", "stride", "==", "0", "and", "word_index", "!=", "0", ":", "\n", "            ", "checkpoint_index", "=", "word_index", "-", "self", ".", "expressivity", "\n", "", "else", ":", "\n", "            ", "checkpoint_index", "=", "(", "\n", "math", ".", "floor", "(", "word_index", "/", "self", ".", "stride", ")", "*", "self", ".", "stride", "\n", "+", "self", ".", "stride", "\n", "-", "self", ".", "expressivity", "\n", ")", "\n", "", "return", "checkpoint_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries": [[72, 85], ["sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "set", "set", "subset_two.union.union.union", "sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "range", "min"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint"], ["", "def", "compute_subset_summaries", "(", "self", ",", "absolute_max", ")", ":", "\n", "        ", "checkpoint_index", "=", "self", ".", "compute_checkpoint", "(", "0", ")", "\n", "subset_two", "=", "set", "(", ")", "\n", "while", "checkpoint_index", "<=", "absolute_max", "-", "1", ":", "\n", "            ", "summary", "=", "set", "(", "\n", "range", "(", "\n", "checkpoint_index", ",", "\n", "min", "(", "checkpoint_index", "+", "self", ".", "expressivity", "+", "1", ",", "absolute_max", ")", ",", "\n", ")", "\n", ")", "\n", "subset_two", "=", "subset_two", ".", "union", "(", "summary", ")", "\n", "checkpoint_index", "=", "self", ".", "compute_checkpoint", "(", "checkpoint_index", "+", "self", ".", "stride", ")", "\n", "", "return", "subset_two", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset": [[87, 117], ["set", "set.union", "math.floor", "set", "set", "sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "range", "range", "min", "max", "min"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries"], ["", "def", "compute_fixed_attention_subset", "(", "self", ",", "word_index", ",", "tgt_len", ")", ":", "\n", "# +1s account for range function; [min, max) -> [min, max]", "\n", "        ", "if", "not", "self", ".", "is_bidirectional", ":", "\n", "            ", "absolute_max", "=", "word_index", "+", "1", "\n", "", "else", ":", "\n", "            ", "absolute_max", "=", "tgt_len", "\n", "\n", "# Subset 1 - whole window", "\n", "", "rounded_index", "=", "(", "\n", "math", ".", "floor", "(", "(", "word_index", "+", "self", ".", "stride", ")", "/", "self", ".", "stride", ")", "*", "self", ".", "stride", "\n", ")", "\n", "if", "word_index", "%", "self", ".", "stride", "==", "0", "and", "word_index", "!=", "0", ":", "\n", "            ", "subset_one", "=", "set", "(", "\n", "range", "(", "word_index", "-", "self", ".", "stride", ",", "min", "(", "absolute_max", ",", "word_index", "+", "1", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "subset_one", "=", "set", "(", "\n", "range", "(", "\n", "max", "(", "0", ",", "rounded_index", "-", "self", ".", "stride", ")", ",", "\n", "min", "(", "absolute_max", ",", "rounded_index", "+", "1", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# Subset 2 - summary per window", "\n", "# If bidirectional, subset 2 is the same for every index", "\n", "", "subset_two", "=", "set", "(", ")", "\n", "if", "not", "self", ".", "is_bidirectional", ":", "\n", "            ", "subset_two", "=", "self", ".", "compute_subset_summaries", "(", "absolute_max", ")", "\n", "\n", "", "return", "subset_one", ".", "union", "(", "subset_two", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask": [[119, 134], ["torch.empty().float().fill_", "set", "range", "torch.empty().float().fill_.type_as", "float", "sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset", "fixed_attention_subset.union.union.union", "torch.LongTensor", "sparse_mask[].index_fill_", "torch.empty().float", "list", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset"], ["", "def", "buffered_sparse_mask", "(", "self", ",", "tensor", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "        ", "assert", "tgt_len", ">", "self", ".", "stride", "\n", "sparse_mask", "=", "torch", ".", "empty", "(", "(", "tgt_len", ",", "src_len", ")", ")", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "\n", "# If bidirectional, subset 2 is the same for every index", "\n", "subset_summaries", "=", "set", "(", ")", "\n", "if", "self", ".", "is_bidirectional", ":", "\n", "            ", "subset_summaries", "=", "self", ".", "compute_subset_summaries", "(", "tgt_len", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "tgt_len", ")", ":", "\n", "            ", "fixed_attention_subset", "=", "self", ".", "compute_fixed_attention_subset", "(", "i", ",", "tgt_len", ")", "\n", "fixed_attention_subset", "=", "fixed_attention_subset", ".", "union", "(", "subset_summaries", ")", "\n", "included_word_indices", "=", "torch", ".", "LongTensor", "(", "list", "(", "fixed_attention_subset", ")", ")", "\n", "sparse_mask", "[", "i", "]", ".", "index_fill_", "(", "0", ",", "included_word_indices", ",", "0", ")", "\n", "", "return", "sparse_mask", ".", "type_as", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.apply_sparse_mask": [[135, 141], ["sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask", "sparse_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "sparse_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", ":", "\n", "        ", "sparse_mask", "=", "self", ".", "buffered_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ")", "\n", "sparse_mask", "=", "sparse_mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", "\n", "attn_weights", "+=", "sparse_mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.__init__": [[12, 84], ["torch.GELU", "torch.GELU", "torch.GELU", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "isinstance", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "ast.literal_eval", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "len", "torch.Linear", "torch.Linear", "torch.Linear", "gumbel_vector_quantizer.GumbelVectorQuantizer.__init__.block"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "num_vars", ",", "\n", "temp", ",", "\n", "groups", ",", "\n", "combine_groups", ",", "\n", "vq_dim", ",", "\n", "time_first", ",", "\n", "activation", "=", "nn", ".", "GELU", "(", ")", ",", "\n", "weight_proj_depth", "=", "1", ",", "\n", "weight_proj_factor", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Vector quantization using gumbel softmax\n\n        Args:\n            dim: input dimension (channels)\n            num_vars: number of quantized vectors per group\n            temp: temperature for training. this should be a tuple of 3 elements: (start, stop, decay factor)\n            groups: number of groups for vector quantization\n            combine_groups: whether to use the vectors for all groups\n            vq_dim: dimensionality of the resulting quantized vector\n            time_first: if true, expect input in BxTxC format, otherwise in BxCxT\n            activation: what activation to use (should be a module). this is only used if weight_proj_depth is > 1\n            weight_proj_depth: number of layers (with activation in between) to project input before computing logits\n            weight_proj_factor: this is used only if weight_proj_depth is > 1. scales the inner dimensionality of\n                                projections by this factor\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "combine_groups", "=", "combine_groups", "\n", "self", ".", "input_dim", "=", "dim", "\n", "self", ".", "num_vars", "=", "num_vars", "\n", "self", ".", "time_first", "=", "time_first", "\n", "\n", "assert", "(", "\n", "vq_dim", "%", "groups", "==", "0", "\n", ")", ",", "f\"dim {vq_dim} must be divisible by groups {groups} for concatenation\"", "\n", "\n", "var_dim", "=", "vq_dim", "//", "groups", "\n", "num_groups", "=", "groups", "if", "not", "combine_groups", "else", "1", "\n", "\n", "self", ".", "vars", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "num_groups", "*", "num_vars", ",", "var_dim", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "vars", ")", "\n", "\n", "if", "weight_proj_depth", ">", "1", ":", "\n", "\n", "            ", "def", "block", "(", "input_dim", ",", "output_dim", ")", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "activation", ")", "\n", "\n", "", "inner_dim", "=", "self", ".", "input_dim", "*", "weight_proj_factor", "\n", "self", ".", "weight_proj", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "block", "(", "self", ".", "input_dim", "if", "i", "==", "0", "else", "inner_dim", ",", "inner_dim", ")", "\n", "for", "i", "in", "range", "(", "weight_proj_depth", "-", "1", ")", "\n", "]", ",", "\n", "nn", ".", "Linear", "(", "inner_dim", ",", "groups", "*", "num_vars", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_proj", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "groups", "*", "num_vars", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight_proj", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "1", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "weight_proj", ".", "bias", ")", "\n", "\n", "", "if", "isinstance", "(", "temp", ",", "str", ")", ":", "\n", "            ", "import", "ast", "\n", "temp", "=", "ast", ".", "literal_eval", "(", "temp", ")", "\n", "", "assert", "len", "(", "temp", ")", "==", "3", ",", "f\"{temp}, {len(temp)}\"", "\n", "\n", "self", ".", "max_temp", ",", "self", ".", "min_temp", ",", "self", ".", "temp_decay", "=", "temp", "\n", "self", ".", "curr_temp", "=", "self", ".", "max_temp", "\n", "self", ".", "codebook_indices", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.set_num_updates": [[85, 88], ["max"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "self", ".", "curr_temp", "=", "max", "(", "\n", "self", ".", "max_temp", "*", "self", ".", "temp_decay", "**", "num_updates", ",", "self", ".", "min_temp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices": [[90, 108], ["list", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "product", "gumbel_vector_quantizer.GumbelVectorQuantizer.codebook_indices.view", "range", "gumbel_vector_quantizer.GumbelVectorQuantizer.codebook_indices.flatten", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_codebook_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "codebook_indices", "is", "None", ":", "\n", "            ", "from", "itertools", "import", "product", "\n", "\n", "p", "=", "[", "range", "(", "self", ".", "num_vars", ")", "]", "*", "self", ".", "groups", "\n", "inds", "=", "list", "(", "product", "(", "*", "p", ")", ")", "\n", "self", ".", "codebook_indices", "=", "torch", ".", "tensor", "(", "\n", "inds", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "vars", ".", "device", "\n", ")", ".", "flatten", "(", ")", "\n", "\n", "if", "not", "self", ".", "combine_groups", ":", "\n", "                ", "self", ".", "codebook_indices", "=", "self", ".", "codebook_indices", ".", "view", "(", "\n", "self", ".", "num_vars", "**", "self", ".", "groups", ",", "-", "1", "\n", ")", "\n", "for", "b", "in", "range", "(", "1", ",", "self", ".", "groups", ")", ":", "\n", "                    ", "self", ".", "codebook_indices", "[", ":", ",", "b", "]", "+=", "self", ".", "num_vars", "*", "b", "\n", "", "self", ".", "codebook_indices", "=", "self", ".", "codebook_indices", ".", "flatten", "(", ")", "\n", "", "", "return", "self", ".", "codebook_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.codebook": [[109, 115], ["gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select().view", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices"], ["", "def", "codebook", "(", "self", ")", ":", "\n", "        ", "indices", "=", "self", ".", "get_codebook_indices", "(", ")", "\n", "return", "(", "\n", "self", ".", "vars", ".", "squeeze", "(", "0", ")", "\n", ".", "index_select", "(", "0", ",", "indices", ")", "\n", ".", "view", "(", "self", ".", "num_vars", "**", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.sample_from_codebook": [[117, 129], ["gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "indices.view.view.view", "indices.view.view.size", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select().view", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select", "indices.view.view.flatten", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "sample_from_codebook", "(", "self", ",", "b", ",", "n", ")", ":", "\n", "        ", "indices", "=", "self", ".", "get_codebook_indices", "(", ")", "\n", "indices", "=", "indices", ".", "view", "(", "-", "1", ",", "self", ".", "groups", ")", "\n", "cb_size", "=", "indices", ".", "size", "(", "0", ")", "\n", "assert", "(", "\n", "n", "<", "cb_size", "\n", ")", ",", "f\"sample size {n} is greater than size of codebook {cb_size}\"", "\n", "sample_idx", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "cb_size", ",", "size", "=", "(", "b", "*", "n", ",", ")", ")", "\n", "indices", "=", "indices", "[", "sample_idx", "]", "\n", "\n", "z", "=", "self", ".", "vars", ".", "squeeze", "(", "0", ")", ".", "index_select", "(", "0", ",", "indices", ".", "flatten", "(", ")", ")", ".", "view", "(", "b", ",", "n", ",", "-", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.to_codebook_index": [[130, 136], ["indices.new_full", "range"], "methods", ["None"], ["", "def", "to_codebook_index", "(", "self", ",", "indices", ")", ":", "\n", "        ", "res", "=", "indices", ".", "new_full", "(", "indices", ".", "shape", "[", ":", "-", "1", "]", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "groups", ")", ":", "\n", "            ", "exponent", "=", "self", ".", "groups", "-", "i", "-", "1", "\n", "res", "+=", "indices", "[", "...", ",", "i", "]", "*", "(", "self", ".", "num_vars", "**", "exponent", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.forward_idx": [[137, 140], ["gumbel_vector_quantizer.GumbelVectorQuantizer.forward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "def", "forward_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "x", ",", "produce_targets", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"targets\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.forward": [[141, 203], ["x.transpose.transpose.reshape", "gumbel_vector_quantizer.GumbelVectorQuantizer.weight_proj", "x.transpose.transpose.view", "x.transpose.transpose.max", "x.transpose.transpose.new_zeros().scatter_().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "x.transpose.transpose.view", "x.transpose.transpose.view", "x.transpose.transpose.sum", "x.transpose.transpose.view", "x.transpose.transpose.transpose", "x.transpose.new_zeros().scatter_().view.float", "torch.gumbel_softmax().type_as", "torch.gumbel_softmax().type_as", "torch.gumbel_softmax().type_as", "vars.repeat.repeat.repeat", "x.transpose.transpose.view().argmax().view().detach", "x.transpose.transpose.unsqueeze", "x.transpose.transpose.transpose", "x.transpose.transpose.new_zeros().scatter_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "k.view", "x.transpose.transpose.view().float", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "x.transpose.transpose.view().argmax().view", "x.transpose.transpose.new_zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.transpose.transpose.float", "x.transpose.transpose.view", "x.transpose.transpose.view().argmax", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "x.transpose.transpose.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "forward", "(", "self", ",", "x", ",", "produce_targets", "=", "False", ")", ":", "\n", "\n", "        ", "result", "=", "{", "\"num_vars\"", ":", "self", ".", "num_vars", "*", "self", ".", "groups", "}", "\n", "\n", "if", "not", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "bsz", ",", "tsz", ",", "fsz", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "-", "1", ",", "fsz", ")", "\n", "x", "=", "self", ".", "weight_proj", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "-", "1", ")", "\n", "\n", "_", ",", "k", "=", "x", ".", "max", "(", "-", "1", ")", "\n", "hard_x", "=", "(", "\n", "x", ".", "new_zeros", "(", "*", "x", ".", "shape", ")", "\n", ".", "scatter_", "(", "-", "1", ",", "k", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n", "hard_probs", "=", "torch", ".", "mean", "(", "hard_x", ".", "float", "(", ")", ",", "dim", "=", "0", ")", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "hard_probs", "*", "torch", ".", "log", "(", "hard_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "avg_probs", "=", "torch", ".", "softmax", "(", "\n", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", ".", "float", "(", ")", ",", "dim", "=", "-", "1", "\n", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "result", "[", "\"prob_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "avg_probs", "*", "torch", ".", "log", "(", "avg_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "result", "[", "\"temp\"", "]", "=", "self", ".", "curr_temp", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "x", "=", "F", ".", "gumbel_softmax", "(", "x", ".", "float", "(", ")", ",", "tau", "=", "self", ".", "curr_temp", ",", "hard", "=", "True", ")", ".", "type_as", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "hard_x", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "-", "1", ")", "\n", "\n", "vars", "=", "self", ".", "vars", "\n", "if", "self", ".", "combine_groups", ":", "\n", "            ", "vars", "=", "vars", ".", "repeat", "(", "1", ",", "self", ".", "groups", ",", "1", ")", "\n", "\n", "", "if", "produce_targets", ":", "\n", "            ", "result", "[", "\"targets\"", "]", "=", "(", "\n", "x", ".", "view", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "-", "1", ")", "\n", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", ".", "view", "(", "bsz", ",", "tsz", ",", "self", ".", "groups", ")", "\n", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "*", "vars", "\n", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "self", ".", "num_vars", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "sum", "(", "-", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "bsz", ",", "tsz", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# BTC -> BCT", "\n", "\n", "", "result", "[", "\"x\"", "]", "=", "x", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_transformer_sentence_encoder_layer.SparseTransformerSentenceEncoderLayer.__init__": [[15, 51], ["fairseq.modules.TransformerSentenceEncoderLayer.__init__", "fairseq.modules.sparse_multihead_attention.SparseMultiheadAttention"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "is_bidirectional", ":", "bool", "=", "True", ",", "\n", "stride", ":", "int", "=", "32", ",", "\n", "expressivity", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "activation_fn", ",", "\n", "export", ",", "\n", ")", "\n", "\n", "self", ".", "self_attn", "=", "SparseMultiheadAttention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "True", ",", "\n", "is_bidirectional", "=", "is_bidirectional", ",", "\n", "stride", "=", "stride", ",", "\n", "expressivity", "=", "expressivity", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.__init__": [[21, 31], ["torch.nn.Module.__init__", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.register_buffer", "int", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "padding_idx", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "if", "padding_idx", "is", "not", "None", "else", "0", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "embedding_dim", ",", "padding_idx", "\n", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "self", ".", "max_positions", "=", "int", "(", "1e5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.prepare_for_onnx_export_": [[32, 34], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding": [[35, 59], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "\n", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "\n", "1", "\n", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "\n", "num_embeddings", ",", "-", "1", "\n", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "emb", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.forward": [[60, 104], ["torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.to", "fairseq.utils.make_positions", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view().detach", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights[].expand", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach().index_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.size", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().repeat", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach", "bsz.view", "seq_len.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "timestep.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input", ",", "\n", "incremental_state", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "timestep", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "positions", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "bspair", "=", "torch", ".", "onnx", ".", "operators", ".", "shape_as_tensor", "(", "input", ")", "\n", "bsz", ",", "seq_len", "=", "bspair", "[", "0", "]", ",", "bspair", "[", "1", "]", "\n", "max_pos", "=", "self", ".", "padding_idx", "+", "1", "+", "seq_len", "\n", "if", "self", ".", "weights", "is", "None", "or", "max_pos", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "max_pos", ",", "self", ".", "embedding_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "", "self", ".", "weights", "=", "self", ".", "weights", ".", "to", "(", "self", ".", "_float_tensor", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "            ", "pos", "=", "timestep", ".", "view", "(", "-", "1", ")", "[", "0", "]", "+", "1", "if", "timestep", "is", "not", "None", "else", "seq_len", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "return", "(", "\n", "self", ".", "weights", ".", "index_select", "(", "index", "=", "self", ".", "padding_idx", "+", "pos", ",", "dim", "=", "0", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "repeat", "(", "bsz", ",", "1", ",", "1", ")", "\n", ")", "\n", "", "return", "self", ".", "weights", "[", "self", ".", "padding_idx", "+", "pos", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "positions", "=", "utils", ".", "make_positions", "(", "\n", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "            ", "flat_embeddings", "=", "self", ".", "weights", ".", "detach", "(", ")", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", "embedding_shape", "=", "torch", ".", "cat", "(", "\n", "(", "bsz", ".", "view", "(", "1", ")", ",", "seq_len", ".", "view", "(", "1", ")", ",", "torch", ".", "tensor", "(", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", ")", "\n", "embeddings", "=", "torch", ".", "onnx", ".", "operators", ".", "reshape_from_tensor_shape", "(", "\n", "flat_embeddings", ",", "embedding_shape", "\n", ")", "\n", "return", "embeddings", "\n", "", "return", "(", "\n", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", ".", "view", "(", "bsz", ",", "seq_len", ",", "-", "1", ")", "\n", ".", "detach", "(", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.Fp32LayerNorm.__init__": [[39, 41], ["torch.LayerNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.Fp32LayerNorm.forward": [[42, 51], ["torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm.type_as", "input.float", "layer_norm.Fp32LayerNorm.weight.float", "layer_norm.Fp32LayerNorm.bias.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "F", ".", "layer_norm", "(", "\n", "input", ".", "float", "(", ")", ",", "\n", "self", ".", "normalized_shape", ",", "\n", "self", ".", "weight", ".", "float", "(", ")", "if", "self", ".", "weight", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "bias", ".", "float", "(", ")", "if", "self", ".", "bias", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "eps", ",", "\n", ")", "\n", "return", "output", ".", "type_as", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm": [[30, 36], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "FusedLayerNorm"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["", "def", "LayerNorm", "(", "normalized_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ",", "export", "=", "False", ")", ":", "\n", "    ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "export", "=", "True", "\n", "", "if", "not", "export", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "has_fused_layernorm", ":", "\n", "        ", "return", "FusedLayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", "return", "torch", ".", "nn", ".", "LayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1d.__init__": [[73, 99], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "fairseq.modules.fairseq_dropout.FairseqDropout", "lightweight_convolution.LightweightConv1d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1d.reset_parameters": [[100, 104], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1d.forward": [[105, 129], ["input.view.view.size", "lightweight_convolution.LightweightConv1d.weight_dropout_module", "input.view.view.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "output.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "lightweight_convolution.LightweightConv1d.bias.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        input size: B x C x T\n        output size: B x C x T\n        \"\"\"", "\n", "B", ",", "C", ",", "T", "=", "input", ".", "size", "(", ")", "\n", "H", "=", "self", ".", "num_heads", "\n", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "# Merge every C/H entries into the batch dimension (C = self.input_size)", "\n", "# B x C x T -> (B * C/H) x H x T", "\n", "# One can also expand the weight to C x 1 x K by a factor of C/H", "\n", "# and do not reshape the input instead, which is slow though", "\n", "input", "=", "input", ".", "view", "(", "-", "1", ",", "H", ",", "T", ")", "\n", "output", "=", "F", ".", "conv1d", "(", "input", ",", "weight", ",", "padding", "=", "self", ".", "padding", ",", "groups", "=", "self", ".", "num_heads", ")", "\n", "output", "=", "output", ".", "view", "(", "B", ",", "C", ",", "T", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.__init__": [[153, 181], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lightweight_convolution.LightweightConv1dTBC.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.reset_parameters": [[182, 186], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.forward": [[187, 204], ["lightweight_convolution.LightweightConv1dTBC._forward_unfolded", "lightweight_convolution.LightweightConv1dTBC._forward_expanded", "lightweight_convolution.LightweightConv1dTBC.bias.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "unfold", "=", "False", ")", ":", "\n", "        ", "\"\"\"Assuming the input, x, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            x: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n        \"\"\"", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "\n", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ")", "\n", "\n", "", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.prepare_for_onnx_export_": [[205, 207], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC._forward_unfolded": [[208, 249], ["x.size", "lightweight_convolution.LightweightConv1dTBC.weight.view", "fairseq.utils.softmax().type_as.view().expand().contiguous().view", "lightweight_convolution.LightweightConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "lightweight_convolution.LightweightConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "fairseq.modules.unfold.unfold1d", "x_unfold.view.view.view", "fairseq.utils.softmax().type_as", "fairseq.utils.softmax().type_as.size", "x.new", "lightweight_convolution.LightweightConv1dTBC._set_input_buffer", "fairseq.utils.softmax().type_as.view().expand().contiguous", "x.unsqueeze", "fairseq.utils.softmax", "fairseq.utils.softmax().type_as.view().expand", "x_unfold.view.view.size", "fairseq.utils.softmax().type_as.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "            ", "x_unfold", "=", "unfold1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "utils", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", ".", "type_as", "(", "\n", "weight", "\n", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "weight", "=", "(", "\n", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "K", ",", "1", ")", "\n", ")", "\n", "\n", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC._forward_expanded": [[250, 284], ["x.view().transpose.view().transpose.size", "lightweight_convolution.LightweightConv1dTBC.weight.view", "weight.narrow.narrow.view().expand().contiguous", "weight.narrow.narrow.view().transpose", "x.view().transpose.view().transpose.view().transpose", "weight.narrow.narrow.new_zeros", "lightweight_convolution.LightweightConv1dTBC.as_strided().copy_", "lightweight_convolution.LightweightConv1dTBC.narrow", "lightweight_convolution.LightweightConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "fairseq.utils.softmax().type_as", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view().expand", "weight.narrow.narrow.view", "x.view().transpose.view().transpose.view", "lightweight_convolution.LightweightConv1dTBC.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "fairseq.utils.softmax", "weight.narrow.narrow.view", "output.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "utils", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", ".", "type_as", "(", "\n", "weight", "\n", ")", "\n", "", "weight", "=", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "P", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "            ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", ")", ".", "copy_", "(", "\n", "weight", "\n", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.reorder_incremental_state": [[285, 290], ["lightweight_convolution.LightweightConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "lightweight_convolution.LightweightConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC._get_input_buffer": [[291, 293], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC._set_input_buffer": [[294, 297], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv1dTBC.extra_repr": [[299, 311], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, bias={}\"", ".", "format", "(", "\n", "self", ".", "input_size", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "\n", "self", ".", "weight_softmax", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", ")", "\n", "if", "self", ".", "weight_dropout_module", ".", "p", ">", "0.0", ":", "\n", "            ", "s", "+=", "\", weight_dropout={}\"", ".", "format", "(", "self", ".", "weight_dropout_module", ".", "p", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.lightweight_convolution.LightweightConv": [[15, 47], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "lightweight_convolution.LightweightConv1dTBC", "LightconvLayer", "print"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print"], ["def", "LightweightConv", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "modules", ".", "lightconv_layer", "import", "LightconvLayer", "\n", "\n", "return", "LightconvLayer", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "", "", "return", "LightweightConv1dTBC", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.fairseq_dropout.FairseqDropout.__init__": [[17, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "p", ",", "module_name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "module_name", "=", "module_name", "\n", "self", ".", "apply_during_inference", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.fairseq_dropout.FairseqDropout.forward": [[23, 28], ["torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "training", "or", "self", ".", "apply_during_inference", ":", "\n", "            ", "return", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "p", ",", "training", "=", "True", ",", "inplace", "=", "inplace", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.fairseq_dropout.FairseqDropout.make_generation_fast_": [[29, 52], ["logger.warning", "logger.info", "logger.info"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "retain_dropout", ":", "bool", "=", "False", ",", "\n", "retain_dropout_modules", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "if", "retain_dropout", ":", "\n", "            ", "if", "retain_dropout_modules", "is", "not", "None", "and", "self", ".", "module_name", "is", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"Cannot enable dropout during inference for module {} \"", "\n", "\"because module_name was not set\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "", "elif", "(", "\n", "retain_dropout_modules", "is", "None", "# if None, apply to all modules", "\n", "or", "self", ".", "module_name", "in", "retain_dropout_modules", "\n", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Enabling dropout during inference for module: {}\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "self", ".", "apply_during_inference", "=", "True", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"Disabling dropout for module: {}\"", ".", "format", "(", "name", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.scalar_bias.ScalarBias.forward": [[16, 24], ["list", "input.new().fill_", "input.new().fill_.narrow().copy_", "input.size", "input.new", "input.new().fill_.narrow"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", ",", "bias_init", ")", ":", "\n", "        ", "size", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "size", "[", "dim", "]", "+=", "1", "\n", "output", "=", "input", ".", "new", "(", "*", "size", ")", ".", "fill_", "(", "bias_init", ")", "\n", "output", ".", "narrow", "(", "dim", ",", "1", ",", "size", "[", "dim", "]", "-", "1", ")", ".", "copy_", "(", "input", ")", "\n", "ctx", ".", "dim", "=", "dim", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.scalar_bias.ScalarBias.backward": [[25, 28], ["grad.narrow", "grad.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "grad", ".", "narrow", "(", "ctx", ".", "dim", ",", "1", ",", "grad", ".", "size", "(", "ctx", ".", "dim", ")", "-", "1", ")", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.scalar_bias.scalar_bias": [[30, 32], ["ScalarBias.apply"], "function", ["None"], ["", "", "def", "scalar_bias", "(", "input", ",", "dim", ",", "bias_init", "=", "0", ")", ":", "\n", "    ", "return", "ScalarBias", ".", "apply", "(", "input", ",", "dim", ",", "bias_init", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution.__init__": [[26, 30], ["conv_tbc.ConvTBC.__init__", "linearized_convolution.LinearizedConvolution.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "self", ".", "_linearized_weight", "=", "None", "\n", "self", ".", "register_backward_hook", "(", "self", ".", "_clear_linearized_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution.state_dict": [[31, 37], ["conv_tbc.ConvTBC.state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "\"\"", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "state", "=", "ConvTBC", ".", "state_dict", "(", "self", ",", "destination", ",", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "\n", "# don't store redundant _linearized_weight in checkpoints", "\n", "if", "prefix", "+", "\"_linearized_weight\"", "in", "state", ":", "\n", "            ", "del", "state", "[", "prefix", "+", "\"_linearized_weight\"", "]", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution.upgrade_state_dict_named": [[38, 42], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "if", "prefix", "+", "\"_linearized_weight\"", "in", "state_dict", ":", "\n", "            ", "del", "state_dict", "[", "prefix", "+", "\"_linearized_weight\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution.forward": [[43, 81], ["linearized_convolution.LinearizedConvolution._get_linearized_weight", "input.size", "torch.linear.view", "linearized_convolution.LinearizedConvolution.conv_tbc", "linearized_convolution.LinearizedConvolution._get_input_buffer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.linear", "torch.linear", "input.new().zero_", "linearized_convolution.LinearizedConvolution._set_input_buffer", "input_buffer[].clone", "input.view", "input.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution._get_linearized_weight", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.conv_tbc.ConvTBC.conv_tbc", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            incremental_state: Used to buffer signal; if not None, then input is\n                expected to contain a single frame. If the input order changes\n                between time steps, call reorder_incremental_state.\n        Input:\n            Time x Batch x Channel during training\n            Batch x Time x Channel during inference\n        \"\"\"", "\n", "if", "incremental_state", "is", "None", ":", "\n", "            ", "output", "=", "self", ".", "conv_tbc", "(", "input", ")", "\n", "if", "self", ".", "kernel_size", "[", "0", "]", ">", "1", "and", "self", ".", "padding", "[", "0", "]", ">", "0", ":", "\n", "# remove future timesteps added by padding", "\n", "                ", "output", "=", "output", "[", ":", "-", "self", ".", "padding", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "", "return", "output", "\n", "\n", "# reshape weight", "\n", "", "weight", "=", "self", ".", "_get_linearized_weight", "(", ")", "\n", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "\n", "bsz", "=", "input", ".", "size", "(", "0", ")", "# input: bsz x len x dim", "\n", "if", "kw", ">", "1", ":", "\n", "            ", "input", "=", "input", ".", "data", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "input", ".", "new", "(", "bsz", ",", "kw", ",", "input", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "", "else", ":", "\n", "# shift buffer", "\n", "                ", "input_buffer", "[", ":", ",", ":", "-", "1", ",", ":", "]", "=", "input_buffer", "[", ":", ",", "1", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "# append next input", "\n", "", "input_buffer", "[", ":", ",", "-", "1", ",", ":", "]", "=", "input", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "input", "=", "input_buffer", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "F", ".", "linear", "(", "input", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "weight", ",", "self", ".", "bias", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution.reorder_incremental_state": [[82, 88], ["linearized_convolution.LinearizedConvolution._get_input_buffer", "input_buffer.index_select.index_select.index_select", "linearized_convolution.LinearizedConvolution._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution._get_input_buffer": [[89, 92], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution._set_input_buffer": [[93, 97], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution._get_linearized_weight": [[99, 107], ["linearized_convolution.LinearizedConvolution.weight.transpose().transpose().contiguous", "linearized_convolution.LinearizedConvolution.view", "linearized_convolution.LinearizedConvolution.size", "linearized_convolution.LinearizedConvolution.weight.transpose().transpose", "linearized_convolution.LinearizedConvolution.weight.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "_get_linearized_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_linearized_weight", "is", "None", ":", "\n", "            ", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "kw", ",", "self", ".", "in_channels", ")", "\n", "return", "weight", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "", "return", "self", ".", "_linearized_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.linearized_convolution.LinearizedConvolution._clear_linearized_weight": [[108, 111], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "_clear_linearized_weight", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_linearized_weight", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise": [[10, 108], ["isinstance", "module.register_forward_pre_hook", "mask.unsqueeze().unsqueeze().repeat.to", "module.weight.size", "weight.size", "weight.size", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave().view", "weight.masked_fill", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave().view", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.unsqueeze().unsqueeze().repeat", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave", "int", "weight.size", "weight.size", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave", "mask.unsqueeze().unsqueeze().repeat.unsqueeze().unsqueeze", "mask.unsqueeze().unsqueeze().repeat.unsqueeze"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["def", "quant_noise", "(", "module", ",", "p", ",", "block_size", ")", ":", "\n", "    ", "\"\"\"\n    Wraps modules and applies quantization noise to the weights for\n    subsequent quantization with Iterative Product Quantization as\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\n\n    Args:\n        - module: nn.Module\n        - p: amount of Quantization Noise\n        - block_size: size of the blocks for subsequent quantization with iPQ\n\n    Remarks:\n        - Module weights must have the right sizes wrt the block size\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\n        - For more detail on how to quantize by blocks with convolutional weights,\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\n        - We implement the simplest form of noise here as stated in the paper\n          which consists in randomly dropping blocks\n    \"\"\"", "\n", "\n", "# if no quantization noise, don't register hook", "\n", "if", "p", "<=", "0", ":", "\n", "        ", "return", "module", "\n", "\n", "# supported modules", "\n", "", "assert", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "nn", ".", "Conv2d", ")", ")", "\n", "\n", "# test whether module.weight has the right sizes wrt block_size", "\n", "is_conv", "=", "module", ".", "weight", ".", "ndim", "==", "4", "\n", "\n", "# 2D matrix", "\n", "if", "not", "is_conv", ":", "\n", "        ", "assert", "(", "\n", "module", ".", "weight", ".", "size", "(", "1", ")", "%", "block_size", "==", "0", "\n", ")", ",", "\"Input features must be a multiple of block sizes\"", "\n", "\n", "# 4D matrix", "\n", "", "else", ":", "\n", "# 1x1 convolutions", "\n", "        ", "if", "module", ".", "kernel_size", "==", "(", "1", ",", "1", ")", ":", "\n", "            ", "assert", "(", "\n", "module", ".", "in_channels", "%", "block_size", "==", "0", "\n", ")", ",", "\"Input channels must be a multiple of block sizes\"", "\n", "# regular convolutions", "\n", "", "else", ":", "\n", "            ", "k", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "\n", "assert", "k", "%", "block_size", "==", "0", ",", "\"Kernel size must be a multiple of block size\"", "\n", "\n", "", "", "def", "_forward_pre_hook", "(", "mod", ",", "input", ")", ":", "\n", "# no noise for evaluation", "\n", "        ", "if", "mod", ".", "training", ":", "\n", "            ", "if", "not", "is_conv", ":", "\n", "# gather weight and sizes", "\n", "                ", "weight", "=", "mod", ".", "weight", "\n", "in_features", "=", "weight", ".", "size", "(", "1", ")", "\n", "out_features", "=", "weight", ".", "size", "(", "0", ")", "\n", "\n", "# split weight matrix into blocks and randomly drop selected blocks", "\n", "mask", "=", "torch", ".", "zeros", "(", "\n", "in_features", "//", "block_size", "*", "out_features", ",", "device", "=", "weight", ".", "device", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "mask", ".", "repeat_interleave", "(", "block_size", ",", "-", "1", ")", ".", "view", "(", "-", "1", ",", "in_features", ")", "\n", "\n", "", "else", ":", "\n", "# gather weight and sizes", "\n", "                ", "weight", "=", "mod", ".", "weight", "\n", "in_channels", "=", "mod", ".", "in_channels", "\n", "out_channels", "=", "mod", ".", "out_channels", "\n", "\n", "# split weight matrix into blocks and randomly drop selected blocks", "\n", "if", "mod", ".", "kernel_size", "==", "(", "1", ",", "1", ")", ":", "\n", "                    ", "mask", "=", "torch", ".", "zeros", "(", "\n", "int", "(", "in_channels", "//", "block_size", "*", "out_channels", ")", ",", "\n", "device", "=", "weight", ".", "device", ",", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "mask", ".", "repeat_interleave", "(", "block_size", ",", "-", "1", ")", ".", "view", "(", "-", "1", ",", "in_channels", ")", "\n", "", "else", ":", "\n", "                    ", "mask", "=", "torch", ".", "zeros", "(", "\n", "weight", ".", "size", "(", "0", ")", ",", "weight", ".", "size", "(", "1", ")", ",", "device", "=", "weight", ".", "device", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "(", "\n", "mask", ".", "unsqueeze", "(", "2", ")", "\n", ".", "unsqueeze", "(", "3", ")", "\n", ".", "repeat", "(", "1", ",", "1", ",", "mod", ".", "kernel_size", "[", "0", "]", ",", "mod", ".", "kernel_size", "[", "1", "]", ")", "\n", ")", "\n", "\n", "# scale weights and apply mask", "\n", "", "", "mask", "=", "mask", ".", "to", "(", "\n", "torch", ".", "bool", "\n", ")", "# x.bool() is not currently supported in TorchScript", "\n", "s", "=", "1", "/", "(", "1", "-", "p", ")", "\n", "mod", ".", "weight", ".", "data", "=", "s", "*", "weight", ".", "masked_fill", "(", "mask", ",", "0", ")", "\n", "\n", "", "", "module", ".", "register_forward_pre_hook", "(", "_forward_pre_hook", ")", "\n", "return", "module", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock.VGGBlock.__init__": [[60, 111], ["super().__init__", "vggblock._pair", "vggblock._pair", "vggblock._pair", "torch.ModuleList", "torch.ModuleList", "range", "tuple", "vggblock._pair", "torch.Conv2d", "torch.Conv2d", "vggblock.VGGBlock.layers.append", "vggblock.VGGBlock.layers.append", "torch.MaxPool2d", "torch.MaxPool2d", "vggblock.VGGBlock.layers.append", "vggblock.infer_conv_output_dim", "vggblock.infer_conv_output_dim", "vggblock.VGGBlock.layers.append", "torch.ReLU", "torch.ReLU", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock.infer_conv_output_dim", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock.infer_conv_output_dim", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "conv_kernel_size", ",", "\n", "pooling_kernel_size", ",", "\n", "num_conv_layers", ",", "\n", "input_dim", ",", "\n", "conv_stride", "=", "1", ",", "\n", "padding", "=", "None", ",", "\n", "layer_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "(", "\n", "input_dim", "is", "not", "None", "\n", ")", ",", "\"Need input_dim for LayerNorm and infer_conv_output_dim\"", "\n", "super", "(", "VGGBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "conv_kernel_size", "=", "_pair", "(", "conv_kernel_size", ")", "\n", "self", ".", "pooling_kernel_size", "=", "_pair", "(", "pooling_kernel_size", ")", "\n", "self", ".", "num_conv_layers", "=", "num_conv_layers", "\n", "self", ".", "padding", "=", "(", "\n", "tuple", "(", "e", "//", "2", "for", "e", "in", "self", ".", "conv_kernel_size", ")", "\n", "if", "padding", "is", "None", "\n", "else", "_pair", "(", "padding", ")", "\n", ")", "\n", "self", ".", "conv_stride", "=", "_pair", "(", "conv_stride", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "num_conv_layers", ")", ":", "\n", "            ", "conv_op", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "if", "layer", "==", "0", "else", "out_channels", ",", "\n", "out_channels", ",", "\n", "self", ".", "conv_kernel_size", ",", "\n", "stride", "=", "self", ".", "conv_stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", ")", "\n", "self", ".", "layers", ".", "append", "(", "conv_op", ")", "\n", "if", "layer_norm", ":", "\n", "                ", "conv_output_dim", ",", "per_channel_dim", "=", "infer_conv_output_dim", "(", "\n", "conv_op", ",", "input_dim", ",", "in_channels", "if", "layer", "==", "0", "else", "out_channels", "\n", ")", "\n", "self", ".", "layers", ".", "append", "(", "nn", ".", "LayerNorm", "(", "per_channel_dim", ")", ")", "\n", "input_dim", "=", "per_channel_dim", "\n", "", "self", ".", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "pooling_kernel_size", "is", "not", "None", ":", "\n", "            ", "pool_op", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "self", ".", "pooling_kernel_size", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "layers", ".", "append", "(", "pool_op", ")", "\n", "self", ".", "total_output_dim", ",", "self", ".", "output_dim", "=", "infer_conv_output_dim", "(", "\n", "pool_op", ",", "input_dim", ",", "out_channels", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock.VGGBlock.forward": [[113, 117], ["enumerate"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "layers", "[", "i", "]", "(", "x", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair": [[15, 20], ["isinstance", "tuple", "itertools.repeat", "len"], "function", ["None"], ["def", "_pair", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "Iterable", ")", ":", "\n", "        ", "assert", "len", "(", "v", ")", "==", "2", ",", "\"len(v) != 2\"", "\n", "return", "v", "\n", "", "return", "tuple", "(", "repeat", "(", "v", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock.infer_conv_output_dim": [[22, 36], ["torch.randn", "torch.randn", "conv_op", "x.transpose.transpose", "x.transpose.size", "x.transpose.size", "x.transpose.contiguous().view().size", "x.transpose.contiguous().view", "x.transpose.contiguous"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "infer_conv_output_dim", "(", "conv_op", ",", "input_dim", ",", "sample_inchannel", ")", ":", "\n", "    ", "sample_seq_len", "=", "200", "\n", "sample_bsz", "=", "10", "\n", "x", "=", "torch", ".", "randn", "(", "sample_bsz", ",", "sample_inchannel", ",", "sample_seq_len", ",", "input_dim", ")", "\n", "# N x C x H x W", "\n", "# N: sample_bsz, C: sample_inchannel, H: sample_seq_len, W: input_dim", "\n", "x", "=", "conv_op", "(", "x", ")", "\n", "# N x C x H x W", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# N x H x C x W", "\n", "bsz", ",", "seq", "=", "x", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "per_channel_dim", "=", "x", ".", "size", "(", ")", "[", "3", "]", "\n", "# bsz: N, seq: H, CxW the rest", "\n", "return", "x", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "seq", ",", "-", "1", ")", ".", "size", "(", "-", "1", ")", ",", "per_channel_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder.TransformerSentenceEncoder.__init__": [[73, 192], ["torch.Module.__init__", "fairseq.modules.FairseqDropout", "transformer_sentence_encoder.TransformerSentenceEncoder.build_embedding", "transformer_sentence_encoder.TransformerSentenceEncoder.layers.extend", "range", "fairseq.modules.quant_noise.quant_noise", "torch.Embedding", "torch.Embedding", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm", "fairseq.modules.LayerDropModuleList", "torch.ModuleList", "torch.ModuleList", "transformer_sentence_encoder.TransformerSentenceEncoder.apply", "transformer_sentence_encoder.TransformerSentenceEncoder.__init__.freeze_module_params"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.positional_embedding.PositionalEmbedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "padding_idx", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "num_encoder_layers", ":", "int", "=", "6", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "layerdrop", ":", "float", "=", "0.0", ",", "\n", "max_seq_len", ":", "int", "=", "256", ",", "\n", "num_segments", ":", "int", "=", "2", ",", "\n", "use_position_embeddings", ":", "bool", "=", "True", ",", "\n", "offset_positions_by_padding", ":", "bool", "=", "True", ",", "\n", "encoder_normalize_before", ":", "bool", "=", "False", ",", "\n", "apply_bert_init", ":", "bool", "=", "False", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "learned_pos_embedding", ":", "bool", "=", "True", ",", "\n", "embed_scale", ":", "float", "=", "None", ",", "\n", "freeze_embeddings", ":", "bool", "=", "False", ",", "\n", "n_trans_layers_to_freeze", ":", "int", "=", "0", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "traceable", ":", "bool", "=", "False", ",", "\n", "q_noise", ":", "float", "=", "0.0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "layerdrop", "=", "layerdrop", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "use_position_embeddings", "=", "use_position_embeddings", "\n", "self", ".", "apply_bert_init", "=", "apply_bert_init", "\n", "self", ".", "learned_pos_embedding", "=", "learned_pos_embedding", "\n", "self", ".", "traceable", "=", "traceable", "\n", "\n", "self", ".", "embed_tokens", "=", "self", ".", "build_embedding", "(", "\n", "self", ".", "vocab_size", ",", "self", ".", "embedding_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "self", ".", "embed_scale", "=", "embed_scale", "\n", "\n", "if", "q_noise", ">", "0", ":", "\n", "            ", "self", ".", "quant_noise", "=", "apply_quant_noise_", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", ",", "self", ".", "embedding_dim", ",", "bias", "=", "False", ")", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "quant_noise", "=", "None", "\n", "\n", "", "self", ".", "segment_embeddings", "=", "(", "\n", "nn", ".", "Embedding", "(", "self", ".", "num_segments", ",", "self", ".", "embedding_dim", ",", "padding_idx", "=", "None", ")", "\n", "if", "self", ".", "num_segments", ">", "0", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "self", ".", "max_seq_len", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "padding_idx", "=", "(", "self", ".", "padding_idx", "if", "offset_positions_by_padding", "else", "None", ")", ",", "\n", "learned", "=", "self", ".", "learned_pos_embedding", ",", "\n", ")", "\n", "if", "self", ".", "use_position_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "emb_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "emb_layer_norm", "=", "None", "\n", "\n", "", "if", "self", ".", "layerdrop", ">", "0.0", ":", "\n", "            ", "self", ".", "layers", "=", "LayerDropModuleList", "(", "p", "=", "self", ".", "layerdrop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "self", ".", "build_transformer_sentence_encoder_layer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "self", ".", "dropout_module", ".", "p", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "# Apply initialization of model params after building the model", "\n", "if", "self", ".", "apply_bert_init", ":", "\n", "            ", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n", "", "def", "freeze_module_params", "(", "m", ")", ":", "\n", "            ", "if", "m", "is", "not", "None", ":", "\n", "                ", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "if", "freeze_embeddings", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "embed_tokens", ")", "\n", "freeze_module_params", "(", "self", ".", "segment_embeddings", ")", "\n", "freeze_module_params", "(", "self", ".", "embed_positions", ")", "\n", "freeze_module_params", "(", "self", ".", "emb_layer_norm", ")", "\n", "\n", "", "for", "layer", "in", "range", "(", "n_trans_layers_to_freeze", ")", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "layers", "[", "layer", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder.TransformerSentenceEncoder.build_embedding": [[193, 195], ["torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "build_embedding", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "        ", "return", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder.TransformerSentenceEncoder.build_transformer_sentence_encoder_layer": [[196, 220], ["fairseq.modules.TransformerSentenceEncoderLayer"], "methods", ["None"], ["", "def", "build_transformer_sentence_encoder_layer", "(", "\n", "self", ",", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "activation_fn", ",", "\n", "export", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", ":", "\n", "        ", "return", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder.TransformerSentenceEncoder.forward": [[222, 284], ["tokens.eq", "transformer_sentence_encoder.TransformerSentenceEncoder.dropout_module", "transformer_sentence_encoder.TransformerSentenceEncoder.transpose", "transformer_sentence_encoder.TransformerSentenceEncoder.embed_tokens", "transformer_sentence_encoder.TransformerSentenceEncoder.quant_noise", "transformer_sentence_encoder.TransformerSentenceEncoder.emb_layer_norm", "inner_states.append", "layer", "tokens.eq.any", "transformer_sentence_encoder.TransformerSentenceEncoder.embed_positions", "transformer_sentence_encoder.TransformerSentenceEncoder.segment_embeddings", "inner_states.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "tokens.eq.unsqueeze().type_as", "tokens.eq.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "tokens", ":", "torch", ".", "Tensor", ",", "\n", "segment_labels", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "last_state_only", ":", "bool", "=", "False", ",", "\n", "positions", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "is_tpu", "=", "tokens", ".", "device", ".", "type", "==", "\"xla\"", "\n", "\n", "# compute padding mask. This is needed for multi-head attention", "\n", "padding_mask", "=", "tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "if", "not", "self", ".", "traceable", "and", "not", "is_tpu", "and", "not", "padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "padding_mask", "=", "None", "\n", "\n", "", "if", "token_embeddings", "is", "not", "None", ":", "\n", "            ", "x", "=", "token_embeddings", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "embed_tokens", "(", "tokens", ")", "\n", "\n", "", "if", "self", ".", "embed_scale", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "self", ".", "embed_scale", "\n", "\n", "", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "embed_positions", "(", "tokens", ",", "positions", "=", "positions", ")", "\n", "\n", "", "if", "self", ".", "segment_embeddings", "is", "not", "None", "and", "segment_labels", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "segment_embeddings", "(", "segment_labels", ")", "\n", "\n", "", "if", "self", ".", "quant_noise", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "quant_noise", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "emb_layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "emb_layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# account for padding while computing the representation", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "x", ")", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "inner_states", "=", "[", "]", "\n", "if", "not", "last_state_only", ":", "\n", "            ", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", ",", "_", "=", "layer", "(", "x", ",", "self_attn_padding_mask", "=", "padding_mask", ")", "\n", "if", "not", "last_state_only", ":", "\n", "                ", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "", "sentence_rep", "=", "x", "[", "0", ",", ":", ",", ":", "]", "\n", "\n", "if", "last_state_only", ":", "\n", "            ", "inner_states", "=", "[", "x", "]", "\n", "\n", "", "if", "self", ".", "traceable", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "inner_states", ")", ",", "sentence_rep", "\n", "", "else", ":", "\n", "            ", "return", "inner_states", ",", "sentence_rep", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_sentence_encoder.init_bert_params": [[21, 47], ["isinstance", "isinstance", "isinstance", "module.weight.data.normal_", "module.weight.data.normal_", "module.q_proj.weight.data.normal_", "module.k_proj.weight.data.normal_", "module.v_proj.weight.data.normal_", "module.bias.data.zero_", "module.weight.data[].zero_"], "function", ["None"], ["def", "init_bert_params", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Initialize the weights specific to the BERT Model.\n    This overrides the default initializations depending on the specified arguments.\n        1. If normal_init_linear_weights is set then weights of linear\n           layer will be initialized using the normal distribution and\n           bais will be set to the specified value.\n        2. If normal_init_embed_weights is set then weights of embedding\n           layer will be initialized using the normal distribution.\n        3. If normal_init_proj_weights is set then weights of\n           in_project_weight for MultiHeadAttention initialized using\n           the normal distribution (to be validated).\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "MultiheadAttention", ")", ":", "\n", "        ", "module", ".", "q_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "k_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "v_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.SingleHeadAttention.__init__": [[21, 73], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "k_layers.append", "v_layers.append", "k_layers.append", "downsampled_multihead_attention.GatedLinear", "v_layers.append", "k_layers.append", "downsampled_multihead_attention.Linear", "v_layers.append", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Downsample", "downsampled_multihead_attention.Downsample", "downsampled_multihead_attention.GatedLinear", "downsampled_multihead_attention.GatedLinear", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "head_dim", ",", "\n", "head_index", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "project_input", "=", "True", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "head_index", "=", "head_index", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "project_input", "=", "project_input", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "projection", "=", "None", "\n", "\n", "k_layers", "=", "[", "]", "\n", "v_layers", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "k_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "v_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "out_proj_size", "=", "self", ".", "head_dim", "\n", "", "else", ":", "\n", "            ", "out_proj_size", "=", "self", ".", "head_dim", "*", "self", ".", "num_heads", "\n", "", "if", "self", ".", "gated", ":", "\n", "            ", "k_layers", ".", "append", "(", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "", "else", ":", "\n", "            ", "k_layers", ".", "append", "(", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "\n", "", "self", ".", "in_proj_k", "=", "nn", ".", "Sequential", "(", "*", "k_layers", ")", "\n", "self", ".", "in_proj_v", "=", "nn", ".", "Sequential", "(", "*", "v_layers", ")", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "self", ".", "out_proj", "=", "Linear", "(", "out_proj_size", ",", "self", ".", "head_dim", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_proj", "=", "Linear", "(", "out_proj_size", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "\n", "", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.SingleHeadAttention.forward": [[74, 168], ["key.size", "query.size", "q.view.view.transpose", "k.view.view.transpose", "fairseq.modules.scalar_bias.scalar_bias.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "downsampled_multihead_attention.SingleHeadAttention.dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "downsampled_multihead_attention.SingleHeadAttention.out_proj", "list", "key.size", "value.size", "downsampled_multihead_attention.SingleHeadAttention.in_proj_q", "downsampled_multihead_attention.SingleHeadAttention.in_proj_k", "downsampled_multihead_attention.SingleHeadAttention.in_proj_v", "q.view.view.view", "k.view.view.view", "fairseq.modules.scalar_bias.scalar_bias.view", "k.view.view.transpose", "[].unsqueeze", "[].unsqueeze", "fairseq.modules.scalar_bias.scalar_bias", "fairseq.modules.scalar_bias.scalar_bias", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "query.size", "key_padding_mask.size", "key_padding_mask.size", "k.view.view.size", "query.size", "key.size", "key_padding_mask.max", "attn_weights.view.view.masked_fill", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights.view.view.view", "key_padding_mask.unsqueeze().unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "attn_weights.view.view.data.new().expand().clone", "attn_weights.view.view.data.new().expand().clone", "key_padding_mask.unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "attn_weights.view.view.data.new().expand", "attn_weights.view.view.data.new().expand", "attn_weights.view.view.data.new", "attn_weights.view.view.data.new"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "use_scalar_bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Self-attention can be implemented by passing in the same arguments for\n        query, key and value. Future timesteps can be masked with the\n        `mask_future_timesteps` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "src_len", ",", "bsz", ",", "out_channels", "=", "key", ".", "size", "(", ")", "\n", "tgt_len", "=", "query", ".", "size", "(", "0", ")", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "out_channels", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "downsample", ":", "\n", "            ", "size", "=", "bsz", "\n", "", "else", ":", "\n", "            ", "size", "=", "bsz", "*", "self", ".", "num_heads", "\n", "\n", "", "k", "=", "key", "\n", "v", "=", "value", "\n", "q", "=", "query", "\n", "if", "self", ".", "project_input", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "q", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "k", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "v", ")", "\n", "src_len", "=", "k", ".", "size", "(", ")", "[", "0", "]", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "not", "self", ".", "downsample", ":", "\n", "            ", "q", "=", "q", ".", "view", "(", "tgt_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "k", "=", "k", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "v", "=", "v", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "\n", "", "q", "=", "q", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "mask_future_timesteps", ":", "\n", "            ", "assert", "(", "\n", "query", ".", "size", "(", ")", "==", "key", ".", "size", "(", ")", "\n", ")", ",", "\"mask_future_timesteps only applies to self-attention\"", "\n", "attn_weights", "*=", "torch", ".", "tril", "(", "\n", "attn_weights", ".", "data", ".", "new", "(", "[", "1", "]", ")", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", ",", "\n", "diagonal", "=", "-", "1", ",", "\n", ")", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "+=", "torch", ".", "triu", "(", "\n", "attn_weights", ".", "data", ".", "new", "(", "[", "-", "math", ".", "inf", "]", ")", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", ",", "\n", "diagonal", "=", "0", ",", "\n", ")", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "tgt_size", "=", "tgt_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "attn_weights", "=", "scalar_bias", "(", "attn_weights", ",", "2", ")", "\n", "v", "=", "scalar_bias", "(", "v", ",", "1", ")", "\n", "tgt_size", "+=", "1", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "if", "key_padding_mask", ".", "max", "(", ")", ">", "0", ":", "\n", "                ", "if", "self", ".", "downsample", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "size", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "-", "math", ".", "inf", ",", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "size", ",", "tgt_len", ",", "src_len", ")", "\n", "", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "attn_weights", "=", "self", ".", "dropout_module", "(", "attn_weights", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "self", ".", "head_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "self", ".", "embed_dim", ")", "\n", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.DownsampledMultiHeadAttention.__init__": [[175, 228], ["range", "torch.ModuleList.__init__", "downsampled_multihead_attention.Linear", "torch.ModuleList.__init__", "downsampled_multihead_attention.SingleHeadAttention", "attention_heads.append", "downsampled_multihead_attention.SingleHeadAttention"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "project_input", "=", "True", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "project_input", "=", "project_input", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "embed_dim", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attention_heads", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "attention_heads", ".", "append", "(", "\n", "SingleHeadAttention", "(", "\n", "out_channels", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "head_dim", ",", "\n", "index", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "self", ".", "project_input", ",", "\n", "self", ".", "gated", ",", "\n", "self", ".", "downsample", ",", "\n", "self", ".", "num_heads", ",", "\n", ")", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "modules", "=", "attention_heads", ")", "\n", "self", ".", "out_proj", "=", "Linear", "(", "embed_dim", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# either we have a list of attention heads, or just one attention head", "\n", "# if not being downsampled, we can do the heads with one linear layer instead of separate ones", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention_module", "=", "SingleHeadAttention", "(", "\n", "out_channels", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "head_dim", ",", "\n", "1", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "self", ".", "project_input", ",", "\n", "self", ".", "gated", ",", "\n", "self", ".", "downsample", ",", "\n", "self", ".", "num_heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.DownsampledMultiHeadAttention.forward": [[230, 285], ["key.size", "query.size", "list", "key.size", "value.size", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "downsampled_multihead_attention.DownsampledMultiHeadAttention.out_proj", "downsampled_multihead_attention.DownsampledMultiHeadAttention.attention_module", "attn.append", "attn_weights.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "full_attn_weights.view.view.view", "query.size", "attn.append", "attn_weights.append", "attn_weights[].clone", "full_attn_weights.view.view.sum"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "use_scalar_bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "src_len", ",", "bsz", ",", "embed_dim", "=", "key", ".", "size", "(", ")", "\n", "tgt_len", "=", "query", ".", "size", "(", "0", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "tgt_size", "=", "tgt_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "tgt_size", "+=", "1", "\n", "\n", "", "attn", "=", "[", "]", "\n", "attn_weights", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "for", "attention_head_number", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "# call the forward of each attention head", "\n", "                ", "_attn", ",", "_attn_weight", "=", "self", "[", "attention_head_number", "]", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", ",", "\n", "key_padding_mask", ",", "\n", "use_scalar_bias", ",", "\n", ")", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn", "=", "self", ".", "out_proj", "(", "full_attn", ")", "\n", "return", "full_attn", ",", "attn_weights", "[", "0", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "_attn", ",", "_attn_weight", "=", "self", ".", "attention_module", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", ",", "\n", "key_padding_mask", ",", "\n", "use_scalar_bias", ",", "\n", ")", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn_weights", "=", "torch", ".", "cat", "(", "attn_weights", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_size", ",", "src_len", "\n", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "return", "full_attn", ",", "full_attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.Downsample.__init__": [[292, 295], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "index", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.Downsample.forward": [[296, 298], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ":", "self", ".", "index", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.Linear": [[300, 306], ["torch.Linear", "nn.Linear.weight.data.normal_", "nn.Linear.bias.data.zero_", "torch.utils.weight_norm", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "", "def", "Linear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ",", "bias", "=", "True", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: B x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "bias", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "dropout", ")", "/", "in_features", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.downsampled_multihead_attention.GatedLinear": [[308, 316], ["torch.Sequential", "downsampled_multihead_attention.Linear", "torch.GLU", "downsampled_multihead_attention.Linear", "torch.GLU", "downsampled_multihead_attention.Linear"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "GatedLinear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ",", "bias", "=", "True", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: B x T x C) with interspersed GLU units\"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "in_features", ",", "out_features", "*", "4", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_features", "*", "2", ",", "out_features", "*", "2", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_features", ",", "out_features", ",", "dropout", ",", "bias", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.__init__": [[12, 51], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Sequential", "torch.Sequential", "torch.MSELoss", "torch.MSELoss", "torch.Conv1d", "torch.Conv1d", "fairseq.modules.Fp32GroupNorm", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_vars", ",", "groups", ",", "combine_groups", ",", "vq_dim", ",", "time_first", ",", "gamma", "=", "0.25", "\n", ")", ":", "\n", "        ", "\"\"\"Vector quantization using straight pass-through estimator (i.e. kmeans)\n\n        Args:\n            dim: input dimension (channels)\n            num_vars: number of quantized vectors per group\n            groups: number of groups for vector quantization\n            combine_groups: whether to use the vectors for all groups\n            vq_dim: dimensionality of the resulting quantized vector\n            time_first: if true, expect input in BxTxC format, otherwise in BxCxT\n            gamma: commitment loss coefficient\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "combine_groups", "=", "combine_groups", "\n", "self", ".", "input_dim", "=", "dim", "\n", "self", ".", "num_vars", "=", "num_vars", "\n", "self", ".", "vq_dim", "=", "vq_dim", "\n", "self", ".", "time_first", "=", "time_first", "\n", "\n", "assert", "(", "\n", "vq_dim", "%", "groups", "==", "0", "\n", ")", ",", "f\"dim {vq_dim} must be divisible by groups {groups} for concatenation\"", "\n", "\n", "self", ".", "var_dim", "=", "vq_dim", "//", "groups", "\n", "num_groups", "=", "groups", "if", "not", "combine_groups", "else", "1", "\n", "\n", "self", ".", "embedding", "=", "nn", ".", "Parameter", "(", "\n", "0.01", "*", "torch", ".", "randn", "(", "num_vars", ",", "num_groups", ",", "self", ".", "var_dim", ")", "\n", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", ",", "\n", "Fp32GroupNorm", "(", "groups", ",", "dim", ")", ",", "\n", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "mse_mean", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad": [[52, 61], ["y.detach", "x.detach"], "methods", ["None"], ["", "def", "_pass_grad", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"Manually set gradient for backward pass.\n        for y = f(x), ensure that during the backward pass,\n        dL/dy = dL/dx regardless of f(x).\n        Returns:\n            y, with the gradient forced to be dL/dy = dL/dx.\n        \"\"\"", "\n", "\n", "return", "y", ".", "detach", "(", ")", "+", "(", "x", "-", "x", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding": [[62, 67], ["kmeans_vector_quantizer.KmeansVectorQuantizer.embedding.expand"], "methods", ["None"], ["", "@", "property", "\n", "def", "expand_embedding", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "combine_groups", ":", "\n", "            ", "return", "self", ".", "embedding", ".", "expand", "(", "self", ".", "num_vars", ",", "self", ".", "groups", ",", "self", ".", "var_dim", ")", "\n", "", "return", "self", ".", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward_idx": [[68, 71], ["kmeans_vector_quantizer.KmeansVectorQuantizer.forward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "def", "forward_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "x", ",", "produce_targets", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"targets\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward": [[72, 128], ["kmeans_vector_quantizer.KmeansVectorQuantizer.projection", "ze.float.float.view().permute", "d.argmin", "torch.stack().view().permute", "torch.stack().view().permute", "torch.stack().view().permute", "torch.stack().view().permute", "kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad", "d.argmin.new_zeros().scatter_().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "ze.float.float.float", "zq.float.float.float", "kmeans_vector_quantizer.KmeansVectorQuantizer.mse_mean", "kmeans_vector_quantizer.KmeansVectorQuantizer.mse_mean", "x.transpose.transpose.transpose", "d.argmin.new_zeros().scatter_().view.float", "x.transpose.transpose.transpose", "ze.float.float.detach", "zq.float.float.detach", "ze.float.float.view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "d.argmin.new_zeros().scatter_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "d.argmin.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "d.argmin.new_zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ze.float.view().permute.unsqueeze", "kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding.unsqueeze().unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding.unsqueeze", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "def", "forward", "(", "self", ",", "x", ",", "produce_targets", "=", "False", ")", ":", "\n", "\n", "        ", "result", "=", "{", "\"num_vars\"", ":", "self", ".", "num_vars", "}", "\n", "\n", "if", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "bsz", ",", "fsz", ",", "tsz", "=", "x", ".", "shape", "\n", "\n", "ze", "=", "self", ".", "projection", "(", "x", ")", "\n", "ze_", "=", "ze", ".", "view", "(", "bsz", ",", "self", ".", "groups", ",", "self", ".", "var_dim", ",", "tsz", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "d", "=", "(", "\n", "(", "ze_", ".", "unsqueeze", "(", "0", ")", "-", "self", ".", "expand_embedding", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", ".", "view", "(", "self", ".", "num_vars", ",", "bsz", ",", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ".", "norm", "(", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", ")", "\n", "idx", "=", "d", ".", "argmin", "(", "dim", "=", "0", ")", "\n", "zq", "=", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "\n", "self", ".", "expand_embedding", "[", "idx", "[", "...", ",", "group", "]", ",", "group", "]", "\n", "for", "group", "in", "range", "(", "self", ".", "groups", ")", "\n", "]", ",", "\n", "dim", "=", "-", "2", ",", "\n", ")", "\n", ".", "view", "(", "bsz", ",", "tsz", ",", "self", ".", "groups", "*", "self", ".", "var_dim", ")", "\n", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", ")", "\n", "assert", "ze", ".", "shape", "==", "zq", ".", "shape", ",", "(", "ze", ".", "shape", ",", "zq", ".", "shape", ")", "\n", "x", "=", "self", ".", "_pass_grad", "(", "ze", ",", "zq", ")", "\n", "\n", "hard_x", "=", "(", "\n", "idx", ".", "new_zeros", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "self", ".", "num_vars", ")", "\n", ".", "scatter_", "(", "-", "1", ",", "idx", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n", "hard_probs", "=", "torch", ".", "mean", "(", "hard_x", ".", "float", "(", ")", ",", "dim", "=", "0", ")", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "hard_probs", "*", "torch", ".", "log", "(", "hard_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "if", "produce_targets", ":", "\n", "            ", "result", "[", "\"targets\"", "]", "=", "idx", "\n", "\n", "", "if", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# BCT -> BTC", "\n", "", "result", "[", "\"x\"", "]", "=", "x", "\n", "\n", "ze", "=", "ze", ".", "float", "(", ")", "\n", "zq", "=", "zq", ".", "float", "(", ")", "\n", "latent_loss", "=", "self", ".", "mse_mean", "(", "zq", ",", "ze", ".", "detach", "(", ")", ")", "\n", "commitment_loss", "=", "self", ".", "mse_mean", "(", "ze", ",", "zq", ".", "detach", "(", ")", ")", "\n", "\n", "result", "[", "\"kmeans_loss\"", "]", "=", "latent_loss", "+", "self", ".", "gamma", "*", "commitment_loss", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.__init__": [[32, 68], ["torch.Module.__init__", "getattr", "transformer_layer.TransformerEncoderLayer.build_self_attention", "fairseq.modules.LayerNorm", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.utils.get_activation_fn", "fairseq.modules.fairseq_dropout.FairseqDropout", "transformer_layer.TransformerEncoderLayer.build_fc1", "transformer_layer.TransformerEncoderLayer.build_fc2", "fairseq.modules.LayerNorm", "getattr", "getattr", "float", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "quant_noise", "=", "getattr", "(", "args", ",", "'quant_noise_pq'", ",", "0", ")", "\n", "self", ".", "quant_noise_block_size", "=", "getattr", "(", "args", ",", "'quant_noise_pq_block_size'", ",", "8", ")", "or", "8", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "self", ".", "embed_dim", ",", "args", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "'activation_fn'", ",", "'relu'", ")", "or", "\"relu\"", "\n", ")", "\n", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "or", "0", "\n", "if", "activation_dropout_p", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "or", "0", "\n", "", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "float", "(", "activation_dropout_p", ")", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.build_fc1": [[69, 72], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.build_fc2": [[74, 77], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.build_self_attention": [[79, 87], ["fairseq.modules.MultiheadAttention"], "methods", ["None"], ["", "def", "build_self_attention", "(", "self", ",", "embed_dim", ",", "args", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.residual_connection": [[89, 91], ["None"], "methods", ["None"], ["", "def", "residual_connection", "(", "self", ",", "x", ",", "residual", ")", ":", "\n", "        ", "return", "residual", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.upgrade_state_dict_named": [[92, 105], ["layer_norm_map.items"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Rename layer norm states from `...layer_norms.0.weight` to\n        `...self_attn_layer_norm.weight` and `...layer_norms.1.weight` to\n        `...final_layer_norm.weight`\n        \"\"\"", "\n", "layer_norm_map", "=", "{", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\"1\"", ":", "\"final_layer_norm\"", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                ", "k", "=", "\"{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                    ", "state_dict", "[", "\"{}.{}.{}\"", ".", "format", "(", "name", ",", "new", ",", "m", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerEncoderLayer.forward": [[106, 156], ["transformer_layer.TransformerEncoderLayer.self_attn", "transformer_layer.TransformerEncoderLayer.dropout_module", "transformer_layer.TransformerEncoderLayer.residual_connection", "transformer_layer.TransformerEncoderLayer.activation_fn", "transformer_layer.TransformerEncoderLayer.activation_dropout_module", "transformer_layer.TransformerEncoderLayer.fc2", "transformer_layer.TransformerEncoderLayer.dropout_module", "transformer_layer.TransformerEncoderLayer.residual_connection", "attn_mask.masked_fill.masked_fill.masked_fill", "transformer_layer.TransformerEncoderLayer.self_attn_layer_norm", "transformer_layer.TransformerEncoderLayer.self_attn_layer_norm", "transformer_layer.TransformerEncoderLayer.final_layer_norm", "transformer_layer.TransformerEncoderLayer.fc1", "transformer_layer.TransformerEncoderLayer.final_layer_norm", "attn_mask.masked_fill.masked_fill.to"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ",", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, seq_len)` where padding elements are indicated by ``1``.\n            attn_mask (ByteTensor): binary tensor of shape `(tgt_len, src_len)`,\n                where `tgt_len` is the length of output and `src_len` is the\n                length of input, though here both are equal to `seq_len`.\n                `attn_mask[tgt_i, src_j] = 1` means that when calculating the\n                embedding for `tgt_i`, we exclude (mask out) `src_j`. This is\n                useful for strided self-attention.\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "# anything in original attn_mask = 1, becomes -1e8", "\n", "# anything in original attn_mask = 0, becomes 0", "\n", "# Note that we cannot use -inf here, because at some edge cases,", "\n", "# the attention weight (before softmax) for some padded element in query", "\n", "# will become -inf, which results in NaN in model parameters", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", ".", "to", "(", "torch", ".", "bool", ")", ",", "-", "1e8", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "", "x", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.__init__": [[175, 239], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "getattr", "getattr", "getattr", "transformer_layer.TransformerDecoderLayer.build_self_attention", "fairseq.utils.get_activation_fn", "fairseq.modules.fairseq_dropout.FairseqDropout", "getattr", "fairseq.modules.LayerNorm", "transformer_layer.TransformerDecoderLayer.build_fc1", "transformer_layer.TransformerDecoderLayer.build_fc2", "fairseq.modules.LayerNorm", "getattr", "float", "transformer_layer.TransformerDecoderLayer.build_encoder_attention", "fairseq.modules.LayerNorm", "getattr", "str", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_encoder_attention", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "quant_noise", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "self", ".", "quant_noise_block_size", "=", "getattr", "(", "args", ",", "\"quant_noise_pq_block_size\"", ",", "8", ")", "\n", "\n", "self", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", "\n", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", ")", "\n", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "str", "(", "args", ".", "activation_fn", ")", "\n", "if", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "None", ")", "is", "not", "None", "\n", "else", "\"relu\"", "\n", ")", "\n", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "or", "0", "\n", "if", "activation_dropout_p", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "or", "0", "\n", "", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "float", "(", "activation_dropout_p", ")", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "# use layerNorm rather than FusedLayerNorm for exporting.", "\n", "# char_inputs can be used to determint this.", "\n", "# TODO  remove this once we update apex with the fix", "\n", "export", "=", "getattr", "(", "args", ",", "\"char_inputs\"", ",", "False", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "self", ".", "build_encoder_attention", "(", "self", ".", "embed_dim", ",", "args", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_ffn_embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "args", ".", "decoder_ffn_embed_dim", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc1": [[240, 242], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_fc2": [[243, 245], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_self_attention": [[246, 258], ["fairseq.modules.MultiheadAttention", "getattr"], "methods", ["None"], ["", "def", "build_self_attention", "(", "\n", "self", ",", "embed_dim", ",", "args", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", "self_attention", "=", "not", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.build_encoder_attention": [[260, 270], ["fairseq.modules.MultiheadAttention", "getattr", "getattr"], "methods", ["None"], ["", "def", "build_encoder_attention", "(", "self", ",", "embed_dim", ",", "args", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "kdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "vdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.prepare_for_onnx_export_": [[272, 274], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection": [[275, 277], ["None"], "methods", ["None"], ["", "def", "residual_connection", "(", "self", ",", "x", ",", "residual", ")", ":", "\n", "        ", "return", "residual", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.forward": [[278, 413], ["transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "transformer_layer.TransformerDecoderLayer.self_attn", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.activation_fn", "transformer_layer.TransformerDecoderLayer.activation_dropout_module", "transformer_layer.TransformerDecoderLayer.fc2", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.self_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.self_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.encoder_attn", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.final_layer_norm", "transformer_layer.TransformerDecoderLayer.fc1", "transformer_layer.TransformerDecoderLayer.final_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.encoder_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.encoder_attn._set_input_buffer", "transformer_layer.TransformerDecoderLayer.encoder_attn_layer_norm", "torch.cat.new_zeros", "torch.cat.new_zeros", "len", "transformer_layer.TransformerDecoderLayer.new_zeros", "encoder_out.size", "encoder_out.size", "transformer_layer.TransformerDecoderLayer.size", "encoder_out.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_out", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "encoder_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "prev_self_attn_state", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "prev_attn_state", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "self_attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "need_attn", ":", "bool", "=", "False", ",", "\n", "need_head_weights", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor, optional): binary\n                ByteTensor of shape `(batch, src_len)` where padding\n                elements are indicated by ``1``.\n            need_attn (bool, optional): return attention weights\n            need_head_weights (bool, optional): return attention weights\n                for each head (default: return average over heads).\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_attn", "=", "True", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "prev_key", ",", "prev_value", "=", "prev_self_attn_state", "[", ":", "2", "]", "\n", "saved_state", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "\n", "\"prev_key\"", ":", "prev_key", ",", "\n", "\"prev_value\"", ":", "prev_value", ",", "\n", "}", "\n", "if", "len", "(", "prev_self_attn_state", ")", ">=", "3", ":", "\n", "                ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_self_attn_state", "[", "2", "]", "\n", "", "assert", "incremental_state", "is", "not", "None", "\n", "self", ".", "self_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "_self_attn_input_buffer", "=", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "self", ".", "cross_self_attention", "and", "not", "(", "\n", "incremental_state", "is", "not", "None", "\n", "and", "_self_attn_input_buffer", "is", "not", "None", "\n", "and", "\"prev_key\"", "in", "_self_attn_input_buffer", "\n", ")", ":", "\n", "            ", "if", "self_attn_mask", "is", "not", "None", ":", "\n", "                ", "assert", "encoder_out", "is", "not", "None", "\n", "self_attn_mask", "=", "torch", ".", "cat", "(", "\n", "(", "x", ".", "new_zeros", "(", "x", ".", "size", "(", "0", ")", ",", "encoder_out", ".", "size", "(", "0", ")", ")", ",", "self_attn_mask", ")", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "if", "encoder_padding_mask", "is", "None", ":", "\n", "                    ", "assert", "encoder_out", "is", "not", "None", "\n", "encoder_padding_mask", "=", "self_attn_padding_mask", ".", "new_zeros", "(", "\n", "encoder_out", ".", "size", "(", "1", ")", ",", "encoder_out", ".", "size", "(", "0", ")", "\n", ")", "\n", "", "self_attn_padding_mask", "=", "torch", ".", "cat", "(", "\n", "(", "encoder_padding_mask", ",", "self_attn_padding_mask", ")", ",", "dim", "=", "1", "\n", ")", "\n", "", "assert", "encoder_out", "is", "not", "None", "\n", "y", "=", "torch", ".", "cat", "(", "(", "encoder_out", ",", "x", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "x", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "y", ",", "\n", "value", "=", "y", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "encoder_attn", "is", "not", "None", "and", "encoder_out", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "                ", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "prev_key", ",", "prev_value", "=", "prev_attn_state", "[", ":", "2", "]", "\n", "saved_state", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "\n", "\"prev_key\"", ":", "prev_key", ",", "\n", "\"prev_value\"", ":", "prev_value", ",", "\n", "}", "\n", "if", "len", "(", "prev_attn_state", ")", ">=", "3", ":", "\n", "                    ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_attn_state", "[", "2", "]", "\n", "", "assert", "incremental_state", "is", "not", "None", "\n", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "need_attn", "or", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", "need_head_weights", "=", "need_head_weights", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "                ", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "if", "self", ".", "onnx_trace", "and", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "assert", "saved_state", "is", "not", "None", "\n", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "self_attn_state", "=", "[", "\n", "saved_state", "[", "\"prev_key\"", "]", ",", "\n", "saved_state", "[", "\"prev_value\"", "]", ",", "\n", "saved_state", "[", "\"prev_key_padding_mask\"", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "                ", "self_attn_state", "=", "[", "saved_state", "[", "\"prev_key\"", "]", ",", "saved_state", "[", "\"prev_value\"", "]", "]", "\n", "", "return", "x", ",", "attn", ",", "self_attn_state", "\n", "", "return", "x", ",", "attn", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transformer_layer.TransformerDecoderLayer.make_generation_fast_": [[414, 416], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gelu.gelu_accurate": [[16, 21], ["hasattr", "math.sqrt", "torch.tanh", "torch.tanh", "torch.pow", "torch.pow"], "function", ["None"], ["def", "gelu_accurate", "(", "x", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "gelu_accurate", ",", "\"_a\"", ")", ":", "\n", "        ", "gelu_accurate", ".", "_a", "=", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n", "", "return", "(", "\n", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "gelu_accurate", ".", "_a", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gelu.gelu": [[24, 26], ["torch.nn.functional.gelu().type_as", "torch.nn.functional.gelu().type_as", "torch.nn.functional.gelu", "torch.nn.functional.gelu", "x.float"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gelu.gelu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gelu.gelu"], ["", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "functional", ".", "gelu", "(", "x", ".", "float", "(", ")", ")", ".", "type_as", "(", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.unfold.unfold1d": [[9, 20], ["x.unsqueeze.size", "torch.pad", "x.unsqueeze.as_strided", "x.unsqueeze.unsqueeze"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["def", "unfold1d", "(", "x", ",", "kernel_size", ",", "padding_l", ",", "pad_value", "=", "0", ")", ":", "\n", "    ", "\"\"\"unfold T x B x C to T x B x C x K\"\"\"", "\n", "if", "kernel_size", ">", "1", ":", "\n", "        ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "pad", "(", "\n", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "padding_l", ",", "kernel_size", "-", "1", "-", "padding_l", ")", ",", "value", "=", "pad_value", "\n", ")", "\n", "x", "=", "x", ".", "as_strided", "(", "(", "T", ",", "B", ",", "C", ",", "kernel_size", ")", ",", "(", "B", "*", "C", ",", "C", ",", "1", ",", "B", "*", "C", ")", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "3", ")", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder.__init__": [[19, 97], ["fairseq.modules.TransformerSentenceEncoder.__init__", "torch.ModuleList", "range", "sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder.__init__.freeze_module_params"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "padding_idx", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "num_encoder_layers", ":", "int", "=", "6", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "max_seq_len", ":", "int", "=", "256", ",", "\n", "num_segments", ":", "int", "=", "2", ",", "\n", "use_position_embeddings", ":", "bool", "=", "True", ",", "\n", "offset_positions_by_padding", ":", "bool", "=", "True", ",", "\n", "encoder_normalize_before", ":", "bool", "=", "False", ",", "\n", "apply_bert_init", ":", "bool", "=", "False", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "learned_pos_embedding", ":", "bool", "=", "True", ",", "\n", "embed_scale", ":", "float", "=", "None", ",", "\n", "freeze_embeddings", ":", "bool", "=", "False", ",", "\n", "n_trans_layers_to_freeze", ":", "int", "=", "0", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "is_bidirectional", ":", "bool", "=", "True", ",", "\n", "stride", ":", "int", "=", "32", ",", "\n", "expressivity", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "padding_idx", ",", "\n", "vocab_size", ",", "\n", "num_encoder_layers", ",", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "max_seq_len", ",", "\n", "num_segments", ",", "\n", "use_position_embeddings", ",", "\n", "offset_positions_by_padding", ",", "\n", "encoder_normalize_before", ",", "\n", "apply_bert_init", ",", "\n", "activation_fn", ",", "\n", "learned_pos_embedding", ",", "\n", "embed_scale", ",", "\n", "freeze_embeddings", ",", "\n", "n_trans_layers_to_freeze", ",", "\n", "export", ",", "\n", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "SparseTransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "is_bidirectional", "=", "is_bidirectional", ",", "\n", "stride", "=", "stride", ",", "\n", "expressivity", "=", "expressivity", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "def", "freeze_module_params", "(", "m", ")", ":", "\n", "            ", "if", "m", "is", "not", "None", ":", "\n", "                ", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "for", "layer", "in", "range", "(", "n_trans_layers_to_freeze", ")", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "layers", "[", "layer", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transpose_last.TransposeLast.__init__": [[13, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "deconstruct_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "deconstruct_idx", "=", "deconstruct_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.transpose_last.TransposeLast.forward": [[17, 21], ["x.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "deconstruct_idx", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", "self", ".", "deconstruct_idx", "]", "\n", "", "return", "x", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qact.ActivationQuantizer.__init__": [[36, 54], ["qact.ActivationQuantizer.register_hook"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qact.ActivationQuantizer.register_hook"], ["def", "__init__", "(", "\n", "self", ",", "\n", "module", ",", "\n", "p", "=", "1", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "clamp_threshold", "=", "5", ",", "\n", ")", ":", "\n", "        ", "self", ".", "module", "=", "module", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "clamp_threshold", "=", "clamp_threshold", "\n", "self", ".", "handle", "=", "None", "\n", "self", ".", "register_hook", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qact.ActivationQuantizer.register_hook": [[55, 89], ["qact.ActivationQuantizer.module.register_forward_hook", "ops.emulate_int", "torch.zeros_like", "torch.zeros_like.bernoulli_", "y.detach", "torch.zeros_like.bool", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "register_hook", "(", "self", ")", ":", "\n", "# forward hook", "\n", "        ", "def", "quantize_hook", "(", "module", ",", "x", ",", "y", ")", ":", "\n", "\n", "# update parameters every 1000 iterations", "\n", "            ", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "                ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "p", "=", "self", ".", "p", "if", "self", ".", "module", ".", "training", "else", "1", "\n", "\n", "# quantize activations", "\n", "y_q", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "y", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "y", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "y_q", "-", "y", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "return", "torch", ".", "clamp", "(", "y", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "+", "noise", ".", "detach", "(", ")", "\n", "\n", "# register hook", "\n", "", "self", ".", "handle", "=", "self", ".", "module", ".", "register_forward_hook", "(", "quantize_hook", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.IntLinear.__init__": [[35, 62], ["torch.Module.__init__", "int", "int", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "qlinear.IntLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "qlinear.IntLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "out_features", ",", "\n", "bias", "=", "True", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "3000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "int", "(", "in_features", ")", "\n", "self", ".", "out_features", "=", "int", "(", "out_features", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "chosen_bias", "=", "bias", "\n", "if", "self", ".", "chosen_bias", ":", "\n", "            ", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.IntLinear.reset_parameters": [[63, 68], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "chosen_bias", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.IntLinear.forward": [[69, 104], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.linear", "torch.linear", "torch.linear", "qlinear.IntLinear.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "F", ".", "linear", "(", "input", ",", "weight", ",", "self", ".", "bias", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.IntLinear.extra_repr": [[105, 113], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"in_features={}, out_features={}, bias={}, quant_noise={}, bits={}, method={}\"", ".", "format", "(", "\n", "self", ".", "in_features", ",", "\n", "self", ".", "out_features", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", "self", ".", "p", ",", "\n", "self", ".", "bits", ",", "\n", "self", ".", "method", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.IntConv2d.__init__": [[34, 74], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.conv._ConvNd.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "p", "=", "0", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "update_step", "=", "1000", ",", "\n", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "IntConv2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "False", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "groups", ",", "\n", "bias", ",", "\n", "padding_mode", ",", "\n", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.IntConv2d._conv_forward": [[75, 94], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.pad", "torch.pad", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair"], ["", "def", "_conv_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "\n", "F", ".", "pad", "(", "input", ",", "self", ".", "_padding_repeated_twice", ",", "mode", "=", "self", ".", "padding_mode", ")", ",", "\n", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "", "return", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.IntConv2d.forward": [[96, 131], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "qconv.IntConv2d._conv_forward", "qconv.IntConv2d.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.IntConv2d._conv_forward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "self", ".", "_conv_forward", "(", "input", ",", "weight", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.IntConv2d.extra_repr": [[132, 148], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"in_channels={}, out_channels={}, kernel_size={}, stride={}, \"", "\n", "\"padding={}, dilation={}, groups={}, bias={}, quant_noise={}, \"", "\n", "\"bits={}, method={}\"", ".", "format", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "out_channels", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", "self", ".", "p", ",", "\n", "self", ".", "bits", ",", "\n", "self", ".", "method", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.IntEmbedding.__init__": [[34, 83], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qemb.IntEmbedding.reset_parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "list"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "\n", "norm_type", "=", "2.0", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "\n", "_weight", "=", "None", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "if", "padding_idx", ">", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", "<", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "", "elif", "padding_idx", "<", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", ">=", "-", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "padding_idx", "=", "self", ".", "num_embeddings", "+", "padding_idx", "\n", "", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "if", "_weight", "is", "None", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "list", "(", "_weight", ".", "shape", ")", "==", "[", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "]", ",", "\"Shape of weight does not match num_embeddings and embedding_dim\"", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "_weight", ")", "\n", "", "self", ".", "sparse", "=", "sparse", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.IntEmbedding.reset_parameters": [[84, 89], ["torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "qemb.IntEmbedding.weight[].fill_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "weight", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.IntEmbedding.forward": [[90, 133], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.embedding", "torch.embedding", "torch.embedding", "qemb.IntEmbedding.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 1000 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "F", ".", "embedding", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "self", ".", "padding_idx", ",", "\n", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "\n", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ",", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.IntEmbedding.extra_repr": [[134, 148], ["s.format"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{num_embeddings}, {embedding_dim}\"", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "s", "+=", "\", padding_idx={padding_idx}\"", "\n", "", "if", "self", ".", "max_norm", "is", "not", "None", ":", "\n", "            ", "s", "+=", "\", max_norm={max_norm}\"", "\n", "", "if", "self", ".", "norm_type", "!=", "2", ":", "\n", "            ", "s", "+=", "\", norm_type={norm_type}\"", "\n", "", "if", "self", ".", "scale_grad_by_freq", "is", "not", "False", ":", "\n", "            ", "s", "+=", "\", scale_grad_by_freq={scale_grad_by_freq}\"", "\n", "", "if", "self", ".", "sparse", "is", "not", "False", ":", "\n", "            ", "s", "+=", "\", sparse=True\"", "\n", "", "s", "+=", "\"quant_noise={p}, bits={bits}, method={method}\"", "\n", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.PQLinear.__init__": [[30, 49], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qlinear.PQLinear.register_buffer", "qlinear.PQLinear.register_buffer", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qlinear.PQLinear.register_parameter", "len", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "out_features", ",", "\n", "bias", "=", "True", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "3000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "int", "(", "in_features", ")", "\n", "self", ".", "out_features", "=", "int", "(", "out_features", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "chosen_bias", "=", "bias", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.PQLinear.weight": [[50, 57], ["qlinear.PQLinear.centroids[].reshape().permute().flatten", "qlinear.PQLinear.centroids[].reshape().permute", "qlinear.PQLinear.centroids[].reshape"], "methods", ["None"], ["if", "self", ".", "chosen_bias", ":", "\n", "            ", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.PQLinear.forward": [[59, 64], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qlinear.PQLinear.extra_repr": [[66, 72], ["None"], "methods", ["None"], ["            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.PQConv2d.__init__": [[35, 79], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qconv.PQConv2d.register_buffer", "qconv.PQConv2d.register_buffer", "qconv.PQConv2d.centroids.register_hook", "ValueError", "ValueError", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qconv.PQConv2d.register_parameter", "len", "numpy.prod", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.vggblock._pair", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qact.ActivationQuantizer.register_hook"], ["self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "p", "=", "0", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "update_step", "=", "1000", ",", "\n", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "IntConv2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "False", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "groups", ",", "\n", "bias", ",", "\n", "padding_mode", ",", "\n", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n", "", "def", "_conv_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "\n", "F", ".", "pad", "(", "input", ",", "self", ".", "_padding_repeated_twice", ",", "mode", "=", "self", ".", "padding_mode", ")", ",", "\n", "weight", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.PQConv2d.weight": [[80, 88], ["qconv.PQConv2d.centroids[].reshape().permute().reshape", "qconv.PQConv2d.centroids[].reshape().permute", "qconv.PQConv2d.centroids[].reshape"], "methods", ["None"], ["self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "", "return", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "weight", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.PQConv2d.forward": [[91, 100], ["torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qconv.PQConv2d.extra_repr": [[102, 116], ["s.format", "len", "len"], "methods", ["None"], ["            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.PQEmbedding.__init__": [[30, 72], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qemb.PQEmbedding.register_buffer", "qemb.PQEmbedding.register_buffer", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "len", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "\n", "norm_type", "=", "2.0", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "\n", "_weight", "=", "None", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "if", "padding_idx", ">", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", "<", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "", "elif", "padding_idx", "<", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", ">=", "-", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "padding_idx", "=", "self", ".", "num_embeddings", "+", "padding_idx", "\n", "", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "if", "_weight", "is", "None", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "list", "(", "_weight", ".", "shape", ")", "==", "[", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.PQEmbedding.weight": [[73, 80], ["qemb.PQEmbedding.centroids[].reshape().permute().flatten", "qemb.PQEmbedding.centroids[].reshape().permute", "qemb.PQEmbedding.centroids[].reshape"], "methods", ["None"], ["]", ",", "\"Shape of weight does not match num_embeddings and embedding_dim\"", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "_weight", ")", "\n", "", "self", ".", "sparse", "=", "sparse", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.PQEmbedding.forward": [[82, 91], ["torch.embedding", "torch.embedding", "torch.embedding"], "methods", ["None"], ["self", ".", "counter", "=", "0", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "weight", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.qemb.PQEmbedding.extra_repr": [[93, 108], ["s.format"], "methods", ["None"], ["\n", "# update parameters every 1000 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.lightconvFunction.forward": [[17, 24], ["lightconv_cuda.forward", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "weights", ",", "padding_l", ")", ":", "\n", "        ", "ctx", ".", "padding_l", "=", "padding_l", "\n", "outputs", "=", "lightconv_cuda", ".", "forward", "(", "x", ",", "weights", ",", "padding_l", ")", "\n", "variables", "=", "[", "x", ",", "weights", "]", "\n", "ctx", ".", "save_for_backward", "(", "*", "variables", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.lightconvFunction.backward": [[25, 32], ["lightconv_cuda.backward", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "outputs", "=", "lightconv_cuda", ".", "backward", "(", "\n", "grad_output", ".", "contiguous", "(", ")", ",", "ctx", ".", "padding_l", ",", "*", "ctx", ".", "saved_tensors", "\n", ")", "\n", "grad_input", ",", "grad_weights", "=", "outputs", "\n", "return", "grad_input", ",", "grad_weights", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.__init__": [[36, 62], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.Parameter", "torch.nn.Parameter", "lightconv_layer.LightconvLayer.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "LightconvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "kernel_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.upgrade_state_dict_named": [[63, 69], ["state_dict.items", "k.endswith", "v.squeeze", "v.dim", "v.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "prefix", "+", "\"weight\"", ")", ":", "\n", "                ", "if", "v", ".", "dim", "(", ")", "==", "3", "and", "v", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "                    ", "state_dict", "[", "k", "]", "=", "v", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.reset_parameters": [[70, 74], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.forward": [[75, 121], ["x.permute().contiguous.permute().contiguous.size", "lightconv_layer.LightconvLayer._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "lightconv_layer.LightconvLayer.size", "lightconv_layer.LightconvLayer.view().expand().contiguous().view", "lightconv_layer.LightconvLayer.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "x.permute().contiguous.permute().contiguous.permute().contiguous", "lightconvFunction.apply().permute", "x.permute().contiguous.permute().contiguous.new", "lightconv_layer.LightconvLayer._set_input_buffer", "torch.softmax().type_as", "torch.softmax().type_as", "torch.softmax", "torch.softmax", "lightconv_layer.LightconvLayer.weight_dropout_module", "x.permute().contiguous.permute().contiguous.unsqueeze", "lightconv_layer.LightconvLayer.view().expand().contiguous", "x.permute().contiguous.permute().contiguous.permute", "lightconvFunction.apply", "torch.softmax", "torch.softmax", "lightconv_layer.LightconvLayer.float", "x_unfold.view.view.size", "lightconv_layer.LightconvLayer.view().expand", "lightconv_layer.LightconvLayer.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ")", ":", "\n", "\n", "# during inference time, incremental BMM is faster", "\n", "        ", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ".", "float", "(", ")", ",", "dim", "=", "1", ")", ".", "type_as", "(", "weight", ")", "\n", "\n", "", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "weight", "=", "(", "\n", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", "\n", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "T", "*", "B", "*", "H", ",", "K", ",", "1", ")", "\n", ")", "\n", "\n", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n", "# during training time, use CUDA kernel", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "self", ".", "weight", ",", "-", "1", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ":", "\n", "                ", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "", "return", "lightconvFunction", ".", "apply", "(", "x", ",", "weight", ",", "self", ".", "padding_l", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.reorder_incremental_state": [[122, 127], ["lightconv_layer.LightconvLayer._get_input_buffer", "input_buffer.index_select.index_select.index_select", "lightconv_layer.LightconvLayer._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer._get_input_buffer": [[128, 130], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer._set_input_buffer": [[131, 134], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half": [[136, 138], ["lightconv_layer.LightconvLayer._apply", "t.is_floating_point", "t.half"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.lightconv_layer.LightconvLayer.half"], ["", "def", "half", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_apply", "(", "lambda", "t", ":", "t", ".", "half", "(", ")", "if", "t", ".", "is_floating_point", "(", ")", "else", "t", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.cuda_function_gen.gen_forward": [[7, 114], ["open", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "sequence_if.format", "forward.write", "forward.write", "case_k.format", "forward.write", "case_k.format", "forward.write", "main_block.format", "main_block.format"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["def", "gen_forward", "(", ")", ":", "\n", "\n", "    ", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "\n", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_forward(at::Tensor input, at::Tensor filters, int padding_l) {\n\n    at::DeviceGuard g(input.device());\n    const auto minibatch = input.size(0);\n    const auto numFeatures = input.size(1);\n    const auto sequenceLength = input.size(2);\n\n    const auto numHeads = filters.size(0);\n    const auto filterSize = filters.size(1);\n\n    const auto numFiltersInBlock = numFeatures / numHeads;\n\n    const dim3 blocks(minibatch, numFeatures);\n\n    auto output = at::zeros_like(input);\n    auto stream = at::cuda::getCurrentCUDAStream();\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n    if (sequenceLength <= {seq}) {{\n        switch(filterSize) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n            case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {pad}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_forward\", ([&] {{\n                        lightconv_forward_kernel<{k}, {b_size}, {pad}, scalar_t>\n                        <<<blocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                output.data<scalar_t>());\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping forward pass\" << std::endl;\n                }\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n            default:\n                std::cout << \"WARNING: Unsupported filter length passed - skipping forward pass\" << std::endl;\n        }\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n    } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "final_return", "=", "\"\"\"\n    }\n\n    return {output};\n}\n\"\"\"", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_forward.cu\"", ",", "\"w\"", ")", "as", "forward", ":", "\n", "        ", "forward", ".", "write", "(", "head", ")", "\n", "for", "seq", "in", "seqs", ":", "\n", "            ", "forward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "                ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                    ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "con_else", ")", "\n", "\n", "", "forward", ".", "write", "(", "final_else", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "            ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "final_return", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.lightconv_layer.cuda_function_gen.gen_backward": [[116, 285], ["open", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "case_k.format", "backward.write", "backward.write", "backward.write", "backward.write", "backward.write", "sequence_if.format", "backward.write", "backward.write", "backward.write", "backward.write", "main_block.format", "weight_grad_short.format", "main_block.format", "weight_grad.format"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "", "def", "gen_backward", "(", ")", ":", "\n", "\n", "    ", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_backward(\n        at::Tensor gradOutput,\n        int padding_l,\n        at::Tensor input,\n        at::Tensor filters) {\n\n    // gradWrtInput\n    const int minibatch = input.size(0);\n    const int numFeatures = input.size(1);\n    const int sequenceLength = input.size(2);\n\n    const int numHeads = filters.size(0);\n    const int filterSize = filters.size(1);\n\n    const dim3 gradBlocks(minibatch, numFeatures);\n    const dim3 weightGradFirstpassShortBlocks(minibatch, numHeads);\n    const dim3 weightGradSecondpassBlocks(numHeads, filterSize);\n\n    const int numFiltersInBlock = numFeatures / numHeads;\n\n    auto gradInput = at::zeros_like(input);\n    auto gradFilters = at::zeros_like(filters);\n\n    at::DeviceGuard g(input.device());\n    auto stream = at::cuda::getCurrentCUDAStream();\n\n    switch(filterSize) {\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n            if (sequenceLength <= {seq}) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n        case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {p}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_backward\", ([&] {{\n                        lightconv_grad_wrt_input_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                gradOutput.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                gradInput.data<scalar_t>());\n\n\"\"\"", "\n", "\n", "weight_grad_short", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numHeads, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_short_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<weightGradFirstpassShortBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                numHeads,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_short_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "weight_grad", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numFeatures, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping backward pass\" << std::endl;\n                }\n\"\"\"", "\n", "\n", "breakout", "=", "\"\"\"\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n        default:\n            std::cout << \"WARNING: Unsupported filter length passed - skipping backward pass\" << std::endl;\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n            } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "last_return", "=", "\"\"\"\n    }\n    return {gradInput, gradFilters};\n}\n\"\"\"", "\n", "\n", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "thresh", "=", "[", "32", ",", "32", ",", "64", ",", "128", ",", "256", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "max_mem", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "192", ",", "96", ",", "64", "]", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_backward.cu\"", ",", "\"w\"", ")", "as", "backward", ":", "\n", "        ", "backward", ".", "write", "(", "head", ")", "\n", "for", "(", "k", ",", "t", ",", "mem", ")", "in", "zip", "(", "kernels", ",", "thresh", ",", "max_mem", ")", ":", "\n", "            ", "backward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "seq", "in", "seqs", ":", "\n", "                ", "if", "(", "t", "==", "-", "1", "or", "seq", "<=", "t", ")", "and", "(", "mem", "==", "-", "1", "or", "seq", "<", "mem", ")", ":", "\n", "                    ", "backward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "p", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                        ", "backward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "p", "=", "p", ")", ")", "\n", "backward", ".", "write", "(", "weight_grad_short", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "p", "=", "p", ")", ")", "\n", "", "backward", ".", "write", "(", "bad_padding", ")", "\n", "", "else", ":", "\n", "                    ", "for", "p", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                        ", "backward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "32", ",", "p", "=", "p", ")", ")", "\n", "backward", ".", "write", "(", "weight_grad", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "32", ",", "p", "=", "p", ")", ")", "\n", "", "backward", ".", "write", "(", "bad_padding", ")", "\n", "backward", ".", "write", "(", "breakout", ")", "\n", "break", "\n", "", "backward", ".", "write", "(", "con_else", ")", "\n", "", "", "backward", ".", "write", "(", "bad_filter", ")", "\n", "backward", ".", "write", "(", "last_return", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.parse_config_yaml": [[7, 39], ["quantization_options.convert_yaml_to_tuple", "quantization_options.convert_yaml_to_tuple", "yaml_data[].items", "yaml_data[].items"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.convert_yaml_to_tuple", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.convert_yaml_to_tuple"], ["def", "parse_config_yaml", "(", "yaml_data", ")", ":", "\n", "# Initialize to default options.", "\n", "    ", "quantization_options", "=", "{", "\n", "\"n_centroids\"", ":", "{", "\n", "\"Linear\"", ":", "[", "\"in_features\"", ",", "{", "\"*\"", ":", "256", "}", "]", ",", "\n", "\"Embedding\"", ":", "[", "\"embedding_dim\"", ",", "{", "\"*\"", ":", "256", "}", "]", ",", "\n", "}", ",", "\n", "\"block_sizes\"", ":", "{", "\n", "\"Linear\"", ":", "[", "\"fuzzy_name\"", ",", "{", "\"fc\"", ":", "8", ",", "\"attn\"", ":", "4", ",", "\"emb\"", ":", "4", "}", "]", ",", "\n", "\"Embedding\"", ":", "[", "\"fuzzy_name\"", ",", "{", "\"emb\"", ":", "8", "}", "]", ",", "\n", "}", ",", "\n", "\"layers_to_quantize\"", ":", "[", "\n", "\"decoder\\\\.layers\\\\.\\\\d+\\\\.fc[12]\"", ",", "\n", "\"decoder\\\\.embed_tokens\\\\.embeddings\\\\.[012]\\\\.[01]\"", ",", "\n", "\"decoder\\\\.layers\\\\.\\\\d+\\\\.self_attn\\\\.(k_proj|v_proj|q_proj|out_proj)\"", ",", "\n", "]", ",", "\n", "}", "\n", "\n", "if", "\"n_centroids\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"n_centroids\"", "]", "=", "{", "\n", "layer", ":", "convert_yaml_to_tuple", "(", "layer_data", ")", "\n", "for", "layer", ",", "layer_data", "in", "yaml_data", "[", "\"n_centroids\"", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "if", "\"block_sizes\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"block_sizes\"", "]", "=", "{", "\n", "layer", ":", "convert_yaml_to_tuple", "(", "layer_data", ")", "\n", "for", "layer", ",", "layer_data", "in", "yaml_data", "[", "\"block_sizes\"", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "if", "\"layers_to_quantize\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"layers_to_quantize\"", "]", "=", "yaml_data", "[", "\"layers_to_quantize\"", "]", "\n", "\n", "", "return", "quantization_options", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.quantization.quantization_options.convert_yaml_to_tuple": [[41, 45], ["None"], "function", ["None"], ["", "def", "convert_yaml_to_tuple", "(", "yaml_dictionary", ")", ":", "\n", "    ", "\"\"\"Converts a yaml dictionary with two keys: `key` and `value` into a two\n    argument tuple of those values.\"\"\"", "\n", "return", "(", "yaml_dictionary", "[", "\"key\"", "]", ",", "yaml_dictionary", "[", "\"value\"", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int": [[9, 12], ["q", "globals"], "function", ["None"], ["def", "emulate_int", "(", "w", ",", "bits", ",", "method", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "q", "=", "globals", "(", ")", "[", "f\"emulate_int{bits}_{method}\"", "]", "\n", "return", "q", "(", "w", ",", "scale", "=", "scale", ",", "zero_point", "=", "zero_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.quantize": [[14, 18], ["torch.clamp", "torch.round"], "function", ["None"], ["", "def", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ":", "\n", "    ", "return", "(", "\n", "torch", ".", "clamp", "(", "torch", ".", "round", "(", "w", "/", "scale", "+", "zero_point", ")", ",", "0", ",", "255", ")", "-", "zero_point", "\n", ")", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int8_histogram": [[20, 28], ["torch.quantization.observer.HistogramObserver", "torch.quantization.observer.HistogramObserver.", "torch.quantization.observer.HistogramObserver.calculate_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "w.float", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_histogram", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "HistogramObserver", "(", ")", "\n", "_", "=", "obs", "(", "w", ".", "float", "(", ")", ")", "\n", "scale", ",", "zero_point", "=", "obs", ".", "calculate_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int8_channel": [[30, 40], ["torch.quantization.observer.PerChannelMinMaxObserver", "torch.quantization.observer.PerChannelMinMaxObserver.", "torch.quantization.observer.PerChannelMinMaxObserver.get_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_channel", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "PerChannelMinMaxObserver", "(", "\n", "ch_axis", "=", "-", "1", ",", "qscheme", "=", "torch", ".", "per_channel_symmetric", "\n", ")", "\n", "_", "=", "obs", "(", "w", ")", "\n", "scale", ",", "zero_point", ",", "ch_axis", "=", "obs", ".", "get_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.ops.emulate_int8_tensor": [[42, 50], ["torch.quantization.observer.MinMaxObserver", "torch.quantization.observer.MinMaxObserver.", "torch.quantization.observer.MinMaxObserver.calculate_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_tensor", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "MinMaxObserver", "(", ")", "\n", "_", "=", "obs", "(", "w", ")", "\n", "scale", ",", "zero_point", "=", "obs", ".", "calculate_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scalar.utils.quantize_model_": [[19, 78], ["pq.utils.get_layers", "isinstance", "modules.ActivationQuantizer", "operator.attrgetter", "logging.info", "tuple", "QuantizedModule.__new__", "params.update", "QuantizedModule.__new__.__dict__.update", "pq.utils.attrsetter", "torch.is_initialized", "torch.is_initialized", "MAPPING.keys", "logging.info", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_layers", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.attrsetter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "", "except", "ImportError", ":", "\n", "    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.pq.PQ.__init__": [[39, 58], ["pq.PQ._reshape", "em.EM.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.pq.PQ._reshape", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "W", ",", "\n", "block_size", ",", "\n", "n_centroids", "=", "256", ",", "\n", "n_iter", "=", "20", ",", "\n", "eps", "=", "1e-6", ",", "\n", "max_tentatives", "=", "30", ",", "\n", "verbose", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "block_size", "=", "block_size", "\n", "W_reshaped", "=", "self", ".", "_reshape", "(", "W", ")", "\n", "super", "(", "PQ", ",", "self", ")", ".", "__init__", "(", "\n", "W_reshaped", ",", "\n", "n_centroids", "=", "n_centroids", ",", "\n", "n_iter", "=", "n_iter", ",", "\n", "eps", "=", "eps", ",", "\n", "max_tentatives", "=", "max_tentatives", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.pq.PQ._reshape": [[60, 93], ["len", "W.size", "W.reshape().permute().flatten", "W.size", "len", "W.size", "W.reshape().permute().flatten", "NotImplementedError", "W.reshape().permute", "W.size", "W.size", "W.reshape().permute", "W.reshape", "W.reshape"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_reshape", "(", "self", ",", "W", ")", ":", "\n", "        ", "\"\"\"\n        Reshapes the matrix W as expained in step (1).\n        \"\"\"", "\n", "\n", "# fully connected: by convention the weight has size out_features x in_features", "\n", "if", "len", "(", "W", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "self", ".", "out_features", ",", "self", ".", "in_features", "=", "W", ".", "size", "(", ")", "\n", "assert", "(", "\n", "self", ".", "in_features", "%", "self", ".", "block_size", "==", "0", "\n", ")", ",", "\"Linear: n_blocks must be a multiple of in_features\"", "\n", "return", "(", "\n", "W", ".", "reshape", "(", "self", ".", "out_features", ",", "-", "1", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "\n", "# convolutional: we reshape along the spatial dimension", "\n", "", "elif", "len", "(", "W", ".", "size", "(", ")", ")", "==", "4", ":", "\n", "            ", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "k_h", ",", "self", ".", "k_w", "=", "W", ".", "size", "(", ")", "\n", "assert", "(", "\n", "self", ".", "in_channels", "*", "self", ".", "k_h", "*", "self", ".", "k_w", "\n", ")", "%", "self", ".", "block_size", "==", "0", ",", "(", "\n", "\"Conv2d: n_blocks must be a multiple of in_channels * k_h * k_w\"", "\n", ")", "\n", "return", "(", "\n", "W", ".", "reshape", "(", "self", ".", "out_channels", ",", "-", "1", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "# not implemented", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "W", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.pq.PQ.encode": [[94, 105], ["pq.PQ.initialize_centroids", "range", "pq.PQ.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.initialize_centroids", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "", "def", "encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs self.n_iter EM steps.\n        \"\"\"", "\n", "\n", "self", ".", "initialize_centroids", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_iter", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "step", "(", "i", ")", "\n", "", "except", "EmptyClusterResolveError", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.pq.PQ.decode": [[106, 128], ["pq.PQ.centroids[].reshape().permute().flatten", "pq.PQ.centroids[].reshape().permute().reshape", "pq.PQ.centroids[].reshape().permute", "pq.PQ.centroids[].reshape().permute", "pq.PQ.centroids[].reshape", "pq.PQ.centroids[].reshape"], "methods", ["None"], ["", "", "", "def", "decode", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the encoded full weight matrix. Must be called after\n        the encode function.\n        \"\"\"", "\n", "\n", "# fully connected case", "\n", "if", "\"k_h\"", "not", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "(", "\n", "self", ".", "centroids", "[", "self", ".", "assignments", "]", "\n", ".", "reshape", "(", "-", "1", ",", "self", ".", "out_features", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "\n", "# convolutional case", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "self", ".", "centroids", "[", "self", ".", "assignments", "]", "\n", ".", "reshape", "(", "-", "1", ",", "self", ".", "out_channels", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", ".", "reshape", "(", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "k_h", ",", "self", ".", "k_w", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.__init__": [[34, 46], ["torch.Tensor", "torch.Tensor"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "W", ",", "n_centroids", "=", "256", ",", "n_iter", "=", "20", ",", "eps", "=", "1e-6", ",", "max_tentatives", "=", "30", ",", "verbose", "=", "True", "\n", ")", ":", "\n", "        ", "self", ".", "W", "=", "W", "\n", "self", ".", "n_centroids", "=", "n_centroids", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "max_tentatives", "=", "max_tentatives", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "centroids", "=", "torch", ".", "Tensor", "(", ")", "\n", "self", ".", "assignments", "=", "torch", ".", "Tensor", "(", ")", "\n", "self", ".", "objective", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.initialize_centroids": [[47, 57], ["em.EM.W.size", "torch.randint().long", "em.EM.W[].t", "torch.randint"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "initialize_centroids", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the centroids by sampling random columns from W.\n        \"\"\"", "\n", "\n", "in_features", ",", "out_features", "=", "self", ".", "W", ".", "size", "(", ")", "\n", "indices", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "high", "=", "out_features", ",", "size", "=", "(", "self", ".", "n_centroids", ",", ")", "\n", ")", ".", "long", "(", ")", "\n", "self", ".", "centroids", "=", "self", ".", "W", "[", ":", ",", "indices", "]", ".", "t", "(", ")", "# (n_centroids x in_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step": [[58, 89], ["em.EM.compute_distances", "torch.argmin", "em.EM.resolve_empty_clusters", "range", "em.EM.objective.append", "W_k.mean", "logging.info", "em.EM.centroids[].t"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.compute_distances", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.resolve_empty_clusters"], ["", "def", "step", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"\n        There are two standard steps for each iteration: expectation (E) and\n        minimization (M). The E-step (assignment) is performed with an exhaustive\n        search and the M-step (centroid computation) is performed with\n        the exact solution.\n\n        Args:\n            - i: step number\n\n        Remarks:\n            - The E-step heavily uses PyTorch broadcasting to speed up computations\n              and reduce the memory overhead\n        \"\"\"", "\n", "\n", "# assignments (E-step)", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "n_empty_clusters", "=", "self", ".", "resolve_empty_clusters", "(", ")", "\n", "\n", "# centroids (M-step)", "\n", "for", "k", "in", "range", "(", "self", ".", "n_centroids", ")", ":", "\n", "            ", "W_k", "=", "self", ".", "W", "[", ":", ",", "self", ".", "assignments", "==", "k", "]", "# (in_features x size_of_cluster_k)", "\n", "self", ".", "centroids", "[", "k", "]", "=", "W_k", ".", "mean", "(", "dim", "=", "1", ")", "# (in_features)", "\n", "\n", "# book-keeping", "\n", "", "obj", "=", "(", "self", ".", "centroids", "[", "self", ".", "assignments", "]", ".", "t", "(", ")", "-", "self", ".", "W", ")", ".", "norm", "(", "p", "=", "2", ")", ".", "item", "(", ")", "\n", "self", ".", "objective", ".", "append", "(", "obj", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "f\"Iteration: {i},\\t\"", "\n", "f\"objective: {obj:.6f},\\t\"", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.resolve_empty_clusters": [[93, 132], ["collections.Counter", "len", "map", "set", "set", "len", "random.choice", "em.EM.centroids[].clone", "em.EM.compute_distances", "torch.argmin", "collections.Counter", "range", "collections.Counter.keys", "list", "torch.randn_like", "map", "set", "set", "logging.info", "x.item", "collections.Counter.most_common", "range", "collections.Counter.keys", "x.item", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.compute_distances", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "", "def", "resolve_empty_clusters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        If one cluster is empty, the most populated cluster is split into\n        two clusters by shifting the respective centroids. This is done\n        iteratively for a fixed number of tentatives.\n        \"\"\"", "\n", "\n", "# empty clusters", "\n", "counts", "=", "Counter", "(", "map", "(", "lambda", "x", ":", "x", ".", "item", "(", ")", ",", "self", ".", "assignments", ")", ")", "\n", "empty_clusters", "=", "set", "(", "range", "(", "self", ".", "n_centroids", ")", ")", "-", "set", "(", "counts", ".", "keys", "(", ")", ")", "\n", "n_empty_clusters", "=", "len", "(", "empty_clusters", ")", "\n", "\n", "tentatives", "=", "0", "\n", "while", "len", "(", "empty_clusters", ")", ">", "0", ":", "\n", "# given an empty cluster, find most populated cluster and split it into two", "\n", "            ", "k", "=", "random", ".", "choice", "(", "list", "(", "empty_clusters", ")", ")", "\n", "m", "=", "counts", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "0", "]", "\n", "e", "=", "torch", ".", "randn_like", "(", "self", ".", "centroids", "[", "m", "]", ")", "*", "self", ".", "eps", "\n", "self", ".", "centroids", "[", "k", "]", "=", "self", ".", "centroids", "[", "m", "]", ".", "clone", "(", ")", "\n", "self", ".", "centroids", "[", "k", "]", "+=", "e", "\n", "self", ".", "centroids", "[", "m", "]", "-=", "e", "\n", "\n", "# recompute assignments", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "\n", "# check for empty clusters", "\n", "counts", "=", "Counter", "(", "map", "(", "lambda", "x", ":", "x", ".", "item", "(", ")", ",", "self", ".", "assignments", ")", ")", "\n", "empty_clusters", "=", "set", "(", "range", "(", "self", ".", "n_centroids", ")", ")", "-", "set", "(", "counts", ".", "keys", "(", ")", ")", "\n", "\n", "# increment tentatives", "\n", "if", "tentatives", "==", "self", ".", "max_tentatives", ":", "\n", "                ", "logging", ".", "info", "(", "\n", "f\"Could not resolve all empty clusters, {len(empty_clusters)} remaining\"", "\n", ")", "\n", "raise", "EmptyClusterResolveError", "\n", "", "tentatives", "+=", "1", "\n", "\n", "", "return", "n_empty_clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.compute_distances": [[133, 163], ["torch.cat", "em.EM.centroids.chunk"], "methods", ["None"], ["", "def", "compute_distances", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        For every centroid m, computes\n\n                          ||M - m[None, :]||_2\n\n        Remarks:\n            - We rely on PyTorch's broadcasting to speed up computations\n              and reduce the memory overhead\n            - Without chunking, the sizes in the broadcasting are modified as:\n              (n_centroids x n_samples x out_features) -> (n_centroids x out_features)\n            - The broadcasting computation is automatically chunked so that\n              the tensors fit into the memory of the GPU\n        \"\"\"", "\n", "\n", "nb_centroids_chunks", "=", "1", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "(", "self", ".", "W", "[", "None", ",", ":", ",", ":", "]", "-", "centroids_c", "[", ":", ",", ":", ",", "None", "]", ")", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "for", "centroids_c", "in", "self", ".", "centroids", ".", "chunk", "(", "\n", "nb_centroids_chunks", ",", "dim", "=", "0", "\n", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                ", "nb_centroids_chunks", "*=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.assign": [[164, 176], ["em.EM.compute_distances", "torch.argmin"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.compute_distances"], ["", "", "", "def", "assign", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Assigns each column of W to its closest centroid, thus essentially\n        performing the E-step in train().\n\n        Remarks:\n            - The function must be called after train() or after loading\n              centroids using self.load(), otherwise it will return empty tensors\n        \"\"\"", "\n", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.save": [[177, 190], ["torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save"], ["", "def", "save", "(", "self", ",", "path", ",", "layer", ")", ":", "\n", "        ", "\"\"\"\n        Saves centroids and assignments.\n\n        Args:\n            - path: folder used to save centroids and assignments\n        \"\"\"", "\n", "\n", "torch", ".", "save", "(", "self", ".", "centroids", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_centroids.pth\"", ".", "format", "(", "layer", ")", ")", ")", "\n", "torch", ".", "save", "(", "\n", "self", ".", "assignments", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_assignments.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "torch", ".", "save", "(", "self", ".", "objective", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_objective.pth\"", ".", "format", "(", "layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.load": [[191, 207], ["torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "def", "load", "(", "self", ",", "path", ",", "layer", ")", ":", "\n", "        ", "\"\"\"\n        Loads centroids and assignments from a given path\n\n        Args:\n            - path: folder use to load centroids and assignments\n        \"\"\"", "\n", "\n", "self", ".", "centroids", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_centroids.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "self", ".", "assignments", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_assignments.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "self", ".", "objective", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_objective.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.SizeTracker.__init__": [[269, 276], ["utils.SizeTracker.compute_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.SizeTracker.compute_size"], ["    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.SizeTracker.compute_size": [[277, 286], ["utils.SizeTracker.model.named_parameters", "p.numel"], "methods", ["None"], ["", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.SizeTracker.update": [[287, 307], ["numpy.log2", "W.numel", "W.numel"], "methods", ["None"], ["        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n", "\n", "", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n", "\n", "", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.SizeTracker.__repr__": [[308, 315], ["None"], "methods", ["None"], ["            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.quantize_model_": [[18, 153], ["utils.get_layers", "utils.get_param", "utils.get_param", "module.weight.data.clone", "pq.PQ", "pq.PQ.encode", "pq.PQ.centroids.contiguous", "pq.PQ.assignments.contiguous", "torch.is_initialized", "isinstance", "size_tracker.update", "operator.attrgetter", "logging.info", "module.bias.data.clone", "torch.broadcast", "torch.broadcast", "map", "modules.PQLinear", "isinstance", "utils.attrsetter", "torch.is_initialized", "torch.is_initialized", "map", "modules.PQEmbedding", "isinstance", "torch.get_rank", "module.named_parameters", "map", "map", "modules.PQConv2d", "ValueError"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_layers", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_param", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_param", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.attrsetter", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_rank"], ["import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "", "except", "ImportError", ":", "\n", "    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n", "\n", "\n", "", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n", "\n", "", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n", "\n", "", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n", "\n", "", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_layers": [[155, 191], ["map", "filter", "map", "map", "re.compile", "list", "operator.itemgetter", "model.named_parameters", "filter", "x.replace", "x.replace"], "function", ["None"], ["            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n", "\n", "", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n", "\n", "", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n", "", "", "return", "embed_dict", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.get_param": [[193, 250], ["KeyError", "str", "getattr", "len", "KeyError", "KeyError"], "function", ["None"], ["\n", "", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n", "\n", "", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n", "\n", "", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n", "\n", "", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "return", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "long", "(", ")", "+", "padding_idx", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.utils.attrsetter": [[322, 338], ["attr.split", "getattr", "utils.attrsetter.resolve_attr"], "function", ["None"], ["            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n", "", "", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "norms", ")", ")", "\n", "return", "total_norm", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.forward": [[18, 25], ["dynamicconv_cuda.forward", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "weights", ",", "padding_l", ")", ":", "\n", "        ", "ctx", ".", "padding_l", "=", "padding_l", "\n", "outputs", "=", "dynamicconv_cuda", ".", "forward", "(", "x", ",", "weights", ",", "padding_l", ")", "\n", "variables", "=", "[", "x", ",", "weights", "]", "\n", "ctx", ".", "save_for_backward", "(", "*", "variables", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward": [[26, 33], ["dynamicconv_cuda.backward", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "outputs", "=", "dynamicconv_cuda", ".", "backward", "(", "\n", "grad_output", ".", "contiguous", "(", ")", ",", "ctx", ".", "padding_l", ",", "*", "ctx", ".", "saved_tensors", "\n", ")", "\n", "grad_input", ",", "grad_weights", "=", "outputs", "\n", "return", "grad_input", ",", "grad_weights", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.__init__": [[37, 70], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.Linear", "torch.nn.Linear", "dynamicconv_layer.DynamicconvLayer.reset_parameters", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "bias", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "DynamicconvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "query_size", "=", "input_size", "if", "query_size", "is", "None", "else", "query_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "renorm_padding", "=", "renorm_padding", "\n", "self", ".", "bias", "=", "bias", "\n", "\n", "self", ".", "weight_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_heads", "*", "kernel_size", ",", "bias", ")", "\n", "if", "conv_bias", ":", "\n", "            ", "self", ".", "conv_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters": [[71, 76], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight_linear", ".", "weight", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv_bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weight_linaer", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.forward": [[77, 120], ["x.permute().contiguous.permute().contiguous.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "dynamicconv_layer.DynamicconvLayer.permute().contiguous", "x.permute().contiguous.permute().contiguous.permute().contiguous", "dynamicconvFunction.apply().permute", "dynamicconv_layer.DynamicconvLayer._forward_unfolded", "dynamicconv_layer.DynamicconvLayer._forward_expanded", "torch.softmax", "torch.softmax", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "x.permute().contiguous.permute().contiguous.size", "dynamicconv_layer.DynamicconvLayer.conv_bias.view", "dynamicconv_layer.DynamicconvLayer.weight_linear", "dynamicconv_layer.DynamicconvLayer.permute", "x.permute().contiguous.permute().contiguous.permute", "dynamicconvFunction.apply", "dynamicconv_layer.DynamicconvLayer.conv_bias.view"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "query", "=", "None", ",", "unfold", "=", "None", ")", ":", "\n", "\n", "        ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "# R = C // H", "\n", "\n", "# during inference time, incremental BMM is faster", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "unfold", "=", "(", "\n", "x", ".", "size", "(", "0", ")", ">", "512", "if", "unfold", "is", "None", "else", "unfold", "\n", ")", "# use unfold mode as default for long sequence to save memory", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "assert", "query", "is", "None", "\n", "\n", "if", "query", "is", "None", ":", "\n", "                ", "query", "=", "x", "\n", "", "if", "unfold", ":", "\n", "                ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "\n", "", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n", "# during training time, use CUDA kernel", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "x", ")", ".", "view", "(", "T", ",", "B", ",", "H", ",", "K", ")", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "-", "1", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ":", "\n", "                ", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "\n", "", "weight", "=", "weight", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "self", ".", "filters", "=", "weight", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "output", "=", "dynamicconvFunction", ".", "apply", "(", "x", ",", "weight", ",", "self", ".", "padding_l", ")", ".", "permute", "(", "\n", "2", ",", "0", ",", "1", "\n", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reorder_incremental_state": [[121, 126], ["dynamicconv_layer.DynamicconvLayer._get_input_buffer", "input_buffer.index_select.index_select.index_select", "dynamicconv_layer.DynamicconvLayer._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer": [[127, 129], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer": [[130, 133], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded": [[135, 183], ["x.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "weight.narrow.narrow.narrow", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamicconv_layer.DynamicconvLayer._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "fairseq.modules.unfold.unfold1d", "x_unfold.view.view.view", "torch.softmax", "torch.softmax", "weight.narrow.narrow.size", "torch.softmax", "torch.softmax", "weight.narrow.narrow.unsqueeze", "dynamicconv_layer.DynamicconvLayer.weight_linear", "x.new", "dynamicconv_layer.DynamicconvLayer._set_input_buffer", "weight.narrow.narrow.narrow", "x.unsqueeze", "x_unfold.view.view.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "assert", "not", "self", ".", "renorm_padding", "or", "incremental_state", "is", "not", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "", "x_unfold", "=", "unfold1d", "(", "x", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ".", "unsqueeze", "(", "2", ")", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded": [[184, 228], ["x.view().transpose.view().transpose.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "weight.narrow.narrow.narrow().contiguous", "weight.narrow.narrow.view().transpose", "x.view().transpose.view().transpose.view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "weight.narrow.narrow.new().fill_", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "weight.narrow.narrow.new_zeros", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "dynamicconv_layer.DynamicconvLayer.weight_linear", "torch.softmax", "torch.softmax", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view", "x.view().transpose.view().transpose.view", "float", "weight.narrow.narrow.narrow", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "weight.narrow.narrow.new", "weight_expanded.narrow.narrow.as_strided", "weight_expanded.narrow.narrow.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_stat", ",", "query", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "# turn the convolution filters into band matrices", "\n", "            ", "weight_expanded", "=", "weight", ".", "new", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "self", ".", "padding_l", ",", "T", ")", "\n", "# normalize the weight over valid positions like self-attention", "\n", "weight_expanded", "=", "F", ".", "softmax", "(", "weight_expanded", ",", "dim", "=", "2", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ",", "inplace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "P", "=", "self", ".", "padding_l", "\n", "# For efficieny, we cut the kernel size and reduce the padding when the kernel is larger than the length", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "# B*H x T x T", "\n", "", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.cuda_function_gen.gen_forward": [[7, 94], ["open", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "case_k.format", "forward.write", "main_block.format"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["def", "gen_forward", "(", ")", ":", "\n", "\n", "    ", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "\n", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_forward(at::Tensor input, at::Tensor filters, int padding_l) {\n\n    at::DeviceGuard g(input.device());\n    const auto minibatch = input.size(0);\n    const auto numFeatures = input.size(1);\n    const auto sequenceLength = input.size(2);\n\n    const auto numHeads = filters.size(0);\n    const auto filterSize = filters.size(1);\n\n    const auto numFiltersInBlock = numFeatures / numHeads;\n\n    const dim3 blocks(minibatch, numFeatures);\n\n    auto output = at::zeros_like(input);\n    auto stream = at::cuda::getCurrentCUDAStream();\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n    if (sequenceLength <= {seq}) {{\n        switch(filterSize) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n            case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {pad}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_forward\", ([&] {{\n                        lightconv_forward_kernel<{k}, {b_size}, {pad}, scalar_t>\n                        <<<blocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                output.data<scalar_t>());\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping forward pass\" << std::endl;\n                }\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n            default:\n                std::cout << \"WARNING: Unsupported filter length passed - skipping forward pass\" << std::endl;\n        }\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n    } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "final_return", "=", "\"\"\"\n    }\n\n    return {output};\n}\n\"\"\"", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_forward.cu\"", ",", "\"w\"", ")", "as", "forward", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.cuda_function_gen.gen_backward": [[96, 219], ["open", "backward.write", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "backward.write", "backward.write", "sequence_if.format", "backward.write", "backward.write", "case_k.format", "chunks_reset.format", "backward.write", "case_k.format", "backward.write", "backward.write", "main_block.format", "chunks_reset.format", "main_block.format"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["for", "seq", "in", "seqs", ":", "\n", "            ", "forward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "                ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                    ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "con_else", ")", "\n", "\n", "", "forward", ".", "write", "(", "final_else", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "            ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "final_return", ")", "\n", "\n", "\n", "", "", "def", "gen_backward", "(", ")", ":", "\n", "\n", "    ", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_backward(\n        at::Tensor gradOutput,\n        int padding_l,\n        at::Tensor input,\n        at::Tensor filters) {\n\n    // gradWrtInput\n    const int minibatch = input.size(0);\n    const int numFeatures = input.size(1);\n    const int sequenceLength = input.size(2);\n\n    const int numHeads = filters.size(0);\n    const int filterSize = filters.size(1);\n\n    const dim3 gradBlocks(minibatch, numFeatures);\n    const dim3 weightGradFirstpassShortBlocks(minibatch, numHeads);\n    const dim3 weightGradSecondpassBlocks(numHeads, filterSize);\n\n    const int numFiltersInBlock = numFeatures / numHeads;\n\n    auto gradInput = at::zeros_like(input);\n    auto gradFilters = at::zeros_like(filters);\n\n    at::DeviceGuard g(input.device());\n    auto stream = at::cuda::getCurrentCUDAStream();\n\n    switch(filterSize) {\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n            if (sequenceLength <= {seq}) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n        case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {p}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_backward\", ([&] {{\n                        lightconv_grad_wrt_input_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                gradOutput.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                gradInput.data<scalar_t>());\n\n\"\"\"", "\n", "\n", "weight_grad_short", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numHeads, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_short_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<weightGradFirstpassShortBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                numHeads,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_short_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "weight_grad", "="]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.add_args": [[29, 35], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.logging_outputs_can_be_summed": [[36, 44], ["criterion.logging_outputs_can_be_summed"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.logging_outputs_can_be_summed"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", "criterion", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `train_step` and `valid_step` can\n        be summed across workers prior to calling `aggregate_logging_outputs`.\n        Setting this to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "criterion", ".", "logging_outputs_can_be_summed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.__init__": [[45, 49], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "cfg", ":", "FairseqDataclass", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "datasets", "=", "{", "}", "\n", "self", ".", "dataset_to_epoch_iter", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.load_dictionary": [[50, 58], ["fairseq.data.Dictionary.load"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "return", "Dictionary", ".", "load", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_dictionary": [[59, 82], ["fairseq.data.Dictionary", "fairseq.data.Dictionary.finalize", "fairseq.data.Dictionary.add_file_to_dictionary"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_file_to_dictionary"], ["", "@", "classmethod", "\n", "def", "build_dictionary", "(", "\n", "cls", ",", "filenames", ",", "workers", "=", "1", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", "\n", ")", ":", "\n", "        ", "\"\"\"Build the dictionary\n\n        Args:\n            filenames (list): list of filenames\n            workers (int): number of concurrent workers\n            threshold (int): defines the minimum word count\n            nwords (int): defines the total number of words in the final dictionary,\n                including special symbols\n            padding_factor (int): can be used to pad the dictionary size to be a\n                multiple of 8, which is important on some hardware (e.g., Nvidia\n                Tensor Cores).\n        \"\"\"", "\n", "d", "=", "Dictionary", "(", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "            ", "Dictionary", ".", "add_file_to_dictionary", "(", "\n", "filename", ",", "d", ",", "tokenizer", ".", "tokenize_line", ",", "workers", "\n", ")", "\n", "", "d", ".", "finalize", "(", "threshold", "=", "threshold", ",", "nwords", "=", "nwords", ",", "padding_factor", "=", "padding_factor", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.setup_task": [[83, 91], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            cfg (omegaconf.DictConfig): parsed command-line arguments\n        \"\"\"", "\n", "return", "cls", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.has_sharded_data": [[92, 94], ["getattr"], "methods", ["None"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "os", ".", "pathsep", "in", "getattr", "(", "self", ".", "cfg", ",", "\"data\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.load_dataset": [[95, 111], ["None"], "methods", ["None"], ["", "def", "load_dataset", "(", "\n", "self", ",", "\n", "split", ":", "str", ",", "\n", "combine", ":", "bool", "=", "False", ",", "\n", "task_cfg", ":", "FairseqDataclass", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n            combine (bool): combines a split segmented into pieces into one dataset\n            task_cfg (FairseqDataclass): optional task configuration stored in the checkpoint that can be used\n                                         to load datasets\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.dataset": [[112, 129], ["KeyError", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "dataset", "(", "self", ",", "split", ")", ":", "\n", "        ", "\"\"\"\n        Return a loaded dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n\n        Returns:\n            a :class:`~fairseq.data.FairseqDataset` corresponding to *split*\n        \"\"\"", "\n", "from", "fairseq", ".", "data", "import", "FairseqDataset", "\n", "\n", "if", "split", "not", "in", "self", ".", "datasets", ":", "\n", "            ", "raise", "KeyError", "(", "\"Dataset not loaded: \"", "+", "split", ")", "\n", "", "if", "not", "isinstance", "(", "self", ".", "datasets", "[", "split", "]", ",", "FairseqDataset", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Datasets are expected to be of type FairseqDataset\"", ")", "\n", "", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.filter_indices_by_size": [[130, 162], ["dataset.filter_indices_by_size", "len", "logger.warning", "Exception", "len", "dataset.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.filter_indices_by_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "filter_indices_by_size", "(", "\n", "self", ",", "indices", ",", "dataset", ",", "max_positions", "=", "None", ",", "ignore_invalid_inputs", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Filter examples that are too large\n\n        Args:\n            indices (np.array): original array of sample indices\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n        Returns:\n            np.array: array of filtered sample indices\n        \"\"\"", "\n", "indices", ",", "ignored", "=", "dataset", ".", "filter_indices_by_size", "(", "indices", ",", "max_positions", ")", "\n", "if", "len", "(", "ignored", ")", ">", "0", ":", "\n", "            ", "if", "not", "ignore_invalid_inputs", ":", "\n", "                ", "raise", "Exception", "(", "\n", "(", "\n", "\"Size of sample #{} is invalid (={}) since max_positions={}, \"", "\n", "\"skip this example with --skip-invalid-size-inputs-valid-test\"", "\n", ")", ".", "format", "(", "ignored", "[", "0", "]", ",", "dataset", ".", "size", "(", "ignored", "[", "0", "]", ")", ",", "max_positions", ")", "\n", ")", "\n", "", "logger", ".", "warning", "(", "\n", "(", "\n", "\"{:,} samples have invalid sizes and will be skipped, \"", "\n", "\"max_positions={}, first few sample ids={}\"", "\n", ")", ".", "format", "(", "len", "(", "ignored", ")", ",", "max_positions", ",", "ignored", "[", ":", "10", "]", ")", "\n", ")", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.can_reuse_epoch_itr": [[163, 169], ["getattr"], "methods", ["None"], ["", "def", "can_reuse_epoch_itr", "(", "self", ",", "dataset", ")", ":", "\n", "# We can reuse the epoch iterator across epochs as long as the dataset", "\n", "# hasn't disabled it. We default to ``False`` here, although in practice", "\n", "# this will be ``True`` for most datasets that inherit from", "\n", "# ``FairseqDataset`` due to the base implementation there.", "\n", "        ", "return", "getattr", "(", "dataset", ",", "\"can_reuse_epoch_itr_across_epochs\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.get_batch_iterator": [[170, 268], ["isinstance", "dataset.set_epoch", "dataset.batch_by_size", "fairseq.data.iterators.EpochBatchIterator", "fairseq_task.FairseqTask.can_reuse_epoch_itr", "logger.debug", "fairseq.data.data_utils.numpy_seed", "dataset.ordered_indices", "fairseq_task.FairseqTask.filter_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.can_reuse_epoch_itr", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.ordered_indices", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.filter_indices_by_size"], ["", "def", "get_batch_iterator", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "data_buffer_size", "=", "0", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Get an iterator that yields batches of data from the given dataset.\n\n        Args:\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_tokens (int, optional): max number of tokens in each batch\n                (default: None).\n            max_sentences (int, optional): max number of sentences in each\n                batch (default: None).\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n            required_batch_size_multiple (int, optional): require batch size to\n                be a multiple of N (default: 1).\n            seed (int, optional): seed for random number generator for\n                reproducibility (default: 1).\n            num_shards (int, optional): shard the data iterator into N\n                shards (default: 1).\n            shard_id (int, optional): which shard of the data iterator to\n                return (default: 0).\n            num_workers (int, optional): how many subprocesses to use for data\n                loading. 0 means the data will be loaded in the main process\n                (default: 0).\n            epoch (int, optional): the epoch to start the iterator from\n                (default: 1).\n            data_buffer_size (int, optional): number of batches to\n                preload (default: 0).\n            disable_iterator_cache (bool, optional): don't cache the\n                EpochBatchIterator (ignores `FairseqTask::can_reuse_epoch_itr`)\n                (default: False).\n        Returns:\n            ~fairseq.iterators.EpochBatchIterator: a batched iterator over the\n                given dataset split\n        \"\"\"", "\n", "can_reuse_epoch_itr", "=", "not", "disable_iterator_cache", "and", "self", ".", "can_reuse_epoch_itr", "(", "\n", "dataset", "\n", ")", "\n", "if", "can_reuse_epoch_itr", "and", "dataset", "in", "self", ".", "dataset_to_epoch_iter", ":", "\n", "            ", "logger", ".", "debug", "(", "\"reusing EpochBatchIterator for epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "return", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "\n", "\n", "", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "\n", "# initialize the dataset with the correct starting epoch", "\n", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# get indices ordered by example size", "\n", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "            ", "indices", "=", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n", "# filter examples that are too large", "\n", "", "if", "max_positions", "is", "not", "None", ":", "\n", "            ", "indices", "=", "self", ".", "filter_indices_by_size", "(", "\n", "indices", ",", "dataset", ",", "max_positions", ",", "ignore_invalid_inputs", "\n", ")", "\n", "\n", "# create mini-batches with given size constraints", "\n", "", "batch_sampler", "=", "dataset", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n", "\n", "# return a reusable, sharded iterator", "\n", "epoch_iter", "=", "iterators", ".", "EpochBatchIterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "buffer_size", "=", "data_buffer_size", ",", "\n", ")", "\n", "\n", "if", "can_reuse_epoch_itr", ":", "\n", "            ", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "=", "epoch_iter", "\n", "\n", "", "return", "epoch_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_model": [[269, 285], ["models.build_model", "quantization_utils.quantize_model_scalar"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.quantize_model_scalar"], ["", "def", "build_model", "(", "self", ",", "cfg", ":", "FairseqDataclass", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.models.BaseFairseqModel` instance for this\n        task.\n\n        Args:\n            cfg (FairseqDataclass): configuration object\n\n        Returns:\n            a :class:`~fairseq.models.BaseFairseqModel` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "models", ",", "quantization_utils", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "cfg", ",", "self", ")", "\n", "model", "=", "quantization_utils", ".", "quantize_model_scalar", "(", "model", ",", "cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_criterion": [[286, 300], ["criterions.build_criterion"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.__init__.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "cfg", ":", "DictConfig", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.criterions.FairseqCriterion` instance for\n        this task.\n\n        Args:\n            cfg (omegaconf.DictConfig): configration object\n\n        Returns:\n            a :class:`~fairseq.criterions.FairseqCriterion` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "criterions", "\n", "\n", "return", "criterions", ".", "build_criterion", "(", "cfg", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_generator": [[301, 400], ["getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "seq_gen_cls", "SequenceScorer", "sum", "ValueError", "fairseq.search.Sampling", "getattr", "fairseq.search.DiverseBeamSearch", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "int", "fairseq.search.LengthConstrainedBeamSearch", "getattr", "fairseq.search.DiverseSiblingsSearch", "fairseq.search.LexicallyConstrainedBeamSearch", "fairseq.search.PrefixConstrainedBeamSearch", "fairseq.search.BeamSearch"], "methods", ["None"], ["", "def", "build_generator", "(", "\n", "self", ",", "models", ",", "args", ",", "seq_gen_cls", "=", "None", ",", "extra_gen_cls_kwargs", "=", "None", "\n", ")", ":", "\n", "        ", "if", "getattr", "(", "args", ",", "\"score_reference\"", ",", "False", ")", ":", "\n", "            ", "from", "fairseq", ".", "sequence_scorer", "import", "SequenceScorer", "\n", "\n", "return", "SequenceScorer", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "compute_alignment", "=", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ",", "\n", ")", "\n", "\n", "", "from", "fairseq", ".", "sequence_generator", "import", "(", "\n", "SequenceGenerator", ",", "\n", "SequenceGeneratorWithAlignment", ",", "\n", ")", "\n", "\n", "# Choose search strategy. Defaults to Beam Search.", "\n", "sampling", "=", "getattr", "(", "args", ",", "\"sampling\"", ",", "False", ")", "\n", "sampling_topk", "=", "getattr", "(", "args", ",", "\"sampling_topk\"", ",", "-", "1", ")", "\n", "sampling_topp", "=", "getattr", "(", "args", ",", "\"sampling_topp\"", ",", "-", "1.0", ")", "\n", "diverse_beam_groups", "=", "getattr", "(", "args", ",", "\"diverse_beam_groups\"", ",", "-", "1", ")", "\n", "diverse_beam_strength", "=", "getattr", "(", "args", ",", "\"diverse_beam_strength\"", ",", "0.5", ")", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", "\n", "diversity_rate", "=", "getattr", "(", "args", ",", "\"diversity_rate\"", ",", "-", "1", ")", "\n", "constrained", "=", "getattr", "(", "args", ",", "\"constraints\"", ",", "False", ")", "\n", "prefix_allowed_tokens_fn", "=", "getattr", "(", "args", ",", "\"prefix_allowed_tokens_fn\"", ",", "None", ")", "\n", "if", "(", "\n", "sum", "(", "\n", "int", "(", "cond", ")", "\n", "for", "cond", "in", "[", "\n", "sampling", ",", "\n", "diverse_beam_groups", ">", "0", ",", "\n", "match_source_len", ",", "\n", "diversity_rate", ">", "0", ",", "\n", "]", "\n", ")", "\n", ">", "1", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Provided Search parameters are mutually exclusive.\"", ")", "\n", "", "assert", "sampling_topk", "<", "0", "or", "sampling", ",", "\"--sampling-topk requires --sampling\"", "\n", "assert", "sampling_topp", "<", "0", "or", "sampling", ",", "\"--sampling-topp requires --sampling\"", "\n", "\n", "if", "sampling", ":", "\n", "            ", "search_strategy", "=", "search", ".", "Sampling", "(", "\n", "self", ".", "target_dictionary", ",", "sampling_topk", ",", "sampling_topp", "\n", ")", "\n", "", "elif", "diverse_beam_groups", ">", "0", ":", "\n", "            ", "search_strategy", "=", "search", ".", "DiverseBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "diverse_beam_groups", ",", "diverse_beam_strength", "\n", ")", "\n", "", "elif", "match_source_len", ":", "\n", "# this is useful for tagging applications where the output", "\n", "# length should match the input length, so we hardcode the", "\n", "# length constraints for simplicity", "\n", "            ", "search_strategy", "=", "search", ".", "LengthConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "min_len_a", "=", "1", ",", "\n", "min_len_b", "=", "0", ",", "\n", "max_len_a", "=", "1", ",", "\n", "max_len_b", "=", "0", ",", "\n", ")", "\n", "", "elif", "diversity_rate", ">", "-", "1", ":", "\n", "            ", "search_strategy", "=", "search", ".", "DiverseSiblingsSearch", "(", "\n", "self", ".", "target_dictionary", ",", "diversity_rate", "\n", ")", "\n", "", "elif", "constrained", ":", "\n", "            ", "search_strategy", "=", "search", ".", "LexicallyConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "args", ".", "constraints", "\n", ")", "\n", "", "elif", "prefix_allowed_tokens_fn", ":", "\n", "            ", "search_strategy", "=", "search", ".", "PrefixConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "prefix_allowed_tokens_fn", "\n", ")", "\n", "", "else", ":", "\n", "            ", "search_strategy", "=", "search", ".", "BeamSearch", "(", "self", ".", "target_dictionary", ")", "\n", "\n", "", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "or", "{", "}", "\n", "if", "seq_gen_cls", "is", "None", ":", "\n", "            ", "if", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ":", "\n", "                ", "seq_gen_cls", "=", "SequenceGeneratorWithAlignment", "\n", "extra_gen_cls_kwargs", "[", "\"print_alignment\"", "]", "=", "args", ".", "print_alignment", "\n", "", "else", ":", "\n", "                ", "seq_gen_cls", "=", "SequenceGenerator", "\n", "\n", "", "", "return", "seq_gen_cls", "(", "\n", "models", ",", "\n", "self", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"beam\"", ",", "5", ")", ",", "\n", "max_len_a", "=", "getattr", "(", "args", ",", "\"max_len_a\"", ",", "0", ")", ",", "\n", "max_len_b", "=", "getattr", "(", "args", ",", "\"max_len_b\"", ",", "200", ")", ",", "\n", "min_len", "=", "getattr", "(", "args", ",", "\"min_len\"", ",", "1", ")", ",", "\n", "normalize_scores", "=", "(", "not", "getattr", "(", "args", ",", "\"unnormalized\"", ",", "False", ")", ")", ",", "\n", "len_penalty", "=", "getattr", "(", "args", ",", "\"lenpen\"", ",", "1", ")", ",", "\n", "unk_penalty", "=", "getattr", "(", "args", ",", "\"unkpen\"", ",", "0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "\"temperature\"", ",", "1.0", ")", ",", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", ",", "\n", "no_repeat_ngram_size", "=", "getattr", "(", "args", ",", "\"no_repeat_ngram_size\"", ",", "0", ")", ",", "\n", "search_strategy", "=", "search_strategy", ",", "\n", "**", "extra_gen_cls_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.train_step": [[402, 434], ["model.train", "model.set_num_updates", "torch.autograd.profiler.record_function", "criterion", "torch.autograd.profiler.record_function", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Do forward and backward, and return the loss as computed by *criterion*\n        for the given *model* and *sample*.\n\n        Args:\n            sample (dict): the mini-batch. The format is defined by the\n                :class:`~fairseq.data.FairseqDataset`.\n            model (~fairseq.models.BaseFairseqModel): the model\n            criterion (~fairseq.criterions.FairseqCriterion): the criterion\n            optimizer (~fairseq.optim.FairseqOptimizer): the optimizer\n            update_num (int): the current update\n            ignore_grad (bool): multiply loss by 0 if this is set to True\n\n        Returns:\n            tuple:\n                - the loss\n                - the sample size, which is used as the denominator for the\n                  gradient\n                - logging outputs to display while training\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "set_num_updates", "(", "update_num", ")", "\n", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"forward\"", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"backward\"", ")", ":", "\n", "            ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.valid_step": [[435, 440], ["model.eval", "torch.no_grad", "criterion"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.criterion"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.optimizer_step": [[441, 443], ["optimizer.step"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pq.em.EM.step"], ["", "def", "optimizer_step", "(", "self", ",", "optimizer", ",", "model", ",", "update_num", ")", ":", "\n", "        ", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_dataset_for_inference": [[444, 448], ["None"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "\n", "self", ",", "src_tokens", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "src_lengths", ":", "List", "[", "int", "]", ",", "**", "kwargs", "\n", ")", "->", "torch", ".", "utils", ".", "data", ".", "Dataset", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.inference_step": [[449, 455], ["torch.no_grad", "generator.generate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "generator", ".", "generate", "(", "\n", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ",", "constraints", "=", "constraints", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_epoch": [[457, 460], ["None"], "methods", ["None"], ["", "", "def", "begin_epoch", "(", "self", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "\"\"\"Hook function called before the start of each epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.begin_valid_epoch": [[461, 464], ["None"], "methods", ["None"], ["", "def", "begin_valid_epoch", "(", "self", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "\"\"\"Hook function called before the start of each validation epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.aggregate_logging_outputs": [[465, 474], ["fairseq.utils.deprecation_warning", "fairseq.metrics.aggregate", "fairseq_task.FairseqTask.reduce_metrics", "agg.get_smoothed_values"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.aggregate", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.MetersDict.get_smoothed_values"], ["", "def", "aggregate_logging_outputs", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "\"\"\"[deprecated] Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"The aggregate_logging_outputs API is deprecated. \"", "\n", "\"Please use the reduce_metrics API instead.\"", "\n", ")", "\n", "with", "metrics", ".", "aggregate", "(", ")", "as", "agg", ":", "\n", "            ", "self", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "return", "agg", ".", "get_smoothed_values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.reduce_metrics": [[475, 510], ["criterion.__class__.reduce_metrics", "getattr", "fairseq.utils.deprecation_warning", "fairseq_task.FairseqTask.aggregate_logging_outputs", "fairseq_task.FairseqTask.items", "any", "warnings.warn", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_speed", "any", "warnings.warn", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "log.get", "log.get"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_speed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar"], ["", "", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "# backward compatibility for tasks that override aggregate_logging_outputs", "\n", "base_func", "=", "FairseqTask", ".", "aggregate_logging_outputs", "\n", "self_func", "=", "getattr", "(", "self", ",", "\"aggregate_logging_outputs\"", ")", ".", "__func__", "\n", "if", "self_func", "is", "not", "base_func", ":", "\n", "            ", "utils", ".", "deprecation_warning", "(", "\n", "\"Tasks should implement the reduce_metrics API. \"", "\n", "\"Falling back to deprecated aggregate_logging_outputs API.\"", "\n", ")", "\n", "agg_logging_outputs", "=", "self", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "criterion", "\n", ")", "\n", "for", "k", ",", "v", "in", "agg_logging_outputs", ".", "items", "(", ")", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "k", ",", "v", ")", "\n", "", "return", "\n", "\n", "", "if", "not", "any", "(", "\"ntokens\"", "in", "log", "for", "log", "in", "logging_outputs", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"ntokens not found in Criterion logging outputs, cannot log wpb or wps\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"wpb\"", ",", "ntokens", ",", "priority", "=", "180", ",", "round", "=", "1", ")", "\n", "metrics", ".", "log_speed", "(", "\"wps\"", ",", "ntokens", ",", "priority", "=", "90", ",", "round", "=", "1", ")", "\n", "\n", "", "if", "not", "any", "(", "\"nsentences\"", "in", "log", "for", "log", "in", "logging_outputs", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"nsentences not found in Criterion logging outputs, cannot log bsz\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"bsz\"", ",", "nsentences", ",", "priority", "=", "190", ",", "round", "=", "1", ")", "\n", "\n", "", "criterion", ".", "__class__", ".", "reduce_metrics", "(", "logging_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.max_positions": [[511, 514], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max input length allowed by the task.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.source_dictionary": [[515, 520], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the source :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.target_dictionary": [[521, 526], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the target :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer": [[527, 530], ["fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer"], ["", "def", "build_tokenizer", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Build the pre-tokenizer for this task.\"\"\"", "\n", "return", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_bpe": [[531, 534], ["fairseq.data.encoders.build_bpe"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_bpe"], ["", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Build the tokenizer for this task.\"\"\"", "\n", "return", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.__init__": [[537, 541], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "datasets", "=", "{", "}", "\n", "self", ".", "dataset_to_epoch_iter", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.setup_task": [[542, 550], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ":", "Namespace", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "return", "cls", "(", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.has_sharded_data": [[551, 553], ["getattr"], "methods", ["None"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "os", ".", "pathsep", "in", "getattr", "(", "self", ".", "args", ",", "\"data\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.build_model": [[554, 570], ["models.build_model", "quantization_utils.quantize_model_scalar"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.quantization_utils.quantize_model_scalar"], ["", "def", "build_model", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.models.BaseFairseqModel` instance for this\n        task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.models.BaseFairseqModel` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "models", ",", "quantization_utils", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "model", "=", "quantization_utils", ".", "quantize_model_scalar", "(", "model", ",", "args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.LegacyFairseqTask.build_criterion": [[571, 585], ["criterions.build_criterion"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.__init__.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.criterions.FairseqCriterion` instance for\n        this task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.criterions.FairseqCriterion` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "criterions", "\n", "\n", "return", "criterions", ".", "build_criterion", "(", "args", ",", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.LabelEncoder.__init__": [[28, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.LabelEncoder.__call__": [[31, 34], ["audio_pretraining.LabelEncoder.dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "__call__", "(", "self", ",", "label", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", ".", "encode_line", "(", "\n", "label", ",", "append_eos", "=", "False", ",", "add_if_not_exist", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.__init__": [[105, 117], ["FairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "AudioPretrainingConfig", ",", "\n", "source_dictionary", "=", "None", ",", "\n", "target_dictionary", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_target_dictionary", "=", "target_dictionary", "\n", "self", ".", "_source_dictionary", "=", "source_dictionary", "\n", "if", "cfg", ".", "eval_wer", ":", "\n", "            ", "assert", "cfg", ".", "labels", "is", "not", "None", ",", "\"eval_wer can only be set during fine-tuning\"", "\n", "", "self", ".", "blank_symbol", "=", "\"<s>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.setup_task": [[118, 133], ["cls", "os.path.join", "fairseq.data.Dictionary.load"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "cfg", ":", "AudioPretrainingConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            cfg (AudioPretrainingConfig): configuration of this task\n        \"\"\"", "\n", "\n", "if", "cfg", ".", "labels", ":", "\n", "            ", "dict_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "data", ",", "f\"dict.{cfg.labels}.txt\"", ")", "\n", "target_dictionary", "=", "Dictionary", ".", "load", "(", "dict_path", ")", "\n", "", "else", ":", "\n", "            ", "target_dictionary", "=", "None", "\n", "\n", "", "return", "cls", "(", "cfg", ",", "target_dictionary", "=", "target_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.load_dataset": [[134, 178], ["isinstance", "os.path.join", "fairseq.data.FileAudioDataset", "os.path.join", "audio_pretraining.LabelEncoder", "fairseq.data.AddTargetDataset", "hasattr", "open", "len", "len", "len", "len", "audio_pretraining.AudioPretrainingTask.target_dictionary.pad", "audio_pretraining.AudioPretrainingTask.target_dictionary.eos", "enumerate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ":", "str", ",", "task_cfg", ":", "FairseqDataclass", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "data_path", "=", "self", ".", "cfg", ".", "data", "\n", "task_cfg", "=", "task_cfg", "or", "self", ".", "cfg", "\n", "\n", "# upgrade old task", "\n", "if", "isinstance", "(", "task_cfg", ",", "Namespace", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "task_cfg", ",", "\"autoregressive\"", ")", ":", "\n", "                ", "task_cfg", ".", "autoregressive", "=", "not", "task_cfg", ".", "criterion", "==", "'ctc'", "\n", "\n", "", "", "manifest", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.tsv\"", ".", "format", "(", "split", ")", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "FileAudioDataset", "(", "\n", "manifest", ",", "\n", "sample_rate", "=", "task_cfg", ".", "sample_rate", ",", "\n", "max_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_length", "=", "self", ".", "cfg", ".", "min_sample_size", ",", "\n", "pad", "=", "task_cfg", ".", "labels", "is", "not", "None", "or", "task_cfg", ".", "enable_padding", ",", "\n", "normalize", "=", "task_cfg", ".", "normalize", ",", "\n", "del_silence", "=", "self", ".", "cfg", ".", "del_silence", ",", "\n", ")", "\n", "\n", "if", "task_cfg", ".", "labels", ":", "\n", "            ", "label_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "f\"{split}.{task_cfg.labels}\"", ")", "\n", "labels", "=", "[", "]", "\n", "with", "open", "(", "label_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "labels", "=", "[", "\n", "line", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", "\n", "if", "i", "in", "self", ".", "datasets", "[", "split", "]", ".", "line_inds", "\n", "]", "\n", "\n", "", "assert", "len", "(", "labels", ")", "==", "len", "(", "self", ".", "datasets", "[", "split", "]", ")", ",", "(", "\n", "f\"labels length ({len(labels)}) and dataset length \"", "\n", "f\"({len(self.datasets[split])}) do not match\"", ")", "\n", "\n", "process_label", "=", "LabelEncoder", "(", "self", ".", "target_dictionary", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "AddTargetDataset", "(", "\n", "self", ".", "datasets", "[", "split", "]", ",", "\n", "labels", ",", "\n", "pad", "=", "self", ".", "target_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", "batch_targets", "=", "True", ",", "\n", "process_label", "=", "process_label", ",", "\n", "add_to_input", "=", "task_cfg", ".", "autoregressive", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.source_dictionary": [[180, 183], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_source_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.target_dictionary": [[184, 189], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "_target_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.max_positions": [[190, 193], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "(", "sys", ".", "maxsize", ",", "sys", ".", "maxsize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.filter_indices_by_size": [[194, 203], ["None"], "methods", ["None"], ["", "def", "filter_indices_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "dataset", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", ")", ":", "\n", "# we do not need to filter by size in this task as dataloaders take care of this", "\n", "        ", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.valid_step": [[204, 213], ["super().valid_step", "audio_pretraining.AudioPretrainingTask._inference_with_wer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask._inference_with_wer"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "metrics", "=", "self", ".", "_inference_with_wer", "(", "self", ".", "sequence_generator", ",", "sample", ",", "model", ")", "\n", "logging_output", "[", "\"_num_char_errors\"", "]", "=", "metrics", "[", "\"num_char_errors\"", "]", "\n", "logging_output", "[", "\"_num_chars\"", "]", "=", "metrics", "[", "\"num_chars\"", "]", "\n", "logging_output", "[", "\"_num_word_errors\"", "]", "=", "metrics", "[", "\"num_word_errors\"", "]", "\n", "logging_output", "[", "\"_num_words\"", "]", "=", "metrics", "[", "\"num_words\"", "]", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.build_model": [[214, 227], ["super().build_model", "audio_pretraining.AudioPretrainingTask.build_generator", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_generator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer"], ["", "def", "build_model", "(", "self", ",", "model_cfg", ":", "FairseqDataclass", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "model_cfg", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "\n", "[", "model", "]", ",", "\n", "self", ".", "cfg", ".", "eval_wer_config", ",", "\n", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer_tokenizer", ":", "\n", "                ", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "self", ".", "cfg", ".", "eval_wer_tokenizer", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "None", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask._inference_with_wer": [[228, 261], ["audio_pretraining.AudioPretrainingTask.inference_step", "range", "audio_pretraining.AudioPretrainingTask.target_dictionary.string", "len", "audio_pretraining.AudioPretrainingTask._inference_with_wer.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.inference_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "_inference_with_wer", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "editdistance", "\n", "\n", "def", "decode", "(", "toks", ")", ":", "\n", "            ", "s", "=", "self", ".", "target_dictionary", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "cfg", ".", "eval_wer_post_process", ",", "\n", "escape_unk", "=", "True", ",", "\n", ")", "\n", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "num_word_errors", ",", "num_char_errors", "=", "0", ",", "0", "\n", "num_chars", ",", "num_words", "=", "0", ",", "0", "\n", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "None", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyp", "=", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", "\n", "ref", "=", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "self", ".", "target_dictionary", ".", "pad", "(", ")", ")", ",", "\n", ")", "\n", "num_char_errors", "+=", "editdistance", ".", "eval", "(", "hyp", ",", "ref", ")", "\n", "num_chars", "+=", "len", "(", "ref", ")", "\n", "hyp_words", "=", "hyp", ".", "split", "(", ")", "\n", "ref_words", "=", "ref", ".", "split", "(", ")", "\n", "num_word_errors", "+=", "editdistance", ".", "eval", "(", "hyp_words", ",", "ref_words", ")", "\n", "num_words", "+=", "len", "(", "ref_words", ")", "\n", "\n", "", "return", "{", "\n", "\"num_char_errors\"", ":", "num_char_errors", ",", "\n", "\"num_chars\"", ":", "num_chars", ",", "\n", "\"num_word_errors\"", ":", "num_word_errors", ",", "\n", "\"num_words\"", ":", "num_words", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_pretraining.AudioPretrainingTask.reduce_metrics": [[263, 295], ["super().reduce_metrics", "torch.scalar_tensor", "sum", "sum", "sum", "sum", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_derived", "logging.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "float", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived"], ["", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "\n", "zero", "=", "torch", ".", "scalar_tensor", "(", "0.0", ")", "\n", "num_char_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_char_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_chars", "=", "sum", "(", "log", ".", "get", "(", "\"_num_chars\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "num_word_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_word_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_words", "=", "sum", "(", "log", ".", "get", "(", "\"_num_words\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_char_errors\"", ",", "num_char_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_chars\"", ",", "num_chars", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_word_errors\"", ",", "num_word_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_words\"", ",", "num_words", ")", "\n", "if", "num_words", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_char_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_chars\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_chars\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_word_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_words\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_words\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.__init__.setup_task": [[24, 45], ["getattr", "isinstance", "task.setup_task", "getattr", "fairseq.dataclass.utils.populate_dataclass", "fairseq.dataclass.utils.merge_with_parent", "TASK_REGISTRY.keys", "dc", "dc"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.populate_dataclass", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.merge_with_parent"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.__init__.register_task": [[47, 100], ["TASK_CLASS_NAMES.add", "ValueError", "issubclass", "ValueError", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "issubclass"], "function", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.__init__.get_task": [[102, 104], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.LabelEncoder.__init__": [[28, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.LabelEncoder.__call__": [[31, 34], ["audio_multitraining.LabelEncoder.dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "__call__", "(", "self", ",", "label", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", ".", "encode_line", "(", "\n", "label", ",", "append_eos", "=", "False", ",", "add_if_not_exist", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.__init__": [[105, 119], ["FairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "AudioMultitrainingConfig", ",", "\n", "source_dictionary", "=", "None", ",", "\n", "target_dictionary", "=", "None", ",", "\n", "additional_dictionary", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_target_dictionary", "=", "target_dictionary", "\n", "self", ".", "_source_dictionary", "=", "source_dictionary", "\n", "self", ".", "_additional_dictionary", "=", "additional_dictionary", "\n", "if", "cfg", ".", "eval_wer", ":", "\n", "            ", "assert", "cfg", ".", "labels", "is", "not", "None", ",", "\"eval_wer can only be set during fine-tuning\"", "\n", "", "self", ".", "blank_symbol", "=", "\"<s>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task": [[120, 139], ["cls", "os.path.join", "fairseq.data.Dictionary.load", "os.path.join", "fairseq.data.Dictionary.load"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "cfg", ":", "AudioMultitrainingConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            cfg (AudioPretrainingConfig): configuration of this task\n        \"\"\"", "\n", "\n", "if", "cfg", ".", "labels", ":", "\n", "            ", "dict_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "data", ",", "f\"dict.{cfg.labels}.txt\"", ")", "\n", "target_dictionary", "=", "Dictionary", ".", "load", "(", "dict_path", ")", "\n", "\n", "add_dict_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "data", ",", "f\"add_dict.{cfg.labels}.txt\"", ")", "\n", "additional_dictionary", "=", "Dictionary", ".", "load", "(", "add_dict_path", ")", "\n", "", "else", ":", "\n", "            ", "target_dictionary", "=", "None", "\n", "additional_dictionary", "=", "None", "\n", "\n", "", "return", "cls", "(", "cfg", ",", "target_dictionary", "=", "target_dictionary", ",", "additional_dictionary", "=", "additional_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.train_step": [[140, 173], ["model.train", "model.set_num_updates", "criterion.set_num_updates", "torch.autograd.profiler.record_function", "criterion", "torch.autograd.profiler.record_function", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq_cli.train.train", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Do forward and backward, and return the loss as computed by *criterion*\n        for the given *model* and *sample*.\n\n        Args:\n            sample (dict): the mini-batch. The format is defined by the\n                :class:`~fairseq.data.FairseqDataset`.\n            model (~fairseq.models.BaseFairseqModel): the model\n            criterion (~fairseq.criterions.FairseqCriterion): the criterion\n            optimizer (~fairseq.optim.FairseqOptimizer): the optimizer\n            update_num (int): the current update\n            ignore_grad (bool): multiply loss by 0 if this is set to True\n\n        Returns:\n            tuple:\n                - the loss\n                - the sample size, which is used as the denominator for the\n                  gradient\n                - logging outputs to display while training\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "set_num_updates", "(", "update_num", ")", "\n", "criterion", ".", "set_num_updates", "(", "update_num", ")", "\n", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"forward\"", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"backward\"", ")", ":", "\n", "            ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.load_dataset": [[174, 235], ["isinstance", "os.path.join", "fairseq.data.FileAudioDataset", "os.path.join", "os.path.join", "audio_multitraining.LabelEncoder", "audio_multitraining.LabelEncoder", "fairseq.data.AddMultiDataset", "hasattr", "open", "open", "len", "len", "len", "len", "len", "len", "len", "len", "audio_multitraining.AudioMultitrainingTask.target_dictionary.pad", "audio_multitraining.AudioMultitrainingTask.target_dictionary.eos", "audio_multitraining.AudioMultitrainingTask.additional_dictionary.pad", "audio_multitraining.AudioMultitrainingTask.additional_dictionary.eos", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ":", "str", ",", "task_cfg", ":", "FairseqDataclass", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "data_path", "=", "self", ".", "cfg", ".", "data", "\n", "task_cfg", "=", "task_cfg", "or", "self", ".", "cfg", "\n", "\n", "# upgrade old task", "\n", "if", "isinstance", "(", "task_cfg", ",", "Namespace", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "task_cfg", ",", "\"autoregressive\"", ")", ":", "\n", "                ", "task_cfg", ".", "autoregressive", "=", "not", "task_cfg", ".", "criterion", "==", "'ctc'", "\n", "\n", "", "", "manifest", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.tsv\"", ".", "format", "(", "split", ")", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "FileAudioDataset", "(", "\n", "manifest", ",", "\n", "sample_rate", "=", "task_cfg", ".", "sample_rate", ",", "\n", "max_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_length", "=", "self", ".", "cfg", ".", "min_sample_size", ",", "\n", "pad", "=", "task_cfg", ".", "labels", "is", "not", "None", "or", "task_cfg", ".", "enable_padding", ",", "\n", "normalize", "=", "task_cfg", ".", "normalize", ",", "\n", "del_silence", "=", "self", ".", "cfg", ".", "del_silence", ",", "\n", ")", "\n", "\n", "if", "task_cfg", ".", "labels", ":", "\n", "            ", "label_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "f\"{split}.{task_cfg.labels}\"", ")", "\n", "labels", "=", "[", "]", "\n", "with", "open", "(", "label_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "labels", "=", "[", "\n", "line", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", "\n", "if", "i", "in", "self", ".", "datasets", "[", "split", "]", ".", "line_inds", "\n", "]", "\n", "\n", "", "add_label_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "f\"add_{split}.{task_cfg.labels}\"", ")", "\n", "add_labels", "=", "[", "]", "\n", "with", "open", "(", "add_label_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "add_labels", "=", "[", "\n", "line", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", "\n", "if", "i", "in", "self", ".", "datasets", "[", "split", "]", ".", "line_inds", "\n", "]", "\n", "\n", "", "assert", "len", "(", "labels", ")", "==", "len", "(", "self", ".", "datasets", "[", "split", "]", ")", ",", "(", "\n", "f\"labels length ({len(labels)}) and dataset length \"", "\n", "f\"({len(self.datasets[split])}) do not match\"", ")", "\n", "\n", "assert", "len", "(", "add_labels", ")", "==", "len", "(", "self", ".", "datasets", "[", "split", "]", ")", ",", "(", "\n", "f\"labels length ({len(add_labels)}) and dataset length \"", "\n", "f\"({len(self.datasets[split])}) do not match\"", ")", "\n", "\n", "process_label", "=", "LabelEncoder", "(", "self", ".", "target_dictionary", ")", "\n", "add_process_label", "=", "LabelEncoder", "(", "self", ".", "additional_dictionary", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "AddMultiDataset", "(", "\n", "self", ".", "datasets", "[", "split", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "add_labels", "=", "add_labels", ",", "\n", "pad", "=", "self", ".", "target_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", "add_pad", "=", "self", ".", "additional_dictionary", ".", "pad", "(", ")", ",", "\n", "add_eos", "=", "self", ".", "additional_dictionary", ".", "eos", "(", ")", ",", "\n", "batch_targets", "=", "True", ",", "\n", "process_label", "=", "process_label", ",", "\n", "add_process_label", "=", "add_process_label", ",", "\n", "add_to_input", "=", "task_cfg", ".", "autoregressive", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.source_dictionary": [[237, 240], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_source_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.target_dictionary": [[241, 246], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "_target_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.additional_dictionary": [[247, 252], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "additional_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "_additional_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.max_positions": [[253, 256], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "(", "sys", ".", "maxsize", ",", "sys", ".", "maxsize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.filter_indices_by_size": [[257, 266], ["None"], "methods", ["None"], ["", "def", "filter_indices_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "dataset", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", ")", ":", "\n", "# we do not need to filter by size in this task as dataloaders take care of this", "\n", "        ", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step": [[267, 276], ["super().valid_step", "audio_multitraining.AudioMultitrainingTask._inference_with_wer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.valid_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask._inference_with_wer"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "metrics", "=", "self", ".", "_inference_with_wer", "(", "self", ".", "sequence_generator", ",", "sample", ",", "model", ")", "\n", "logging_output", "[", "\"_num_char_errors\"", "]", "=", "metrics", "[", "\"num_char_errors\"", "]", "\n", "logging_output", "[", "\"_num_chars\"", "]", "=", "metrics", "[", "\"num_chars\"", "]", "\n", "logging_output", "[", "\"_num_word_errors\"", "]", "=", "metrics", "[", "\"num_word_errors\"", "]", "\n", "logging_output", "[", "\"_num_words\"", "]", "=", "metrics", "[", "\"num_words\"", "]", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.build_model": [[277, 290], ["super().build_model", "audio_multitraining.AudioMultitrainingTask.build_generator", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_generator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_tokenizer"], ["", "def", "build_model", "(", "self", ",", "model_cfg", ":", "FairseqDataclass", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "model_cfg", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "\n", "[", "model", "]", ",", "\n", "self", ".", "cfg", ".", "eval_wer_config", ",", "\n", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer_tokenizer", ":", "\n", "                ", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "self", ".", "cfg", ".", "eval_wer_tokenizer", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "None", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask._inference_with_wer": [[291, 324], ["audio_multitraining.AudioMultitrainingTask.inference_step", "range", "audio_multitraining.AudioMultitrainingTask.target_dictionary.string", "len", "audio_multitraining.AudioMultitrainingTask._inference_with_wer.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.inference_step", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "_inference_with_wer", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "editdistance", "\n", "\n", "def", "decode", "(", "toks", ")", ":", "\n", "            ", "s", "=", "self", ".", "target_dictionary", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "cfg", ".", "eval_wer_post_process", ",", "\n", "escape_unk", "=", "True", ",", "\n", ")", "\n", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "num_word_errors", ",", "num_char_errors", "=", "0", ",", "0", "\n", "num_chars", ",", "num_words", "=", "0", ",", "0", "\n", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "None", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyp", "=", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", "\n", "ref", "=", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "self", ".", "target_dictionary", ".", "pad", "(", ")", ")", ",", "\n", ")", "\n", "num_char_errors", "+=", "editdistance", ".", "eval", "(", "hyp", ",", "ref", ")", "\n", "num_chars", "+=", "len", "(", "ref", ")", "\n", "hyp_words", "=", "hyp", ".", "split", "(", ")", "\n", "ref_words", "=", "ref", ".", "split", "(", ")", "\n", "num_word_errors", "+=", "editdistance", ".", "eval", "(", "hyp_words", ",", "ref_words", ")", "\n", "num_words", "+=", "len", "(", "ref_words", ")", "\n", "\n", "", "return", "{", "\n", "\"num_char_errors\"", ":", "num_char_errors", ",", "\n", "\"num_chars\"", ":", "num_chars", ",", "\n", "\"num_word_errors\"", ":", "num_word_errors", ",", "\n", "\"num_words\"", ":", "num_words", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.reduce_metrics": [[326, 358], ["super().reduce_metrics", "torch.scalar_tensor", "sum", "sum", "sum", "sum", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_derived", "logging.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "float", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived"], ["", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "\n", "zero", "=", "torch", ".", "scalar_tensor", "(", "0.0", ")", "\n", "num_char_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_char_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_chars", "=", "sum", "(", "log", ".", "get", "(", "\"_num_chars\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "num_word_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_word_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_words", "=", "sum", "(", "log", ".", "get", "(", "\"_num_words\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_char_errors\"", ",", "num_char_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_chars\"", ",", "num_chars", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_word_errors\"", ",", "num_word_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_words\"", ",", "num_words", ")", "\n", "if", "num_words", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_char_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_chars\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_chars\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_word_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_words\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_words\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.__init__": [[29, 32], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.forward": [[33, 42], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.forward_torchscript": [[43, 56], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "fairseq_encoder.FairseqEncoder.forward", "fairseq_encoder.FairseqEncoder.forward_non_torchscript"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.forward_non_torchscript"], ["", "def", "forward_torchscript", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"A TorchScript-compatible version of forward.\n\n        Encoders which use additional arguments may want to override\n        this method for TorchScript compatibility.\n        \"\"\"", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "return", "self", ".", "forward", "(", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", ",", "\n", "src_lengths", "=", "net_input", "[", "\"src_lengths\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "forward_non_torchscript", "(", "net_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.forward_non_torchscript": [[57, 63], ["fairseq_encoder.FairseqEncoder.forward", "net_input.items"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "forward_non_torchscript", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "net_input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "return", "self", ".", "forward", "(", "**", "encoder_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.reorder_encoder_out": [[64, 76], ["None"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to `new_order`.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            `encoder_out` rearranged according to `new_order`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.max_positions": [[77, 80], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.upgrade_state_dict_named": [[81, 84], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_encoder.FairseqEncoder.set_num_updates": [[85, 93], ["fairseq_encoder.FairseqEncoder.apply", "hasattr", "m.set_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"State from trainer to pass along to model at every update.\"\"\"", "\n", "\n", "def", "_apply", "(", "m", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"set_num_updates\"", ")", "and", "m", "!=", "self", ":", "\n", "                ", "m", ".", "set_num_updates", "(", "num_updates", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.script_skip_tensor_list": [[12, 22], ["enumerate", "t.numel", "outputs.append", "outputs.append", "xi.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor_list", "(", "x", ":", "List", "[", "Tensor", "]", ",", "mask", ")", ":", "\n", "    ", "res", "=", "[", "xi", "[", "mask", "]", "if", "xi", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "xi", "[", ":", ",", "mask", "]", "for", "xi", "in", "x", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "res", ")", ":", "\n", "        ", "if", "t", ".", "numel", "(", ")", "!=", "0", ":", "\n", "            ", "outputs", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ".", "append", "(", "x", "[", "i", "]", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.script_skip_tensor": [[24, 34], ["x.size", "res.numel", "x.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor", "(", "x", ":", "Tensor", ",", "mask", ")", ":", "\n", "# None case", "\n", "    ", "if", "x", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "res", "=", "x", "[", "mask", "]", "if", "x", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "x", "[", ":", ",", "mask", "]", "\n", "if", "res", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.expand_2d_or_3d_tensor": [[36, 55], ["torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.dim", "dims.append", "torch.cat.dim", "torch.cat.dim", "torch.cat.size", "torch.cat.size", "torch.zeros().to().fill_", "torch.zeros().to", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "expand_2d_or_3d_tensor", "(", "x", ",", "trg_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Expand 2D/3D tensor on dim=1\n    \"\"\"", "\n", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "x", ".", "dim", "(", ")", "==", "3", "\n", "assert", "trg_dim", ">=", "x", ".", "size", "(", "1", ")", ",", "(", "trg_dim", ",", "x", ".", "size", "(", ")", ")", "\n", "if", "trg_dim", "==", "x", ".", "size", "(", "1", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "dims", "=", "[", "x", ".", "size", "(", "0", ")", ",", "trg_dim", "-", "x", ".", "size", "(", "1", ")", "]", "\n", "if", "x", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "dims", ".", "append", "(", "x", ".", "size", "(", "2", ")", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "torch", ".", "zeros", "(", "dims", ")", ".", "to", "(", "x", ")", ".", "fill_", "(", "padding_idx", ")", "]", ",", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.coalesce": [[57, 60], ["None"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "coalesce", "(", "x", ":", "Optional", "[", "Tensor", "]", ",", "y", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "    ", "return", "x", "if", "x", "is", "not", "None", "else", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.fill_tensors": [[62, 93], ["mask.sum", "y.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.size", "y.size", "model_utils.expand_2d_or_3d_tensor", "expand_2d_or_3d_tensor.dim", "y.dim", "mask.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "y.size", "expand_2d_or_3d_tensor.size", "y.size", "torch.tensor().type_as", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "expand_2d_or_3d_tensor.size", "y.size", "expand_2d_or_3d_tensor.dim", "torch.tensor", "y.size", "y.size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.model_utils.expand_2d_or_3d_tensor", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "fill_tensors", "(", "\n", "x", ":", "Optional", "[", "Tensor", "]", ",", "mask", ",", "y", ":", "Optional", "[", "Tensor", "]", ",", "padding_idx", ":", "int", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Filling tensor x with y at masked positions (dim=0).\n    \"\"\"", "\n", "if", "x", "is", "None", "or", "x", ".", "size", "(", ")", "[", "0", "]", "==", "0", "or", "y", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "and", "mask", ".", "size", "(", "0", ")", "==", "x", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "(", "x", ".", "dim", "(", ")", "==", "3", "and", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", ")", "\n", "\n", "n_selected", "=", "mask", ".", "sum", "(", ")", "\n", "if", "n_selected", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "assert", "n_selected", "==", "y", ".", "size", "(", "0", ")", "\n", "if", "n_selected", "==", "x", ".", "size", "(", "0", ")", ":", "\n", "        ", "return", "y", "\n", "\n", "", "if", "x", ".", "size", "(", "1", ")", "<", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "=", "expand_2d_or_3d_tensor", "(", "x", ",", "y", ".", "size", "(", "1", ")", ",", "padding_idx", ")", "\n", "x", "[", "mask", "]", "=", "y", "\n", "", "elif", "x", ".", "size", "(", "1", ")", ">", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "[", "mask", "]", "=", "torch", ".", "tensor", "(", "padding_idx", ")", ".", "type_as", "(", "x", ")", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", "]", "=", "y", "\n", "", "else", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", ",", ":", "]", "=", "y", "\n", "", "", "else", ":", "\n", "        ", "x", "[", "mask", "]", "=", "y", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.__init__": [[40, 42], ["fairseq.models.FairseqDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.forward": [[43, 61], ["None"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict, optional): dictionary used for storing\n                state during :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.extract_features": [[62, 72], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state": [[73, 85], ["None"], "methods", ["None"], ["", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Reorder incremental state.\n\n        This will be called when the order of the input has changed from the\n        previous time step. A typical use case is beam search, where the input\n        order changes between time steps based on the selection of beams.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state_scripting": [[86, 102], ["fairseq_incremental_decoder.FairseqIncrementalDecoder.modules", "hasattr", "module.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state"], ["", "def", "reorder_incremental_state_scripting", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Main entry point for reordering the incremental state.\n\n        Due to limitations in TorchScript, we call this function in\n        :class:`fairseq.sequence_generator.SequenceGenerator` instead of\n        calling :func:`reorder_incremental_state` directly.\n        \"\"\"", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "module", ",", "\"reorder_incremental_state\"", ")", ":", "\n", "                ", "result", "=", "module", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "                    ", "incremental_state", "=", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.set_beam_size": [[103, 119], ["getattr", "set", "fairseq_incremental_decoder.FairseqIncrementalDecoder.apply", "hasattr", "set.add", "module.set_beam_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.set_beam_size"], ["", "", "", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Sets the beam size in the decoder and all children.\"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"_beam_size\"", ",", "-", "1", ")", "!=", "beam_size", ":", "\n", "            ", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_set_beam_size", "(", "module", ")", ":", "\n", "                ", "if", "(", "\n", "module", "!=", "self", "\n", "and", "hasattr", "(", "module", ",", "\"set_beam_size\"", ")", "\n", "and", "module", "not", "in", "seen", "\n", ")", ":", "\n", "                    ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "set_beam_size", "(", "beam_size", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_set_beam_size", ")", "\n", "self", ".", "_beam_size", "=", "beam_size", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.__init__": [[34, 37], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_is_generation_fast", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.add_args": [[38, 45], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "# do not set defaults so that settings defaults from various architectures still works", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ",", "delete_default", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.build_model": [[46, 50], ["NotImplementedError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Model must implement the build_model method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.get_targets": [[51, 54], ["None"], "methods", ["None"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ")", ":", "\n", "        ", "\"\"\"Get targets from either the sample or the net's output.\"\"\"", "\n", "return", "sample", "[", "\"target\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.get_normalized_probs": [[55, 63], ["fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "return", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable": [[68, 86], ["hasattr", "fairseq_model.BaseFairseqModel.decoder.get_normalized_probs", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "net_output.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs_scriptable", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"decoder\"", ")", ":", "\n", "            ", "return", "self", ".", "decoder", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "net_output", ")", ":", "\n", "# syntactic sugar for simple models which don't have a decoder", "\n", "# (e.g., the classification tutorial)", "\n", "            ", "logits", "=", "net_output", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.extract_features": [[87, 90], ["fairseq_model.BaseFairseqModel."], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Similar to *forward* but only return features.\"\"\"", "\n", "return", "self", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.max_positions": [[91, 94], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.load_state_dict": [[95, 116], ["fairseq_model.BaseFairseqModel.upgrade_state_dict", "fairseq.checkpoint_utils.prune_state_dict", "super().load_state_dict", "logger.warn", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.upgrade_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.prune_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf"], ["", "def", "load_state_dict", "(", "\n", "self", ",", "\n", "state_dict", ",", "\n", "strict", "=", "True", ",", "\n", "model_cfg", ":", "Optional", "[", "DictConfig", "]", "=", "None", ",", "\n", "args", ":", "Optional", "[", "Namespace", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "\n", "if", "model_cfg", "is", "None", "and", "args", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\"using 'args' is deprecated, please update your code to use dataclass config\"", ")", "\n", "model_cfg", "=", "convert_namespace_to_omegaconf", "(", "args", ")", ".", "model", "\n", "\n", "", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "new_state_dict", "=", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ")", "\n", "return", "super", "(", ")", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.upgrade_state_dict": [[117, 120], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\"\"\"", "\n", "self", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.upgrade_state_dict_named": [[121, 143], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named.do_upgrade"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\n\n        Args:\n            state_dict (dict): state dictionary to upgrade, in place\n            name (str): the state dict key corresponding to the current module\n        \"\"\"", "\n", "assert", "state_dict", "is", "not", "None", "\n", "\n", "def", "do_upgrade", "(", "m", ",", "prefix", ")", ":", "\n", "            ", "if", "len", "(", "prefix", ")", ">", "0", ":", "\n", "                ", "prefix", "+=", "\".\"", "\n", "\n", "", "for", "n", ",", "c", "in", "m", ".", "named_children", "(", ")", ":", "\n", "                ", "name", "=", "prefix", "+", "n", "\n", "if", "hasattr", "(", "c", ",", "\"upgrade_state_dict_named\"", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "", "elif", "hasattr", "(", "c", ",", "\"upgrade_state_dict\"", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "", "do_upgrade", "(", "c", ",", "name", ")", "\n", "\n", "", "", "do_upgrade", "(", "self", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.set_num_updates": [[144, 152], ["fairseq_model.BaseFairseqModel.apply", "hasattr", "m.set_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"State from trainer to pass along to model at every update.\"\"\"", "\n", "\n", "def", "_apply", "(", "m", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"set_num_updates\"", ")", "and", "m", "!=", "self", ":", "\n", "                ", "m", ".", "set_num_updates", "(", "num_updates", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.prepare_for_inference_": [[153, 166], ["getattr", "getattr", "fairseq_model.BaseFairseqModel.make_generation_fast_", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.make_generation_fast_"], ["", "def", "prepare_for_inference_", "(", "self", ",", "cfg", ":", "DictConfig", ")", ":", "\n", "        ", "\"\"\"Prepare model for inference.\"\"\"", "\n", "kwargs", "=", "{", "}", "\n", "kwargs", "[", "\"beamable_mm_beam_size\"", "]", "=", "(", "\n", "None", "\n", "if", "getattr", "(", "cfg", ".", "generation", ",", "\"no_beamable_mm\"", ",", "False", ")", "\n", "else", "getattr", "(", "cfg", ".", "generation", ",", "\"beam\"", ",", "5", ")", "\n", ")", "\n", "kwargs", "[", "\"need_attn\"", "]", "=", "getattr", "(", "cfg", ".", "generation", ",", "\"print_alignment\"", ",", "False", ")", "\n", "if", "getattr", "(", "cfg", ".", "generation", ",", "\"retain_dropout\"", ",", "False", ")", ":", "\n", "            ", "kwargs", "[", "\"retain_dropout\"", "]", "=", "cfg", ".", "generation", ".", "retain_dropout", "\n", "kwargs", "[", "\"retain_dropout_modules\"", "]", "=", "cfg", ".", "generation", ".", "retain_dropout_modules", "\n", "", "self", ".", "make_generation_fast_", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.make_generation_fast_": [[167, 210], ["fairseq_model.BaseFairseqModel.apply", "fairseq_model.BaseFairseqModel.make_generation_fast_.apply_make_generation_fast_"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Legacy entry point to optimize model for faster generation.\n        Prefer prepare_for_inference_.\n        \"\"\"", "\n", "if", "self", ".", "_is_generation_fast", ":", "\n", "            ", "return", "# only apply once", "\n", "", "self", ".", "_is_generation_fast", "=", "True", "\n", "\n", "# remove weight norm from all modules in the network", "\n", "def", "apply_remove_weight_norm", "(", "module", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "module", ")", "\n", "", "except", "(", "AttributeError", ",", "ValueError", ")", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_remove_weight_norm", ")", "\n", "\n", "def", "apply_make_generation_fast_", "(", "module", ",", "prefix", ")", ":", "\n", "            ", "if", "len", "(", "prefix", ")", ">", "0", ":", "\n", "                ", "prefix", "+=", "\".\"", "\n", "\n", "", "base_func", "=", "BaseFairseqModel", ".", "make_generation_fast_", "\n", "for", "n", ",", "m", "in", "module", ".", "named_modules", "(", ")", ":", "\n", "                ", "if", "(", "\n", "m", "!=", "self", "\n", "and", "hasattr", "(", "m", ",", "\"make_generation_fast_\"", ")", "\n", "# don't call this implementation again, e.g., if", "\n", "# children modules also inherit from BaseFairseqModel", "\n", "and", "m", ".", "make_generation_fast_", ".", "__func__", "is", "not", "base_func", "\n", ")", ":", "\n", "                    ", "name", "=", "prefix", "+", "n", "\n", "m", ".", "make_generation_fast_", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "", "apply_make_generation_fast_", "(", "self", ",", "\"\"", ")", "\n", "\n", "def", "train", "(", "mode", "=", "True", ")", ":", "\n", "            ", "if", "mode", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"cannot train after make_generation_fast\"", ")", "\n", "\n", "# this model should no longer be used for training", "\n", "", "", "self", ".", "eval", "(", ")", "\n", "self", ".", "train", "=", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.prepare_for_onnx_export_": [[211, 225], ["set", "fairseq_model.BaseFairseqModel.apply", "hasattr", "set.add", "module.prepare_for_onnx_export_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.prepare_for_onnx_export_"], ["", "def", "prepare_for_onnx_export_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Make model exportable via ONNX trace.\"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_prepare_for_onnx_export_", "(", "module", ")", ":", "\n", "            ", "if", "(", "\n", "module", "!=", "self", "\n", "and", "hasattr", "(", "module", ",", "\"prepare_for_onnx_export_\"", ")", "\n", "and", "module", "not", "in", "seen", "\n", ")", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "prepare_for_onnx_export_", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_prepare_for_onnx_export_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.from_pretrained": [[226, 266], ["hub_utils.from_pretrained", "logger.info", "hub_utils.GeneratorHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.from_pretrained", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.hub_models"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Load a :class:`~fairseq.models.FairseqModel` from a pre-trained model\n        file. Downloads and caches the pre-trained model file if needed.\n\n        The base implementation returns a\n        :class:`~fairseq.hub_utils.GeneratorHubInterface`, which can be used to\n        generate translations or sample from language models. The underlying\n        :class:`~fairseq.models.FairseqModel` can be accessed via the\n        *generator.models* attribute.\n\n        Other models may override this to implement custom hub interfaces.\n\n        Args:\n            model_name_or_path (str): either the name of a pre-trained model to\n                load or a path/URL to a pre-trained model state dict\n            checkpoint_file (str, optional): colon-separated list of checkpoint\n                files in the model archive to ensemble (default: 'model.pt')\n            data_name_or_path (str, optional): point args.data to the archive\n                at the given path/URL. Can start with '.' or './' to reuse the\n                model archive path.\n        \"\"\"", "\n", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "logger", ".", "info", "(", "x", "[", "\"args\"", "]", ")", "\n", "return", "hub_utils", ".", "GeneratorHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.hub_models": [[267, 270], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.__init__": [[280, 287], ["fairseq_model.BaseFairseqModel.__init__", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.forward": [[288, 316], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for an encoder-decoder model.\n\n        First feed a batch of source tokens through the encoder. Then, feed the\n        encoder output and previous decoder outputs (i.e., teacher forcing) to\n        the decoder to produce the next outputs::\n\n            encoder_out = self.encoder(src_tokens, src_lengths)\n            return self.decoder(prev_output_tokens, encoder_out)\n\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.forward_decoder": [[317, 319], ["fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.extract_features": [[320, 334], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "features", "=", "self", ".", "decoder", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.output_layer": [[335, 338], ["fairseq_model.FairseqEncoderDecoderModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.max_positions": [[339, 342], ["fairseq_model.FairseqEncoderDecoderModel.encoder.max_positions", "fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "(", "self", ".", "encoder", ".", "max_positions", "(", ")", ",", "self", ".", "decoder", ".", "max_positions", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderDecoderModel.max_decoder_positions": [[343, 346], ["fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqModel.__init__": [[349, 355], ["fairseq_model.FairseqEncoderDecoderModel.__init__", "fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"FairseqModel is deprecated, please use FairseqEncoderDecoderModel \"", "\n", "\"or BaseFairseqModel instead\"", ",", "\n", "stacklevel", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.__init__": [[361, 373], ["fairseq_model.BaseFairseqModel.__init__", "list", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "encoders.keys", "decoders.keys", "encoders.keys", "isinstance", "isinstance", "fairseq_model.FairseqEncoderDecoderModel"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "encoders", ".", "keys", "(", ")", "==", "decoders", ".", "keys", "(", ")", "\n", "self", ".", "keys", "=", "list", "(", "encoders", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "assert", "isinstance", "(", "encoders", "[", "key", "]", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "decoders", "[", "key", "]", ",", "FairseqDecoder", ")", "\n", "\n", "", "self", ".", "models", "=", "nn", ".", "ModuleDict", "(", "\n", "{", "\n", "key", ":", "FairseqEncoderDecoderModel", "(", "encoders", "[", "key", "]", ",", "decoders", "[", "key", "]", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.build_shared_embeddings": [[376, 405], ["any", "build_embedding", "ValueError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding"], ["", "@", "staticmethod", "\n", "def", "build_shared_embeddings", "(", "\n", "dicts", ":", "Dict", "[", "str", ",", "Dictionary", "]", ",", "\n", "langs", ":", "List", "[", "str", "]", ",", "\n", "embed_dim", ":", "int", ",", "\n", "build_embedding", ":", "callable", ",", "\n", "pretrained_embed_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Helper function to build shared embeddings for a set of languages after\n        checking that all dicts corresponding to those languages are equivalent.\n\n        Args:\n            dicts: Dict of lang_id to its corresponding Dictionary\n            langs: languages that we want to share embeddings for\n            embed_dim: embedding dimension\n            build_embedding: callable function to actually build the embedding\n            pretrained_embed_path: Optional path to load pretrained embeddings\n        \"\"\"", "\n", "shared_dict", "=", "dicts", "[", "langs", "[", "0", "]", "]", "\n", "if", "any", "(", "dicts", "[", "lang", "]", "!=", "shared_dict", "for", "lang", "in", "langs", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--share-*-embeddings requires a joined dictionary: \"", "\n", "\"--share-encoder-embeddings requires a joined source \"", "\n", "\"dictionary, --share-decoder-embeddings requires a joined \"", "\n", "\"target dictionary, and --share-all-embeddings requires a \"", "\n", "\"joint source + target dictionary.\"", "\n", ")", "\n", "", "return", "build_embedding", "(", "shared_dict", ",", "embed_dim", ",", "pretrained_embed_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.forward": [[406, 408], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.max_positions": [[409, 417], ["fairseq_model.FairseqMultiModel.models[].encoder.max_positions", "fairseq_model.FairseqMultiModel.models[].decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "{", "\n", "key", ":", "(", "\n", "self", ".", "models", "[", "key", "]", ".", "encoder", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "models", "[", "key", "]", ".", "decoder", ".", "max_positions", "(", ")", ",", "\n", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.max_decoder_positions": [[419, 422], ["min", "model.decoder.max_positions", "fairseq_model.FairseqMultiModel.models.values"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "min", "(", "model", ".", "decoder", ".", "max_positions", "(", ")", "for", "model", "in", "self", ".", "models", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder": [[423, 426], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder": [[427, 430], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.forward_decoder": [[431, 433], ["fairseq_model.FairseqMultiModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.load_state_dict": [[434, 455], ["fairseq_model.FairseqMultiModel.upgrade_state_dict", "fairseq.checkpoint_utils.prune_state_dict", "fairseq_model.BaseFairseqModel.load_state_dict", "logger.warn", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.upgrade_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.prune_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf"], ["", "def", "load_state_dict", "(", "\n", "self", ",", "\n", "state_dict", ",", "\n", "strict", "=", "True", ",", "\n", "model_cfg", "=", "None", ",", "\n", "args", ":", "Optional", "[", "Namespace", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "\n", "if", "model_cfg", "is", "None", "and", "args", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\"using 'args' is deprecated, please update your code to use dataclass config\"", ")", "\n", "model_cfg", "=", "convert_namespace_to_omegaconf", "(", "args", ")", ".", "model", "\n", "\n", "", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "new_state_dict", "=", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ")", "\n", "return", "super", "(", ")", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.__init__": [[464, 468], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.forward": [[469, 486], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a decoder-only model.\n\n        Feeds a batch of tokens through the decoder to predict the next tokens.\n\n        Args:\n            src_tokens (LongTensor): tokens on which to condition the decoder,\n                of shape `(batch, tgt_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, seq_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.forward_decoder": [[487, 489], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.extract_features": [[490, 500], ["fairseq_model.FairseqLanguageModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, seq_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", ".", "extract_features", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.output_layer": [[501, 504], ["fairseq_model.FairseqLanguageModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.max_positions": [[505, 508], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.max_decoder_positions": [[509, 512], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqLanguageModel.supported_targets": [[513, 516], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"future\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderModel.__init__": [[525, 529], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderModel.forward": [[530, 544], ["fairseq_model.FairseqEncoderModel.encoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a encoder-only model.\n\n        Feeds a batch of tokens through the encoder to generate features.\n\n        Args:\n            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            the encoder's output, typically of shape `(batch, src_len, features)`\n        \"\"\"", "\n", "return", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderModel.get_normalized_probs": [[545, 555], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "encoder_out.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "encoder_out", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "torch", ".", "is_tensor", "(", "encoder_out", ")", ":", "\n", "            ", "logits", "=", "encoder_out", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqEncoderModel.max_positions": [[556, 559], ["fairseq_model.FairseqEncoderModel.encoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "encoder", ".", "max_positions", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.build_model": [[53, 97], ["model.build_model", "getattr", "getattr", "next", "isinstance", "len", "iter", "Exception", "fairseq.dataclass.utils.populate_dataclass", "fairseq.dataclass.utils.merge_with_parent", "dc", "dc", "str", "MODEL_DATACLASS_REGISTRY.keys", "str", "MODEL_DATACLASS_REGISTRY.keys"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.populate_dataclass", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.merge_with_parent"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model": [[99, 148], ["ValueError", "issubclass", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "__init__.register_model_architecture", "issubclass"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture": [[150, 196], ["ARCH_MODEL_INV_REGISTRY.setdefault().append", "ValueError", "ValueError", "callable", "ValueError", "ARCH_MODEL_INV_REGISTRY.setdefault"], "function", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.__init__": [[20, 25], ["fairseq_encoder.FairseqEncoder.__init__", "composite_encoder.CompositeEncoder.add_module", "next", "iter", "encoders.values"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "next", "(", "iter", "(", "encoders", ".", "values", "(", ")", ")", ")", ".", "dictionary", ")", "\n", "self", ".", "encoders", "=", "encoders", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "self", ".", "add_module", "(", "key", ",", "self", ".", "encoders", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.forward": [[26, 42], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n\n        Returns:\n            dict:\n                the outputs from each Encoder\n        \"\"\"", "\n", "encoder_out", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "encoder_out", "[", "key", "]", "=", "self", ".", "encoders", "[", "key", "]", "(", "src_tokens", ",", "src_lengths", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.reorder_encoder_out": [[43, 50], ["composite_encoder.CompositeEncoder.encoders[].reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder encoder output according to new_order.\"\"\"", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "encoder_out", "[", "key", "]", "=", "self", ".", "encoders", "[", "key", "]", ".", "reorder_encoder_out", "(", "\n", "encoder_out", "[", "key", "]", ",", "new_order", "\n", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.max_positions": [[51, 53], ["min", "composite_encoder.CompositeEncoder.encoders[].max_positions"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "self", ".", "encoders", "[", "key", "]", ".", "max_positions", "(", ")", "for", "key", "in", "self", ".", "encoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.upgrade_state_dict": [[54, 58], ["composite_encoder.CompositeEncoder.encoders[].upgrade_state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.upgrade_state_dict"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "self", ".", "encoders", "[", "key", "]", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "", "return", "state_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.__init__": [[16, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.forward": [[21, 39], ["fairseq_decoder.FairseqDecoder.extract_features", "fairseq_decoder.FairseqDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.extract_features": [[40, 48], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.output_layer": [[49, 57], ["None"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project features to the default output size, e.g., vocabulary size.\n\n        Args:\n            features (Tensor): features returned by *extract_features*.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.get_normalized_probs": [[58, 80], ["hasattr", "fairseq_decoder.FairseqDecoder.adaptive_softmax.get_log_prob", "fairseq.utils.log_softmax", "fairseq.utils.softmax", "fairseq_decoder.FairseqDecoder.exp_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"adaptive_softmax\"", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "if", "sample", "is", "not", "None", ":", "\n", "                ", "assert", "\"target\"", "in", "sample", "\n", "target", "=", "sample", "[", "\"target\"", "]", "\n", "", "else", ":", "\n", "                ", "target", "=", "None", "\n", "", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "net_output", "[", "0", "]", ",", "target", "=", "target", ")", "\n", "return", "out", ".", "exp_", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.max_positions": [[81, 84], ["None"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the decoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict_named": [[85, 88], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_decoder.FairseqDecoder.prepare_for_onnx_export_": [[89, 91], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.__init__": [[157, 162], ["torch.Module.__init__", "fairseq.distributed_utils.get_world_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_world_size"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "process_group", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "process_group", "=", "process_group", "\n", "self", ".", "world_size", "=", "distributed_utils", ".", "get_world_size", "(", "self", ".", "process_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.forward": [[163, 165], ["distributed_fairseq_model.TPUDistributedDataParallel.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads": [[166, 186], ["distributed_fairseq_model.TPUDistributedDataParallel.parameters", "xm.all_reduce", "gradients.append", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce"], ["", "def", "all_reduce_grads", "(", "self", ")", ":", "\n", "        ", "gradients", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "", "if", "p", ".", "grad", "is", "None", ":", "\n", "                ", "p", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "if", "p", ".", "grad", ".", "requires_grad", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"TPUDistributedDataParallel only works with gradients that don't \"", "\n", "\"require grad\"", "\n", ")", "\n", "", "gradients", ".", "append", "(", "p", ".", "grad", ")", "\n", "\n", "", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "xm", ".", "all_reduce", "(", "\n", "'sum'", ",", "\n", "gradients", ",", "\n", "scale", "=", "1.", "/", "self", ".", "world_size", ",", "\n", "groups", "=", "self", ".", "process_group", "[", "1", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.distributed_fairseq_model.DistributedFairseqModel": [[29, 153], ["isinstance", "getattr", "_DistributedFairseqModel", "dict", "dict", "super().__init__", "distributed_fairseq_model.._heartbeat.wait", "super().__getattr__", "hasattr", "super().__getattr__", "super().forward", "dict", "threading.Event", "threading.Thread", "distributed_fairseq_model.._heartbeat_thread.start", "distributed_fairseq_model.._heartbeat.clear", "distributed_fairseq_model.._heartbeat.wait", "getattr", "distributed_fairseq_model.._heartbeat.set", "inspect.getargspec", "dict", "ValueError", "logger.error", "os.kill", "ImportError", "os.getpid", "int"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start"], ["", "def", "DistributedFairseqModel", "(", "args", ",", "model", ",", "process_group", ")", ":", "\n", "    ", "\"\"\"\n    Wrap a *model* to support distributed data parallel training.\n\n    This is similar to the built-in DistributedDataParallel, but allows\n    additional configuration of the DistributedDataParallel class to\n    use, and also provides easier access to the wrapped model by\n    forwarding requests for missing attributes to the wrapped model.\n\n    Args:\n        args (argparse.Namespace): fairseq args\n        model (BaseFairseqModel): model to wrap\n        process_group: the c10d process group to be used for distributed data\n            parallel all-reduction.\n    \"\"\"", "\n", "# determine which DDP class to extend", "\n", "assert", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", "\n", "if", "args", ".", "tpu", ":", "\n", "        ", "ddp_class", "=", "TPUDistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "", "elif", "args", ".", "distributed_wrapper", "==", "\"DDP\"", "and", "args", ".", "ddp_backend", "==", "\"c10d\"", ":", "\n", "        ", "ddp_class", "=", "nn", ".", "parallel", ".", "DistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "device_id", "]", ",", "\n", "output_device", "=", "args", ".", "device_id", ",", "\n", "broadcast_buffers", "=", "args", ".", "broadcast_buffers", ",", "\n", "bucket_cap_mb", "=", "args", ".", "bucket_cap_mb", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "# Maintain backward compatibility", "\n", "if", "\"find_unused_parameters\"", "in", "inspect", ".", "getargspec", "(", "ddp_class", ")", "[", "0", "]", ":", "\n", "            ", "init_kwargs", "[", "\"find_unused_parameters\"", "]", "=", "args", ".", "find_unused_parameters", "\n", "", "", "elif", "args", ".", "distributed_wrapper", "==", "\"DDP\"", "and", "args", ".", "ddp_backend", "==", "\"no_c10d\"", ":", "\n", "        ", "ddp_class", "=", "LegacyDistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "buffer_size", "=", "2", "**", "28", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "", "elif", "args", ".", "distributed_wrapper", "==", "\"SlowMo\"", ":", "\n", "        ", "if", "_GOSSIP_DISABLED", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Cannot find gossip library. Please install from: \"", "\n", "\"github.com/facebookresearch/stochastic_gradient_push\"", "\n", ")", "\n", "", "ddp_class", "=", "gossip", ".", "GossipDataParallel", "\n", "\n", "# The values of slowmo_momentum below were obtained by tuning on the", "\n", "# En-De 16 dataset by training the transformer_wmt_en_de_large model", "\n", "if", "args", ".", "slowmo_momentum", "is", "None", ":", "\n", "            ", "if", "args", ".", "distributed_world_size", "<=", "16", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.0", "\n", "", "elif", "args", ".", "distributed_world_size", "<=", "32", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.2", "\n", "", "elif", "args", ".", "distributed_world_size", "<=", "64", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.5", "\n", "", "else", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.6", "\n", "\n", "", "", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "device_id", "]", ",", "\n", "output_device", "=", "args", ".", "device_id", ",", "\n", "broadcast_buffers", "=", "args", ".", "broadcast_buffers", ",", "\n", "nprocs_per_node", "=", "args", ".", "nprocs_per_node", ",", "\n", "slowmo_momentum", "=", "args", ".", "slowmo_momentum", ",", "\n", "localsgd", "=", "(", "args", ".", "slowmo_algorithm", "==", "\"LocalSGD\"", ")", ",", "\n", "localsgd_frequency", "=", "args", ".", "localsgd_frequency", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown --ddp-backend: \"", "+", "args", ".", "ddp_backend", ")", "\n", "\n", "", "heartbeat_timeout", "=", "getattr", "(", "args", ",", "\"heartbeat_timeout\"", ",", "-", "1", ")", "\n", "\n", "class", "_DistributedFairseqModel", "(", "ddp_class", ")", ":", "\n", "        ", "\"\"\"\n        Extend DistributedDataParallel to check for missing attributes in the\n        wrapped module and to add a timeout to kill the job if no progress is\n        made (--heartbeat-timeout).\n        \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_heartbeat_timeout", "=", "heartbeat_timeout", "\n", "if", "self", ".", "_heartbeat_timeout", ">", "0", ":", "\n", "                ", "self", ".", "_heartbeat", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "_heartbeat_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "_check_heartbeat", ",", "\n", "args", "=", "(", "os", ".", "getpid", "(", ")", ",", ")", ",", "\n", "daemon", "=", "True", ",", "\n", ")", "\n", "self", ".", "_heartbeat_thread", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_heartbeat", "=", "None", "\n", "\n", "", "", "def", "_check_heartbeat", "(", "self", ",", "parent_pid", ")", ":", "\n", "            ", "self", ".", "_heartbeat", ".", "wait", "(", ")", "# wait for the first forward pass", "\n", "while", "True", ":", "\n", "                ", "self", ".", "_heartbeat", ".", "clear", "(", ")", "\n", "success", "=", "self", ".", "_heartbeat", ".", "wait", "(", "timeout", "=", "self", ".", "_heartbeat_timeout", ")", "\n", "if", "not", "success", ":", "\n", "                    ", "logger", ".", "error", "(", "(", "\n", "\"Killing job for not making progress in {} seconds. \"", "\n", "\"Set --heartbeat-timeout=-1 to disable this timeout.\"", "\n", ")", ".", "format", "(", "int", "(", "self", ".", "_heartbeat_timeout", ")", ")", ")", "\n", "os", ".", "kill", "(", "parent_pid", ",", "signal", ".", "SIGKILL", ")", "\n", "return", "\n", "\n", "", "", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "            ", "wrapped_module", "=", "super", "(", ")", ".", "__getattr__", "(", "\"module\"", ")", "\n", "if", "hasattr", "(", "wrapped_module", ",", "name", ")", ":", "\n", "                ", "return", "getattr", "(", "wrapped_module", ",", "name", ")", "\n", "", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "if", "self", ".", "_heartbeat", "is", "not", "None", ":", "\n", "                ", "self", ".", "_heartbeat", ".", "set", "(", ")", "\n", "", "return", "super", "(", ")", ".", "forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_DistributedFairseqModel", "(", "**", "init_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.ModelParallelTransformerLanguageModel.add_args": [[75, 78], ["fairseq.models.transformer_lm.TransformerLanguageModel.add_args"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "TransformerLanguageModel", ".", "add_args", "(", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.ModelParallelTransformerLanguageModel.build_model": [[30, 74], ["transformer_lm.base_lm_architecture", "task.source_dictionary.pad_to_multiple_", "task.target_dictionary.pad_to_multiple_", "fairseq.model_parallel.models.transformer.ModelParallelTransformerDecoder", "cls", "ImportError", "len", "getattr", "getattr", "NotImplementedError", "args.decoder_layers_to_keep.split", "NotImplementedError", "cls.build_embedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.base_lm_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "if", "not", "has_megatron_submodule", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "\n", "# make sure all arguments are present in older models", "\n", "", "base_lm_architecture", "(", "args", ")", "\n", "\n", "task", ".", "source_dictionary", ".", "pad_to_multiple_", "(", "args", ".", "model_parallel_size", "*", "8", ")", "\n", "task", ".", "target_dictionary", ".", "pad_to_multiple_", "(", "args", ".", "model_parallel_size", "*", "8", ")", "\n", "\n", "if", "args", ".", "decoder_layers_to_keep", ":", "\n", "            ", "args", ".", "decoder_layers", "=", "len", "(", "args", ".", "decoder_layers_to_keep", ".", "split", "(", "\",\"", ")", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "getattr", "(", "\n", "args", ",", "\"tokens_per_sample\"", ",", "DEFAULT_MAX_TARGET_POSITIONS", "\n", ")", "\n", "\n", "", "if", "args", ".", "character_embeddings", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Character embeddings is not supported for model parallel\"", "\n", ")", "\n", "", "elif", "args", ".", "adaptive_input", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Adaptive input is not supported for model parallel\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "embed_tokens", "=", "cls", ".", "build_embedding", "(", "\n", "args", ",", "task", ".", "source_dictionary", ",", "args", ".", "decoder_input_dim", "\n", ")", "\n", "\n", "", "decoder", "=", "ModelParallelTransformerDecoder", "(", "\n", "args", ",", "\n", "task", ".", "target_dictionary", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "True", ",", "\n", ")", "\n", "return", "cls", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.ModelParallelTransformerLanguageModel.build_embedding": [[79, 89], ["VocabParallelEmbedding", "torch.init.normal_", "torch.init.constant_", "len", "dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["", "@", "classmethod", "\n", "def", "build_embedding", "(", "cls", ",", "args", ",", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "        ", "def", "_vocab_init", "(", "tensor", ",", "**", "kwargs", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "tensor", ",", "mean", "=", "0", ",", "std", "=", "embed_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "tensor", "[", "1", "]", ",", "0", ")", "\n", "\n", "", "embed_tokens", "=", "VocabParallelEmbedding", "(", "\n", "len", "(", "dictionary", ")", ",", "embed_dim", ",", "dictionary", ".", "pad", "(", ")", ",", "init_method", "=", "_vocab_init", "\n", ")", "\n", "return", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.base_lm_architecture": [[91, 149], ["hasattr", "hasattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["", "", "def", "base_lm_architecture", "(", "args", ")", ":", "\n", "# backward compatibility for older model checkpoints", "\n", "    ", "if", "hasattr", "(", "args", ",", "\"no_tie_adaptive_proj\"", ")", ":", "\n", "# previous models defined --no-tie-adaptive-proj, so use the existence of", "\n", "# that option to determine if this is an \"old\" model checkpoint", "\n", "        ", "args", ".", "no_decoder_final_norm", "=", "True", "# old models always set this to True", "\n", "if", "args", ".", "no_tie_adaptive_proj", "is", "False", ":", "\n", "            ", "args", ".", "tie_adaptive_proj", "=", "True", "\n", "", "", "if", "hasattr", "(", "args", ",", "\"decoder_final_norm\"", ")", ":", "\n", "        ", "args", ".", "no_decoder_final_norm", "=", "not", "args", ".", "decoder_final_norm", "\n", "\n", "", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "relu_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0.0", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "# Model training is not stable without this", "\n", "args", ".", "decoder_normalize_before", "=", "True", "\n", "args", ".", "no_decoder_final_norm", "=", "getattr", "(", "args", ",", "\"no_decoder_final_norm\"", ",", "False", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "adaptive_softmax_factor", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_factor\"", ",", "4", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "character_embeddings", "=", "getattr", "(", "args", ",", "\"character_embeddings\"", ",", "False", ")", "\n", "args", ".", "character_filters", "=", "getattr", "(", "\n", "args", ",", "\n", "\"character_filters\"", ",", "\n", "\"[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]\"", ",", "\n", ")", "\n", "args", ".", "character_embedding_dim", "=", "getattr", "(", "args", ",", "\"character_embedding_dim\"", ",", "4", ")", "\n", "args", ".", "char_embedder_highway_layers", "=", "getattr", "(", "args", ",", "\"char_embedder_highway_layers\"", ",", "2", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "adaptive_input_factor", "=", "getattr", "(", "args", ",", "\"adaptive_input_factor\"", ",", "4", ")", "\n", "args", ".", "adaptive_input_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_input_cutoff\"", ",", "None", ")", "\n", "args", ".", "tie_adaptive_weights", "=", "getattr", "(", "args", ",", "\"tie_adaptive_weights\"", ",", "False", ")", "\n", "args", ".", "tie_adaptive_proj", "=", "getattr", "(", "args", ",", "\"tie_adaptive_proj\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0.0", ")", "\n", "args", ".", "decoder_layers_to_keep", "=", "getattr", "(", "args", ",", "\"decoder_layers_to_keep\"", ",", "None", ")", "\n", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "args", ".", "quant_noise_pq", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0.0", ")", "\n", "args", ".", "quant_noise_pq_block_size", "=", "getattr", "(", "args", ",", "\"quant_noise_pq_block_size\"", ",", "8", ")", "\n", "args", ".", "quant_noise_scalar", "=", "getattr", "(", "args", ",", "\"quant_noise_scalar\"", ",", "0.0", ")", "\n", "args", ".", "add_bos_token", "=", "getattr", "(", "args", ",", "\"add_bos_token\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.transformer_lm_megatron": [[151, 161], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"model_parallel_transformer_lm\"", ",", "\"transformer_lm_megatron\"", ")", "\n", "def", "transformer_lm_megatron", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "3072", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "3072", "*", "4", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "72", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "32", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.transformer_lm_megatron_11b": [[163, 175], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"model_parallel_transformer_lm\"", ",", "\"transformer_lm_megatron_11b\"", "\n", ")", "\n", "def", "transformer_lm_megatron_11b", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "3072", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "3072", "*", "6", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "72", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "32", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding": [[43, 68], ["dictionary.pad_to_multiple_", "len", "dictionary.pad", "VocabParallelEmbedding", "ImportError", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["@", "classmethod", "\n", "def", "build_embedding", "(", "cls", ",", "args", ",", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "        ", "if", "not", "has_megatron_submodule", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "", "dictionary", ".", "pad_to_multiple_", "(", "args", ".", "model_parallel_size", "*", "8", ")", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "\n", "def", "_vocab_init", "(", "tensor", ",", "**", "kwargs", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "tensor", ",", "mean", "=", "0", ",", "std", "=", "num_embeddings", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "tensor", "[", "1", "]", ",", "0", ")", "\n", "\n", "", "emb", "=", "VocabParallelEmbedding", "(", "\n", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ",", "init_method", "=", "_vocab_init", "\n", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Loading of embedding from path is not supported for model parallel\"", "\n", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_encoder": [[69, 72], ["transformer.ModelParallelTransformerEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "ModelParallelTransformerEncoder", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_decoder": [[73, 80], ["transformer.ModelParallelTransformerDecoder", "getattr"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "ModelParallelTransformerDecoder", "(", "\n", "args", ",", "\n", "tgt_dict", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "getattr", "(", "args", ",", "\"no_cross_attention\"", ",", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerEncoder.build_encoder_layer": [[89, 91], ["fairseq.model_parallel.modules.ModelParallelTransformerEncoderLayer"], "methods", ["None"], ["def", "build_encoder_layer", "(", "self", ",", "args", ")", ":", "\n", "        ", "return", "ModelParallelTransformerEncoderLayer", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerDecoder.build_decoder_layer": [[99, 101], ["fairseq.model_parallel.modules.ModelParallelTransformerDecoderLayer"], "methods", ["None"], ["def", "build_decoder_layer", "(", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "return", "ModelParallelTransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerDecoder.output_layer": [[102, 117], ["copy_to_model_parallel_region", "transformer.ModelParallelTransformerDecoder.output_projection", "NotImplementedError", "getattr", "gather_from_model_parallel_region().contiguous", "gather_from_model_parallel_region"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Model parallel training currently requires --share-decoder-input-output-embed\"", "\n", ")", "\n", "\n", "", "features", "=", "copy_to_model_parallel_region", "(", "features", ")", "\n", "\n", "# project back to size of vocabulary", "\n", "x", "=", "self", ".", "output_projection", "(", "features", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"criterion\"", ")", "!=", "\"vocab_parallel_cross_entropy\"", ":", "\n", "            ", "x", "=", "gather_from_model_parallel_region", "(", "x", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.__init__": [[224, 321], ["fairseq.models.BaseFairseqModel.__init__", "eval", "wav2vec2.ConvFeatureExtractionModel", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "wav2vec2.TransformerEncoder", "fairseq.modules.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.modules.GumbelVectorQuantizer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.modules.GumbelVectorQuantizer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2Config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "feature_enc_layers", "=", "eval", "(", "cfg", ".", "conv_feature_layers", ")", "\n", "self", ".", "embed", "=", "feature_enc_layers", "[", "-", "1", "]", "[", "0", "]", "\n", "\n", "self", ".", "feature_extractor", "=", "ConvFeatureExtractionModel", "(", "\n", "conv_layers", "=", "feature_enc_layers", ",", "\n", "dropout", "=", "0.0", ",", "\n", "mode", "=", "cfg", ".", "extractor_mode", ",", "\n", "conv_bias", "=", "cfg", ".", "conv_bias", ",", "\n", ")", "\n", "\n", "self", ".", "post_extract_proj", "=", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embed", ",", "cfg", ".", "encoder_embed_dim", ")", "\n", "if", "self", ".", "embed", "!=", "cfg", ".", "encoder_embed_dim", "and", "not", "cfg", ".", "quantize_input", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "mask_prob", "=", "cfg", ".", "mask_prob", "\n", "self", ".", "mask_selection", "=", "cfg", ".", "mask_selection", "\n", "self", ".", "mask_other", "=", "cfg", ".", "mask_other", "\n", "self", ".", "mask_length", "=", "cfg", ".", "mask_length", "\n", "self", ".", "no_mask_overlap", "=", "cfg", ".", "no_mask_overlap", "\n", "self", ".", "mask_min_space", "=", "cfg", ".", "mask_min_space", "\n", "\n", "self", ".", "mask_channel_prob", "=", "cfg", ".", "mask_channel_prob", "\n", "self", ".", "mask_channel_selection", "=", "cfg", ".", "mask_channel_selection", "\n", "self", ".", "mask_channel_other", "=", "cfg", ".", "mask_channel_other", "\n", "self", ".", "mask_channel_length", "=", "cfg", ".", "mask_channel_length", "\n", "self", ".", "no_mask_channel_overlap", "=", "cfg", ".", "no_mask_channel_overlap", "\n", "self", ".", "mask_channel_min_space", "=", "cfg", ".", "mask_channel_min_space", "\n", "\n", "self", ".", "dropout_input", "=", "nn", ".", "Dropout", "(", "cfg", ".", "dropout_input", ")", "\n", "self", ".", "dropout_features", "=", "nn", ".", "Dropout", "(", "cfg", ".", "dropout_features", ")", "\n", "\n", "self", ".", "feature_grad_mult", "=", "cfg", ".", "feature_grad_mult", "\n", "\n", "self", ".", "quantizer", "=", "None", "\n", "self", ".", "input_quantizer", "=", "None", "\n", "\n", "self", ".", "n_negatives", "=", "cfg", ".", "num_negatives", "\n", "self", ".", "cross_sample_negatives", "=", "cfg", ".", "cross_sample_negatives", "\n", "self", ".", "codebook_negatives", "=", "cfg", ".", "codebook_negatives", "\n", "self", ".", "negatives_from_everywhere", "=", "cfg", ".", "negatives_from_everywhere", "\n", "\n", "self", ".", "logit_temp", "=", "cfg", ".", "logit_temp", "\n", "\n", "final_dim", "=", "cfg", ".", "final_dim", "if", "cfg", ".", "final_dim", ">", "0", "else", "cfg", ".", "encoder_embed_dim", "\n", "\n", "if", "cfg", ".", "quantize_targets", ":", "\n", "            ", "vq_dim", "=", "cfg", ".", "latent_dim", "if", "cfg", ".", "latent_dim", ">", "0", "else", "final_dim", "\n", "self", ".", "quantizer", "=", "GumbelVectorQuantizer", "(", "\n", "dim", "=", "self", ".", "embed", ",", "\n", "num_vars", "=", "cfg", ".", "latent_vars", ",", "\n", "temp", "=", "cfg", ".", "latent_temp", ",", "\n", "groups", "=", "cfg", ".", "latent_groups", ",", "\n", "combine_groups", "=", "False", ",", "\n", "vq_dim", "=", "vq_dim", ",", "\n", "time_first", "=", "True", ",", "\n", ")", "\n", "self", ".", "project_q", "=", "nn", ".", "Linear", "(", "vq_dim", ",", "final_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "project_q", "=", "nn", ".", "Linear", "(", "self", ".", "embed", ",", "final_dim", ")", "\n", "\n", "", "if", "cfg", ".", "quantize_input", ":", "\n", "            ", "if", "cfg", ".", "same_quantizer", "and", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "                ", "vq_dim", "=", "final_dim", "\n", "self", ".", "input_quantizer", "=", "self", ".", "quantizer", "\n", "", "else", ":", "\n", "                ", "vq_dim", "=", "cfg", ".", "latent_dim", "if", "cfg", ".", "latent_dim", ">", "0", "else", "cfg", ".", "encoder_embed_dim", "\n", "self", ".", "input_quantizer", "=", "GumbelVectorQuantizer", "(", "\n", "dim", "=", "self", ".", "embed", ",", "\n", "num_vars", "=", "cfg", ".", "latent_vars", ",", "\n", "temp", "=", "cfg", ".", "latent_temp", ",", "\n", "groups", "=", "cfg", ".", "latent_groups", ",", "\n", "combine_groups", "=", "False", ",", "\n", "vq_dim", "=", "vq_dim", ",", "\n", "time_first", "=", "True", ",", "\n", ")", "\n", "", "self", ".", "project_inp", "=", "nn", ".", "Linear", "(", "vq_dim", ",", "cfg", ".", "encoder_embed_dim", ")", "\n", "\n", "", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "cfg", ".", "encoder_embed_dim", ")", ".", "uniform_", "(", ")", "\n", ")", "\n", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "cfg", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "self", ".", "embed", ")", "\n", "\n", "self", ".", "target_glu", "=", "None", "\n", "if", "cfg", ".", "target_glu", ":", "\n", "            ", "self", ".", "target_glu", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "final_dim", ",", "final_dim", "*", "2", ")", ",", "nn", ".", "GLU", "(", ")", "\n", ")", "\n", "\n", "", "self", ".", "final_proj", "=", "nn", ".", "Linear", "(", "cfg", ".", "encoder_embed_dim", ",", "final_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.upgrade_state_dict_named": [[322, 326], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.build_model": [[327, 332], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "cfg", ":", "Wav2Vec2Config", ",", "task", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "return", "cls", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.apply_mask": [[333, 372], ["fairseq.data.data_utils.compute_mask_indices", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "fairseq.data.data_utils.compute_mask_indices", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.compute_mask_indices", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.compute_mask_indices"], ["", "def", "apply_mask", "(", "self", ",", "x", ",", "padding_mask", ")", ":", "\n", "        ", "B", ",", "T", ",", "C", "=", "x", ".", "shape", "\n", "if", "self", ".", "mask_prob", ">", "0", ":", "\n", "            ", "mask_indices", "=", "compute_mask_indices", "(", "\n", "(", "B", ",", "T", ")", ",", "\n", "padding_mask", ",", "\n", "self", ".", "mask_prob", ",", "\n", "self", ".", "mask_length", ",", "\n", "self", ".", "mask_selection", ",", "\n", "self", ".", "mask_other", ",", "\n", "min_masks", "=", "2", ",", "\n", "no_overlap", "=", "self", ".", "no_mask_overlap", ",", "\n", "min_space", "=", "self", ".", "mask_min_space", ",", "\n", ")", "\n", "mask_indices", "=", "torch", ".", "from_numpy", "(", "mask_indices", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "x", "[", "mask_indices", "]", "=", "self", ".", "mask_emb", "\n", "", "else", ":", "\n", "            ", "mask_indices", "=", "None", "\n", "\n", "", "if", "self", ".", "mask_channel_prob", ">", "0", ":", "\n", "            ", "mask_channel_indices", "=", "compute_mask_indices", "(", "\n", "(", "B", ",", "C", ")", ",", "\n", "None", ",", "\n", "self", ".", "mask_channel_prob", ",", "\n", "self", ".", "mask_channel_length", ",", "\n", "self", ".", "mask_channel_selection", ",", "\n", "self", ".", "mask_channel_other", ",", "\n", "no_overlap", "=", "self", ".", "no_mask_channel_overlap", ",", "\n", "min_space", "=", "self", ".", "mask_channel_min_space", ",", "\n", ")", "\n", "mask_channel_indices", "=", "(", "\n", "torch", ".", "from_numpy", "(", "mask_channel_indices", ")", "\n", ".", "to", "(", "x", ".", "device", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "T", ",", "-", "1", ")", "\n", ")", "\n", "x", "[", "mask_channel_indices", "]", "=", "0", "\n", "\n", "", "return", "x", ",", "mask_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives": [[373, 430], ["y.view.view.view", "negs.view().permute.view().permute.view().permute", "y.view.view.new", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint.view", "torch.randint.view", "torch.randint.view", "negs.view().permute.view().permute.view", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange", "fairseq.utils.buffered_arange"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.buffered_arange", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.buffered_arange"], ["", "def", "sample_negatives", "(", "self", ",", "y", ",", "num", ")", ":", "\n", "\n", "        ", "if", "self", ".", "n_negatives", "==", "0", "and", "self", ".", "cross_sample_negatives", "==", "0", ":", "\n", "            ", "return", "y", ".", "new", "(", "0", ")", "\n", "\n", "", "bsz", ",", "tsz", ",", "fsz", "=", "y", ".", "shape", "\n", "y", "=", "y", ".", "view", "(", "-", "1", ",", "fsz", ")", "# BTC => (BxT)C", "\n", "\n", "cross_high", "=", "tsz", "*", "bsz", "\n", "high", "=", "tsz", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "assert", "high", ">", "1", ",", "f\"{bsz,tsz,fsz}\"", "\n", "\n", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "num", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "n_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "high", "=", "high", "-", "1", ",", "size", "=", "(", "bsz", ",", "self", ".", "n_negatives", "*", "num", ")", "\n", ")", "\n", "neg_idxs", "[", "neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "num", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "cross_sample_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "cross_neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "cross_high", "-", "1", ",", "\n", "size", "=", "(", "bsz", ",", "self", ".", "cross_sample_negatives", "*", "num", ")", ",", "\n", ")", "\n", "cross_neg_idxs", "[", "cross_neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "bsz", ")", ":", "\n", "                ", "neg_idxs", "[", "i", "]", "+=", "i", "*", "high", "\n", "", "", "else", ":", "\n", "            ", "neg_idxs", "=", "cross_neg_idxs", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", "and", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "neg_idxs", "=", "torch", ".", "cat", "(", "[", "neg_idxs", ",", "cross_neg_idxs", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "negs", "=", "y", "[", "neg_idxs", ".", "view", "(", "-", "1", ")", "]", "\n", "negs", "=", "negs", ".", "view", "(", "\n", "bsz", ",", "num", ",", "self", ".", "n_negatives", "+", "self", ".", "cross_sample_negatives", ",", "fsz", "\n", ")", ".", "permute", "(", "\n", "2", ",", "0", ",", "1", ",", "3", "\n", ")", "# to NxBxTxC", "\n", "return", "negs", ",", "neg_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.compute_preds": [[431, 445], ["y.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "neg_is_pos.any", "float", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "x.float", "torch.cat.float", "torch.cat.float", "torch.cat.float"], "methods", ["None"], ["", "def", "compute_preds", "(", "self", ",", "x", ",", "y", ",", "negatives", ")", ":", "\n", "\n", "        ", "neg_is_pos", "=", "(", "y", "==", "negatives", ")", ".", "all", "(", "-", "1", ")", "\n", "y", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "targets", "=", "torch", ".", "cat", "(", "[", "y", ",", "negatives", "]", ",", "dim", "=", "0", ")", "\n", "\n", "logits", "=", "torch", ".", "cosine_similarity", "(", "x", ".", "float", "(", ")", ",", "targets", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "x", ")", "\n", "\n", "logits", "/=", "self", ".", "logit_temp", "\n", "\n", "if", "neg_is_pos", ".", "any", "(", ")", ":", "\n", "            ", "logits", "[", "1", ":", "]", "[", "neg_is_pos", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.forward": [[446, 561], ["wav2vec2.Wav2Vec2Model.float().pow().mean", "wav2vec2.Wav2Vec2Model.transpose", "wav2vec2.Wav2Vec2Model.layer_norm", "wav2vec2.Wav2Vec2Model.clone", "wav2vec2.Wav2Vec2Model.dropout_input", "wav2vec2.Wav2Vec2Model.dropout_features", "wav2vec2.Wav2Vec2Model.encoder", "x[].view", "wav2vec2.Wav2Vec2Model.final_proj", "wav2vec2.Wav2Vec2Model.compute_preds", "wav2vec2.Wav2Vec2Model.feature_extractor", "padding_mask.all.all.view", "padding_mask.all.all.all", "wav2vec2.Wav2Vec2Model.post_extract_proj", "wav2vec2.Wav2Vec2Model.input_quantizer", "wav2vec2.Wav2Vec2Model.project_inp", "wav2vec2.Wav2Vec2Model.apply_mask", "wav2vec2.Wav2Vec2Model.quantizer", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.target_glu", "wav2vec2.Wav2Vec2Model.target_glu", "fairseq.modules.GradMultiply.apply", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "wav2vec2.Wav2Vec2Model.feature_extractor", "wav2vec2.Wav2Vec2Model.float().pow", "padding_mask.all.all.size", "wav2vec2.Wav2Vec2Model.size", "padding_mask.all.all.size", "wav2vec2.Wav2Vec2Model.size", "unmasked_features[].view", "wav2vec2.Wav2Vec2Model.quantizer", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.quantizer.sample_from_codebook", "wav2vec2.Wav2Vec2Model.view", "wav2vec2.Wav2Vec2Model.project_q", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "wav2vec2.Wav2Vec2Model.float", "unmasked_features[].view.size", "unmasked_features[].view.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.compute_preds", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.apply_mask", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.sample_from_codebook", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", "=", "None", ",", "mask", "=", "True", ",", "features_only", "=", "False", ")", ":", "\n", "\n", "        ", "if", "self", ".", "feature_grad_mult", ">", "0", ":", "\n", "            ", "features", "=", "self", ".", "feature_extractor", "(", "source", ")", "\n", "if", "self", ".", "feature_grad_mult", "!=", "1.0", ":", "\n", "                ", "features", "=", "GradMultiply", ".", "apply", "(", "features", ",", "self", ".", "feature_grad_mult", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "features", "=", "self", ".", "feature_extractor", "(", "source", ")", "\n", "\n", "", "", "features_pen", "=", "features", ".", "float", "(", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "features", "=", "features", ".", "transpose", "(", "1", ",", "2", ")", "\n", "features", "=", "self", ".", "layer_norm", "(", "features", ")", "\n", "unmasked_features", "=", "features", ".", "clone", "(", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "extra", "=", "padding_mask", ".", "size", "(", "1", ")", "%", "features", ".", "size", "(", "1", ")", "\n", "if", "extra", ">", "0", ":", "\n", "                ", "padding_mask", "=", "padding_mask", "[", ":", ",", ":", "-", "extra", "]", "\n", "", "padding_mask", "=", "padding_mask", ".", "view", "(", "padding_mask", ".", "size", "(", "0", ")", ",", "features", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "padding_mask", "=", "padding_mask", ".", "all", "(", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "post_extract_proj", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "post_extract_proj", "(", "features", ")", "\n", "\n", "", "features", "=", "self", ".", "dropout_input", "(", "features", ")", "\n", "unmasked_features", "=", "self", ".", "dropout_features", "(", "unmasked_features", ")", "\n", "\n", "num_vars", "=", "None", "\n", "code_ppl", "=", "None", "\n", "prob_ppl", "=", "None", "\n", "curr_temp", "=", "None", "\n", "\n", "if", "self", ".", "input_quantizer", ":", "\n", "            ", "q", "=", "self", ".", "input_quantizer", "(", "features", ",", "produce_targets", "=", "False", ")", "\n", "features", "=", "q", "[", "\"x\"", "]", "\n", "num_vars", "=", "q", "[", "\"num_vars\"", "]", "\n", "code_ppl", "=", "q", "[", "\"code_perplexity\"", "]", "\n", "prob_ppl", "=", "q", "[", "\"prob_perplexity\"", "]", "\n", "curr_temp", "=", "q", "[", "\"temp\"", "]", "\n", "features", "=", "self", ".", "project_inp", "(", "features", ")", "\n", "\n", "", "if", "mask", ":", "\n", "            ", "x", ",", "mask_indices", "=", "self", ".", "apply_mask", "(", "features", ",", "padding_mask", ")", "\n", "if", "mask_indices", "is", "not", "None", ":", "\n", "                ", "y", "=", "unmasked_features", "[", "mask_indices", "]", ".", "view", "(", "\n", "unmasked_features", ".", "size", "(", "0", ")", ",", "-", "1", ",", "unmasked_features", ".", "size", "(", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "y", "=", "unmasked_features", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "features", "\n", "y", "=", "unmasked_features", "\n", "mask_indices", "=", "None", "\n", "\n", "", "x", "=", "self", ".", "encoder", "(", "x", ",", "padding_mask", "=", "padding_mask", ")", "\n", "\n", "if", "features_only", ":", "\n", "            ", "return", "{", "\"x\"", ":", "x", ",", "\"padding_mask\"", ":", "padding_mask", "}", "\n", "\n", "", "if", "self", ".", "quantizer", ":", "\n", "            ", "q", "=", "self", ".", "quantizer", "(", "y", ",", "produce_targets", "=", "False", ")", "\n", "y", "=", "q", "[", "\"x\"", "]", "\n", "num_vars", "=", "q", "[", "\"num_vars\"", "]", "\n", "code_ppl", "=", "q", "[", "\"code_perplexity\"", "]", "\n", "prob_ppl", "=", "q", "[", "\"prob_perplexity\"", "]", "\n", "curr_temp", "=", "q", "[", "\"temp\"", "]", "\n", "\n", "y", "=", "self", ".", "project_q", "(", "y", ")", "\n", "\n", "if", "self", ".", "negatives_from_everywhere", ":", "\n", "                ", "neg_cands", ",", "*", "_", "=", "self", ".", "quantizer", "(", "unmasked_features", ",", "produce_targets", "=", "False", ")", "\n", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "neg_cands", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "negs", "=", "self", ".", "project_q", "(", "negs", ")", "\n", "\n", "", "else", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "y", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "codebook_negatives", ">", "0", ":", "\n", "                ", "cb_negs", "=", "self", ".", "quantizer", ".", "sample_from_codebook", "(", "\n", "y", ".", "size", "(", "0", ")", "*", "y", ".", "size", "(", "1", ")", ",", "self", ".", "codebook_negatives", "\n", ")", "\n", "cb_negs", "=", "cb_negs", ".", "view", "(", "\n", "self", ".", "codebook_negatives", ",", "y", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "# order doesnt matter", "\n", "cb_negs", "=", "self", ".", "project_q", "(", "cb_negs", ")", "\n", "negs", "=", "torch", ".", "cat", "(", "[", "negs", ",", "cb_negs", "]", ",", "dim", "=", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "y", "=", "self", ".", "project_q", "(", "y", ")", "\n", "\n", "if", "self", ".", "negatives_from_everywhere", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "unmasked_features", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "negs", "=", "self", ".", "project_q", "(", "negs", ")", "\n", "", "else", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "y", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "\n", "", "", "x", "=", "x", "[", "mask_indices", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "target_glu", ":", "\n", "            ", "y", "=", "self", ".", "target_glu", "(", "y", ")", "\n", "negs", "=", "self", ".", "target_glu", "(", "negs", ")", "\n", "\n", "", "x", "=", "self", ".", "final_proj", "(", "x", ")", "\n", "x", "=", "self", ".", "compute_preds", "(", "x", ",", "y", ",", "negs", ")", "\n", "\n", "result", "=", "{", "\"x\"", ":", "x", ",", "\"padding_mask\"", ":", "padding_mask", ",", "\"features_pen\"", ":", "features_pen", "}", "\n", "\n", "if", "prob_ppl", "is", "not", "None", ":", "\n", "            ", "result", "[", "\"prob_perplexity\"", "]", "=", "prob_ppl", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "code_ppl", "\n", "result", "[", "\"num_vars\"", "]", "=", "num_vars", "\n", "result", "[", "\"temp\"", "]", "=", "curr_temp", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.quantize": [[562, 568], ["wav2vec2.Wav2Vec2Model.feature_extractor", "wav2vec2.Wav2Vec2Model.transpose", "wav2vec2.Wav2Vec2Model.layer_norm", "wav2vec2.Wav2Vec2Model.quantizer.forward_idx"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward_idx"], ["", "def", "quantize", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "self", ".", "quantizer", "is", "not", "None", "\n", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "return", "self", ".", "quantizer", ".", "forward_idx", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.extract_features": [[569, 572], ["wav2vec2.Wav2Vec2Model.forward"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward"], ["", "def", "extract_features", "(", "self", ",", "source", ",", "padding_mask", ",", "mask", "=", "False", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "source", ",", "padding_mask", ",", "mask", "=", "mask", ",", "features_only", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"padding_mask\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.get_logits": [[573, 578], ["logits.reshape.reshape.transpose", "logits.reshape.reshape.reshape", "logits.reshape.reshape.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"x\"", "]", "\n", "logits", "=", "logits", ".", "transpose", "(", "0", ",", "2", ")", "\n", "logits", "=", "logits", ".", "reshape", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.get_targets": [[579, 582], ["x.new_zeros", "x.size", "x.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ",", "expand_steps", "=", "True", ")", ":", "\n", "        ", "x", "=", "net_output", "[", "\"x\"", "]", "\n", "return", "x", ".", "new_zeros", "(", "x", ".", "size", "(", "1", ")", "*", "x", ".", "size", "(", "2", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.get_extra_losses": [[583, 596], ["pen.append", "pen.append"], "methods", ["None"], ["", "def", "get_extra_losses", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "pen", "=", "[", "]", "\n", "\n", "if", "\"prob_perplexity\"", "in", "net_output", ":", "\n", "            ", "pen", ".", "append", "(", "\n", "(", "net_output", "[", "\"num_vars\"", "]", "-", "net_output", "[", "\"prob_perplexity\"", "]", ")", "\n", "/", "net_output", "[", "\"num_vars\"", "]", "\n", ")", "\n", "\n", "", "if", "\"features_pen\"", "in", "net_output", ":", "\n", "            ", "pen", ".", "append", "(", "net_output", "[", "\"features_pen\"", "]", ")", "\n", "\n", "", "return", "pen", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules": [[597, 602], ["None"], "methods", ["None"], ["", "def", "remove_pretraining_modules", "(", "self", ")", ":", "\n", "        ", "self", ".", "quantizer", "=", "None", "\n", "self", ".", "project_q", "=", "None", "\n", "self", ".", "target_glu", "=", "None", "\n", "self", ".", "final_proj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.ConvFeatureExtractionModel.__init__": [[605, 673], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "wav2vec2.ConvFeatureExtractionModel.conv_layers.append", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.Sequential", "torch.Sequential", "torch.Sequential", "len", "str", "wav2vec2.ConvFeatureExtractionModel.__init__.block"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "conv_layers", ":", "List", "[", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "mode", ":", "str", "=", "\"default\"", ",", "\n", "conv_bias", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "mode", "in", "{", "\"default\"", ",", "\"layer_norm\"", "}", "\n", "\n", "def", "block", "(", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "k", ",", "\n", "stride", ",", "\n", "is_layer_norm", "=", "False", ",", "\n", "is_group_norm", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", ")", ":", "\n", "            ", "def", "make_conv", "(", ")", ":", "\n", "                ", "conv", "=", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", "=", "stride", ",", "bias", "=", "conv_bias", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "conv", ".", "weight", ")", "\n", "return", "conv", "\n", "\n", "", "assert", "(", "\n", "is_layer_norm", "and", "is_group_norm", "\n", ")", "==", "False", ",", "\"layer norm and group norm are exclusive\"", "\n", "\n", "if", "is_layer_norm", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "\n", "make_conv", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Sequential", "(", "\n", "TransposeLast", "(", ")", ",", "\n", "Fp32LayerNorm", "(", "dim", ",", "elementwise_affine", "=", "True", ")", ",", "\n", "TransposeLast", "(", ")", ",", "\n", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", ")", "\n", "", "elif", "is_group_norm", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "\n", "make_conv", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "Fp32GroupNorm", "(", "dim", ",", "dim", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "make_conv", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "nn", ".", "GELU", "(", ")", ")", "\n", "\n", "", "", "in_d", "=", "1", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", ",", "cl", "in", "enumerate", "(", "conv_layers", ")", ":", "\n", "            ", "assert", "len", "(", "cl", ")", "==", "3", ",", "\"invalid conv definition: \"", "+", "str", "(", "cl", ")", "\n", "(", "dim", ",", "k", ",", "stride", ")", "=", "cl", "\n", "\n", "self", ".", "conv_layers", ".", "append", "(", "\n", "block", "(", "\n", "in_d", ",", "\n", "dim", ",", "\n", "k", ",", "\n", "stride", ",", "\n", "is_layer_norm", "=", "mode", "==", "\"layer_norm\"", ",", "\n", "is_group_norm", "=", "mode", "==", "\"default\"", "and", "i", "==", "0", ",", "\n", "conv_bias", "=", "conv_bias", ",", "\n", ")", "\n", ")", "\n", "in_d", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.ConvFeatureExtractionModel.forward": [[674, 683], ["conv.unsqueeze", "conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "# BxT -> BxCxT", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "conv", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", "=", "conv", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerEncoder.__init__": [[686, 728], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "math.sqrt", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "wav2vec2.TransformerEncoder.apply", "fairseq.modules.SamePad", "torch.GELU", "torch.GELU", "torch.GELU", "wav2vec2.TransformerSentenceEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "embedding_dim", "=", "args", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "pos_conv", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "kernel_size", "=", "args", ".", "conv_pos", ",", "\n", "padding", "=", "args", ".", "conv_pos", "//", "2", ",", "\n", "groups", "=", "args", ".", "conv_pos_groups", ",", "\n", ")", "\n", "dropout", "=", "0", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "args", ".", "conv_pos", "*", "self", ".", "embedding_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "pos_conv", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "pos_conv", ".", "bias", ",", "0", ")", "\n", "\n", "self", ".", "pos_conv", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "pos_conv", ",", "name", "=", "\"weight\"", ",", "dim", "=", "2", ")", "\n", "self", ".", "pos_conv", "=", "nn", ".", "Sequential", "(", "self", ".", "pos_conv", ",", "SamePad", "(", "args", ".", "conv_pos", ")", ",", "nn", ".", "GELU", "(", ")", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "num_attention_heads", "=", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "attention_dropout", "=", "args", ".", "attention_dropout", ",", "\n", "activation_dropout", "=", "args", ".", "activation_dropout", ",", "\n", "activation_fn", "=", "args", ".", "activation_fn", ",", "\n", "layer_norm_first", "=", "args", ".", "layer_norm_first", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "layer_norm_first", "=", "args", ".", "layer_norm_first", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "layerdrop", "=", "args", ".", "encoder_layerdrop", "\n", "\n", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerEncoder.forward": [[729, 736], ["wav2vec2.TransformerEncoder.extract_features", "wav2vec2.TransformerEncoder.layer_norm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "x", ",", "padding_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "extract_features", "(", "x", ",", "padding_mask", ")", "\n", "\n", "if", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerEncoder.extract_features": [[737, 765], ["wav2vec2.TransformerEncoder.pos_conv", "x_conv.transpose.transpose.transpose", "torch.dropout", "torch.dropout", "torch.dropout", "wav2vec2.TransformerEncoder.transpose", "enumerate", "wav2vec2.TransformerEncoder.transpose", "wav2vec2.TransformerEncoder.transpose", "wav2vec2.TransformerEncoder.layer_norm", "numpy.random.random", "layer", "layer_results.append"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "x", ",", "padding_mask", "=", "None", ")", ":", "\n", "\n", "        ", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "[", "padding_mask", "]", "=", "0", "\n", "\n", "", "x_conv", "=", "self", ".", "pos_conv", "(", "x", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "+=", "x_conv", "\n", "\n", "if", "not", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "layer_results", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "dropout_probability", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "if", "not", "self", ".", "training", "or", "(", "dropout_probability", ">", "self", ".", "layerdrop", ")", ":", "\n", "                ", "x", ",", "z", "=", "layer", "(", "x", ",", "self_attn_padding_mask", "=", "padding_mask", ",", "need_weights", "=", "False", ")", "\n", "layer_results", ".", "append", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerEncoder.max_positions": [[766, 769], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the encoder.\"\"\"", "\n", "return", "self", ".", "args", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerEncoder.upgrade_state_dict_named": [[770, 773], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerSentenceEncoderLayer.__init__": [[781, 821], ["torch.Module.__init__", "fairseq.utils.get_activation_fn", "fairseq.modules.MultiheadAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.modules.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "float", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "float", "=", "3072", ",", "\n", "num_attention_heads", ":", "float", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "layer_norm_first", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Initialize parameters", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "activation_dropout", "=", "activation_dropout", "\n", "\n", "# Initialize blocks", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "self", ".", "activation_dropout", ")", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "layer_norm_first", "=", "layer_norm_first", "\n", "\n", "# layer norm associated with the self attention layer", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", ",", "ffn_embedding_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ffn_embedding_dim", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "# layer norm associated with the position wise feed-forward NN", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.TransformerSentenceEncoderLayer.forward": [[822, 879], ["wav2vec2.TransformerSentenceEncoderLayer.self_attn_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.self_attn", "wav2vec2.TransformerSentenceEncoderLayer.dropout1", "wav2vec2.TransformerSentenceEncoderLayer.final_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.activation_fn", "wav2vec2.TransformerSentenceEncoderLayer.dropout2", "wav2vec2.TransformerSentenceEncoderLayer.fc2", "wav2vec2.TransformerSentenceEncoderLayer.dropout3", "wav2vec2.TransformerSentenceEncoderLayer.self_attn", "wav2vec2.TransformerSentenceEncoderLayer.dropout1", "wav2vec2.TransformerSentenceEncoderLayer.self_attn_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.activation_fn", "wav2vec2.TransformerSentenceEncoderLayer.dropout2", "wav2vec2.TransformerSentenceEncoderLayer.fc2", "wav2vec2.TransformerSentenceEncoderLayer.dropout3", "wav2vec2.TransformerSentenceEncoderLayer.final_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.fc1", "wav2vec2.TransformerSentenceEncoderLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "self_attn_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "False", ",", "\n", "att_args", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        LayerNorm is applied either before or after the self-attention/ffn\n        modules similar to the original Transformer imlementation.\n        \"\"\"", "\n", "residual", "=", "x", "\n", "\n", "if", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout3", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "", "else", ":", "\n", "            ", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "need_weights", ",", "\n", ")", "\n", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout3", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.__init__": [[48, 52], ["fairseq.models.BaseFairseqModel.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2Ctc3Config", ",", "w2v_encoder", ":", "BaseFairseqModel", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "w2v_encoder", "=", "w2v_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.upgrade_state_dict_named": [[53, 56], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.build_model": [[57, 62], ["wav2vec2_asr3.Wav2VecEncoder3", "cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "cfg", ":", "Wav2Vec2Ctc3Config", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "w2v_encoder", "=", "Wav2VecEncoder3", "(", "cfg", ",", "task", ".", "target_dictionary", ")", "\n", "return", "cls", "(", "cfg", ",", "w2v_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.get_normalized_probs": [[63, 71], ["fairseq.utils.log_softmax", "fairseq.utils.softmax", "logits.float", "logits.float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.get_logits": [[72, 81], ["padding.any", "float"], "methods", ["None"], ["", "", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "padding", "=", "net_output", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "padding", "is", "not", "None", "and", "padding", ".", "any", "(", ")", ":", "\n", "            ", "padding", "=", "padding", ".", "T", "\n", "logits", "[", "padding", "]", "[", "...", ",", "0", "]", "=", "0", "\n", "logits", "[", "padding", "]", "[", "...", ",", "1", ":", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecCtc3.forward": [[82, 85], ["wav2vec2_asr3.Wav2VecCtc3.w2v_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "w2v_encoder", "(", "**", "kwargs", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.__init__": [[87, 166], ["fairseq.tasks.setup_task", "fairseq.tasks.setup_task.build_model", "tasks.setup_task.build_model.remove_pretraining_modules", "fairseq.models.FairseqEncoder.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "isinstance", "tasks.setup_task.build_model.load_state_dict", "wav2vec2_asr3.Linear", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.models.wav2vec.TransformerSentenceEncoderLayer", "len", "getattr", "wav2vec2_asr3.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2AsrConfig", ",", "tgt_dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "apply_mask", "=", "cfg", ".", "apply_mask", "\n", "\n", "arg_overrides", "=", "{", "\n", "\"dropout\"", ":", "cfg", ".", "dropout", ",", "\n", "\"activation_dropout\"", ":", "cfg", ".", "activation_dropout", ",", "\n", "\"dropout_input\"", ":", "cfg", ".", "dropout_input", ",", "\n", "\"attention_dropout\"", ":", "cfg", ".", "attention_dropout", ",", "\n", "\"mask_length\"", ":", "cfg", ".", "mask_length", ",", "\n", "\"mask_prob\"", ":", "cfg", ".", "mask_prob", ",", "\n", "\"mask_selection\"", ":", "cfg", ".", "mask_selection", ",", "\n", "\"mask_other\"", ":", "cfg", ".", "mask_other", ",", "\n", "\"no_mask_overlap\"", ":", "cfg", ".", "no_mask_overlap", ",", "\n", "\"mask_channel_length\"", ":", "cfg", ".", "mask_channel_length", ",", "\n", "\"mask_channel_prob\"", ":", "cfg", ".", "mask_channel_prob", ",", "\n", "\"mask_channel_selection\"", ":", "cfg", ".", "mask_channel_selection", ",", "\n", "\"mask_channel_other\"", ":", "cfg", ".", "mask_channel_other", ",", "\n", "\"no_mask_channel_overlap\"", ":", "cfg", ".", "no_mask_channel_overlap", ",", "\n", "\"encoder_layerdrop\"", ":", "cfg", ".", "layerdrop", ",", "\n", "\"feature_grad_mult\"", ":", "cfg", ".", "feature_grad_mult", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "w2v_args", "is", "None", ":", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "cfg", ".", "w2v_path", ",", "arg_overrides", ")", "\n", "w2v_args", "=", "state", ".", "get", "(", "\"cfg\"", ",", "None", ")", "\n", "if", "w2v_args", "is", "None", ":", "\n", "                ", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "cfg", ".", "w2v_args", "=", "w2v_args", "\n", "", "else", ":", "\n", "            ", "state", "=", "None", "\n", "w2v_args", "=", "cfg", ".", "w2v_args", "\n", "if", "isinstance", "(", "w2v_args", ",", "Namespace", ")", ":", "\n", "                ", "cfg", ".", "w2v_args", "=", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "w2v_args", ")", "\n", "\n", "", "", "assert", "cfg", ".", "normalize", "==", "w2v_args", ".", "task", ".", "normalize", ",", "(", "\n", "\"Fine-tuning works best when data normalization is the same. \"", "\n", "\"Please check that --normalize is set or unset for both pre-training and here\"", "\n", ")", "\n", "\n", "w2v_args", ".", "task", ".", "data", "=", "cfg", ".", "data", "\n", "task", "=", "tasks", ".", "setup_task", "(", "w2v_args", ".", "task", ")", "\n", "model", "=", "task", ".", "build_model", "(", "w2v_args", ".", "model", ")", "\n", "\n", "if", "state", "is", "not", "None", "and", "not", "cfg", ".", "no_pretrained_weights", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "model", ".", "remove_pretraining_modules", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "task", ".", "source_dictionary", ")", "\n", "\n", "d", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "w2v_model", "=", "model", "\n", "self", ".", "additional_layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", ",", "\n", "ffn_embedding_dim", "=", "self", ".", "w2v_model", ".", "cfg", ".", "encoder_ffn_embed_dim", ",", "\n", "num_attention_heads", "=", "self", ".", "w2v_model", ".", "cfg", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "cfg", ".", "dropout", ",", "\n", "attention_dropout", "=", "cfg", ".", "attention_dropout", ",", "\n", "activation_dropout", "=", "cfg", ".", "activation_dropout", ",", "\n", "activation_fn", "=", "self", ".", "w2v_model", ".", "cfg", ".", "activation_fn", ",", "\n", "layer_norm_first", "=", "self", ".", "w2v_model", ".", "cfg", ".", "layer_norm_first", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "cfg", ".", "additional_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "final_dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "final_dropout", ")", "\n", "self", ".", "freeze_finetune_updates", "=", "cfg", ".", "freeze_finetune_updates", "\n", "self", ".", "num_updates", "=", "0", "\n", "\n", "if", "tgt_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "len", "(", "tgt_dict", ")", ")", "\n", "", "elif", "getattr", "(", "cfg", ",", "\"decoder_embed_dim\"", ",", "d", ")", "!=", "d", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "cfg", ".", "decoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.set_num_updates": [[167, 171], ["super().set_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates"], ["", "", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "super", "(", ")", ".", "set_num_updates", "(", "num_updates", ")", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.forward": [[172, 204], ["enumerate", "wav2vec2_asr3.Wav2VecEncoder3.final_dropout", "wav2vec2_asr3.Wav2VecEncoder3.w2v_model.extract_features", "wav2vec2_asr3.Wav2VecEncoder3.transpose", "layer", "wav2vec2_asr3.Wav2VecEncoder3.transpose", "wav2vec2_asr3.Wav2VecEncoder3.proj", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "contextlib.ExitStack"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", ",", "tbc", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "w2v_args", "=", "{", "\n", "\"source\"", ":", "source", ",", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "\"mask\"", ":", "self", ".", "apply_mask", "and", "self", ".", "training", ",", "\n", "}", "\n", "\n", "ft", "=", "self", ".", "freeze_finetune_updates", "<=", "self", ".", "num_updates", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", "if", "not", "ft", "else", "contextlib", ".", "ExitStack", "(", ")", ":", "\n", "            ", "x", ",", "padding_mask", "=", "self", ".", "w2v_model", ".", "extract_features", "(", "**", "w2v_args", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "additional_layer", ")", ":", "\n", "            ", "x", ",", "z", "=", "layer", "(", "x", ",", "self_attn_padding_mask", "=", "padding_mask", ",", "need_weights", "=", "False", ")", "\n", "\n", "", "if", "not", "tbc", ":", "\n", "# T x B x C -> B x T x C", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "## upper token out", "\n", "", "x", "=", "self", ".", "final_dropout", "(", "x", ")", "\n", "if", "self", ".", "proj", ":", "\n", "            ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "\n", "", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# T x B x C", "\n", "\"encoder_padding_mask\"", ":", "padding_mask", ",", "# B x T", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.reorder_encoder_out": [[206, 216], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.max_positions": [[217, 220], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Wav2VecEncoder3.upgrade_state_dict_named": [[221, 223], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Embedding": [[226, 231], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr3.Linear": [[233, 239], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.__init__": [[48, 52], ["fairseq.models.BaseFairseqModel.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2Ctc2Config", ",", "w2v_encoder", ":", "BaseFairseqModel", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "w2v_encoder", "=", "w2v_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.upgrade_state_dict_named": [[53, 56], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.build_model": [[57, 62], ["wav2vec2_asr2.Wav2VecEncoder2", "cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "cfg", ":", "Wav2Vec2Ctc2Config", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "w2v_encoder", "=", "Wav2VecEncoder2", "(", "cfg", ",", "task", ".", "target_dictionary", ",", "task", ".", "additional_dictionary", ")", "\n", "return", "cls", "(", "cfg", ",", "w2v_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_normalized_probs": [[63, 71], ["fairseq.utils.log_softmax", "fairseq.utils.softmax", "logits.float", "logits.float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_logits": [[72, 81], ["padding.any", "float"], "methods", ["None"], ["", "", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "padding", "=", "net_output", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "padding", "is", "not", "None", "and", "padding", ".", "any", "(", ")", ":", "\n", "            ", "padding", "=", "padding", ".", "T", "\n", "logits", "[", "padding", "]", "[", "...", ",", "0", "]", "=", "0", "\n", "logits", "[", "padding", "]", "[", "...", ",", "1", ":", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_normalized_addprobs": [[82, 90], ["fairseq.utils.log_softmax", "fairseq.utils.softmax", "logits.float", "logits.float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_addprobs", "(", "self", ",", "net_output", ",", "log_probs", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "\"additional_out\"", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_addlogits": [[91, 100], ["padding.any", "float"], "methods", ["None"], ["", "", "def", "get_addlogits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"additional_out\"", "]", "\n", "padding", "=", "net_output", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "padding", "is", "not", "None", "and", "padding", ".", "any", "(", ")", ":", "\n", "            ", "padding", "=", "padding", ".", "T", "\n", "logits", "[", "padding", "]", "[", "...", ",", "0", "]", "=", "0", "\n", "logits", "[", "padding", "]", "[", "...", ",", "1", ":", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.forward": [[102, 105], ["wav2vec2_asr2.Wav2VecCtc2.w2v_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "w2v_encoder", "(", "**", "kwargs", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.__init__": [[107, 193], ["fairseq.tasks.setup_task", "fairseq.tasks.setup_task.build_model", "tasks.setup_task.build_model.remove_pretraining_modules", "fairseq.models.FairseqEncoder.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "isinstance", "tasks.setup_task.build_model.load_state_dict", "wav2vec2_asr2.Linear", "wav2vec2_asr2.Linear", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.models.wav2vec.TransformerSentenceEncoderLayer", "len", "getattr", "wav2vec2_asr2.Linear", "len", "getattr", "wav2vec2_asr2.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2AsrConfig", ",", "tgt_dict", "=", "None", ",", "tgt_dict2", "=", "None", ")", ":", "\n", "        ", "self", ".", "apply_mask", "=", "cfg", ".", "apply_mask", "\n", "\n", "arg_overrides", "=", "{", "\n", "\"dropout\"", ":", "cfg", ".", "dropout", ",", "\n", "\"activation_dropout\"", ":", "cfg", ".", "activation_dropout", ",", "\n", "\"dropout_input\"", ":", "cfg", ".", "dropout_input", ",", "\n", "\"attention_dropout\"", ":", "cfg", ".", "attention_dropout", ",", "\n", "\"mask_length\"", ":", "cfg", ".", "mask_length", ",", "\n", "\"mask_prob\"", ":", "cfg", ".", "mask_prob", ",", "\n", "\"mask_selection\"", ":", "cfg", ".", "mask_selection", ",", "\n", "\"mask_other\"", ":", "cfg", ".", "mask_other", ",", "\n", "\"no_mask_overlap\"", ":", "cfg", ".", "no_mask_overlap", ",", "\n", "\"mask_channel_length\"", ":", "cfg", ".", "mask_channel_length", ",", "\n", "\"mask_channel_prob\"", ":", "cfg", ".", "mask_channel_prob", ",", "\n", "\"mask_channel_selection\"", ":", "cfg", ".", "mask_channel_selection", ",", "\n", "\"mask_channel_other\"", ":", "cfg", ".", "mask_channel_other", ",", "\n", "\"no_mask_channel_overlap\"", ":", "cfg", ".", "no_mask_channel_overlap", ",", "\n", "\"encoder_layerdrop\"", ":", "cfg", ".", "layerdrop", ",", "\n", "\"feature_grad_mult\"", ":", "cfg", ".", "feature_grad_mult", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "w2v_args", "is", "None", ":", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "cfg", ".", "w2v_path", ",", "arg_overrides", ")", "\n", "w2v_args", "=", "state", ".", "get", "(", "\"cfg\"", ",", "None", ")", "\n", "if", "w2v_args", "is", "None", ":", "\n", "                ", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "cfg", ".", "w2v_args", "=", "w2v_args", "\n", "", "else", ":", "\n", "            ", "state", "=", "None", "\n", "w2v_args", "=", "cfg", ".", "w2v_args", "\n", "if", "isinstance", "(", "w2v_args", ",", "Namespace", ")", ":", "\n", "                ", "cfg", ".", "w2v_args", "=", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "w2v_args", ")", "\n", "\n", "", "", "assert", "cfg", ".", "normalize", "==", "w2v_args", ".", "task", ".", "normalize", ",", "(", "\n", "\"Fine-tuning works best when data normalization is the same. \"", "\n", "\"Please check that --normalize is set or unset for both pre-training and here\"", "\n", ")", "\n", "\n", "w2v_args", ".", "task", ".", "data", "=", "cfg", ".", "data", "\n", "task", "=", "tasks", ".", "setup_task", "(", "w2v_args", ".", "task", ")", "\n", "model", "=", "task", ".", "build_model", "(", "w2v_args", ".", "model", ")", "\n", "\n", "if", "state", "is", "not", "None", "and", "not", "cfg", ".", "no_pretrained_weights", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "model", ".", "remove_pretraining_modules", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "task", ".", "source_dictionary", ")", "\n", "\n", "d", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "w2v_model", "=", "model", "\n", "self", ".", "additional_layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", ",", "\n", "ffn_embedding_dim", "=", "self", ".", "w2v_model", ".", "cfg", ".", "encoder_ffn_embed_dim", ",", "\n", "num_attention_heads", "=", "self", ".", "w2v_model", ".", "cfg", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "cfg", ".", "dropout", ",", "\n", "attention_dropout", "=", "cfg", ".", "attention_dropout", ",", "\n", "activation_dropout", "=", "cfg", ".", "activation_dropout", ",", "\n", "activation_fn", "=", "self", ".", "w2v_model", ".", "cfg", ".", "activation_fn", ",", "\n", "layer_norm_first", "=", "self", ".", "w2v_model", ".", "cfg", ".", "layer_norm_first", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "cfg", ".", "additional_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "final_dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "final_dropout", ")", "\n", "self", ".", "freeze_finetune_updates", "=", "cfg", ".", "freeze_finetune_updates", "\n", "self", ".", "num_updates", "=", "0", "\n", "\n", "if", "tgt_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "len", "(", "tgt_dict", ")", ")", "\n", "", "elif", "getattr", "(", "cfg", ",", "\"decoder_embed_dim\"", ",", "d", ")", "!=", "d", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "cfg", ".", "decoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "None", "\n", "\n", "", "if", "tgt_dict2", "is", "not", "None", ":", "\n", "            ", "self", ".", "proj2", "=", "Linear", "(", "d", ",", "len", "(", "tgt_dict2", ")", ")", "\n", "", "elif", "getattr", "(", "cfg", ",", "\"decoder_embed_dim\"", ",", "d", ")", "!=", "d", ":", "\n", "            ", "self", ".", "proj2", "=", "Linear", "(", "d", ",", "cfg", ".", "decoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj2", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.set_num_updates": [[194, 198], ["super().set_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates"], ["", "", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "super", "(", ")", ".", "set_num_updates", "(", "num_updates", ")", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.forward": [[199, 239], ["enumerate", "wav2vec2_asr2.Wav2VecEncoder2.final_dropout", "wav2vec2_asr2.Wav2VecEncoder2.final_dropout", "wav2vec2_asr2.Wav2VecEncoder2.w2v_model.extract_features", "wav2vec2_asr2.Wav2VecEncoder2.transpose", "layer", "wav2vec2_asr2.Wav2VecEncoder2.transpose", "wav2vec2_asr2.Wav2VecEncoder2.transpose", "wav2vec2_asr2.Wav2VecEncoder2.proj", "wav2vec2_asr2.Wav2VecEncoder2.proj2", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "contextlib.ExitStack"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", ",", "tbc", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "w2v_args", "=", "{", "\n", "\"source\"", ":", "source", ",", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "\"mask\"", ":", "self", ".", "apply_mask", "and", "self", ".", "training", ",", "\n", "}", "\n", "\n", "ft", "=", "self", ".", "freeze_finetune_updates", "<=", "self", ".", "num_updates", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", "if", "not", "ft", "else", "contextlib", ".", "ExitStack", "(", ")", ":", "\n", "            ", "x", ",", "padding_mask", "=", "self", ".", "w2v_model", ".", "extract_features", "(", "**", "w2v_args", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "additional_x", "=", "x", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "additional_layer", ")", ":", "\n", "            ", "additional_x", ",", "z", "=", "layer", "(", "additional_x", ",", "self_attn_padding_mask", "=", "padding_mask", ",", "need_weights", "=", "False", ")", "\n", "\n", "", "if", "not", "tbc", ":", "\n", "# T x B x C -> B x T x C", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "additional_x", "=", "additional_x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "## lower token out", "\n", "", "x", "=", "self", ".", "final_dropout", "(", "x", ")", "\n", "if", "self", ".", "proj", ":", "\n", "            ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "\n", "## upper token out", "\n", "", "additional_x", "=", "self", ".", "final_dropout", "(", "additional_x", ")", "\n", "if", "self", ".", "proj2", ":", "\n", "            ", "additional_x", "=", "self", ".", "proj2", "(", "additional_x", ")", "\n", "\n", "", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# T x B x C", "\n", "\"additional_out\"", ":", "additional_x", ",", "# T x B x C", "\n", "\"encoder_padding_mask\"", ":", "padding_mask", ",", "# B x T", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.reorder_encoder_out": [[241, 251], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.max_positions": [[252, 255], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecEncoder2.upgrade_state_dict_named": [[256, 258], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Embedding": [[261, 266], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Linear": [[268, 274], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.__init__": [[135, 139], ["fairseq.models.BaseFairseqModel.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2CtcConfig", ",", "w2v_encoder", ":", "BaseFairseqModel", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "w2v_encoder", "=", "w2v_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.upgrade_state_dict_named": [[140, 143], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.build_model": [[144, 149], ["wav2vec2_asr.Wav2VecEncoder", "cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "cfg", ":", "Wav2Vec2CtcConfig", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "w2v_encoder", "=", "Wav2VecEncoder", "(", "cfg", ",", "task", ".", "target_dictionary", ")", "\n", "return", "cls", "(", "cfg", ",", "w2v_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.get_normalized_probs": [[150, 158], ["fairseq.utils.log_softmax", "fairseq.utils.softmax", "logits.float", "logits.float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "softmax_temp", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ".", "float", "(", ")", "/", "softmax_temp", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ".", "float", "(", ")", "/", "softmax_temp", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.get_logits": [[159, 168], ["padding.any", "float"], "methods", ["None"], ["", "", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "padding", "=", "net_output", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "padding", "is", "not", "None", "and", "padding", ".", "any", "(", ")", ":", "\n", "            ", "padding", "=", "padding", ".", "T", "\n", "logits", "[", "padding", "]", "[", "...", ",", "0", "]", "=", "0", "\n", "logits", "[", "padding", "]", "[", "...", ",", "1", ":", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.forward": [[169, 172], ["wav2vec2_asr.Wav2VecCtc.w2v_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "w2v_encoder", "(", "**", "kwargs", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.__init__": [[227, 229], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.build_model": [[230, 248], ["wav2vec2_asr.Wav2Vec2Seq2SeqModel.build_model.build_embedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "cfg", ":", "Wav2Vec2Seq2SeqConfig", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "return", "emb", "\n", "\n", "", "decoder_embed_tokens", "=", "build_embedding", "(", "tgt_dict", ",", "cfg", ".", "decoder_embed_dim", ")", "\n", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "cfg", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "cfg", ",", "tgt_dict", ",", "decoder_embed_tokens", ")", "\n", "\n", "return", "Wav2Vec2Seq2SeqModel", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.build_encoder": [[249, 252], ["wav2vec2_asr.Wav2VecEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "cfg", ":", "Wav2Vec2AsrConfig", ")", ":", "\n", "        ", "return", "Wav2VecEncoder", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.build_decoder": [[253, 256], ["wav2vec2_asr.TransformerDecoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "cfg", ":", "Wav2Vec2Seq2SeqConfig", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "cfg", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.forward": [[257, 261], ["wav2vec2_asr.Wav2Vec2Seq2SeqModel.encoder", "wav2vec2_asr.Wav2Vec2Seq2SeqModel.decoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "tbc", "=", "False", ",", "**", "kwargs", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2Vec2Seq2SeqModel.upgrade_state_dict_named": [[262, 265], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.__init__": [[268, 332], ["fairseq.tasks.setup_task", "fairseq.tasks.setup_task.build_model", "tasks.setup_task.build_model.remove_pretraining_modules", "fairseq.models.FairseqEncoder.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "isinstance", "tasks.setup_task.build_model.load_state_dict", "wav2vec2_asr.Linear", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "len", "getattr", "wav2vec2_asr.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.audio_multitraining.AudioMultitrainingTask.setup_task", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "Wav2Vec2AsrConfig", ",", "tgt_dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "apply_mask", "=", "cfg", ".", "apply_mask", "\n", "\n", "arg_overrides", "=", "{", "\n", "\"dropout\"", ":", "cfg", ".", "dropout", ",", "\n", "\"activation_dropout\"", ":", "cfg", ".", "activation_dropout", ",", "\n", "\"dropout_input\"", ":", "cfg", ".", "dropout_input", ",", "\n", "\"attention_dropout\"", ":", "cfg", ".", "attention_dropout", ",", "\n", "\"mask_length\"", ":", "cfg", ".", "mask_length", ",", "\n", "\"mask_prob\"", ":", "cfg", ".", "mask_prob", ",", "\n", "\"mask_selection\"", ":", "cfg", ".", "mask_selection", ",", "\n", "\"mask_other\"", ":", "cfg", ".", "mask_other", ",", "\n", "\"no_mask_overlap\"", ":", "cfg", ".", "no_mask_overlap", ",", "\n", "\"mask_channel_length\"", ":", "cfg", ".", "mask_channel_length", ",", "\n", "\"mask_channel_prob\"", ":", "cfg", ".", "mask_channel_prob", ",", "\n", "\"mask_channel_selection\"", ":", "cfg", ".", "mask_channel_selection", ",", "\n", "\"mask_channel_other\"", ":", "cfg", ".", "mask_channel_other", ",", "\n", "\"no_mask_channel_overlap\"", ":", "cfg", ".", "no_mask_channel_overlap", ",", "\n", "\"encoder_layerdrop\"", ":", "cfg", ".", "layerdrop", ",", "\n", "\"feature_grad_mult\"", ":", "cfg", ".", "feature_grad_mult", ",", "\n", "}", "\n", "\n", "if", "cfg", ".", "w2v_args", "is", "None", ":", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "cfg", ".", "w2v_path", ",", "arg_overrides", ")", "\n", "w2v_args", "=", "state", ".", "get", "(", "\"cfg\"", ",", "None", ")", "\n", "if", "w2v_args", "is", "None", ":", "\n", "                ", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "cfg", ".", "w2v_args", "=", "w2v_args", "\n", "", "else", ":", "\n", "            ", "state", "=", "None", "\n", "w2v_args", "=", "cfg", ".", "w2v_args", "\n", "if", "isinstance", "(", "w2v_args", ",", "Namespace", ")", ":", "\n", "                ", "cfg", ".", "w2v_args", "=", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "w2v_args", ")", "\n", "\n", "", "", "assert", "cfg", ".", "normalize", "==", "w2v_args", ".", "task", ".", "normalize", ",", "(", "\n", "\"Fine-tuning works best when data normalization is the same. \"", "\n", "\"Please check that --normalize is set or unset for both pre-training and here\"", "\n", ")", "\n", "\n", "w2v_args", ".", "task", ".", "data", "=", "cfg", ".", "data", "\n", "task", "=", "tasks", ".", "setup_task", "(", "w2v_args", ".", "task", ")", "\n", "model", "=", "task", ".", "build_model", "(", "w2v_args", ".", "model", ")", "\n", "\n", "if", "state", "is", "not", "None", "and", "not", "cfg", ".", "no_pretrained_weights", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "model", ".", "remove_pretraining_modules", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "task", ".", "source_dictionary", ")", "\n", "\n", "d", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "w2v_model", "=", "model", "\n", "\n", "self", ".", "final_dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "final_dropout", ")", "\n", "self", ".", "freeze_finetune_updates", "=", "cfg", ".", "freeze_finetune_updates", "\n", "self", ".", "num_updates", "=", "0", "\n", "\n", "if", "tgt_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "len", "(", "tgt_dict", ")", ")", "\n", "", "elif", "getattr", "(", "cfg", ",", "\"decoder_embed_dim\"", ",", "d", ")", "!=", "d", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "cfg", ".", "decoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates": [[333, 337], ["super().set_num_updates"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates"], ["", "", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "super", "(", ")", ".", "set_num_updates", "(", "num_updates", ")", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.forward": [[338, 364], ["wav2vec2_asr.Wav2VecEncoder.final_dropout", "wav2vec2_asr.Wav2VecEncoder.w2v_model.extract_features", "wav2vec2_asr.Wav2VecEncoder.proj", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "contextlib.ExitStack", "x.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", ",", "tbc", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "w2v_args", "=", "{", "\n", "\"source\"", ":", "source", ",", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "\"mask\"", ":", "self", ".", "apply_mask", "and", "self", ".", "training", ",", "\n", "}", "\n", "\n", "ft", "=", "self", ".", "freeze_finetune_updates", "<=", "self", ".", "num_updates", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", "if", "not", "ft", "else", "contextlib", ".", "ExitStack", "(", ")", ":", "\n", "            ", "x", ",", "padding_mask", "=", "self", ".", "w2v_model", ".", "extract_features", "(", "**", "w2v_args", ")", "\n", "\n", "if", "tbc", ":", "\n", "# B x T x C -> T x B x C", "\n", "                ", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "", "x", "=", "self", ".", "final_dropout", "(", "x", ")", "\n", "\n", "if", "self", ".", "proj", ":", "\n", "            ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "\n", "", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# T x B x C", "\n", "\"encoder_padding_mask\"", ":", "padding_mask", ",", "# B x T", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.reorder_encoder_out": [[366, 376], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.max_positions": [[377, 380], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecEncoder.upgrade_state_dict_named": [[381, 383], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.__init__": [[398, 468], ["fairseq.models.FairseqIncrementalDecoder.__init__", "math.sqrt", "copy.deepcopy", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "wav2vec2_asr.TransformerDecoder.layers.extend", "wav2vec2_asr.Linear", "fairseq.modules.PositionalEmbedding", "omegaconf.open_dict", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "fairseq.modules.LayerNorm", "fairseq.modules.TransformerDecoderLayer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.positional_embedding.PositionalEmbedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "Wav2Vec2Seq2SeqConfig", ",", "\n", "dictionary", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "\n", "self", ".", "dropout", "=", "cfg", ".", "decoder_dropout", "\n", "self", ".", "share_input_output_embed", "=", "cfg", ".", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "embed_dim", "=", "cfg", ".", "decoder_embed_dim", "\n", "self", ".", "output_embed_dim", "=", "cfg", ".", "decoder_embed_dim", "\n", "\n", "self", ".", "layerdrop", "=", "cfg", ".", "decoder_layerdrop", "\n", "\n", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "cfg", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "# todo: try with input_embed_dim", "\n", "\n", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "cfg", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", "learned", "=", "cfg", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "cfg", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "# TODO: update this when transformer gets converted to dataclass configs", "\n", "transformer_cfg", "=", "copy", ".", "deepcopy", "(", "cfg", ")", "\n", "with", "open_dict", "(", "transformer_cfg", ")", ":", "\n", "            ", "transformer_cfg", ".", "dropout", "=", "transformer_cfg", ".", "decoder_dropout", "\n", "transformer_cfg", ".", "attention_dropout", "=", "(", "\n", "transformer_cfg", ".", "decoder_attention_dropout", "\n", ")", "\n", "transformer_cfg", ".", "activation_dropout", "=", "(", "\n", "transformer_cfg", ".", "decoder_activation_dropout", "\n", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "TransformerDecoderLayer", "(", "transformer_cfg", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "transformer_cfg", ".", "decoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "if", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "self", ".", "output_embed_dim", ")", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", ")", "\n", "\n", "", "if", "transformer_cfg", ".", "decoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.forward": [[469, 492], ["prev_output_tokens.long.long.long", "wav2vec2_asr.TransformerDecoder.extract_features", "wav2vec2_asr.TransformerDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (Tensor, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "prev_output_tokens", "=", "prev_output_tokens", ".", "long", "(", ")", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "\n", ")", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.extract_features": [[493, 559], ["torch.dropout", "torch.dropout", "torch.dropout", "wav2vec2_asr.TransformerDecoder.transpose", "wav2vec2_asr.TransformerDecoder.transpose", "wav2vec2_asr.TransformerDecoder.embed_positions", "wav2vec2_asr.TransformerDecoder.embed_tokens", "wav2vec2_asr.TransformerDecoder.project_in_dim", "numpy.random.random", "wav2vec2_asr.TransformerDecoder.layer_norm", "layer", "inner_states.append", "wav2vec2_asr.TransformerDecoder.buffered_future_mask"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask"], ["", "def", "extract_features", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "\n", "# embed positions", "\n", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "incremental_state", "=", "incremental_state", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "x", "]", "\n", "\n", "# decoder layers", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "dropout_probability", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "if", "not", "self", ".", "training", "or", "(", "dropout_probability", ">", "self", ".", "layerdrop", ")", ":", "\n", "                ", "x", ",", "attn", ",", "_", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "encoder_out", "is", "not", "None", "\n", "else", "None", ",", "\n", "incremental_state", ",", "\n", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "if", "incremental_state", "is", "None", "\n", "else", "None", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", ",", "{", "\"attn\"", ":", "attn", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.output_layer": [[560, 567], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "# project back to size of vocabulary", "\n", "if", "self", ".", "share_input_output_embed", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.max_positions": [[568, 573], ["min"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_target_positions", "\n", "", "return", "min", "(", "self", ".", "max_target_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.buffered_future_mask": [[574, 586], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "wav2vec2_asr.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "tensor.new"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", "or", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.TransformerDecoder.upgrade_state_dict_named": [[587, 589], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Embedding": [[591, 596], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Linear": [[598, 604], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.__init__": [[30, 38], ["fairseq.trainer.Trainer.__init__", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqConfig", ",", "task", ",", "model", ",", "criterion", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "has_megatron_submodule", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "task", ",", "model", ",", "criterion", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm": [[39, 51], ["megatron_trainer.MegatronTrainer.optimizer.clip_grad_norm", "fairseq.distributed_utils.all_reduce", "fairseq.distributed_utils.get_model_parallel_group"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.all_reduce", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "clip_grad_norm", "(", "self", ",", "clip_norm", ")", ":", "\n", "        ", "def", "_aggregate_model_parallel_grad_norm", "(", "total_norm", ")", ":", "\n", "            ", "total_norm", "=", "total_norm", "**", "2", "\n", "distributed_utils", ".", "all_reduce", "(", "\n", "total_norm", ",", "group", "=", "distributed_utils", ".", "get_model_parallel_group", "(", ")", "\n", ")", "\n", "total_norm", "=", "total_norm", "**", "0.5", "\n", "return", "total_norm", "\n", "\n", "", "return", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "\n", "clip_norm", ",", "\n", "aggregate_norm_fn", "=", "_aggregate_model_parallel_grad_norm", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint": [[53, 58], ["get_cuda_rng_tracker().get_states", "super().save_checkpoint", "get_cuda_rng_tracker"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint"], ["", "def", "save_checkpoint", "(", "self", ",", "filename", ",", "extra_state", ")", ":", "\n", "        ", "\"\"\"Save all training state in a checkpoint file.\"\"\"", "\n", "extra_state", "[", "'rng_tracker_states'", "]", "=", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "super", "(", ")", ".", "save_checkpoint", "(", "filename", ",", "extra_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint": [[59, 72], ["super().load_checkpoint", "get_cuda_rng_tracker().set_states", "get_cuda_rng_tracker"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint"], ["", "def", "load_checkpoint", "(", "\n", "self", ",", "\n", "filename", ",", "\n", "reset_optimizer", "=", "False", ",", "\n", "reset_lr_scheduler", "=", "False", ",", "\n", "optimizer_overrides", "=", "None", ",", "\n", "reset_meters", "=", "False", ",", "\n", ")", ":", "\n", "        ", "extra_state", "=", "super", "(", ")", ".", "load_checkpoint", "(", "filename", ",", "reset_optimizer", "=", "reset_optimizer", ",", "reset_lr_scheduler", "=", "reset_lr_scheduler", ",", "optimizer_overrides", "=", "optimizer_overrides", ",", "reset_meters", "=", "reset_meters", ")", "\n", "if", "extra_state", "is", "not", "None", "and", "'rng_tracker_states'", "in", "extra_state", ":", "\n", "            ", "get_cuda_rng_tracker", "(", ")", ".", "set_states", "(", "\n", "extra_state", "[", "'rng_tracker_states'", "]", ")", "\n", "", "return", "extra_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding.__init__": [[35, 61], ["torch.Module.__init__", "isinstance", "math.sqrt", "getattr", "sum", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.positional_embedding.PositionalEmbedding", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "max_source_positions", "=", "args", ".", "max_source_positions", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "self", ".", "padding_idx", "=", "embed_tokens", "[", "0", "]", ".", "padding_idx", "\n", "embed_dim", "=", "sum", "(", "e", ".", "embedding_dim", "for", "e", "in", "embed_tokens", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "encoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "if", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding.forward": [[62, 86], ["isinstance", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderEmbedding.transpose", "src_tokens.eq", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.TransformerEncoderEmbedding.embed_tokens", "layers.TransformerEncoderEmbedding.layernorm_embedding", "x_embed_list.append", "layers.TransformerEncoderEmbedding.embed_positions", "embed_tokens_part"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "src_tokens", "=", "input", "[", "0", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "x_embed_list", "=", "[", "]", "\n", "for", "embed_tokens_part", "in", "self", ".", "embed_tokens", ":", "\n", "                ", "x_embed_list", ".", "append", "(", "embed_tokens_part", "(", "src_tokens", ")", ")", "\n", "\n", "", "embedded", "=", "torch", ".", "cat", "(", "x_embed_list", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "embedded", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "", "x", "=", "embed", "=", "self", ".", "embed_scale", "*", "embedded", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "=", "embed", "+", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "", "if", "self", ".", "layernorm_embedding", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# compute padding mask", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm.__init__": [[94, 100], ["torch.Module.__init__", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm.forward": [[101, 109], ["layers.TransformerEncoderLayerNorm.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "# keeping track of the incremental_state is not supported yet", "\n", "", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding.__init__": [[114, 151], ["torch.Module.__init__", "math.sqrt", "isinstance", "sum", "isinstance", "layers.Linear", "fairseq.modules.PositionalEmbedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.positional_embedding.PositionalEmbedding"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "input_embed_dim", "=", "(", "\n", "sum", "(", "e", ".", "embedding_dim", "for", "e", "in", "embed_tokens", ")", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "else", "embed_tokens", ".", "embedding_dim", "\n", ")", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "\n", "padding_idx", "=", "(", "\n", "embed_tokens", "[", "0", "]", ".", "padding_idx", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "else", "embed_tokens", ".", "padding_idx", "\n", ")", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "# todo: try with input_embed_dim", "\n", "\n", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding.forward": [[153, 213], ["isinstance", "isinstance", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderEmbedding.transpose", "layers.TransformerDecoderEmbedding.embed_positions", "layers.TransformerDecoderEmbedding.project_in_dim", "len", "x_embed_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.TransformerDecoderEmbedding.embed_tokens", "embed_tokens_part"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "mt_task", "=", "False", "\n", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "if", "len", "(", "input", ")", "==", "3", ":", "\n", "                ", "encoder_out", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "incremental_state", "=", "None", "# Hardcoding to avoid passing of None objects", "\n", "mt_task", "=", "True", "\n", "", "else", ":", "\n", "# HACK for now, need to fix (TODO sidgoyal)", "\n", "                ", "prev_output_tokens", "=", "input", "[", "0", "]", "\n", "# discard \"src_lengths\"", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "", "else", ":", "\n", "            ", "prev_output_tokens", "=", "input", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "\n", "", "", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "x_embed_list", "=", "[", "]", "\n", "for", "embed_tokens_part", "in", "self", ".", "embed_tokens", ":", "\n", "                ", "x_embed_list", ".", "append", "(", "embed_tokens_part", "(", "prev_output_tokens", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "embed_scale", "*", "torch", ".", "cat", "(", "x_embed_list", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "mt_task", ":", "\n", "            ", "return", "(", "x", ",", "encoder_out", ",", "encoder_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.__init__": [[216, 254], ["torch.Module.__init__", "layers.Linear", "fairseq.modules.AdaptiveSoftmax", "fairseq.modules.LayerNorm", "isinstance", "len", "fairseq.options.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "getattr", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "\n", "self", ".", "project_out_dim", "=", "(", "\n", "Linear", "(", "embed_dim", ",", "self", ".", "output_embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "self", ".", "output_embed_dim", "and", "not", "args", ".", "tie_adaptive_weights", "\n", "else", "None", "\n", ")", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "if", "args", ".", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "assert", "not", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "len", "(", "dictionary", ")", ",", "\n", "self", ".", "output_embed_dim", ",", "\n", "options", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "args", ".", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "embed_tokens", "if", "args", ".", "tie_adaptive_weights", "else", "None", ",", "\n", "factor", "=", "args", ".", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "args", ".", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "self", ".", "output_embed_dim", ")", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "\n", "self", ".", "embed_tokens", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", "\n", ")", "\n", "\n", "", "if", "args", ".", "decoder_normalize_before", "and", "not", "getattr", "(", "\n", "args", ",", "\"no_decoder_final_norm\"", ",", "False", "\n", ")", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.forward": [[255, 272], ["isinstance", "layers.TransformerDecoderOutputLayer.transpose", "layers.TransformerDecoderOutputLayer.layer_norm", "layers.TransformerDecoderOutputLayer.project_out_dim", "layers.TransformerDecoderOutputLayer.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "apply_final_proj", "=", "True", ")", ":", "\n", "        ", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "input", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "", "if", "apply_final_proj", ":", "\n", "            ", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.output_layer": [[273, 295], ["isinstance", "torch.linear", "torch.linear", "torch.linear", "enumerate", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "                    ", "output", "=", "None", "\n", "for", "i", ",", "emb", "in", "enumerate", "(", "self", ".", "embed_tokens", ")", ":", "\n", "                        ", "sidx", "=", "i", "*", "emb", ".", "embedding_dim", "\n", "eidx", "=", "(", "i", "+", "1", ")", "*", "emb", ".", "embedding_dim", "\n", "if", "output", "is", "None", ":", "\n", "                            ", "output", "=", "F", ".", "linear", "(", "features", "[", ":", ",", ":", ",", "sidx", ":", "eidx", "]", ",", "emb", ".", "weight", ")", "\n", "", "else", ":", "\n", "                            ", "output", "+=", "F", ".", "linear", "(", "features", "[", ":", ",", ":", ",", "sidx", ":", "eidx", "]", ",", "emb", ".", "weight", ")", "\n", "\n", "", "", "return", "output", "\n", "", "else", ":", "\n", "                    ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "", "else", ":", "\n", "                ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayer.__init__": [[311, 333], ["torch.Module.__init__", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "fairseq.utils.get_activation_fn", "getattr", "layers.Linear", "layers.Linear", "fairseq.modules.LayerNorm", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "encoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "encoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayer.upgrade_state_dict_named": [[334, 347], ["layer_norm_map.items"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Rename layer norm states from `...layer_norms.0.weight` to\n        `...self_attn_layer_norm.weight` and `...layer_norms.1.weight` to\n        `...final_layer_norm.weight`\n        \"\"\"", "\n", "layer_norm_map", "=", "{", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\"1\"", ":", "\"final_layer_norm\"", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                ", "k", "=", "\"{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                    ", "state_dict", "[", "\"{}.{}.{}\"", ".", "format", "(", "name", ",", "new", ",", "m", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayer.forward": [[348, 385], ["layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm"], ["", "", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (Tuple):\n                input[0] (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n                input[1] (ByteTensor/FloatTensor): encoder padding mask -\n                    binary ByteTensor of shape `(batch, src_len)` where padding elements\n                    are indicated by ``1``.\n                input[2] (LongTensor): previous decoder outputs of shape\n                    `(batch, tgt_len)`, for teacher forcing)\n        Returns:\n            output (Tuple):\n                output[0] (Tensor): encoded output of shape `(batch, src_len, embed_dim)`\n                output[1] (ByteTensor/FloatTensor): encoder padding mask\n                output[2] (LongTensor): previous decoder outputs\n        \"\"\"", "\n", "x", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "encoder_padding_mask", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerEncoderLayer.maybe_layer_norm": [[386, 392], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.__init__": [[411, 461], ["torch.Module.__init__", "fairseq.modules.MultiheadAttention", "fairseq.utils.get_activation_fn", "getattr", "getattr", "fairseq.modules.LayerNorm", "layers.Linear", "layers.Linear", "fairseq.modules.LayerNorm", "getattr", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "# use layerNorm rather than FusedLayerNorm for exporting.", "\n", "# char_inputs can be used to determint this.", "\n", "# TODO  remove this once we update apex with the fix", "\n", "export", "=", "getattr", "(", "args", ",", "\"char_inputs\"", ",", "False", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "kdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "vdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.prepare_for_onnx_export_": [[462, 464], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.forward": [[465, 560], ["isinstance", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.buffered_future_mask", "layers.TransformerDecoderLayer.self_attn._set_input_buffer", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.encoder_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.fc1", "layers.TransformerDecoderLayer.encoder_attn._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (Tuple):\n                input[0] (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n                input[1] (Tensor): encoder output of shape `(batch, src_len, embed_dim)`\n                input[2] (ByteTensor/FloatTensor): encoder padding mask -\n                    binary ByteTensor of shape `(batch, src_len)` where padding elements\n                    are indicated by ``1``.\n        Returns:\n            output (Tuple):\n                output[0] (Tensor): encoded output of shape `(batch, src_len, embed_dim)`\n                output[1] (ByteTensor/FloatTensor): encoder padding mask\n                output[2] (LongTensor): previous decoder outputs\n        \"\"\"", "\n", "# Note: incremental state is not yet supported", "\n", "mt_task", "=", "False", "\n", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "input", "[", "0", "]", "\n", "encoder_out", "=", "input", "[", "1", "]", "\n", "encoder_padding_mask", "=", "input", "[", "2", "]", "\n", "incremental_state", "=", "None", "\n", "mt_task", "=", "True", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "if", "incremental_state", "is", "None", ":", "\n", "            ", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "self_attn_mask", "=", "None", "\n", "\n", "# TODO: add back prev_self_attn_state, prev_attn_state,", "\n", "# self_attn_padding_mask", "\n", "", "prev_self_attn_state", "=", "None", "\n", "prev_attn_state", "=", "None", "\n", "self_attn_padding_mask", "=", "None", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "if", "incremental_state", "is", "None", ":", "\n", "                ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_self_attn_state", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "self", ".", "self_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "if", "self", ".", "encoder_attn", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "if", "incremental_state", "is", "None", ":", "\n", "                    ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_attn_state", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "if", "mt_task", ":", "\n", "            ", "return", "(", "x", ",", "encoder_out", ",", "encoder_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.buffered_future_mask": [[561, 576], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "layers.TransformerDecoderLayer._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "fairseq.utils.fill_with_neg_inf", "fairseq.utils.fill_with_neg_inf", "tensor.new", "layers.TransformerDecoderLayer._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.fill_with_neg_inf", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm": [[577, 583], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.TransformerDecoderLayer.make_generation_fast_": [[584, 586], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding": [[588, 593], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear": [[595, 601], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.__init__": [[46, 85], ["fairseq.models.BaseFairseqModel.__init__", "isinstance", "isinstance", "len", "len", "Pipe", "model.PipelineParallelTransformerModel.max_positions_helper", "model.PipelineParallelTransformerModel.max_positions_helper", "getattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "ImportError", "list", "list"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "balance", ",", "devices", ",", "chunks", ",", "checkpoint", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairscale", ".", "nn", "import", "Pipe", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fairscale with: pip install fairscale\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "encoder", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "decoder", ",", "FairseqDecoder", ")", "\n", "encoder_module_list", "=", "(", "\n", "[", "encoder", ".", "embedding_layer", "]", "\n", "+", "list", "(", "encoder", ".", "encoder_layers", ")", "\n", "+", "[", "encoder", ".", "final_layer_norm", "]", "\n", ")", "\n", "self", ".", "num_encoder_modules", "=", "len", "(", "encoder_module_list", ")", "\n", "decoder_module_list", "=", "(", "\n", "[", "decoder", ".", "embedding_layer", "]", "\n", "+", "list", "(", "decoder", ".", "decoder_layers", ")", "\n", "+", "[", "decoder", ".", "decoder_output_layer", "]", "\n", ")", "\n", "self", ".", "num_decoder_modules", "=", "len", "(", "decoder_module_list", ")", "\n", "module_list", "=", "encoder_module_list", "+", "decoder_module_list", "\n", "self", ".", "devices", "=", "devices", "\n", "self", ".", "model", "=", "Pipe", "(", "\n", "nn", ".", "Sequential", "(", "*", "module_list", ")", ",", "\n", "balance", "=", "balance", ",", "\n", "devices", "=", "devices", ",", "\n", "chunks", "=", "chunks", ",", "\n", "checkpoint", "=", "checkpoint", ",", "\n", ")", "\n", "self", ".", "encoder_max_positions", "=", "self", ".", "max_positions_helper", "(", "\n", "encoder", ".", "embedding_layer", ",", "\"max_source_positions\"", "\n", ")", "\n", "self", ".", "decoder_max_positions", "=", "self", ".", "max_positions_helper", "(", "\n", "decoder", ".", "embedding_layer", ",", "\"max_target_positions\"", "\n", ")", "\n", "self", ".", "adaptive_softmax", "=", "getattr", "(", "decoder", ",", "\"adaptive_softmax\"", ",", "None", ")", "\n", "# Note: To be populated during inference", "\n", "self", ".", "encoder", "=", "None", "\n", "self", ".", "decoder", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.forward": [[86, 98], ["tuple", "model.PipelineParallelTransformerModel.model", "model.PipelineParallelTransformerModel.encoder", "model.PipelineParallelTransformerModel.decoder", "i.to"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "input_lst", "=", "[", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", "]", "\n", "input", "=", "tuple", "(", "i", ".", "to", "(", "self", ".", "devices", "[", "0", "]", ",", "non_blocking", "=", "True", ")", "for", "i", "in", "input_lst", ")", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "encoder", "is", "not", "None", "and", "self", ".", "decoder", "is", "not", "None", ",", "(", "\n", "\"encoder and decoder need to be initialized by \"", "\n", "+", "\"calling the `prepare_for_inference_()` method\"", "\n", ")", "\n", "encoder_output_tuple", "=", "self", ".", "encoder", "(", "input", ")", "\n", "return", "self", ".", "decoder", "(", "encoder_output_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_": [[99, 117], ["model.TransformerEncoder", "model.TransformerDecoder", "logger.info", "encoder_module_list.append", "decoder_module_list.append"], "methods", ["None"], ["", "", "def", "prepare_for_inference_", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "self", ".", "encoder", "is", "not", "None", "and", "self", ".", "decoder", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Encoder and Decoder already initialized\"", ")", "\n", "return", "\n", "", "encoder_module_list", "=", "[", "]", "\n", "decoder_module_list", "=", "[", "]", "\n", "module_count", "=", "0", "\n", "for", "partition", "in", "self", ".", "model", ".", "partitions", ":", "\n", "            ", "for", "module", "in", "partition", ":", "\n", "                ", "if", "module_count", "<", "self", ".", "num_encoder_modules", ":", "\n", "                    ", "encoder_module_list", ".", "append", "(", "module", ")", "\n", "", "else", ":", "\n", "                    ", "decoder_module_list", ".", "append", "(", "module", ")", "\n", "", "module_count", "+=", "1", "\n", "", "", "self", ".", "model", "=", "None", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "cfg", ".", "distributed_training", ",", "None", ",", "None", ",", "encoder_module_list", ")", "\n", "self", ".", "decoder", "=", "TransformerDecoder", "(", "\n", "cfg", ".", "distributed_training", ",", "None", ",", "None", ",", "decoder_module_list", "=", "decoder_module_list", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.add_args": [[119, 174], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_available_activation_fns"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--activation-fn'", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each encoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the decoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each decoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-all-embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share encoder, decoder and output embeddings'", "\n", "' (requires shared dictionary and embed dim)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-token-positional-embeddings'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, disables positional embeddings (outside self attention)'", ")", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-cutoff'", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'comma separated list of adaptive softmax cutoff points. '", "\n", "'Must be used with adaptive_loss criterion'", ")", ",", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'sets adaptive softmax dropout for the tail projections'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-embedding-chunks'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of embedding layer chunks (enables more even distribution'", "\n", "'of optimizer states across data parallel nodes'", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model_base": [[179, 259], ["fairseq.models.transformer.base_architecture", "cls.build_encoder", "cls.build_decoder", "hasattr", "hasattr", "len", "dictionary.pad", "model.PipelineParallelTransformerModel.build_model_base.build_embedding"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.base_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.transformer.ModelParallelTransformerModel.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model_base", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_source_positions\"", ")", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "DEFAULT_MAX_SOURCE_POSITIONS", "\n", "", "if", "not", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "DEFAULT_MAX_TARGET_POSITIONS", "\n", "\n", "", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ",", "num_embed_chunks", "=", "1", ")", ":", "\n", "            ", "assert", "embed_dim", "%", "num_embed_chunks", "==", "0", ",", "(", "\n", "f\"Number of embedding chunks = {num_embed_chunks} should be \"", "\n", "+", "f\"divisible by the embedding dimension = {embed_dim}\"", "\n", ")", "\n", "assert", "path", "is", "None", "or", "num_embed_chunks", "==", "1", ",", "(", "\n", "\"Loading embedding from a path with number of embedding chunks > 1\"", "\n", "+", "\" is not yet supported\"", "\n", ")", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "                ", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "else", ":", "\n", "                ", "embed_chunk_dim", "=", "embed_dim", "//", "num_embed_chunks", "\n", "emb", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_embed_chunks", ")", ":", "\n", "                    ", "emb", ".", "append", "(", "Embedding", "(", "num_embeddings", ",", "embed_chunk_dim", ",", "padding_idx", ")", ")", "\n", "", "", "return", "emb", "\n", "\n", "", "num_embed_chunks", "=", "args", ".", "num_embedding_chunks", "\n", "if", "args", ".", "share_all_embeddings", ":", "\n", "            ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "                ", "raise", "ValueError", "(", "\"--share-all-embeddings requires a joined dictionary\"", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to match --decoder-embed-dim\"", "\n", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "args", ".", "encoder_embed_path", ",", "\n", "num_embed_chunks", ",", "\n", ")", "\n", "decoder_embed_tokens", "=", "encoder_embed_tokens", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "            ", "assert", "args", ".", "share_decoder_input_output_embed", "or", "num_embed_chunks", "==", "1", ",", "(", "\n", "\"Not sharing decoder I/O embeddings is not yet supported with number of \"", "\n", "+", "\"embedding chunks > 1\"", "\n", ")", "\n", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "args", ".", "encoder_embed_path", ",", "\n", "num_embed_chunks", ",", "\n", ")", "\n", "decoder_embed_tokens", "=", "build_embedding", "(", "\n", "tgt_dict", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "args", ".", "decoder_embed_path", ",", "\n", "num_embed_chunks", ",", "\n", ")", "\n", "\n", "", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ",", "src_dict", ",", "encoder_embed_tokens", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "tgt_dict", ",", "decoder_embed_tokens", ")", "\n", "return", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder": [[260, 263], ["model.TransformerEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerEncoder", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder": [[264, 267], ["model.TransformerDecoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model": [[268, 278], ["cls.build_model_base", "model.PipelineParallelTransformerModel", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model_base", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "cls", ".", "build_model_base", "(", "args", ",", "task", ")", "\n", "return", "PipelineParallelTransformerModel", "(", "\n", "encoder", "=", "encoder", ",", "\n", "decoder", "=", "decoder", ",", "\n", "balance", "=", "utils", ".", "eval_str_list", "(", "args", ".", "pipeline_balance", ",", "type", "=", "int", ")", ",", "\n", "devices", "=", "utils", ".", "eval_str_list", "(", "args", ".", "pipeline_devices", ",", "type", "=", "int", ")", ",", "\n", "chunks", "=", "args", ".", "pipeline_chunks", ",", "\n", "checkpoint", "=", "args", ".", "pipeline_checkpoint", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.output_layer": [[280, 283], ["model.PipelineParallelTransformerModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions": [[284, 287], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "(", "self", ".", "encoder_max_positions", ",", "self", ".", "decoder_max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper": [[288, 297], ["min", "getattr", "getattr"], "methods", ["None"], ["", "def", "max_positions_helper", "(", "\n", "self", ",", "embedding_layer", ",", "max_positions_field", "=", "\"max_source_positions\"", "\n", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder or decoder.\"\"\"", "\n", "if", "embedding_layer", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "getattr", "(", "embedding_layer", ",", "max_positions_field", ")", "\n", "", "return", "min", "(", "\n", "getattr", "(", "embedding_layer", ",", "max_positions_field", ")", ",", "\n", "embedding_layer", ".", "embed_positions", ".", "max_positions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs": [[299, 318], ["hasattr", "model.PipelineParallelTransformerModel.adaptive_softmax.get_log_prob", "isinstance", "fairseq.utils.log_softmax", "fairseq.utils.softmax", "model.PipelineParallelTransformerModel.exp_"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"adaptive_softmax\"", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "if", "sample", "is", "not", "None", ":", "\n", "                ", "assert", "\"target\"", "in", "sample", "\n", "target", "=", "sample", "[", "\"target\"", "]", "\n", "", "else", ":", "\n", "                ", "target", "=", "None", "\n", "", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "net_output", ",", "target", "=", "target", ")", "\n", "return", "out", ".", "exp_", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "# A Pipe() module returns a tuple of tensors as the output.", "\n", "# In this case, the tuple has one element - the output tensor of logits", "\n", "", "logits", "=", "net_output", "if", "isinstance", "(", "net_output", ",", "torch", ".", "Tensor", ")", "else", "net_output", "[", "0", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions": [[319, 322], ["None"], "methods", ["None"], ["", "", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder_max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.load_state_dict": [[323, 335], ["model.PipelineParallelTransformerModel.upgrade_state_dict", "super().load_state_dict", "any", "model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.composite_encoder.CompositeEncoder.upgrade_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ",", "model_cfg", "=", "None", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "is_regular_transformer", "=", "not", "any", "(", "\"model.partitions\"", "in", "k", "for", "k", "in", "state_dict", ")", "\n", "if", "is_regular_transformer", ":", "\n", "            ", "state_dict", "=", "self", ".", "convert_to_pipeline_parallel_state_dict", "(", "state_dict", ")", "\n", "", "return", "super", "(", ")", ".", "load_state_dict", "(", "state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict": [[336, 412], ["model.PipelineParallelTransformerModel.state_dict", "enumerate", "logger.info", "enumerate", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "convert_to_pipeline_parallel_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "new_state_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "encoder_layer_idx", "=", "0", "\n", "decoder_layer_idx", "=", "0", "\n", "encoder_key_suffixes", "=", "[", "\n", "\"self_attn.k_proj.weight\"", ",", "\n", "\"self_attn.k_proj.bias\"", ",", "\n", "\"self_attn.v_proj.weight\"", ",", "\n", "\"self_attn.v_proj.bias\"", ",", "\n", "\"self_attn.q_proj.weight\"", ",", "\n", "\"self_attn.q_proj.bias\"", ",", "\n", "\"self_attn.out_proj.weight\"", ",", "\n", "\"self_attn.out_proj.bias\"", ",", "\n", "\"self_attn_layer_norm.weight\"", ",", "\n", "\"self_attn_layer_norm.bias\"", ",", "\n", "\"fc1.weight\"", ",", "\n", "\"fc1.bias\"", ",", "\n", "\"fc2.weight\"", ",", "\n", "\"fc2.bias\"", ",", "\n", "\"final_layer_norm.weight\"", ",", "\n", "\"final_layer_norm.bias\"", ",", "\n", "]", "\n", "decoder_key_suffixes", "=", "[", "\n", "\"self_attn.k_proj.weight\"", ",", "\n", "\"self_attn.k_proj.bias\"", ",", "\n", "\"self_attn.v_proj.weight\"", ",", "\n", "\"self_attn.v_proj.bias\"", ",", "\n", "\"self_attn.q_proj.weight\"", ",", "\n", "\"self_attn.q_proj.bias\"", ",", "\n", "\"self_attn.out_proj.weight\"", ",", "\n", "\"self_attn.out_proj.bias\"", ",", "\n", "\"self_attn_layer_norm.weight\"", ",", "\n", "\"self_attn_layer_norm.bias\"", ",", "\n", "\"encoder_attn.k_proj.weight\"", ",", "\n", "\"encoder_attn.k_proj.bias\"", ",", "\n", "\"encoder_attn.v_proj.weight\"", ",", "\n", "\"encoder_attn.v_proj.bias\"", ",", "\n", "\"encoder_attn.q_proj.weight\"", ",", "\n", "\"encoder_attn.q_proj.bias\"", ",", "\n", "\"encoder_attn.out_proj.weight\"", ",", "\n", "\"encoder_attn.out_proj.bias\"", ",", "\n", "\"encoder_attn_layer_norm.weight\"", ",", "\n", "\"encoder_attn_layer_norm.bias\"", ",", "\n", "\"fc1.weight\"", ",", "\n", "\"fc1.bias\"", ",", "\n", "\"fc2.weight\"", ",", "\n", "\"fc2.bias\"", ",", "\n", "\"final_layer_norm.weight\"", ",", "\n", "\"final_layer_norm.bias\"", ",", "\n", "]", "\n", "for", "pid", ",", "partition", "in", "enumerate", "(", "self", ".", "model", ".", "partitions", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Begin Partition {pid}\"", ")", "\n", "for", "mid", ",", "module", "in", "enumerate", "(", "partition", ")", ":", "\n", "# fmt: off", "\n", "                ", "if", "isinstance", "(", "module", ",", "TransformerEncoderEmbedding", ")", ":", "\n", "                    ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.embed_tokens.weight'", "]", "=", "state_dict", "[", "'encoder.embed_tokens.weight'", "]", "\n", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.embed_positions._float_tensor'", "]", "=", "state_dict", "[", "'encoder.embed_positions._float_tensor'", "]", "\n", "", "if", "isinstance", "(", "module", ",", "TransformerEncoderLayer", ")", ":", "\n", "                    ", "for", "suffix", "in", "encoder_key_suffixes", ":", "\n", "                        ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.{suffix}'", "]", "=", "state_dict", "[", "f'encoder.layers.{encoder_layer_idx}.{suffix}'", "]", "\n", "", "encoder_layer_idx", "+=", "1", "\n", "", "if", "isinstance", "(", "module", ",", "TransformerDecoderLayer", ")", ":", "\n", "                    ", "for", "suffix", "in", "decoder_key_suffixes", ":", "\n", "                        ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.{suffix}'", "]", "=", "state_dict", "[", "f'decoder.layers.{decoder_layer_idx}.{suffix}'", "]", "\n", "", "decoder_layer_idx", "+=", "1", "\n", "", "if", "isinstance", "(", "module", ",", "TransformerEncoderLayerNorm", ")", ":", "\n", "                    ", "if", "'encoder.layer_norm.weight'", "in", "state_dict", ":", "\n", "                        ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.layer_norm.weight'", "]", "=", "state_dict", "[", "'encoder.layer_norm.weight'", "]", "\n", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.layer_norm.bias'", "]", "=", "state_dict", "[", "'encoder.layer_norm.bias'", "]", "\n", "", "", "if", "isinstance", "(", "module", ",", "TransformerDecoderEmbedding", ")", ":", "\n", "                    ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.embed_tokens.weight'", "]", "=", "state_dict", "[", "'decoder.embed_tokens.weight'", "]", "\n", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.embed_positions._float_tensor'", "]", "=", "state_dict", "[", "'decoder.embed_positions._float_tensor'", "]", "\n", "", "if", "isinstance", "(", "module", ",", "TransformerDecoderOutputLayer", ")", ":", "\n", "                    ", "new_state_dict", "[", "f'model.partitions.{pid}.{mid}.output_projection.weight'", "]", "=", "state_dict", "[", "'decoder.output_projection.weight'", "]", "\n", "# fmt: on", "\n", "", "", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.__init__": [[425, 458], ["fairseq.models.FairseqEncoder.__init__", "model.TransformerEncoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "isinstance", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "Pipe", "ImportError", "sum", "sum", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderLayer", "len", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "encoder_module_list", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "3", "]", ")", ")", "\n", "try", ":", "\n", "            ", "from", "fairscale", ".", "nn", "import", "Pipe", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fairscale with: pip install fairscale\"", ")", "\n", "", "self", ".", "use_pipeline", "=", "encoder_module_list", "is", "not", "None", "\n", "if", "not", "self", ".", "use_pipeline", ":", "\n", "            ", "self", ".", "embedding_layer", "=", "TransformerEncoderEmbedding", "(", "args", ",", "embed_tokens", ")", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "Sequential", "(", "*", "[", "TransformerEncoderLayer", "(", "args", ")", "for", "i", "in", "range", "(", "args", ".", "encoder_layers", ")", "]", ")", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "                ", "emb_dim", "=", "sum", "(", "e", ".", "embedding_dim", "for", "e", "in", "embed_tokens", ")", "\n", "", "else", ":", "\n", "                ", "emb_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "", "self", ".", "final_layer_norm", "=", "TransformerEncoderLayerNorm", "(", "args", ",", "emb_dim", ")", "\n", "", "else", ":", "\n", "            ", "encoder_balance", "=", "utils", ".", "eval_str_list", "(", "\n", "args", ".", "pipeline_encoder_balance", ",", "type", "=", "int", "\n", ")", "\n", "encoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "args", ".", "pipeline_encoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "assert", "sum", "(", "encoder_balance", ")", "==", "len", "(", "encoder_module_list", ")", ",", "(", "\n", "f\"Sum of encoder_balance={encoder_balance} is not equal \"", "\n", "+", "f\"to num_encoder_modules={len(encoder_module_list)}\"", "\n", ")", "\n", "self", ".", "model", "=", "Pipe", "(", "\n", "module", "=", "nn", ".", "Sequential", "(", "*", "encoder_module_list", ")", ",", "\n", "balance", "=", "encoder_balance", ",", "\n", "devices", "=", "encoder_devices", ",", "\n", "chunks", "=", "args", ".", "pipeline_chunks", ",", "\n", "checkpoint", "=", "args", ".", "pipeline_checkpoint", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.forward": [[460, 498], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "fairseq.models.fairseq_encoder.EncoderOut", "tuple", "model.TransformerEncoder.model", "model.TransformerEncoder.embedding_layer", "model.TransformerEncoder.encoder_layers", "model.TransformerEncoder.final_layer_norm", "i.to"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_tuple(\n                src_tokens (LongTensor): tokens in the source language of shape\n                    `(batch, src_len)`\n                src_lengths (torch.LongTensor): lengths of each source sentence of\n                    shape `(batch)`\n            )\n\n        Returns:\n            output_tuple(\n                - **encoder_out** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n                - **encoder_padding_mask** (ByteTensor): the positions of\n                  padding elements of shape `(batch, src_len)`\n                - prev_output_tokens\n                - **encoder_states** (List[Tensor]): all intermediate\n                  hidden states of shape `(src_len, batch, embed_dim)`.\n                  Only populated if *return_all_hiddens* is True.\n            )\n        \"\"\"", "\n", "dummy_prev_output_tokens", "=", "torch", ".", "zeros", "(", "\n", "1", ",", "dtype", "=", "src_tokens", ".", "dtype", ",", "device", "=", "src_tokens", ".", "device", "\n", ")", "\n", "input_tuple", "=", "(", "src_tokens", ",", "src_lengths", ",", "dummy_prev_output_tokens", ")", "\n", "if", "self", ".", "use_pipeline", ":", "\n", "            ", "input_tuple", "=", "tuple", "(", "i", ".", "to", "(", "self", ".", "model", ".", "devices", "[", "0", "]", ")", "for", "i", "in", "input_tuple", ")", "\n", "encoder_out", "=", "self", ".", "model", "(", "input_tuple", ")", "\n", "", "else", ":", "\n", "            ", "encoder_embed_output_tuple", "=", "self", ".", "embedding_layer", "(", "input_tuple", ")", "\n", "encoder_layers_output", "=", "self", ".", "encoder_layers", "(", "encoder_embed_output_tuple", ")", "\n", "encoder_out", "=", "self", ".", "final_layer_norm", "(", "encoder_layers_output", ")", "\n", "# first element is the encoder output", "\n", "# second element is the encoder padding mask", "\n", "# the remaining elements of EncoderOut are not computed by", "\n", "# the PipelineParallelTransformer", "\n", "", "return", "EncoderOut", "(", "encoder_out", "[", "0", "]", ",", "encoder_out", "[", "1", "]", ",", "None", ",", "None", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out": [[499, 530], ["encoder_out._replace._replace._replace", "encoder_out._replace._replace._replace", "encoder_out._replace._replace._replace", "enumerate", "state.index_select", "encoder_out._replace._replace.encoder_out.index_select", "encoder_out._replace._replace.encoder_padding_mask.index_select", "encoder_out._replace._replace.encoder_embedding.index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "if", "encoder_out", ".", "encoder_out", "is", "not", "None", ":", "\n", "            ", "encoder_out", "=", "encoder_out", ".", "_replace", "(", "\n", "encoder_out", "=", "encoder_out", ".", "encoder_out", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", ")", "\n", "", "if", "encoder_out", ".", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "encoder_out", "=", "encoder_out", ".", "_replace", "(", "\n", "encoder_padding_mask", "=", "encoder_out", ".", "encoder_padding_mask", ".", "index_select", "(", "\n", "0", ",", "new_order", "\n", ")", "\n", ")", "\n", "", "if", "encoder_out", ".", "encoder_embedding", "is", "not", "None", ":", "\n", "            ", "encoder_out", "=", "encoder_out", ".", "_replace", "(", "\n", "encoder_embedding", "=", "encoder_out", ".", "encoder_embedding", ".", "index_select", "(", "\n", "0", ",", "new_order", "\n", ")", "\n", ")", "\n", "", "if", "encoder_out", ".", "encoder_states", "is", "not", "None", ":", "\n", "            ", "for", "idx", ",", "state", "in", "enumerate", "(", "encoder_out", ".", "encoder_states", ")", ":", "\n", "                ", "encoder_out", ".", "encoder_states", "[", "idx", "]", "=", "state", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerEncoder.max_positions": [[531, 538], ["min"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "if", "self", ".", "embedding_layer", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "embedding_layer", ".", "max_source_positions", "\n", "", "return", "min", "(", "\n", "self", ".", "embedding_layer", ".", "max_source_positions", ",", "\n", "self", ".", "embedding_layer", ".", "embed_positions", ".", "max_positions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.__init__": [[554, 595], ["fairseq.models.FairseqDecoder.__init__", "model.TransformerDecoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "Pipe", "ImportError", "sum", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderLayer", "len", "range"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.eval_str_list"], ["def", "__init__", "(", "\n", "self", ",", "\n", "args", ",", "\n", "dictionary", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "False", ",", "\n", "decoder_module_list", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "3", "]", ")", ")", "\n", "try", ":", "\n", "            ", "from", "fairscale", ".", "nn", "import", "Pipe", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fairscale with: pip install fairscale\"", ")", "\n", "", "self", ".", "use_pipeline", "=", "decoder_module_list", "is", "not", "None", "\n", "if", "not", "self", ".", "use_pipeline", ":", "\n", "            ", "self", ".", "embedding_layer", "=", "TransformerDecoderEmbedding", "(", "args", ",", "embed_tokens", ")", "\n", "self", ".", "decoder_layers", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "decoder_layers", ")", "\n", "]", ")", "\n", "self", ".", "decoder_output_layer", "=", "TransformerDecoderOutputLayer", "(", "\n", "args", ",", "embed_tokens", ",", "dictionary", "\n", ")", "\n", "", "else", ":", "\n", "            ", "decoder_balance", "=", "utils", ".", "eval_str_list", "(", "\n", "args", ".", "pipeline_decoder_balance", ",", "type", "=", "int", "\n", ")", "\n", "decoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "args", ".", "pipeline_decoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "assert", "sum", "(", "decoder_balance", ")", "==", "len", "(", "decoder_module_list", ")", ",", "(", "\n", "f\"Sum of decoder_balance={decoder_balance} is not equal \"", "\n", "+", "f\"to num_decoder_modules={len(decoder_module_list)}\"", "\n", ")", "\n", "self", ".", "model", "=", "Pipe", "(", "\n", "module", "=", "nn", ".", "Sequential", "(", "*", "decoder_module_list", ")", ",", "\n", "balance", "=", "decoder_balance", ",", "\n", "devices", "=", "decoder_devices", ",", "\n", "chunks", "=", "args", ".", "pipeline_chunks", ",", "\n", "checkpoint", "=", "args", ".", "pipeline_checkpoint", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.forward": [[597, 630], ["tuple", "model.TransformerDecoder.embedding_layer", "model.TransformerDecoder.decoder_layers", "model.TransformerDecoder.model", "model.TransformerDecoder.decoder_output_layer", "i.to"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n            features_only (bool, optional): only return features without\n                applying output layer (default: False).\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "input_tuple", "=", "(", "\n", "encoder_out", ".", "encoder_out", ",", "\n", "encoder_out", ".", "encoder_padding_mask", ",", "\n", "prev_output_tokens", ",", "\n", ")", "\n", "if", "self", ".", "use_pipeline", ":", "\n", "            ", "input_tuple", "=", "tuple", "(", "i", ".", "to", "(", "self", ".", "model", ".", "devices", "[", "0", "]", ")", "for", "i", "in", "input_tuple", ")", "\n", "return", "(", "self", ".", "model", "(", "input_tuple", ")", ",", ")", "\n", "", "else", ":", "\n", "            ", "embed_layer_output", "=", "self", ".", "embedding_layer", "(", "input_tuple", ")", "\n", "state", "=", "self", ".", "decoder_layers", "(", "embed_layer_output", ")", "\n", "return", "(", "self", ".", "decoder_output_layer", "(", "state", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.output_layer": [[631, 641], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_out", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.max_positions": [[642, 649], ["min"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embedding_layer", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "embedding_layer", ".", "max_target_positions", "\n", "", "return", "min", "(", "\n", "self", ".", "embedding_layer", ".", "max_target_positions", ",", "\n", "self", ".", "embedding_layer", ".", "embed_positions", ".", "max_positions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask": [[651, 663], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "model.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "tensor.new"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", "or", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named": [[664, 698], ["isinstance", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "layer_norm_map.items", "fairseq.utils.item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "embed_positions", ",", "SinusoidalPositionalEmbedding", ")", ":", "\n", "            ", "weights_key", "=", "\"{}.embed_positions.weights\"", ".", "format", "(", "name", ")", "\n", "if", "weights_key", "in", "state_dict", ":", "\n", "                ", "del", "state_dict", "[", "weights_key", "]", "\n", "", "state_dict", "[", "\n", "\"{}.embed_positions._float_tensor\"", ".", "format", "(", "name", ")", "\n", "]", "=", "torch", ".", "FloatTensor", "(", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "# update layer norms", "\n", "            ", "layer_norm_map", "=", "{", "\n", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\n", "\"1\"", ":", "\"encoder_attn_layer_norm\"", ",", "\n", "\"2\"", ":", "\"final_layer_norm\"", ",", "\n", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "                ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                    ", "k", "=", "\"{}.layers.{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "i", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                        ", "state_dict", "[", "\n", "\"{}.layers.{}.{}.{}\"", ".", "format", "(", "name", ",", "i", ",", "new", ",", "m", ")", "\n", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "", "", "", "version_key", "=", "\"{}.version\"", ".", "format", "(", "name", ")", "\n", "if", "utils", ".", "item", "(", "state_dict", ".", "get", "(", "version_key", ",", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ")", "[", "0", "]", ")", "<=", "2", ":", "\n", "# earlier checkpoints did not normalize after the stack of layers", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "self", ".", "normalize", "=", "False", "\n", "state_dict", "[", "version_key", "]", "=", "torch", ".", "Tensor", "(", "[", "1", "]", ")", "\n", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.transformer_iwslt_de_en_dist": [[700, 705], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.transformer_iwslt_de_en"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\n", "\"pipeline_parallel_transformer\"", ",", "\"transformer_iwslt_de_en_pipeline_parallel\"", "\n", ")", "\n", "def", "transformer_iwslt_de_en_dist", "(", "args", ")", ":", "\n", "    ", "transformer_iwslt_de_en", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.transformer_wmt_en_de_big_dist": [[707, 712], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.transformer_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"pipeline_parallel_transformer\"", ",", "\"transformer_wmt_en_de_big_pipeline_parallel\"", "\n", ")", "\n", "def", "transformer_wmt_en_de_big_dist", "(", "args", ")", ":", "\n", "    ", "transformer_wmt_en_de_big", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.__init__": [[44, 48], ["fairseq.models.roberta.RobertaModel.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["@", "register_model", "(", "\"pipeline_parallel_transformer\"", ")", "\n", "class", "PipelineParallelTransformerModel", "(", "BaseFairseqModel", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "balance", ",", "devices", ",", "chunks", ",", "checkpoint", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairscale", ".", "nn", "import", "Pipe", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.add_args": [[49, 52], ["super().add_args"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args"], ["", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fairscale with: pip install fairscale\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "encoder", ",", "FairseqEncoder", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.build_model": [[53, 73], ["model.base_architecture", "task.source_dictionary.pad_to_multiple_", "task.target_dictionary.pad_to_multiple_", "getattr", "model.ModelParallelRobertaEncoder", "cls", "hasattr", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.base_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_"], ["assert", "isinstance", "(", "decoder", ",", "FairseqDecoder", ")", "\n", "encoder_module_list", "=", "(", "\n", "[", "encoder", ".", "embedding_layer", "]", "\n", "+", "list", "(", "encoder", ".", "encoder_layers", ")", "\n", "+", "[", "encoder", ".", "final_layer_norm", "]", "\n", ")", "\n", "self", ".", "num_encoder_modules", "=", "len", "(", "encoder_module_list", ")", "\n", "decoder_module_list", "=", "(", "\n", "[", "decoder", ".", "embedding_layer", "]", "\n", "+", "list", "(", "decoder", ".", "decoder_layers", ")", "\n", "+", "[", "decoder", ".", "decoder_output_layer", "]", "\n", ")", "\n", "self", ".", "num_decoder_modules", "=", "len", "(", "decoder_module_list", ")", "\n", "module_list", "=", "encoder_module_list", "+", "decoder_module_list", "\n", "self", ".", "devices", "=", "devices", "\n", "self", ".", "model", "=", "Pipe", "(", "\n", "nn", ".", "Sequential", "(", "*", "module_list", ")", ",", "\n", "balance", "=", "balance", ",", "\n", "devices", "=", "devices", ",", "\n", "chunks", "=", "chunks", ",", "\n", "checkpoint", "=", "checkpoint", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.forward": [[74, 90], ["model.ModelParallelRobertaModel.encoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.FairseqMultiModel.encoder"], [")", "\n", "self", ".", "encoder_max_positions", "=", "self", ".", "max_positions_helper", "(", "\n", "encoder", ".", "embedding_layer", ",", "\"max_source_positions\"", "\n", ")", "\n", "self", ".", "decoder_max_positions", "=", "self", ".", "max_positions_helper", "(", "\n", "decoder", ".", "embedding_layer", ",", "\"max_target_positions\"", "\n", ")", "\n", "self", ".", "adaptive_softmax", "=", "getattr", "(", "decoder", ",", "\"adaptive_softmax\"", ",", "None", ")", "\n", "# Note: To be populated during inference", "\n", "self", ".", "encoder", "=", "None", "\n", "self", ".", "decoder", "=", "None", "\n", "\n", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "input_lst", "=", "[", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", "]", "\n", "input", "=", "tuple", "(", "i", ".", "to", "(", "self", ".", "devices", "[", "0", "]", ",", "non_blocking", "=", "True", ")", "for", "i", "in", "input_lst", ")", "\n", "return", "self", ".", "model", "(", "input", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaModel.register_classification_head": [[91, 111], ["model.ModelParallelRobertaClassificationHead", "logger.warning"], "methods", ["None"], ["", "else", ":", "\n", "            ", "assert", "self", ".", "encoder", "is", "not", "None", "and", "self", ".", "decoder", "is", "not", "None", ",", "(", "\n", "\"encoder and decoder need to be initialized by \"", "\n", "+", "\"calling the `prepare_for_inference_()` method\"", "\n", ")", "\n", "encoder_output_tuple", "=", "self", ".", "encoder", "(", "input", ")", "\n", "return", "self", ".", "decoder", "(", "encoder_output_tuple", ")", "\n", "\n", "", "", "def", "prepare_for_inference_", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "self", ".", "encoder", "is", "not", "None", "and", "self", ".", "decoder", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Encoder and Decoder already initialized\"", ")", "\n", "return", "\n", "", "encoder_module_list", "=", "[", "]", "\n", "decoder_module_list", "=", "[", "]", "\n", "module_count", "=", "0", "\n", "for", "partition", "in", "self", ".", "model", ".", "partitions", ":", "\n", "            ", "for", "module", "in", "partition", ":", "\n", "                ", "if", "module_count", "<", "self", ".", "num_encoder_modules", ":", "\n", "                    ", "encoder_module_list", ".", "append", "(", "module", ")", "\n", "", "else", ":", "\n", "                    ", "decoder_module_list", ".", "append", "(", "module", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaLMHead.__init__": [[117, 127], ["torch.Module.__init__", "ColumnParallelLinear", "fairseq.utils.get_activation_fn", "fairseq.modules.LayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], [")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--activation-fn'", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaLMHead.forward": [[128, 144], ["model.ModelParallelRobertaLMHead.dense", "model.ModelParallelRobertaLMHead.activation_fn", "model.ModelParallelRobertaLMHead.layer_norm", "copy_to_model_parallel_region", "torch.linear", "torch.linear", "torch.linear", "gather_from_model_parallel_region().contiguous", "gather_from_model_parallel_region"], "methods", ["None"], ["parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each encoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaClassificationHead.__init__": [[149, 157], ["torch.Module.__init__", "ColumnParallelLinear", "fairseq.utils.get_activation_fn", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.layers.Linear"], ["help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the decoder'", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaClassificationHead.forward": [[158, 166], ["model.ModelParallelRobertaClassificationHead.dropout", "model.ModelParallelRobertaClassificationHead.dense", "model.ModelParallelRobertaClassificationHead.activation_fn", "model.ModelParallelRobertaClassificationHead.dropout", "model.ModelParallelRobertaClassificationHead.out_proj"], "methods", ["None"], ["parser", ".", "add_argument", "(", "'--decoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each decoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-all-embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share encoder, decoder and output embeddings'", "\n", "' (requires shared dictionary and embed dim)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-token-positional-embeddings'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, disables positional embeddings (outside self attention)'", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.__init__": [[175, 209], ["fairseq.models.FairseqEncoder.__init__", "fairseq.model_parallel.modules.ModelParallelTransformerSentenceEncoder", "model.ModelParallelRobertaLMHead", "len", "args.encoder_layers_to_keep.split", "dictionary.pad", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["'when using optimizer state sharding and'", "\n", "'a big embedding vocabulary)'", ")", "\n", "# fmt: on", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_model_base", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_source_positions\"", ")", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "DEFAULT_MAX_SOURCE_POSITIONS", "\n", "", "if", "not", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "DEFAULT_MAX_TARGET_POSITIONS", "\n", "\n", "", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ",", "num_embed_chunks", "=", "1", ")", ":", "\n", "            ", "assert", "embed_dim", "%", "num_embed_chunks", "==", "0", ",", "(", "\n", "f\"Number of embedding chunks = {num_embed_chunks} should be \"", "\n", "+", "f\"divisible by the embedding dimension = {embed_dim}\"", "\n", ")", "\n", "assert", "path", "is", "None", "or", "num_embed_chunks", "==", "1", ",", "(", "\n", "\"Loading embedding from a path with number of embedding chunks > 1\"", "\n", "+", "\" is not yet supported\"", "\n", ")", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "                ", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.forward": [[211, 241], ["model.ModelParallelRobertaEncoder.extract_features", "model.ModelParallelRobertaEncoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer"], ["emb", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_embed_chunks", ")", ":", "\n", "                    ", "emb", ".", "append", "(", "Embedding", "(", "num_embeddings", ",", "embed_chunk_dim", ",", "padding_idx", ")", ")", "\n", "", "", "return", "emb", "\n", "\n", "", "num_embed_chunks", "=", "args", ".", "num_embedding_chunks", "\n", "if", "args", ".", "share_all_embeddings", ":", "\n", "            ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "                ", "raise", "ValueError", "(", "\"--share-all-embeddings requires a joined dictionary\"", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to match --decoder-embed-dim\"", "\n", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "args", ".", "encoder_embed_path", ",", "\n", "num_embed_chunks", ",", "\n", ")", "\n", "decoder_embed_tokens", "=", "encoder_embed_tokens", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "            ", "assert", "args", ".", "share_decoder_input_output_embed", "or", "num_embed_chunks", "==", "1", ",", "(", "\n", "\"Not sharing decoder I/O embeddings is not yet supported with number of \"", "\n", "+", "\"embedding chunks > 1\"", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.extract_features": [[242, 249], ["model.ModelParallelRobertaEncoder.sentence_encoder", "inner_states[].transpose"], "methods", ["None"], [")", "\n", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "args", ".", "encoder_embed_path", ",", "\n", "num_embed_chunks", ",", "\n", ")", "\n", "decoder_embed_tokens", "=", "build_embedding", "(", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.output_layer": [[250, 252], ["model.ModelParallelRobertaEncoder.lm_head"], "methods", ["None"], ["tgt_dict", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "args", ".", "decoder_embed_path", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.ModelParallelRobertaEncoder.max_positions": [[253, 256], ["None"], "methods", ["None"], ["num_embed_chunks", ",", "\n", ")", "\n", "\n", "", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ",", "src_dict", ",", "encoder_embed_tokens", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.base_architecture": [[258, 274], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture"], ["return", "(", "encoder", ",", "decoder", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerEncoder", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "cls", ".", "build_model_base", "(", "args", ",", "task", ")", "\n", "return", "PipelineParallelTransformerModel", "(", "\n", "encoder", "=", "encoder", ",", "\n", "decoder", "=", "decoder", ",", "\n", "balance", "=", "utils", ".", "eval_str_list", "(", "args", ".", "pipeline_balance", ",", "type", "=", "int", ")", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.roberta_base_architecture": [[276, 279], ["fairseq.models.register_model_architecture", "model.base_architecture"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.base_architecture"], ["chunks", "=", "args", ".", "pipeline_chunks", ",", "\n", "checkpoint", "=", "args", ".", "pipeline_checkpoint", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.roberta_large_architecture": [[281, 288], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "model.base_architecture"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.roberta.model.base_architecture"], ["        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "(", "self", ".", "encoder_max_positions", ",", "self", ".", "decoder_max_positions", ")", "\n", "\n", "", "def", "max_positions_helper", "(", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.wav2vec_criterion.Wav2vecCriterion.__init__": [[38, 43], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "infonce", "=", "False", ",", "loss_weights", "=", "None", ",", "log_keys", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "infonce", "=", "infonce", "\n", "self", ".", "loss_weights", "=", "loss_weights", "\n", "self", ".", "log_keys", "=", "[", "]", "if", "log_keys", "is", "None", "else", "log_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.wav2vec_criterion.Wav2vecCriterion.forward": [[44, 137], ["model", "model.get_logits().float", "model.get_targets", "losses.append", "hasattr", "model.get_target_weights", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.cross_entropy", "torch.cross_entropy", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "model.get_targets.numel", "model.get_targets.long().sum().item", "torch.binary_cross_entropy_with_logits.detach().clone", "hasattr", "model.get_extra_losses", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "zip", "sample[].numel", "len", "enumerate", "model.get_logits", "weights.float.float.float", "model.get_targets.float", "len", "len", "torch.binary_cross_entropy_with_logits.item", "l.item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_targets.long().sum", "torch.binary_cross_entropy_with_logits.detach", "len", "len", "len", "len", "len", "losses.append", "model.get_logits().float.cpu().numpy", "model.get_logits().float.numel", "max.numel", "model.get_targets.cpu().numpy", "float", "model.get_logits().float.dim", "model.get_logits().float.argmax", "model.get_logits().float.argmin", "max.long().sum().item", "both.long().sum().item", "model.get_targets.long", "p.float", "model.get_logits().float.cpu", "model.get_targets.cpu", "max.long().sum", "both.long().sum", "max.long", "both.long"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.get_targets", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2.Wav2Vec2Model.get_extra_losses", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr.Wav2VecCtc.get_logits", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "logits", "=", "model", ".", "get_logits", "(", "net_output", ")", ".", "float", "(", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", "\n", "\n", "weights", "=", "None", "\n", "if", "hasattr", "(", "model", ",", "\"get_target_weights\"", ")", "and", "not", "self", ".", "infonce", ":", "\n", "            ", "weights", "=", "model", ".", "get_target_weights", "(", "target", ",", "net_output", ")", "\n", "if", "torch", ".", "is_tensor", "(", "weights", ")", ":", "\n", "                ", "weights", "=", "weights", ".", "float", "(", ")", "\n", "\n", "", "", "losses", "=", "[", "]", "\n", "\n", "if", "self", ".", "infonce", ":", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "logits", ",", "\n", "target", ",", "\n", "reduction", "=", "\"sum\"", "if", "reduce", "else", "\"none\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "logits", ",", "\n", "target", ".", "float", "(", ")", ",", "\n", "weights", ",", "\n", "reduction", "=", "\"sum\"", "if", "reduce", "else", "\"none\"", ",", "\n", ")", "\n", "\n", "", "sample_size", "=", "target", ".", "numel", "(", ")", "if", "self", ".", "infonce", "else", "target", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "clone", "(", ")", ")", "\n", "\n", "if", "self", ".", "loss_weights", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "model", ",", "\"get_extra_losses\"", ")", "\n", "extra_losses", "=", "model", ".", "get_extra_losses", "(", "net_output", ")", "\n", "if", "torch", ".", "is_tensor", "(", "extra_losses", ")", ":", "\n", "                ", "extra_losses", "=", "[", "extra_losses", "]", "\n", "", "if", "len", "(", "self", ".", "loss_weights", ")", "==", "1", "and", "len", "(", "extra_losses", ")", "!=", "1", ":", "\n", "                ", "self", ".", "loss_weights", "=", "[", "self", ".", "loss_weights", "[", "0", "]", "]", "*", "len", "(", "extra_losses", ")", "\n", "", "assert", "len", "(", "extra_losses", ")", "==", "len", "(", "\n", "self", ".", "loss_weights", "\n", ")", ",", "f\"{len(extra_losses)}, {len(self.loss_weights)}\"", "\n", "for", "p", ",", "coef", "in", "zip", "(", "extra_losses", ",", "self", ".", "loss_weights", ")", ":", "\n", "                ", "if", "coef", "!=", "0", "and", "p", "is", "not", "None", ":", "\n", "                    ", "p", "=", "coef", "*", "p", ".", "float", "(", ")", "*", "sample_size", "\n", "loss", "+=", "p", "\n", "losses", ".", "append", "(", "p", ")", "\n", "\n", "", "", "", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "item", "(", ")", "if", "reduce", "else", "loss", ",", "\n", "\"ntokens\"", ":", "sample_size", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "for", "lk", "in", "self", ".", "log_keys", ":", "\n", "# Only store \"logits\" and \"target\" for computing MAP and MAUC", "\n", "# during validation", "\n", "            ", "if", "lk", "==", "\"logits\"", ":", "\n", "                ", "if", "not", "self", ".", "training", ":", "\n", "                    ", "logging_output", "[", "\"logits\"", "]", "=", "logits", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "elif", "lk", "==", "\"target\"", ":", "\n", "                ", "if", "not", "self", ".", "training", ":", "\n", "                    ", "logging_output", "[", "\"target\"", "]", "=", "target", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "elif", "lk", "in", "net_output", ":", "\n", "                ", "logging_output", "[", "lk", "]", "=", "float", "(", "net_output", "[", "lk", "]", ")", "\n", "\n", "", "", "if", "len", "(", "losses", ")", ">", "1", ":", "\n", "            ", "for", "i", ",", "l", "in", "enumerate", "(", "losses", ")", ":", "\n", "                ", "logging_output", "[", "f\"loss_{i}\"", "]", "=", "l", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "infonce", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "logits", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "corr", "=", "0", "\n", "count", "=", "0", "\n", "", "else", ":", "\n", "                    ", "assert", "logits", ".", "dim", "(", ")", ">", "1", ",", "logits", ".", "shape", "\n", "max", "=", "logits", ".", "argmax", "(", "-", "1", ")", "==", "0", "\n", "min", "=", "logits", ".", "argmin", "(", "-", "1", ")", "==", "0", "\n", "both", "=", "max", "&", "min", "\n", "corr", "=", "max", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "-", "both", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "count", "=", "max", ".", "numel", "(", ")", "\n", "\n", "", "logging_output", "[", "\"correct\"", "]", "=", "corr", "\n", "logging_output", "[", "\"count\"", "]", "=", "count", "\n", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.wav2vec_criterion.Wav2vecCriterion.reduce_metrics": [[138, 190], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "sum", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "sum", "k.startswith", "log.get", "log.get", "log.get", "log.get", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.logging.meters.safe_round", "float", "log.get", "math.log", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nsentences", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"ntokens\"", ",", "ntokens", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nsentences\"", ",", "nsentences", ")", "\n", "\n", "correct", "=", "sum", "(", "log", ".", "get", "(", "\"correct\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_correct\"", ",", "correct", ")", "\n", "\n", "total", "=", "sum", "(", "log", ".", "get", "(", "\"count\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_total\"", ",", "total", ")", "\n", "\n", "if", "total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"accuracy\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_correct\"", "]", ".", "sum", "/", "meters", "[", "\"_total\"", "]", ".", "sum", ",", "5", "\n", ")", "\n", "if", "meters", "[", "\"_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "\n", "", "builtin_keys", "=", "{", "\n", "\"loss\"", ",", "\n", "\"ntokens\"", ",", "\n", "\"nsentences\"", ",", "\n", "\"sample_size\"", ",", "\n", "\"correct\"", ",", "\n", "\"count\"", ",", "\n", "}", "\n", "\n", "for", "k", "in", "logging_outputs", "[", "0", "]", ":", "\n", "            ", "if", "k", "not", "in", "builtin_keys", ":", "\n", "                ", "val", "=", "sum", "(", "log", ".", "get", "(", "k", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "if", "k", ".", "startswith", "(", "\"loss\"", ")", ":", "\n", "                    ", "metrics", ".", "log_scalar", "(", "\n", "k", ",", "val", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "metrics", ".", "log_scalar", "(", "k", ",", "val", "/", "len", "(", "logging_outputs", ")", ",", "round", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.wav2vec_criterion.Wav2vecCriterion.logging_outputs_can_be_summed": [[191, 199], ["None"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.__init__": [[16, 22], ["torch.nn.modules.loss._Loss.__init__", "hasattr", "tgt_dict.pad"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "task", "=", "task", "\n", "if", "hasattr", "(", "task", ",", "\"target_dictionary\"", ")", ":", "\n", "            ", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "self", ".", "padding_idx", "=", "tgt_dict", ".", "pad", "(", ")", "if", "tgt_dict", "is", "not", "None", "else", "-", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.add_args": [[23, 29], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.dataclass.utils.gen_parser_from_dataclass"], ["", "", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.build_criterion": [[30, 61], ["inspect.signature().parameters.values", "cls", "NotImplementedError", "inspect.signature", "hasattr", "getattr", "NotImplementedError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "cfg", ":", "FairseqDataclass", ",", "task", ")", ":", "\n", "        ", "\"\"\"Construct a criterion from command-line args.\"\"\"", "\n", "# arguments in the __init__.", "\n", "init_args", "=", "{", "}", "\n", "for", "p", "in", "inspect", ".", "signature", "(", "cls", ")", ".", "parameters", ".", "values", "(", ")", ":", "\n", "            ", "if", "(", "\n", "p", ".", "kind", "==", "p", ".", "POSITIONAL_ONLY", "\n", "or", "p", ".", "kind", "==", "p", ".", "VAR_POSITIONAL", "\n", "or", "p", ".", "kind", "==", "p", ".", "VAR_KEYWORD", "\n", ")", ":", "\n", "# we haven't implemented inference for these argument types,", "\n", "# but PRs welcome :)", "\n", "                ", "raise", "NotImplementedError", "(", "\"{} not supported\"", ".", "format", "(", "p", ".", "kind", ")", ")", "\n", "\n", "", "assert", "p", ".", "kind", "in", "{", "p", ".", "POSITIONAL_OR_KEYWORD", ",", "p", ".", "KEYWORD_ONLY", "}", "\n", "\n", "if", "p", ".", "name", "==", "\"task\"", ":", "\n", "                ", "init_args", "[", "\"task\"", "]", "=", "task", "\n", "", "elif", "p", ".", "name", "==", "\"cfg\"", ":", "\n", "                ", "init_args", "[", "\"cfg\"", "]", "=", "cfg", "\n", "", "elif", "hasattr", "(", "cfg", ",", "p", ".", "name", ")", ":", "\n", "                ", "init_args", "[", "p", ".", "name", "]", "=", "getattr", "(", "cfg", ",", "p", ".", "name", ")", "\n", "", "elif", "p", ".", "default", "!=", "p", ".", "empty", ":", "\n", "                ", "pass", "# we'll use the default value", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Unable to infer Criterion arguments, please implement \"", "\n", "\"{}.build_criterion\"", ".", "format", "(", "cls", ".", "__name__", ")", "\n", ")", "\n", "", "", "return", "cls", "(", "**", "init_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.forward": [[62, 71], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs": [[72, 82], ["fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"The aggregate_logging_outputs API is deprecated. \"", "\n", "\"Please use the reduce_metrics API instead.\"", "\n", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.reduce_metrics": [[83, 95], ["fairseq.utils.deprecation_warning", "cls.aggregate_logging_outputs", "cls.aggregate_logging_outputs.items", "fairseq.metrics.log_scalar"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar"], ["", "@", "classmethod", "\n", "def", "reduce_metrics", "(", "cls", ",", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Criterions should implement the reduce_metrics API. \"", "\n", "\"Falling back to deprecated aggregate_logging_outputs API.\"", "\n", ")", "\n", "agg_logging_outputs", "=", "cls", ".", "aggregate_logging_outputs", "(", "logging_outputs", ")", "\n", "for", "k", ",", "v", "in", "agg_logging_outputs", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "{", "\"nsentences\"", ",", "\"ntokens\"", ",", "\"sample_size\"", "}", ":", "\n", "                ", "continue", "\n", "", "metrics", ".", "log_scalar", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.FairseqCriterion.logging_outputs_can_be_summed": [[96, 104], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.LegacyFairseqCriterion.__init__": [[107, 113], ["fairseq_criterion.FairseqCriterion.__init__", "fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.deprecation_warning"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", "=", "task", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Criterions should take explicit arguments instead of an \"", "\n", "\"argparse.Namespace object, please update your criterion by \"", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.fairseq_criterion.LegacyFairseqCriterion.build_criterion": [[117, 121], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Construct a criterion from command-line args.\"\"\"", "\n", "return", "cls", "(", "args", ",", "task", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.multi_ctc.MultiCtcCriterion.__init__": [[73, 139], ["fairseq.criterions.FairseqCriterion.__init__", "task.target_dictionary.pad", "task.target_dictionary.eos", "task.additional_dictionary.pad", "task.additional_dictionary.eos", "hasattr", "task.target_dictionary.index", "hasattr", "task.additional_dictionary.index", "eval", "argparse.Namespace", "min", "min", "W2lKenLMDecoder", "argparse.Namespace", "min", "min", "W2lKenLMDecoder", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "MultiCtcCriterionConfig", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "blank_idx", "=", "task", ".", "target_dictionary", ".", "index", "(", "task", ".", "blank_symbol", ")", "if", "hasattr", "(", "task", ",", "'blank_symbol'", ")", "else", "0", "\n", "self", ".", "pad_idx", "=", "task", ".", "target_dictionary", ".", "pad", "(", ")", "\n", "self", ".", "eos_idx", "=", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", "\n", "self", ".", "add_blank_idx", "=", "task", ".", "additional_dictionary", ".", "index", "(", "task", ".", "blank_symbol", ")", "if", "hasattr", "(", "task", ",", "'blank_symbol'", ")", "else", "0", "\n", "self", ".", "add_pad_idx", "=", "task", ".", "additional_dictionary", ".", "pad", "(", ")", "\n", "self", ".", "add_eos_idx", "=", "task", ".", "additional_dictionary", ".", "eos", "(", ")", "\n", "\n", "self", ".", "post_process", "=", "cfg", ".", "post_process", "\n", "\n", "if", "cfg", ".", "wer_args", "is", "not", "None", ":", "\n", "            ", "(", "\n", "cfg", ".", "wer_kenlm_model", ",", "\n", "cfg", ".", "wer_lexicon", ",", "\n", "cfg", ".", "wer_lm_weight", ",", "\n", "cfg", ".", "wer_word_score", ",", "\n", ")", "=", "eval", "(", "cfg", ".", "wer_args", ")", "\n", "\n", "", "if", "cfg", ".", "wer_kenlm_model", "is", "not", "None", ":", "\n", "            ", "from", "examples", ".", "speech_recognition", ".", "w2l_decoder", "import", "W2lKenLMDecoder", "\n", "\n", "dec_args", "=", "Namespace", "(", ")", "\n", "dec_args", ".", "nbest", "=", "1", "\n", "dec_args", ".", "criterion", "=", "\"ctc\"", "\n", "dec_args", ".", "kenlm_model", "=", "cfg", ".", "wer_kenlm_model", "\n", "dec_args", ".", "lexicon", "=", "cfg", ".", "wer_lexicon", "\n", "dec_args", ".", "beam", "=", "50", "\n", "dec_args", ".", "beam_size_token", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "beam_threshold", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "lm_weight", "=", "cfg", ".", "wer_lm_weight", "\n", "dec_args", ".", "word_score", "=", "cfg", ".", "wer_word_score", "\n", "dec_args", ".", "unk_weight", "=", "-", "math", ".", "inf", "\n", "dec_args", ".", "sil_weight", "=", "0", "\n", "\n", "self", ".", "w2l_decoder", "=", "W2lKenLMDecoder", "(", "dec_args", ",", "task", ".", "target_dictionary", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "w2l_decoder", "=", "None", "\n", "\n", "", "if", "cfg", ".", "wer_kenlm_model", "is", "not", "None", ":", "\n", "            ", "from", "examples", ".", "speech_recognition", ".", "w2l_decoder", "import", "W2lKenLMDecoder", "\n", "\n", "dec_args", "=", "Namespace", "(", ")", "\n", "dec_args", ".", "nbest", "=", "1", "\n", "dec_args", ".", "criterion", "=", "\"ctc\"", "\n", "dec_args", ".", "kenlm_model", "=", "cfg", ".", "wer_kenlm_model", "\n", "dec_args", ".", "lexicon", "=", "cfg", ".", "wer_lexicon", "\n", "dec_args", ".", "beam", "=", "50", "\n", "dec_args", ".", "beam_size_token", "=", "min", "(", "50", ",", "len", "(", "task", ".", "additional_dictionary", ")", ")", "\n", "dec_args", ".", "beam_threshold", "=", "min", "(", "50", ",", "len", "(", "task", ".", "additional_dictionary", ")", ")", "\n", "dec_args", ".", "lm_weight", "=", "cfg", ".", "wer_lm_weight", "\n", "dec_args", ".", "word_score", "=", "cfg", ".", "wer_word_score", "\n", "dec_args", ".", "unk_weight", "=", "-", "math", ".", "inf", "\n", "dec_args", ".", "sil_weight", "=", "0", "\n", "\n", "self", ".", "add_w2l_decoder", "=", "W2lKenLMDecoder", "(", "dec_args", ",", "task", ".", "additional_dictionary", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_w2l_decoder", "=", "None", "\n", "\n", "", "self", ".", "zero_infinity", "=", "cfg", ".", "zero_infinity", "\n", "self", ".", "sentence_avg", "=", "cfg", ".", "sentence_avg", "\n", "\n", "## \uad6c\uc0c9 \ub9de\ucd94\uae30", "\n", "self", ".", "num_updates", "=", "0", "\n", "self", ".", "multi_use_update", "=", "cfg", ".", "multi_use_update", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.multi_ctc.MultiCtcCriterion.set_num_updates": [[140, 143], ["None"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.multi_ctc.MultiCtcCriterion.forward": [[144, 352], ["model", "model.get_normalized_probs().contiguous", "model.get_normalized_addprobs().contiguous", "sample[].masked_select", "sample[].masked_select", "non_padding_mask.long().sum", "pad_mask.sum", "add_pad_mask.sum", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.ctc_loss", "torch.ctc_loss", "pad_mask.sum.sum().item", "sample[].size", "fairseq.utils.item", "sample[].numel", "model.get_normalized_probs", "model.get_normalized_addprobs", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.ctc_loss", "torch.ctc_loss", "fairseq.utils.item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_normalized_probs().contiguous.transpose().float().contiguous().cpu", "zip", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_normalized_addprobs().contiguous.transpose().float().contiguous().cpu", "zip", "non_padding_mask.long", "pad_mask.sum.sum", "lp[].unsqueeze", "multi_ctc.MultiCtcCriterion.task.target_dictionary.string", "targ.tolist", "lp[].unsqueeze.argmax().unique_consecutive", "toks[].tolist", "editdistance.eval", "len", "fairseq.data.data_utils.post_process().split", "multi_ctc.MultiCtcCriterion.task.target_dictionary.string", "fairseq.data.data_utils.post_process().split", "len", "lp[].unsqueeze", "multi_ctc.MultiCtcCriterion.task.additional_dictionary.string", "targ.tolist", "lp[].unsqueeze.argmax().unique_consecutive", "toks[].tolist", "editdistance.eval", "len", "fairseq.data.data_utils.post_process().split", "multi_ctc.MultiCtcCriterion.task.additional_dictionary.string", "fairseq.data.data_utils.post_process().split", "len", "model.get_normalized_probs().contiguous.transpose().float().contiguous", "multi_ctc.MultiCtcCriterion.w2l_decoder.decode", "editdistance.eval", "editdistance.eval", "editdistance.eval", "model.get_normalized_addprobs().contiguous.transpose().float().contiguous", "multi_ctc.MultiCtcCriterion.add_w2l_decoder.decode", "editdistance.eval", "editdistance.eval", "editdistance.eval", "len", "multi_ctc.MultiCtcCriterion.task.target_dictionary.pad", "multi_ctc.MultiCtcCriterion.task.target_dictionary.eos", "lp[].unsqueeze.argmax", "fairseq.data.data_utils.post_process", "fairseq.data.data_utils.post_process", "len", "multi_ctc.MultiCtcCriterion.task.additional_dictionary.pad", "multi_ctc.MultiCtcCriterion.task.additional_dictionary.eos", "lp[].unsqueeze.argmax", "fairseq.data.data_utils.post_process", "fairseq.data.data_utils.post_process", "model.get_normalized_probs().contiguous.transpose().float", "len", "model.get_normalized_addprobs().contiguous.transpose().float", "len", "model.get_normalized_probs().contiguous.transpose", "model.get_normalized_addprobs().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.wav2vec.wav2vec2_asr2.Wav2VecCtc2.get_normalized_addprobs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "\n", "net_output", ",", "log_probs", "=", "True", "\n", ")", ".", "contiguous", "(", ")", "# (T, B, C) from the encoder", "\n", "\n", "add_lprobs", "=", "model", ".", "get_normalized_addprobs", "(", "\n", "net_output", ",", "log_probs", "=", "True", "\n", ")", ".", "contiguous", "(", ")", "# (T, B, C) from the encoder", "\n", "\n", "if", "\"src_lengths\"", "in", "sample", "[", "\"net_input\"", "]", ":", "\n", "            ", "input_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "non_padding_mask", "=", "~", "net_output", "[", "\"padding_mask\"", "]", "\n", "input_lengths", "=", "non_padding_mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "pad_mask", "=", "(", "sample", "[", "\"target\"", "]", "!=", "self", ".", "pad_idx", ")", "&", "(", "\n", "sample", "[", "\"target\"", "]", "!=", "self", ".", "eos_idx", "\n", ")", "\n", "targets_flat", "=", "sample", "[", "\"target\"", "]", ".", "masked_select", "(", "pad_mask", ")", "\n", "\n", "add_pad_mask", "=", "(", "sample", "[", "\"add_target\"", "]", "!=", "self", ".", "add_pad_idx", ")", "&", "(", "\n", "sample", "[", "\"add_target\"", "]", "!=", "self", ".", "add_eos_idx", "\n", ")", "\n", "add_targets_flat", "=", "sample", "[", "\"add_target\"", "]", ".", "masked_select", "(", "add_pad_mask", ")", "\n", "\n", "if", "\"target_lengths\"", "in", "sample", ":", "\n", "            ", "target_lengths", "=", "sample", "[", "\"target_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "target_lengths", "=", "pad_mask", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "if", "\"add_target_lengths\"", "in", "sample", ":", "\n", "            ", "add_target_lengths", "=", "sample", "[", "\"add_target_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "add_target_lengths", "=", "add_pad_mask", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "with", "torch", ".", "backends", ".", "cudnn", ".", "flags", "(", "enabled", "=", "False", ")", ":", "\n", "            ", "loss", "=", "F", ".", "ctc_loss", "(", "\n", "lprobs", ",", "\n", "targets_flat", ",", "\n", "input_lengths", ",", "\n", "target_lengths", ",", "\n", "blank", "=", "self", ".", "blank_idx", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "zero_infinity", "=", "self", ".", "zero_infinity", ",", "\n", ")", "\n", "\n", "", "add_loss", "=", "None", "\n", "if", "self", ".", "multi_use_update", "<=", "self", ".", "num_updates", ":", "\n", "            ", "with", "torch", ".", "backends", ".", "cudnn", ".", "flags", "(", "enabled", "=", "False", ")", ":", "\n", "                ", "add_loss", "=", "F", ".", "ctc_loss", "(", "\n", "add_lprobs", ",", "\n", "add_targets_flat", ",", "\n", "input_lengths", ",", "\n", "add_target_lengths", ",", "\n", "blank", "=", "self", ".", "add_blank_idx", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "zero_infinity", "=", "self", ".", "zero_infinity", ",", "\n", ")", "\n", "loss", "=", "loss", "+", "add_loss", "\n", "\n", "", "", "ntokens", "=", "(", "\n", "sample", "[", "\"ntokens\"", "]", "if", "\"ntokens\"", "in", "sample", "else", "target_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "ntokens", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", ",", "# * sample['ntokens'],", "\n", "\"add_loss\"", ":", "utils", ".", "item", "(", "add_loss", ".", "data", ")", "if", "add_loss", "is", "not", "None", "else", "0.0", ",", "# * sample['ntokens'],", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "if", "not", "model", ".", "training", ":", "\n", "            ", "import", "editdistance", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "lprobs_t", "=", "lprobs", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "contiguous", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "c_err", "=", "0", "\n", "c_len", "=", "0", "\n", "w_errs", "=", "0", "\n", "w_len", "=", "0", "\n", "wv_errs", "=", "0", "\n", "for", "lp", ",", "t", ",", "inp_l", "in", "zip", "(", "\n", "lprobs_t", ",", "\n", "sample", "[", "\"target_label\"", "]", "\n", "if", "\"target_label\"", "in", "sample", "\n", "else", "sample", "[", "\"target\"", "]", ",", "\n", "input_lengths", ",", "\n", ")", ":", "\n", "                    ", "lp", "=", "lp", "[", ":", "inp_l", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "decoded", "=", "None", "\n", "if", "self", ".", "w2l_decoder", "is", "not", "None", ":", "\n", "                        ", "decoded", "=", "self", ".", "w2l_decoder", ".", "decode", "(", "lp", ")", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                            ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                            ", "decoded", "=", "decoded", "[", "0", "]", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                                ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                                ", "decoded", "=", "decoded", "[", "0", "]", "\n", "\n", "", "", "", "p", "=", "(", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "pad", "(", ")", ")", "&", "(", "\n", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", ")", "\n", "targ", "=", "t", "[", "p", "]", "\n", "targ_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "targ", ")", "\n", "targ_units_arr", "=", "targ", ".", "tolist", "(", ")", "\n", "\n", "toks", "=", "lp", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "unique_consecutive", "(", ")", "\n", "pred_units_arr", "=", "toks", "[", "toks", "!=", "self", ".", "blank_idx", "]", ".", "tolist", "(", ")", "\n", "\n", "c_err", "+=", "editdistance", ".", "eval", "(", "pred_units_arr", ",", "targ_units_arr", ")", "\n", "c_len", "+=", "len", "(", "targ_units_arr", ")", "\n", "\n", "targ_words", "=", "post_process", "(", "targ_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "pred_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "pred_units_arr", ")", "\n", "pred_words_raw", "=", "post_process", "(", "pred_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "if", "decoded", "is", "not", "None", "and", "\"words\"", "in", "decoded", ":", "\n", "                        ", "pred_words", "=", "decoded", "[", "\"words\"", "]", "\n", "w_errs", "+=", "editdistance", ".", "eval", "(", "pred_words", ",", "targ_words", ")", "\n", "wv_errs", "+=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "", "else", ":", "\n", "                        ", "dist", "=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "w_errs", "+=", "dist", "\n", "wv_errs", "+=", "dist", "\n", "\n", "", "w_len", "+=", "len", "(", "targ_words", ")", "\n", "\n", "", "logging_output", "[", "\"wv_errors\"", "]", "=", "wv_errs", "\n", "logging_output", "[", "\"w_errors\"", "]", "=", "w_errs", "\n", "logging_output", "[", "\"w_total\"", "]", "=", "w_len", "\n", "logging_output", "[", "\"c_errors\"", "]", "=", "c_err", "\n", "logging_output", "[", "\"c_total\"", "]", "=", "c_len", "\n", "\n", "## \ucd94\uac00\ubd80\ubd84", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "add_lprobs_t", "=", "add_lprobs", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "contiguous", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "c_err", "=", "0", "\n", "c_len", "=", "0", "\n", "w_errs", "=", "0", "\n", "w_len", "=", "0", "\n", "wv_errs", "=", "0", "\n", "for", "lp", ",", "t", ",", "inp_l", "in", "zip", "(", "\n", "add_lprobs_t", ",", "\n", "sample", "[", "\"add_target_label\"", "]", "\n", "if", "\"add_target_label\"", "in", "sample", "\n", "else", "sample", "[", "\"add_target\"", "]", ",", "\n", "input_lengths", ",", "\n", ")", ":", "\n", "                    ", "lp", "=", "lp", "[", ":", "inp_l", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "decoded", "=", "None", "\n", "if", "self", ".", "add_w2l_decoder", "is", "not", "None", ":", "\n", "                        ", "decoded", "=", "self", ".", "add_w2l_decoder", ".", "decode", "(", "lp", ")", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                            ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                            ", "decoded", "=", "decoded", "[", "0", "]", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                                ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                                ", "decoded", "=", "decoded", "[", "0", "]", "\n", "\n", "", "", "", "p", "=", "(", "t", "!=", "self", ".", "task", ".", "additional_dictionary", ".", "pad", "(", ")", ")", "&", "(", "\n", "t", "!=", "self", ".", "task", ".", "additional_dictionary", ".", "eos", "(", ")", "\n", ")", "\n", "targ", "=", "t", "[", "p", "]", "\n", "targ_units", "=", "self", ".", "task", ".", "additional_dictionary", ".", "string", "(", "targ", ")", "\n", "targ_units_arr", "=", "targ", ".", "tolist", "(", ")", "\n", "\n", "toks", "=", "lp", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "unique_consecutive", "(", ")", "\n", "pred_units_arr", "=", "toks", "[", "toks", "!=", "self", ".", "add_blank_idx", "]", ".", "tolist", "(", ")", "\n", "\n", "c_err", "+=", "editdistance", ".", "eval", "(", "pred_units_arr", ",", "targ_units_arr", ")", "\n", "c_len", "+=", "len", "(", "targ_units_arr", ")", "\n", "\n", "targ_words", "=", "post_process", "(", "targ_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "pred_units", "=", "self", ".", "task", ".", "additional_dictionary", ".", "string", "(", "pred_units_arr", ")", "\n", "pred_words_raw", "=", "post_process", "(", "pred_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "if", "decoded", "is", "not", "None", "and", "\"words\"", "in", "decoded", ":", "\n", "                        ", "pred_words", "=", "decoded", "[", "\"words\"", "]", "\n", "w_errs", "+=", "editdistance", ".", "eval", "(", "pred_words", ",", "targ_words", ")", "\n", "wv_errs", "+=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "", "else", ":", "\n", "                        ", "dist", "=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "w_errs", "+=", "dist", "\n", "wv_errs", "+=", "dist", "\n", "\n", "", "w_len", "+=", "len", "(", "targ_words", ")", "\n", "\n", "", "logging_output", "[", "\"add_wv_errors\"", "]", "=", "wv_errs", "\n", "logging_output", "[", "\"add_w_errors\"", "]", "=", "w_errs", "\n", "logging_output", "[", "\"add_w_total\"", "]", "=", "w_len", "\n", "logging_output", "[", "\"add_c_errors\"", "]", "=", "c_err", "\n", "logging_output", "[", "\"add_c_total\"", "]", "=", "c_len", "\n", "\n", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.multi_ctc.MultiCtcCriterion.reduce_metrics": [[353, 454], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "fairseq.utils.item", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "sum", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "log.get", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nsentences", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"ntokens\"", ",", "ntokens", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nsentences\"", ",", "nsentences", ")", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "\n", "", "c_errors", "=", "sum", "(", "log", ".", "get", "(", "\"c_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_errors\"", ",", "c_errors", ")", "\n", "c_total", "=", "sum", "(", "log", ".", "get", "(", "\"c_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_total\"", ",", "c_total", ")", "\n", "w_errors", "=", "sum", "(", "log", ".", "get", "(", "\"w_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_errors\"", ",", "w_errors", ")", "\n", "wv_errors", "=", "sum", "(", "log", ".", "get", "(", "\"wv_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_wv_errors\"", ",", "wv_errors", ")", "\n", "w_total", "=", "sum", "(", "log", ".", "get", "(", "\"w_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_total\"", ",", "w_total", ")", "\n", "\n", "if", "c_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_c_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_c_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_c_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "", "if", "w_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_w_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"raw_wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_wv_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "## \ucd94\uac00", "\n", "", "add_loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"add_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"add_loss\"", ",", "add_loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "\n", "add_c_errors", "=", "sum", "(", "log", ".", "get", "(", "\"add_c_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_add_c_errors\"", ",", "add_c_errors", ")", "\n", "add_c_total", "=", "sum", "(", "log", ".", "get", "(", "\"add_c_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_add_c_total\"", ",", "add_c_total", ")", "\n", "add_w_errors", "=", "sum", "(", "log", ".", "get", "(", "\"add_w_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_add_w_errors\"", ",", "add_w_errors", ")", "\n", "add_wv_errors", "=", "sum", "(", "log", ".", "get", "(", "\"add_wv_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_add_wv_errors\"", ",", "add_wv_errors", ")", "\n", "add_w_total", "=", "sum", "(", "log", ".", "get", "(", "\"add_w_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_add_w_total\"", ",", "add_w_total", ")", "\n", "if", "add_c_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"add_uer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_add_c_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_add_c_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_add_c_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "", "if", "add_w_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"add_wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_add_w_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_add_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_add_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"add_raw_wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_add_wv_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_add_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_add_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.multi_ctc.MultiCtcCriterion.logging_outputs_can_be_summed": [[457, 465], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.__init__": [[67, 107], ["fairseq.criterions.FairseqCriterion.__init__", "task.target_dictionary.pad", "task.target_dictionary.eos", "hasattr", "task.target_dictionary.index", "eval", "argparse.Namespace", "min", "min", "W2lKenLMDecoder", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "CtcCriterionConfig", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "blank_idx", "=", "task", ".", "target_dictionary", ".", "index", "(", "task", ".", "blank_symbol", ")", "if", "hasattr", "(", "task", ",", "'blank_symbol'", ")", "else", "0", "\n", "self", ".", "pad_idx", "=", "task", ".", "target_dictionary", ".", "pad", "(", ")", "\n", "self", ".", "eos_idx", "=", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", "self", ".", "post_process", "=", "cfg", ".", "post_process", "\n", "\n", "if", "cfg", ".", "wer_args", "is", "not", "None", ":", "\n", "            ", "(", "\n", "cfg", ".", "wer_kenlm_model", ",", "\n", "cfg", ".", "wer_lexicon", ",", "\n", "cfg", ".", "wer_lm_weight", ",", "\n", "cfg", ".", "wer_word_score", ",", "\n", ")", "=", "eval", "(", "cfg", ".", "wer_args", ")", "\n", "\n", "", "if", "cfg", ".", "wer_kenlm_model", "is", "not", "None", ":", "\n", "            ", "from", "examples", ".", "speech_recognition", ".", "w2l_decoder", "import", "W2lKenLMDecoder", "\n", "\n", "dec_args", "=", "Namespace", "(", ")", "\n", "dec_args", ".", "nbest", "=", "1", "\n", "dec_args", ".", "criterion", "=", "\"ctc\"", "\n", "dec_args", ".", "kenlm_model", "=", "cfg", ".", "wer_kenlm_model", "\n", "dec_args", ".", "lexicon", "=", "cfg", ".", "wer_lexicon", "\n", "dec_args", ".", "beam", "=", "50", "\n", "dec_args", ".", "beam_size_token", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "beam_threshold", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "lm_weight", "=", "cfg", ".", "wer_lm_weight", "\n", "dec_args", ".", "word_score", "=", "cfg", ".", "wer_word_score", "\n", "dec_args", ".", "unk_weight", "=", "-", "math", ".", "inf", "\n", "dec_args", ".", "sil_weight", "=", "0", "\n", "\n", "self", ".", "w2l_decoder", "=", "W2lKenLMDecoder", "(", "dec_args", ",", "task", ".", "target_dictionary", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "w2l_decoder", "=", "None", "\n", "\n", "", "self", ".", "zero_infinity", "=", "cfg", ".", "zero_infinity", "\n", "self", ".", "sentence_avg", "=", "cfg", ".", "sentence_avg", "\n", "\n", "## \uad6c\uc0c9 \ub9de\ucd94\uae30", "\n", "self", ".", "num_updates", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.set_num_updates": [[108, 111], ["None"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.forward": [[112, 225], ["model", "model.get_normalized_probs().contiguous", "sample[].masked_select", "non_padding_mask.long().sum", "pad_mask.sum", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.ctc_loss", "torch.ctc_loss", "pad_mask.sum.sum().item", "sample[].size", "fairseq.utils.item", "sample[].numel", "model.get_normalized_probs", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_normalized_probs().contiguous.transpose().float().contiguous().cpu", "zip", "non_padding_mask.long", "pad_mask.sum.sum", "lp[].unsqueeze", "ctc.CtcCriterion.task.target_dictionary.string", "targ.tolist", "lp[].unsqueeze.argmax().unique_consecutive", "toks[].tolist", "editdistance.eval", "len", "fairseq.data.data_utils.post_process().split", "ctc.CtcCriterion.task.target_dictionary.string", "fairseq.data.data_utils.post_process().split", "len", "model.get_normalized_probs().contiguous.transpose().float().contiguous", "ctc.CtcCriterion.w2l_decoder.decode", "editdistance.eval", "editdistance.eval", "editdistance.eval", "len", "ctc.CtcCriterion.task.target_dictionary.pad", "ctc.CtcCriterion.task.target_dictionary.eos", "lp[].unsqueeze.argmax", "fairseq.data.data_utils.post_process", "fairseq.data.data_utils.post_process", "model.get_normalized_probs().contiguous.transpose().float", "len", "model.get_normalized_probs().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "\n", "net_output", ",", "log_probs", "=", "True", "\n", ")", ".", "contiguous", "(", ")", "# (T, B, C) from the encoder", "\n", "\n", "if", "\"src_lengths\"", "in", "sample", "[", "\"net_input\"", "]", ":", "\n", "            ", "input_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "non_padding_mask", "=", "~", "net_output", "[", "\"padding_mask\"", "]", "\n", "input_lengths", "=", "non_padding_mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "pad_mask", "=", "(", "sample", "[", "\"target\"", "]", "!=", "self", ".", "pad_idx", ")", "&", "(", "\n", "sample", "[", "\"target\"", "]", "!=", "self", ".", "eos_idx", "\n", ")", "\n", "targets_flat", "=", "sample", "[", "\"target\"", "]", ".", "masked_select", "(", "pad_mask", ")", "\n", "\n", "if", "\"target_lengths\"", "in", "sample", ":", "\n", "            ", "target_lengths", "=", "sample", "[", "\"target_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "target_lengths", "=", "pad_mask", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "with", "torch", ".", "backends", ".", "cudnn", ".", "flags", "(", "enabled", "=", "False", ")", ":", "\n", "            ", "loss", "=", "F", ".", "ctc_loss", "(", "\n", "lprobs", ",", "\n", "targets_flat", ",", "\n", "input_lengths", ",", "\n", "target_lengths", ",", "\n", "blank", "=", "self", ".", "blank_idx", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "zero_infinity", "=", "self", ".", "zero_infinity", ",", "\n", ")", "\n", "\n", "", "ntokens", "=", "(", "\n", "sample", "[", "\"ntokens\"", "]", "if", "\"ntokens\"", "in", "sample", "else", "target_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "ntokens", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", ",", "# * sample['ntokens'],", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "if", "not", "model", ".", "training", ":", "\n", "            ", "import", "editdistance", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "lprobs_t", "=", "lprobs", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "contiguous", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "c_err", "=", "0", "\n", "c_len", "=", "0", "\n", "w_errs", "=", "0", "\n", "w_len", "=", "0", "\n", "wv_errs", "=", "0", "\n", "for", "lp", ",", "t", ",", "inp_l", "in", "zip", "(", "\n", "lprobs_t", ",", "\n", "sample", "[", "\"target_label\"", "]", "\n", "if", "\"target_label\"", "in", "sample", "\n", "else", "sample", "[", "\"target\"", "]", ",", "\n", "input_lengths", ",", "\n", ")", ":", "\n", "                    ", "lp", "=", "lp", "[", ":", "inp_l", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "decoded", "=", "None", "\n", "if", "self", ".", "w2l_decoder", "is", "not", "None", ":", "\n", "                        ", "decoded", "=", "self", ".", "w2l_decoder", ".", "decode", "(", "lp", ")", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                            ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                            ", "decoded", "=", "decoded", "[", "0", "]", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                                ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                                ", "decoded", "=", "decoded", "[", "0", "]", "\n", "\n", "", "", "", "p", "=", "(", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "pad", "(", ")", ")", "&", "(", "\n", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", ")", "\n", "targ", "=", "t", "[", "p", "]", "\n", "targ_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "targ", ")", "\n", "targ_units_arr", "=", "targ", ".", "tolist", "(", ")", "\n", "\n", "toks", "=", "lp", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "unique_consecutive", "(", ")", "\n", "pred_units_arr", "=", "toks", "[", "toks", "!=", "self", ".", "blank_idx", "]", ".", "tolist", "(", ")", "\n", "\n", "c_err", "+=", "editdistance", ".", "eval", "(", "pred_units_arr", ",", "targ_units_arr", ")", "\n", "c_len", "+=", "len", "(", "targ_units_arr", ")", "\n", "\n", "targ_words", "=", "post_process", "(", "targ_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "pred_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "pred_units_arr", ")", "\n", "pred_words_raw", "=", "post_process", "(", "pred_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "if", "decoded", "is", "not", "None", "and", "\"words\"", "in", "decoded", ":", "\n", "                        ", "pred_words", "=", "decoded", "[", "\"words\"", "]", "\n", "w_errs", "+=", "editdistance", ".", "eval", "(", "pred_words", ",", "targ_words", ")", "\n", "wv_errs", "+=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "", "else", ":", "\n", "                        ", "dist", "=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "w_errs", "+=", "dist", "\n", "wv_errs", "+=", "dist", "\n", "\n", "", "w_len", "+=", "len", "(", "targ_words", ")", "\n", "\n", "", "logging_output", "[", "\"wv_errors\"", "]", "=", "wv_errs", "\n", "logging_output", "[", "\"w_errors\"", "]", "=", "w_errs", "\n", "logging_output", "[", "\"w_total\"", "]", "=", "w_len", "\n", "logging_output", "[", "\"c_errors\"", "]", "=", "c_err", "\n", "logging_output", "[", "\"c_total\"", "]", "=", "c_len", "\n", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.reduce_metrics": [[226, 285], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.metrics.log_derived", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.log", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.safe_round"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nsentences", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"ntokens\"", ",", "ntokens", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nsentences\"", ",", "nsentences", ")", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "\n", "", "c_errors", "=", "sum", "(", "log", ".", "get", "(", "\"c_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_errors\"", ",", "c_errors", ")", "\n", "c_total", "=", "sum", "(", "log", ".", "get", "(", "\"c_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_total\"", ",", "c_total", ")", "\n", "w_errors", "=", "sum", "(", "log", ".", "get", "(", "\"w_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_errors\"", ",", "w_errors", ")", "\n", "wv_errors", "=", "sum", "(", "log", ".", "get", "(", "\"wv_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_wv_errors\"", ",", "wv_errors", ")", "\n", "w_total", "=", "sum", "(", "log", ".", "get", "(", "\"w_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_total\"", ",", "w_total", ")", "\n", "\n", "if", "c_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_c_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_c_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_c_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "", "if", "w_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_w_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"raw_wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_wv_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.ctc.CtcCriterion.logging_outputs_can_be_summed": [[287, 295], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.criterions.__init__.build_criterion": [[28, 30], ["build_criterion_"], "function", ["None"], []], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.EpochListening.can_reuse_epoch_itr_across_epochs": [[17, 29], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Whether we can reuse the :class:`fairseq.data.EpochBatchIterator` for\n        this dataset across epochs.\n\n        This needs to return ``False`` if the sample sizes can change across\n        epochs, in which case we may need to regenerate batches at each epoch.\n        If your dataset relies in ``set_epoch`` then you should consider setting\n        this to ``False``.\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.EpochListening.set_epoch": [[30, 33], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Will receive the updated epoch number at the beginning of the epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.__getitem__": [[38, 40], ["None"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.__len__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.collater": [[44, 54], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch suitable for forwarding with a Model\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.num_tokens": [[55, 59], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.num_tokens_vec": [[60, 64], ["None"], "methods", ["None"], ["", "def", "num_tokens_vec", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens for a set of positions defined by indices.\n        This value is used to enforce ``--max-tokens`` during batching.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.size": [[65, 69], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.ordered_indices": [[70, 74], ["numpy.arange", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.supports_prefetch": [[75, 79], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports prefetching.\"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.attr": [[80, 82], ["getattr"], "methods", ["None"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "attr", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.prefetch": [[83, 86], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Prefetch the data required for this epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.get_batch_shapes": [[87, 103], ["None"], "methods", ["None"], ["", "def", "get_batch_shapes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a list of valid batch shapes, for example::\n\n            [(8, 512), (16, 256), (32, 128)]\n\n        The first dimension of each tuple is the batch size and can be ``None``\n        to automatically infer the max batch size based on ``--max-tokens``.\n        The second dimension of each tuple is the max supported length as given\n        by :func:`fairseq.data.FairseqDataset.num_tokens`.\n\n        This will be used by :func:`fairseq.data.FairseqDataset.batch_by_size`\n        to restrict batch shapes. This is useful on TPUs to avoid too many\n        dynamic shapes (and recompilations).\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.batch_by_size": [[104, 153], ["fairseq_dataset.FairseqDataset.get_batch_shapes", "fairseq.data.data_utils.batch_by_size", "numpy.array", "fairseq_dataset.FairseqDataset.num_tokens_vec().astype", "min", "fairseq_dataset.FairseqDataset.num_tokens_vec", "fairseq_dataset.FairseqDataset.batch_by_size.adjust_bsz"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.get_batch_shapes", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.num_tokens_vec"], ["", "def", "batch_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given an ordered set of indices, return batches according to\n        *max_tokens*, *max_sentences* and *required_batch_size_multiple*.\n        \"\"\"", "\n", "from", "fairseq", ".", "data", "import", "data_utils", "\n", "\n", "fixed_shapes", "=", "self", ".", "get_batch_shapes", "(", ")", "\n", "if", "fixed_shapes", "is", "not", "None", ":", "\n", "\n", "            ", "def", "adjust_bsz", "(", "bsz", ",", "num_tokens", ")", ":", "\n", "                ", "if", "bsz", "is", "None", ":", "\n", "                    ", "assert", "max_tokens", "is", "not", "None", ",", "\"Must specify --max-tokens\"", "\n", "bsz", "=", "max_tokens", "//", "num_tokens", "\n", "", "if", "max_sentences", "is", "not", "None", ":", "\n", "                    ", "bsz", "=", "min", "(", "bsz", ",", "max_sentences", ")", "\n", "", "elif", "(", "\n", "bsz", ">=", "required_batch_size_multiple", "\n", "and", "bsz", "%", "required_batch_size_multiple", "!=", "0", "\n", ")", ":", "\n", "                    ", "bsz", "-=", "bsz", "%", "required_batch_size_multiple", "\n", "", "return", "bsz", "\n", "\n", "", "fixed_shapes", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "adjust_bsz", "(", "bsz", ",", "num_tokens", ")", ",", "num_tokens", "]", "\n", "for", "(", "bsz", ",", "num_tokens", ")", "in", "fixed_shapes", "\n", "]", "\n", ")", "\n", "\n", "", "try", ":", "\n", "            ", "num_tokens_vec", "=", "self", ".", "num_tokens_vec", "(", "indices", ")", ".", "astype", "(", "'int64'", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "            ", "num_tokens_vec", "=", "None", "\n", "\n", "", "return", "data_utils", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "num_tokens_fn", "=", "self", ".", "num_tokens", ",", "\n", "num_tokens_vec", "=", "num_tokens_vec", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", "fixed_shapes", "=", "fixed_shapes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.filter_indices_by_size": [[155, 191], ["isinstance", "isinstance", "fairseq.data.data_utils._filter_by_size_dynamic", "hasattr", "isinstance", "indices[].tolist", "hasattr", "isinstance", "indices[].tolist", "fairseq.data.data_utils._filter_by_size_dynamic", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils._filter_by_size_dynamic"], ["", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Filter a list of sample indices. Remove those that are longer than\n        specified in *max_sizes*.\n\n        WARNING: don't update, override method in child classes\n\n        Args:\n            indices (np.array): original array of sample indices\n            max_sizes (int or list[int] or tuple[int]): max sample size,\n                can be defined separately for src and tgt (then list or tuple)\n\n        Returns:\n            np.array: filtered sample array\n            list: list of removed indices\n        \"\"\"", "\n", "if", "isinstance", "(", "max_sizes", ",", "float", ")", "or", "isinstance", "(", "max_sizes", ",", "int", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"sizes\"", ")", "and", "isinstance", "(", "self", ".", "sizes", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "ignored", "=", "indices", "[", "self", ".", "sizes", "[", "indices", "]", ">", "max_sizes", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "self", ".", "sizes", "[", "indices", "]", "<=", "max_sizes", "]", "\n", "", "elif", "(", "\n", "hasattr", "(", "self", ",", "\"sizes\"", ")", "\n", "and", "isinstance", "(", "self", ".", "sizes", ",", "list", ")", "\n", "and", "len", "(", "self", ".", "sizes", ")", "==", "1", "\n", ")", ":", "\n", "                ", "ignored", "=", "indices", "[", "self", ".", "sizes", "[", "0", "]", "[", "indices", "]", ">", "max_sizes", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "self", ".", "sizes", "[", "0", "]", "[", "indices", "]", "<=", "max_sizes", "]", "\n", "", "else", ":", "\n", "                ", "indices", ",", "ignored", "=", "data_utils", ".", "_filter_by_size_dynamic", "(", "\n", "indices", ",", "self", ".", "size", ",", "max_sizes", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "indices", ",", "ignored", "=", "data_utils", ".", "_filter_by_size_dynamic", "(", "\n", "indices", ",", "self", ".", "size", ",", "max_sizes", "\n", ")", "\n", "", "return", "indices", ",", "ignored", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqDataset.supports_fetch_outside_dataloader": [[192, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_fetch_outside_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports fetching outside the workers of the dataloader.\"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fairseq_dataset.FairseqIterableDataset.__iter__": [[204, 206], ["None"], "methods", ["None"], ["def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.id_dataset.IdDataset.__getitem__": [[12, 14], ["None"], "methods", ["None"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.id_dataset.IdDataset.__len__": [[15, 17], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.id_dataset.IdDataset.collater": [[18, 20], ["torch.tensor"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "samples", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.__init__": [[12, 37], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "labels", ",", "\n", "add_labels", ",", "\n", "pad", ",", "\n", "eos", ",", "\n", "add_pad", ",", "\n", "add_eos", ",", "\n", "batch_targets", ",", "\n", "process_label", "=", "None", ",", "\n", "add_process_label", "=", "None", ",", "\n", "add_to_input", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "add_labels", "=", "add_labels", "\n", "self", ".", "batch_targets", "=", "batch_targets", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "eos", "=", "eos", "\n", "self", ".", "add_pad", "=", "add_pad", "\n", "self", ".", "add_eos", "=", "add_eos", "\n", "self", ".", "process_label", "=", "process_label", "\n", "self", ".", "add_process_label", "=", "add_process_label", "\n", "self", ".", "add_to_input", "=", "add_to_input", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.get_label": [[38, 43], ["add_multi_dataset.AddMultiDataset.process_label"], "methods", ["None"], ["", "def", "get_label", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "labels", "[", "index", "]", "\n", "if", "self", ".", "process_label", "is", "None", "\n", "else", "self", ".", "process_label", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.get_add_label": [[45, 50], ["add_multi_dataset.AddMultiDataset.add_process_label"], "methods", ["None"], ["", "def", "get_add_label", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "add_labels", "[", "index", "]", "\n", "if", "self", ".", "add_process_label", "is", "None", "\n", "else", "self", ".", "add_process_label", "(", "self", ".", "add_labels", "[", "index", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.__getitem__": [[52, 57], ["add_multi_dataset.AddMultiDataset.get_label", "add_multi_dataset.AddMultiDataset.get_add_label"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.get_label", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.get_add_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "item", "[", "\"label\"", "]", "=", "self", ".", "get_label", "(", "index", ")", "\n", "item", "[", "\"add_label\"", "]", "=", "self", ".", "get_add_label", "(", "index", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.size": [[58, 62], ["add_multi_dataset.AddMultiDataset.dataset.size", "len", "add_multi_dataset.AddMultiDataset.get_label"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.get_label"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "sz", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "own_sz", "=", "len", "(", "self", ".", "get_label", "(", "index", ")", ")", "\n", "return", "(", "sz", ",", "own_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_multi_dataset.AddMultiDataset.collater": [[63, 102], ["add_multi_dataset.AddMultiDataset.dataset.collater", "set", "len", "collated[].tolist", "torch.LongTensor", "data_utils.collate_tokens", "collated[].sum().item", "torch.LongTensor", "data_utils.collate_tokens", "collated[].sum().item", "sum", "sum", "data_utils.collate_tokens.new_full", "torch.cat().long", "torch.cat().long", "data_utils.collate_tokens.size", "data_utils.collate_tokens.new_full", "torch.cat().long", "torch.cat().long", "data_utils.collate_tokens.size", "len", "collated[].sum", "len", "collated[].sum", "len", "len", "data_utils.collate_tokens.size", "torch.cat", "torch.cat", "data_utils.collate_tokens.size", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.collater", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "collated", "=", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "if", "len", "(", "collated", ")", "==", "0", ":", "\n", "            ", "return", "collated", "\n", "", "indices", "=", "set", "(", "collated", "[", "\"id\"", "]", ".", "tolist", "(", ")", ")", "\n", "target", "=", "[", "s", "[", "\"label\"", "]", "for", "s", "in", "samples", "if", "s", "[", "\"id\"", "]", "in", "indices", "]", "\n", "add_target", "=", "[", "s", "[", "\"add_label\"", "]", "for", "s", "in", "samples", "if", "s", "[", "\"id\"", "]", "in", "indices", "]", "\n", "\n", "if", "self", ".", "batch_targets", ":", "\n", "            ", "collated", "[", "\"target_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "target", "=", "data_utils", ".", "collate_tokens", "(", "target", ",", "pad_idx", "=", "self", ".", "pad", ",", "left_pad", "=", "False", ")", "\n", "collated", "[", "\"ntokens\"", "]", "=", "collated", "[", "\"target_lengths\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "collated", "[", "\"add_target_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "t", ")", "for", "t", "in", "add_target", "]", ")", "\n", "add_target", "=", "data_utils", ".", "collate_tokens", "(", "add_target", ",", "pad_idx", "=", "self", ".", "add_pad", ",", "left_pad", "=", "False", ")", "\n", "collated", "[", "\"add_ntokens\"", "]", "=", "collated", "[", "\"add_target_lengths\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "collated", "[", "\"ntokens\"", "]", "=", "sum", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "collated", "[", "\"add_ntokens\"", "]", "=", "sum", "(", "[", "len", "(", "t", ")", "for", "t", "in", "add_target", "]", ")", "\n", "\n", "", "collated", "[", "\"target\"", "]", "=", "target", "\n", "collated", "[", "\"add_target\"", "]", "=", "add_target", "\n", "\n", "if", "self", ".", "add_to_input", ":", "\n", "            ", "eos", "=", "target", ".", "new_full", "(", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", ",", "self", ".", "eos", ")", "\n", "collated", "[", "\"target\"", "]", "=", "torch", ".", "cat", "(", "[", "target", ",", "eos", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "eos", ",", "target", "]", ",", "dim", "=", "-", "1", "\n", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"ntokens\"", "]", "+=", "target", ".", "size", "(", "0", ")", "\n", "\n", "add_eos", "=", "add_target", ".", "new_full", "(", "(", "add_target", ".", "size", "(", "0", ")", ",", "1", ")", ",", "self", ".", "add_eos", ")", "\n", "collated", "[", "\"add_target\"", "]", "=", "torch", ".", "cat", "(", "[", "add_target", ",", "add_eos", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"net_input\"", "]", "[", "\"prev_output_add_tokens\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "add_eos", ",", "add_target", "]", ",", "dim", "=", "-", "1", "\n", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"add_ntokens\"", "]", "+=", "add_target", ".", "size", "(", "0", ")", "\n", "\n", "", "return", "collated", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.__init__": [[41, 54], ["iter", "getattr", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "start", "=", "None", ",", "total", "=", "None", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "itr", "=", "iter", "(", "self", ")", "\n", "\n", "if", "start", "is", "None", ":", "\n", "            ", "self", ".", "n", "=", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "n", "=", "start", "\n", "\n", "", "if", "total", "is", "None", ":", "\n", "            ", "self", ".", "total", "=", "self", ".", "n", "+", "len", "(", "iterable", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "total", "=", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.__len__": [[55, 57], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.__iter__": [[58, 71], ["RuntimeError"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "iterable", ":", "\n", "            ", "if", "self", ".", "n", ">=", "self", ".", "total", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Mismatch between actual and expected iterable length. \"", "\n", "\"This may be caused by resuming training from a checkpoint using \"", "\n", "\"a different number of GPUs, in which case you can try the \"", "\n", "\"--reset-dataloader option. Alternatively you may have a train or \"", "\n", "\"validation set that is smaller than the number of GPUs. If none \"", "\n", "\"of these apply, please report this to the fairseq developers.\"", "\n", ")", "\n", "", "self", ".", "n", "+=", "1", "\n", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.__next__": [[72, 74], ["next"], "methods", ["None"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.has_next": [[75, 78], ["len"], "methods", ["None"], ["", "def", "has_next", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether the iterator has been exhausted.\"\"\"", "\n", "return", "self", ".", "n", "<", "len", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.skip": [[79, 83], ["next", "itertools.islice"], "methods", ["None"], ["", "def", "skip", "(", "self", ",", "num_to_skip", ")", ":", "\n", "        ", "\"\"\"Fast-forward the iterator by skipping *num_to_skip* elements.\"\"\"", "\n", "next", "(", "itertools", ".", "islice", "(", "self", ".", "itr", ",", "num_to_skip", ",", "num_to_skip", ")", ",", "None", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.take": [[84, 102], ["min", "max", "hasattr", "iterators.CountingIterator.iterable.take", "itertools.islice"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.take"], ["", "def", "take", "(", "self", ",", "n", ")", ":", "\n", "        ", "\"\"\"\n        Truncates the iterator to n elements at most.\n        \"\"\"", "\n", "self", ".", "total", "=", "min", "(", "self", ".", "total", ",", "n", ")", "\n", "\n", "# Propagate this change to the underlying iterator", "\n", "# Only take after what we have already consumed (i.e. after restarting", "\n", "# from checkpoint mid epoch, we have to subtract self.n which is the", "\n", "# starting point)", "\n", "#", "\n", "# This to maintain the invariant self.total = self.n + len(iterable),", "\n", "# before calling __next__ or __iter__", "\n", "propagated_take", "=", "max", "(", "n", "-", "self", ".", "n", ",", "0", ")", "\n", "if", "hasattr", "(", "self", ".", "iterable", ",", "\"take\"", ")", ":", "\n", "            ", "self", ".", "iterable", ".", "take", "(", "propagated_take", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "iterable", "=", "itertools", ".", "islice", "(", "self", ".", "iterable", ",", "propagated_take", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.__len__": [[105, 107], ["None"], "methods", ["None"], ["    ", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.next_epoch_idx": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.next_epoch_itr": [[112, 127], ["None"], "methods", ["None"], ["", "def", "next_epoch_itr", "(", "\n", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ",", "set_dataset_epoch", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus (bool, optional): ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n            set_dataset_epoch (bool, optional): update the wrapped Dataset with\n                the new epoch number (default: True).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.end_of_epoch": [[128, 131], ["None"], "methods", ["None"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.iterations_in_epoch": [[132, 136], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.state_dict": [[137, 140], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.load_state_dict": [[141, 144], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterating.first_batch": [[145, 148], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "first_batch", "(", "self", ")", ":", "\n", "        ", "return", "\"DUMMY\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.__init__": [[169, 191], ["isinstance", "max", "min"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_sentences", "=", "1", ",", "\n", "collate_fn", "=", "None", ",", "\n", "epoch", "=", "1", ",", "\n", "num_workers", "=", "0", ",", "\n", "buffer_size", "=", "0", ",", "\n", "timeout", "=", "0", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "IterableDataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "max_sentences", "=", "max_sentences", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "epoch", "=", "max", "(", "epoch", ",", "1", ")", "# we use 1-based indexing for epochs", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "# This upper limit here is to prevent people from abusing this feature", "\n", "# in a shared computing environment.", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "20", ")", "\n", "self", ".", "timeout", "=", "timeout", "\n", "\n", "self", ".", "_current_epoch_iterator", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.next_epoch_idx": [[192, 199], ["iterators.StreamingEpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the epoch index after *next_epoch_itr* is called.\"\"\"", "\n", "if", "self", ".", "_current_epoch_iterator", "is", "not", "None", "and", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "return", "self", ".", "epoch", "+", "1", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.next_epoch_itr": [[200, 208], ["iterators.StreamingEpochBatchIterator._get_iterator_for_epoch", "hasattr", "iterators.StreamingEpochBatchIterator.dataset.set_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator._get_iterator_for_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch"], ["", "", "def", "next_epoch_itr", "(", "\n", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ",", "set_dataset_epoch", "=", "True", "\n", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "self", ".", "next_epoch_idx", "\n", "if", "set_dataset_epoch", "and", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "", "self", ".", "_current_epoch_iterator", "=", "self", ".", "_get_iterator_for_epoch", "(", "self", ".", "epoch", ",", "shuffle", ")", "\n", "return", "self", ".", "_current_epoch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.end_of_epoch": [[209, 211], ["iterators.StreamingEpochBatchIterator._current_epoch_iterator.has_next"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "not", "self", ".", "_current_epoch_iterator", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.iterations_in_epoch": [[212, 217], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "if", "self", ".", "_current_epoch_iterator", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_current_epoch_iterator", ".", "n", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.state_dict": [[218, 221], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"epoch\"", ":", "self", ".", "epoch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator.load_state_dict": [[223, 225], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "state_dict", "[", "\"epoch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.StreamingEpochBatchIterator._get_iterator_for_epoch": [[226, 249], ["getattr", "torch.utils.data.DataLoader", "iterators.CountingIterator", "iterators.BufferedIterator"], "methods", ["None"], ["", "def", "_get_iterator_for_epoch", "(", "self", ",", "epoch", ",", "shuffle", ",", "offset", "=", "0", ")", ":", "\n", "        ", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "            ", "os", ".", "environ", "[", "\"PYTHONWARNINGS\"", "]", "=", "\"ignore:semaphore_tracker:UserWarning\"", "\n", "\n", "# Create data loader", "\n", "", "worker_init_fn", "=", "getattr", "(", "self", ".", "dataset", ",", "\"worker_init_fn\"", ",", "None", ")", "\n", "itr", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "batch_size", "=", "self", ".", "max_sentences", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "timeout", "=", "self", ".", "timeout", ",", "\n", "worker_init_fn", "=", "worker_init_fn", ",", "\n", ")", "\n", "\n", "# Wrap with a BufferedIterator if needed", "\n", "if", "self", ".", "buffer_size", ">", "0", ":", "\n", "            ", "itr", "=", "BufferedIterator", "(", "self", ".", "buffer_size", ",", "itr", ")", "\n", "\n", "# Wrap with CountingIterator", "\n", "", "itr", "=", "CountingIterator", "(", "itr", ",", "start", "=", "offset", ")", "\n", "\n", "return", "itr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.__init__": [[289, 325], ["isinstance", "min", "max", "getattr", "tuple", "callable"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "collate_fn", ",", "\n", "batch_sampler", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "buffer_size", "=", "0", ",", "\n", "timeout", "=", "0", ",", "\n", "disable_shuffling", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "self", ".", "_frozen_batches", "=", "(", "\n", "tuple", "(", "batch_sampler", ")", "if", "not", "callable", "(", "batch_sampler", ")", "else", "None", "\n", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_shards", "=", "num_shards", "\n", "self", ".", "shard_id", "=", "shard_id", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "# This upper limit here is to prevent people from abusing this feature", "\n", "# in a shared computing environment.", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "20", ")", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "disable_shuffling", "=", "disable_shuffling", "\n", "\n", "self", ".", "epoch", "=", "max", "(", "epoch", ",", "1", ")", "# we use 1-based indexing for epochs", "\n", "self", ".", "shuffle", "=", "not", "disable_shuffling", "\n", "self", ".", "_cur_epoch_itr", "=", "None", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "self", ".", "_supports_prefetch", "=", "getattr", "(", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.frozen_batches": [[326, 331], ["tuple", "iterators.EpochBatchIterator.batch_sampler"], "methods", ["None"], ["", "@", "property", "\n", "def", "frozen_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_frozen_batches", "is", "None", ":", "\n", "            ", "self", ".", "_frozen_batches", "=", "tuple", "(", "self", ".", "batch_sampler", "(", "self", ".", "dataset", ",", "self", ".", "epoch", ")", ")", "\n", "", "return", "self", ".", "_frozen_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.first_batch": [[332, 346], ["getattr", "len", "Exception", "iterators.EpochBatchIterator.collate_fn"], "methods", ["None"], ["", "@", "property", "\n", "def", "first_batch", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "frozen_batches", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"The dataset is empty. This could indicate \"", "\n", "\"that all elements in the dataset have been skipped. \"", "\n", "\"Try increasing the max number of allowed tokens or using \"", "\n", "\"a larger dataset.\"", "\n", ")", "\n", "\n", "", "if", "getattr", "(", "self", ".", "dataset", ",", "\"supports_fetch_outside_dataloader\"", ",", "True", ")", ":", "\n", "            ", "return", "self", ".", "collate_fn", "(", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "self", ".", "frozen_batches", "[", "0", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"DUMMY\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.__len__": [[347, 349], ["int", "math.ceil", "len", "float"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "frozen_batches", ")", "/", "float", "(", "self", ".", "num_shards", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.n": [[350, 353], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "iterations_in_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_idx": [[354, 363], ["iterators.EpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the epoch index after *next_epoch_itr* is called.\"\"\"", "\n", "if", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "", "elif", "self", ".", "_cur_epoch_itr", "is", "not", "None", "and", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "return", "self", ".", "epoch", "+", "1", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.next_epoch_itr": [[364, 397], ["hasattr", "iterators.EpochBatchIterator.dataset.set_epoch", "callable", "iterators.EpochBatchIterator._get_iterator_for_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator._get_iterator_for_epoch"], ["", "", "def", "next_epoch_itr", "(", "\n", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ",", "set_dataset_epoch", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus (bool, optional): ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n            set_dataset_epoch (bool, optional): update the wrapped Dataset with\n                the new epoch number (default: True).\n        \"\"\"", "\n", "if", "self", ".", "disable_shuffling", ":", "\n", "            ", "shuffle", "=", "False", "\n", "", "self", ".", "epoch", "=", "self", ".", "next_epoch_idx", "\n", "if", "set_dataset_epoch", "and", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "", "if", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_next_epoch_itr", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "callable", "(", "self", ".", "batch_sampler", ")", ":", "\n", "# reset _frozen_batches to refresh the next epoch", "\n", "                ", "self", ".", "_frozen_batches", "=", "None", "\n", "", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "\n", "shuffle", ",", "\n", "fix_batches_to_gpus", "=", "fix_batches_to_gpus", ",", "\n", ")", "\n", "", "self", ".", "shuffle", "=", "shuffle", "\n", "return", "self", ".", "_cur_epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.end_of_epoch": [[398, 401], ["iterators.EpochBatchIterator._cur_epoch_itr.has_next"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "return", "not", "self", ".", "_cur_epoch_itr", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.iterations_in_epoch": [[402, 410], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "if", "self", ".", "_cur_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_cur_epoch_itr", ".", "n", "\n", "", "elif", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_next_epoch_itr", ".", "n", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.state_dict": [[411, 424], ["iterators.EpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "if", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "epoch", "=", "self", ".", "epoch", "+", "1", "\n", "iter_in_epoch", "=", "0", "\n", "", "else", ":", "\n", "            ", "epoch", "=", "self", ".", "epoch", "\n", "iter_in_epoch", "=", "self", ".", "iterations_in_epoch", "\n", "", "return", "{", "\n", "\"version\"", ":", "2", ",", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"iterations_in_epoch\"", ":", "iter_in_epoch", ",", "\n", "\"shuffle\"", ":", "self", ".", "shuffle", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator.load_state_dict": [[426, 450], ["state_dict.get", "state_dict.get", "iterators.EpochBatchIterator._get_iterator_for_epoch", "state_dict.get", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator._get_iterator_for_epoch"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "self", ".", "epoch", "=", "state_dict", "[", "\"epoch\"", "]", "\n", "itr_pos", "=", "state_dict", ".", "get", "(", "\"iterations_in_epoch\"", ",", "0", ")", "\n", "version", "=", "state_dict", ".", "get", "(", "\"version\"", ",", "1", ")", "\n", "if", "itr_pos", ">", "0", ":", "\n", "# fast-forward epoch iterator", "\n", "            ", "self", ".", "_next_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "\n", "shuffle", "=", "state_dict", ".", "get", "(", "\"shuffle\"", ",", "True", ")", ",", "\n", "offset", "=", "itr_pos", ",", "\n", ")", "\n", "if", "self", ".", "_next_epoch_itr", "is", "None", ":", "\n", "                ", "if", "version", "==", "1", ":", "\n", "# legacy behavior: we finished the epoch, increment epoch counter", "\n", "                    ", "self", ".", "epoch", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Cannot resume training due to dataloader mismatch, please \"", "\n", "\"report this to the fairseq developers. You can relaunch \"", "\n", "\"training with `--reset-dataloader` and it should work.\"", "\n", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_next_epoch_itr", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.EpochBatchIterator._get_iterator_for_epoch": [[451, 503], ["torch.utils.data.DataLoader", "iterators.CountingIterator", "list", "iterators.EpochBatchIterator.dataset.prefetch", "list", "iterators.BufferedIterator", "fairseq.data.data_utils.numpy_seed", "numpy.random.shuffle", "iterators.EpochBatchIterator._get_iterator_for_epoch.shuffle_batches"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.prefetch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.shuffle"], ["", "", "def", "_get_iterator_for_epoch", "(", "\n", "self", ",", "epoch", ",", "shuffle", ",", "fix_batches_to_gpus", "=", "False", ",", "offset", "=", "0", "\n", ")", ":", "\n", "        ", "def", "shuffle_batches", "(", "batches", ",", "seed", ")", ":", "\n", "            ", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "return", "batches", "\n", "\n", "", "if", "self", ".", "_supports_prefetch", ":", "\n", "            ", "batches", "=", "self", ".", "frozen_batches", "\n", "\n", "if", "shuffle", "and", "not", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "\n", "", "batches", "=", "list", "(", "\n", "ShardedIterator", "(", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", ")", "\n", ")", "\n", "self", ".", "dataset", ".", "prefetch", "(", "[", "i", "for", "s", "in", "batches", "for", "i", "in", "s", "]", ")", "\n", "\n", "if", "shuffle", "and", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "batches", ",", "self", ".", "seed", "+", "epoch", "+", "self", ".", "shard_id", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "self", ".", "frozen_batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "batches", "=", "self", ".", "frozen_batches", "\n", "", "batches", "=", "list", "(", "\n", "ShardedIterator", "(", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", ")", "\n", ")", "\n", "\n", "", "if", "offset", ">", "0", "and", "offset", ">=", "len", "(", "batches", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "            ", "os", ".", "environ", "[", "\"PYTHONWARNINGS\"", "]", "=", "\"ignore:semaphore_tracker:UserWarning\"", "\n", "\n", "# Create data loader", "\n", "", "itr", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "\n", "batch_sampler", "=", "batches", "[", "offset", ":", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "timeout", "=", "self", ".", "timeout", ",", "\n", ")", "\n", "\n", "# Wrap with a BufferedIterator if needed", "\n", "if", "self", ".", "buffer_size", ">", "0", ":", "\n", "            ", "itr", "=", "BufferedIterator", "(", "self", ".", "buffer_size", ",", "itr", ")", "\n", "\n", "# Wrap with CountingIterator", "\n", "", "itr", "=", "CountingIterator", "(", "itr", ",", "start", "=", "offset", ")", "\n", "return", "itr", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.GroupedIterator.__init__": [[516, 524], ["iterators._chunk_iterator", "iterators.CountingIterator.__init__", "int", "int", "math.ceil", "math.ceil", "getattr", "float", "len", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators._chunk_iterator", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "chunk_size", ")", ":", "\n", "        ", "itr", "=", "_chunk_iterator", "(", "iterable", ",", "chunk_size", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "itr", ",", "\n", "start", "=", "int", "(", "math", ".", "ceil", "(", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "/", "float", "(", "chunk_size", ")", ")", ")", ",", "\n", "total", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "iterable", ")", "/", "float", "(", "chunk_size", ")", ")", ")", ",", "\n", ")", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.ShardedIterator.__init__": [[551, 567], ["int", "map", "iterators.CountingIterator.__init__", "ValueError", "math.ceil", "operator.itemgetter", "itertools.zip_longest", "range", "itertools.islice", "int", "len", "float", "len", "math.ceil", "getattr", "float"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "num_shards", ",", "shard_id", ",", "fill_value", "=", "None", ")", ":", "\n", "        ", "if", "shard_id", "<", "0", "or", "shard_id", ">=", "num_shards", ":", "\n", "            ", "raise", "ValueError", "(", "\"shard_id must be between 0 and num_shards\"", ")", "\n", "", "sharded_len", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "iterable", ")", "/", "float", "(", "num_shards", ")", ")", ")", "\n", "itr", "=", "map", "(", "\n", "operator", ".", "itemgetter", "(", "1", ")", ",", "\n", "itertools", ".", "zip_longest", "(", "\n", "range", "(", "sharded_len", ")", ",", "\n", "itertools", ".", "islice", "(", "iterable", ",", "shard_id", ",", "len", "(", "iterable", ")", ",", "num_shards", ")", ",", "\n", "fillvalue", "=", "fill_value", ",", "\n", ")", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "itr", ",", "\n", "start", "=", "int", "(", "math", ".", "ceil", "(", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "/", "float", "(", "num_shards", ")", ")", ")", ",", "\n", "total", "=", "sharded_len", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BackgroundConsumer.__init__": [[571, 578], ["threading.Thread.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "queue", ",", "source", ",", "max_len", ")", ":", "\n", "        ", "Thread", ".", "__init__", "(", "self", ")", "\n", "\n", "self", ".", "_queue", "=", "queue", "\n", "self", ".", "_source", "=", "source", "\n", "self", ".", "_max_len", "=", "max_len", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BackgroundConsumer.run": [[579, 593], ["iterators.BackgroundConsumer._queue.put", "iterators.BackgroundConsumer._queue.put", "iterators.BackgroundConsumer._queue.put"], "methods", ["None"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "item", "in", "self", ".", "_source", ":", "\n", "                ", "self", ".", "_queue", ".", "put", "(", "item", ")", "\n", "\n", "# Stop if we reached the maximum length", "\n", "self", ".", "count", "+=", "1", "\n", "if", "self", ".", "_max_len", "is", "not", "None", "and", "self", ".", "count", ">=", "self", ".", "_max_len", ":", "\n", "                    ", "break", "\n", "\n", "# Signal the consumer we are done.", "\n", "", "", "self", ".", "_queue", ".", "put", "(", "_sentinel", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "_queue", ".", "put", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.__init__": [[596, 605], ["queue.Queue", "time.time", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "iterable", ")", ":", "\n", "        ", "self", ".", "_queue", "=", "queue", ".", "Queue", "(", "size", ")", "\n", "self", ".", "_iterable", "=", "iterable", "\n", "self", ".", "_consumer", "=", "None", "\n", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "warning_time", "=", "None", "\n", "\n", "self", ".", "total", "=", "len", "(", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator._create_consumer": [[606, 614], ["iterators.BackgroundConsumer", "iterators.BufferedIterator._consumer.start"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.meters.StopwatchMeter.start"], ["", "def", "_create_consumer", "(", "self", ")", ":", "\n", "        ", "self", ".", "_consumer", "=", "BackgroundConsumer", "(", "\n", "self", ".", "_queue", ",", "\n", "self", ".", "_iterable", ",", "\n", "self", ".", "total", ",", "\n", ")", "\n", "self", ".", "_consumer", ".", "daemon", "=", "True", "\n", "self", ".", "_consumer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.__iter__": [[615, 617], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.__len__": [[618, 620], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.take": [[621, 627], ["min", "hasattr", "iterators.BufferedIterator._iterable.take"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.take"], ["", "def", "take", "(", "self", ",", "n", ")", ":", "\n", "        ", "self", ".", "total", "=", "min", "(", "self", ".", "total", ",", "n", ")", "\n", "\n", "# Propagate this change to the underlying iterator", "\n", "if", "hasattr", "(", "self", ".", "_iterable", ",", "\"take\"", ")", ":", "\n", "            ", "self", ".", "_iterable", ".", "take", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator.__next__": [[628, 654], ["iterators.BufferedIterator._queue.get", "isinstance", "iterators.BufferedIterator._create_consumer", "iterators.BufferedIterator._queue.qsize", "min", "StopIteration", "max", "time.time", "logger.debug", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators.BufferedIterator._create_consumer"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "# Create consumer if not created yet", "\n", "        ", "if", "self", ".", "_consumer", "is", "None", ":", "\n", "            ", "self", ".", "_create_consumer", "(", ")", "\n", "\n", "# Notify the user if there is a data loading bottleneck", "\n", "", "if", "self", ".", "_queue", ".", "qsize", "(", ")", "<", "min", "(", "2", ",", "max", "(", "1", ",", "self", ".", "_queue", ".", "maxsize", "//", "2", ")", ")", ":", "\n", "            ", "if", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ">", "5", "*", "60", ":", "\n", "                ", "if", "(", "\n", "self", ".", "warning_time", "is", "None", "\n", "or", "time", ".", "time", "(", ")", "-", "self", ".", "warning_time", ">", "15", "*", "60", "\n", ")", ":", "\n", "                    ", "logger", ".", "debug", "(", "\n", "\"Data loading buffer is empty or nearly empty. This may \"", "\n", "\"indicate a data loading bottleneck, and increasing the \"", "\n", "\"number of workers (--num-workers) may help.\"", "\n", ")", "\n", "self", ".", "warning_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get next example", "\n", "", "", "", "item", "=", "self", ".", "_queue", ".", "get", "(", "True", ")", "\n", "if", "isinstance", "(", "item", ",", "Exception", ")", ":", "\n", "            ", "raise", "item", "\n", "", "if", "item", "is", "_sentinel", ":", "\n", "            ", "raise", "StopIteration", "(", ")", "\n", "", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.iterators._chunk_iterator": [[526, 535], ["chunk.append", "len", "len"], "function", ["None"], ["", "", "def", "_chunk_iterator", "(", "itr", ",", "chunk_size", ")", ":", "\n", "    ", "chunk", "=", "[", "]", "\n", "for", "x", "in", "itr", ":", "\n", "        ", "chunk", ".", "append", "(", "x", ")", "\n", "if", "len", "(", "chunk", ")", "==", "chunk_size", ":", "\n", "            ", "yield", "chunk", "\n", "chunk", "=", "[", "]", "\n", "", "", "if", "len", "(", "chunk", ")", ">", "0", ":", "\n", "        ", "yield", "chunk", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.infer_language_pair": [[24, 32], ["os.listdir", "filename.split", "parts[].split", "len", "len", "parts[].split"], "function", ["None"], ["def", "infer_language_pair", "(", "path", ")", ":", "\n", "    ", "\"\"\"Infer language pair from filename: <split>.<lang1>-<lang2>.(...).idx\"\"\"", "\n", "src", ",", "dst", "=", "None", ",", "None", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "        ", "parts", "=", "filename", ".", "split", "(", "\".\"", ")", "\n", "if", "len", "(", "parts", ")", ">=", "3", "and", "len", "(", "parts", "[", "1", "]", ".", "split", "(", "\"-\"", ")", ")", "==", "2", ":", "\n", "            ", "return", "parts", "[", "1", "]", ".", "split", "(", "\"-\"", ")", "\n", "", "", "return", "src", ",", "dst", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens": [[34, 65], ["max", "values[].new().fill_", "enumerate", "max", "int", "data_utils.collate_tokens.copy_tensor"], "function", ["None"], ["", "def", "collate_tokens", "(", "\n", "values", ",", "\n", "pad_idx", ",", "\n", "eos_idx", "=", "None", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", "pad_to_length", "=", "None", ",", "\n", "pad_to_multiple", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Convert a list of 1d tensors into a padded 2d tensor.\"\"\"", "\n", "size", "=", "max", "(", "v", ".", "size", "(", "0", ")", "for", "v", "in", "values", ")", "\n", "size", "=", "size", "if", "pad_to_length", "is", "None", "else", "max", "(", "size", ",", "pad_to_length", ")", "\n", "if", "pad_to_multiple", "!=", "1", "and", "size", "%", "pad_to_multiple", "!=", "0", ":", "\n", "        ", "size", "=", "int", "(", "(", "(", "size", "-", "0.1", ")", "//", "pad_to_multiple", "+", "1", ")", "*", "pad_to_multiple", ")", "\n", "", "res", "=", "values", "[", "0", "]", ".", "new", "(", "len", "(", "values", ")", ",", "size", ")", ".", "fill_", "(", "pad_idx", ")", "\n", "\n", "def", "copy_tensor", "(", "src", ",", "dst", ")", ":", "\n", "        ", "assert", "dst", ".", "numel", "(", ")", "==", "src", ".", "numel", "(", ")", "\n", "if", "move_eos_to_beginning", ":", "\n", "            ", "if", "eos_idx", "is", "None", ":", "\n", "# if no eos_idx is specified, then use the last token in src", "\n", "                ", "dst", "[", "0", "]", "=", "src", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "dst", "[", "0", "]", "=", "eos_idx", "\n", "", "dst", "[", "1", ":", "]", "=", "src", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "dst", ".", "copy_", "(", "src", ")", "\n", "\n", "", "", "for", "i", ",", "v", "in", "enumerate", "(", "values", ")", ":", "\n", "        ", "copy_tensor", "(", "v", ",", "res", "[", "i", "]", "[", "size", "-", "len", "(", "v", ")", ":", "]", "if", "left_pad", "else", "res", "[", "i", "]", "[", ":", "len", "(", "v", ")", "]", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.load_indexed_dataset": [[67, 112], ["itertools.count", "indexed_dataset.get_indexed_dataset_to_local", "indexed_dataset.make_dataset", "logger.info", "datasets.append", "len", "indexed_dataset.infer_dataset_impl", "len", "ConcatDataset", "str", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.get_indexed_dataset_to_local", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.make_dataset", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.infer_dataset_impl"], ["", "def", "load_indexed_dataset", "(", "\n", "path", ",", "dictionary", "=", "None", ",", "dataset_impl", "=", "None", ",", "combine", "=", "False", ",", "default", "=", "\"cached\"", "\n", ")", ":", "\n", "    ", "\"\"\"A helper function for loading indexed datasets.\n\n    Args:\n        path (str): path to indexed dataset (e.g., 'data-bin/train')\n        dictionary (~fairseq.data.Dictionary): data dictionary\n        dataset_impl (str, optional): which dataset implementation to use. If\n            not provided, it will be inferred automatically. For legacy indexed\n            data we use the 'cached' implementation by default.\n        combine (bool, optional): automatically load and combine multiple\n            datasets. For example, if *path* is 'data-bin/train', then we will\n            combine 'data-bin/train', 'data-bin/train1', ... and return a\n            single ConcatDataset instance.\n    \"\"\"", "\n", "import", "fairseq", ".", "data", ".", "indexed_dataset", "as", "indexed_dataset", "\n", "from", "fairseq", ".", "data", ".", "concat_dataset", "import", "ConcatDataset", "\n", "\n", "datasets", "=", "[", "]", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "        ", "path_k", "=", "path", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "path_k", "=", "indexed_dataset", ".", "get_indexed_dataset_to_local", "(", "path_k", ")", "\n", "\n", "dataset_impl_k", "=", "dataset_impl", "\n", "if", "dataset_impl_k", "is", "None", ":", "\n", "            ", "dataset_impl_k", "=", "indexed_dataset", ".", "infer_dataset_impl", "(", "path_k", ")", "\n", "", "dataset", "=", "indexed_dataset", ".", "make_dataset", "(", "\n", "path_k", ",", "\n", "impl", "=", "dataset_impl_k", "or", "default", ",", "\n", "fix_lua_indexing", "=", "True", ",", "\n", "dictionary", "=", "dictionary", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "break", "\n", "", "logger", ".", "info", "(", "\"loaded {:,} examples from: {}\"", ".", "format", "(", "len", "(", "dataset", ")", ",", "path_k", ")", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "if", "not", "combine", ":", "\n", "            ", "break", "\n", "", "", "if", "len", "(", "datasets", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "elif", "len", "(", "datasets", ")", "==", "1", ":", "\n", "        ", "return", "datasets", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "ConcatDataset", "(", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.numpy_seed": [[114, 129], ["numpy.random.get_state", "numpy.random.seed", "len", "int", "numpy.random.set_state", "hash"], "function", ["None"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "numpy_seed", "(", "seed", ",", "*", "addl_seeds", ")", ":", "\n", "    ", "\"\"\"Context manager which seeds the NumPy PRNG with the specified seed and\n    restores the state afterward\"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "        ", "yield", "\n", "return", "\n", "", "if", "len", "(", "addl_seeds", ")", ">", "0", ":", "\n", "        ", "seed", "=", "int", "(", "hash", "(", "(", "seed", ",", "*", "addl_seeds", ")", ")", "%", "1e6", ")", "\n", "", "state", "=", "np", ".", "random", ".", "get_state", "(", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "np", ".", "random", ".", "set_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collect_filtered": [[131, 146], ["function", "filtered.append"], "function", ["None"], ["", "", "def", "collect_filtered", "(", "function", ",", "iterable", ",", "filtered", ")", ":", "\n", "    ", "\"\"\"\n    Similar to :func:`filter` but collects filtered elements in ``filtered``.\n\n    Args:\n        function (callable): function that returns ``False`` for elements that\n            should be filtered\n        iterable (iterable): iterable to filter\n        filtered (list): list to store filtered elements\n    \"\"\"", "\n", "for", "el", "in", "iterable", ":", "\n", "        ", "if", "function", "(", "el", ")", ":", "\n", "            ", "yield", "el", "\n", "", "else", ":", "\n", "            ", "filtered", ".", "append", "(", "el", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils._filter_by_size_dynamic": [[148, 185], ["data_utils.collect_filtered", "numpy.fromiter", "isinstance", "isinstance", "isinstance", "isinstance", "max", "size_fn", "size_fn", "isinstance", "all", "all", "set", "set", "isinstance", "isinstance", "all", "isinstance", "all", "max_positions.keys", "size_fn.keys", "all", "size_fn", "size_fn", "zip", "data_utils._filter_by_size_dynamic.compare_leq"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collect_filtered"], ["", "", "", "def", "_filter_by_size_dynamic", "(", "indices", ",", "size_fn", ",", "max_positions", ",", "raise_exception", "=", "False", ")", ":", "\n", "    ", "def", "compare_leq", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", "<=", "b", "if", "not", "isinstance", "(", "a", ",", "tuple", ")", "else", "max", "(", "a", ")", "<=", "b", "\n", "\n", "", "def", "check_size", "(", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "max_positions", ",", "float", ")", "or", "isinstance", "(", "max_positions", ",", "int", ")", ":", "\n", "            ", "return", "size_fn", "(", "idx", ")", "<=", "max_positions", "\n", "", "elif", "isinstance", "(", "max_positions", ",", "dict", ")", ":", "\n", "            ", "idx_size", "=", "size_fn", "(", "idx", ")", "\n", "assert", "isinstance", "(", "idx_size", ",", "dict", ")", "\n", "intersect_keys", "=", "set", "(", "max_positions", ".", "keys", "(", ")", ")", "&", "set", "(", "idx_size", ".", "keys", "(", ")", ")", "\n", "return", "all", "(", "\n", "all", "(", "\n", "a", "is", "None", "or", "b", "is", "None", "or", "a", "<=", "b", "\n", "for", "a", ",", "b", "in", "zip", "(", "idx_size", "[", "key", "]", ",", "max_positions", "[", "key", "]", ")", "\n", ")", "\n", "for", "key", "in", "intersect_keys", "\n", ")", "\n", "", "else", ":", "\n", "# Hacky as heck, for the specific case of multilingual training with RoundRobin.", "\n", "            ", "if", "isinstance", "(", "size_fn", "(", "idx", ")", ",", "dict", ")", "and", "isinstance", "(", "max_positions", ",", "tuple", ")", ":", "\n", "                ", "return", "all", "(", "\n", "a", "is", "None", "or", "b", "is", "None", "or", "compare_leq", "(", "a", ",", "b", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "size_fn", "(", "idx", ")", ".", "values", "(", ")", ",", "max_positions", ")", "\n", ")", "\n", "# For MultiCorpusSampledDataset, will generalize it later", "\n", "", "if", "not", "isinstance", "(", "size_fn", "(", "idx", ")", ",", "Iterable", ")", ":", "\n", "                ", "return", "all", "(", "size_fn", "(", "idx", ")", "<=", "b", "for", "b", "in", "max_positions", ")", "\n", "", "return", "all", "(", "\n", "a", "is", "None", "or", "b", "is", "None", "or", "a", "<=", "b", "\n", "for", "a", ",", "b", "in", "zip", "(", "size_fn", "(", "idx", ")", ",", "max_positions", ")", "\n", ")", "\n", "\n", "", "", "ignored", "=", "[", "]", "\n", "itr", "=", "collect_filtered", "(", "check_size", ",", "indices", ",", "ignored", ")", "\n", "indices", "=", "np", ".", "fromiter", "(", "itr", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "-", "1", ")", "\n", "return", "indices", ",", "ignored", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.filter_by_size": [[187, 238], ["warnings.warn", "isinstance", "isinstance", "data_utils._filter_by_size_dynamic", "Exception", "len", "logger.warning", "hasattr", "isinstance", "indices[].tolist", "len", "hasattr", "isinstance", "indices[].tolist", "data_utils._filter_by_size_dynamic", "dataset.size", "len", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "filter_by_size", "(", "indices", ",", "dataset", ",", "max_positions", ",", "raise_exception", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    [deprecated] Filter indices based on their size.\n    Use `FairseqDataset::filter_indices_by_size` instead.\n\n    Args:\n        indices (List[int]): ordered list of dataset indices\n        dataset (FairseqDataset): fairseq dataset instance\n        max_positions (tuple): filter elements larger than this size.\n            Comparisons are done component-wise.\n        raise_exception (bool, optional): if ``True``, raise an exception if\n            any elements are filtered (default: False).\n    \"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "\"data_utils.filter_by_size is deprecated. \"", "\n", "\"Use `FairseqDataset::filter_indices_by_size` instead.\"", ",", "\n", "stacklevel", "=", "2", ",", "\n", ")", "\n", "if", "isinstance", "(", "max_positions", ",", "float", ")", "or", "isinstance", "(", "max_positions", ",", "int", ")", ":", "\n", "        ", "if", "hasattr", "(", "dataset", ",", "\"sizes\"", ")", "and", "isinstance", "(", "dataset", ".", "sizes", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "ignored", "=", "indices", "[", "dataset", ".", "sizes", "[", "indices", "]", ">", "max_positions", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "dataset", ".", "sizes", "[", "indices", "]", "<=", "max_positions", "]", "\n", "", "elif", "(", "\n", "hasattr", "(", "dataset", ",", "\"sizes\"", ")", "\n", "and", "isinstance", "(", "dataset", ".", "sizes", ",", "list", ")", "\n", "and", "len", "(", "dataset", ".", "sizes", ")", "==", "1", "\n", ")", ":", "\n", "            ", "ignored", "=", "indices", "[", "dataset", ".", "sizes", "[", "0", "]", "[", "indices", "]", ">", "max_positions", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "dataset", ".", "sizes", "[", "0", "]", "[", "indices", "]", "<=", "max_positions", "]", "\n", "", "else", ":", "\n", "            ", "indices", ",", "ignored", "=", "_filter_by_size_dynamic", "(", "\n", "indices", ",", "dataset", ".", "size", ",", "max_positions", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "indices", ",", "ignored", "=", "_filter_by_size_dynamic", "(", "indices", ",", "dataset", ".", "size", ",", "max_positions", ")", "\n", "\n", "", "if", "len", "(", "ignored", ")", ">", "0", "and", "raise_exception", ":", "\n", "        ", "raise", "Exception", "(", "\n", "(", "\n", "\"Size of sample #{} is invalid (={}) since max_positions={}, \"", "\n", "\"skip this example with --skip-invalid-size-inputs-valid-test\"", "\n", ")", ".", "format", "(", "ignored", "[", "0", "]", ",", "dataset", ".", "size", "(", "ignored", "[", "0", "]", ")", ",", "max_positions", ")", "\n", ")", "\n", "", "if", "len", "(", "ignored", ")", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "(", "\n", "\"{} samples have invalid sizes and will be skipped, \"", "\n", "\"max_positions={}, first few sample ids={}\"", "\n", ")", ".", "format", "(", "len", "(", "ignored", ")", ",", "max_positions", ",", "ignored", "[", ":", "10", "]", ")", "\n", ")", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.filter_paired_dataset_indices_by_size": [[240, 274], ["type", "len", "ignored.tolist"], "function", ["None"], ["", "def", "filter_paired_dataset_indices_by_size", "(", "src_sizes", ",", "tgt_sizes", ",", "indices", ",", "max_sizes", ")", ":", "\n", "    ", "\"\"\"Filter a list of sample indices. Remove those that are longer\n        than specified in max_sizes.\n\n    Args:\n        indices (np.array): original array of sample indices\n        max_sizes (int or list[int] or tuple[int]): max sample size,\n            can be defined separately for src and tgt (then list or tuple)\n\n    Returns:\n        np.array: filtered sample array\n        list: list of removed indices\n    \"\"\"", "\n", "if", "max_sizes", "is", "None", ":", "\n", "        ", "return", "indices", ",", "[", "]", "\n", "", "if", "type", "(", "max_sizes", ")", "in", "(", "int", ",", "float", ")", ":", "\n", "        ", "max_src_size", ",", "max_tgt_size", "=", "max_sizes", ",", "max_sizes", "\n", "", "else", ":", "\n", "        ", "max_src_size", ",", "max_tgt_size", "=", "max_sizes", "\n", "", "if", "tgt_sizes", "is", "None", ":", "\n", "        ", "ignored", "=", "indices", "[", "src_sizes", "[", "indices", "]", ">", "max_src_size", "]", "\n", "", "else", ":", "\n", "        ", "ignored", "=", "indices", "[", "\n", "(", "src_sizes", "[", "indices", "]", ">", "max_src_size", ")", "|", "(", "tgt_sizes", "[", "indices", "]", ">", "max_tgt_size", ")", "\n", "]", "\n", "", "if", "len", "(", "ignored", ")", ">", "0", ":", "\n", "        ", "if", "tgt_sizes", "is", "None", ":", "\n", "            ", "indices", "=", "indices", "[", "src_sizes", "[", "indices", "]", "<=", "max_src_size", "]", "\n", "", "else", ":", "\n", "            ", "indices", "=", "indices", "[", "\n", "(", "src_sizes", "[", "indices", "]", "<=", "max_src_size", ")", "\n", "&", "(", "tgt_sizes", "[", "indices", "]", "<=", "max_tgt_size", ")", "\n", "]", "\n", "", "", "return", "indices", ",", "ignored", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.batch_by_size": [[276, 355], ["isinstance", "numpy.fromiter", "numpy.fromiter", "numpy.array", "numpy.lexsort", "batch_fixed_shapes_fast", "ImportError", "isinstance", "batch_by_size_fn", "batch_by_size_vec", "fixed_shapes[].argsort", "fixed_shapes[].argsort"], "function", ["None"], ["", "def", "batch_by_size", "(", "\n", "indices", ",", "\n", "num_tokens_fn", ",", "\n", "num_tokens_vec", "=", "None", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "fixed_shapes", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Yield mini-batches of indices bucketed by size. Batches may contain\n    sequences of different lengths.\n\n    Args:\n        indices (List[int]): ordered list of dataset indices\n        num_tokens_fn (callable): function that returns the number of tokens at\n            a given index\n        num_tokens_vec (List[int], optional): precomputed vector of the number\n            of tokens for each index in indices (to enable faster batch generation)\n        max_tokens (int, optional): max number of tokens in each batch\n            (default: None).\n        max_sentences (int, optional): max number of sentences in each\n            batch (default: None).\n        required_batch_size_multiple (int, optional): require batch size to\n            be less than N or a multiple of N (default: 1).\n        fixed_shapes (List[Tuple[int, int]], optional): if given, batches will\n            only be created with the given shapes. *max_sentences* and\n            *required_batch_size_multiple* will be ignored (default: None).\n    \"\"\"", "\n", "try", ":", "\n", "        ", "from", "fairseq", ".", "data", ".", "data_utils_fast", "import", "(", "\n", "batch_by_size_fn", ",", "\n", "batch_by_size_vec", ",", "\n", "batch_fixed_shapes_fast", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"Please build Cython components with: `pip install --editable .` \"", "\n", "\"or `python setup.py build_ext --inplace`\"", "\n", ")", "\n", "\n", "", "max_tokens", "=", "max_tokens", "if", "max_tokens", "is", "not", "None", "else", "-", "1", "\n", "max_sentences", "=", "max_sentences", "if", "max_sentences", "is", "not", "None", "else", "-", "1", "\n", "bsz_mult", "=", "required_batch_size_multiple", "\n", "\n", "if", "not", "isinstance", "(", "indices", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "indices", "=", "np", ".", "fromiter", "(", "indices", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "-", "1", ")", "\n", "\n", "", "if", "num_tokens_vec", "is", "not", "None", "and", "not", "isinstance", "(", "num_tokens_vec", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "num_tokens_vec", "=", "np", ".", "fromiter", "(", "num_tokens_vec", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "-", "1", ")", "\n", "\n", "", "if", "fixed_shapes", "is", "None", ":", "\n", "        ", "if", "num_tokens_vec", "is", "None", ":", "\n", "            ", "return", "batch_by_size_fn", "(", "\n", "indices", ",", "\n", "num_tokens_fn", ",", "\n", "max_tokens", ",", "\n", "max_sentences", ",", "\n", "bsz_mult", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "batch_by_size_vec", "(", "\n", "indices", ",", "\n", "num_tokens_vec", ",", "\n", "max_tokens", ",", "\n", "max_sentences", ",", "\n", "bsz_mult", ",", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "fixed_shapes", "=", "np", ".", "array", "(", "fixed_shapes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "sort_order", "=", "np", ".", "lexsort", "(", "\n", "[", "\n", "fixed_shapes", "[", ":", ",", "1", "]", ".", "argsort", "(", ")", ",", "# length", "\n", "fixed_shapes", "[", ":", ",", "0", "]", ".", "argsort", "(", ")", ",", "# bsz", "\n", "]", "\n", ")", "\n", "fixed_shapes_sorted", "=", "fixed_shapes", "[", "sort_order", "]", "\n", "return", "batch_fixed_shapes_fast", "(", "indices", ",", "num_tokens_fn", ",", "fixed_shapes_sorted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process": [[357, 375], ["sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace", "NotImplementedError", "sentence.replace().replace().strip.replace"], "function", ["None"], ["", "", "def", "post_process", "(", "sentence", ":", "str", ",", "symbol", ":", "str", ")", ":", "\n", "    ", "if", "symbol", "==", "\"sentencepiece\"", ":", "\n", "        ", "sentence", "=", "sentence", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"\\u2581\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "elif", "symbol", "==", "\"wordpiece\"", ":", "\n", "        ", "sentence", "=", "sentence", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "elif", "symbol", "==", "\"letter\"", ":", "\n", "        ", "sentence", "=", "sentence", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"|\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "elif", "symbol", "==", "\"_EOW\"", ":", "\n", "        ", "sentence", "=", "sentence", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"_EOW\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "elif", "symbol", "in", "{", "\"subword_nmt\"", ",", "\"@@ \"", ",", "\"@@\"", "}", ":", "\n", "        ", "if", "symbol", "==", "\"subword_nmt\"", ":", "\n", "            ", "symbol", "=", "\"@@ \"", "\n", "", "sentence", "=", "(", "sentence", "+", "\" \"", ")", ".", "replace", "(", "symbol", ",", "\"\"", ")", ".", "rstrip", "(", ")", "\n", "", "elif", "symbol", "==", "\"none\"", ":", "\n", "        ", "pass", "\n", "", "elif", "symbol", "is", "not", "None", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unknown post_process option: {symbol}\"", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.get_sep_token": [[376, 394], ["NotImplementedError"], "function", ["None"], ["", "def", "get_sep_token", "(", "symbol", ":", "str", ")", ":", "\n", "    ", "if", "symbol", "==", "\"sentencepiece\"", ":", "\n", "        ", "sentence", "=", "\"\\u2581\"", "\n", "", "elif", "symbol", "==", "\"wordpiece\"", ":", "\n", "        ", "sentence", "=", "\"_\"", "\n", "", "elif", "symbol", "==", "\"letter\"", ":", "\n", "        ", "sentence", "=", "\"|\"", "\n", "", "elif", "symbol", "==", "\"_EOW\"", ":", "\n", "        ", "sentence", "=", "\"_EOW\"", "\n", "", "elif", "symbol", "in", "{", "\"subword_nmt\"", ",", "\"@@ \"", ",", "\"@@\"", "}", ":", "\n", "        ", "if", "symbol", "==", "\"subword_nmt\"", ":", "\n", "            ", "symbol", "=", "\"@@ \"", "\n", "", "sentence", "=", "symbol", "\n", "", "elif", "symbol", "==", "\"none\"", ":", "\n", "        ", "pass", "\n", "", "elif", "symbol", "is", "not", "None", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unknown post_process option: {symbol}\"", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.sudo_process": [[395, 398], ["None"], "function", ["None"], ["", "def", "sudo_process", "(", "tokens", ",", "sep_token_idx", ")", ":", "\n", "## \ub9e8 \uc55e\uc5d0 SEP token \uc81c\uac70", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.compute_mask_indices": [[402, 530], ["numpy.full", "int", "max", "range", "min", "enumerate", "mask_idcs.append", "numpy.random.rand", "int", "max", "numpy.full", "sum", "min", "min", "sorted", "numpy.asarray", "min", "numpy.random.choice", "numpy.asarray", "numpy.unique", "len", "len", "numpy.random.choice", "float", "padding_mask[].long().sum().item", "numpy.random.randint", "numpy.random.randint", "np.random.choice.extend", "numpy.fromiter", "numpy.sum", "numpy.random.choice", "parts.pop", "parts.extend", "numpy.random.rand", "numpy.random.normal", "new_parts.append", "new_parts.append", "numpy.sum", "len", "data_utils.compute_mask_indices.arrange"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "def", "compute_mask_indices", "(", "\n", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", ",", "\n", "mask_prob", ":", "float", ",", "\n", "mask_length", ":", "int", ",", "\n", "mask_type", ":", "str", "=", "\"static\"", ",", "\n", "mask_other", ":", "float", "=", "0.0", ",", "\n", "min_masks", ":", "int", "=", "0", ",", "\n", "no_overlap", ":", "bool", "=", "False", ",", "\n", "min_space", ":", "int", "=", "0", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Computes random mask spans for a given shape\n\n    Args:\n        shape: the the shape for which to compute masks.\n            should be of size 2 where first element is batch size and 2nd is timesteps\n        padding_mask: optional padding mask of the same size as shape, which will prevent masking padded elements\n        mask_prob: probability for each token to be chosen as start of the span to be masked. this will be multiplied by\n            number of timesteps divided by length of mask span to mask approximately this percentage of all elements.\n            however due to overlaps, the actual number will be smaller (unless no_overlap is True)\n        mask_type: how to compute mask lengths\n            static = fixed size\n            uniform = sample from uniform distribution [mask_other, mask_length*2]\n            normal = sample from normal distribution with mean mask_length and stdev mask_other. mask is min 1 element\n            poisson = sample from possion distribution with lambda = mask length\n        min_masks: minimum number of masked spans\n        no_overlap: if false, will switch to an alternative recursive algorithm that prevents spans from overlapping\n        min_space: only used if no_overlap is True, this is how many elements to keep unmasked between spans\n    \"\"\"", "\n", "\n", "bsz", ",", "all_sz", "=", "shape", "\n", "mask", "=", "np", ".", "full", "(", "(", "bsz", ",", "all_sz", ")", ",", "False", ")", "\n", "\n", "all_num_mask", "=", "int", "(", "\n", "# add a random number for probabilistic rounding", "\n", "mask_prob", "*", "all_sz", "/", "float", "(", "mask_length", ")", "\n", "+", "np", ".", "random", ".", "rand", "(", ")", "\n", ")", "\n", "\n", "all_num_mask", "=", "max", "(", "min_masks", ",", "all_num_mask", ")", "\n", "\n", "if", "all_num_mask", "==", "0", ":", "\n", "        ", "return", "mask", "\n", "\n", "", "mask_idcs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "        ", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "sz", "=", "all_sz", "-", "padding_mask", "[", "i", "]", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_mask", "=", "int", "(", "\n", "# add a random number for probabilistic rounding", "\n", "mask_prob", "*", "sz", "/", "float", "(", "mask_length", ")", "\n", "+", "np", ".", "random", ".", "rand", "(", ")", "\n", ")", "\n", "num_mask", "=", "max", "(", "min_masks", ",", "num_mask", ")", "\n", "", "else", ":", "\n", "            ", "sz", "=", "all_sz", "\n", "num_mask", "=", "all_num_mask", "\n", "\n", "", "if", "mask_type", "==", "\"static\"", ":", "\n", "            ", "lengths", "=", "np", ".", "full", "(", "num_mask", ",", "mask_length", ")", "\n", "", "elif", "mask_type", "==", "\"uniform\"", ":", "\n", "            ", "lengths", "=", "np", ".", "random", ".", "randint", "(", "mask_other", ",", "mask_length", "*", "2", "+", "1", ",", "size", "=", "num_mask", ")", "\n", "", "elif", "mask_type", "==", "\"normal\"", ":", "\n", "            ", "lengths", "=", "np", ".", "random", ".", "normal", "(", "mask_length", ",", "mask_other", ",", "size", "=", "num_mask", ")", "\n", "lengths", "=", "[", "max", "(", "1", ",", "int", "(", "round", "(", "x", ")", ")", ")", "for", "x", "in", "lengths", "]", "\n", "", "elif", "mask_type", "==", "\"poisson\"", ":", "\n", "            ", "lengths", "=", "np", ".", "random", ".", "poisson", "(", "mask_length", ",", "size", "=", "num_mask", ")", "\n", "lengths", "=", "[", "int", "(", "round", "(", "x", ")", ")", "for", "x", "in", "lengths", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unknown mask selection \"", "+", "mask_type", ")", "\n", "\n", "", "if", "sum", "(", "lengths", ")", "==", "0", ":", "\n", "            ", "lengths", "[", "0", "]", "=", "min", "(", "mask_length", ",", "sz", "-", "1", ")", "\n", "\n", "", "if", "no_overlap", ":", "\n", "            ", "mask_idc", "=", "[", "]", "\n", "\n", "def", "arrange", "(", "s", ",", "e", ",", "length", ",", "keep_length", ")", ":", "\n", "                ", "span_start", "=", "np", ".", "random", ".", "randint", "(", "s", ",", "e", "-", "length", ")", "\n", "mask_idc", ".", "extend", "(", "span_start", "+", "i", "for", "i", "in", "range", "(", "length", ")", ")", "\n", "\n", "new_parts", "=", "[", "]", "\n", "if", "span_start", "-", "s", "-", "min_space", ">=", "keep_length", ":", "\n", "                    ", "new_parts", ".", "append", "(", "(", "s", ",", "span_start", "-", "min_space", "+", "1", ")", ")", "\n", "", "if", "e", "-", "span_start", "-", "keep_length", "-", "min_space", ">", "keep_length", ":", "\n", "                    ", "new_parts", ".", "append", "(", "(", "span_start", "+", "length", "+", "min_space", ",", "e", ")", ")", "\n", "", "return", "new_parts", "\n", "\n", "", "parts", "=", "[", "(", "0", ",", "sz", ")", "]", "\n", "min_length", "=", "min", "(", "lengths", ")", "\n", "for", "length", "in", "sorted", "(", "lengths", ",", "reverse", "=", "True", ")", ":", "\n", "                ", "lens", "=", "np", ".", "fromiter", "(", "\n", "(", "e", "-", "s", "if", "e", "-", "s", ">=", "length", "+", "min_space", "else", "0", "for", "s", ",", "e", "in", "parts", ")", ",", "\n", "np", ".", "int", ",", "\n", ")", "\n", "l_sum", "=", "np", ".", "sum", "(", "lens", ")", "\n", "if", "l_sum", "==", "0", ":", "\n", "                    ", "break", "\n", "", "probs", "=", "lens", "/", "np", ".", "sum", "(", "lens", ")", "\n", "c", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "parts", ")", ",", "p", "=", "probs", ")", "\n", "s", ",", "e", "=", "parts", ".", "pop", "(", "c", ")", "\n", "parts", ".", "extend", "(", "arrange", "(", "s", ",", "e", ",", "length", ",", "min_length", ")", ")", "\n", "", "mask_idc", "=", "np", ".", "asarray", "(", "mask_idc", ")", "\n", "", "else", ":", "\n", "            ", "min_len", "=", "min", "(", "lengths", ")", "\n", "if", "sz", "-", "min_len", "<=", "num_mask", ":", "\n", "                ", "min_len", "=", "sz", "-", "num_mask", "-", "1", "\n", "\n", "", "mask_idc", "=", "np", ".", "random", ".", "choice", "(", "sz", "-", "min_len", ",", "num_mask", ",", "replace", "=", "False", ")", "\n", "\n", "mask_idc", "=", "np", ".", "asarray", "(", "\n", "[", "\n", "mask_idc", "[", "j", "]", "+", "offset", "\n", "for", "j", "in", "range", "(", "len", "(", "mask_idc", ")", ")", "\n", "for", "offset", "in", "range", "(", "lengths", "[", "j", "]", ")", "\n", "]", "\n", ")", "\n", "\n", "", "mask_idcs", ".", "append", "(", "np", ".", "unique", "(", "mask_idc", "[", "mask_idc", "<", "sz", "]", ")", ")", "\n", "\n", "", "min_len", "=", "min", "(", "[", "len", "(", "m", ")", "for", "m", "in", "mask_idcs", "]", ")", "\n", "for", "i", ",", "mask_idc", "in", "enumerate", "(", "mask_idcs", ")", ":", "\n", "        ", "if", "len", "(", "mask_idc", ")", ">", "min_len", ":", "\n", "            ", "mask_idc", "=", "np", ".", "random", ".", "choice", "(", "mask_idc", ",", "min_len", ",", "replace", "=", "False", ")", "\n", "", "mask", "[", "i", ",", "mask_idc", "]", "=", "True", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.get_mem_usage": [[532, 540], ["psutil.virtual_memory", "psutil.virtual_memory"], "function", ["None"], ["", "def", "get_mem_usage", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "psutil", "\n", "\n", "mb", "=", "1024", "*", "1024", "\n", "return", "f\"used={psutil.virtual_memory().used / mb}Mb; avail={psutil.virtual_memory().available / mb}Mb\"", "\n", "", "except", "ImportError", ":", "\n", "        ", "return", "\"N/A\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.lengths_to_padding_mask": [[542, 547], ["torch.arange().to().view", "lens.size", "torch.max().item", "torch.arange().to().view.expand", "lens.view().expand", "torch.arange().to", "torch.max", "lens.view", "torch.arange"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item"], ["", "", "def", "lengths_to_padding_mask", "(", "lens", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "BoolTensor", ":", "\n", "    ", "bsz", ",", "max_lens", "=", "lens", ".", "size", "(", "0", ")", ",", "torch", ".", "max", "(", "lens", ")", ".", "item", "(", ")", "\n", "mask", "=", "torch", ".", "arange", "(", "max_lens", ")", ".", "to", "(", "lens", ".", "device", ")", ".", "view", "(", "1", ",", "max_lens", ")", "\n", "mask", "=", "mask", ".", "expand", "(", "bsz", ",", "-", "1", ")", ">=", "lens", ".", "view", "(", "bsz", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "max_lens", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.lengths_to_mask": [[549, 551], ["data_utils.lengths_to_padding_mask"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.lengths_to_padding_mask"], ["", "def", "lengths_to_mask", "(", "lens", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "BoolTensor", ":", "\n", "    ", "return", "~", "lengths_to_padding_mask", "(", "lens", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.__init__": [[12, 29], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "labels", ",", "\n", "pad", ",", "\n", "eos", ",", "\n", "batch_targets", ",", "\n", "process_label", "=", "None", ",", "\n", "add_to_input", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "batch_targets", "=", "batch_targets", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "eos", "=", "eos", "\n", "self", ".", "process_label", "=", "process_label", "\n", "self", ".", "add_to_input", "=", "add_to_input", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.get_label": [[30, 35], ["add_target_dataset.AddTargetDataset.process_label"], "methods", ["None"], ["", "def", "get_label", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "labels", "[", "index", "]", "\n", "if", "self", ".", "process_label", "is", "None", "\n", "else", "self", ".", "process_label", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.__getitem__": [[37, 41], ["add_target_dataset.AddTargetDataset.get_label"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.get_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "item", "[", "\"label\"", "]", "=", "self", ".", "get_label", "(", "index", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.size": [[42, 46], ["add_target_dataset.AddTargetDataset.dataset.size", "len", "add_target_dataset.AddTargetDataset.get_label"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.get_label"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "sz", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "own_sz", "=", "len", "(", "self", ".", "get_label", "(", "index", ")", ")", "\n", "return", "(", "sz", ",", "own_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.add_target_dataset.AddTargetDataset.collater": [[47, 71], ["add_target_dataset.AddTargetDataset.dataset.collater", "set", "len", "collated[].tolist", "torch.LongTensor", "data_utils.collate_tokens", "collated[].sum().item", "sum", "data_utils.collate_tokens.new_full", "torch.cat().long", "torch.cat().long", "data_utils.collate_tokens.size", "len", "collated[].sum", "len", "data_utils.collate_tokens.size", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.collater", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.utils.item", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "collated", "=", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "if", "len", "(", "collated", ")", "==", "0", ":", "\n", "            ", "return", "collated", "\n", "", "indices", "=", "set", "(", "collated", "[", "\"id\"", "]", ".", "tolist", "(", ")", ")", "\n", "target", "=", "[", "s", "[", "\"label\"", "]", "for", "s", "in", "samples", "if", "s", "[", "\"id\"", "]", "in", "indices", "]", "\n", "\n", "if", "self", ".", "batch_targets", ":", "\n", "            ", "collated", "[", "\"target_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "target", "=", "data_utils", ".", "collate_tokens", "(", "target", ",", "pad_idx", "=", "self", ".", "pad", ",", "left_pad", "=", "False", ")", "\n", "collated", "[", "\"ntokens\"", "]", "=", "collated", "[", "\"target_lengths\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "collated", "[", "\"ntokens\"", "]", "=", "sum", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "\n", "", "collated", "[", "\"target\"", "]", "=", "target", "\n", "\n", "if", "self", ".", "add_to_input", ":", "\n", "            ", "eos", "=", "target", ".", "new_full", "(", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", ",", "self", ".", "eos", ")", "\n", "collated", "[", "\"target\"", "]", "=", "torch", ".", "cat", "(", "[", "target", ",", "eos", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "eos", ",", "target", "]", ",", "dim", "=", "-", "1", "\n", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"ntokens\"", "]", "+=", "target", ".", "size", "(", "0", ")", "\n", "", "return", "collated", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.__init__": [[21, 42], ["dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "len", "dictionary.Dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol"], ["def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "# begin keyword-only arguments", "\n", "bos", "=", "\"<s>\"", ",", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "eos", "=", "\"</s>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "extra_special_symbols", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "bos_word", ",", "self", ".", "unk_word", ",", "self", ".", "pad_word", ",", "self", ".", "eos_word", "=", "bos", ",", "unk", ",", "pad", ",", "eos", "\n", "self", ".", "symbols", "=", "[", "]", "\n", "self", ".", "count", "=", "[", "]", "\n", "self", ".", "indices", "=", "{", "}", "\n", "self", ".", "bos_index", "=", "self", ".", "add_symbol", "(", "bos", ")", "\n", "self", ".", "pad_index", "=", "self", ".", "add_symbol", "(", "pad", ")", "\n", "self", ".", "eos_index", "=", "self", ".", "add_symbol", "(", "eos", ")", "\n", "self", ".", "unk_index", "=", "self", ".", "add_symbol", "(", "unk", ")", "\n", "if", "extra_special_symbols", ":", "\n", "            ", "for", "s", "in", "extra_special_symbols", ":", "\n", "                ", "self", ".", "add_symbol", "(", "s", ")", "\n", "", "", "self", ".", "nspecial", "=", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.__eq__": [[43, 45], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "indices", "==", "other", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.__getitem__": [[46, 50], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "len", "(", "self", ".", "symbols", ")", ":", "\n", "            ", "return", "self", ".", "symbols", "[", "idx", "]", "\n", "", "return", "self", ".", "unk_word", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.__len__": [[51, 54], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of symbols in the dictionary\"\"\"", "\n", "return", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.__contains__": [[55, 57], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "sym", ")", ":", "\n", "        ", "return", "sym", "in", "self", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index": [[58, 64], ["isinstance"], "methods", ["None"], ["", "def", "index", "(", "self", ",", "sym", ")", ":", "\n", "        ", "\"\"\"Returns the index of the specified symbol\"\"\"", "\n", "assert", "isinstance", "(", "sym", ",", "str", ")", "\n", "if", "sym", "in", "self", ".", "indices", ":", "\n", "            ", "return", "self", ".", "indices", "[", "sym", "]", "\n", "", "return", "self", ".", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.string": [[65, 106], ["set", "set.add", "hasattr", "fairseq.data.data_utils.post_process", "torch.is_tensor", "dictionary.Dictionary.eos", "set.add", "tensor.dim", "dictionary.Dictionary.unk", "dictionary.Dictionary.bos", "dictionary.Dictionary.string.token_string"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.post_process", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.bos"], ["", "def", "string", "(", "\n", "self", ",", "\n", "tensor", ",", "\n", "bpe_symbol", "=", "None", ",", "\n", "escape_unk", "=", "False", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", "unk_string", "=", "None", ",", "\n", "include_eos", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Helper for converting a tensor of token indices to a string.\n\n        Can optionally remove BPE symbols or escape <unk> words.\n        \"\"\"", "\n", "if", "torch", ".", "is_tensor", "(", "tensor", ")", "and", "tensor", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "return", "\"\\n\"", ".", "join", "(", "\n", "self", ".", "string", "(", "t", ",", "bpe_symbol", ",", "escape_unk", ",", "extra_symbols_to_ignore", ",", "include_eos", "=", "include_eos", ")", "\n", "for", "t", "in", "tensor", "\n", ")", "\n", "\n", "", "extra_symbols_to_ignore", "=", "set", "(", "extra_symbols_to_ignore", "or", "[", "]", ")", "\n", "extra_symbols_to_ignore", ".", "add", "(", "self", ".", "eos", "(", ")", ")", "\n", "\n", "def", "token_string", "(", "i", ")", ":", "\n", "            ", "if", "i", "==", "self", ".", "unk", "(", ")", ":", "\n", "                ", "if", "unk_string", "is", "not", "None", ":", "\n", "                    ", "return", "unk_string", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "unk_string", "(", "escape_unk", ")", "\n", "", "", "else", ":", "\n", "                ", "return", "self", "[", "i", "]", "\n", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"bos_index\"", ")", ":", "\n", "            ", "extra_symbols_to_ignore", ".", "add", "(", "self", ".", "bos", "(", ")", ")", "\n", "\n", "", "sent", "=", "\" \"", ".", "join", "(", "\n", "token_string", "(", "i", ")", "\n", "for", "i", "in", "tensor", "\n", "if", "utils", ".", "item", "(", "i", ")", "not", "in", "extra_symbols_to_ignore", "\n", ")", "\n", "\n", "return", "data_utils", ".", "post_process", "(", "sent", ",", "bpe_symbol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk_string": [[107, 113], ["None"], "methods", ["None"], ["", "def", "unk_string", "(", "self", ",", "escape", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return unknown string, optionally escaped as: <<unk>>\"\"\"", "\n", "if", "escape", ":", "\n", "            ", "return", "\"<{}>\"", ".", "format", "(", "self", ".", "unk_word", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "unk_word", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol": [[114, 126], ["len", "dictionary.Dictionary.symbols.append", "dictionary.Dictionary.count.append"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "word", ",", "n", "=", "1", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "\"\"\"Adds a word to the dictionary\"\"\"", "\n", "if", "word", "in", "self", ".", "indices", "and", "not", "overwrite", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "self", ".", "count", "[", "idx", "]", "=", "self", ".", "count", "[", "idx", "]", "+", "n", "\n", "return", "idx", "\n", "", "else", ":", "\n", "            ", "idx", "=", "len", "(", "self", ".", "symbols", ")", "\n", "self", ".", "indices", "[", "word", "]", "=", "idx", "\n", "self", ".", "symbols", ".", "append", "(", "word", ")", "\n", "self", ".", "count", ".", "append", "(", "n", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update": [[127, 139], ["len", "dictionary.Dictionary.symbols.append", "dictionary.Dictionary.count.append"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "new_dict", ")", ":", "\n", "        ", "\"\"\"Updates counts from new dictionary.\"\"\"", "\n", "for", "word", "in", "new_dict", ".", "symbols", ":", "\n", "            ", "idx2", "=", "new_dict", ".", "indices", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "indices", ":", "\n", "                ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "self", ".", "count", "[", "idx", "]", "=", "self", ".", "count", "[", "idx", "]", "+", "new_dict", ".", "count", "[", "idx2", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "symbols", ")", "\n", "self", ".", "indices", "[", "word", "]", "=", "idx", "\n", "self", ".", "symbols", ".", "append", "(", "word", ")", "\n", "self", ".", "count", ".", "append", "(", "new_dict", ".", "count", "[", "idx2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.finalize": [[140, 178], ["dict", "collections.Counter", "collections.Counter.most_common", "list", "list", "dictionary.Dictionary.pad_to_multiple_", "len", "zip", "dict", "len", "len", "range", "sorted", "len", "new_symbols.append", "new_count.append", "zip"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_"], ["", "", "", "def", "finalize", "(", "self", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", ")", ":", "\n", "        ", "\"\"\"Sort symbols by frequency in descending order, ignoring special ones.\n\n        Args:\n            - threshold defines the minimum word count\n            - nwords defines the total number of words in the final dictionary,\n                including special symbols\n            - padding_factor can be used to pad the dictionary size to be a\n                multiple of 8, which is important on some hardware (e.g., Nvidia\n                Tensor Cores).\n        \"\"\"", "\n", "if", "nwords", "<=", "0", ":", "\n", "            ", "nwords", "=", "len", "(", "self", ")", "\n", "\n", "", "new_indices", "=", "dict", "(", "zip", "(", "self", ".", "symbols", "[", ":", "self", ".", "nspecial", "]", ",", "range", "(", "self", ".", "nspecial", ")", ")", ")", "\n", "new_symbols", "=", "self", ".", "symbols", "[", ":", "self", ".", "nspecial", "]", "\n", "new_count", "=", "self", ".", "count", "[", ":", "self", ".", "nspecial", "]", "\n", "\n", "c", "=", "Counter", "(", "\n", "dict", "(", "\n", "sorted", "(", "zip", "(", "self", ".", "symbols", "[", "self", ".", "nspecial", ":", "]", ",", "self", ".", "count", "[", "self", ".", "nspecial", ":", "]", ")", ")", "\n", ")", "\n", ")", "\n", "for", "symbol", ",", "count", "in", "c", ".", "most_common", "(", "nwords", "-", "self", ".", "nspecial", ")", ":", "\n", "            ", "if", "count", ">=", "threshold", ":", "\n", "                ", "new_indices", "[", "symbol", "]", "=", "len", "(", "new_symbols", ")", "\n", "new_symbols", ".", "append", "(", "symbol", ")", "\n", "new_count", ".", "append", "(", "count", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "assert", "len", "(", "new_symbols", ")", "==", "len", "(", "new_indices", ")", "\n", "\n", "self", ".", "count", "=", "list", "(", "new_count", ")", "\n", "self", ".", "symbols", "=", "list", "(", "new_symbols", ")", "\n", "self", ".", "indices", "=", "new_indices", "\n", "\n", "self", ".", "pad_to_multiple_", "(", "padding_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad_to_multiple_": [[179, 187], ["dictionary.Dictionary.add_symbol", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol"], ["", "def", "pad_to_multiple_", "(", "self", ",", "padding_factor", ")", ":", "\n", "        ", "\"\"\"Pad Dictionary size to be a multiple of *padding_factor*.\"\"\"", "\n", "if", "padding_factor", ">", "1", ":", "\n", "            ", "i", "=", "0", "\n", "while", "len", "(", "self", ")", "%", "padding_factor", "!=", "0", ":", "\n", "                ", "symbol", "=", "\"madeupword{:04d}\"", ".", "format", "(", "i", ")", "\n", "self", ".", "add_symbol", "(", "symbol", ",", "n", "=", "0", ")", "\n", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.bos": [[188, 191], ["None"], "methods", ["None"], ["", "", "", "def", "bos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of beginning-of-sentence symbol\"\"\"", "\n", "return", "self", ".", "bos_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad": [[192, 195], ["None"], "methods", ["None"], ["", "def", "pad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of pad symbol\"\"\"", "\n", "return", "self", ".", "pad_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos": [[196, 199], ["None"], "methods", ["None"], ["", "def", "eos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of end-of-sentence symbol\"\"\"", "\n", "return", "self", ".", "eos_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk": [[200, 203], ["None"], "methods", ["None"], ["", "def", "unk", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of unk symbol\"\"\"", "\n", "return", "self", ".", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load": [[204, 217], ["cls", "cls.add_from_file"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_from_file"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "f", ")", ":", "\n", "        ", "\"\"\"Loads the dictionary from a text file with the format:\n\n        ```\n        <symbol0> <count0>\n        <symbol1> <count1>\n        ...\n        ```\n        \"\"\"", "\n", "d", "=", "cls", "(", ")", "\n", "d", ".", "add_from_file", "(", "f", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_from_file": [[218, 261], ["isinstance", "f.readlines", "dictionary.Dictionary._load_meta", "line.rstrip().rsplit", "int", "dictionary.Dictionary.add_symbol", "open", "dictionary.Dictionary.add_from_file", "Exception", "line.rsplit", "RuntimeError", "ValueError", "fairseq.file_io.PathManager.get_local_path", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._load_meta", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_from_file", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path"], ["", "def", "add_from_file", "(", "self", ",", "f", ")", ":", "\n", "        ", "\"\"\"\n        Loads a pre-existing dictionary from a text file and adds its symbols\n        to this instance.\n        \"\"\"", "\n", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "f", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fd", ":", "\n", "                    ", "self", ".", "add_from_file", "(", "fd", ")", "\n", "", "", "except", "FileNotFoundError", "as", "fnfe", ":", "\n", "                ", "raise", "fnfe", "\n", "", "except", "UnicodeError", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Incorrect encoding detected in {}, please \"", "\n", "\"rebuild the dataset\"", ".", "format", "(", "f", ")", "\n", ")", "\n", "", "return", "\n", "\n", "", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "indices_start_line", "=", "self", ".", "_load_meta", "(", "lines", ")", "\n", "\n", "for", "line", "in", "lines", "[", "indices_start_line", ":", "]", ":", "\n", "            ", "try", ":", "\n", "                ", "line", ",", "field", "=", "line", ".", "rstrip", "(", ")", ".", "rsplit", "(", "\" \"", ",", "1", ")", "\n", "if", "field", "==", "\"#fairseq:overwrite\"", ":", "\n", "                    ", "overwrite", "=", "True", "\n", "line", ",", "field", "=", "line", ".", "rsplit", "(", "\" \"", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "overwrite", "=", "False", "\n", "", "count", "=", "int", "(", "field", ")", "\n", "word", "=", "line", "\n", "if", "word", "in", "self", "and", "not", "overwrite", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Duplicate word found when loading Dictionary: '{}'. \"", "\n", "\"Duplicate words can overwrite earlier ones by adding the \"", "\n", "\"#fairseq:overwrite flag at the end of the corresponding row \"", "\n", "\"in the dictionary file. If using the Camembert model, please \"", "\n", "\"download an updated copy of the model file.\"", ".", "format", "(", "word", ")", "\n", ")", "\n", "", "self", ".", "add_symbol", "(", "word", ",", "n", "=", "count", ",", "overwrite", "=", "overwrite", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Incorrect dictionary format, expected '<token> <cnt> [flags]'\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._save": [[263, 270], ["isinstance", "fairseq.file_io.PathManager.mkdirs", "print", "os.path.dirname", "fairseq.file_io.PathManager.open", "dictionary.Dictionary.save"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.mkdirs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save"], ["", "", "", "def", "_save", "(", "self", ",", "f", ",", "kv_iterator", ")", ":", "\n", "        ", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "os", ".", "path", ".", "dirname", "(", "f", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "f", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fd", ":", "\n", "                ", "return", "self", ".", "save", "(", "fd", ")", "\n", "", "", "for", "k", ",", "v", "in", "kv_iterator", ":", "\n", "            ", "print", "(", "\"{} {}\"", ".", "format", "(", "k", ",", "v", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta": [[271, 273], ["None"], "methods", ["None"], ["", "", "def", "_get_meta", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._load_meta": [[274, 276], ["None"], "methods", ["None"], ["", "def", "_load_meta", "(", "self", ",", "lines", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save": [[277, 285], ["dictionary.Dictionary._get_meta", "dictionary.Dictionary._save", "zip"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._get_meta", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._save"], ["", "def", "save", "(", "self", ",", "f", ")", ":", "\n", "        ", "\"\"\"Stores dictionary into a text file\"\"\"", "\n", "ex_keys", ",", "ex_vals", "=", "self", ".", "_get_meta", "(", ")", "\n", "self", ".", "_save", "(", "\n", "f", ",", "\n", "zip", "(", "\n", "ex_keys", "+", "self", ".", "symbols", "[", "self", ".", "nspecial", ":", "]", ",", "\n", "ex_vals", "+", "self", ".", "count", "[", "self", ".", "nspecial", ":", "]", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.dummy_sentence": [[288, 292], ["torch.Tensor().uniform_().long", "dictionary.Dictionary.eos", "torch.Tensor().uniform_", "len", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos"], ["", "def", "dummy_sentence", "(", "self", ",", "length", ")", ":", "\n", "        ", "t", "=", "torch", ".", "Tensor", "(", "length", ")", ".", "uniform_", "(", "self", ".", "nspecial", "+", "1", ",", "len", "(", "self", ")", ")", ".", "long", "(", ")", "\n", "t", "[", "-", "1", "]", "=", "self", ".", "eos", "(", ")", "\n", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line": [[293, 319], ["line_tokenizer", "len", "torch.IntTensor", "enumerate", "list", "reversed", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.index", "consumer"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["", "def", "encode_line", "(", "\n", "self", ",", "\n", "line", ",", "\n", "line_tokenizer", "=", "tokenize_line", ",", "\n", "add_if_not_exist", "=", "True", ",", "\n", "consumer", "=", "None", ",", "\n", "append_eos", "=", "True", ",", "\n", "reverse_order", "=", "False", ",", "\n", ")", "->", "torch", ".", "IntTensor", ":", "\n", "        ", "words", "=", "line_tokenizer", "(", "line", ")", "\n", "if", "reverse_order", ":", "\n", "            ", "words", "=", "list", "(", "reversed", "(", "words", ")", ")", "\n", "", "nwords", "=", "len", "(", "words", ")", "\n", "ids", "=", "torch", ".", "IntTensor", "(", "nwords", "+", "1", "if", "append_eos", "else", "nwords", ")", "\n", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "if", "add_if_not_exist", ":", "\n", "                ", "idx", "=", "self", ".", "add_symbol", "(", "word", ")", "\n", "", "else", ":", "\n", "                ", "idx", "=", "self", ".", "index", "(", "word", ")", "\n", "", "if", "consumer", "is", "not", "None", ":", "\n", "                ", "consumer", "(", "word", ",", "idx", ")", "\n", "", "ids", "[", "i", "]", "=", "idx", "\n", "", "if", "append_eos", ":", "\n", "            ", "ids", "[", "nwords", "]", "=", "self", ".", "eos_index", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary._add_file_to_dictionary_single_worker": [[320, 348], ["collections.Counter", "open", "f.seek", "f.readline", "fairseq.file_io.PathManager.get_local_path", "os.fstat", "fairseq.binarizer.safe_readline", "tokenize", "collections.Counter.update", "f.readline", "f.fileno", "collections.Counter.update", "f.tell", "f.tell"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.update"], ["", "@", "staticmethod", "\n", "def", "_add_file_to_dictionary_single_worker", "(", "\n", "filename", ",", "tokenize", ",", "eos_word", ",", "worker_id", "=", "0", ",", "num_workers", "=", "1", "\n", ")", ":", "\n", "        ", "counter", "=", "Counter", "(", ")", "\n", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "size", "=", "os", ".", "fstat", "(", "f", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "chunk_size", "=", "size", "//", "num_workers", "\n", "offset", "=", "worker_id", "*", "chunk_size", "\n", "end", "=", "offset", "+", "chunk_size", "\n", "f", ".", "seek", "(", "offset", ")", "\n", "if", "offset", ">", "0", ":", "\n", "                ", "safe_readline", "(", "f", ")", "# drop first incomplete line", "\n", "", "line", "=", "f", ".", "readline", "(", ")", "\n", "while", "line", ":", "\n", "                ", "for", "word", "in", "tokenize", "(", "line", ")", ":", "\n", "                    ", "counter", ".", "update", "(", "[", "word", "]", ")", "\n", "", "counter", ".", "update", "(", "[", "eos_word", "]", ")", "\n", "# f.tell() returns only an opaque number which can", "\n", "# return to the position in the file via f.seek()", "\n", "# and does not necessarily represent a byte position", "\n", "# in the file. However, f.tell() is faithful to the", "\n", "# byte position _most of the time_. Thus we can just", "\n", "# check against the file size to prevent early exit.", "\n", "if", "f", ".", "tell", "(", ")", ">", "end", "and", "f", ".", "tell", "(", ")", "<", "size", ":", "\n", "                    ", "break", "\n", "", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.add_file_to_dictionary": [[349, 373], ["sorted", "multiprocessing.Pool", "range", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "dictionary.Dictionary.add_file_to_dictionary.merge_result"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "@", "staticmethod", "\n", "def", "add_file_to_dictionary", "(", "filename", ",", "dict", ",", "tokenize", ",", "num_workers", ")", ":", "\n", "        ", "def", "merge_result", "(", "counter", ")", ":", "\n", "            ", "for", "w", ",", "c", "in", "sorted", "(", "counter", ".", "items", "(", ")", ")", ":", "\n", "                ", "dict", ".", "add_symbol", "(", "w", ",", "c", ")", "\n", "\n", "", "", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", "=", "Pool", "(", "processes", "=", "num_workers", ")", "\n", "results", "=", "[", "]", "\n", "for", "worker_id", "in", "range", "(", "num_workers", ")", ":", "\n", "                ", "results", ".", "append", "(", "\n", "pool", ".", "apply_async", "(", "\n", "Dictionary", ".", "_add_file_to_dictionary_single_worker", ",", "\n", "(", "filename", ",", "tokenize", ",", "dict", ".", "eos_word", ",", "worker_id", ",", "num_workers", ")", ",", "\n", ")", "\n", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "for", "r", "in", "results", ":", "\n", "                ", "merge_result", "(", "r", ".", "get", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "merge_result", "(", "\n", "Dictionary", ".", "_add_file_to_dictionary_single_worker", "(", "\n", "filename", ",", "tokenize", ",", "dict", ".", "eos_word", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.TruncatedDictionary.__init__": [[378, 387], ["type", "min", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "wrapped_dict", ",", "length", ")", ":", "\n", "        ", "self", ".", "__class__", "=", "type", "(", "\n", "wrapped_dict", ".", "__class__", ".", "__name__", ",", "\n", "(", "self", ".", "__class__", ",", "wrapped_dict", ".", "__class__", ")", ",", "\n", "{", "}", ",", "\n", ")", "\n", "self", ".", "__dict__", "=", "wrapped_dict", ".", "__dict__", "\n", "self", ".", "wrapped_dict", "=", "wrapped_dict", "\n", "self", ".", "length", "=", "min", "(", "len", "(", "self", ".", "wrapped_dict", ")", ",", "length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.TruncatedDictionary.__len__": [[388, 390], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.TruncatedDictionary.__getitem__": [[391, 395], ["dictionary.TruncatedDictionary.wrapped_dict.unk"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.unk"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "self", ".", "length", ":", "\n", "            ", "return", "self", ".", "wrapped_dict", "[", "i", "]", "\n", "", "return", "self", ".", "wrapped_dict", ".", "unk", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__init__": [[24, 36], ["fasta_dataset.fasta_file_path", "threading.local", "pathlib.Path", "fasta_dataset.FastaDataset.cache.exists", "fasta_dataset.FastaDataset._build_index", "numpy.load", "fasta_dataset.FastaDataset._build_index", "numpy.save", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.fasta_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset._build_index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset._build_index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.save"], ["def", "__init__", "(", "self", ",", "path", ":", "str", ",", "cache_indices", "=", "False", ")", ":", "\n", "        ", "self", ".", "fn", "=", "fasta_file_path", "(", "path", ")", "\n", "self", ".", "threadlocal", "=", "threading", ".", "local", "(", ")", "\n", "self", ".", "cache", "=", "Path", "(", "f\"{path}.fasta.idx.npy\"", ")", "\n", "if", "cache_indices", ":", "\n", "            ", "if", "self", ".", "cache", ".", "exists", "(", ")", ":", "\n", "                ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "np", ".", "load", "(", "self", ".", "cache", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "self", ".", "_build_index", "(", "path", ")", "\n", "np", ".", "save", "(", "self", ".", "cache", ",", "np", ".", "stack", "(", "[", "self", ".", "offsets", ",", "self", ".", "sizes", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "self", ".", "_build_index", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset._get_file": [[37, 41], ["hasattr", "open"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "", "def", "_get_file", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ".", "threadlocal", ",", "\"f\"", ")", ":", "\n", "            ", "self", ".", "threadlocal", ".", "f", "=", "open", "(", "self", ".", "fn", ",", "\"r\"", ")", "\n", "", "return", "self", ".", "threadlocal", ".", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__getitem__": [[42, 52], ["fasta_dataset.FastaDataset._get_file", "fasta_dataset.FastaDataset.seek", "fasta_dataset.FastaDataset.readline().strip", "fasta_dataset.FastaDataset.readline", "fasta_dataset.FastaDataset.readline.strip", "fasta_dataset.FastaDataset.readline", "fasta_dataset.FastaDataset.readline"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset._get_file"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "f", "=", "self", ".", "_get_file", "(", ")", "\n", "f", ".", "seek", "(", "self", ".", "offsets", "[", "idx", "]", ")", "\n", "desc", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "seq", "=", "\"\"", "\n", "while", "line", "!=", "\"\"", "and", "line", "[", "0", "]", "!=", "\">\"", ":", "\n", "            ", "seq", "+=", "line", ".", "strip", "(", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "return", "desc", ",", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__len__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "offsets", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset._build_index": [[56, 73], ["fasta_dataset.fasta_file_path", "subprocess.check_output", "subprocess.check_output", "numpy.fromstring", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.fasta_file_path"], ["", "def", "_build_index", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "# Use grep and awk to get 100M/s on local SSD.", "\n", "# Should process your enormous 100G fasta in ~10 min single core...", "\n", "        ", "path", "=", "fasta_file_path", "(", "path", ")", "\n", "bytes_offsets", "=", "subprocess", ".", "check_output", "(", "\n", "f\"cat {path} | tqdm --bytes --total $(wc -c < {path})\"", "\n", "\"| grep --byte-offset '^>' -o | cut -d: -f1\"", ",", "\n", "shell", "=", "True", ",", "\n", ")", "\n", "fasta_lengths", "=", "subprocess", ".", "check_output", "(", "\n", "f\"cat {path} | tqdm --bytes --total $(wc -c < {path})\"", "\n", "\"| awk '/^>/ {print \\\"\\\";next;} { printf(\\\"%s\\\",$0);}' | tail -n+2 | awk '{print length($1)}'\"", ",", "\n", "shell", "=", "True", ",", "\n", ")", "\n", "bytes_np", "=", "np", ".", "fromstring", "(", "bytes_offsets", ",", "dtype", "=", "np", ".", "int64", ",", "sep", "=", "\" \"", ")", "\n", "sizes_np", "=", "np", ".", "fromstring", "(", "fasta_lengths", ",", "dtype", "=", "np", ".", "int64", ",", "sep", "=", "\" \"", ")", "\n", "return", "bytes_np", ",", "sizes_np", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__setstate__": [[74, 77], ["threading.local"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "state", "\n", "self", ".", "threadlocal", "=", "threading", ".", "local", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__getstate__": [[78, 84], ["fasta_dataset.FastaDataset.__dict__.items"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "d", "=", "{", "}", "\n", "for", "i", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "i", "!=", "\"threadlocal\"", ":", "\n", "                ", "d", "[", "i", "]", "=", "v", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.__del__": [[85, 89], ["hasattr", "fasta_dataset.FastaDataset.threadlocal.f.close"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "threadlocal", ",", "\"f\"", ")", ":", "\n", "            ", "self", ".", "threadlocal", ".", "f", ".", "close", "(", ")", "\n", "del", "self", ".", "threadlocal", ".", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.FastaDataset.exists": [[90, 93], ["os.path.exists", "fasta_dataset.fasta_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.fasta_file_path"], ["", "", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "exists", "(", "fasta_file_path", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.EncodedFastaDataset.__init__": [[101, 104], ["fasta_dataset.FastaDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["def", "__init__", "(", "self", ",", "path", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "path", ",", "cache_indices", "=", "True", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.EncodedFastaDataset.__getitem__": [[105, 108], ["fasta_dataset.FastaDataset.__getitem__", "fasta_dataset.EncodedFastaDataset.dictionary.encode_line().long", "fasta_dataset.EncodedFastaDataset.dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__getitem__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "desc", ",", "seq", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "return", "self", ".", "dictionary", ".", "encode_line", "(", "seq", ",", "line_tokenizer", "=", "list", ")", ".", "long", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.fasta_dataset.fasta_file_path": [[15, 17], ["None"], "function", ["None"], ["def", "fasta_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".fasta\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.__init__": [[127, 133], ["FairseqDataset.__init__", "indexed_dataset.IndexedDataset.read_index"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.read_index"], ["def", "__init__", "(", "self", ",", "path", ",", "fix_lua_indexing", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "fix_lua_indexing", "=", "fix_lua_indexing", "\n", "self", ".", "data_file", "=", "None", "\n", "self", ".", "read_index", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.read_index": [[134, 149], ["open", "f.read", "f.read", "struct.unpack", "struct.unpack", "indexed_dataset.read_longs", "indexed_dataset.read_longs", "indexed_dataset.read_longs", "indexed_dataset.index_file_path", "struct.unpack", "f.read", "f.read"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path"], ["", "def", "read_index", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "index_file_path", "(", "path", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "magic", "=", "f", ".", "read", "(", "8", ")", "\n", "assert", "magic", "==", "self", ".", "_HDR_MAGIC", ",", "(", "\n", "\"Index file doesn't match expected format. \"", "\n", "\"Make sure that --dataset-impl is configured properly.\"", "\n", ")", "\n", "version", "=", "f", ".", "read", "(", "8", ")", "\n", "assert", "struct", ".", "unpack", "(", "\"<Q\"", ",", "version", ")", "==", "(", "1", ",", ")", "\n", "code", ",", "self", ".", "element_size", "=", "struct", ".", "unpack", "(", "\"<QQ\"", ",", "f", ".", "read", "(", "16", ")", ")", "\n", "self", ".", "dtype", "=", "dtypes", "[", "code", "]", "\n", "self", ".", "_len", ",", "self", ".", "s", "=", "struct", ".", "unpack", "(", "\"<QQ\"", ",", "f", ".", "read", "(", "16", ")", ")", "\n", "self", ".", "dim_offsets", "=", "read_longs", "(", "f", ",", "self", ".", "_len", "+", "1", ")", "\n", "self", ".", "data_offsets", "=", "read_longs", "(", "f", ",", "self", ".", "_len", "+", "1", ")", "\n", "self", ".", "sizes", "=", "read_longs", "(", "f", ",", "self", ".", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.read_data": [[150, 152], ["open", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "", "def", "read_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "data_file", "=", "open", "(", "data_file_path", "(", "path", ")", ",", "\"rb\"", ",", "buffering", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.check_index": [[153, 156], ["IndexError"], "methods", ["None"], ["", "def", "check_index", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "0", "or", "i", ">=", "self", ".", "_len", ":", "\n", "            ", "raise", "IndexError", "(", "\"index out of range\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.__del__": [[157, 160], ["indexed_dataset.IndexedDataset.data_file.close"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "data_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.__getitem__": [[161, 174], ["functools.lru_cache", "indexed_dataset.IndexedDataset.check_index", "numpy.empty", "indexed_dataset.IndexedDataset.data_file.seek", "indexed_dataset.IndexedDataset.data_file.readinto", "torch.from_numpy().long", "indexed_dataset.IndexedDataset.read_data", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.check_index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.read_data"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "not", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "read_data", "(", "self", ".", "path", ")", "\n", "", "self", ".", "check_index", "(", "i", ")", "\n", "tensor_size", "=", "self", ".", "sizes", "[", "self", ".", "dim_offsets", "[", "i", "]", ":", "self", ".", "dim_offsets", "[", "i", "+", "1", "]", "]", "\n", "a", "=", "np", ".", "empty", "(", "tensor_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "self", ".", "data_file", ".", "seek", "(", "self", ".", "data_offsets", "[", "i", "]", "*", "self", ".", "element_size", ")", "\n", "self", ".", "data_file", ".", "readinto", "(", "a", ")", "\n", "item", "=", "torch", ".", "from_numpy", "(", "a", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "fix_lua_indexing", ":", "\n", "            ", "item", "-=", "1", "# subtract 1 for 0-based indexing", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.__len__": [[175, 177], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.num_tokens": [[178, 180], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.size": [[181, 183], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.exists": [[184, 188], ["fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "index_file_path", "(", "path", ")", ")", "and", "PathManager", ".", "exists", "(", "\n", "data_file_path", "(", "path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDataset.supports_prefetch": [[190, 193], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "# avoid prefetching to save memory", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedCachedDataset.__init__": [[196, 200], ["indexed_dataset.IndexedDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "fix_lua_indexing", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "self", ".", "cache", "=", "None", "\n", "self", ".", "cache_index", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedCachedDataset.supports_prefetch": [[201, 204], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedCachedDataset.prefetch": [[205, 228], ["all", "sorted", "numpy.empty", "indexed_dataset.IndexedCachedDataset.cache_index.clear", "indexed_dataset.IndexedCachedDataset.read_data", "set", "indexed_dataset.IndexedCachedDataset.data_file.seek", "indexed_dataset.IndexedCachedDataset.data_file.readinto", "indexed_dataset.IndexedCachedDataset.data_file.close"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.read_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "if", "all", "(", "i", "in", "self", ".", "cache_index", "for", "i", "in", "indices", ")", ":", "\n", "            ", "return", "\n", "", "if", "not", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "read_data", "(", "self", ".", "path", ")", "\n", "", "indices", "=", "sorted", "(", "set", "(", "indices", ")", ")", "\n", "total_size", "=", "0", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "total_size", "+=", "self", ".", "data_offsets", "[", "i", "+", "1", "]", "-", "self", ".", "data_offsets", "[", "i", "]", "\n", "", "self", ".", "cache", "=", "np", ".", "empty", "(", "total_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "ptx", "=", "0", "\n", "self", ".", "cache_index", ".", "clear", "(", ")", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "self", ".", "cache_index", "[", "i", "]", "=", "ptx", "\n", "size", "=", "self", ".", "data_offsets", "[", "i", "+", "1", "]", "-", "self", ".", "data_offsets", "[", "i", "]", "\n", "a", "=", "self", ".", "cache", "[", "ptx", ":", "ptx", "+", "size", "]", "\n", "self", ".", "data_file", ".", "seek", "(", "self", ".", "data_offsets", "[", "i", "]", "*", "self", ".", "element_size", ")", "\n", "self", ".", "data_file", ".", "readinto", "(", "a", ")", "\n", "ptx", "+=", "size", "\n", "", "if", "self", ".", "data_file", ":", "\n", "# close and delete data file after prefetch so we can pickle", "\n", "            ", "self", ".", "data_file", ".", "close", "(", ")", "\n", "self", ".", "data_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedCachedDataset.__getitem__": [[229, 240], ["functools.lru_cache", "indexed_dataset.IndexedCachedDataset.check_index", "numpy.empty", "numpy.copyto", "torch.from_numpy().long", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "tensor_size", "=", "self", ".", "sizes", "[", "self", ".", "dim_offsets", "[", "i", "]", ":", "self", ".", "dim_offsets", "[", "i", "+", "1", "]", "]", "\n", "a", "=", "np", ".", "empty", "(", "tensor_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "ptx", "=", "self", ".", "cache_index", "[", "i", "]", "\n", "np", ".", "copyto", "(", "a", ",", "self", ".", "cache", "[", "ptx", ":", "ptx", "+", "a", ".", "size", "]", ")", "\n", "item", "=", "torch", ".", "from_numpy", "(", "a", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "fix_lua_indexing", ":", "\n", "            ", "item", "-=", "1", "# subtract 1 for 0-based indexing", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.__init__": [[246, 254], ["indexed_dataset.IndexedRawTextDataset.read_data", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.read_data"], ["def", "__init__", "(", "self", ",", "path", ",", "dictionary", ",", "append_eos", "=", "True", ",", "reverse_order", "=", "False", ")", ":", "\n", "        ", "self", ".", "tokens_list", "=", "[", "]", "\n", "self", ".", "lines", "=", "[", "]", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "append_eos", "=", "append_eos", "\n", "self", ".", "reverse_order", "=", "reverse_order", "\n", "self", ".", "read_data", "(", "path", ",", "dictionary", ")", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "tokens_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.read_data": [[255, 268], ["numpy.array", "open", "indexed_dataset.IndexedRawTextDataset.lines.append", "dictionary.encode_line().long", "indexed_dataset.IndexedRawTextDataset.tokens_list.append", "indexed_dataset.IndexedRawTextDataset.sizes.append", "line.strip", "len", "dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "read_data", "(", "self", ",", "path", ",", "dictionary", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "self", ".", "lines", ".", "append", "(", "line", ".", "strip", "(", "\"\\n\"", ")", ")", "\n", "tokens", "=", "dictionary", ".", "encode_line", "(", "\n", "line", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", "append_eos", "=", "self", ".", "append_eos", ",", "\n", "reverse_order", "=", "self", ".", "reverse_order", ",", "\n", ")", ".", "long", "(", ")", "\n", "self", ".", "tokens_list", ".", "append", "(", "tokens", ")", "\n", "self", ".", "sizes", ".", "append", "(", "len", "(", "tokens", ")", ")", "\n", "", "", "self", ".", "sizes", "=", "np", ".", "array", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.check_index": [[269, 272], ["IndexError"], "methods", ["None"], ["", "def", "check_index", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "0", "or", "i", ">=", "self", ".", "size", ":", "\n", "            ", "raise", "IndexError", "(", "\"index out of range\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.__getitem__": [[273, 277], ["functools.lru_cache", "indexed_dataset.IndexedRawTextDataset.check_index"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "return", "self", ".", "tokens_list", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.get_original_text": [[278, 281], ["indexed_dataset.IndexedRawTextDataset.check_index"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "def", "get_original_text", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "return", "self", ".", "lines", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.__del__": [[282, 284], ["None"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.__len__": [[285, 287], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.num_tokens": [[288, 290], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.size": [[291, 293], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedRawTextDataset.exists": [[294, 297], ["fairseq.file_io.PathManager.exists"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDatasetBuilder.__init__": [[310, 317], ["open"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["def", "__init__", "(", "self", ",", "out_file", ",", "dtype", "=", "np", ".", "int32", ")", ":", "\n", "        ", "self", ".", "out_file", "=", "open", "(", "out_file", ",", "\"wb\"", ")", "\n", "self", ".", "dtype", "=", "dtype", "\n", "self", ".", "data_offsets", "=", "[", "0", "]", "\n", "self", ".", "dim_offsets", "=", "[", "0", "]", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "element_size", "=", "self", ".", "element_sizes", "[", "self", ".", "dtype", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDatasetBuilder.add_item": [[318, 325], ["indexed_dataset.IndexedDatasetBuilder.out_file.write", "indexed_dataset.IndexedDatasetBuilder.data_offsets.append", "tensor.size", "indexed_dataset.IndexedDatasetBuilder.dim_offsets.append", "numpy.array", "indexed_dataset.IndexedDatasetBuilder.sizes.append", "len", "tensor.numpy", "tensor.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "add_item", "(", "self", ",", "tensor", ")", ":", "\n", "# +1 for Lua compatibility", "\n", "        ", "bytes", "=", "self", ".", "out_file", ".", "write", "(", "np", ".", "array", "(", "tensor", ".", "numpy", "(", ")", "+", "1", ",", "dtype", "=", "self", ".", "dtype", ")", ")", "\n", "self", ".", "data_offsets", ".", "append", "(", "self", ".", "data_offsets", "[", "-", "1", "]", "+", "bytes", "/", "self", ".", "element_size", ")", "\n", "for", "s", "in", "tensor", ".", "size", "(", ")", ":", "\n", "            ", "self", ".", "sizes", ".", "append", "(", "s", ")", "\n", "", "self", ".", "dim_offsets", ".", "append", "(", "self", ".", "dim_offsets", "[", "-", "1", "]", "+", "len", "(", "tensor", ".", "size", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDatasetBuilder.merge_file_": [[326, 345], ["indexed_dataset.IndexedDataset", "indexed_dataset.IndexedDatasetBuilder.sizes.extend", "indexed_dataset.IndexedDatasetBuilder.data_offsets.append", "indexed_dataset.IndexedDatasetBuilder.dim_offsets.append", "open", "indexed_dataset.data_file_path", "f.read", "indexed_dataset.IndexedDatasetBuilder.out_file.write"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "def", "merge_file_", "(", "self", ",", "another_file", ")", ":", "\n", "        ", "index", "=", "IndexedDataset", "(", "another_file", ")", "\n", "assert", "index", ".", "dtype", "==", "self", ".", "dtype", "\n", "\n", "begin", "=", "self", ".", "data_offsets", "[", "-", "1", "]", "\n", "for", "offset", "in", "index", ".", "data_offsets", "[", "1", ":", "]", ":", "\n", "            ", "self", ".", "data_offsets", ".", "append", "(", "begin", "+", "offset", ")", "\n", "", "self", ".", "sizes", ".", "extend", "(", "index", ".", "sizes", ")", "\n", "begin", "=", "self", ".", "dim_offsets", "[", "-", "1", "]", "\n", "for", "dim_offset", "in", "index", ".", "dim_offsets", "[", "1", ":", "]", ":", "\n", "            ", "self", ".", "dim_offsets", ".", "append", "(", "begin", "+", "dim_offset", ")", "\n", "\n", "", "with", "open", "(", "data_file_path", "(", "another_file", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "data", "=", "f", ".", "read", "(", "1024", ")", "\n", "if", "data", ":", "\n", "                    ", "self", ".", "out_file", ".", "write", "(", "data", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.IndexedDatasetBuilder.finalize": [[346, 357], ["indexed_dataset.IndexedDatasetBuilder.out_file.close", "open", "open.write", "open.write", "open.write", "open.write", "indexed_dataset.write_longs", "indexed_dataset.write_longs", "indexed_dataset.write_longs", "open.close", "struct.pack", "struct.pack", "struct.pack", "indexed_dataset.code", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.code"], ["", "", "", "", "def", "finalize", "(", "self", ",", "index_file", ")", ":", "\n", "        ", "self", ".", "out_file", ".", "close", "(", ")", "\n", "index", "=", "open", "(", "index_file", ",", "\"wb\"", ")", "\n", "index", ".", "write", "(", "b\"TNTIDX\\x00\\x00\"", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<Q\"", ",", "1", ")", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<QQ\"", ",", "code", "(", "self", ".", "dtype", ")", ",", "self", ".", "element_size", ")", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<QQ\"", ",", "len", "(", "self", ".", "data_offsets", ")", "-", "1", ",", "len", "(", "self", ".", "sizes", ")", ")", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "dim_offsets", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "data_offsets", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "sizes", ")", "\n", "index", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__init__": [[461, 469], ["super().__init__", "indexed_dataset.MMapIndexedDataset._do_init"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset._do_init"], ["", "", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_path", "=", "None", "\n", "self", ".", "_index", "=", "None", "\n", "self", ".", "_bin_buffer", "=", "None", "\n", "\n", "self", ".", "_do_init", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__getstate__": [[470, 472], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_path", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__setstate__": [[473, 475], ["indexed_dataset.MMapIndexedDataset._do_init"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset._do_init"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "_do_init", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset._do_init": [[476, 485], ["indexed_dataset.MMapIndexedDataset.Index", "indexed_dataset._warmup_mmap_file", "numpy.memmap", "memoryview", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset._warmup_mmap_file", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "def", "_do_init", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "_path", "=", "path", "\n", "self", ".", "_index", "=", "self", ".", "Index", "(", "index_file_path", "(", "self", ".", "_path", ")", ")", "\n", "\n", "_warmup_mmap_file", "(", "data_file_path", "(", "self", ".", "_path", ")", ")", "\n", "self", ".", "_bin_buffer_mmap", "=", "np", ".", "memmap", "(", "\n", "data_file_path", "(", "self", ".", "_path", ")", ",", "mode", "=", "\"r\"", ",", "order", "=", "\"C\"", "\n", ")", "\n", "self", ".", "_bin_buffer", "=", "memoryview", "(", "self", ".", "_bin_buffer_mmap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__del__": [[486, 490], ["indexed_dataset.MMapIndexedDataset._bin_buffer_mmap._mmap.close"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_bin_buffer_mmap", ".", "_mmap", ".", "close", "(", ")", "\n", "del", "self", ".", "_bin_buffer_mmap", "\n", "del", "self", ".", "_index", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__len__": [[491, 493], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.__getitem__": [[494, 504], ["functools.lru_cache", "numpy.frombuffer", "torch.from_numpy", "np_array.astype.astype.astype"], "methods", ["None"], ["", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "ptr", ",", "size", "=", "self", ".", "_index", "[", "i", "]", "\n", "np_array", "=", "np", ".", "frombuffer", "(", "\n", "self", ".", "_bin_buffer", ",", "dtype", "=", "self", ".", "_index", ".", "dtype", ",", "count", "=", "size", ",", "offset", "=", "ptr", "\n", ")", "\n", "if", "self", ".", "_index", ".", "dtype", "!=", "np", ".", "int64", ":", "\n", "            ", "np_array", "=", "np_array", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "np_array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.sizes": [[505, 508], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_index", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.supports_prefetch": [[509, 512], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists": [[513, 517], ["fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "index_file_path", "(", "path", ")", ")", "and", "PathManager", ".", "exists", "(", "\n", "data_file_path", "(", "path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDatasetBuilder.__init__": [[535, 539], ["open"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["    ", "def", "__init__", "(", "self", ",", "out_file", ",", "dtype", "=", "np", ".", "int64", ")", ":", "\n", "        ", "self", ".", "_data_file", "=", "open", "(", "out_file", ",", "\"wb\"", ")", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "self", ".", "_sizes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDatasetBuilder.add_item": [[540, 544], ["numpy.array", "indexed_dataset.MMapIndexedDatasetBuilder._data_file.write", "indexed_dataset.MMapIndexedDatasetBuilder._sizes.append", "tensor.numpy", "numpy.array.tobytes"], "methods", ["None"], ["", "def", "add_item", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "np_array", "=", "np", ".", "array", "(", "tensor", ".", "numpy", "(", ")", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "self", ".", "_data_file", ".", "write", "(", "np_array", ".", "tobytes", "(", "order", "=", "\"C\"", ")", ")", "\n", "self", ".", "_sizes", ".", "append", "(", "np_array", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDatasetBuilder.merge_file_": [[545, 556], ["MMapIndexedDataset.Index", "indexed_dataset.index_file_path", "indexed_dataset.MMapIndexedDatasetBuilder._sizes.append", "open", "shutil.copyfileobj", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "def", "merge_file_", "(", "self", ",", "another_file", ")", ":", "\n", "# Concatenate index", "\n", "        ", "index", "=", "MMapIndexedDataset", ".", "Index", "(", "index_file_path", "(", "another_file", ")", ")", "\n", "assert", "index", ".", "dtype", "==", "self", ".", "_dtype", "\n", "\n", "for", "size", "in", "index", ".", "sizes", ":", "\n", "            ", "self", ".", "_sizes", ".", "append", "(", "size", ")", "\n", "\n", "# Concatenate data", "\n", "", "with", "open", "(", "data_file_path", "(", "another_file", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "shutil", ".", "copyfileobj", "(", "f", ",", "self", ".", "_data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize": [[557, 562], ["indexed_dataset.MMapIndexedDatasetBuilder._data_file.close", "MMapIndexedDataset.Index.writer", "index.write"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.nan_detector.NanDetector.close"], ["", "", "def", "finalize", "(", "self", ",", "index_file", ")", ":", "\n", "        ", "self", ".", "_data_file", ".", "close", "(", ")", "\n", "\n", "with", "MMapIndexedDataset", ".", "Index", ".", "writer", "(", "index_file", ",", "self", ".", "_dtype", ")", "as", "index", ":", "\n", "            ", "index", ".", "write", "(", "self", ".", "_sizes", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.__best_fitting_dtype": [[19, 24], ["None"], "function", ["None"], ["def", "__best_fitting_dtype", "(", "vocab_size", "=", "None", ")", ":", "\n", "    ", "if", "vocab_size", "is", "not", "None", "and", "vocab_size", "<", "65500", ":", "\n", "        ", "return", "np", ".", "uint16", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.get_available_dataset_impl": [[26, 28], ["list", "map"], "function", ["None"], ["", "", "def", "get_available_dataset_impl", "(", ")", ":", "\n", "    ", "return", "list", "(", "map", "(", "str", ",", "DATASET_IMPL_CHOICES", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.infer_dataset_impl": [[30, 46], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.IndexedDataset.exists", "fairseq.data.fasta_dataset.FastaDataset.exists", "open", "f.read", "indexed_dataset.index_file_path"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path"], ["", "def", "infer_dataset_impl", "(", "path", ")", ":", "\n", "    ", "if", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "\"raw\"", "\n", "", "elif", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "with", "open", "(", "index_file_path", "(", "path", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "magic", "=", "f", ".", "read", "(", "8", ")", "\n", "if", "magic", "==", "IndexedDataset", ".", "_HDR_MAGIC", ":", "\n", "                ", "return", "\"cached\"", "\n", "", "elif", "magic", "==", "MMapIndexedDataset", ".", "Index", ".", "_HDR_MAGIC", "[", ":", "8", "]", ":", "\n", "                ", "return", "\"mmap\"", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "", "", "", "elif", "FastaDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "\"fasta\"", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.make_builder": [[48, 57], ["indexed_dataset.MMapIndexedDatasetBuilder", "indexed_dataset.IndexedDatasetBuilder", "indexed_dataset.__best_fitting_dtype"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.__best_fitting_dtype"], ["", "", "def", "make_builder", "(", "out_file", ",", "impl", ",", "vocab_size", "=", "None", ")", ":", "\n", "    ", "if", "impl", "==", "\"mmap\"", ":", "\n", "        ", "return", "MMapIndexedDatasetBuilder", "(", "\n", "out_file", ",", "dtype", "=", "__best_fitting_dtype", "(", "vocab_size", ")", "\n", ")", "\n", "", "elif", "impl", "==", "\"fasta\"", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "return", "IndexedDatasetBuilder", "(", "out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.make_dataset": [[59, 74], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.IndexedRawTextDataset", "indexed_dataset.IndexedDataset.exists", "indexed_dataset.IndexedDataset", "indexed_dataset.IndexedDataset.exists", "indexed_dataset.IndexedCachedDataset", "indexed_dataset.MMapIndexedDataset.exists", "indexed_dataset.MMapIndexedDataset", "fairseq.data.fasta_dataset.FastaDataset.exists", "EncodedFastaDataset"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "def", "make_dataset", "(", "path", ",", "impl", ",", "fix_lua_indexing", "=", "False", ",", "dictionary", "=", "None", ")", ":", "\n", "    ", "if", "impl", "==", "\"raw\"", "and", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "assert", "dictionary", "is", "not", "None", "\n", "return", "IndexedRawTextDataset", "(", "path", ",", "dictionary", ")", "\n", "", "elif", "impl", "==", "\"lazy\"", "and", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "IndexedDataset", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "", "elif", "impl", "==", "\"cached\"", "and", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "IndexedCachedDataset", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "", "elif", "impl", "==", "\"mmap\"", "and", "MMapIndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "MMapIndexedDataset", "(", "path", ")", "\n", "", "elif", "impl", "==", "\"fasta\"", "and", "FastaDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "from", "fairseq", ".", "data", ".", "fasta_dataset", "import", "EncodedFastaDataset", "\n", "\n", "return", "EncodedFastaDataset", "(", "path", ",", "dictionary", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.dataset_exists": [[76, 83], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.MMapIndexedDataset.exists", "indexed_dataset.IndexedDataset.exists"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "dataset_exists", "(", "path", ",", "impl", ")", ":", "\n", "    ", "if", "impl", "==", "\"raw\"", ":", "\n", "        ", "return", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", "\n", "", "elif", "impl", "==", "\"mmap\"", ":", "\n", "        ", "return", "MMapIndexedDataset", ".", "exists", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "IndexedDataset", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.read_longs": [[85, 89], ["numpy.empty", "f.readinto"], "function", ["None"], ["", "", "def", "read_longs", "(", "f", ",", "n", ")", ":", "\n", "    ", "a", "=", "np", ".", "empty", "(", "n", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "f", ".", "readinto", "(", "a", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.write_longs": [[91, 93], ["f.write", "numpy.array"], "function", ["None"], ["", "def", "write_longs", "(", "f", ",", "a", ")", ":", "\n", "    ", "f", ".", "write", "(", "np", ".", "array", "(", "a", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.code": [[107, 112], ["dtypes.keys", "ValueError"], "function", ["None"], ["def", "code", "(", "dtype", ")", ":", "\n", "    ", "for", "k", "in", "dtypes", ".", "keys", "(", ")", ":", "\n", "        ", "if", "dtypes", "[", "k", "]", "==", "dtype", ":", "\n", "            ", "return", "k", "\n", "", "", "raise", "ValueError", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path": [[114, 116], ["None"], "function", ["None"], ["", "def", "index_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".idx\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path": [[118, 120], ["None"], "function", ["None"], ["", "def", "data_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".bin\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset._warmup_mmap_file": [[359, 363], ["open", "stream.read"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "", "def", "_warmup_mmap_file", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "stream", ":", "\n", "        ", "while", "stream", ".", "read", "(", "100", "*", "1024", "*", "1024", ")", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.get_indexed_dataset_to_local": [[520, 532], ["fairseq.file_io.PathManager.get_local_path", "fairseq.file_io.PathManager.get_local_path", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path", "PathManager.get_local_path.endswith", "PathManager.get_local_path.endswith"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.data_file_path"], ["", "", "def", "get_indexed_dataset_to_local", "(", "path", ")", "->", "str", ":", "\n", "    ", "local_index_path", "=", "PathManager", ".", "get_local_path", "(", "index_file_path", "(", "path", ")", ")", "\n", "local_data_path", "=", "PathManager", ".", "get_local_path", "(", "data_file_path", "(", "path", ")", ")", "\n", "\n", "assert", "local_index_path", ".", "endswith", "(", "\".idx\"", ")", "and", "local_data_path", ".", "endswith", "(", "\".bin\"", ")", ",", "(", "\n", "\"PathManager.get_local_path does not return files with expected patterns: \"", "\n", "f\"{local_index_path} and {local_data_path}\"", "\n", ")", "\n", "\n", "local_path", "=", "local_data_path", "[", ":", "-", "4", "]", "# stripping surfix \".bin\"", "\n", "assert", "local_path", "==", "local_index_path", "[", ":", "-", "4", "]", "# stripping surfix \".idx\"", "\n", "return", "local_path", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.__init__": [[12, 15], ["FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.__getitem__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.__len__": [[19, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.collater": [[22, 27], ["hasattr", "base_wrapper_dataset.BaseWrapperDataset.dataset.collater", "torch.utils.data.dataloader.default_collate"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"collater\"", ")", ":", "\n", "            ", "return", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "", "else", ":", "\n", "            ", "return", "default_collate", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.sizes": [[28, 31], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.num_tokens": [[32, 34], ["base_wrapper_dataset.BaseWrapperDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.size": [[35, 37], ["base_wrapper_dataset.BaseWrapperDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.ordered_indices": [[38, 40], ["base_wrapper_dataset.BaseWrapperDataset.dataset.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.supports_prefetch": [[41, 44], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.attr": [[45, 47], ["base_wrapper_dataset.BaseWrapperDataset.dataset.attr"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.attr"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "attr", "(", "attr", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.prefetch": [[48, 50], ["base_wrapper_dataset.BaseWrapperDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.get_batch_shapes": [[51, 53], ["base_wrapper_dataset.BaseWrapperDataset.dataset.get_batch_shapes"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.get_batch_shapes"], ["", "def", "get_batch_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "get_batch_shapes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size": [[54, 66], ["base_wrapper_dataset.BaseWrapperDataset.dataset.batch_by_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size"], ["", "def", "batch_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.filter_indices_by_size": [[68, 70], ["base_wrapper_dataset.BaseWrapperDataset.dataset.filter_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.filter_indices_by_size"], ["", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "filter_indices_by_size", "(", "indices", ",", "max_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.can_reuse_epoch_itr_across_epochs": [[71, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "can_reuse_epoch_itr_across_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch": [[75, 79], ["super().set_epoch", "hasattr", "base_wrapper_dataset.BaseWrapperDataset.dataset.set_epoch"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.__init__": [[23, 45], ["FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sample_rate", ",", "\n", "max_sample_size", "=", "None", ",", "\n", "min_sample_size", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "pad", "=", "False", ",", "\n", "normalize", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "max_sample_size", "=", "(", "\n", "max_sample_size", "if", "max_sample_size", "is", "not", "None", "else", "sys", ".", "maxsize", "\n", ")", "\n", "self", ".", "min_sample_size", "=", "min_sample_size", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.__getitem__": [[46, 48], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.__len__": [[49, 51], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.postprocess": [[52, 65], ["torch.layer_norm.dim", "torch.layer_norm.dim", "torch.layer_norm.mean", "Exception", "torch.layer_norm.dim", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.layer_norm", "torch.layer_norm"], "methods", ["None"], ["", "def", "postprocess", "(", "self", ",", "feats", ",", "curr_sample_rate", ")", ":", "\n", "        ", "if", "feats", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "feats", "=", "feats", ".", "mean", "(", "-", "1", ")", "\n", "\n", "", "if", "curr_sample_rate", "!=", "self", ".", "sample_rate", ":", "\n", "            ", "raise", "Exception", "(", "f\"sample rate: {curr_sample_rate}, need {self.sample_rate}\"", ")", "\n", "\n", "", "assert", "feats", ".", "dim", "(", ")", "==", "1", ",", "feats", ".", "dim", "(", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "feats", "=", "F", ".", "layer_norm", "(", "feats", ",", "feats", ".", "shape", ")", "\n", "", "", "return", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.crop_to_max_size": [[66, 75], ["len", "numpy.random.randint"], "methods", ["None"], ["", "def", "crop_to_max_size", "(", "self", ",", "wav", ",", "target_size", ")", ":", "\n", "        ", "size", "=", "len", "(", "wav", ")", "\n", "diff", "=", "size", "-", "target_size", "\n", "if", "diff", "<=", "0", ":", "\n", "            ", "return", "wav", "\n", "\n", "", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "diff", "+", "1", ")", "\n", "end", "=", "size", "-", "diff", "+", "start", "\n", "return", "wav", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.collater": [[76, 110], ["sources[].new_zeros", "enumerate", "len", "len", "min", "min", "len", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "zip", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max", "min", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "raw_audio_dataset.RawAudioDataset.crop_to_max_size", "source.new_full"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.crop_to_max_size"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "samples", "=", "[", "s", "for", "s", "in", "samples", "if", "s", "[", "\"source\"", "]", "is", "not", "None", "]", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "", "sources", "=", "[", "s", "[", "\"source\"", "]", "for", "s", "in", "samples", "]", "\n", "sizes", "=", "[", "len", "(", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "target_size", "=", "min", "(", "max", "(", "sizes", ")", ",", "self", ".", "max_sample_size", ")", "\n", "", "else", ":", "\n", "            ", "target_size", "=", "min", "(", "min", "(", "sizes", ")", ",", "self", ".", "max_sample_size", ")", "\n", "\n", "", "collated_sources", "=", "sources", "[", "0", "]", ".", "new_zeros", "(", "len", "(", "sources", ")", ",", "target_size", ")", "\n", "padding_mask", "=", "(", "\n", "torch", ".", "BoolTensor", "(", "collated_sources", ".", "shape", ")", ".", "fill_", "(", "False", ")", "if", "self", ".", "pad", "else", "None", "\n", ")", "\n", "for", "i", ",", "(", "source", ",", "size", ")", "in", "enumerate", "(", "zip", "(", "sources", ",", "sizes", ")", ")", ":", "\n", "            ", "diff", "=", "size", "-", "target_size", "\n", "if", "diff", "==", "0", ":", "\n", "                ", "collated_sources", "[", "i", "]", "=", "source", "\n", "", "elif", "diff", "<", "0", ":", "\n", "                ", "assert", "self", ".", "pad", "\n", "collated_sources", "[", "i", "]", "=", "torch", ".", "cat", "(", "\n", "[", "source", ",", "source", ".", "new_full", "(", "(", "-", "diff", ",", ")", ",", "0.0", ")", "]", "\n", ")", "\n", "padding_mask", "[", "i", ",", "diff", ":", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "collated_sources", "[", "i", "]", "=", "self", ".", "crop_to_max_size", "(", "source", ",", "target_size", ")", "\n", "\n", "", "", "input", "=", "{", "\"source\"", ":", "collated_sources", "}", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "input", "[", "\"padding_mask\"", "]", "=", "padding_mask", "\n", "", "return", "{", "\"id\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", ",", "\"net_input\"", ":", "input", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.num_tokens": [[111, 113], ["raw_audio_dataset.RawAudioDataset.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.size": [[114, 120], ["min"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "", "return", "min", "(", "self", ".", "sizes", "[", "index", "]", ",", "self", ".", "max_sample_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.ordered_indices": [[121, 132], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "\n", "", "order", ".", "append", "(", "self", ".", "sizes", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.FileAudioDataset.__init__": [[135, 175], ["raw_audio_dataset.RawAudioDataset.__init__", "set", "logger.info", "open", "f.readline().strip", "enumerate", "line.strip().split", "int", "raw_audio_dataset.FileAudioDataset.fnames.append", "raw_audio_dataset.FileAudioDataset.line_inds.add", "raw_audio_dataset.FileAudioDataset.sizes.append", "f.readline", "len", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "manifest_path", ",", "\n", "sample_rate", ",", "\n", "max_sample_size", "=", "None", ",", "\n", "min_sample_size", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "pad", "=", "False", ",", "\n", "normalize", "=", "False", ",", "\n", "del_silence", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "max_sample_size", "=", "max_sample_size", ",", "\n", "min_sample_size", "=", "min_sample_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "min_length", "=", "min_length", ",", "\n", "pad", "=", "pad", ",", "\n", "normalize", "=", "normalize", ",", "\n", ")", "\n", "\n", "self", ".", "fnames", "=", "[", "]", "\n", "self", ".", "line_inds", "=", "set", "(", ")", "\n", "self", ".", "del_silence", "=", "del_silence", "\n", "\n", "skipped", "=", "0", "\n", "with", "open", "(", "manifest_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "root_dir", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "assert", "len", "(", "items", ")", "==", "2", ",", "line", "\n", "sz", "=", "int", "(", "items", "[", "1", "]", ")", "\n", "if", "min_length", "is", "not", "None", "and", "sz", "<", "min_length", ":", "\n", "                    ", "skipped", "+=", "1", "\n", "continue", "\n", "", "self", ".", "fnames", ".", "append", "(", "items", "[", "0", "]", ")", "\n", "self", ".", "line_inds", ".", "add", "(", "i", ")", "\n", "self", ".", "sizes", ".", "append", "(", "sz", ")", "\n", "", "", "logger", ".", "info", "(", "f\"loaded {len(self.fnames)}, skipped {skipped} samples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.FileAudioDataset.__getitem__": [[176, 195], ["os.path.join", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "raw_audio_dataset.FileAudioDataset.postprocess", "sf.read", "librosa.effects.split", "numpy.concatenate", "pathlib.Path", "ValueError", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "pathlib.Path", "numpy.memmap().astype", "numpy.memmap", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.raw_audio_dataset.RawAudioDataset.postprocess"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "import", "soundfile", "as", "sf", "\n", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "self", ".", "fnames", "[", "index", "]", ")", "\n", "if", "Path", "(", "fname", ")", ".", "suffix", "==", "'.wav'", ":", "\n", "            ", "wav", ",", "curr_sample_rate", "=", "sf", ".", "read", "(", "fname", ")", "\n", "", "elif", "Path", "(", "fname", ")", ".", "suffix", "==", "'.pcm'", ":", "\n", "            ", "wav", "=", "np", ".", "memmap", "(", "fname", ",", "dtype", "=", "'h'", ",", "mode", "=", "'r'", ")", ".", "astype", "(", "'float32'", ")", "/", "32767", "\n", "curr_sample_rate", "=", "16000", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported preprocess method : {0}\"", ".", "format", "(", "Path", "(", "fname", ")", ".", "suffix", ")", ")", "\n", "\n", "", "if", "self", ".", "del_silence", ":", "\n", "            ", "non_silence_indices", "=", "librosa", ".", "effects", ".", "split", "(", "wav", ",", "top_db", "=", "30", ")", "\n", "wav", "=", "np", ".", "concatenate", "(", "[", "wav", "[", "start", ":", "end", "]", "for", "start", ",", "end", "in", "non_silence_indices", "]", ")", "\n", "\n", "", "feats", "=", "torch", ".", "from_numpy", "(", "wav", ")", ".", "float", "(", ")", "\n", "feats", "=", "self", ".", "postprocess", "(", "feats", ",", "curr_sample_rate", ")", "\n", "return", "{", "\"id\"", ":", "index", ",", "\"source\"", ":", "feats", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.__init__": [[32, 46], ["os.isfile", "logger.info", "print", "open", "yaml.load", "logger.info"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.logging.progress_bar.AzureMLProgressBarWrapper.print", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load"], ["def", "__init__", "(", "self", ",", "yaml_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install PyYAML to load YAML files for \"", "\"S2T data config\"", ")", "\n", "", "self", ".", "config", "=", "{", "}", "\n", "if", "op", ".", "isfile", "(", "yaml_path", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "with", "open", "(", "yaml_path", ")", "as", "f", ":", "\n", "                    ", "self", ".", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "logger", ".", "info", "(", "f\"Failed to load config from {yaml_path}: {e}\"", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Cannot find {yaml_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.vocab_filename": [[47, 51], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "vocab_filename", "(", "self", ")", ":", "\n", "        ", "\"\"\"fairseq vocabulary file under data root\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"vocab_filename\"", ",", "\"dict.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.shuffle": [[52, 56], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "shuffle", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Shuffle dataset samples before batching\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"shuffle\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.pre_tokenizer": [[57, 64], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "pre_tokenizer", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Pre-tokenizer to apply before subword tokenization. Returning\n        a dictionary with `tokenizer` providing the tokenizer name and\n        the other items providing the tokenizer-specific arguments.\n        Tokenizers are defined in `fairseq.data.encoders.*`\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"pre_tokenizer\"", ",", "{", "\"tokenizer\"", ":", "None", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.bpe_tokenizer": [[65, 72], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "bpe_tokenizer", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Subword tokenizer to apply after pre-tokenization. Returning\n        a dictionary with `bpe` providing the tokenizer name and\n        the other items providing the tokenizer-specific arguments.\n        Tokenizers are defined in `fairseq.data.encoders.*`\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"bpe_tokenizer\"", ",", "{", "\"bpe\"", ":", "None", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.prepend_tgt_lang_tag": [[73, 79], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "prepend_tgt_lang_tag", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Prepend target lang ID token as the target BOS (e.g. for to-many\n        multilingual setting). During inference, this requires `--prefix-size 1`\n        to force BOS to be lang ID token.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"prepend_tgt_lang_tag\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.input_feat_per_channel": [[80, 84], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_feat_per_channel", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dimension of input features (per audio channel)\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"input_feat_per_channel\"", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.input_channels": [[85, 89], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_channels", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of channels in the input audio\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"input_channels\"", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.sampling_alpha": [[90, 95], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "sampling_alpha", "(", "self", ")", ":", "\n", "        ", "\"\"\"Hyper-parameter alpha = 1/T for temperature-based resampling.\n        (alpha = 1 for no resampling)\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"sampling_alpha\"", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.use_audio_input": [[96, 101], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "use_audio_input", "(", "self", ")", ":", "\n", "        ", "\"\"\"Needed by the dataset loader to see if the model requires\n        raw audio as inputs.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"use_audio_input\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.audio_root": [[102, 107], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "audio_root", "(", "self", ")", ":", "\n", "        ", "\"\"\"Audio paths in the manifest TSV can be relative and this provides\n        the root path. Set this to empty string when using absolute paths.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"audio_root\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.get_feature_transforms": [[108, 121], ["deepcopy", "deepcopy.get", "deepcopy.get.get", "deepcopy.get.get", "deepcopy.get.get", "deepcopy.get.get"], "methods", ["None"], ["", "def", "get_feature_transforms", "(", "self", ",", "split", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Split-specific feature transforms. Allowing train set wildcard `_train`,\n        evaluation set wildcard `_eval` and general wildcard `*` for matching.\"\"\"", "\n", "from", "copy", "import", "deepcopy", "\n", "\n", "cfg", "=", "deepcopy", "(", "self", ".", "config", ")", "\n", "_cur", "=", "cfg", ".", "get", "(", "\"transforms\"", ",", "{", "}", ")", "\n", "cur", "=", "_cur", ".", "get", "(", "split", ")", "\n", "cur", "=", "_cur", ".", "get", "(", "\"_train\"", ")", "if", "cur", "is", "None", "and", "is_train", "else", "cur", "\n", "cur", "=", "_cur", ".", "get", "(", "\"_eval\"", ")", "if", "cur", "is", "None", "and", "not", "is_train", "else", "cur", "\n", "cur", "=", "_cur", ".", "get", "(", "\"*\"", ")", "if", "cur", "is", "None", "else", "cur", "\n", "cfg", "[", "\"transforms\"", "]", "=", "cur", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__init__": [[218, 264], ["len", "speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag", "fairseq.data.audio.feature_transforms.CompositeAudioFeatureTransform.from_config_dict", "logger.info", "len", "speech_to_text_dataset.SpeechToTextDataset.data_cfg.get_feature_transforms", "speech_to_text_dataset.SpeechToTextDataset.__repr__", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.S2TDataConfig.get_feature_transforms", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__repr__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "split", ":", "str", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "audio_paths", ":", "List", "[", "str", "]", ",", "\n", "n_frames", ":", "List", "[", "int", "]", ",", "\n", "src_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "speakers", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "src_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "ids", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_dict", ":", "Optional", "[", "Dictionary", "]", "=", "None", ",", "\n", "pre_tokenizer", "=", "None", ",", "\n", "bpe_tokenizer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "split", ",", "self", ".", "is_train_split", "=", "split", ",", "is_train_split", "\n", "self", ".", "data_cfg", "=", "data_cfg", "\n", "self", ".", "audio_paths", ",", "self", ".", "n_frames", "=", "audio_paths", ",", "n_frames", "\n", "self", ".", "n_samples", "=", "len", "(", "audio_paths", ")", "\n", "assert", "len", "(", "n_frames", ")", "==", "self", ".", "n_samples", ">", "0", "\n", "assert", "src_texts", "is", "None", "or", "len", "(", "src_texts", ")", "==", "self", ".", "n_samples", "\n", "assert", "tgt_texts", "is", "None", "or", "len", "(", "tgt_texts", ")", "==", "self", ".", "n_samples", "\n", "assert", "speakers", "is", "None", "or", "len", "(", "speakers", ")", "==", "self", ".", "n_samples", "\n", "assert", "src_langs", "is", "None", "or", "len", "(", "src_langs", ")", "==", "self", ".", "n_samples", "\n", "assert", "tgt_langs", "is", "None", "or", "len", "(", "tgt_langs", ")", "==", "self", ".", "n_samples", "\n", "assert", "ids", "is", "None", "or", "len", "(", "ids", ")", "==", "self", ".", "n_samples", "\n", "assert", "(", "tgt_dict", "is", "None", "and", "tgt_texts", "is", "None", ")", "or", "(", "\n", "tgt_dict", "is", "not", "None", "and", "tgt_texts", "is", "not", "None", "\n", ")", "\n", "self", ".", "src_texts", ",", "self", ".", "tgt_texts", "=", "src_texts", ",", "tgt_texts", "\n", "self", ".", "src_langs", ",", "self", ".", "tgt_langs", "=", "src_langs", ",", "tgt_langs", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "check_tgt_lang_tag", "(", ")", "\n", "self", ".", "ids", "=", "ids", "\n", "self", ".", "shuffle", "=", "data_cfg", ".", "shuffle", "if", "is_train_split", "else", "False", "\n", "\n", "self", ".", "feature_transforms", "=", "CompositeAudioFeatureTransform", ".", "from_config_dict", "(", "\n", "self", ".", "data_cfg", ".", "get_feature_transforms", "(", "split", ",", "is_train_split", ")", "\n", ")", "\n", "\n", "self", ".", "pre_tokenizer", "=", "pre_tokenizer", "\n", "self", ".", "bpe_tokenizer", "=", "bpe_tokenizer", "\n", "\n", "logger", ".", "info", "(", "self", ".", "__repr__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__repr__": [[265, 269], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "__class__", ".", "__name__", "\n", "+", "f'(split=\"{self.split}\", n_samples={self.n_samples}, '", "\n", "f\"prepend_tgt_lang_tag={self.data_cfg.prepend_tgt_lang_tag}, \"", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.is_lang_tag": [[273, 277], ["cls.LANG_TAG_TEMPLATE.replace", "re.match"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "is_lang_tag", "(", "cls", ",", "token", ")", ":", "\n", "        ", "pattern", "=", "cls", ".", "LANG_TAG_TEMPLATE", ".", "replace", "(", "\"{}\"", ",", "\"(.*)\"", ")", "\n", "return", "re", ".", "match", "(", "pattern", ",", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag": [[278, 285], ["all", "speech_to_text_dataset.SpeechToTextDataset.LANG_TAG_TEMPLATE.format", "set"], "methods", ["None"], ["", "def", "check_tgt_lang_tag", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", ":", "\n", "            ", "assert", "self", ".", "tgt_langs", "is", "not", "None", "and", "self", ".", "tgt_dict", "is", "not", "None", "\n", "tgt_lang_tags", "=", "[", "\n", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "t", ")", "for", "t", "in", "set", "(", "self", ".", "tgt_langs", ")", "\n", "]", "\n", "assert", "all", "(", "t", "in", "self", ".", "tgt_dict", "for", "t", "in", "tgt_lang_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text": [[286, 292], ["speech_to_text_dataset.SpeechToTextDataset.pre_tokenizer.encode", "speech_to_text_dataset.SpeechToTextDataset.bpe_tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "", "def", "tokenize_text", "(", "self", ",", "text", ":", "str", ")", ":", "\n", "        ", "if", "self", ".", "pre_tokenizer", "is", "not", "None", ":", "\n", "            ", "text", "=", "self", ".", "pre_tokenizer", ".", "encode", "(", "text", ")", "\n", "", "if", "self", ".", "bpe_tokenizer", "is", "not", "None", ":", "\n", "            ", "text", "=", "self", ".", "bpe_tokenizer", ".", "encode", "(", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__getitem__": [[293, 315], ["speech_to_text_dataset.get_features_or_waveform", "torch.from_numpy().float", "speech_to_text_dataset.SpeechToTextDataset.feature_transforms", "speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.encode_line().long", "torch.from_numpy", "speech_to_text_dataset.SpeechToTextDataset.LANG_TAG_TEMPLATE.format", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.index", "torch.cat", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.encode_line", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_or_waveform", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.encode_line"], ["", "def", "__getitem__", "(", "\n", "self", ",", "index", ":", "int", "\n", ")", "->", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "source", "=", "get_features_or_waveform", "(", "\n", "self", ".", "audio_paths", "[", "index", "]", ",", "need_waveform", "=", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "if", "self", ".", "feature_transforms", "is", "not", "None", ":", "\n", "            ", "assert", "not", "self", ".", "data_cfg", ".", "use_audio_input", "\n", "source", "=", "self", ".", "feature_transforms", "(", "source", ")", "\n", "", "source", "=", "torch", ".", "from_numpy", "(", "source", ")", ".", "float", "(", ")", "\n", "\n", "target", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "tgt_texts", "[", "index", "]", ")", "\n", "target", "=", "self", ".", "tgt_dict", ".", "encode_line", "(", "\n", "tokenized", ",", "add_if_not_exist", "=", "False", ",", "append_eos", "=", "True", "\n", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", ":", "\n", "                ", "lang_tag", "=", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "self", ".", "tgt_langs", "[", "index", "]", ")", "\n", "lang_tag_idx", "=", "self", ".", "tgt_dict", ".", "index", "(", "lang_tag", ")", "\n", "target", "=", "torch", ".", "cat", "(", "(", "torch", ".", "LongTensor", "(", "[", "lang_tag_idx", "]", ")", ",", "target", ")", ",", "0", ")", "\n", "", "", "return", "index", ",", "source", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.__len__": [[316, 318], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.collater": [[319, 370], ["torch.tensor", "speech_to_text_dataset._collate_frames", "torch.tensor", "torch.tensor.sort", "indices.index_select.index_select.index_select", "frames.index_select.index_select.index_select", "len", "fairseq.data.data_utils.collate_tokens", "target.index_select.index_select.index_select", "torch.tensor().index_select", "fairseq.data.data_utils.collate_tokens", "prev_output_tokens.index_select.index_select.index_select", "sum", "len", "s.size", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.pad", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.eos", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.pad", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.eos", "torch.tensor", "t.size", "t.size"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset._collate_frames", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", ":", "\n", "        ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "indices", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", ",", "_", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "frames", "=", "_collate_frames", "(", "\n", "[", "s", "for", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "# sort samples by descending number of frames", "\n", "n_frames", "=", "torch", ".", "tensor", "(", "[", "s", ".", "size", "(", "0", ")", "for", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "n_frames", ",", "order", "=", "n_frames", ".", "sort", "(", "descending", "=", "True", ")", "\n", "indices", "=", "indices", ".", "index_select", "(", "0", ",", "order", ")", "\n", "frames", "=", "frames", ".", "index_select", "(", "0", ",", "order", ")", "\n", "\n", "target", ",", "target_lengths", "=", "None", ",", "None", "\n", "prev_output_tokens", "=", "None", "\n", "ntokens", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "target", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "target", "=", "target", ".", "index_select", "(", "0", ",", "order", ")", "\n", "target_lengths", "=", "torch", ".", "tensor", "(", "\n", "[", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "index_select", "(", "0", ",", "order", ")", "\n", "prev_output_tokens", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "prev_output_tokens", "=", "prev_output_tokens", ".", "index_select", "(", "0", ",", "order", ")", "\n", "ntokens", "=", "sum", "(", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "t", "in", "samples", ")", "\n", "\n", "", "out", "=", "{", "\n", "\"id\"", ":", "indices", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "frames", ",", "\n", "\"src_lengths\"", ":", "n_frames", ",", "\n", "\"prev_output_tokens\"", ":", "prev_output_tokens", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "\"target_lengths\"", ":", "target_lengths", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.num_tokens": [[371, 373], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "n_frames", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size": [[374, 380], ["speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "len", "speech_to_text_dataset.SpeechToTextDataset.split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "t_len", "=", "0", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "tgt_texts", "[", "index", "]", ")", "\n", "t_len", "=", "len", "(", "tokenized", ".", "split", "(", "\" \"", ")", ")", "\n", "", "return", "self", ".", "n_frames", "[", "index", "]", ",", "t_len", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.sizes": [[381, 384], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "self", ".", "n_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.can_reuse_epoch_itr_across_epochs": [[385, 388], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.ordered_indices": [[389, 397], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "# first by descending order of # of frames then by original/random order", "\n", "", "order", ".", "append", "(", "[", "-", "n", "for", "n", "in", "self", ".", "n_frames", "]", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.prefetch": [[398, 400], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "raise", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._from_list": [[412, 453], ["speech_to_text_dataset.SpeechToTextDataset", "ids.extend", "audio_paths.extend", "n_frames.extend", "tgt_texts.extend", "src_texts.extend", "speakers.extend", "src_langs.extend", "tgt_langs.extend", "os.join", "int", "ss.get", "ss.get", "ss.get", "ss.get"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_from_list", "(", "\n", "cls", ",", "\n", "split_name", ":", "str", ",", "\n", "is_train_split", ",", "\n", "samples", ":", "List", "[", "List", "[", "Dict", "]", "]", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "->", "SpeechToTextDataset", ":", "\n", "        ", "audio_paths", ",", "n_frames", ",", "src_texts", ",", "tgt_texts", ",", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "speakers", ",", "src_langs", ",", "tgt_langs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "s", "in", "samples", ":", "\n", "            ", "ids", ".", "extend", "(", "[", "ss", "[", "cls", ".", "KEY_ID", "]", "for", "ss", "in", "s", "]", ")", "\n", "audio_paths", ".", "extend", "(", "\n", "[", "op", ".", "join", "(", "data_cfg", ".", "audio_root", ",", "ss", "[", "cls", ".", "KEY_AUDIO", "]", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "n_frames", ".", "extend", "(", "[", "int", "(", "ss", "[", "cls", ".", "KEY_N_FRAMES", "]", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_texts", ".", "extend", "(", "[", "ss", "[", "cls", ".", "KEY_TGT_TEXT", "]", "for", "ss", "in", "s", "]", ")", "\n", "src_texts", ".", "extend", "(", "\n", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_TEXT", ",", "cls", ".", "DEFAULT_SRC_TEXT", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "speakers", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SPEAKER", ",", "cls", ".", "DEFAULT_SPEAKER", ")", "for", "ss", "in", "s", "]", ")", "\n", "src_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_TGT_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "", "return", "SpeechToTextDataset", "(", "\n", "split_name", ",", "\n", "is_train_split", ",", "\n", "data_cfg", ",", "\n", "audio_paths", ",", "\n", "n_frames", ",", "\n", "src_texts", ",", "\n", "tgt_texts", ",", "\n", "speakers", ",", "\n", "src_langs", ",", "\n", "tgt_langs", ",", "\n", "ids", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._get_size_ratios": [[455, 472], ["numpy.array", "str", "logger.info", "str", "logger.info", "str", "logger.info", "size_ratio.tolist", "numpy.array.sum", "smoothed_prob.sum", "numpy.array.sum", "enumerate", "enumerate", "enumerate"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_size_ratios", "(", "cls", ",", "ids", ":", "List", "[", "str", "]", ",", "sizes", ":", "List", "[", "int", "]", ",", "alpha", ":", "float", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Size ratios for temperature-based sampling\n        (https://arxiv.org/abs/1907.05019)\"\"\"", "\n", "_sizes", "=", "np", ".", "array", "(", "sizes", ")", "\n", "prob", "=", "_sizes", "/", "_sizes", ".", "sum", "(", ")", "\n", "smoothed_prob", "=", "prob", "**", "alpha", "\n", "smoothed_prob", "=", "smoothed_prob", "/", "smoothed_prob", ".", "sum", "(", ")", "\n", "size_ratio", "=", "(", "smoothed_prob", "*", "_sizes", ".", "sum", "(", ")", ")", "/", "_sizes", "\n", "\n", "o_str", "=", "str", "(", "{", "_i", ":", "f\"{prob[i]:.3f}\"", "for", "i", ",", "_i", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"original sampling probability: {o_str}\"", ")", "\n", "p_str", "=", "str", "(", "{", "_i", ":", "f\"{smoothed_prob[i]:.3f}\"", "for", "i", ",", "_i", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"balanced sampling probability: {p_str}\"", ")", "\n", "sr_str", "=", "str", "(", "{", "_id", ":", "f\"{size_ratio[i]:.3f}\"", "for", "i", ",", "_id", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"balanced sampling size ratio: {sr_str}\"", ")", "\n", "return", "size_ratio", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDatasetCreator.from_tsv": [[473, 529], ["splits.split", "fairseq.data.ConcatDataset", "os.join", "cls._from_list", "cls._get_size_ratios", "os.isfile", "FileNotFoundError", "open", "csv.DictReader", "samples.append", "zip", "len", "fairseq.data.ResamplingDataset", "len", "len", "zip", "dict"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._from_list", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._get_size_ratios", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "@", "classmethod", "\n", "def", "from_tsv", "(", "\n", "cls", ",", "\n", "root", ":", "str", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "splits", ":", "str", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "epoch", ":", "int", ",", "\n", "seed", ":", "int", ",", "\n", ")", "->", "SpeechToTextDataset", ":", "\n", "        ", "samples", "=", "[", "]", "\n", "_splits", "=", "splits", ".", "split", "(", "\",\"", ")", "\n", "for", "split", "in", "_splits", ":", "\n", "            ", "tsv_path", "=", "op", ".", "join", "(", "root", ",", "f\"{split}.tsv\"", ")", "\n", "if", "not", "op", ".", "isfile", "(", "tsv_path", ")", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "f\"Dataset not found: {tsv_path}\"", ")", "\n", "", "with", "open", "(", "tsv_path", ")", "as", "f", ":", "\n", "                ", "reader", "=", "csv", ".", "DictReader", "(", "\n", "f", ",", "\n", "delimiter", "=", "\"\\t\"", ",", "\n", "quotechar", "=", "None", ",", "\n", "doublequote", "=", "False", ",", "\n", "lineterminator", "=", "\"\\n\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", ")", "\n", "samples", ".", "append", "(", "[", "dict", "(", "e", ")", "for", "e", "in", "reader", "]", ")", "\n", "assert", "len", "(", "samples", ")", ">", "0", "\n", "\n", "", "", "datasets", "=", "[", "\n", "cls", ".", "_from_list", "(", "\n", "name", ",", "\n", "is_train_split", ",", "\n", "[", "s", "]", ",", "\n", "data_cfg", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n", "for", "name", ",", "s", "in", "zip", "(", "_splits", ",", "samples", ")", "\n", "]", "\n", "\n", "if", "is_train_split", "and", "len", "(", "_splits", ")", ">", "1", "and", "data_cfg", ".", "sampling_alpha", "!=", "1.0", ":", "\n", "# temperature-based sampling", "\n", "            ", "size_ratios", "=", "cls", ".", "_get_size_ratios", "(", "\n", "_splits", ",", "[", "len", "(", "s", ")", "for", "s", "in", "samples", "]", ",", "alpha", "=", "data_cfg", ".", "sampling_alpha", "\n", ")", "\n", "datasets", "=", "[", "\n", "ResamplingDataset", "(", "\n", "d", ",", "size_ratio", "=", "r", ",", "seed", "=", "seed", ",", "epoch", "=", "epoch", ",", "replace", "=", "(", "r", ">=", "1.0", ")", "\n", ")", "\n", "for", "d", ",", "r", "in", "zip", "(", "datasets", ",", "size_ratios", ")", "\n", "]", "\n", "", "return", "ConcatDataset", "(", "datasets", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.is_npy_data": [[123, 125], ["None"], "function", ["None"], ["", "", "def", "is_npy_data", "(", "data", ":", "bytes", ")", "->", "bool", ":", "\n", "    ", "return", "data", "[", "0", "]", "==", "147", "and", "data", "[", "1", "]", "==", "78", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.is_flac_or_wav_data": [[127, 131], ["None"], "function", ["None"], ["", "def", "is_flac_or_wav_data", "(", "data", ":", "bytes", ")", "->", "bool", ":", "\n", "    ", "is_flac", "=", "data", "[", "0", "]", "==", "102", "and", "data", "[", "1", "]", "==", "76", "\n", "is_wav", "=", "data", "[", "0", "]", "==", "82", "and", "data", "[", "1", "]", "==", "73", "\n", "return", "is_flac", "or", "is_wav", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.read_from_uncompressed_zip": [[133, 138], ["open", "f.seek", "f.read"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "def", "read_from_uncompressed_zip", "(", "file_path", ",", "offset", ",", "file_size", ")", "->", "bytes", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "seek", "(", "offset", ")", "\n", "data", "=", "f", ".", "read", "(", "file_size", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_from_npy_or_audio": [[140, 145], ["os.splitext", "ValueError", "numpy.load", "fairseq.data.audio.audio_utils.get_fbank", "os.basename"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_fbank"], ["", "def", "get_features_from_npy_or_audio", "(", "path", ")", ":", "\n", "    ", "ext", "=", "op", ".", "splitext", "(", "op", ".", "basename", "(", "path", ")", ")", "[", "1", "]", "\n", "if", "ext", "not", "in", "{", "\".npy\"", ",", "\".flac\"", ",", "\".wav\"", "}", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unsupported file format for \"{path}\"'", ")", "\n", "", "return", "np", ".", "load", "(", "path", ")", "if", "ext", "==", "\".npy\"", "else", "get_fbank", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip": [[147, 160], ["path.endswith", "speech_to_text_dataset.read_from_uncompressed_zip", "io.BytesIO", "speech_to_text_dataset.is_npy_data", "numpy.load", "speech_to_text_dataset.is_flac_or_wav_data", "ValueError", "fairseq.data.audio.audio_utils.get_fbank", "fairseq.data.audio.audio_utils.get_waveform"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.read_from_uncompressed_zip", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.is_npy_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.is_flac_or_wav_data", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_fbank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_waveform"], ["", "def", "get_features_or_waveform_from_uncompressed_zip", "(", "\n", "path", ",", "byte_offset", ",", "byte_size", ",", "need_waveform", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "path", ".", "endswith", "(", "\".zip\"", ")", "\n", "data", "=", "read_from_uncompressed_zip", "(", "path", ",", "byte_offset", ",", "byte_size", ")", "\n", "f", "=", "io", ".", "BytesIO", "(", "data", ")", "\n", "if", "is_npy_data", "(", "data", ")", ":", "\n", "        ", "features_or_waveform", "=", "np", ".", "load", "(", "f", ")", "\n", "", "elif", "is_flac_or_wav_data", "(", "data", ")", ":", "\n", "        ", "features_or_waveform", "=", "get_waveform", "(", "f", ")", "[", "0", "]", "if", "need_waveform", "else", "get_fbank", "(", "f", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unknown file format for \"{path}\"'", ")", "\n", "", "return", "features_or_waveform", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_or_waveform": [[162, 192], ["path.split", "os.exists", "FileNotFoundError", "len", "speech_to_text_dataset.get_features_from_npy_or_audio", "fairseq.data.audio.audio_utils.get_waveform", "len", "speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip", "ValueError", "int"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_from_npy_or_audio", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_waveform", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip"], ["", "def", "get_features_or_waveform", "(", "path", ":", "str", ",", "need_waveform", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get speech features from .npy file or waveform from .wav/.flac file.\n    The file may be inside an uncompressed ZIP file and is accessed via byte\n    offset and length.\n\n    Args:\n        path (str): File path in the format of \"<.npy/.wav/.flac path>\" or\n        \"<zip path>:<byte offset>:<byte length>\".\n        need_waveform (bool): return waveform instead of features.\n\n    Returns:\n        features_or_waveform (numpy.ndarray): speech features or waveform.\n    \"\"\"", "\n", "_path", ",", "*", "extra", "=", "path", ".", "split", "(", "\":\"", ")", "\n", "if", "not", "op", ".", "exists", "(", "_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"File not found: {_path}\"", ")", "\n", "\n", "", "if", "len", "(", "extra", ")", "==", "0", ":", "\n", "        ", "if", "need_waveform", ":", "\n", "            ", "return", "get_waveform", "(", "_path", ")", "\n", "", "return", "get_features_from_npy_or_audio", "(", "_path", ")", "\n", "", "elif", "len", "(", "extra", ")", "==", "2", ":", "\n", "        ", "extra", "=", "[", "int", "(", "i", ")", "for", "i", "in", "extra", "]", "\n", "features_or_waveform", "=", "get_features_or_waveform_from_uncompressed_zip", "(", "\n", "_path", ",", "extra", "[", "0", "]", ",", "extra", "[", "1", "]", ",", "need_waveform", "=", "need_waveform", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid path: {path}\"", ")", "\n", "\n", "", "return", "features_or_waveform", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset._collate_frames": [[194, 213], ["max", "enumerate", "frames[].new_zeros", "frames[].new_zeros", "frame.size", "len", "len", "frames[].size", "v.size"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.speech_to_text_dataset.SpeechToTextDataset.size"], ["", "def", "_collate_frames", "(", "\n", "frames", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "is_audio_input", ":", "bool", "=", "False", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert a list of 2D frames into a padded 3D tensor\n    Args:\n        frames (list): list of 2D frames of size L[i]*f_dim. Where L[i] is\n            length of i-th frame and f_dim is static dimension of features\n    Returns:\n        3D tensor of size len(frames)*len_max*f_dim where len_max is max of L[i]\n    \"\"\"", "\n", "max_len", "=", "max", "(", "frame", ".", "size", "(", "0", ")", "for", "frame", "in", "frames", ")", "\n", "if", "is_audio_input", ":", "\n", "        ", "out", "=", "frames", "[", "0", "]", ".", "new_zeros", "(", "(", "len", "(", "frames", ")", ",", "max_len", ")", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "frames", "[", "0", "]", ".", "new_zeros", "(", "(", "len", "(", "frames", ")", ",", "max_len", ",", "frames", "[", "0", "]", ".", "size", "(", "1", ")", ")", ")", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "frames", ")", ":", "\n", "        ", "out", "[", "i", ",", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_waveform": [[7, 30], ["isinstance", "sf.read", "os.splitext", "ValueError", "ImportError", "os.basename"], "function", ["None"], ["def", "get_waveform", "(", "\n", "path_or_fp", ":", "Union", "[", "str", ",", "BinaryIO", "]", ",", "normalization", "=", "True", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "int", "]", ":", "\n", "    ", "\"\"\"Get the waveform and sample rate of a 16-bit mono-channel WAV or FLAC.\n\n    Args:\n        path_or_fp (str or BinaryIO): the path or file-like object\n        normalization (bool): Normalize values to [-1, 1] (Default: True)\n    \"\"\"", "\n", "if", "isinstance", "(", "path_or_fp", ",", "str", ")", ":", "\n", "        ", "ext", "=", "op", ".", "splitext", "(", "op", ".", "basename", "(", "path_or_fp", ")", ")", "[", "1", "]", "\n", "if", "ext", "not", "in", "{", "\".flac\"", ",", "\".wav\"", "}", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unsupported audio format: {ext}\"", ")", "\n", "\n", "", "", "try", ":", "\n", "        ", "import", "soundfile", "as", "sf", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "\"Please install soundfile to load WAV/FLAC file\"", ")", "\n", "\n", "", "waveform", ",", "sample_rate", "=", "sf", ".", "read", "(", "path_or_fp", ",", "dtype", "=", "\"float32\"", ")", "\n", "if", "not", "normalization", ":", "\n", "        ", "waveform", "*=", "2", "**", "15", "# denormalized to 16-bit signed integers", "\n", "", "return", "waveform", ",", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils._get_kaldi_fbank": [[32, 52], ["MelBanksOptions", "FrameExtractionOptions", "FbankOptions", "Fbank", "Fbank.compute().numpy", "Fbank.compute", "Vector"], "function", ["None"], ["", "def", "_get_kaldi_fbank", "(", "waveform", ",", "sample_rate", ",", "n_bins", "=", "80", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via PyKaldi.\"\"\"", "\n", "try", ":", "\n", "        ", "from", "kaldi", ".", "feat", ".", "mel", "import", "MelBanksOptions", "\n", "from", "kaldi", ".", "feat", ".", "fbank", "import", "FbankOptions", ",", "Fbank", "\n", "from", "kaldi", ".", "feat", ".", "window", "import", "FrameExtractionOptions", "\n", "from", "kaldi", ".", "matrix", "import", "Vector", "\n", "\n", "mel_opts", "=", "MelBanksOptions", "(", ")", "\n", "mel_opts", ".", "num_bins", "=", "n_bins", "\n", "frame_opts", "=", "FrameExtractionOptions", "(", ")", "\n", "frame_opts", ".", "samp_freq", "=", "sample_rate", "\n", "opts", "=", "FbankOptions", "(", ")", "\n", "opts", ".", "mel_opts", "=", "mel_opts", "\n", "opts", ".", "frame_opts", "=", "frame_opts", "\n", "fbank", "=", "Fbank", "(", "opts", "=", "opts", ")", "\n", "features", "=", "fbank", ".", "compute", "(", "Vector", "(", "waveform", ")", ",", "1.0", ")", ".", "numpy", "(", ")", "\n", "return", "features", "\n", "", "except", "ImportError", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils._get_torchaudio_fbank": [[54, 67], ["torch.from_numpy().unsqueeze", "ta_kaldi.fbank", "ta_kaldi.fbank.numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "_get_torchaudio_fbank", "(", "waveform", ",", "sample_rate", ",", "n_bins", "=", "80", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via TorchAudio.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "torch", "\n", "import", "torchaudio", ".", "compliance", ".", "kaldi", "as", "ta_kaldi", "\n", "\n", "waveform", "=", "torch", ".", "from_numpy", "(", "waveform", ")", ".", "unsqueeze", "(", "0", ")", "\n", "features", "=", "ta_kaldi", ".", "fbank", "(", "\n", "waveform", ",", "num_mel_bins", "=", "n_bins", ",", "sample_frequency", "=", "sample_rate", "\n", ")", "\n", "return", "features", ".", "numpy", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_fbank": [[69, 86], ["audio_utils.get_waveform", "audio_utils._get_kaldi_fbank", "audio_utils._get_torchaudio_fbank", "ImportError"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils.get_waveform", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils._get_kaldi_fbank", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.audio.audio_utils._get_torchaudio_fbank"], ["", "", "def", "get_fbank", "(", "path_or_fp", ":", "Union", "[", "str", ",", "BinaryIO", "]", ",", "n_bins", "=", "80", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via PyKaldi or TorchAudio. Prefer PyKaldi\n    (faster CPP implementation) to TorchAudio (Python implementation). Note that\n    Kaldi/TorchAudio requires 16-bit signed integers as inputs and hence the\n    waveform should not be normalized.\"\"\"", "\n", "sound", ",", "sample_rate", "=", "get_waveform", "(", "path_or_fp", ",", "normalization", "=", "False", ")", "\n", "\n", "features", "=", "_get_kaldi_fbank", "(", "sound", ",", "sample_rate", ",", "n_bins", ")", "\n", "if", "features", "is", "None", ":", "\n", "        ", "features", "=", "_get_torchaudio_fbank", "(", "sound", ",", "sample_rate", ",", "n_bins", ")", "\n", "", "if", "features", "is", "None", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"Please install pyKaldi or torchaudio to enable \"", "\n", "\"online filterbank feature extraction\"", "\n", ")", "\n", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.nltk_tokenizer.NLTKTokenizer.__init__": [[12, 19], ["ImportError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "\n", "self", ".", "word_tokenize", "=", "word_tokenize", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install nltk with: pip install nltk\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.nltk_tokenizer.NLTKTokenizer.encode": [[20, 22], ["nltk_tokenizer.NLTKTokenizer.word_tokenize"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "word_tokenize", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.nltk_tokenizer.NLTKTokenizer.decode": [[23, 25], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe.GPT2BPE.__init__": [[31, 35], ["fairseq.file_utils.cached_path", "fairseq.file_utils.cached_path", "gpt2_bpe_utils.get_encoder"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.get_encoder"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "encoder_json", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "gpt2_encoder_json", ")", "\n", "vocab_bpe", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "gpt2_vocab_bpe", ")", "\n", "self", ".", "bpe", "=", "get_encoder", "(", "encoder_json", ",", "vocab_bpe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe.GPT2BPE.encode": [[36, 38], ["map", "gpt2_bpe.GPT2BPE.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "map", "(", "str", ",", "self", ".", "bpe", ".", "encode", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe.GPT2BPE.decode": [[39, 42], ["gpt2_bpe.GPT2BPE.bpe.decode", "int", "x.split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "\n", "[", "int", "(", "tok", ")", "if", "tok", "not", "in", "{", "\"<unk>\"", ",", "\"<mask>\"", "}", "else", "tok", "for", "tok", "in", "x", ".", "split", "(", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe.GPT2BPE.is_beginning_of_word": [[44, 46], ["gpt2_bpe.GPT2BPE.decode().startswith", "gpt2_bpe.GPT2BPE.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "decode", "(", "x", ")", ".", "startswith", "(", "\" \"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.subword_nmt_bpe.SubwordNMTBPE.__init__": [[21, 48], ["fairseq.file_utils.cached_path", "ValueError", "apply_bpe.create_parser", "apply_bpe.create_parser.parse_args", "apply_bpe.BPE", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "cfg", ".", "bpe_codes", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"--bpe-codes is required for --bpe=subword_nmt\"", ")", "\n", "", "codes", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_codes", ")", "\n", "try", ":", "\n", "            ", "from", "subword_nmt", "import", "apply_bpe", "\n", "\n", "bpe_parser", "=", "apply_bpe", ".", "create_parser", "(", ")", "\n", "bpe_args", "=", "bpe_parser", ".", "parse_args", "(", "\n", "[", "\n", "\"--codes\"", ",", "\n", "codes", ",", "\n", "\"--separator\"", ",", "\n", "cfg", ".", "bpe_separator", ",", "\n", "]", "\n", ")", "\n", "self", ".", "bpe", "=", "apply_bpe", ".", "BPE", "(", "\n", "bpe_args", ".", "codes", ",", "\n", "bpe_args", ".", "merges", ",", "\n", "bpe_args", ".", "separator", ",", "\n", "None", ",", "\n", "bpe_args", ".", "glossaries", ",", "\n", ")", "\n", "self", ".", "bpe_symbol", "=", "bpe_args", ".", "separator", "+", "\" \"", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install subword_nmt with: pip install subword-nmt\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.subword_nmt_bpe.SubwordNMTBPE.encode": [[50, 52], ["subword_nmt_bpe.SubwordNMTBPE.bpe.process_line"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "process_line", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.subword_nmt_bpe.SubwordNMTBPE.decode": [[53, 55], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "(", "x", "+", "\" \"", ")", ".", "replace", "(", "self", ".", "bpe_symbol", ",", "\"\"", ")", ".", "rstrip", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_bpe.ByteBPE.__init__": [[29, 39], ["fairseq.file_utils.cached_path", "spm.SentencePieceProcessor", "byte_bpe.ByteBPE.sp.Load", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "vocab", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "sentencepiece_model_path", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "\n", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "vocab", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install sentencepiece with: pip install sentencepiece\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_bpe.ByteBPE.encode": [[41, 44], ["fairseq.data.encoders.byte_utils.byte_encode", "fairseq.data.encoders.byte_utils.SPACE.join", "byte_bpe.ByteBPE.sp.EncodeAsPieces"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_encode"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "byte_encoded", "=", "byte_encode", "(", "x", ")", "\n", "return", "SPACE", ".", "join", "(", "self", ".", "sp", ".", "EncodeAsPieces", "(", "byte_encoded", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_bpe.ByteBPE.decode": [[45, 49], ["x.replace().replace", "fairseq.data.encoders.byte_utils.smart_byte_decode", "x.replace"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.smart_byte_decode"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "unescaped", "=", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "return", "smart_byte_decode", "(", "unescaped", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_bert_bpe.BertBPE.__init__": [[23, 40], ["BertTokenizer", "BertTokenizer.from_pretrained", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.models.fairseq_model.BaseFairseqModel.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "transformers", "import", "BertTokenizer", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install transformers with: pip install transformers\"", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "bpe_vocab_file", ":", "\n", "            ", "self", ".", "bert_tokenizer", "=", "BertTokenizer", "(", "\n", "cfg", ".", "bpe_vocab_file", ",", "do_lower_case", "=", "not", "cfg", ".", "bpe_cased", "\n", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file_name", "=", "(", "\n", "\"bert-base-cased\"", "if", "cfg", ".", "bpe_cased", "else", "\"bert-base-uncased\"", "\n", ")", "\n", "self", ".", "bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "vocab_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_bert_bpe.BertBPE.encode": [[41, 43], ["hf_bert_bpe.BertBPE.bert_tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_bert_bpe.BertBPE.decode": [[44, 47], ["hf_bert_bpe.BertBPE.bert_tokenizer.clean_up_tokenization", "hf_bert_bpe.BertBPE.bert_tokenizer.convert_tokens_to_string", "x.split"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bert_tokenizer", ".", "clean_up_tokenization", "(", "\n", "self", ".", "bert_tokenizer", ".", "convert_tokens_to_string", "(", "x", ".", "split", "(", "\" \"", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_bert_bpe.BertBPE.is_beginning_of_word": [[49, 51], ["x.startswith"], "methods", ["None"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "not", "x", ".", "startswith", "(", "\"##\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.characters.Characters.__init__": [[16, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.characters.Characters.add_args": [[19, 22], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.characters.Characters.encode": [[23, 27], ["x.replace", "SPACE.join", "list"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "escaped", "=", "x", ".", "replace", "(", "SPACE", ",", "SPACE_ESCAPE", ")", "\n", "return", "SPACE", ".", "join", "(", "list", "(", "escaped", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.characters.Characters.decode": [[28, 31], ["x.replace().replace", "x.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.Encoder.__init__": [[52, 71], ["gpt2_bpe_utils.bytes_to_unicode", "dict", "gpt2_bpe_utils.Encoder.re.compile", "zip", "gpt2_bpe_utils.Encoder.encoder.items", "gpt2_bpe_utils.Encoder.byte_encoder.items", "range", "ImportError", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.bytes_to_unicode"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "bpe_merges", ",", "errors", "=", "\"replace\"", ")", ":", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "try", ":", "\n", "            ", "import", "regex", "as", "re", "\n", "\n", "self", ".", "re", "=", "re", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install regex with: pip install regex\"", ")", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "", "self", ".", "pat", "=", "self", ".", "re", ".", "compile", "(", "\n", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.Encoder.bpe": [[73, 113], ["tuple", "gpt2_bpe_utils.get_pairs", "min", "tuple", "len", "len", "gpt2_bpe_utils.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "gpt2_bpe_utils.Encoder.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.get_pairs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.get_pairs", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.Encoder.encode": [[114, 122], ["gpt2_bpe_utils.Encoder.re.findall", "bpe_tokens.extend", "token.encode", "gpt2_bpe_utils.Encoder.bpe().split", "gpt2_bpe_utils.Encoder.bpe"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.Encoder.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "\"\"", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "\n", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", "\n", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.Encoder.decode": [[123, 129], ["bytearray().decode", "gpt2_bpe_utils.Encoder.decoder.get", "bytearray"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "\"\"", ".", "join", "(", "[", "self", ".", "decoder", ".", "get", "(", "token", ",", "token", ")", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "\n", "\"utf-8\"", ",", "errors", "=", "self", ".", "errors", "\n", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.bytes_to_unicode": [[12, 37], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "(", "\n", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "\n", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "\n", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.get_pairs": [[39, 49], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.gpt2_bpe_utils.get_encoder": [[131, 140], ["gpt2_bpe_utils.Encoder", "open", "json.load", "open", "f.read", "tuple", "merge_str.split", "f.read.split"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_io.PathManager.open"], ["", "", "def", "get_encoder", "(", "encoder_json_path", ",", "vocab_bpe_path", ")", ":", "\n", "    ", "with", "open", "(", "encoder_json_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "encoder", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "vocab_bpe_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "bpe_data", "=", "f", ".", "read", "(", ")", "\n", "", "bpe_merges", "=", "[", "tuple", "(", "merge_str", ".", "split", "(", ")", ")", "for", "merge_str", "in", "bpe_data", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "]", "\n", "return", "Encoder", "(", "\n", "encoder", "=", "encoder", ",", "\n", "bpe_merges", "=", "bpe_merges", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.__init__": [[24, 39], ["fairseq.file_utils.cached_path", "fairseq.file_utils.cached_path", "ByteLevelBPETokenizer", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "tokenizers", "import", "ByteLevelBPETokenizer", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install huggingface/tokenizers with: \"", "\"pip install tokenizers\"", "\n", ")", "\n", "\n", "", "bpe_vocab", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_vocab", ")", "\n", "bpe_merges", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_merges", ")", "\n", "\n", "self", ".", "bpe", "=", "ByteLevelBPETokenizer", "(", "\n", "bpe_vocab", ",", "\n", "bpe_merges", ",", "\n", "add_prefix_space", "=", "cfg", ".", "bpe_add_prefix_space", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.encode": [[41, 43], ["map", "hf_byte_bpe.HuggingFaceByteLevelBPE.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "map", "(", "str", ",", "self", ".", "bpe", ".", "encode", "(", "x", ")", ".", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.decode": [[44, 47], ["hf_byte_bpe.HuggingFaceByteLevelBPE.bpe.decode", "int", "x.split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "\n", "[", "int", "(", "tok", ")", "if", "tok", "not", "in", "{", "\"<unk>\"", ",", "\"<mask>\"", "}", "else", "tok", "for", "tok", "in", "x", ".", "split", "(", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.is_beginning_of_word": [[49, 51], ["hf_byte_bpe.HuggingFaceByteLevelBPE.decode().startswith", "hf_byte_bpe.HuggingFaceByteLevelBPE.decode"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "decode", "(", "x", ")", ".", "startswith", "(", "\" \"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.moses_tokenizer.MosesTokenizer.__init__": [[27, 38], ["moses_tokenizer.MosesTokenizer", "MosesDetokenizer", "ImportError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "MosesTokenizerConfig", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "\n", "try", ":", "\n", "            ", "from", "sacremoses", "import", "MosesTokenizer", ",", "MosesDetokenizer", "\n", "\n", "self", ".", "tok", "=", "MosesTokenizer", "(", "cfg", ".", "source_lang", ")", "\n", "self", ".", "detok", "=", "MosesDetokenizer", "(", "cfg", ".", "target_lang", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install Moses tokenizer with: pip install sacremoses\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.moses_tokenizer.MosesTokenizer.encode": [[40, 46], ["moses_tokenizer.MosesTokenizer.tok.tokenize"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tok", ".", "tokenize", "(", "\n", "x", ",", "\n", "aggressive_dash_splits", "=", "(", "not", "self", ".", "cfg", ".", "moses_no_dash_splits", ")", ",", "\n", "return_str", "=", "True", ",", "\n", "escape", "=", "(", "not", "self", ".", "cfg", ".", "moses_no_escape", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.moses_tokenizer.MosesTokenizer.decode": [[48, 50], ["moses_tokenizer.MosesTokenizer.detok.detokenize", "x.split"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.hub_utils.GeneratorHubInterface.detokenize"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "detok", ".", "detokenize", "(", "x", ".", "split", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.__init__": [[18, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.add_args": [[21, 24], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.encode": [[25, 30], ["fairseq.data.encoders.byte_utils.byte_encode", "fairseq.data.encoders.byte_utils.byte_encode.replace", "fairseq.data.encoders.byte_utils.SPACE.join", "list"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_encode"], ["", "@", "staticmethod", "\n", "def", "encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "encoded", "=", "byte_encode", "(", "x", ")", "\n", "escaped", "=", "encoded", ".", "replace", "(", "SPACE", ",", "SPACE_ESCAPE", ")", "\n", "return", "SPACE", ".", "join", "(", "list", "(", "escaped", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.bytes.Bytes.decode": [[31, 35], ["x.replace().replace", "fairseq.data.encoders.byte_utils.smart_byte_decode", "x.replace"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.smart_byte_decode"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "unescaped", "=", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "return", "smart_byte_decode", "(", "unescaped", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_encode": [[22, 25], ["WHITESPACE_NORMALIZER.sub", "WHITESPACE_NORMALIZER.sub.encode"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["def", "byte_encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "normalized", "=", "WHITESPACE_NORMALIZER", ".", "sub", "(", "SPACE", ",", "x", ")", "\n", "return", "\"\"", ".", "join", "(", "[", "BYTE_TO_BCHAR", "[", "b", "]", "for", "b", "in", "normalized", ".", "encode", "(", "\"utf-8\"", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_decode": [[27, 32], ["bytes().decode", "bytes"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "byte_decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "bytes", "(", "[", "BCHAR_TO_BYTE", "[", "bc", "]", "for", "bc", "in", "x", "]", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.smart_byte_decode": [[34, 52], ["byte_utils.byte_decode", "len", "range", "range", "range", "range", "min", "byte_utils.byte_decode", "len", "byte_utils.byte_decode"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_decode", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.byte_utils.byte_decode"], ["", "", "def", "smart_byte_decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "output", "=", "byte_decode", "(", "x", ")", "\n", "if", "output", "==", "\"\"", ":", "\n", "# DP the best recovery (max valid chars) if it's broken", "\n", "        ", "n_bytes", "=", "len", "(", "x", ")", "\n", "f", "=", "[", "0", "for", "_", "in", "range", "(", "n_bytes", "+", "1", ")", "]", "\n", "pt", "=", "[", "0", "for", "_", "in", "range", "(", "n_bytes", "+", "1", ")", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "n_bytes", "+", "1", ")", ":", "\n", "            ", "f", "[", "i", "]", ",", "pt", "[", "i", "]", "=", "f", "[", "i", "-", "1", "]", ",", "i", "-", "1", "\n", "for", "j", "in", "range", "(", "1", ",", "min", "(", "4", ",", "i", ")", "+", "1", ")", ":", "\n", "                ", "if", "f", "[", "i", "-", "j", "]", "+", "1", ">", "f", "[", "i", "]", "and", "len", "(", "byte_decode", "(", "x", "[", "i", "-", "j", ":", "i", "]", ")", ")", ">", "0", ":", "\n", "                    ", "f", "[", "i", "]", ",", "pt", "[", "i", "]", "=", "f", "[", "i", "-", "j", "]", "+", "1", ",", "i", "-", "j", "\n", "", "", "", "cur_pt", "=", "n_bytes", "\n", "while", "cur_pt", ">", "0", ":", "\n", "            ", "if", "f", "[", "cur_pt", "]", "==", "f", "[", "pt", "[", "cur_pt", "]", "]", "+", "1", ":", "\n", "                ", "output", "=", "byte_decode", "(", "x", "[", "pt", "[", "cur_pt", "]", ":", "cur_pt", "]", ")", "+", "output", "\n", "", "cur_pt", "=", "pt", "[", "cur_pt", "]", "\n", "", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.space_tokenizer.SpaceTokenizer.__init__": [[14, 16], ["re.compile"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "self", ".", "space_tok", "=", "re", ".", "compile", "(", "r\"\\s+\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.space_tokenizer.SpaceTokenizer.encode": [[17, 19], ["space_tokenizer.SpaceTokenizer.space_tok.sub"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "space_tok", ".", "sub", "(", "\" \"", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.space_tokenizer.SpaceTokenizer.decode": [[20, 22], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.fastbpe.fastBPE.__init__": [[20, 31], ["fairseq.file_utils.cached_path", "ValueError", "fastBPE.fastBPE", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "cfg", ".", "bpe_codes", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"--bpe-codes is required for --bpe=fastbpe\"", ")", "\n", "", "codes", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_codes", ")", "\n", "try", ":", "\n", "            ", "import", "fastBPE", "\n", "\n", "self", ".", "bpe", "=", "fastBPE", ".", "fastBPE", "(", "codes", ")", "\n", "self", ".", "bpe_symbol", "=", "\"@@ \"", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fastBPE with: pip install fastBPE\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.fastbpe.fastBPE.encode": [[32, 34], ["fastbpe.fastBPE.bpe.apply"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "apply", "(", "[", "x", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.fastbpe.fastBPE.decode": [[35, 37], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "(", "x", "+", "\" \"", ")", ".", "replace", "(", "self", ".", "bpe_symbol", ",", "\"\"", ")", ".", "rstrip", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.__init__": [[22, 32], ["fairseq.file_utils.cached_path", "spm.SentencePieceProcessor", "sentencepiece_bpe.SentencepieceBPE.sp.Load", "ImportError"], "methods", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "sentencepiece_model", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "sentencepiece_model", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "\n", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "sentencepiece_model", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install sentencepiece with: pip install sentencepiece\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.encode": [[34, 36], ["sentencepiece_bpe.SentencepieceBPE.sp.EncodeAsPieces"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "sp", ".", "EncodeAsPieces", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.decode": [[37, 39], ["x.replace().replace().strip", "x.replace().replace", "x.replace"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"\\u2581\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.is_beginning_of_word": [[40, 49], ["x.startswith"], "methods", ["None"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "x", "in", "[", "\"<unk>\"", ",", "\"<s>\"", ",", "\"</s>\"", ",", "\"<pad>\"", "]", ":", "\n", "# special elements are always considered beginnings", "\n", "# HACK: this logic is already present in fairseq/tasks/masked_lm.py", "\n", "# but these special tokens are also contained in the sentencepiece", "\n", "# vocabulary which causes duplicate special tokens. This hack makes", "\n", "# sure that they are all taken into account.", "\n", "            ", "return", "True", "\n", "", "return", "x", ".", "startswith", "(", "\"\\u2581\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.utils.get_whole_word_mask": [[10, 31], ["fairseq.data.encoders.build_bpe", "torch.ByteTensor", "tok.startswith", "list", "encoders.build_bpe.is_beginning_of_word", "map", "range", "len"], "function", ["home.repos.pwc.inspect_result.joungheekim_k-wav2vec.tasks.fairseq_task.FairseqTask.build_bpe", "home.repos.pwc.inspect_result.joungheekim_k-wav2vec.encoders.sentencepiece_bpe.SentencepieceBPE.is_beginning_of_word"], ["import", "logging", "\n", "import", "os", "\n", "import", "sys", "\n", "import", "tempfile", "\n", "import", "warnings", "\n", "from", "itertools", "import", "accumulate", "\n", "from", "typing", "import", "Callable", ",", "Dict", ",", "List", ",", "Optional", "\n", "\n", "import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n"]]}