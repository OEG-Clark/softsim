{"home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.__init__": [[48, 67], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay_rate", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "not", "lr", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay_rate", "=", "weight_decay_rate", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "VCWEAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.get_lr": [[68, 84], ["print", "len", "print", "len", "lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "print", "(", "\"l_total=\"", ",", "len", "(", "self", ".", "param_groups", ")", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "print", "(", "\"l_p=\"", ",", "len", "(", "group", "[", "'params'", "]", ")", ")", "\n", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to": [[85, 90], ["optimization.VCWEAdam.state.values", "state[].to", "state[].to"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\" Move the optimizer state to a specified device\"\"\"", "\n", "for", "state", "in", "self", ".", "state", ".", "values", "(", ")", ":", "\n", "            ", "state", "[", "'exp_avg'", "]", ".", "to", "(", "device", ")", "\n", "state", "[", "'exp_avg_sq'", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.initialize_step": [[91, 105], ["torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "", "def", "initialize_step", "(", "self", ",", "initial_step", ")", ":", "\n", "        ", "\"\"\"Initialize state with a defined step (but we don't have stored averaged).\n        Arguments:\n            initial_step (int): Initial step number.\n        \"\"\"", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "# State initialization", "\n", "state", "[", "'step'", "]", "=", "initial_step", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.step": [[106, 174], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want ot decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay_rate'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay_rate'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.warmup_cosine": [[12, 16], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.warmup_constant": [[17, 21], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.warmup_linear": [[22, 26], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.trainer.Word2VecTrainer.__init__": [[13, 36], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "numpy.load", "data_reader.DataReader", "data_reader.Word2vecDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "model.VCWEModel", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "int", "len", "trainer.Word2VecTrainer.VCWE_model.cuda", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_file", ",", "vocabulary_file", ",", "img_data_file", ",", "char2ix_file", ",", "output_dir", ",", "maxwordlength", ",", "emb_dimension", ",", "line_batch_size", ",", "sample_batch_size", ",", "\n", "neg_num", ",", "window_size", ",", "discard", ",", "epochs", ",", "initial_lr", ",", "seed", ")", ":", "\n", "\n", "        ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "self", ".", "img_data", "=", "np", ".", "load", "(", "img_data_file", ")", "\n", "self", ".", "data", "=", "DataReader", "(", "input_file", ",", "vocabulary_file", ",", "char2ix_file", ",", "maxwordlength", ",", "discard", ",", "seed", ")", "\n", "dataset", "=", "Word2vecDataset", "(", "self", ".", "data", ",", "window_size", ",", "sample_batch_size", ",", "neg_num", ")", "\n", "self", ".", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "line_batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "collate_fn", "=", "dataset", ".", "collate", ")", "\n", "\n", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "emb_size", "=", "len", "(", "self", ".", "data", ".", "word2id", ")", "\n", "self", ".", "char_size", "=", "len", "(", "self", ".", "data", ".", "char2id", ")", "+", "1", "#5031", "\n", "self", ".", "emb_dimension", "=", "emb_dimension", "\n", "self", ".", "line_batch_size", "=", "line_batch_size", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "initial_lr", "=", "initial_lr", "\n", "self", ".", "VCWE_model", "=", "VCWEModel", "(", "self", ".", "emb_size", ",", "self", ".", "emb_dimension", ",", "self", ".", "data", ".", "wordid2charid", ",", "self", ".", "char_size", ")", "\n", "self", ".", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "self", ".", "use_cuda", "else", "\"cpu\"", ")", "\n", "self", ".", "num_train_steps", "=", "int", "(", "len", "(", "self", ".", "dataloader", ")", "*", "self", ".", "epochs", ")", "\n", "if", "self", ".", "use_cuda", ":", "\n", "            ", "self", ".", "VCWE_model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.trainer.Word2VecTrainer.train": [[38, 81], ["torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "print", "optimization.VCWEAdam", "range", "print", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tqdm.tqdm.tqdm", "trainer.Word2VecTrainer.VCWE_model.save_embedding", "str", "len", "sample_batched[].to", "sample_batched[].to", "sample_batched[].to", "sample_batched[].to", "optimization.VCWEAdam.zero_grad", "trainer.Word2VecTrainer.VCWE_model.forward", "trainer.Word2VecTrainer.item", "trainer.Word2VecTrainer.backward", "optimization.VCWEAdam.step", "trainer.Word2VecTrainer.VCWE_model.named_parameters", "trainer.Word2VecTrainer.VCWE_model.named_parameters", "any", "print", "any", "str"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.VCWEModel.save_embedding", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.forward", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "img_data", "=", "torch", ".", "from_numpy", "(", "self", ".", "img_data", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "no_decay", "=", "[", "'bias'", "]", "\n", "optimizer_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "VCWE_model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay_rate'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "VCWE_model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay_rate'", ":", "0.0", "}", "\n", "]", "\n", "\n", "print", "(", "\"num_train_steps=\"", ",", "self", ".", "num_train_steps", ")", "\n", "optimizer", "=", "VCWEAdam", "(", "optimizer_parameters", ",", "\n", "lr", "=", "self", ".", "initial_lr", ",", "\n", "warmup", "=", "0.1", ",", "\n", "t_total", "=", "self", ".", "num_train_steps", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "\n", "            ", "print", "(", "\"Epoch: \"", "+", "str", "(", "epoch", "+", "1", ")", ")", "\n", "\n", "\n", "running_loss", "=", "0.0", "\n", "for", "i", ",", "sample_batched", "in", "enumerate", "(", "tqdm", "(", "self", ".", "dataloader", ")", ")", ":", "\n", "\n", "                ", "if", "len", "(", "sample_batched", "[", "0", "]", ")", ">", "1", ":", "\n", "                    ", "pos_u", "=", "sample_batched", "[", "0", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "pos_v", "=", "sample_batched", "[", "1", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "neg_v", "=", "sample_batched", "[", "2", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "lengths", "=", "sample_batched", "[", "3", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "VCWE_model", ".", "forward", "(", "pos_u", ",", "pos_v", ",", "neg_v", ",", "self", ".", "img_data", ")", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", ">", "0", "and", "i", "%", "1000", "==", "0", ":", "\n", "                        ", "print", "(", "'loss='", ",", "running_loss", "/", "1000", ")", "\n", "running_loss", "=", "0.0", "\n", "\n", "\n", "", "", "", "if", "(", "epoch", "+", "1", ")", "%", "5", "==", "0", "or", "(", "epoch", "+", "1", ")", "==", "self", ".", "epochs", ":", "\n", "                ", "self", ".", "VCWE_model", ".", "save_embedding", "(", "self", ".", "data", ".", "id2word", ",", "self", ".", "output_dir", "+", "\"zh_wiki_VCWE_ep\"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\".txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.trainer.main": [[83, 165], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "trainer.Word2VecTrainer", "trainer.Word2VecTrainer.train"], "function", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.trainer.Word2VecTrainer.train"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input_file\"", ",", "\n", "default", "=", "\"./data/zh_wiki.txt\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input file that the VCWE model was trained on.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab_file\"", ",", "\n", "default", "=", "\"./data/vocabulary.txt\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The vocabulary file that the VCWE model was trained on.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_data_file\"", ",", "\n", "default", "=", "\"./data/char_img_sub_mean.npy\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The image data file that the VCWE model was trained on.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--char2ix_file\"", ",", "\n", "default", "=", "\"./data/char2ix.npz\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The character-to-index file corespond to the image data file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "\n", "default", "=", "\"./embedding/\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The output directory where the embedding file will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--line_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for lines.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample_batch_size\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for samples in a line.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--emb_dim\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Embedding dimensions.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--maxwordlength\"", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum number of characters in a word.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--neg_num\"", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The number of negative samplings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--window_size\"", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The window size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--discard\"", ",", "\n", "default", "=", "1e-5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The sub-sampling threshold.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "default", "=", "0.001", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "\n", "default", "=", "50", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "12345", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "w2v", "=", "Word2VecTrainer", "(", "input_file", "=", "args", ".", "input_file", ",", "vocabulary_file", "=", "args", ".", "vocab_file", ",", "img_data_file", "=", "args", ".", "img_data_file", ",", "char2ix_file", "=", "args", ".", "char2ix_file", ",", "output_dir", "=", "args", ".", "output_dir", ",", "\n", "maxwordlength", "=", "args", ".", "maxwordlength", ",", "\n", "emb_dimension", "=", "args", ".", "emb_dim", ",", "\n", "line_batch_size", "=", "args", ".", "line_batch_size", ",", "\n", "sample_batch_size", "=", "args", ".", "sample_batch_size", ",", "\n", "neg_num", "=", "args", ".", "neg_num", ",", "\n", "window_size", "=", "args", ".", "window_size", ",", "\n", "discard", "=", "args", ".", "discard", ",", "\n", "epochs", "=", "args", ".", "num_train_epochs", ",", "\n", "initial_lr", "=", "args", ".", "learning_rate", ",", "\n", "seed", "=", "args", ".", "seed", ")", "\n", "w2v", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.VCWEModel.__init__": [[15, 31], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "model.CNNModel", "model.LSTMModel", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "emb_size", ",", "emb_dimension", ",", "wordid2charid", ",", "char_size", ")", ":", "\n", "        ", "super", "(", "VCWEModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "wordid2charid", "=", "wordid2charid", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "emb_dimension", "=", "emb_dimension", "\n", "self", ".", "u_embeddings", "=", "nn", ".", "Embedding", "(", "emb_size", ",", "emb_dimension", ",", "sparse", "=", "False", ")", "\n", "self", ".", "v_embeddings", "=", "nn", ".", "Embedding", "(", "emb_size", ",", "emb_dimension", ",", "sparse", "=", "False", ")", "\n", "self", ".", "char_embeddings", "=", "nn", ".", "Embedding", "(", "char_size", ",", "emb_dimension", ",", "sparse", "=", "False", ")", "\n", "self", ".", "cnn_model", "=", "CNNModel", "(", "32", ",", "32", ",", "self", ".", "emb_dimension", ")", "\n", "self", ".", "lstm_model", "=", "LSTMModel", "(", "self", ".", "emb_dimension", ")", "\n", "\n", "initrange", "=", "1.0", "/", "self", ".", "emb_dimension", "\n", "init", ".", "uniform_", "(", "self", ".", "u_embeddings", ".", "weight", ".", "data", ",", "-", "initrange", ",", "initrange", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "v_embeddings", ".", "weight", ".", "data", ",", "-", "initrange", ",", "initrange", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "char_embeddings", ".", "weight", ".", "data", ",", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.VCWEModel.forward": [[33, 74], ["model.VCWEModel.cnn_model.forward", "model.VCWEModel.u_embeddings", "model.VCWEModel.v_embeddings().mean", "model.VCWEModel.v_embeddings", "pos_v.view().cpu.view().cpu.view().cpu", "model.VCWEModel.wordid2charid[].reshape", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "img_emb[].view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model.VCWEModel.lstm_model.forward", "torch.mean.view", "torch.mean.view", "torch.mean.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "neg_v.view().cpu", "model.VCWEModel.wordid2charid[].reshape", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "img_emb[].view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model.VCWEModel.lstm_model.forward", "emb_neg_char_v.view.view.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "len", "len", "pos_u.size", "len", "len", "pos_u.size", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.VCWEModel.v_embeddings", "pos_v.view().cpu.view().cpu.view", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "neg_v.view", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "model.VCWEModel.unsqueeze", "model.VCWEModel.unsqueeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().to().long.reshape", "torch.from_numpy().to().long.reshape", "torch.from_numpy().to().long.reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().to().long.reshape", "torch.from_numpy().to().long.reshape", "torch.from_numpy().to().long.reshape"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.forward", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.forward", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.forward", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to"], ["", "def", "forward", "(", "self", ",", "pos_u", ",", "pos_v", ",", "neg_v", ",", "img_data", ")", ":", "\n", "        ", "img_emb", "=", "self", ".", "cnn_model", ".", "forward", "(", "img_data", ")", "\n", "emb_u", "=", "self", ".", "u_embeddings", "(", "pos_u", ")", "\n", "emb_v", "=", "self", ".", "v_embeddings", "(", "pos_v", ")", ".", "mean", "(", "dim", "=", "1", ")", "\n", "emb_neg_v", "=", "self", ".", "v_embeddings", "(", "neg_v", ")", "\n", "pos_v", "=", "pos_v", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "temp", "=", "self", ".", "wordid2charid", "[", "pos_v", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "temp", "=", "torch", ".", "from_numpy", "(", "temp", ")", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "lstm_input", "=", "img_emb", "[", "temp", ".", "reshape", "(", "1", ",", "-", "1", ")", "]", ".", "view", "(", "len", "(", "pos_v", ")", ",", "-", "1", ",", "self", ".", "emb_dimension", ")", "\n", "del", "temp", "\n", "lstm_input", "=", "torch", ".", "transpose", "(", "lstm_input", ",", "0", ",", "1", ")", "#  self.data.maxwordlength, batch_size, embedding_dim", "\n", "emb_char_v", "=", "self", ".", "lstm_model", ".", "forward", "(", "lstm_input", ",", "len", "(", "pos_v", ")", ")", "\n", "emb_char_v", "=", "emb_char_v", ".", "view", "(", "pos_u", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "emb_dimension", ")", "\n", "emb_char_v", "=", "torch", ".", "mean", "(", "emb_char_v", ",", "dim", "=", "1", ")", "\n", "\n", "pos_neg_v", "=", "neg_v", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "temp", "=", "self", ".", "wordid2charid", "[", "pos_neg_v", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "temp", "=", "torch", ".", "from_numpy", "(", "temp", ")", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "lstm_input2", "=", "img_emb", "[", "temp", ".", "reshape", "(", "1", ",", "-", "1", ")", "]", ".", "view", "(", "len", "(", "pos_neg_v", ")", ",", "-", "1", ",", "self", ".", "emb_dimension", ")", "\n", "del", "temp", "\n", "lstm_input2", "=", "torch", ".", "transpose", "(", "lstm_input2", ",", "0", ",", "1", ")", "\n", "emb_neg_char_v", "=", "self", ".", "lstm_model", ".", "forward", "(", "lstm_input2", ",", "len", "(", "pos_neg_v", ")", ")", "\n", "emb_neg_char_v", "=", "emb_neg_char_v", ".", "view", "(", "pos_u", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "emb_dimension", ")", "\n", "\n", "c_score", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "emb_u", ",", "emb_char_v", ")", ",", "dim", "=", "1", ")", "\n", "c_score", "=", "torch", ".", "clamp", "(", "c_score", ",", "max", "=", "10", ",", "min", "=", "-", "10", ")", "\n", "c_score", "=", "-", "F", ".", "logsigmoid", "(", "c_score", ")", "\n", "\n", "neg_c_score", "=", "torch", ".", "bmm", "(", "emb_neg_char_v", ",", "emb_u", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", ")", "\n", "neg_c_score", "=", "torch", ".", "clamp", "(", "neg_c_score", ",", "max", "=", "10", ",", "min", "=", "-", "10", ")", "\n", "neg_c_score", "=", "-", "torch", ".", "sum", "(", "F", ".", "logsigmoid", "(", "-", "neg_c_score", ")", ",", "dim", "=", "1", ")", "\n", "\n", "score", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "emb_u", ",", "emb_v", ")", ",", "dim", "=", "1", ")", "\n", "score", "=", "torch", ".", "clamp", "(", "score", ",", "max", "=", "10", ",", "min", "=", "-", "10", ")", "\n", "score", "=", "-", "F", ".", "logsigmoid", "(", "score", ")", "\n", "\n", "neg_score", "=", "torch", ".", "bmm", "(", "emb_neg_v", ",", "emb_u", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", ")", "\n", "neg_score", "=", "torch", ".", "clamp", "(", "neg_score", ",", "max", "=", "10", ",", "min", "=", "-", "10", ")", "\n", "neg_score", "=", "-", "torch", ".", "sum", "(", "F", ".", "logsigmoid", "(", "-", "neg_score", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "torch", ".", "mean", "(", "c_score", "+", "neg_c_score", "+", "score", "+", "neg_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.VCWEModel.save_embedding": [[75, 82], ["model.VCWEModel.u_embeddings.weight.cpu().data.numpy", "open", "f.write", "id2word.items", "f.write", "model.VCWEModel.u_embeddings.weight.cpu", "map", "len", "str"], "methods", ["None"], ["", "def", "save_embedding", "(", "self", ",", "id2word", ",", "file_name", ")", ":", "\n", "        ", "embedding", "=", "self", ".", "u_embeddings", ".", "weight", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "with", "open", "(", "file_name", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'%d %d\\n'", "%", "(", "len", "(", "id2word", ")", ",", "self", ".", "emb_dimension", ")", ")", "\n", "for", "wid", ",", "w", "in", "id2word", ".", "items", "(", ")", ":", "\n", "                ", "e", "=", "' '", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "embedding", "[", "wid", "]", ")", ")", "\n", "f", ".", "write", "(", "'%s %s\\n'", "%", "(", "w", ",", "e", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.LSTMModel.__init__": [[86, 102], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model.LSTMModel.linear_first.bias.data.fill_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model.LSTMModel.linear_second.bias.data.fill_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model.LSTMModel.linear_third.bias.data.fill_", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "emb_dimension", ",", "d_a", "=", "128", ")", ":", "\n", "        ", "super", "(", "LSTMModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_dimension", "=", "emb_dimension", "\n", "self", ".", "hidden_dim", "=", "emb_dimension", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "self", ".", "emb_dimension", ",", "hidden_size", "=", "self", ".", "hidden_dim", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ")", "\n", "initrange", "=", "1.0", "/", "self", ".", "emb_dimension", "\n", "init", ".", "uniform_", "(", "self", ".", "lstm", ".", "all_weights", "[", "0", "]", "[", "0", "]", ",", "-", "initrange", ",", "initrange", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "lstm", ".", "all_weights", "[", "0", "]", "[", "1", "]", ",", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "self", ".", "linear_first", "=", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_dim", ",", "d_a", ")", "\n", "self", ".", "linear_first", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "linear_second", "=", "torch", ".", "nn", ".", "Linear", "(", "d_a", ",", "1", ")", "\n", "self", ".", "linear_second", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "linear_third", "=", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_dim", ",", "self", ".", "emb_dimension", ")", "\n", "self", ".", "linear_third", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.LSTMModel.init_hidden": [[103, 108], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.optimization.VCWEAdam.to"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "# first is the hidden h", "\n", "# second is the cell c", "\n", "        ", "return", "(", "torch", ".", "zeros", "(", "2", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "2", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.LSTMModel.forward": [[109, 120], ["model.LSTMModel.init_hidden", "model.LSTMModel.lstm", "model.LSTMModel.linear_first", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "model.LSTMModel.linear_second", "torch.softmax", "torch.softmax", "torch.softmax", "a.expand.expand.expand", "model.LSTMModel.linear_third"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.LSTMModel.init_hidden"], ["", "def", "forward", "(", "self", ",", "input", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "lstm_out", ",", "self", ".", "hidden", "=", "self", ".", "lstm", "(", "input", ",", "self", ".", "hidden", ")", "\n", "a", "=", "self", ".", "linear_first", "(", "lstm_out", ")", "\n", "a", "=", "torch", ".", "tanh", "(", "a", ")", "\n", "a", "=", "self", ".", "linear_second", "(", "a", ")", "\n", "a", "=", "F", ".", "softmax", "(", "a", ",", "dim", "=", "0", ")", "\n", "a", "=", "a", ".", "expand", "(", "5", ",", "batch_size", ",", "2", "*", "self", ".", "hidden_dim", ")", "\n", "y", "=", "(", "a", "*", "lstm_out", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "y", "=", "self", ".", "linear_third", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.__init__": [[122, 137], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output1", ",", "output2", ",", "emb_dimension", ")", ":", "#output1=32 output2=32", "\n", "        ", "super", "(", "CNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_dimension", "=", "emb_dimension", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "output1", ",", "(", "3", ",", "3", ")", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "output1", ",", "output2", ",", "(", "3", ",", "3", ")", ")", "\n", "self", ".", "hidden2result", "=", "nn", ".", "Linear", "(", "output2", "*", "64", ",", "emb_dimension", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "output1", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "output2", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm1d", "(", "emb_dimension", ")", "\n", "initrange", "=", "1.0", "/", "self", ".", "emb_dimension", "\n", "initrange1", "=", "1e-4", "\n", "initrange2", "=", "1e-2", "\n", "init", ".", "uniform_", "(", "self", ".", "conv1", ".", "weight", ".", "data", ",", "-", "initrange1", ",", "initrange1", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "conv2", ".", "weight", ".", "data", ",", "-", "initrange2", ",", "initrange2", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "hidden2result", ".", "weight", ".", "data", ",", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.model.CNNModel.forward": [[138, 147], ["model.CNNModel.conv1", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.CNNModel.conv2", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu.view", "model.CNNModel.hidden2result", "torch.relu", "torch.relu", "torch.relu", "model.CNNModel.bn1", "model.CNNModel.bn2", "model.CNNModel.bn3", "torch.relu.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "self", ".", "bn1", "(", "x", ")", ",", "2", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "self", ".", "bn2", "(", "x", ")", ",", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "hidden2result", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn3", "(", "x", ")", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.__init__": [[11, 35], ["numpy.random.seed", "random.seed", "numpy.load", "data[].item", "dict", "dict", "dict", "data_reader.DataReader.read_words", "data_reader.DataReader.initTableNegatives", "data_reader.DataReader.initTableDiscards"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.read_words", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.initTableNegatives", "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.initTableDiscards"], ["def", "__init__", "(", "self", ",", "inputFileName", ",", "vocabulary_file", ",", "char2ix_file", ",", "maxwordlength", ",", "discard", ",", "seed", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "self", ".", "discard", "=", "discard", "\n", "data", "=", "np", ".", "load", "(", "char2ix_file", ")", "\n", "self", ".", "char2id", "=", "data", "[", "'char_to_ix'", "]", ".", "item", "(", ")", "\n", "self", ".", "negatives", "=", "[", "]", "\n", "self", ".", "discards", "=", "[", "]", "\n", "self", ".", "negpos", "=", "0", "\n", "self", ".", "maxwordlength", "=", "maxwordlength", "\n", "\n", "self", ".", "word2id", "=", "dict", "(", ")", "\n", "self", ".", "id2word", "=", "dict", "(", ")", "\n", "self", ".", "wordid2charid", "=", "[", "]", "\n", "self", ".", "sentences_count", "=", "0", "\n", "self", ".", "token_count", "=", "0", "\n", "self", ".", "word_frequency", "=", "dict", "(", ")", "\n", "\n", "self", ".", "inputFileName", "=", "inputFileName", "\n", "self", ".", "vocabulary_file", "=", "vocabulary_file", "\n", "self", ".", "char2ix_file", "=", "char2ix_file", "\n", "self", ".", "read_words", "(", ")", "\n", "self", ".", "initTableNegatives", "(", ")", "\n", "self", ".", "initTableDiscards", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.read_words": [[36, 67], ["range", "numpy.array", "print", "open", "f.readline().strip().split", "int", "int", "f.readline().strip().split", "len", "range", "data_reader.DataReader.wordid2charid.append", "int", "f.readline().strip().split", "len", "len", "w.append", "str", "f.readline().strip", "f.readline().strip", "w.append", "len", "f.readline().strip", "w.append", "f.readline", "f.readline", "f.readline"], "methods", ["None"], ["", "def", "read_words", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "vocabulary_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "s", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "self", ".", "sentences_count", "=", "int", "(", "s", "[", "0", "]", ")", "\n", "self", ".", "token_count", "=", "int", "(", "s", "[", "1", "]", ")", "\n", "s", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "wid", "=", "0", "\n", "while", "s", ":", "\n", "                ", "w", "=", "s", "[", "0", "]", "\n", "c", "=", "int", "(", "s", "[", "1", "]", ")", "\n", "self", ".", "word2id", "[", "w", "]", "=", "wid", "\n", "self", ".", "id2word", "[", "wid", "]", "=", "w", "\n", "self", ".", "word_frequency", "[", "wid", "]", "=", "c", "\n", "wid", "+=", "1", "\n", "s", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "id2word", ")", ")", ":", "\n", "            ", "word", "=", "self", ".", "id2word", "[", "i", "]", "\n", "w", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "word", ")", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "w", ".", "append", "(", "self", ".", "char2id", "[", "word", "[", "j", "]", "]", ")", "\n", "", "except", ":", "\n", "                    ", "w", ".", "append", "(", "0", ")", "\n", "", "", "while", "len", "(", "w", ")", "<", "self", ".", "maxwordlength", ":", "w", ".", "append", "(", "0", ")", "\n", "w", "=", "w", "[", ":", "self", ".", "maxwordlength", "]", "\n", "self", ".", "wordid2charid", ".", "append", "(", "w", ")", "\n", "\n", "", "self", ".", "wordid2charid", "=", "np", ".", "array", "(", "self", ".", "wordid2charid", ")", "\n", "print", "(", "\"Total embeddings: \"", "+", "str", "(", "len", "(", "self", ".", "word2id", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.initTableDiscards": [[68, 72], ["numpy.sqrt", "numpy.array", "list", "data_reader.DataReader.word_frequency.values"], "methods", ["None"], ["", "def", "initTableDiscards", "(", "self", ")", ":", "\n", "        ", "t", "=", "self", ".", "discard", "#t is a chosen threshold, typically around 10^\u22125", "\n", "f", "=", "np", ".", "array", "(", "list", "(", "self", ".", "word_frequency", ".", "values", "(", ")", ")", ")", "/", "self", ".", "token_count", "\n", "self", ".", "discards", "=", "np", ".", "sqrt", "(", "t", "/", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.initTableNegatives": [[74, 83], ["sum", "numpy.round", "enumerate", "numpy.array", "numpy.random.shuffle", "numpy.array", "list", "int", "data_reader.DataReader.word_frequency.values"], "methods", ["None"], ["", "def", "initTableNegatives", "(", "self", ")", ":", "\n", "        ", "pow_frequency", "=", "np", ".", "array", "(", "list", "(", "self", ".", "word_frequency", ".", "values", "(", ")", ")", ")", "**", "0.5", "\n", "words_pow", "=", "sum", "(", "pow_frequency", ")", "\n", "ratio", "=", "pow_frequency", "/", "words_pow", "\n", "count", "=", "np", ".", "round", "(", "ratio", "*", "DataReader", ".", "NEGATIVE_TABLE_SIZE", ")", "\n", "for", "wid", ",", "c", "in", "enumerate", "(", "count", ")", ":", "\n", "            ", "self", ".", "negatives", "+=", "[", "wid", "]", "*", "int", "(", "c", ")", "\n", "", "self", ".", "negatives", "=", "np", ".", "array", "(", "self", ".", "negatives", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "negatives", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.getNegatives": [[84, 90], ["len", "len", "numpy.concatenate"], "methods", ["None"], ["", "def", "getNegatives", "(", "self", ",", "target", ",", "size", ")", ":", "# TODO check equality with target", "\n", "        ", "response", "=", "self", ".", "negatives", "[", "self", ".", "negpos", ":", "self", ".", "negpos", "+", "size", "]", "\n", "self", ".", "negpos", "=", "(", "self", ".", "negpos", "+", "size", ")", "%", "len", "(", "self", ".", "negatives", ")", "\n", "if", "len", "(", "response", ")", "!=", "size", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "(", "response", ",", "self", ".", "negatives", "[", "0", ":", "self", ".", "negpos", "]", ")", ")", "\n", "", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__init__": [[95, 101], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "window_size", ",", "sample_batch_size", ",", "neg_num", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "sample_batch_size", "=", "sample_batch_size", "\n", "self", ".", "neg_num", "=", "neg_num", "\n", "self", ".", "input_file", "=", "open", "(", "data", ".", "inputFileName", ",", "encoding", "=", "\"utf8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__len__": [[102, 104], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data", ".", "sentences_count", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.__getitem__": [[105, 135], ["data_reader.Word2vecDataset.input_file.readline", "data_reader.Word2vecDataset.input_file.seek", "data_reader.Word2vecDataset.input_file.readline", "len", "data_reader.Word2vecDataset.split", "len", "enumerate", "random.shuffle", "result.sort", "data_reader.Word2vecDataset.data.getNegatives", "enumerate", "numpy.array", "result.append", "len", "numpy.random.rand", "v_list.append", "len", "max"], "methods", ["home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.DataReader.getNegatives"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "self", ".", "input_file", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "self", ".", "input_file", ".", "seek", "(", "0", ",", "0", ")", "\n", "line", "=", "self", ".", "input_file", ".", "readline", "(", ")", "\n", "\n", "", "if", "len", "(", "line", ")", ">", "1", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "\n", "\n", "if", "len", "(", "words", ")", ">", "1", ":", "\n", "                    ", "word_ids", "=", "[", "self", ".", "data", ".", "word2id", "[", "w", "]", "for", "w", "in", "words", "if", "\n", "w", "in", "self", ".", "data", ".", "word2id", "and", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "data", ".", "discards", "[", "self", ".", "data", ".", "word2id", "[", "w", "]", "]", "]", "\n", "\n", "boundary", "=", "self", ".", "window_size", "\n", "\n", "result", "=", "[", "]", "\n", "for", "i", ",", "u", "in", "enumerate", "(", "word_ids", ")", ":", "\n", "                        ", "if", "i", ">", "boundary", "and", "i", "+", "boundary", "<", "len", "(", "word_ids", ")", ":", "\n", "                            ", "v_list", "=", "[", "]", "\n", "neg", "=", "self", ".", "data", ".", "getNegatives", "(", "u", ",", "self", ".", "neg_num", ")", "\n", "for", "j", ",", "v", "in", "enumerate", "(", "word_ids", "[", "max", "(", "i", "-", "boundary", ",", "0", ")", ":", "i", "+", "boundary", "]", ")", ":", "\n", "                                ", "if", "j", "!=", "boundary", ":", "\n", "                                    ", "v_list", ".", "append", "(", "v", ")", "\n", "", "", "v_np", "=", "np", ".", "array", "(", "v_list", ")", "\n", "result", ".", "append", "(", "(", "u", ",", "v_np", ",", "neg", ",", "len", "(", "self", ".", "data", ".", "id2word", "[", "u", "]", ")", ")", ")", "\n", "", "", "random", ".", "shuffle", "(", "result", ")", "\n", "result", "=", "result", "[", ":", "self", ".", "sample_batch_size", "]", "\n", "result", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "3", "]", ",", "reverse", "=", "True", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.None.data_reader.Word2vecDataset.collate": [[136, 143], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "collate", "(", "batches", ")", ":", "\n", "        ", "all_u", "=", "[", "u", "for", "batch", "in", "batches", "for", "u", ",", "_", ",", "_", ",", "_", "in", "batch", "if", "len", "(", "batch", ")", ">", "0", "]", "\n", "all_v", "=", "[", "v", "for", "batch", "in", "batches", "for", "_", ",", "v", ",", "_", ",", "_", "in", "batch", "if", "len", "(", "batch", ")", ">", "0", "]", "\n", "all_neg_v", "=", "[", "neg_v", "for", "batch", "in", "batches", "for", "_", ",", "_", ",", "neg_v", ",", "_", "in", "batch", "if", "len", "(", "batch", ")", ">", "0", "]", "\n", "all_length", "=", "[", "length", "for", "batch", "in", "batches", "for", "_", ",", "_", ",", "_", ",", "length", "in", "batch", "if", "len", "(", "batch", ")", ">", "0", "]", "\n", "return", "torch", ".", "LongTensor", "(", "all_u", ")", ",", "torch", ".", "LongTensor", "(", "all_v", ")", ",", "torch", ".", "LongTensor", "(", "all_neg_v", ")", ",", "torch", ".", "LongTensor", "(", "all_length", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.read_write.read_word_vectors": [[5, 20], ["print", "open", "f.readline().strip().lower", "numpy.zeros", "enumerate", "f.readline().strip().lower", "f.readline().strip", "f.readline().strip().lower.split", "float", "math.sqrt", "len", "f.readline().strip().lower.split", "f.readline().strip", "f.readline", "f.readline().strip().lower.split", "f.readline"], "function", ["None"], ["def", "read_word_vectors", "(", "filename", ",", "is_normalization", "=", "True", ")", ":", "\n", "    ", "word_vecs", "=", "{", "}", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "while", "line", ":", "\n", "            ", "word", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "word_vecs", "[", "word", "]", "=", "numpy", ".", "zeros", "(", "len", "(", "line", ".", "split", "(", ")", ")", "-", "1", ",", "dtype", "=", "float", ")", "\n", "for", "index", ",", "vec_val", "in", "enumerate", "(", "line", ".", "split", "(", ")", "[", "1", ":", "]", ")", ":", "\n", "                ", "word_vecs", "[", "word", "]", "[", "index", "]", "=", "float", "(", "vec_val", ")", "\n", "", "''' normalize weight vector '''", "\n", "if", "is_normalization", ":", "word_vecs", "[", "word", "]", "/=", "math", ".", "sqrt", "(", "(", "word_vecs", "[", "word", "]", "**", "2", ")", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "\n", "", "", "print", "(", "\"Vectors read from: \"", "+", "filename", "+", "\" \\n\"", ")", "\n", "return", "word_vecs", "\n", "", ""]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.ranking.euclidean": [[8, 11], ["math.sqrt", "diff.dot"], "function", ["None"], ["def", "euclidean", "(", "vec1", ",", "vec2", ")", ":", "\n", "    ", "diff", "=", "vec1", "-", "vec2", "\n", "return", "math", ".", "sqrt", "(", "diff", ".", "dot", "(", "diff", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.ranking.cosine_sim": [[12, 16], ["numpy.ones", "numpy.ones", "vec1.dot", "len", "len", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cosine_sim", "(", "vec1", ",", "vec2", ")", ":", "\n", "    ", "vec1", "+=", "EPSILON", "*", "numpy", ".", "ones", "(", "len", "(", "vec1", ")", ")", "\n", "vec2", "+=", "EPSILON", "*", "numpy", ".", "ones", "(", "len", "(", "vec1", ")", ")", "\n", "return", "vec1", ".", "dot", "(", "vec2", ")", "/", "(", "norm", "(", "vec1", ")", "*", "norm", "(", "vec2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.ranking.assign_ranks": [[17, 30], ["enumerate", "enumerate", "sorted", "len", "item_dict.items", "same_val_indices.append", "len", "operator.itemgetter", "sum"], "function", ["None"], ["", "def", "assign_ranks", "(", "item_dict", ")", ":", "\n", "    ", "ranked_dict", "=", "{", "}", "\n", "sorted_list", "=", "[", "(", "key", ",", "val", ")", "for", "(", "key", ",", "val", ")", "in", "sorted", "(", "item_dict", ".", "items", "(", ")", ",", "key", "=", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "]", "\n", "for", "i", ",", "(", "key", ",", "val", ")", "in", "enumerate", "(", "sorted_list", ")", ":", "\n", "        ", "same_val_indices", "=", "[", "]", "\n", "for", "j", ",", "(", "key2", ",", "val2", ")", "in", "enumerate", "(", "sorted_list", ")", ":", "\n", "            ", "if", "val2", "==", "val", ":", "\n", "                ", "same_val_indices", ".", "append", "(", "j", "+", "1", ")", "\n", "", "", "if", "len", "(", "same_val_indices", ")", "==", "1", ":", "\n", "            ", "ranked_dict", "[", "key", "]", "=", "i", "+", "1", "\n", "", "else", ":", "\n", "            ", "ranked_dict", "[", "key", "]", "=", "1.", "*", "sum", "(", "same_val_indices", ")", "/", "len", "(", "same_val_indices", ")", "\n", "", "", "return", "ranked_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.ranking.correlation": [[31, 40], ["zip", "len", "len", "dict1.itervalues", "dict2.itervalues", "math.sqrt", "sum", "sum", "dict1.iteritems", "dict2.iteritems"], "function", ["None"], ["", "def", "correlation", "(", "dict1", ",", "dict2", ")", ":", "\n", "    ", "avg1", "=", "1.", "*", "sum", "(", "[", "val", "for", "key", ",", "val", "in", "dict1", ".", "iteritems", "(", ")", "]", ")", "/", "len", "(", "dict1", ")", "\n", "avg2", "=", "1.", "*", "sum", "(", "[", "val", "for", "key", ",", "val", "in", "dict2", ".", "iteritems", "(", ")", "]", ")", "/", "len", "(", "dict2", ")", "\n", "numr", ",", "den1", ",", "den2", "=", "(", "0.", ",", "0.", ",", "0.", ")", "\n", "for", "val1", ",", "val2", "in", "zip", "(", "dict1", ".", "itervalues", "(", ")", ",", "dict2", ".", "itervalues", "(", ")", ")", ":", "\n", "        ", "numr", "+=", "(", "val1", "-", "avg1", ")", "*", "(", "val2", "-", "avg2", ")", "\n", "den1", "+=", "(", "val1", "-", "avg1", ")", "**", "2", "\n", "den2", "+=", "(", "val2", "-", "avg2", ")", "**", "2", "\n", "", "return", "numr", "/", "math", ".", "sqrt", "(", "den1", "*", "den2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HSLCY_VCWE.evaluation.ranking.spearmans_rho": [[41, 55], ["ranked_dict1.keys", "len", "len", "len", "len", "math.sqrt", "len", "len", "sum", "sum", "ranked_dict1.values", "ranked_dict2.values"], "function", ["None"], ["", "def", "spearmans_rho", "(", "ranked_dict1", ",", "ranked_dict2", ")", ":", "\n", "    ", "assert", "len", "(", "ranked_dict1", ")", "==", "len", "(", "ranked_dict2", ")", "\n", "if", "len", "(", "ranked_dict1", ")", "==", "0", "or", "len", "(", "ranked_dict2", ")", "==", "0", ":", "\n", "        ", "return", "0.", "\n", "", "x_avg", "=", "1.", "*", "sum", "(", "[", "val", "for", "val", "in", "ranked_dict1", ".", "values", "(", ")", "]", ")", "/", "len", "(", "ranked_dict1", ")", "\n", "y_avg", "=", "1.", "*", "sum", "(", "[", "val", "for", "val", "in", "ranked_dict2", ".", "values", "(", ")", "]", ")", "/", "len", "(", "ranked_dict2", ")", "\n", "num", ",", "d_x", ",", "d_y", "=", "(", "0.", ",", "0.", ",", "0.", ")", "\n", "for", "key", "in", "ranked_dict1", ".", "keys", "(", ")", ":", "\n", "        ", "xi", "=", "ranked_dict1", "[", "key", "]", "\n", "yi", "=", "ranked_dict2", "[", "key", "]", "\n", "num", "+=", "(", "xi", "-", "x_avg", ")", "*", "(", "yi", "-", "y_avg", ")", "\n", "d_x", "+=", "(", "xi", "-", "x_avg", ")", "**", "2", "\n", "d_y", "+=", "(", "yi", "-", "y_avg", ")", "**", "2", "\n", "", "return", "num", "/", "(", "math", ".", "sqrt", "(", "d_x", "*", "d_y", ")", ")", "\n", "", ""]]}