{"home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.generate.ArgsEvaluate.__init__": [[9, 38], ["training.graphgen_training_utils.get_model_attribute", "training.graphgen_training_utils.get_model_attribute"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", "=", "None", ",", "\n", "graph_gen_model_path", "=", "'training_artifacts/graph_generation/graph_generation_model.dat'", ",", "\n", "num_graphs", "=", "500", ",", "graphs_path", "=", "''", ")", ":", "\n", "# Can manually select the device too", "\n", "        ", "self", ".", "device", "=", "'cpu'", "\n", "self", ".", "model_path", "=", "graph_gen_model_path", "\n", "\n", "if", "dataset_name", ":", "\n", "            ", "self", ".", "starting_nodes", "=", "[", "dataset_name", ",", "'pandas.read_csv'", "]", "\n", "# print('Starting Nodes:', self.starting_nodes)", "\n", "\n", "", "self", ".", "num_epochs", "=", "get_model_attribute", "(", "'epoch'", ",", "self", ".", "model_path", ",", "self", ".", "device", ")", "\n", "\n", "# Whether to generate networkx format graphs for real datasets", "\n", "self", ".", "generate_graphs", "=", "True", "\n", "\n", "self", ".", "count", "=", "num_graphs", "\n", "self", ".", "batch_size", "=", "200", "# Must be a factor of count", "\n", "\n", "self", ".", "metric_eval_batch_size", "=", "1", "\n", "\n", "# Specific to GraphRNN and DGMG", "\n", "self", ".", "max_num_node", "=", "15", "\n", "\n", "self", ".", "train_args", "=", "get_model_attribute", "(", "\n", "'saved_args'", ",", "self", ".", "model_path", ",", "self", ".", "device", ")", "\n", "\n", "self", ".", "graphs_save_path", "=", "'graphs/'", "\n", "self", ".", "current_graphs_save_path", "=", "graphs_path", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.generate.generate_pipeline_graphs": [[41, 59], ["generate.ArgsEvaluate", "graph_generation_model.train.predict_graphs", "os.path.isdir", "os.makedirs", "training.graphgen_training_utils.save_graphs", "shutil.rmtree"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.train.predict_graphs", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.save_graphs"], ["", "", "def", "generate_pipeline_graphs", "(", "injected_dataset_name", "=", "None", ",", "\n", "graph_gen_model_path", "=", "'training_artifacts/graph_generation/graph_generation_model.dat'", ",", "\n", "num_graphs", "=", "500", ",", "graphs_path", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    Generate graphs (networkx format) given a trained generative model\n    and save them to a directory\n    \"\"\"", "\n", "eval_args", "=", "ArgsEvaluate", "(", "dataset_name", "=", "injected_dataset_name", ",", "graph_gen_model_path", "=", "graph_gen_model_path", ",", "\n", "num_graphs", "=", "num_graphs", ",", "graphs_path", "=", "graphs_path", ")", "\n", "\n", "gen_graphs", "=", "gen_graphs_dgmg", "(", "eval_args", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "eval_args", ".", "current_graphs_save_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "eval_args", ".", "current_graphs_save_path", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "eval_args", ".", "current_graphs_save_path", ")", "\n", "\n", "save_graphs", "(", "eval_args", ".", "current_graphs_save_path", ",", "gen_graphs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__init__": [[32, 64], ["os.cpu_count"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_graphs", "=", "7", ",", "time_budget", "=", "300", ",", "hpo", "=", "'autosklearn'", ",", "\n", "graph_gen_model_path", "=", "None", ",", "dataset_embeddings_path", "=", "None", ",", "\n", "seed", "=", "123", ",", "num_threads", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        @param num_graphs: number of graphs/pipelines to generate by the graph generator\n        @param time_budget: total time budget in seconds\n        @param hpo: hyperparameter optimizer. Either 'autosklearn' or 'flaml'\n        @param graph_gen_model_path: path to the trained graph generation model. If None, defaults to 'training_artifacts/graph_generation/graph_generation_model.dat'\n        @param dataset_embeddings_path: path to an object containing the embeddings of training datasets. if None, defaults to 'training_artifacts/dataset_embeddings/training_set_embeddings.pickle']\n        @param seed: random seed for data split and fitting.\n        @param num_threads: number of threads to use while fitting.\n        \"\"\"", "\n", "\n", "self", ".", "num_graphs", "=", "num_graphs", "\n", "self", ".", "time_budget", "=", "time_budget", "\n", "assert", "hpo", "in", "[", "'autosklearn'", ",", "'flaml'", "]", ",", "\"HPO must be either 'autosklearn' or 'flaml'\"", "\n", "self", ".", "hpo", "=", "hpo", "\n", "self", ".", "is_autosklearn", "=", "self", ".", "hpo", "==", "'autosklearn'", "\n", "self", ".", "graph_gen_model_path", "=", "graph_gen_model_path", "or", "f'{KGPIP_PATH}/training_artifacts/graph_generation/graph_generation_model.dat'", "\n", "self", ".", "dataset_embeddings_path", "=", "dataset_embeddings_path", "or", "f'{KGPIP_PATH}/training_artifacts/dataset_embeddings/training_set_embeddings.pickle'", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_threads", "=", "num_threads", "or", "os", ".", "cpu_count", "(", ")", "-", "1", "\n", "self", ".", "is_regression", "=", "None", "\n", "self", ".", "target_preprocessors", "=", "None", "\n", "self", ".", "target_estimators", "=", "None", "\n", "self", ".", "X_train", "=", "None", "\n", "self", ".", "X_test", "=", "None", "\n", "self", ".", "y_train", "=", "None", "\n", "self", ".", "y_test", "=", "None", "\n", "self", ".", "closest_dataset", "=", "None", "\n", "self", ".", "pipeline_graphs", "=", "None", "\n", "self", ".", "automl_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__find_closest_training_dataset_by_embedding": [[67, 87], ["kgpip.KGpip.X_train.sample", "dataset_embedding_model.api.embed_dataset", "pandas.read_pickle", "task_embeddings.items", "min", "float", "len", "scipy.spatial.distance.cosine"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api.embed_dataset"], ["", "def", "__find_closest_training_dataset_by_embedding", "(", "self", ")", ":", "\n", "\n", "        ", "X", "=", "self", ".", "X_train", ".", "sample", "(", "min", "(", "1000", ",", "len", "(", "self", ".", "X_train", ")", ")", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "embedding", "=", "embed_dataset", "(", "X", ")", "\n", "\n", "training_datasets_embeddings", "=", "pd", ".", "read_pickle", "(", "self", ".", "dataset_embeddings_path", ")", "\n", "if", "self", ".", "is_regression", ":", "\n", "            ", "task_embeddings", "=", "training_datasets_embeddings", "[", "'regression'", "]", "\n", "", "else", ":", "\n", "            ", "task_embeddings", "=", "training_datasets_embeddings", "[", "'classification'", "]", "\n", "\n", "", "shortest_distance", "=", "np", ".", "inf", "\n", "closest_dataset", "=", "None", "\n", "for", "dataset_name", ",", "properties", "in", "task_embeddings", ".", "items", "(", ")", ":", "\n", "            ", "distance", "=", "float", "(", "cosine", "(", "embedding", ",", "properties", "[", "'embedding'", "]", ")", ")", "\n", "if", "distance", "<", "shortest_distance", ":", "\n", "                ", "shortest_distance", "=", "distance", "\n", "closest_dataset", "=", "dataset_name", "\n", "\n", "", "", "return", "closest_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__preprocess": [[89, 147], ["X.drop.drop.replace", "y.astype.astype.replace", "X.drop.drop.apply", "pandas.to_numeric", "X[].reset_index", "y[].reset_index", "utils.kgpip_utils.is_text_column", "y.astype.astype.astype", "X[].fillna", "X[].fillna", "spacy_universal_sentence_encoder.load_model", "print", "X[].apply().values.tolist", "pandas.DataFrame", "pandas.concat", "X.drop.drop.drop", "X[].astype", "len", "X[].mean", "kgpip.KGpip.X_train[].mean", "range", "X[].mode", "kgpip.KGpip.X_train[].mode", "X[].apply", "len", "kgpip.KGpip.X_train[].mean", "y.astype.astype.isna", "y.astype.astype.isna", "kgpip.KGpip.X_train[].mode", "spacy_universal_sentence_encoder.load_model.vector.round", "spacy_universal_sentence_encoder.load_model."], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_tables.dataset_statistics_and_info.is_text_column", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.load_model"], ["", "def", "__preprocess", "(", "self", ",", "X", ",", "y", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"\n        Do pre-processing for the input dataframe before passing it to AutoSklearn.\n        Pre-processing:\n            1. Drop rows missing values in target variable          TODO: any way around this?\n            2. Impute missing values in each column with the mean in case of numerical column and mode otherwise \n            3. Vectorize text columns by using CountVectorizer and selecting the top 500 words by frequency (i.e. columns). \n                TODO: other options include TfidfVectorizer\n                TODO: the whole vocabulary could be 10s of thousands. But does this make sense?\n            4. Convert String columns to categorical type\n        \"\"\"", "\n", "# 1. drop rows with missing values in y", "\n", "X", ",", "y", "=", "X", ".", "replace", "(", "'?'", ",", "np", ".", "nan", ")", ",", "y", ".", "replace", "(", "'?'", ",", "np", ".", "nan", ")", "# some datasets have NaNs as \"?\"", "\n", "X", ",", "y", "=", "X", ".", "apply", "(", "pd", ".", "to_numeric", ",", "errors", "=", "'ignore'", ")", ",", "pd", ".", "to_numeric", "(", "y", ",", "errors", "=", "'ignore'", ")", "# re-evaluate column types", "\n", "X", ",", "y", "=", "X", "[", "~", "y", ".", "isna", "(", ")", "]", ".", "reset_index", "(", "drop", "=", "True", ")", ",", "y", "[", "~", "y", ".", "isna", "(", ")", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "\n", "# 2. Impute missing values with mean or mode depending on column type.", "\n", "# for test set, use mean/mode of training set", "\n", "for", "col", "in", "[", "i", "for", "i", "in", "X", ".", "columns", "if", "i", "in", "self", ".", "X_train", ".", "columns", "]", ":", "\n", "            ", "if", "is_train", ":", "\n", "                ", "X", "[", "col", "]", "=", "X", "[", "col", "]", ".", "fillna", "(", "X", "[", "col", "]", ".", "mean", "(", ")", "if", "X", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'biufc'", "else", "X", "[", "col", "]", ".", "mode", "(", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "X", "[", "col", "]", "=", "X", "[", "col", "]", ".", "fillna", "(", "self", ".", "X_train", "[", "col", "]", ".", "mean", "(", ")", "if", "self", ".", "X_train", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'biufc'", "else", "self", ".", "X_train", "[", "col", "]", ".", "mode", "(", ")", "[", "0", "]", ")", "\n", "\n", "# 3. vectorize textual columns ", "\n", "", "", "for", "c", "in", "X", ".", "columns", ":", "\n", "            ", "if", "is_text_column", "(", "X", "[", "c", "]", ")", ":", "\n", "                ", "import", "spacy_universal_sentence_encoder", "\n", "nlp", "=", "spacy_universal_sentence_encoder", ".", "load_model", "(", "'en_use_md'", ")", "\n", "print", "(", "'Vectorizing column:'", ",", "c", ")", "\n", "vectorized", "=", "X", "[", "c", "]", ".", "apply", "(", "lambda", "x", ":", "nlp", "(", "x", ")", ".", "vector", ".", "round", "(", "3", ")", ")", ".", "values", ".", "tolist", "(", ")", "\n", "new_column_names", "=", "[", "f'embed_{c}_{i}'", "for", "i", "in", "range", "(", "len", "(", "vectorized", "[", "0", "]", ")", ")", "]", "\n", "# instead of using all columns (might be too high), use the top 500 words", "\n", "vectorized_df", "=", "pd", ".", "DataFrame", "(", "vectorized", ",", "columns", "=", "new_column_names", ")", "\n", "# add the new columns", "\n", "X", "=", "pd", ".", "concat", "(", "[", "X", ",", "vectorized_df", "]", ",", "axis", "=", "1", ")", "\n", "# drop the text column", "\n", "X", "=", "X", ".", "drop", "(", "c", ",", "axis", "=", "1", ")", "\n", "\n", "# For test set: add missing columns from X_train and re-order them ", "\n", "", "", "if", "not", "is_train", ":", "\n", "            ", "for", "col", "in", "[", "i", "for", "i", "in", "self", ".", "X_train", ".", "columns", "if", "i", "not", "in", "X", ".", "columns", "]", ":", "\n", "                ", "X", "[", "col", "]", "=", "[", "self", ".", "X_train", "[", "col", "]", ".", "mean", "(", ")", "if", "self", ".", "X_train", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'biufc'", "else", "self", ".", "X_train", "[", "col", "]", ".", "mode", "(", ")", "[", "0", "]", "]", "*", "len", "(", "X", ")", "\n", "\n", "# re-order columns", "\n", "", "X", "=", "X", "[", "self", ".", "X_train", ".", "columns", "]", "\n", "\n", "# 4. convert string columns to categorical.", "\n", "", "for", "c", "in", "X", ".", "columns", ":", "\n", "            ", "if", "X", "[", "c", "]", ".", "dtype", "==", "object", ":", "\n", "                ", "X", "[", "c", "]", "=", "X", "[", "c", "]", ".", "astype", "(", "'category'", ")", "\n", "\n", "# if y is a column of string type, convert it into categorical type", "\n", "", "", "if", "y", ".", "dtype", "==", "object", ":", "\n", "            ", "y", "=", "y", ".", "astype", "(", "'category'", ")", "\n", "\n", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__filter_invalid_pipeline_graphs": [[149, 177], ["list", "range", "kgpip.KGpip.target_estimators.keys", "networkx.dfs_edges", "any", "len", "valid_pipeline_graphs.append"], "methods", ["None"], ["", "def", "__filter_invalid_pipeline_graphs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Graph is valid if it:\n        1. Starts with the dataset name node then pandas.read_csv\n        2. Has a linear structure.\n        3. Has at least one estimator (from the target AutoML library) that matches the task (regression vs. classification)\n        \"\"\"", "\n", "valid_pipeline_graphs", "=", "[", "]", "\n", "for", "graph", "in", "self", ".", "pipeline_graphs", ":", "\n", "# check 1", "\n", "            ", "if", "self", ".", "closest_dataset", "not", "in", "graph", "or", "'pandas.read_csv'", "not", "in", "graph", ":", "\n", "                ", "continue", "\n", "", "dfs_edges", "=", "list", "(", "nx", ".", "dfs_edges", "(", "graph", ",", "source", "=", "self", ".", "closest_dataset", ")", ")", "\n", "# check 2", "\n", "is_linear_graph", "=", "True", "\n", "for", "i", "in", "range", "(", "len", "(", "dfs_edges", ")", "-", "1", ")", ":", "\n", "                ", "if", "dfs_edges", "[", "i", "]", "[", "1", "]", "!=", "dfs_edges", "[", "i", "+", "1", "]", "[", "0", "]", ":", "\n", "                    ", "is_linear_graph", "=", "False", "\n", "break", "\n", "", "", "if", "not", "is_linear_graph", ":", "\n", "                ", "continue", "\n", "\n", "", "ordered_nodes", "=", "[", "i", "[", "0", "]", "for", "i", "in", "dfs_edges", "]", "+", "[", "dfs_edges", "[", "-", "1", "]", "[", "1", "]", "]", "\n", "# check 3", "\n", "for", "target_estimator", "in", "self", ".", "target_estimators", ".", "keys", "(", ")", ":", "\n", "                ", "if", "any", "(", "[", "target_estimator", "in", "i", "for", "i", "in", "ordered_nodes", "]", ")", ":", "\n", "                    ", "valid_pipeline_graphs", ".", "append", "(", "graph", ")", "# condition 3 satisfied.", "\n", "", "", "", "self", ".", "pipeline_graphs", "=", "valid_pipeline_graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__extract_pipeline_skeletons": [[179, 220], ["set", "enumerate", "kgpip.KGpip.target_estimators.values", "set", "set", "kgpip.KGpip.target_preprocessors.items", "kgpip.KGpip.target_estimators.items", "list", "any", "any", "sorted", "sorted", "set", "set.update", "pipeline_skeletons.extend", "set.add", "isinstance", "ordered_pipeline_skeletons.append", "set.update", "set.add", "str", "str"], "methods", ["None"], ["", "def", "__extract_pipeline_skeletons", "(", "self", ")", ":", "\n", "        ", "pipeline_skeletons", "=", "[", "]", "\n", "explored_estimators", "=", "set", "(", ")", "\n", "for", "idx", ",", "graph", "in", "enumerate", "(", "self", ".", "pipeline_graphs", ")", ":", "\n", "#  get the preprocessors and estimators from the graphs", "\n", "            ", "extracted_preprocessors", "=", "set", "(", ")", "\n", "extracted_estimators", "=", "set", "(", ")", "\n", "for", "graph_preprocessor", ",", "automl_preprocessor", "in", "self", ".", "target_preprocessors", ".", "items", "(", ")", ":", "\n", "                ", "if", "any", "(", "[", "graph_preprocessor", "in", "i", "for", "i", "in", "graph", "]", ")", ":", "\n", "# add the equivalent preprocessor from the target AutoML library.", "\n", "                    ", "extracted_preprocessors", ".", "add", "(", "automl_preprocessor", ")", "\n", "\n", "", "", "extracted_preprocessors", "=", "extracted_preprocessors", "or", "[", "'no_preprocessing'", "]", "\n", "\n", "for", "graph_estimator", ",", "automl_estimator", "in", "self", ".", "target_estimators", ".", "items", "(", ")", ":", "\n", "                ", "if", "any", "(", "[", "graph_estimator", "in", "i", "for", "i", "in", "graph", "]", ")", ":", "\n", "# add the equivalent estimator(s) from the target AutoML library.", "\n", "                    ", "if", "isinstance", "(", "automl_estimator", ",", "list", ")", ":", "\n", "                        ", "extracted_estimators", ".", "update", "(", "automl_estimator", ")", "\n", "", "else", ":", "\n", "                        ", "extracted_estimators", ".", "add", "(", "automl_estimator", ")", "\n", "\n", "", "", "", "extracted_preprocessors", ",", "extracted_estimators", "=", "sorted", "(", "extracted_preprocessors", ")", ",", "sorted", "(", "extracted_estimators", ")", "\n", "\n", "# remove previously explored estimators", "\n", "# TODO: refactor (merge explored_estimators and pipeline_skeletons)", "\n", "unexplored_estimators", "=", "list", "(", "\n", "set", "(", "[", "e", "for", "e", "in", "extracted_estimators", "if", "(", "str", "(", "extracted_preprocessors", ")", ",", "e", ")", "not", "in", "explored_estimators", "]", ")", ")", "\n", "if", "unexplored_estimators", ":", "\n", "                ", "explored_estimators", ".", "update", "(", "[", "(", "str", "(", "extracted_preprocessors", ")", ",", "e", ")", "for", "e", "in", "unexplored_estimators", "]", ")", "\n", "pipeline_skeletons", ".", "extend", "(", "[", "(", "extracted_preprocessors", ",", "[", "e", "]", ")", "for", "e", "in", "unexplored_estimators", "]", ")", "\n", "\n", "\n", "", "", "ordered_pipeline_skeletons", "=", "[", "]", "\n", "\n", "for", "estimator", "in", "self", ".", "target_estimators", ".", "values", "(", ")", ":", "\n", "            ", "for", "p_list", ",", "e_list", "in", "pipeline_skeletons", ":", "\n", "                ", "if", "[", "estimator", "]", "==", "e_list", "and", "(", "p_list", ",", "e_list", ")", "not", "in", "ordered_pipeline_skeletons", ":", "\n", "                    ", "ordered_pipeline_skeletons", ".", "append", "(", "(", "p_list", ",", "e_list", ")", ")", "\n", "\n", "", "", "", "return", "ordered_pipeline_skeletons", "[", ":", "self", ".", "num_graphs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit": [[222, 367], ["sklearn.model_selection.train_test_split", "datetime.datetime.datetime.now", "kgpip.KGpip.__find_closest_training_dataset_by_embedding", "datetime.datetime.datetime.now", "kgpip.KGpip.__preprocess", "kgpip.KGpip.__preprocess", "datetime.datetime.datetime.now", "generate.generate_pipeline_graphs", "print", "glob.glob.glob", "shutil.rmtree", "kgpip.KGpip.__filter_invalid_pipeline_graphs", "kgpip.KGpip.__extract_pipeline_skeletons", "datetime.datetime.datetime.now", "print", "print", "datetime.datetime.datetime.now", "pandas.read_pickle", "node_labels.items", "networkx.relabel_nodes", "edge_labels.items", "graphs.append", "print", "int", "print", "print", "datetime.datetime.datetime.now", "datetime.datetime.datetime.now", "random.randint", "v.replace", "v.replace", "datetime.datetime.datetime.now", "len", "datetime.datetime.datetime.now", "AutoSklearnModel", "flaml.AutoML", "datetime.datetime.datetime.now", "networkx.relabel_nodes.get_edge_data", "len", "flaml.AutoML.fit", "flaml.AutoML.fit", "sklearn.metrics.r2_score", "sklearn.metrics.f1_score", "print", "print", "print", "flaml.AutoML.predict", "flaml.AutoML.predict", "datetime.datetime.datetime.now", "datetime.datetime.datetime.now", "autosklearn.metrics.make_scorer", "random.randint"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__find_closest_training_dataset_by_embedding", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__preprocess", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__preprocess", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.generate.generate_pipeline_graphs", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__filter_invalid_pipeline_graphs", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__extract_pipeline_skeletons", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", ",", "task", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        \n        @param X: A pandas DataFrame of features\n        @param y: A pandas DataFrame/Series of the target column\n        @param task: Either 'classification' or 'regression' \n        @param verbose: whether to print the progress. \n        \"\"\"", "\n", "assert", "task", "in", "[", "'classification'", ",", "'regression'", "]", ",", "\"Task must be either 'classification' or 'regression'\"", "\n", "self", ".", "is_regression", "=", "task", "==", "'regression'", "\n", "if", "self", ".", "is_regression", ":", "\n", "            ", "self", ".", "target_estimators", "=", "supported_autosklearn_regressors", "if", "self", ".", "is_autosklearn", "else", "supported_flaml_regressors", "\n", "", "else", ":", "\n", "            ", "self", ".", "target_estimators", "=", "supported_autosklearn_classifiers", "if", "self", ".", "is_autosklearn", "else", "supported_flaml_classifiers", "\n", "", "self", ".", "target_preprocessors", "=", "supported_autosklearn_preprocessors", "if", "self", ".", "is_autosklearn", "else", "supported_flaml_preprocessors", "\n", "\n", "self", ".", "X_train", ",", "self", ".", "X_test", ",", "self", ".", "y_train", ",", "self", ".", "y_test", "=", "train_test_split", "(", "X", ",", "y", ",", "train_size", "=", "0.8", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'==='", ",", "dt", ".", "now", "(", ")", ",", "'==='", ",", "'Regression?'", ",", "self", ".", "is_regression", ",", "'==='", ",", "'Time Budget:'", ",", "self", ".", "time_budget", ",", "\n", "'==='", ",", "'Graph Gen Model:'", ",", "self", ".", "graph_gen_model_path", ",", "'==='", ",", "'Optimizer:'", ",", "self", ".", "hpo", ",", "'==='", ",", "\n", "'Num Graphs:'", ",", "self", ".", "num_graphs", ",", "'==='", ")", "\n", "\n", "", "d0", "=", "dt", ".", "now", "(", ")", "\n", "\n", "# 1. finding closest dataset from the training set of KGpip", "\n", "self", ".", "closest_dataset", "=", "self", ".", "__find_closest_training_dataset_by_embedding", "(", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "dt", ".", "now", "(", ")", ",", "f'Closest Dataset is: {self.closest_dataset}'", ")", "\n", "\n", "", "d1", "=", "dt", ".", "now", "(", ")", "\n", "\n", "# 2. Pre-processing", "\n", "self", ".", "X_train", ",", "self", ".", "y_train", "=", "self", ".", "__preprocess", "(", "self", ".", "X_train", ",", "self", ".", "y_train", ",", "is_train", "=", "True", ")", "\n", "self", ".", "X_test", ",", "self", ".", "y_test", "=", "self", ".", "__preprocess", "(", "self", ".", "X_test", ",", "self", ".", "y_test", ",", "is_train", "=", "False", ")", "\n", "\n", "d2", "=", "dt", ".", "now", "(", ")", "\n", "\n", "# 3. Graph Generation", "\n", "# TODO: move this to a separate method: generate pipeline graphs", "\n", "tmp_graphs_dir", "=", "f'tmp/pipeline_graphs_{randint(1, 100000000)}/'", "\n", "generate_pipeline_graphs", "(", "self", ".", "closest_dataset", ",", "graph_gen_model_path", "=", "self", ".", "graph_gen_model_path", ",", "num_graphs", "=", "1000", ",", "\n", "graphs_path", "=", "tmp_graphs_dir", ")", "\n", "\n", "print", "(", "dt", ".", "now", "(", ")", ",", "'Using Graphs generated at:'", ",", "tmp_graphs_dir", ")", "\n", "\n", "graphs", "=", "[", "]", "\n", "for", "graph_file", "in", "glob", "(", "tmp_graphs_dir", "+", "'*.dat'", ")", ":", "\n", "# read the graph", "\n", "            ", "g", "=", "pd", ".", "read_pickle", "(", "graph_file", ")", "\n", "# relabel nodes and edges (use label instead of IDs)", "\n", "node_labels", "=", "{", "n", ":", "g", ".", "node", "[", "n", "]", "[", "'label'", "]", "for", "n", "in", "g", ".", "nodes", "}", "\n", "# TODO: is this needed?", "\n", "for", "k", ",", "v", "in", "node_labels", ".", "items", "(", ")", ":", "\n", "                ", "node_labels", "[", "k", "]", "=", "v", ".", "replace", "(", "'http://purl.org/twc/'", ",", "''", ")", "\n", "\n", "", "g", "=", "nx", ".", "relabel_nodes", "(", "g", ",", "node_labels", ")", "\n", "edge_labels", "=", "{", "e", ":", "g", ".", "get_edge_data", "(", "*", "e", ")", "[", "'label'", "]", "for", "e", "in", "g", ".", "edges", "}", "\n", "# TODO: is this needed?", "\n", "for", "k", ",", "v", "in", "edge_labels", ".", "items", "(", ")", ":", "\n", "                ", "edge_labels", "[", "k", "]", "=", "v", ".", "replace", "(", "'http://purl.org/twc/graph4code/'", ",", "''", ")", "\n", "", "graphs", ".", "append", "(", "g", ")", "\n", "\n", "", "shutil", ".", "rmtree", "(", "tmp_graphs_dir", ")", "\n", "self", ".", "pipeline_graphs", "=", "graphs", "\n", "\n", "\n", "# Filter out invalid pipeline graphs", "\n", "self", ".", "__filter_invalid_pipeline_graphs", "(", ")", "\n", "\n", "# extract pipeline skeletons from validated pipeline graphs", "\n", "pipeline_skeletons", "=", "self", ".", "__extract_pipeline_skeletons", "(", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "dt", ".", "now", "(", ")", ",", "'Considering'", ",", "len", "(", "pipeline_skeletons", ")", ",", "'Skeletons:'", ",", "pipeline_skeletons", ")", "\n", "", "d3", "=", "dt", ".", "now", "(", ")", "\n", "\n", "# time budget is calculated end to end (i.e. include graph generation time in the calculation)", "\n", "time_budget_per_graph", "=", "0", "\n", "if", "pipeline_skeletons", ":", "\n", "            ", "time_budget_per_graph", "=", "int", "(", "(", "self", ".", "time_budget", "-", "(", "d3", "-", "d0", ")", ".", "seconds", ")", "/", "len", "(", "pipeline_skeletons", ")", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "dt", ".", "now", "(", ")", ",", "'Time budget per graph:'", ",", "time_budget_per_graph", ")", "\n", "\n", "# 6. train the automl models on X_train", "\n", "", "top_score", "=", "-", "1", "\n", "top_skeleton", "=", "None", "\n", "for", "preprocessors", ",", "estimators", "in", "pipeline_skeletons", ":", "\n", "\n", "            ", "if", "self", ".", "is_autosklearn", ":", "\n", "                ", "AutoSklearnModel", "=", "AutoSklearnRegressor", "if", "self", ".", "is_regression", "else", "AutoSklearnClassifier", "\n", "include_param", "=", "{", "'regressor'", ":", "estimators", ",", "'feature_preprocessor'", ":", "preprocessors", "}", "if", "self", ".", "is_regression", "else", "{", "'classifier'", ":", "estimators", ",", "'feature_preprocessor'", ":", "preprocessors", "}", "\n", "\n", "automl_model", "=", "AutoSklearnModel", "(", "include", "=", "include_param", ",", "\n", "n_jobs", "=", "self", ".", "num_threads", ",", "\n", "memory_limit", "=", "8000", ",", "\n", "time_left_for_this_task", "=", "time_budget_per_graph", ",", "\n", "resampling_strategy", "=", "'cv'", ",", "\n", "resampling_strategy_arguments", "=", "{", "'folds'", ":", "5", "}", ",", "\n", "metric", "=", "autosklearn", ".", "metrics", ".", "r2", "if", "self", ".", "is_regression", "else", "\n", "autosklearn", ".", "metrics", ".", "make_scorer", "(", "'f1'", ",", "f1_score", ",", "average", "=", "'macro'", ")", ",", "\n", "tmp_folder", "=", "f'{KGPIP_PATH}/tmp/autosklearn-{randint(1, 10000000000)}'", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", "initial_configurations_via_metalearning", "=", "0", "\n", ")", "\n", "", "else", ":", "\n", "# use FLAML", "\n", "                ", "automl_model", "=", "AutoML", "(", ")", "\n", "", "try", ":", "\n", "                ", "if", "self", ".", "is_autosklearn", ":", "\n", "                    ", "automl_model", ".", "fit", "(", "self", ".", "X_train", ",", "self", ".", "y_train", ")", "\n", "", "else", ":", "\n", "                    ", "automl_model", ".", "fit", "(", "self", ".", "X_train", ",", "self", ".", "y_train", ",", "\n", "task", "=", "'regression'", "if", "self", ".", "is_regression", "else", "'classification'", ",", "\n", "estimator_list", "=", "estimators", ",", "\n", "time_budget", "=", "time_budget_per_graph", ",", "\n", "metric", "=", "'r2'", "if", "self", ".", "is_regression", "else", "'macro_f1'", ",", "\n", "eval_method", "=", "'cv'", ",", "n_splits", "=", "5", ",", "\n", "retrain_full", "=", "'budget'", ",", "\n", "verbose", "=", "False", ",", "\n", "mem_thres", "=", "15", "*", "1024", "**", "3", ",", "\n", "n_jobs", "=", "self", ".", "num_threads", ")", "\n", "\n", "# evaluate the automl models in X_test", "\n", "", "if", "self", ".", "is_regression", ":", "\n", "                    ", "model_score", "=", "r2_score", "(", "self", ".", "y_test", ",", "automl_model", ".", "predict", "(", "self", ".", "X_test", ")", ")", "\n", "", "else", ":", "\n", "                    ", "model_score", "=", "f1_score", "(", "self", ".", "y_test", ",", "automl_model", ".", "predict", "(", "self", ".", "X_test", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "if", "model_score", ">", "top_score", ":", "\n", "                    ", "top_score", "=", "model_score", "\n", "top_skeleton", "=", "(", "preprocessors", ",", "estimators", ")", "\n", "self", ".", "automl_model", "=", "automl_model", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "dt", ".", "now", "(", ")", ",", "'Score of:'", ",", "preprocessors", ",", "' - '", ",", "estimators", ",", "':'", ",", "model_score", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "dt", ".", "now", "(", ")", ",", "'AutoML automl_model failed: Pre-processors'", ",", "preprocessors", ",", "'Estimators:'", ",", "estimators", ")", "\n", "print", "(", "e", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "            ", "print", "(", "dt", ".", "now", "(", ")", ",", "'Fitting Done. Best Score:'", ",", "top_score", ",", "'. Best Skeleton:'", ",", "top_skeleton", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict": [[369, 373], ["pandas.Series", "kgpip.KGpip.__preprocess", "kgpip.KGpip.automl_model.predict", "len"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.__preprocess", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict"], ["", "", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "dummy_target", "=", "pd", ".", "Series", "(", "[", "1", "]", "*", "len", "(", "X", ")", ",", "index", "=", "X", ".", "index", ")", "\n", "X_test", ",", "_", "=", "self", ".", "__preprocess", "(", "X", ",", "dummy_target", ",", "is_train", "=", "False", ")", "\n", "return", "self", ".", "automl_model", ".", "predict", "(", "X_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.args.Args.__init__": [[11, 85], ["torch.device", "round", "torch.device", "datetime.datetime.datetime.now", "torch.cuda.is_available"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Can manually select the device too", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:0'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "# self.device = 'cpu'", "\n", "# Clean tensorboard", "\n", "self", ".", "clean_tensorboard", "=", "False", "\n", "# Clean temp folder", "\n", "self", ".", "clean_temp", "=", "True", "\n", "\n", "# Whether to use tensorboard for logging", "\n", "self", ".", "log_tensorboard", "=", "False", "\n", "\n", "# Algorithm Version - # Algorithm Version DGMG (Deep GMG)", "\n", "self", ".", "note", "=", "'DGMG'", "\n", "\n", "# Check datasets/process_dataset for datasets", "\n", "# Select dataset to train the model", "\n", "self", ".", "graph_type", "=", "'graph4code_large'", "\n", "self", ".", "num_graphs", "=", "None", "# Set it None to take complete dataset", "\n", "\n", "# Whether to produce networkx format graphs for real datasets", "\n", "self", ".", "produce_graphs", "=", "True", "\n", "\n", "\n", "self", ".", "batch_size", "=", "16", "# normal: 32, and the rest should be changed accordingly", "\n", "\n", "# Specific to DGMG", "\n", "# Model parameters", "\n", "self", ".", "feat_size", "=", "32", "\n", "self", ".", "hops", "=", "1", "\n", "self", ".", "dropout", "=", "0.2", "\n", "\n", "# training config", "\n", "self", ".", "num_workers", "=", "0", "# num workers to load data, default 4", "\n", "self", ".", "epochs", "=", "400", "\n", "\n", "self", ".", "lr", "=", "0.001", "# Learning rate", "\n", "# Learning rate decay factor at each milestone (no. of epochs)", "\n", "self", ".", "gamma", "=", "0.5", "\n", "self", ".", "milestones", "=", "[", "50", ",", "100", ",", "150", ",", "200", "]", "# List of milestones", "\n", "\n", "# Whether to do gradient clipping", "\n", "self", ".", "gradient_clipping", "=", "True", "\n", "\n", "# Output config", "\n", "self", ".", "dir_input", "=", "''", "\n", "self", ".", "model_save_path", "=", "self", ".", "dir_input", "+", "'model_save/'", "\n", "self", ".", "tensorboard_path", "=", "self", ".", "dir_input", "+", "'tensorboard/'", "\n", "self", ".", "dataset_path", "=", "self", ".", "dir_input", "+", "'datasets/'", "\n", "self", ".", "temp_path", "=", "self", ".", "dir_input", "+", "'tmp/'", "\n", "\n", "# Model save and validate parameters", "\n", "self", ".", "save_model", "=", "True", "\n", "self", ".", "epochs_save", "=", "round", "(", "self", ".", "epochs", "/", "20", ")", "\n", "self", ".", "epochs_validate", "=", "1", "\n", "\n", "# Time at which code is run", "\n", "self", ".", "time", "=", "'{0:%Y-%m-%d_%H:%M:%S}'", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", "\n", "\n", "# Filenames to save intermediate and final outputs", "\n", "self", ".", "fname", "=", "self", ".", "note", "+", "'_'", "+", "self", ".", "graph_type", "\n", "\n", "# Calcuated at run time", "\n", "self", ".", "current_model_save_path", "=", "self", ".", "model_save_path", "+", "self", ".", "fname", "+", "'_'", "+", "self", ".", "time", "+", "'/'", "\n", "self", ".", "current_dataset_path", "=", "None", "\n", "self", ".", "current_processed_dataset_path", "=", "None", "\n", "self", ".", "current_temp_path", "=", "self", ".", "temp_path", "+", "self", ".", "fname", "+", "'_'", "+", "self", ".", "time", "+", "'/'", "\n", "\n", "# Model load parameters", "\n", "self", ".", "load_model", "=", "False", "\n", "self", ".", "load_model_path", "=", "''", "\n", "self", ".", "load_device", "=", "torch", ".", "device", "(", "'cuda:0'", ")", "\n", "self", ".", "epochs_end", "=", "10000", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.args.Args.update_args": [[86, 103], ["training.graphgen_training_utils.get_model_attribute"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute"], ["", "def", "update_args", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "load_model", ":", "\n", "            ", "args", "=", "get_model_attribute", "(", "\n", "'saved_args'", ",", "self", ".", "load_model_path", ",", "self", ".", "load_device", ")", "\n", "args", ".", "device", "=", "self", ".", "load_device", "\n", "args", ".", "load_model", "=", "True", "\n", "args", ".", "load_model_path", "=", "self", ".", "load_model_path", "\n", "args", ".", "epochs", "=", "self", ".", "epochs_end", "\n", "\n", "args", ".", "clean_tensorboard", "=", "False", "\n", "args", ".", "clean_temp", "=", "False", "\n", "\n", "args", ".", "produce_graphs", "=", "False", "\n", "\n", "return", "args", "\n", "\n", "", "return", "self", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.utils.kgpip_utils.is_text_column": [[73, 97], ["df_column.values.tolist", "len", "isinstance", "df_column.unique", "len"], "function", ["None"], ["def", "is_text_column", "(", "df_column", ")", ":", "\n", "    ", "\"\"\"\n    Check if the dataframe column is a text (as opposed to short strings).\n    Simple heuristic: check if it has 20+ unique values and 30%+ of the column contains 2+ space characters.\n    TODO: this will not work with timestamp columns that contain spaces.\n    \"\"\"", "\n", "# to speed up the search in case of string column, check how many unique values", "\n", "if", "df_column", ".", "dtype", "!=", "object", "or", "len", "(", "df_column", ".", "unique", "(", ")", ")", "<", "20", ":", "\n", "        ", "return", "False", "\n", "\n", "", "num_text_rows", "=", "0", "\n", "for", "value", "in", "df_column", ".", "values", ".", "tolist", "(", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "            ", "continue", "\n", "", "space_count", "=", "0", "\n", "for", "character", "in", "value", ":", "\n", "            ", "if", "character", "==", "' '", ":", "\n", "                ", "space_count", "+=", "1", "\n", "", "if", "space_count", ">", "1", ":", "\n", "                ", "num_text_rows", "+=", "1", "\n", "break", "\n", "", "", "if", "num_text_rows", ">", "0.3", "*", "len", "(", "df_column", ")", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.numerical.NumericalEmbeddingModel.__init__": [[7, 15], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "NumericalEmbeddingModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_size", "=", "embedding_size", "\n", "# layer dimensions: 32 -> 300 -> 300 -> 300 (if embedding size is 300)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "32", ",", "embedding_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "embedding_size", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "embedding_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.numerical.NumericalEmbeddingModel.forward": [[16, 25], ["numerical.NumericalEmbeddingModel.fc1", "numerical.NumericalEmbeddingModel.tanh", "numerical.NumericalEmbeddingModel.fc2", "numerical.NumericalEmbeddingModel.tanh", "numerical.NumericalEmbeddingModel.fc3", "numerical.NumericalEmbeddingModel.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "hidden1", "=", "self", ".", "fc1", "(", "x", ")", "\n", "tanh1", "=", "self", ".", "tanh", "(", "hidden1", ")", "\n", "hidden2", "=", "self", ".", "fc2", "(", "tanh1", ")", "\n", "tanh2", "=", "self", ".", "tanh", "(", "hidden2", ")", "\n", "hidden3", "=", "self", ".", "fc3", "(", "tanh2", ")", "\n", "output", "=", "self", ".", "tanh", "(", "hidden3", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.numerical.NumericalScalingModel.__init__": [[29, 37], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_size", ")", ":", "\n", "        ", "super", "(", "NumericalScalingModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_size", "=", "embedding_size", "\n", "# layer dimensions: 32 -> 300 -> 300 -> 1 (if embedding_size is 300)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "32", ",", "embedding_size", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "embedding_size", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.numerical.NumericalScalingModel.forward": [[38, 47], ["numerical.NumericalScalingModel.fc1", "numerical.NumericalScalingModel.relu", "numerical.NumericalScalingModel.fc2", "numerical.NumericalScalingModel.relu", "numerical.NumericalScalingModel.fc3", "torch.square"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "hidden1", "=", "self", ".", "fc1", "(", "x", ")", "\n", "relu1", "=", "self", ".", "relu", "(", "hidden1", ")", "\n", "hidden2", "=", "self", ".", "fc2", "(", "relu1", ")", "\n", "relu2", "=", "self", ".", "relu", "(", "hidden2", ")", "\n", "hidden3", "=", "self", ".", "fc3", "(", "relu2", ")", "\n", "output", "=", "torch", ".", "square", "(", "hidden3", ")", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._load_embedding_model": [[16, 22], ["dataset_embedding_model.numerical.NumericalEmbeddingModel().to", "NumericalEmbeddingModel().to.load_state_dict", "NumericalEmbeddingModel().to.eval", "torch.load", "dataset_embedding_model.numerical.NumericalEmbeddingModel"], "function", ["None"], ["def", "_load_embedding_model", "(", "path", ")", ":", "\n", "    ", "model", "=", "NumericalEmbeddingModel", "(", "EMBEDDING_SIZE", ")", ".", "to", "(", "DEVICE", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._get_column_embedding": [[24, 35], ["column.swifter.progress_bar().apply().to_list", "torch.FloatTensor().to", "embedding_model().mean.tolist", "torch.no_grad", "embedding_model().mean", "int", "column.swifter.progress_bar().apply", "torch.FloatTensor", "embedding_model", "bitstring.BitArray", "column.swifter.progress_bar", "float"], "function", ["None"], ["", "def", "_get_column_embedding", "(", "column", ",", "embedding_model", ")", ":", "\n", "# pre-process the column", "\n", "\n", "    ", "def", "get_bin_repr", "(", "val", ")", ":", "\n", "        ", "return", "[", "int", "(", "j", ")", "for", "j", "in", "bitstring", ".", "BitArray", "(", "float", "=", "float", "(", "val", ")", ",", "length", "=", "32", ")", ".", "bin", "]", "\n", "", "bin_repr", "=", "column", ".", "swifter", ".", "progress_bar", "(", "False", ")", ".", "apply", "(", "get_bin_repr", ",", "convert_dtype", "=", "False", ")", ".", "to_list", "(", ")", "\n", "bin_tensor", "=", "torch", ".", "FloatTensor", "(", "bin_repr", ")", ".", "to", "(", "DEVICE", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "embedding_tensor", "=", "embedding_model", "(", "bin_tensor", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "", "return", "embedding_tensor", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._is_numerical_column": [[37, 48], ["any", "str().startswith", "str"], "function", ["None"], ["", "def", "_is_numerical_column", "(", "column", ")", ":", "\n", "    ", "\"\"\"\n    Checks whether the dtype of a pandas column is numerical\n    :param column: a Pandas Series object representing a column of a table\n    :return: whether column is numerical\n    \"\"\"", "\n", "numerical_dtypes", "=", "[", "'int'", ",", "'uint'", ",", "'float'", ",", "'bool'", "]", "# bool is ok because all will be converted to float eventually.", "\n", "\n", "if", "any", "(", "[", "str", "(", "column", ".", "dtype", ")", ".", "startswith", "(", "i", ")", "for", "i", "in", "numerical_dtypes", "]", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api.embed_dataset": [[50, 70], ["api._load_embedding_model", "tqdm.tqdm", "numpy.average", "df[].dropna", "api._is_numerical_column", "col_embeddings.append", "len", "api._get_column_embedding"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._load_embedding_model", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._is_numerical_column", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api._get_column_embedding"], ["", "def", "embed_dataset", "(", "df", ",", "prints", "=", "True", ")", ":", "\n", "    ", "numerical_model", "=", "_load_embedding_model", "(", "KGPIP_PATH", "+", "'/training_artifacts/dataset_embeddings/dataset_embedding_model.pt'", ")", "\n", "\n", "col_embeddings", "=", "[", "]", "\n", "for", "c", "in", "tqdm", "(", "df", ".", "columns", ",", "disable", "=", "not", "prints", ")", ":", "\n", "# first drop the NaN values in the column", "\n", "        ", "col", "=", "df", "[", "c", "]", ".", "dropna", "(", ")", "\n", "if", "len", "(", "col", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "_is_numerical_column", "(", "col", ")", ":", "\n", "            ", "col_embedding", "=", "_get_column_embedding", "(", "col", ",", "numerical_model", ")", "\n", "", "else", ":", "\n", "# TODO: for now, use an embedding of zeros for non-numerical columns.", "\n", "            ", "col_embedding", "=", "[", "1e-10", "]", "*", "EMBEDDING_SIZE", "\n", "", "col_embeddings", ".", "append", "(", "col_embedding", ")", "\n", "\n", "# TODO: for now, a dataset embedding is mean of column embeddings. Maybe we need to experiment with this later.", "\n", "", "dataset_embedding", "=", "np", ".", "average", "(", "col_embeddings", ",", "axis", "=", "0", ")", "\n", "\n", "return", "dataset_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.experiments.evaluate_automl_systems.main": [[26, 128], ["pandas.read_csv", "datetime.datetime.now", "pandas.read_csv", "sklearn.model_selection.train_test_split", "datetime.datetime.now", "print", "print", "print", "print", "os.path.exists", "os.makedirs", "pd.read_csv.drop", "datetime.datetime.now", "datetime.datetime.now", "open", "f.write", "datetime.datetime.now", "kgpip.KGpip", "VolcanoModel.fit", "VolcanoModel.predict", "sklearn.metrics.r2_score", "sklearn.metrics.f1_score", "print", "traceback.print_exc", "str", "datetime.datetime.now", "flaml.AutoML", "VolcanoModel.fit", "VolcanoModel.predict", "AutoSklearnModel", "VolcanoModel.fit", "VolcanoModel.predict", "mindware.utils.data_manager.DataManager", "mindware.utils.data_manager.DataManager.get_data_node", "mindware.utils.data_manager.DataManager.get_data_node", "VolcanoModel", "VolcanoModel.fit", "VolcanoModel.predict", "y_train.astype.astype", "y_test.astype.astype", "sklearn.preprocessing.LabelEncoder", "pandas.concat", "pandas.Series", "X_train[].astype", "X_test[].astype", "sklearn.preprocessing.LabelEncoder.fit_transform", "os.cpu_count", "autosklearn.metrics.make_scorer", "os.cpu_count", "random.randint", "len", "len"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.fit", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.None.kgpip.KGpip.predict"], ["def", "main", "(", "dataset_id", ",", "system_id", ",", "time_budget", "=", "3600", ",", "results_dir", "=", "'results'", ",", "num_graphs", "=", "7", ",", "\n", "graph_gen_model_path", "=", "None", ",", "dataset_embeddings_path", "=", "None", ")", ":", "\n", "    ", "benchmark_datasets", "=", "pd", ".", "read_csv", "(", "f'{KGPIP_PATH}/benchmark_datasets/benchmark_datasets_info.csv'", ")", "\n", "ds", "=", "benchmark_datasets", ".", "iloc", "[", "dataset_id", "]", "\n", "base_dir", ",", "dataset_name", ",", "is_regression", ",", "target", "=", "ds", "[", "'base_dir'", "]", ",", "ds", "[", "'name'", "]", ",", "ds", "[", "'is_regression'", "]", ",", "ds", "[", "'target'", "]", "\n", "\n", "save_path", "=", "f'{results_dir}/{dataset_name}/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "d0", "=", "dt", ".", "now", "(", ")", "\n", "\n", "# load dataset", "\n", "df", "=", "pd", ".", "read_csv", "(", "f'{KGPIP_PATH}/{base_dir}/{dataset_name}/{dataset_name}.csv'", ",", "low_memory", "=", "False", ")", "\n", "X", ",", "y", "=", "df", ".", "drop", "(", "target", ",", "axis", "=", "1", ")", ",", "df", "[", "target", "]", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "X", ",", "y", ",", "random_state", "=", "123", ")", "\n", "\n", "d1", "=", "dt", ".", "now", "(", ")", "\n", "loading_time", "=", "(", "d1", "-", "d0", ")", ".", "seconds", "\n", "\n", "assert", "0", "<=", "system_id", "<=", "4", ",", "f'Invalid system id: {system_id}'", "\n", "target_system", "=", "[", "'KGpipFLAML'", ",", "'KGpipAutoSklearn'", ",", "'FLAML'", ",", "'AutoSklearn'", ",", "'VolcanoML'", "]", "[", "system_id", "]", "\n", "print", "(", "dt", ".", "now", "(", ")", ",", "f'Task #{dataset_id * 5 + system_id}: Evaluating {target_system} on dataset: {dataset_name}'", ")", "\n", "\n", "try", ":", "\n", "        ", "if", "system_id", "==", "0", "or", "system_id", "==", "1", ":", "\n", "# KGpipFLAML or KGpipAutoSklearn", "\n", "            ", "automl_model", "=", "KGpip", "(", "num_graphs", "=", "num_graphs", ",", "\n", "time_budget", "=", "time_budget", "-", "loading_time", ",", "\n", "hpo", "=", "'flaml'", "if", "system_id", "==", "0", "else", "'autosklearn'", ",", "\n", "graph_gen_model_path", "=", "graph_gen_model_path", ",", "\n", "dataset_embeddings_path", "=", "dataset_embeddings_path", ")", "\n", "automl_model", ".", "fit", "(", "X_train", ",", "y_train", ",", "\n", "task", "=", "'regression'", "if", "is_regression", "else", "'classification'", ")", "\n", "predictions", "=", "automl_model", ".", "predict", "(", "X_test", ")", "\n", "\n", "", "elif", "system_id", "==", "2", ":", "\n", "# FLAML", "\n", "            ", "automl_model", "=", "AutoML", "(", ")", "\n", "automl_model", ".", "fit", "(", "X_train", ",", "y_train", ",", "task", "=", "\"regression\"", "if", "is_regression", "else", "\"classification\"", ",", "\n", "time_budget", "=", "time_budget", "-", "loading_time", ",", "\n", "retrain_full", "=", "'budget'", ",", "\n", "verbose", "=", "0", ",", "metric", "=", "'r2'", "if", "is_regression", "else", "'macro_f1'", ")", "\n", "predictions", "=", "automl_model", ".", "predict", "(", "X_test", ")", "\n", "\n", "", "elif", "system_id", "==", "3", ":", "\n", "# AutoSklearn", "\n", "            ", "for", "col", "in", "X_train", ".", "columns", ":", "\n", "                ", "if", "X_train", "[", "col", "]", ".", "dtype", "==", "object", ":", "\n", "                    ", "X_train", "[", "col", "]", "=", "X_train", "[", "col", "]", ".", "astype", "(", "'category'", ")", "\n", "X_test", "[", "col", "]", "=", "X_test", "[", "col", "]", ".", "astype", "(", "'category'", ")", "\n", "", "", "if", "y_train", ".", "dtype", "==", "object", ":", "\n", "                ", "y_train", "=", "y_train", ".", "astype", "(", "'category'", ")", "\n", "y_test", "=", "y_test", ".", "astype", "(", "'category'", ")", "\n", "\n", "", "AutoSklearnModel", "=", "AutoSklearnRegressor", "if", "is_regression", "else", "AutoSklearnClassifier", "\n", "automl_model", "=", "AutoSklearnModel", "(", "n_jobs", "=", "os", ".", "cpu_count", "(", ")", "-", "1", ",", "\n", "memory_limit", "=", "8000", ",", "\n", "time_left_for_this_task", "=", "time_budget", "-", "loading_time", ",", "\n", "metric", "=", "autosklearn", ".", "metrics", ".", "r2", "if", "is_regression", "else", "\n", "autosklearn", ".", "metrics", ".", "make_scorer", "(", "'f1'", ",", "f1_score", ",", "average", "=", "'macro'", ")", ",", "\n", "tmp_folder", "=", "f'{KGPIP_PATH}/tmp/autosklearn-{randint(1, 1000000)}'", ",", "\n", "seed", "=", "123", ",", "\n", "initial_configurations_via_metalearning", "=", "0", ")", "\n", "automl_model", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "predictions", "=", "automl_model", ".", "predict", "(", "X_test", ")", "\n", "\n", "", "else", ":", "\n", "# VolcanoML", "\n", "            ", "if", "not", "is_regression", ":", "\n", "# encode the target column categories so it works with Volcano", "\n", "                ", "encoder", "=", "LabelEncoder", "(", ")", "\n", "y", "=", "pd", ".", "concat", "(", "[", "y_train", ",", "y_test", "]", ")", "\n", "y", "=", "pd", ".", "Series", "(", "encoder", ".", "fit_transform", "(", "y", ")", ")", "\n", "y_train", ",", "y_test", "=", "y", ".", "iloc", "[", ":", "len", "(", "y_train", ")", "]", ",", "y", ".", "iloc", "[", "len", "(", "y_train", ")", ":", "]", "\n", "", "dm", "=", "DataManager", "(", "X_train", ",", "y_train", ")", "\n", "train_data", "=", "dm", ".", "get_data_node", "(", "X_train", ",", "y_train", ")", "\n", "test_data", "=", "dm", ".", "get_data_node", "(", "X_test", ",", "y_test", ")", "\n", "\n", "VolcanoModel", "=", "Regressor", "if", "is_regression", "else", "Classifier", "\n", "automl_model", "=", "VolcanoModel", "(", "time_limit", "=", "time_budget", "-", "loading_time", ",", "\n", "metric", "=", "'mse'", "if", "is_regression", "else", "'f1'", ",", "\n", "n_jobs", "=", "os", ".", "cpu_count", "(", ")", "-", "1", ",", "\n", "ensemble_method", "=", "None", ",", "\n", "# enable_meta_algorithm_selection=False,", "\n", "# enable_fe=False,", "\n", "output_dir", "=", "\"tmp/\"", ")", "\n", "automl_model", ".", "fit", "(", "train_data", ")", "\n", "predictions", "=", "automl_model", ".", "predict", "(", "test_data", ")", "\n", "\n", "", "score", "=", "r2_score", "(", "y_test", ",", "predictions", ")", "if", "is_regression", "else", "f1_score", "(", "y_test", ",", "predictions", ",", "average", "=", "'macro'", ")", "\n", "\n", "", "except", "Exception", ":", "\n", "        ", "print", "(", "f'{target_system} Failed with dataset: {dataset_name}'", ")", "\n", "traceback", ".", "print_exc", "(", "file", "=", "sys", ".", "stdout", ")", "\n", "score", "=", "0", "\n", "\n", "", "print", "(", "dt", ".", "now", "(", ")", ",", "f'Score of {target_system} on dataset {dataset_name}: {score}'", ")", "\n", "with", "open", "(", "f'{save_path}{target_system}.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "score", ")", ")", "\n", "", "print", "(", "'Results saved in'", ",", "f'{save_path}{target_system}.txt'", ")", "\n", "print", "(", "dt", ".", "now", "(", ")", ",", "'Done. Total Time:'", ",", "dt", ".", "now", "(", ")", "-", "d0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig8b_pipeline_coverage.rotate": [[7, 9], ["None"], "function", ["None"], ["def", "rotate", "(", "l", ",", "n", ")", ":", "\n", "    ", "return", "l", "[", "-", "n", ":", "]", "+", "l", "[", ":", "-", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory": [[14, 94], ["numpy.linspace", "matplotlib.projections.register_projection", "super().__init__", "fig6_score_comparison_radar_charts..set_theta_zero_location", "super().fill", "super().plot", "line.get_data", "numpy.linspace", "fig6_score_comparison_radar_charts..set_thetagrids", "fig6_score_comparison_radar_charts.._close_line", "numpy.append", "numpy.append", "line.set_data", "len", "numpy.degrees", "matplotlib.patches.Circle", "super()._gen_axes_spines", "matplotlib.patches.RegularPolygon", "ValueError", "matplotlib.spines.Spine", "matplotlib.spines.Spine.set_transform", "ValueError", "matplotlib.path.Path.unit_regular_polygon", "matplotlib.transforms.Affine2D().scale().translate", "matplotlib.transforms.Affine2D().scale", "matplotlib.transforms.Affine2D"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["def", "radar_factory", "(", "num_vars", ",", "frame", "=", "'circle'", ")", ":", "\n", "    ", "\"\"\"\n    Create a radar chart with `num_vars` axes.\n\n    This function creates a RadarAxes projection and registers it.\n\n    Parameters\n    ----------\n    num_vars : int\n        Number of variables for radar chart.\n    frame : {'circle', 'polygon'}\n        Shape of frame surrounding axes.\n\n    \"\"\"", "\n", "# calculate evenly-spaced axis angles", "\n", "theta", "=", "np", ".", "linspace", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "num_vars", ",", "endpoint", "=", "False", ")", "\n", "\n", "class", "RadarAxes", "(", "PolarAxes", ")", ":", "\n", "\n", "        ", "name", "=", "'radar'", "\n", "# use 1 line segment to connect specified points", "\n", "RESOLUTION", "=", "1", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# rotate plot such that the first axis is at the top", "\n", "self", ".", "set_theta_zero_location", "(", "'N'", ")", "\n", "\n", "", "def", "fill", "(", "self", ",", "*", "args", ",", "closed", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "            ", "\"\"\"Override fill so that line is closed by default\"\"\"", "\n", "return", "super", "(", ")", ".", "fill", "(", "closed", "=", "closed", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "plot", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "\"\"\"Override plot so that line is closed by default\"\"\"", "\n", "lines", "=", "super", "(", ")", ".", "plot", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "self", ".", "_close_line", "(", "line", ")", "\n", "\n", "", "", "def", "_close_line", "(", "self", ",", "line", ")", ":", "\n", "            ", "x", ",", "y", "=", "line", ".", "get_data", "(", ")", "\n", "# FIXME: markers at x[0], y[0] get doubled-up", "\n", "if", "x", "[", "0", "]", "!=", "x", "[", "-", "1", "]", ":", "\n", "                ", "x", "=", "np", ".", "append", "(", "x", ",", "x", "[", "0", "]", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "y", "[", "0", "]", ")", "\n", "line", ".", "set_data", "(", "x", ",", "y", ")", "\n", "\n", "", "", "def", "set_varlabels", "(", "self", ",", "labels", ")", ":", "\n", "            ", "theta", "=", "np", ".", "linspace", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "len", "(", "labels", ")", ",", "endpoint", "=", "False", ")", "#added by ibrahim", "\n", "self", ".", "set_thetagrids", "(", "np", ".", "degrees", "(", "theta", ")", ",", "labels", ")", "\n", "\n", "", "def", "_gen_axes_patch", "(", "self", ")", ":", "\n", "# The Axes patch must be centered at (0.5, 0.5) and of radius 0.5", "\n", "# in axes coordinates.", "\n", "            ", "if", "frame", "==", "'circle'", ":", "\n", "                ", "return", "Circle", "(", "(", "0.5", ",", "0.5", ")", ",", "0.5", ")", "\n", "", "elif", "frame", "==", "'polygon'", ":", "\n", "                ", "return", "RegularPolygon", "(", "(", "0.5", ",", "0.5", ")", ",", "num_vars", ",", "\n", "radius", "=", ".5", ",", "edgecolor", "=", "\"k\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown value for 'frame': %s\"", "%", "frame", ")", "\n", "\n", "", "", "def", "_gen_axes_spines", "(", "self", ")", ":", "\n", "            ", "if", "frame", "==", "'circle'", ":", "\n", "                ", "return", "super", "(", ")", ".", "_gen_axes_spines", "(", ")", "\n", "", "elif", "frame", "==", "'polygon'", ":", "\n", "# spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.", "\n", "                ", "spine", "=", "Spine", "(", "axes", "=", "self", ",", "\n", "spine_type", "=", "'circle'", ",", "\n", "path", "=", "Path", ".", "unit_regular_polygon", "(", "num_vars", ")", ")", "\n", "# unit_regular_polygon gives a polygon of radius 1 centered at", "\n", "# (0, 0) but we want a polygon of radius 0.5 centered at (0.5,", "\n", "# 0.5) in axes coordinates.", "\n", "spine", ".", "set_transform", "(", "Affine2D", "(", ")", ".", "scale", "(", ".5", ")", ".", "translate", "(", ".5", ",", ".5", ")", "\n", "+", "self", ".", "transAxes", ")", "\n", "return", "{", "'polar'", ":", "spine", "}", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown value for 'frame': %s\"", "%", "frame", ")", "\n", "\n", "", "", "", "register_projection", "(", "RadarAxes", ")", "\n", "return", "theta", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.example_data": [[96, 143], ["None"], "function", ["None"], ["", "def", "example_data", "(", ")", ":", "\n", "# The following data is from the Denver Aerosol Sources and Health study.", "\n", "# See doi:10.1016/j.atmosenv.2008.12.017", "\n", "#", "\n", "# The data are pollution source profile estimates for five modeled", "\n", "# pollution sources (e.g., cars, wood-burning, etc) that emit 7-9 chemical", "\n", "# species. The radar charts are experimented with here to see if we can", "\n", "# nicely visualize how the modeled source profiles change across four", "\n", "# scenarios:", "\n", "#  1) No gas-phase species present, just seven particulate counts on", "\n", "#     Sulfate", "\n", "#     Nitrate", "\n", "#     Elemental Carbon (EC)", "\n", "#     Organic Carbon fraction 1 (OC)", "\n", "#     Organic Carbon fraction 2 (OC2)", "\n", "#     Organic Carbon fraction 3 (OC3)", "\n", "#     Pyrolized Organic Carbon (OP)", "\n", "#  2)Inclusion of gas-phase specie carbon monoxide (CO)", "\n", "#  3)Inclusion of gas-phase specie ozone (O3).", "\n", "#  4)Inclusion of both gas-phase species is present...", "\n", "    ", "data", "=", "[", "\n", "(", "'Basecase'", ",", "[", "\n", "[", "0.88", ",", "0.01", ",", "0.03", ",", "0.03", ",", "0.00", ",", "0.06", ",", "0.01", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.07", ",", "0.95", ",", "0.04", ",", "0.05", ",", "0.00", ",", "0.02", ",", "0.01", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.02", ",", "0.85", ",", "0.19", ",", "0.05", ",", "0.10", ",", "0.00", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.02", ",", "0.01", ",", "0.07", ",", "0.01", ",", "0.21", ",", "0.12", ",", "0.98", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.01", ",", "0.02", ",", "0.71", ",", "0.74", ",", "0.70", ",", "0.00", ",", "0.00", ",", "0.00", "]", "]", ")", ",", "\n", "(", "'With CO'", ",", "[", "\n", "[", "0.88", ",", "0.02", ",", "0.02", ",", "0.02", ",", "0.00", ",", "0.05", ",", "0.00", ",", "0.05", ",", "0.00", "]", ",", "\n", "[", "0.08", ",", "0.94", ",", "0.04", ",", "0.02", ",", "0.00", ",", "0.01", ",", "0.12", ",", "0.04", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.01", ",", "0.79", ",", "0.10", ",", "0.00", ",", "0.05", ",", "0.00", ",", "0.31", ",", "0.00", "]", ",", "\n", "[", "0.00", ",", "0.02", ",", "0.03", ",", "0.38", ",", "0.31", ",", "0.31", ",", "0.00", ",", "0.59", ",", "0.00", "]", ",", "\n", "[", "0.02", ",", "0.02", ",", "0.11", ",", "0.47", ",", "0.69", ",", "0.58", ",", "0.88", ",", "0.00", ",", "0.00", "]", "]", ")", ",", "\n", "(", "'With O3'", ",", "[", "\n", "[", "0.89", ",", "0.01", ",", "0.07", ",", "0.00", ",", "0.00", ",", "0.05", ",", "0.00", ",", "0.00", ",", "0.03", "]", ",", "\n", "[", "0.07", ",", "0.95", ",", "0.05", ",", "0.04", ",", "0.00", ",", "0.02", ",", "0.12", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.02", ",", "0.86", ",", "0.27", ",", "0.16", ",", "0.19", ",", "0.00", ",", "0.00", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.03", ",", "0.00", ",", "0.32", ",", "0.29", ",", "0.27", ",", "0.00", ",", "0.00", ",", "0.95", "]", ",", "\n", "[", "0.02", ",", "0.00", ",", "0.03", ",", "0.37", ",", "0.56", ",", "0.47", ",", "0.87", ",", "0.00", ",", "0.00", "]", "]", ")", ",", "\n", "(", "'CO & O3'", ",", "[", "\n", "[", "0.87", ",", "0.01", ",", "0.08", ",", "0.00", ",", "0.00", ",", "0.04", ",", "0.00", ",", "0.00", ",", "0.01", "]", ",", "\n", "[", "0.09", ",", "0.95", ",", "0.02", ",", "0.03", ",", "0.00", ",", "0.01", ",", "0.13", ",", "0.06", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.02", ",", "0.71", ",", "0.24", ",", "0.13", ",", "0.16", ",", "0.00", ",", "0.50", ",", "0.00", "]", ",", "\n", "[", "0.01", ",", "0.03", ",", "0.00", ",", "0.28", ",", "0.24", ",", "0.23", ",", "0.00", ",", "0.44", ",", "0.88", "]", ",", "\n", "[", "0.02", ",", "0.00", ",", "0.18", ",", "0.45", ",", "0.64", ",", "0.55", ",", "0.86", ",", "0.00", ",", "0.16", "]", "]", ")", "\n", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data": [[144, 164], ["range", "len", "categories.append", "FLAML.append", "KGpipAutoSklearn.append", "AutoSklearn.append", "KGpipFLAML.append", "AL.append", "str"], "function", ["None"], ["", "def", "get_task_data", "(", "task_name", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "KGpipFLAML_data", ",", "AL_data", "=", "None", ")", ":", "\n", "    ", "FLAML", "=", "[", "]", "\n", "KGpipAutoSklearn", "=", "[", "]", "\n", "AutoSklearn", "=", "[", "]", "\n", "KGpipFLAML", "=", "[", "]", "\n", "AL", "=", "[", "]", "\n", "\n", "categories", "=", "[", "]", "\n", "max_len_dataset", "=", "7", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "Tasks", ")", ")", ":", "\n", "        ", "if", "Tasks", "[", "i", "]", "==", "task_name", ":", "\n", "            ", "categories", ".", "append", "(", "str", "(", "Datasets", "[", "i", "]", ")", "[", ":", "max_len_dataset", "]", ")", "\n", "FLAML", ".", "append", "(", "FLAML_data", "[", "i", "]", ")", "\n", "KGpipAutoSklearn", ".", "append", "(", "KGpipAutoSklearn_data", "[", "i", "]", ")", "\n", "AutoSklearn", ".", "append", "(", "AutoSklearn_data", "[", "i", "]", ")", "\n", "KGpipFLAML", ".", "append", "(", "KGpipFLAML_data", "[", "i", "]", ")", "\n", "if", "AL_data", ":", "\n", "                ", "AL", ".", "append", "(", "AL_data", "[", "i", "]", ")", "\n", "\n", "", "", "", "return", "categories", ",", "FLAML", ",", "KGpipAutoSklearn", ",", "AutoSklearn", ",", "KGpipFLAML", ",", "AL", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.draw_all_coulmns": [[165, 253], ["pandas.read_excel", "pandas.DataFrame", "pd.DataFrame.Task.tolist", "pd.DataFrame.Dataset.tolist", "pd.DataFrame.FLAML.tolist", "pd.DataFrame.KGpipFLAML.tolist", "pd.DataFrame.KGpipAutoSklearn.tolist", "pd.DataFrame.AutoSklearn.tolist", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "print", "print", "print", "print", "fig6_score_comparison_radar_charts.radar_factory", "matplotlib.subplots", "fig.subplots_adjust", "zip", "axs[].legend", "matplotlib.show", "fig.savefig", "open", "fig6_score_comparison_radar_charts.radar_factory", "ax.set_rgrids", "ax.set_title", "zip", "ax.set_varlabels", "dict", "len", "ax.plot", "sheet_name.replace", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory"], ["", "def", "draw_all_coulmns", "(", "sheet_name", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_excel", "(", "open", "(", "'KGpipResults.xlsx'", ",", "'rb'", ")", ",", "sheet_name", "=", "sheet_name", ")", "\n", "frame", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "Tasks", "=", "frame", ".", "Task", ".", "tolist", "(", ")", "\n", "Datasets", "=", "frame", ".", "Dataset", ".", "tolist", "(", ")", "\n", "\n", "FLAML_data", "=", "frame", ".", "FLAML", ".", "tolist", "(", ")", "\n", "KGpipFLAML_data", "=", "frame", ".", "KGpipFLAML", ".", "tolist", "(", ")", "\n", "KGpipAutoSklearn_data", "=", "frame", ".", "KGpipAutoSklearn", ".", "tolist", "(", ")", "\n", "AutoSklearn_data", "=", "frame", ".", "AutoSklearn", ".", "tolist", "(", ")", "\n", "max_len_dataset", "=", "5", "\n", "\n", "r_categories", ",", "r_FLAML", ",", "r_KGpipAutoSklearn", ",", "r_AutoSklearn", ",", "r_KGpipFLAML", ",", "AL", "=", "get_task_data", "(", "'regression'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", ",", "AL", "=", "get_task_data", "(", "'binary-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", ",", "AL", "=", "get_task_data", "(", "'multi-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "\n", "print", "(", "f'FLAML: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_FLAML):.2f} ({statistics.stdev(bc_FLAML):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_FLAML):.2f} ({statistics.stdev(mc_FLAML):.2f})'", "\n", "f'\\n\\tregression (mean/stdev): {statistics.mean(r_FLAML):.2f} ({statistics.stdev(r_FLAML):.2f})'", ")", "\n", "\n", "print", "(", "f'KGPip+FLAML: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_KGpipFLAML):.2f} ({statistics.stdev(bc_KGpipFLAML):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_KGpipFLAML):.2f} ({statistics.stdev(mc_KGpipFLAML):.2f})'", "\n", "f'\\n\\tregression (mean/stdev): {statistics.mean(r_KGpipFLAML):.2f} ({statistics.stdev(r_KGpipFLAML):.2f})'", ")", "\n", "\n", "print", "(", "f'AutoSklearn: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_AutoSklearn):.2f} ({statistics.stdev(bc_AutoSklearn):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_AutoSklearn):.2f} ({statistics.stdev(mc_AutoSklearn):.2f})'", "\n", "f'\\n\\tregression (mean/stdev): {statistics.mean(r_AutoSklearn):.2f} ({statistics.stdev(r_AutoSklearn):.2f})'", ")", "\n", "\n", "print", "(", "f'KGPip+AutoSklearn: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_KGpipAutoSklearn):.2f} ({statistics.stdev(bc_KGpipAutoSklearn):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_KGpipAutoSklearn):.2f} ({statistics.stdev(mc_KGpipAutoSklearn):.2f})'", "\n", "f'\\n\\tregression (mean/stdev): {statistics.mean(r_KGpipAutoSklearn):.2f} ({statistics.stdev(r_KGpipAutoSklearn):.2f})'", ")", "\n", "\n", "data", "=", "[", "\n", "(", "'Binary Classification'", ",", "[", "\n", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", "\n", "]", ")", ",", "\n", "(", "'Multi-class Classification'", ",", "[", "\n", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", "\n", "]", ")", ",", "\n", "(", "'Regression'", ",", "[", "\n", "r_categories", ",", "r_FLAML", ",", "r_KGpipAutoSklearn", ",", "r_AutoSklearn", ",", "r_KGpipFLAML", "\n", "]", ")", "\n", "\n", "]", "\n", "# font = {'family': 'normal',", "\n", "#         'weight': 'bold',", "\n", "#         'size': 14}", "\n", "#", "\n", "# matplotlib.rc('font', **font)", "\n", "# plt.style.use('ggplot')", "\n", "N", "=", "9", "\n", "theta", "=", "radar_factory", "(", "N", ",", "frame", "=", "'polygon'", ")", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "16", ",", "6", ")", ",", "nrows", "=", "1", ",", "ncols", "=", "3", ",", "subplot_kw", "=", "dict", "(", "projection", "=", "'radar'", ")", ")", "\n", "# fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "0.3", ",", "hspace", "=", "0.", ",", "top", "=", "0.85", ",", "bottom", "=", "0.05", ")", "\n", "\n", "colors", "=", "[", "'b'", ",", "'r'", ",", "'g'", ",", "'m'", "]", "# , 'y']", "\n", "# Plot the four cases from the example data on separate axes", "\n", "for", "ax", ",", "(", "title", ",", "case_data", ")", "in", "zip", "(", "axs", ".", "flat", ",", "data", ")", ":", "\n", "        ", "categories", ",", "FLAML", ",", "KGpipAutoSklearn", ",", "AutoSklearn", ",", "KGpipFLAML", "=", "case_data", "\n", "theta", "=", "radar_factory", "(", "len", "(", "categories", ")", ",", "frame", "=", "'polygon'", ")", "\n", "ax", ".", "set_rgrids", "(", "[", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ")", "\n", "ax", ".", "set_title", "(", "title", ",", "weight", "=", "'bold'", ",", "size", "=", "'medium'", ",", "position", "=", "(", "0.5", ",", "1.1", ")", ",", "\n", "horizontalalignment", "=", "'center'", ",", "verticalalignment", "=", "'center'", ")", "\n", "for", "d", ",", "color", "in", "zip", "(", "case_data", "[", "1", ":", "]", ",", "colors", ")", ":", "\n", "            ", "ax", ".", "plot", "(", "theta", ",", "d", ",", "color", "=", "color", ")", "\n", "# ax.fill(theta, d, facecolor=color, alpha=0.25)", "\n", "", "ax", ".", "set_varlabels", "(", "categories", ")", "\n", "# label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(categories))", "\n", "# lines, labels = plt.thetagrids(np.degrees(label_loc), labels=categories)", "\n", "\n", "# add legend relative to top-left plot", "\n", "", "labels", "=", "(", "'FLAML'", ",", "'KGpipAutoSklearn'", ",", "'AutoSklearn'", ",", "'KGpipFLAML'", ")", "\n", "legend", "=", "axs", "[", "0", "]", ".", "legend", "(", "labels", ",", "loc", "=", "(", "0.8", ",", "1.2", ")", ",", "\n", "labelspacing", "=", "0.1", ",", "fontsize", "=", "'large'", ",", "mode", "=", "'extend'", ",", "borderaxespad", "=", "0", ",", "ncol", "=", "8", ")", "\n", "\n", "# fig.text(0.5, 0.965, '1 Hour time limit',", "\n", "#          horizontalalignment='center', color='black', weight='bold',", "\n", "#          size='large')", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "sheet_name", ".", "replace", "(", "' '", ",", "'_'", ")", "+", "'.pdf'", ",", "dpi", "=", "fig", ".", "dpi", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_sheet_data": [[255, 279], ["pandas.read_excel", "pandas.DataFrame", "pd.DataFrame.Task.tolist", "pd.DataFrame.Dataset.tolist", "pd.DataFrame.FLAML.tolist", "pd.DataFrame.KGpipFLAML.tolist", "pd.DataFrame.KGpipAutoSklearn.tolist", "pd.DataFrame.AutoSklearn.tolist", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "open"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data"], ["", "def", "get_sheet_data", "(", "sheet_name", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_excel", "(", "open", "(", "'KGpipResults.xlsx'", ",", "'rb'", ")", ",", "sheet_name", "=", "sheet_name", ")", "\n", "frame", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "Tasks", "=", "frame", ".", "Task", ".", "tolist", "(", ")", "\n", "Datasets", "=", "frame", ".", "Dataset", ".", "tolist", "(", ")", "\n", "\n", "FLAML_data", "=", "frame", ".", "FLAML", ".", "tolist", "(", ")", "\n", "KGpipFLAML_data", "=", "frame", ".", "KGpipFLAML", ".", "tolist", "(", ")", "\n", "KGpipAutoSklearn_data", "=", "frame", ".", "KGpipAutoSklearn", ".", "tolist", "(", ")", "\n", "AutoSklearn_data", "=", "frame", ".", "AutoSklearn", ".", "tolist", "(", ")", "\n", "max_len_dataset", "=", "5", "\n", "\n", "r_categories", ",", "r_FLAML", ",", "r_KGpipAutoSklearn", ",", "r_AutoSklearn", ",", "r_KGpipFLAML", "=", "get_task_data", "(", "'regression'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", "=", "get_task_data", "(", "'binary-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", "=", "get_task_data", "(", "'multi-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ")", "\n", "return", "r_categories", ",", "r_FLAML", ",", "r_KGpipAutoSklearn", ",", "r_AutoSklearn", ",", "r_KGpipFLAML", ",", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", ",", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.draw_all_coulmns_with_AL": [[280, 369], ["pandas.read_excel", "pandas.DataFrame", "pd.DataFrame.Task.tolist", "pd.DataFrame.Dataset.tolist", "pd.DataFrame.FLAML.tolist", "pd.DataFrame.KGpipFLAML.tolist", "pd.DataFrame.KGpipAutoSklearn.tolist", "pd.DataFrame.AutoSklearn.tolist", "pd.DataFrame.AL.tolist", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "fig6_score_comparison_radar_charts.get_task_data", "print", "print", "print", "print", "print", "fig6_score_comparison_radar_charts.radar_factory", "matplotlib.subplots", "fig.subplots_adjust", "zip", "axs[].legend", "matplotlib.show", "fig.savefig", "open", "fig6_score_comparison_radar_charts.radar_factory", "ax.set_rgrids", "ax.set_title", "zip", "ax.set_varlabels", "dict", "len", "ax.plot", "sheet_name.replace", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev", "statistics.mean", "statistics.stdev"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_task_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory"], ["", "def", "draw_all_coulmns_with_AL", "(", "sheet_name", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_excel", "(", "open", "(", "'KGpipResults.xlsx'", ",", "'rb'", ")", ",", "sheet_name", "=", "sheet_name", ")", "\n", "frame", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "Tasks", "=", "frame", ".", "Task", ".", "tolist", "(", ")", "\n", "Datasets", "=", "frame", ".", "Dataset", ".", "tolist", "(", ")", "\n", "\n", "FLAML_data", "=", "frame", ".", "FLAML", ".", "tolist", "(", ")", "\n", "KGpipFLAML_data", "=", "frame", ".", "KGpipFLAML", ".", "tolist", "(", ")", "\n", "KGpipAutoSklearn_data", "=", "frame", ".", "KGpipAutoSklearn", ".", "tolist", "(", ")", "\n", "AutoSklearn_data", "=", "frame", ".", "AutoSklearn", ".", "tolist", "(", ")", "\n", "max_len_dataset", "=", "5", "\n", "AL_data", "=", "frame", ".", "AL", ".", "tolist", "(", ")", "\n", "\n", "r_categories", ",", "r_FLAML", ",", "r_KGpipAutoSklearn", ",", "r_AutoSklearn", ",", "r_KGpipFLAML", ",", "r_AL", "=", "get_task_data", "(", "'regression'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ",", "AL_data", ")", "\n", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", ",", "bc_AL", "=", "get_task_data", "(", "'binary-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ",", "AL_data", ")", "\n", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", ",", "mc_AL", "=", "get_task_data", "(", "'multi-classification'", ",", "Tasks", ",", "Datasets", ",", "FLAML_data", ",", "KGpipAutoSklearn_data", ",", "AutoSklearn_data", ",", "\n", "KGpipFLAML_data", ",", "AL_data", ")", "\n", "\n", "print", "(", "f'FLAML: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_FLAML):.2f} ({statistics.stdev(bc_FLAML):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_FLAML):.2f} ({statistics.stdev(mc_FLAML):.2f})'", ")", "\n", "\n", "print", "(", "f'KGPip+FLAML: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_KGpipFLAML):.2f} ({statistics.stdev(bc_KGpipFLAML):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_KGpipFLAML):.2f} ({statistics.stdev(mc_KGpipFLAML):.2f})'", ")", "\n", "\n", "print", "(", "f'AutoSklearn: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_AutoSklearn):.2f} ({statistics.stdev(bc_AutoSklearn):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_AutoSklearn):.2f} ({statistics.stdev(mc_AutoSklearn):.2f})'", ")", "\n", "\n", "print", "(", "f'KGPip+AutoSklearn: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_KGpipAutoSklearn):.2f} ({statistics.stdev(bc_KGpipAutoSklearn):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_KGpipAutoSklearn):.2f} ({statistics.stdev(mc_KGpipAutoSklearn):.2f})'", ")", "\n", "\n", "print", "(", "f'AL: \\n\\tbinary classification (mean/stdev): {statistics.mean(bc_AL):.2f} ({statistics.stdev(bc_AL):.2f})'", "\n", "f'\\n\\tmulti-class classification (mean/stdev): {statistics.mean(mc_AL):.2f} ({statistics.stdev(mc_AL):.2f})'", ")", "\n", "\n", "\n", "data", "=", "[", "\n", "(", "'Binary Classification'", ",", "[", "\n", "bc_categories", ",", "bc_FLAML", ",", "bc_KGpipAutoSklearn", ",", "bc_AutoSklearn", ",", "bc_KGpipFLAML", ",", "bc_AL", "\n", "]", ")", ",", "\n", "(", "'Multi-class Classification'", ",", "[", "\n", "mc_categories", ",", "mc_FLAML", ",", "mc_KGpipAutoSklearn", ",", "mc_AutoSklearn", ",", "mc_KGpipFLAML", ",", "mc_AL", "\n", "]", ")", ",", "\n", "# ('Regression', [", "\n", "#     r_categories, r_FLAML, r_KGpipAutoSklearn, r_AutoSklearn, r_KGpipFLAML, r_AL", "\n", "# ])", "\n", "\n", "]", "\n", "# font = {'family': 'normal',", "\n", "#         'weight': 'bold',", "\n", "#         'size': 14}", "\n", "#", "\n", "# matplotlib.rc('font', **font)", "\n", "# plt.style.use('ggplot')", "\n", "N", "=", "9", "\n", "theta", "=", "radar_factory", "(", "N", ",", "frame", "=", "'polygon'", ")", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "10", ",", "7", ")", ",", "nrows", "=", "1", ",", "ncols", "=", "2", ",", "subplot_kw", "=", "dict", "(", "projection", "=", "'radar'", ")", ")", "\n", "# fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "0.3", ",", "hspace", "=", "0.", ",", "top", "=", "0.85", ",", "bottom", "=", "0.05", ")", "\n", "\n", "colors", "=", "[", "'b'", ",", "'r'", ",", "'g'", ",", "'m'", ",", "'k'", "]", "\n", "# Plot the four cases from the example data on separate axes", "\n", "for", "ax", ",", "(", "title", ",", "case_data", ")", "in", "zip", "(", "axs", ".", "flat", ",", "data", ")", ":", "\n", "# categories, FLAML, KGpipAutoSklearn, AutoSklearn, KGpipFLAML = case_data", "\n", "        ", "theta", "=", "radar_factory", "(", "len", "(", "case_data", "[", "0", "]", ")", ",", "frame", "=", "'polygon'", ")", "\n", "ax", ".", "set_rgrids", "(", "[", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ")", "\n", "ax", ".", "set_title", "(", "title", ",", "weight", "=", "'bold'", ",", "size", "=", "'medium'", ",", "position", "=", "(", "0.5", ",", "1.1", ")", ",", "\n", "horizontalalignment", "=", "'center'", ",", "verticalalignment", "=", "'center'", ")", "\n", "for", "d", ",", "color", "in", "zip", "(", "case_data", "[", "1", ":", "]", ",", "colors", ")", ":", "\n", "            ", "ax", ".", "plot", "(", "theta", ",", "d", ",", "color", "=", "color", ")", "\n", "# ax.fill(theta, d, facecolor=color, alpha=0.25)", "\n", "", "ax", ".", "set_varlabels", "(", "case_data", "[", "0", "]", ")", "\n", "# label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(categories))", "\n", "# lines, labels = plt.thetagrids(np.degrees(label_loc), labels=categories)", "\n", "\n", "# add legend relative to top-left plot", "\n", "", "labels", "=", "(", "'FLAML'", ",", "'KGpipAutoSklearn'", ",", "'AutoSklearn'", ",", "'KGpipFLAML'", ",", "'AL'", ")", "\n", "legend", "=", "axs", "[", "0", "]", ".", "legend", "(", "labels", ",", "loc", "=", "(", "0.0", ",", "1.2", ")", ",", "\n", "labelspacing", "=", "0.1", ",", "fontsize", "=", "'large'", ",", "mode", "=", "'extend'", ",", "borderaxespad", "=", "0", ",", "ncol", "=", "8", ")", "\n", "\n", "# fig.text(0.5, 0.965, '1 Hour time limit',", "\n", "#          horizontalalignment='center', color='black', weight='bold',", "\n", "#          size='large')", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "sheet_name", ".", "replace", "(", "' '", ",", "'_'", ")", "+", "'.pdf'", ",", "dpi", "=", "fig", ".", "dpi", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.draw_variable_graphs_fig": [[372, 449], ["fig6_score_comparison_radar_charts.get_sheet_data", "fig6_score_comparison_radar_charts.get_sheet_data", "fig6_score_comparison_radar_charts.get_sheet_data", "fig6_score_comparison_radar_charts.radar_factory", "matplotlib.subplots", "fig.subplots_adjust", "zip", "axs[].legend", "matplotlib.show", "fig.savefig", "fig6_score_comparison_radar_charts.radar_factory", "ax.set_rgrids", "ax.set_title", "zip", "ax.set_varlabels", "dict", "len", "ax.plot"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_sheet_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_sheet_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.get_sheet_data", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_figures.fig6_score_comparison_radar_charts.radar_factory"], ["", "def", "draw_variable_graphs_fig", "(", "sysname", ")", ":", "\n", "# draw_variable_graphs_fig(sheet_name= '30m_r1_5graphs')", "\n", "# draw_variable_graphs_fig(sheet_name = '30m_r1_3graphs1')", "\n", "# draw_variable_graphs_fig(sheet_name='avg. 30m')", "\n", "\n", "\n", "    ", "g3_r_categories", ",", "_", ",", "g3_r_KGpipAutoSklearn", ",", "_", ",", "g3_r_KGpipFLAML", ",", "g3_bc_categories", ",", "_", ",", "g3_bc_KGpipAutoSklearn", ",", "_", ",", "g3_bc_KGpipFLAML", ",", "g3_mc_categories", ",", "_", ",", "g3_mc_KGpipAutoSklearn", ",", "_", ",", "g3_mc_KGpipFLAML", "=", "get_sheet_data", "(", "'30m_r1_3graphs_extra'", ")", "\n", "\n", "g5_r_categories", ",", "_", ",", "g5_r_KGpipAutoSklearn", ",", "_", ",", "g5_r_KGpipFLAML", ",", "g5_bc_categories", ",", "_", ",", "g5_bc_KGpipAutoSklearn", ",", "_", ",", "g5_bc_KGpipFLAML", ",", "g5_mc_categories", ",", "_", ",", "g5_mc_KGpipAutoSklearn", ",", "_", ",", "g5_mc_KGpipFLAML", "=", "get_sheet_data", "(", "'30m_r1_5graphs_extra'", ")", "\n", "\n", "g7_r_categories", ",", "_", ",", "g7_r_KGpipAutoSklearn", ",", "_", ",", "g7_r_KGpipFLAML", ",", "g7_bc_categories", ",", "_", ",", "g7_bc_KGpipAutoSklearn", ",", "_", ",", "g7_bc_KGpipFLAML", ",", "g7_mc_categories", ",", "_", ",", "g7_mc_KGpipAutoSklearn", ",", "_", ",", "g7_mc_KGpipFLAML", "=", "get_sheet_data", "(", "'30m_r1_extra'", ")", "\n", "\n", "if", "sysname", "==", "'KGpipFLAML'", ":", "\n", "        ", "data", "=", "[", "\n", "(", "'Binary Classification'", ",", "[", "\n", "g5_bc_categories", ",", "g3_bc_KGpipFLAML", ",", "g5_bc_KGpipFLAML", ",", "g7_bc_KGpipFLAML", "\n", "]", ")", ",", "\n", "(", "'Multi-class Classification'", ",", "[", "\n", "g5_mc_categories", ",", "g3_mc_KGpipFLAML", ",", "g5_mc_KGpipFLAML", ",", "g7_mc_KGpipFLAML", "\n", "]", ")", ",", "\n", "(", "'Regression'", ",", "[", "# categories are fixed", "\n", "g5_r_categories", ",", "g3_r_KGpipFLAML", ",", "g5_r_KGpipFLAML", ",", "g7_r_KGpipFLAML", "\n", "]", ")", ",", "\n", "]", "\n", "labels", "=", "(", "'KGpipFLAML (3 graphs)'", ",", "'KGpipFLAML (5 graphs)'", ",", "'KGpipFLAML (7 graphs)'", ")", "\n", "", "elif", "sysname", "==", "'KGpipAutoSklearn'", ":", "\n", "        ", "data", "=", "[", "\n", "(", "'Binary Classification'", ",", "[", "\n", "g5_bc_categories", ",", "g3_bc_KGpipAutoSklearn", ",", "g5_bc_KGpipAutoSklearn", ",", "g7_bc_KGpipAutoSklearn", "\n", "]", ")", ",", "\n", "(", "'Multi-class Classification'", ",", "[", "\n", "g5_mc_categories", ",", "g3_mc_KGpipAutoSklearn", ",", "g5_mc_KGpipAutoSklearn", ",", "g7_mc_KGpipAutoSklearn", "\n", "]", ")", ",", "\n", "(", "'Regression'", ",", "[", "# categories are fixed", "\n", "g5_r_categories", ",", "g3_r_KGpipAutoSklearn", ",", "g5_r_KGpipAutoSklearn", ",", "g7_r_KGpipAutoSklearn", "\n", "]", ")", ",", "\n", "]", "\n", "labels", "=", "(", "'KGpipAutoSklearn (3 graphs)'", ",", "'KGpipAutoSklearn (5 graphs)'", ",", "'KGpipAutoSklearn (7 graphs)'", ")", "\n", "\n", "# plt.style.use('ggplot')", "\n", "", "N", "=", "9", "\n", "theta", "=", "radar_factory", "(", "N", ",", "frame", "=", "'polygon'", ")", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "16", ",", "6", ")", ",", "nrows", "=", "1", ",", "ncols", "=", "3", ",", "subplot_kw", "=", "dict", "(", "projection", "=", "'radar'", ")", ")", "\n", "fig", ".", "subplots_adjust", "(", "wspace", "=", "0.3", ",", "hspace", "=", "0.3", ",", "top", "=", "0.85", ",", "bottom", "=", "0.05", ")", "\n", "\n", "colors", "=", "[", "'k'", ",", "'r'", ",", "'m'", "]", "# , 'y']", "\n", "# Plot the four cases from the example data on separate axes", "\n", "for", "ax", ",", "(", "title", ",", "case_data", ")", "in", "zip", "(", "axs", ".", "flat", ",", "data", ")", ":", "\n", "        ", "categories", "=", "case_data", "[", "0", "]", "\n", "theta", "=", "radar_factory", "(", "len", "(", "categories", ")", ",", "frame", "=", "'polygon'", ")", "\n", "ax", ".", "set_rgrids", "(", "[", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ")", "\n", "ax", ".", "set_title", "(", "title", ",", "weight", "=", "'bold'", ",", "size", "=", "'medium'", ",", "position", "=", "(", "0.5", ",", "1.1", ")", ",", "\n", "horizontalalignment", "=", "'center'", ",", "verticalalignment", "=", "'center'", ")", "\n", "for", "d", ",", "color", "in", "zip", "(", "case_data", "[", "1", ":", "]", ",", "colors", ")", ":", "\n", "            ", "ax", ".", "plot", "(", "theta", ",", "d", ",", "color", "=", "color", ")", "\n", "# ax.fill(theta, d, facecolor=color, alpha=0.25)", "\n", "", "ax", ".", "set_varlabels", "(", "categories", ")", "\n", "# label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(categories))", "\n", "# lines, labels = plt.thetagrids(np.degrees(label_loc), labels=categories)", "\n", "\n", "# add legend relative to top-left plot", "\n", "# legend = axs[0].legend(labels, loc=(0.2, 1.2), labelspacing=0.1, fontsize='large', mode='extend', borderaxespad=0, ncol=8)", "\n", "", "legend", "=", "axs", "[", "0", "]", ".", "legend", "(", "labels", ",", "loc", "=", "(", "0.45", ",", "1.2", ")", ",", "labelspacing", "=", "0.1", ",", "fontsize", "=", "'large'", ",", "mode", "=", "'extend'", ",", "borderaxespad", "=", "0", ",", "ncol", "=", "8", ")", "\n", "\n", "\n", "# fig.text(0.5, 0.965, '1 Hour time limit',", "\n", "#          horizontalalignment='center', color='black', weight='bold',", "\n", "#          size='large')", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "sysname", "+", "'_var_graphs_30m.pdf'", ",", "dpi", "=", "fig", ".", "dpi", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_tables.dataset_statistics_and_info.is_text_column": [[10, 35], ["df_column.values.tolist", "len", "isinstance", "df_column.unique", "len"], "function", ["None"], ["def", "is_text_column", "(", "df_column", ")", ":", "\n", "    ", "\"\"\"\n    Check if the dataframe column is a text (as opposed to short strings).\n    Simple heuristic: check if it has 20+ unique values and 30%+ of the column contains 2+ space characters.\n    TODO: this will not work with timestamp columns that contain spaces.\n    \"\"\"", "\n", "\n", "# to speed up the search in case of string column, check how many unique values", "\n", "if", "df_column", ".", "dtype", "!=", "object", "or", "len", "(", "df_column", ".", "unique", "(", ")", ")", "<", "20", ":", "\n", "        ", "return", "False", "\n", "\n", "", "num_text_rows", "=", "0", "\n", "for", "value", "in", "df_column", ".", "values", ".", "tolist", "(", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "            ", "continue", "\n", "", "space_count", "=", "0", "\n", "for", "character", "in", "value", ":", "\n", "            ", "if", "character", "==", "' '", ":", "\n", "                ", "space_count", "+=", "1", "\n", "", "if", "space_count", ">", "1", ":", "\n", "                ", "num_text_rows", "+=", "1", "\n", "break", "\n", "", "", "if", "num_text_rows", ">", "0.3", "*", "len", "(", "df_column", ")", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_tables.dataset_statistics_and_info.main": [[38, 79], ["pandas.read_csv", "tqdm.tqdm", "pandas.DataFrame", "df.apply.Dataset.str.lower", "df.apply.sort_values", "list", "df.apply.drop", "print", "os.path.join", "pd.read_csv.itertuples", "round", "pandas.read_csv", "df.apply.replace", "df.apply.apply", "len", "len", "rows.append", "range", "len", "df.apply.drop", "len", "os.path.getsize", "y.value_counts", "dataset_statistics_and_info.is_text_column", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.paper_tables.dataset_statistics_and_info.is_text_column"], ["", "def", "main", "(", ")", ":", "\n", "    ", "benchmark_info", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "KGPIP_PATH", ",", "'benchmark_datasets/benchmark_datasets_info.csv'", ")", ")", "\n", "rows", "=", "[", "]", "\n", "for", "row", "in", "tqdm", "(", "benchmark_info", ".", "itertuples", "(", "index", "=", "False", ")", ",", "total", "=", "len", "(", "benchmark_info", ")", ")", ":", "\n", "        ", "file", "=", "f'{KGPIP_PATH}/{row.base_dir}/{row.name}/{row.name}.csv'", "\n", "size", "=", "round", "(", "os", ".", "path", ".", "getsize", "(", "file", ")", "/", "1024", "**", "2", ",", "1", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "file", ",", "low_memory", "=", "False", ")", "\n", "df", ",", "y", "=", "df", ".", "drop", "(", "row", ".", "target", ",", "axis", "=", "1", ")", ",", "df", "[", "row", ".", "target", "]", "\n", "df", "=", "df", ".", "replace", "(", "'?'", ",", "np", ".", "nan", ")", "\n", "df", "=", "df", ".", "apply", "(", "pd", ".", "to_numeric", ",", "errors", "=", "'ignore'", ")", "\n", "\n", "nrows", "=", "len", "(", "df", ")", "\n", "ncols", "=", "len", "(", "df", ".", "columns", ")", "\n", "nclasses", "=", "len", "(", "y", ".", "value_counts", "(", ")", ")", "if", "not", "row", ".", "is_regression", "else", "'-'", "\n", "\n", "task", "=", "row", ".", "task", "\n", "source", "=", "row", ".", "source", "\n", "papers", "=", "row", ".", "papers", "\n", "sort_priority", "=", "row", ".", "sort_priority", "\n", "\n", "nnumerical", "=", "ncategorical", "=", "ntextual", "=", "0", "\n", "for", "col", "in", "df", ".", "columns", ":", "\n", "            ", "if", "df", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'iufc'", ":", "\n", "                ", "nnumerical", "+=", "1", "\n", "", "elif", "is_text_column", "(", "df", "[", "col", "]", ")", ":", "\n", "                ", "ntextual", "+=", "1", "\n", "", "elif", "df", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'bO'", ":", "\n", "                ", "ncategorical", "+=", "1", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unexpected column type: dataset:'", ",", "row", ".", "name", ",", "'Column:'", ",", "col", ",", "'Type:'", ",", "df", "[", "col", "]", ".", "dtype", ")", "\n", "\n", "", "", "rows", ".", "append", "(", "[", "row", ".", "name", ",", "nrows", ",", "ncols", ",", "nclasses", ",", "nnumerical", ",", "ncategorical", ",", "ntextual", ",", "size", ",", "task", ",", "source", ",", "papers", ",", "sort_priority", "]", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "rows", ",", "columns", "=", "[", "'Dataset'", ",", "'Rows'", ",", "'Columns'", ",", "'Classes'", ",", "'Numerical'", ",", "'Categorical'", ",", "'Textual'", ",", "\n", "'Size (MB)'", ",", "'Task'", ",", "'Source'", ",", "'Papers'", ",", "'priority'", "]", ")", "\n", "\n", "df", "[", "'dataset_lower'", "]", "=", "df", ".", "Dataset", ".", "str", ".", "lower", "(", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "[", "'priority'", ",", "'Task'", ",", "'dataset_lower'", "]", ")", "\n", "df", ".", "index", "=", "list", "(", "range", "(", "1", ",", "len", "(", "df", ")", "+", "1", ")", ")", "\n", "df", "=", "df", ".", "drop", "(", "[", "'dataset_lower'", ",", "'priority'", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.misc.tsne_plot.main": [[13, 142], ["pandas.read_pickle", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "set", "sklearn.manifold.TSNE", "sklearn.manifold.TSNE.fit_transform", "matplotlib.subplots", "ax.scatter", "enumerate", "ax.legend", "ax.add_artist", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.show", "datasets_clusters.values", "numpy.array", "elem_class.append", "elem_class.append", "embeds[].keys", "plotted_embeddings.append", "len", "ax.annotate", "ax.annotate", "list", "list().index", "list().index", "embeds[].keys", "plotted_embeddings.append", "txt.split", "ax.scatter.legend_elements", "txt.split", "list", "list"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "reg", "=", "[", "'jiashenliu.515k-hotel-reviews-data-in-europe'", ",", "\n", "'paolocons.another-fiat-500-dataset-1538-rows'", ",", "\n", "'danielkyrka.bmw-pricing-challenge'", ",", "\n", "'antfarol.car-sale-advertisements'", ",", "\n", "'gagandeep16.car-sales'", ",", "\n", "'austinreese.craigslist-carstrucks-data'", ",", "\n", "'jpallard.google-store-ecommerce-data-fake-retail-data'", ",", "\n", "'roccoli.gpx-hike-tracks'", ",", "\n", "'rohitmathur100.happiness'", ",", "\n", "'jmmvutu.summer-products-and-sales-in-ecommerce-wish'", ",", "\n", "'nicapotato.womens-ecommerce-clothing-reviews'", ",", "\n", "'unsdsn.world-happiness'", ",", "\n", "'home-depot-product-search-relevance'", ",", "\n", "'liberty-mutual-group-property-inspection-prediction'", ",", "\n", "'machinery-tube-pricing'", ",", "\n", "'rossmann-store-sales'", "]", "\n", "\n", "cls", "=", "[", "'barelydedicated.bank-customer-churn-modeling'", ",", "\n", "'abineshkumark.carsdata'", ",", "\n", "'mathchi.churn-for-bank-customers'", ",", "\n", "'sakshigoyal7.credit-card-customers'", ",", "\n", "'christianlillelund.csgo-round-winner-classification'", ",", "\n", "'uciml.default-of-credit-card-clients-dataset'", ",", "\n", "'futurecorporation.epitope-prediction'", ",", "\n", "'gdaley.hkracing'", ",", "\n", "'asad1m9a9h6mood.news-articles'", ",", "\n", "'septa.on-time-performance'", ",", "\n", "'rounakbanik.pokemon'", ",", "\n", "'terminus7.pokemon-challenge'", ",", "\n", "'aaron7sun.stocknews'", ",", "\n", "'rajeevw.ufcdata'", ",", "\n", "'sobhanmoosavi.us-accidents'", ",", "\n", "'bnp-paribas-cardif-claims-management'", ",", "\n", "'crowdflower-search-relevance'", ",", "\n", "'flavours-of-physics'", ",", "\n", "'predict-west-nile-virus'", ",", "\n", "'santander-customer-satisfaction'", "]", "\n", "datasets_clusters", "=", "{", "\n", "'unsdsn.world-happiness'", ":", "'happiness'", ",", "\n", "'rohitmathur100.happiness'", ":", "'happiness'", ",", "\n", "###########", "\n", "'sakshigoyal7.credit-card-customers'", ":", "'finance'", ",", "\n", "'jpallard.google-store-ecommerce-data-fake-retail-data'", ":", "'finance'", ",", "\n", "'mathchi.churn-for-bank-customers'", ":", "'finance'", ",", "\n", "'barelydedicated.bank-customer-churn-model'", ":", "'finance'", ",", "\n", "'rossmann-store-sales'", ":", "'finance'", ",", "\n", "'uciml.default-of-credit-card-clients-dataset'", ":", "'finance'", ",", "\n", "'barelydedicated.bank-customer-churn-modeling'", ":", "'finance'", ",", "\n", "'santander-customer-satisfaction'", ":", "'finance'", ",", "\n", "###########", "\n", "'asad1m9a9h6mood.news-articles'", ":", "'news'", ",", "\n", "'aaron7sun.stocknews'", ":", "'news'", ",", "\n", "###########", "\n", "'machinery-tube-pricing'", ":", "'sales'", ",", "\n", "'danielkyrka.bmw-pricing-challenge'", ":", "'sales'", ",", "\n", "\n", "###########", "\n", "'jiashenliu.515k-hotel-reviews-data-in-europe'", ":", "'reviews'", ",", "\n", "'nicapotato.womens-ecommerce-clothing-reviews'", ":", "'reviews'", ",", "\n", "'jmmvutu.summer-products-and-sales-in-ecommerce-wish'", ":", "'reviews'", ",", "\n", "'crowdflower-search-relevance'", ":", "'reviews'", ",", "\n", "'home-depot-product-search-relevance'", ":", "'reviews'", ",", "\n", "###########", "\n", "'abineshkumark.carsdata'", ":", "'cars'", ",", "\n", "'gagandeep16.car-sales'", ":", "'cars'", ",", "\n", "'paolocons.another-fiat-500-dataset-1538-rows'", ":", "'cars'", ",", "\n", "'antfarol.car-sale-advertisements'", ":", "'cars'", ",", "\n", "################", "\n", "'terminus7.pokemon-challenge'", ":", "'games'", ",", "\n", "'rounakbanik.pokemon'", ":", "'games'", ",", "\n", "'christianlillelund.csgo-round-winner-classification'", ":", "'games'", ",", "\n", "'gdaley.hkracing'", ":", "'games'", ",", "\n", "################", "\n", "'roccoli.gpx-hike-tracks'", ":", "'other'", ",", "\n", "'septa.on-time-performance'", ":", "'other'", ",", "\n", "}", "\n", "\n", "embeds", "=", "pd", ".", "read_pickle", "(", "'embeddings/al_training_plus_11k_datasets_embeddings.pickle'", ")", "\n", "ds", "=", "reg", "+", "cls", "\n", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "2", "}", ")", "\n", "plt", ".", "rcParams", "[", "\"figure.figsize\"", "]", "=", "(", "2.5", ",", "3", ")", "\n", "\n", "######################assign classes###################", "\n", "clusters", "=", "set", "(", "datasets_clusters", ".", "values", "(", ")", ")", "\n", "elem_class", "=", "[", "]", "\n", "\n", "for", "elem", "in", "ds", ":", "\n", "        ", "if", "elem", "in", "datasets_clusters", ":", "\n", "            ", "elem_class", ".", "append", "(", "list", "(", "clusters", ")", ".", "index", "(", "datasets_clusters", "[", "elem", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "elem_class", ".", "append", "(", "list", "(", "clusters", ")", ".", "index", "(", "'other'", ")", ")", "\n", "\n", "########################################################3", "\n", "", "", "plotted_embeddings", "=", "[", "]", "\n", "for", "i", "in", "ds", ":", "\n", "        ", "if", "i", "in", "embeds", "[", "'regression'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "plotted_embeddings", ".", "append", "(", "embeds", "[", "'regression'", "]", "[", "i", "]", "[", "'embedding'", "]", ")", "\n", "", "elif", "i", "in", "embeds", "[", "'classification'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "plotted_embeddings", ".", "append", "(", "embeds", "[", "'classification'", "]", "[", "i", "]", "[", "'embedding'", "]", ")", "\n", "\n", "# plt.scatter(features[0], features[1], alpha=0.2,", "\n", "#             s=100*features[3], c=iris.target, cmap='viridis')", "\n", "# plt.xlabel(iris.feature_names[0])", "\n", "# plt.ylabel(iris.feature_names[1]);", "\n", "\n", "", "", "tsne", "=", "TSNE", "(", "random_state", "=", "10", ",", "perplexity", "=", "5", ")", "\n", "X_tsne", "=", "tsne", ".", "fit_transform", "(", "np", ".", "array", "(", "plotted_embeddings", ")", ")", "\n", "# print(X_tsne[:, 0], X_tsne[:, 1])", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "# cmap = plt.get_cmap('viridis')", "\n", "scatt", "=", "ax", ".", "scatter", "(", "X_tsne", "[", ":", ",", "0", "]", ",", "X_tsne", "[", ":", ",", "1", "]", ",", "c", "=", "elem_class", ",", "cmap", "=", "'tab20'", ")", "\n", "for", "i", ",", "txt", "in", "enumerate", "(", "ds", ")", ":", "\n", "        ", "if", "len", "(", "txt", ".", "split", "(", "'.'", ")", ")", ">", "1", ":", "\n", "            ", "ax", ".", "annotate", "(", "txt", ".", "split", "(", "'.'", ")", "[", "1", "]", ",", "(", "X_tsne", "[", ":", ",", "0", "]", "[", "i", "]", ",", "X_tsne", "[", ":", ",", "1", "]", "[", "i", "]", ")", ",", "ha", "=", "'center'", ")", "\n", "", "else", ":", "\n", "            ", "ax", ".", "annotate", "(", "txt", ",", "(", "X_tsne", "[", ":", ",", "0", "]", "[", "i", "]", ",", "X_tsne", "[", ":", ",", "1", "]", "[", "i", "]", "-", "6", ")", ",", "ha", "=", "'center'", ")", "\n", "#         ax.annotate(txt, (X_tsne[:, 0][i], X_tsne[:, 1][i]),ha='center')", "\n", "\n", "", "", "legend1", "=", "ax", ".", "legend", "(", "handles", "=", "scatt", ".", "legend_elements", "(", ")", "[", "0", "]", ",", "\n", "loc", "=", "\"center left\"", ",", "labels", "=", "list", "(", "clusters", ")", ",", "prop", "=", "{", "'size'", ":", "4", "}", ")", "\n", "ax", ".", "add_artist", "(", "legend1", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "# adjust_text(txt, only_move={'points':'y', 'texts':'y'}, arrowprops=dict(arrowstyle=\"->\", color='r', lw=0.5))", "\n", "plt", ".", "savefig", "(", "'fig.pdf'", ",", "dpi", "=", "1000", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.misc.store_embeddings.main": [[15, 52], ["pandas.read_csv", "df.dropna.dropna", "tqdm.tqdm", "df.dropna.iterrows", "pandas.read_csv", "dataset_embedding_model.api.embed_dataset", "open", "pickle.dump", "len", "os.path.exists", "print", "dataset.sample.drop", "dataset[].fillna", "len", "dataset.sample.sample", "dataset[].mean", "dataset[].mode"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.dataset_embedding_model.api.embed_dataset"], ["def", "main", "(", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "'../../training/training_set_info.csv'", ")", "\n", "df", "=", "df", "[", "df", ".", "Regression", "|", "df", ".", "Classification", "]", "\n", "df", "=", "df", ".", "dropna", "(", "subset", "=", "[", "'Target'", "]", ")", "\n", "\n", "embeds", "=", "{", "'regression'", ":", "{", "}", ",", "'classification'", ":", "{", "}", "}", "\n", "\n", "for", "_", ",", "row", "in", "tqdm", "(", "df", ".", "iterrows", "(", ")", ",", "total", "=", "len", "(", "df", ")", ",", "disable", "=", "False", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "f'kaggle_datasets/{row.Name}/{row.Name}.csv'", ")", ":", "\n", "            ", "print", "(", "'Skipping dataset:'", ",", "row", ".", "Name", ")", "\n", "continue", "\n", "# print('Dataset:', row.Name, 'Target:', row.Target)", "\n", "", "dataset", "=", "pd", ".", "read_csv", "(", "f'kaggle_datasets/{row.Name}/{row.Name}.csv'", ",", "low_memory", "=", "False", ")", "\n", "# print(row['Target'])", "\n", "if", "row", ".", "Target", "in", "dataset", ".", "columns", ":", "\n", "# print(row.Target, row.Name)", "\n", "            ", "dataset", "=", "dataset", ".", "drop", "(", "row", ".", "Target", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "# fill nans first", "\n", "", "for", "col", "in", "dataset", ".", "columns", ":", "\n", "            ", "dataset", "[", "col", "]", "=", "dataset", "[", "col", "]", ".", "fillna", "(", "dataset", "[", "col", "]", ".", "mean", "(", ")", "if", "dataset", "[", "col", "]", ".", "dtype", ".", "kind", "in", "'biufc'", "else", "dataset", "[", "col", "]", ".", "mode", "(", ")", "[", "0", "]", ")", "\n", "\n", "# sample 1000 rows", "\n", "", "if", "len", "(", "dataset", ")", ">", "1000", ":", "\n", "            ", "dataset", "=", "dataset", ".", "sample", "(", "1000", ")", "\n", "\n", "", "embedding", "=", "embed_dataset", "(", "dataset", ",", "prints", "=", "False", ")", "\n", "\n", "if", "row", ".", "Regression", ":", "\n", "            ", "embeds", "[", "'regression'", "]", "[", "row", ".", "Name", "]", "=", "{", "'target'", ":", "row", ".", "Target", "if", "row", ".", "Target", "else", "''", ",", "'embedding'", ":", "embedding", "}", "\n", "\n", "", "if", "row", ".", "Classification", ":", "\n", "            ", "embeds", "[", "'classification'", "]", "[", "row", ".", "Name", "]", "=", "{", "'target'", ":", "row", ".", "Target", "if", "row", ".", "Target", "else", "''", ",", "'embedding'", ":", "embedding", "}", "\n", "\n", "", "", "with", "open", "(", "'training_set_embeddings.pickle'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "embeds", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.mkdir": [[7, 16], ["os.path.isdir", "os.makedirs", "is_del.strip().lower", "shutil.rmtree", "exit", "is_del.strip"], "function", ["None"], ["def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "is_del", "=", "'y'", "\n", "if", "is_del", ".", "strip", "(", ")", ".", "lower", "(", ")", "==", "'y'", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "path", ")", "\n", "", "else", ":", "\n", "            ", "exit", "(", ")", "\n", "\n", "", "", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.load_graphs": [[18, 38], ["os.listdir", "name.endswith", "open", "graphs.append", "open", "graphs.append", "pickle.load", "pickle.load", "str"], "function", ["None"], ["", "def", "load_graphs", "(", "graphs_path", ",", "graphs_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Returns a list of graphs given graphs directory and graph indices (Optional)\n    If graphs_indices are not provided all graphs will be loaded\n    \"\"\"", "\n", "\n", "graphs", "=", "[", "]", "\n", "if", "graphs_indices", "is", "None", ":", "\n", "        ", "for", "name", "in", "os", ".", "listdir", "(", "graphs_path", ")", ":", "\n", "            ", "if", "not", "name", ".", "endswith", "(", "'.dat'", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "with", "open", "(", "graphs_path", "+", "name", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "graphs", ".", "append", "(", "pickle", ".", "load", "(", "f", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "for", "ind", "in", "graphs_indices", ":", "\n", "            ", "with", "open", "(", "graphs_path", "+", "'graph'", "+", "str", "(", "ind", ")", "+", "'.dat'", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "graphs", ".", "append", "(", "pickle", ".", "load", "(", "f", ")", ")", "\n", "\n", "", "", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.save_graphs": [[40, 47], ["range", "len", "open", "pickle.dump", "str"], "function", ["None"], ["", "def", "save_graphs", "(", "graphs_path", ",", "graphs", ")", ":", "\n", "    ", "\"\"\"\n    Save networkx graphs to a directory with indexing starting from 0\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "graphs", ")", ")", ":", "\n", "        ", "with", "open", "(", "graphs_path", "+", "'graph'", "+", "str", "(", "i", ")", "+", "'.dat'", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "graphs", "[", "i", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.create_dirs": [[50, 68], ["os.path.isdir", "shutil.rmtree", "os.path.isdir", "shutil.rmtree", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs"], "function", ["None"], ["", "", "", "def", "create_dirs", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "clean_tensorboard", "and", "os", ".", "path", ".", "isdir", "(", "args", ".", "tensorboard_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "args", ".", "tensorboard_path", ")", "\n", "\n", "", "if", "args", ".", "clean_temp", "and", "os", ".", "path", ".", "isdir", "(", "args", ".", "temp_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "args", ".", "temp_path", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_save_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "model_save_path", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "temp_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "temp_path", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "tensorboard_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "tensorboard_path", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "current_temp_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "current_temp_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.save_model": [[70, 96], ["save_items.items", "torch.save", "os.path.isdir", "os.makedirs", "d.items", "extra_args.items", "str", "value.state_dict"], "function", ["None"], ["", "", "def", "save_model", "(", "epoch", ",", "args", ",", "model", ",", "optimizer", "=", "None", ",", "scheduler", "=", "None", ",", "**", "extra_args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "current_model_save_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "current_model_save_path", ")", "\n", "\n", "", "fname", "=", "args", ".", "current_model_save_path", "+", "args", ".", "fname", "+", "'_'", "+", "str", "(", "epoch", ")", "+", "'.dat'", "\n", "checkpoint", "=", "{", "'saved_args'", ":", "args", ",", "'epoch'", ":", "epoch", "}", "\n", "\n", "save_items", "=", "{", "'model'", ":", "model", "}", "\n", "if", "optimizer", ":", "\n", "        ", "save_items", "[", "'optimizer'", "]", "=", "optimizer", "\n", "", "if", "scheduler", ":", "\n", "        ", "save_items", "[", "'scheduler'", "]", "=", "scheduler", "\n", "\n", "", "for", "name", ",", "d", "in", "save_items", ".", "items", "(", ")", ":", "\n", "        ", "save_dict", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "save_dict", "[", "key", "]", "=", "value", ".", "state_dict", "(", ")", "\n", "\n", "", "checkpoint", "[", "name", "]", "=", "save_dict", "\n", "\n", "", "if", "extra_args", ":", "\n", "        ", "for", "arg_name", ",", "arg", "in", "extra_args", ".", "items", "(", ")", ":", "\n", "            ", "checkpoint", "[", "arg_name", "]", "=", "arg", "\n", "\n", "", "", "torch", ".", "save", "(", "checkpoint", ",", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.load_model": [[98, 109], ["torch.load", "d.items", "d.items", "value.load_state_dict", "value.to"], "function", ["None"], ["", "def", "load_model", "(", "path", ",", "device", ",", "model", ",", "optimizer", "=", "None", ",", "scheduler", "=", "None", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "device", ")", "\n", "\n", "for", "name", ",", "d", "in", "{", "'model'", ":", "model", ",", "'optimizer'", ":", "optimizer", ",", "'scheduler'", ":", "scheduler", "}", ".", "items", "(", ")", ":", "\n", "        ", "if", "d", "is", "not", "None", ":", "\n", "            ", "for", "key", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "value", ".", "load_state_dict", "(", "checkpoint", "[", "name", "]", "[", "key", "]", ")", "\n", "\n", "", "", "if", "name", "==", "'model'", ":", "\n", "            ", "for", "_", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "value", ".", "to", "(", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute": [[111, 116], ["torch.load"], "function", ["None"], ["", "", "", "", "def", "get_model_attribute", "(", "attribute", ",", "path", ",", "device", ")", ":", "\n", "    ", "fname", "=", "path", "\n", "checkpoint", "=", "torch", ".", "load", "(", "fname", ",", "map_location", "=", "device", ")", "\n", "\n", "return", "checkpoint", "[", "attribute", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.fetch_and_clean_graphs": [[11, 127], ["print", "fetch_and_clean_pipeline_graphs.get_graphs_for_datasets", "print", "os.path.exists", "enumerate", "os.path.exists", "print", "len", "os.path.exists", "os.makedirs", "os.rename", "tqdm.tqdm", "SPARQLWrapper.SPARQLWrapper", "SPARQLWrapper.SPARQLWrapper.setQuery", "SPARQLWrapper.SPARQLWrapper.query().convert", "pandas.DataFrame", "fetch_and_clean_pipeline_graphs.clean_graph4code_pipeline_graph", "clean_graph4code_pipeline_graph.values.tolist", "lines.append", "lines.extend", "lines.append", "lines.extend", "os.remove", "GRAPH_TRIPLES_QUERY.replace", "isinstance", "obj.replace().replace.replace().replace", "df.values.tolist.append", "len", "print", "edges.append", "str", "list", "str", "open", "f.write", "SPARQLWrapper.SPARQLWrapper.query", "[].strip", "len", "len", "len", "len", "node2id.keys", "len", "FORMATTED_DATASET_PATH.rindex", "FORMATTED_DATASET_PATH.rindex", "obj.replace().replace.replace", "len", "len"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.get_graphs_for_datasets", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.clean_graph4code_pipeline_graph"], ["def", "fetch_and_clean_graphs", "(", ")", ":", "\n", "\n", "    ", "FORMATTED_DATASET_PATH", "=", "'datasets/graph4code_large_p3/graph4code_large_p3.txt'", "\n", "ENDPOINT", "=", "'http://localhost:3030/Graph4CodeLarge/sparql'", "\n", "GRAPH_TRIPLES_QUERY", "=", "\"\"\"\n                          select ?s ?p ?o\n                          where{ \n                                graph ?g {?s ?p ?o}\n                                values ?g {<GRAPH_URL>}\n                          }\n                          \"\"\"", "\n", "ALL_GRAPHS_QUERY", "=", "\"\"\"\n                       select distinct ?g\n                       where {\n                         filter regex(str(?g), \"PLACEHOLDER\", \"i\") .\n                         graph ?g {?s ?p ?o}\n                       }\n                       \"\"\"", "\n", "\"\"\"\n    Definition of an ML pipeline:\n        1. has an import statement of sklearn\n        2. has a .fit() call (a statement ending with \".fit\"). This is a heuristic to check if an estimator is used.\n    Note: normalizedLabel is used instead of label. This is to work with the latest version of Graph4Code.\n    \"\"\"", "\n", "ML_PIPELINES_QUERY", "=", "\"\"\"\n                            prefix sch: <http://www.w3.org/2000/01/rdf-schema#>\n                            prefix g4c: <http://purl.org/twc/graph4code/>\n                            prefix syntax: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n                            select distinct ?g\n                            where {\n                              filter regex(str(?g), \"PLACEHOLDER\", \"i\") .\n                              graph ?g {?s syntax:type g4c:Imported .\n                                ?s sch:label ?lib .\n                                filter (?lib = 'sklearn' || ?lib = 'xgboost' || ?lib = 'lgbm')\n                                ?s2 <http://schema.org/about> \"fit\"\n                                }\n                            }\n                         \"\"\"", "\n", "\n", "DATASETS_AL_TRAINING", "=", "[", "'bnp-paribas-cardif-claims-management'", ",", "'crowdflower-search-relevance'", ",", "\n", "'flavours-of-physics'", ",", "'home-depot-product-search-relevance'", ",", "\n", "'liberty-mutual-group-property-inspection-prediction'", ",", "'machinery-tube-pricing'", ",", "\n", "'predict-west-nile-virus'", ",", "'rossmann-store-sales'", ",", "'santander-customer-satisfaction'", "]", "\n", "\n", "print", "(", "'Getting Graph URLS ...'", ")", "\n", "graph_urls", ",", "dataset_names", "=", "get_graphs_for_datasets", "(", "dataset_names_11k_scripts", ",", "ML_PIPELINES_QUERY", ",", "ENDPOINT", ")", "\n", "\n", "# bad graph: 'http://github/data.kg21.unsdsn.world-happiness.manojkumarvk.eda-ensemble-learning.eda-ensemble-learning.py/eda-ensemble-learning'", "\n", "\n", "print", "(", "len", "(", "graph_urls", ")", ",", "'Graphs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "FORMATTED_DATASET_PATH", "[", ":", "FORMATTED_DATASET_PATH", ".", "rindex", "(", "'/'", ")", "]", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "FORMATTED_DATASET_PATH", "[", ":", "FORMATTED_DATASET_PATH", ".", "rindex", "(", "'/'", ")", "]", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "FORMATTED_DATASET_PATH", ")", ":", "\n", "        ", "os", ".", "rename", "(", "FORMATTED_DATASET_PATH", ",", "FORMATTED_DATASET_PATH", "+", "'.old'", ")", "\n", "\n", "", "for", "i", ",", "graph_url", "in", "enumerate", "(", "tqdm", "(", "graph_urls", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "dataset_name", "=", "dataset_names", "[", "i", "-", "1", "]", "\n", "node2id", "=", "{", "}", "\n", "id2node", "=", "{", "}", "\n", "edges", "=", "[", "]", "\n", "lines", "=", "[", "f'#{10000 + i+1}'", "]", "\n", "\n", "sparql", "=", "SPARQLWrapper", "(", "ENDPOINT", ",", "returnFormat", "=", "JSON", ")", "\n", "sparql", ".", "setQuery", "(", "GRAPH_TRIPLES_QUERY", ".", "replace", "(", "'GRAPH_URL'", ",", "graph_url", ")", ")", "\n", "results", "=", "sparql", ".", "query", "(", ")", ".", "convert", "(", ")", "\n", "\n", "triples", "=", "[", "]", "\n", "for", "result", "in", "results", "[", "\"results\"", "]", "[", "\"bindings\"", "]", ":", "\n", "            ", "subj", ",", "pred", ",", "obj", "=", "result", "[", "'s'", "]", "[", "\"value\"", "]", ",", "result", "[", "'p'", "]", "[", "\"value\"", "]", ".", "strip", "(", ")", ",", "result", "[", "'o'", "]", "[", "\"value\"", "]", "\n", "\n", "# For RDF* triples ignore the edge label (they indicate ordinal position and \"expression\" name of se nodes)", "\n", "if", "isinstance", "(", "subj", ",", "dict", ")", ":", "\n", "                ", "subj", ",", "pred", ",", "obj", "=", "subj", "[", "'subject'", "]", "[", "'value'", "]", ",", "subj", "[", "'property'", "]", "[", "'value'", "]", ",", "subj", "[", "'object'", "]", "[", "'value'", "]", "\n", "\n", "# fix literal objects that are empty strings or contain new lines", "\n", "", "if", "len", "(", "obj", ")", "==", "0", ":", "\n", "                ", "obj", "=", "'-'", "\n", "", "obj", "=", "obj", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "' '", ",", "'___'", ")", "\n", "\n", "triples", ".", "append", "(", "(", "subj", ",", "pred", ",", "obj", ")", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "triples", ",", "columns", "=", "[", "'subject'", ",", "'predicate'", ",", "'object'", "]", ")", "\n", "\n", "\n", "df", "=", "clean_graph4code_pipeline_graph", "(", "df", ",", "dataset_name", ")", "\n", "if", "len", "(", "df", ")", "==", "0", ":", "\n", "            ", "print", "(", "f'WARNING: no flowsTo triples in graph {i} - dataset: {dataset_name}'", ")", "\n", "continue", "\n", "\n", "", "triples", "=", "df", ".", "values", ".", "tolist", "(", ")", "\n", "for", "subj", ",", "pred", ",", "obj", "in", "triples", ":", "\n", "            ", "if", "subj", "not", "in", "node2id", ":", "\n", "                ", "node2id", "[", "subj", "]", "=", "len", "(", "node2id", ")", "\n", "id2node", "[", "len", "(", "id2node", ")", "]", "=", "subj", "\n", "", "if", "obj", "not", "in", "node2id", ":", "\n", "                ", "node2id", "[", "obj", "]", "=", "len", "(", "node2id", ")", "\n", "id2node", "[", "len", "(", "id2node", ")", "]", "=", "obj", "\n", "\n", "", "edges", ".", "append", "(", "f'{node2id[subj]} {node2id[obj]} {pred}'", ")", "\n", "\n", "# number of nodes + nodes", "\n", "", "lines", ".", "append", "(", "str", "(", "len", "(", "node2id", ")", ")", ")", "\n", "lines", ".", "extend", "(", "list", "(", "node2id", ".", "keys", "(", ")", ")", ")", "\n", "\n", "# number of edges + edges", "\n", "lines", ".", "append", "(", "str", "(", "len", "(", "edges", ")", ")", ")", "\n", "lines", ".", "extend", "(", "edges", ")", "\n", "\n", "with", "open", "(", "FORMATTED_DATASET_PATH", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", "+", "'\\n\\n'", ")", "\n", "\n", "# remove the old dataset if the generation is successful.", "\n", "", "", "if", "os", ".", "path", ".", "exists", "(", "FORMATTED_DATASET_PATH", "+", "'.old'", ")", ":", "\n", "        ", "os", ".", "remove", "(", "FORMATTED_DATASET_PATH", "+", "'.old'", ")", "\n", "", "print", "(", "'Done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.clean_graph4code_pipeline_graph": [[130, 207], ["[].tolist", "fetch_and_clean_pipeline_graphs.get_pandas_se_nodes_from_spo", "flowsTo_spo.sort_values", "int", "zip", "flowsTo_sorted_spo.append.append", "flowsTo_sorted_spo.append.append", "flowsTo_sorted_spo.append.replace", "filtered_df_spo.drop_duplicates.drop_duplicates", "len", "pandas.DataFrame", "flowsTo_sorted_spo[].tolist", "flowsTo_sorted_spo[].tolist", "flowsTo_sorted_spo[].tolist", "sklearn_xgb_label_spo.set_index().to_dict().items", "natsort.natsort_keygen", "max", "triples_to_remove.append", "flowsTo_sorted_spo.append.apply", "df_spo[].isin", "int", "int", "flowsTo_sorted_spo[].isin", "flowsTo_sorted_spo[].tolist", "df_spo[].str.contains", "df_spo[].isin", "sklearn_xgb_label_spo.set_index().to_dict", "last_se_node.index", "sklearn_xgb_label_spo.set_index", "obj.index", "subj.index"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.get_pandas_se_nodes_from_spo"], ["", "def", "clean_graph4code_pipeline_graph", "(", "df_spo", ",", "dataset_name", ",", "use_data_flow", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Graph4Code Filtration: only extract Sklearn and XGBoost calls.\n    Works as follows:\n    1. filter out non sklearn/xgboost se nodes\n    2. filter out Import se nodes\n    3. filter out all BNodes\n    4. filter out non-flowsTo triples (choose between data flow (default) or code flow\n    5. add extra flowsTo triples between the remaining nodes to make the graph a straight line\n    6. replace the remaining URI with their normalizedLabel\n    7. add closest_dataset and pandas.read_csv nodes to the start of the graph\n    \"\"\"", "\n", "g4c_prefix", "=", "'http://purl.org/twc/graph4code/'", "\n", "if", "use_data_flow", ":", "\n", "        ", "flowsTo_predicate", "=", "g4c_prefix", "+", "'flowsTo'", "\n", "", "else", ":", "\n", "        ", "flowsTo_predicate", "=", "'http://semanticscience.org/resource/SIO_000250'", "\n", "# filter out non-(sklearn.|xgboost.) label nodes and imported se nodes", "\n", "", "imported_se_nodes", "=", "df_spo", "[", "df_spo", "[", "'object'", "]", "==", "g4c_prefix", "+", "'Imported'", "]", "[", "'subject'", "]", ".", "tolist", "(", ")", "\n", "pandas_se_nodes", "=", "get_pandas_se_nodes_from_spo", "(", "df_spo", "[", "df_spo", "[", "'predicate'", "]", "==", "g4c_prefix", "+", "'normalizedLabel'", "]", ")", "\n", "sklearn_xgb_label_spo", "=", "df_spo", "[", "(", "df_spo", "[", "'predicate'", "]", "==", "g4c_prefix", "+", "'normalizedLabel'", ")", "&", "\n", "(", "df_spo", "[", "'object'", "]", ".", "str", ".", "contains", "(", "r'^(sklearn|xgboost|lgbm)\\.'", ",", "regex", "=", "True", ")", ")", "&", "\n", "(", "~", "df_spo", "[", "'subject'", "]", ".", "isin", "(", "imported_se_nodes", "+", "pandas_se_nodes", ")", ")", "]", "\n", "se_to_label", "=", "{", "i", ":", "j", "[", "'object'", "]", "for", "i", ",", "j", "in", "sklearn_xgb_label_spo", ".", "set_index", "(", "'subject'", ")", ".", "to_dict", "(", "orient", "=", "'index'", ")", ".", "items", "(", ")", "}", "\n", "flowsTo_spo", "=", "df_spo", "[", "(", "df_spo", "[", "'predicate'", "]", "==", "flowsTo_predicate", ")", "&", "\n", "(", "df_spo", "[", "'subject'", "]", ".", "isin", "(", "sklearn_xgb_label_spo", "[", "'subject'", "]", ")", ")", "]", "\n", "\n", "# skip this graph if no flowsTo triples (probably a bad graph)", "\n", "if", "len", "(", "flowsTo_spo", ")", "==", "0", ":", "\n", "        ", "return", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "# natural sort by se name", "\n", "", "flowsTo_sorted_spo", "=", "flowsTo_spo", ".", "sort_values", "(", "'subject'", ",", "key", "=", "natsort_keygen", "(", ")", ")", "\n", "\n", "# replace non-sklearn/xgb se objects with ones in the subjects. i.e. connect nodes together", "\n", "last_se_node", "=", "flowsTo_sorted_spo", "[", "'subject'", "]", ".", "tolist", "(", ")", "[", "-", "1", "]", "# last se node that has an sklearn/xgb label", "\n", "last_se_index", "=", "int", "(", "last_se_node", "[", "last_se_node", ".", "index", "(", "'/se'", ")", "+", "3", ":", "]", ")", "# se nodes have the format: http://purl.org/twc/graph4code/se65", "\n", "triples_to_remove", "=", "[", "]", "# remove the triples having objects in this list", "\n", "for", "subj", ",", "obj", "in", "zip", "(", "flowsTo_sorted_spo", "[", "'subject'", "]", ".", "tolist", "(", ")", ",", "flowsTo_sorted_spo", "[", "'object'", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# no need to change anything if the object is already in the subject list", "\n", "        ", "if", "obj", "in", "flowsTo_sorted_spo", "[", "'subject'", "]", ".", "values", ":", "\n", "            ", "continue", "\n", "# increment it till we find a node in the subject, starting from the greater index between subj and obj.", "\n", "# (sometimes subject has higher index than object)", "\n", "", "se_index", "=", "max", "(", "int", "(", "obj", "[", "obj", ".", "index", "(", "'/se'", ")", "+", "3", ":", "]", ")", ",", "int", "(", "subj", "[", "subj", ".", "index", "(", "'/se'", ")", "+", "3", ":", "]", ")", ")", "+", "1", "\n", "while", "se_index", "<=", "last_se_index", ":", "\n", "            ", "next_se_node", "=", "f'{g4c_prefix}se{se_index}'", "\n", "if", "next_se_node", "in", "flowsTo_sorted_spo", "[", "'subject'", "]", ".", "values", ":", "\n", "                ", "break", "\n", "", "se_index", "+=", "1", "\n", "\n", "# if se_index is greater than the last index, remove triples having this object", "\n", "# otherwise, set the object to the se node having this index", "\n", "", "if", "se_index", ">", "last_se_index", ":", "\n", "            ", "triples_to_remove", ".", "append", "(", "obj", ")", "\n", "", "else", ":", "\n", "            ", "flowsTo_sorted_spo", "[", "'object'", "]", "=", "flowsTo_sorted_spo", ".", "apply", "(", "lambda", "x", ":", "next_se_node", "if", "x", "[", "'subject'", "]", "==", "subj", "and", "\n", "x", "[", "'object'", "]", "==", "obj", "\n", "else", "x", "[", "'object'", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "", "flowsTo_sorted_spo", "=", "flowsTo_sorted_spo", "[", "~", "flowsTo_sorted_spo", "[", "'object'", "]", ".", "isin", "(", "triples_to_remove", ")", "]", "\n", "# add dataset name and pandas.read_csv nodes", "\n", "flowsTo_sorted_spo", "=", "flowsTo_sorted_spo", ".", "append", "(", "{", "'subject'", ":", "dataset_name", ",", "\n", "'predicate'", ":", "flowsTo_predicate", ",", "\n", "'object'", ":", "'pandas.read_csv'", "}", ",", "ignore_index", "=", "True", ")", "\n", "flowsTo_sorted_spo", "=", "flowsTo_sorted_spo", ".", "append", "(", "{", "'subject'", ":", "'pandas.read_csv'", ",", "\n", "'predicate'", ":", "flowsTo_predicate", ",", "\n", "'object'", ":", "flowsTo_sorted_spo", "[", "'subject'", "]", ".", "tolist", "(", ")", "[", "0", "]", "}", ",", "\n", "ignore_index", "=", "True", ")", "\n", "\n", "filtered_df_spo", "=", "flowsTo_sorted_spo", ".", "replace", "(", "se_to_label", ")", "\n", "# remove self-loops", "\n", "filtered_df_spo", "=", "filtered_df_spo", "[", "filtered_df_spo", "[", "'subject'", "]", "!=", "filtered_df_spo", "[", "'object'", "]", "]", "\n", "# remove duplicate edges", "\n", "filtered_df_spo", "=", "filtered_df_spo", ".", "drop_duplicates", "(", ")", "\n", "\n", "return", "filtered_df_spo", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.get_pandas_se_nodes_from_spo": [[209, 221], ["set", "df_spo_labels[].tolist", "[].tolist", "re.search", "set.add", "label.endswith", "set.add", "df_spo_labels[].isin"], "function", ["None"], ["", "def", "get_pandas_se_nodes_from_spo", "(", "df_spo_labels", ")", ":", "\n", "    ", "pandas_calls", "=", "[", "'shape'", ",", "'null'", ",", "'expr'", ",", "'columns'", ",", "'T'", ",", "'sum'", ",", "'max'", ",", "'min'", ",", "'mean'", ",", "'astype'", ",", "\n", "'drop'", ",", "'value_counts'", ",", "'iloc'", ",", "'loc'", "]", "\n", "bad_labels", "=", "set", "(", ")", "\n", "for", "label", "in", "df_spo_labels", "[", "'object'", "]", ".", "tolist", "(", ")", ":", "\n", "        ", "if", "re", ".", "search", "(", "r'\\.[0-9]'", ",", "label", ")", ":", "\n", "            ", "bad_labels", ".", "add", "(", "label", ")", "\n", "", "for", "pc", "in", "pandas_calls", ":", "\n", "            ", "if", "label", ".", "endswith", "(", "f'.{pc}'", ")", "or", "f'.{pc}.'", "in", "label", ":", "\n", "                ", "bad_labels", ".", "add", "(", "label", ")", "\n", "\n", "", "", "", "return", "df_spo_labels", "[", "df_spo_labels", "[", "'object'", "]", ".", "isin", "(", "bad_labels", ")", "]", "[", "'subject'", "]", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.get_graphs_for_datasets": [[224, 236], ["tqdm.tqdm", "SPARQLWrapper.SPARQLWrapper", "SPARQLWrapper.SPARQLWrapper.setQuery", "SPARQLWrapper.SPARQLWrapper.query().convert", "graphs.extend", "datasets.extend", "query.replace", "SPARQLWrapper.SPARQLWrapper.query", "len", "utils.constants.dataset_names_11k_scripts"], "function", ["None"], ["", "def", "get_graphs_for_datasets", "(", "dataset_names", ",", "query", ",", "sparql_endpoint", ")", ":", "\n", "    ", "graphs", "=", "[", "]", "\n", "datasets", "=", "[", "]", "\n", "for", "dataset_name", "in", "tqdm", "(", "dataset_names", ")", ":", "\n", "        ", "sparql", "=", "SPARQLWrapper", "(", "sparql_endpoint", ",", "returnFormat", "=", "JSON", ")", "\n", "sparql", ".", "setQuery", "(", "query", ".", "replace", "(", "'PLACEHOLDER'", ",", "dataset_name", ")", ")", "\n", "results", "=", "sparql", ".", "query", "(", ")", ".", "convert", "(", ")", "\n", "bindings", "=", "results", "[", "\"results\"", "]", "[", "\"bindings\"", "]", "\n", "graphs", ".", "extend", "(", "[", "i", "[", "'g'", "]", "[", "'value'", "]", "for", "i", "in", "bindings", "]", ")", "\n", "datasets", ".", "extend", "(", "[", "dataset_name", "]", "*", "len", "(", "bindings", ")", ")", "\n", "\n", "", "return", "graphs", ",", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.main": [[239, 241], ["fetch_and_clean_pipeline_graphs.fetch_and_clean_graphs"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.fetch_and_clean_pipeline_graphs.fetch_and_clean_graphs"], ["", "def", "main", "(", ")", ":", "\n", "    ", "fetch_and_clean_graphs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.train_epoch": [[14, 50], ["model.items", "len", "enumerate", "net.train", "model.items", "graph_generation_model.train.evaluate_loss", "print", "graph_generation_model.train.evaluate_loss.backward", "graph_generation_model.train.evaluate_loss.data.item", "optimizer.items", "scheduler.items", "net.to", "net.zero_grad", "datetime.datetime.now", "open", "f.write", "model.items", "opt.step", "sched.step", "summary_writer.add_scalar", "torch.nn.utils.clip_grad_value_", "graph_generation_model.train.evaluate_loss.data.item", "net.parameters", "graph_generation_model.train.evaluate_loss.data.item"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.train", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.train.evaluate_loss"], ["def", "train_epoch", "(", "epoch", ",", "args", ",", "model", ",", "dataloader_train", ",", "optimizer", ",", "scheduler", ",", "feature_map", ",", "summary_writer", "=", "None", ")", ":", "\n", "# Set training mode for modules", "\n", "    ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "\n", "", "batch_count", "=", "len", "(", "dataloader_train", ")", "\n", "total_loss", "=", "0.0", "\n", "for", "batch_id", ",", "data", "in", "enumerate", "(", "dataloader_train", ")", ":", "\n", "        ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "            ", "net", ".", "to", "(", "args", ".", "device", ")", "\n", "net", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "", "loss", "=", "eval_loss_dgmg", "(", "model", ",", "data", ")", "\n", "print", "(", "datetime", ".", "now", "(", ")", ",", "f'Batch {batch_id} / {batch_count} | loss: {loss.data.item():.4f}'", ")", "\n", "with", "open", "(", "'loss_values.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f'{loss.data.item()}\\n'", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "total_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "# Clipping gradients", "\n", "if", "args", ".", "gradient_clipping", ":", "\n", "            ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "                ", "clip_grad_value_", "(", "net", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "\n", "# Update params of rnn and mlp", "\n", "", "", "for", "_", ",", "opt", "in", "optimizer", ".", "items", "(", ")", ":", "\n", "            ", "opt", ".", "step", "(", ")", "\n", "\n", "", "for", "_", ",", "sched", "in", "scheduler", ".", "items", "(", ")", ":", "\n", "            ", "sched", ".", "step", "(", ")", "\n", "\n", "", "if", "args", ".", "log_tensorboard", ":", "\n", "            ", "summary_writer", ".", "add_scalar", "(", "f'{args.graph_type} Loss/train batch'", ",", "loss", ",", "batch_id", "+", "batch_count", "*", "epoch", ")", "\n", "\n", "", "", "return", "total_loss", "/", "batch_count", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.test_data": [[52, 64], ["model.items", "len", "net.eval", "torch.no_grad", "enumerate", "graph_generation_model.train.evaluate_loss", "graph_generation_model.train.evaluate_loss.data.item"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.train.evaluate_loss"], ["", "def", "test_data", "(", "args", ",", "model", ",", "dataloader", ",", "feature_map", ")", ":", "\n", "    ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "net", ".", "eval", "(", ")", "\n", "\n", "", "batch_count", "=", "len", "(", "dataloader", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "total_loss", "=", "0.0", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "loss", "=", "eval_loss_dgmg", "(", "model", ",", "data", ")", "\n", "total_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "", "", "return", "total_loss", "/", "batch_count", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.train": [[67, 124], ["model.items", "model.items", "training.graphgen_training_utils.save_model", "print", "torch.optim.Adam", "torch.optim.lr_scheduler.MultiStepLR", "training.graphgen_training_utils.load_model", "print", "training.graphgen_training_utils.get_model_attribute", "torch.utils.tensorboard.SummaryWriter", "train.train_epoch", "filter", "torch.utils.tensorboard.SummaryWriter.add_scalar", "training.graphgen_training_utils.save_model", "print", "train.test_data", "net.parameters", "torch.utils.tensorboard.SummaryWriter.add_scalar", "print", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.save_model", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.load_model", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.train_epoch", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.save_model", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.train.test_data"], ["", "def", "train", "(", "args", ",", "dataloader_train", ",", "model", ",", "feature_map", ",", "dataloader_validate", "=", "None", ")", ":", "\n", "# initialize optimizer", "\n", "    ", "optimizer", "=", "{", "}", "\n", "for", "name", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "optimizer", "[", "'optimizer_'", "+", "name", "]", "=", "optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "net", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "lr", ",", "\n", "weight_decay", "=", "5e-5", ")", "\n", "\n", "", "scheduler", "=", "{", "}", "\n", "for", "name", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "scheduler", "[", "'scheduler_'", "+", "name", "]", "=", "MultiStepLR", "(", "\n", "optimizer", "[", "'optimizer_'", "+", "name", "]", ",", "milestones", "=", "args", ".", "milestones", ",", "\n", "gamma", "=", "args", ".", "gamma", ")", "\n", "\n", "", "if", "args", ".", "load_model", ":", "\n", "        ", "load_model", "(", "args", ".", "load_model_path", ",", "args", ".", "device", ",", "\n", "model", ",", "optimizer", ",", "scheduler", ")", "\n", "print", "(", "'Model loaded'", ")", "\n", "\n", "epoch", "=", "get_model_attribute", "(", "'epoch'", ",", "args", ".", "load_model_path", ",", "args", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "epoch", "=", "0", "\n", "\n", "", "if", "args", ".", "log_tensorboard", ":", "\n", "        ", "writer", "=", "SummaryWriter", "(", "\n", "log_dir", "=", "args", ".", "tensorboard_path", "+", "args", ".", "fname", "+", "' '", "+", "args", ".", "time", ",", "flush_secs", "=", "5", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "while", "epoch", "<", "args", ".", "epochs", ":", "\n", "        ", "loss", "=", "train_epoch", "(", "\n", "epoch", ",", "args", ",", "model", ",", "dataloader_train", ",", "optimizer", ",", "scheduler", ",", "feature_map", ",", "writer", ")", "\n", "epoch", "+=", "1", "\n", "\n", "# logging", "\n", "if", "args", ".", "log_tensorboard", ":", "\n", "            ", "writer", ".", "add_scalar", "(", "f'{args.graph_type} Loss/train'", ",", "loss", ",", "epoch", ")", "\n", "\n", "# save model checkpoint", "\n", "", "if", "args", ".", "save_model", "and", "epoch", "!=", "0", "and", "epoch", "%", "args", ".", "epochs_save", "==", "0", ":", "\n", "            ", "save_model", "(", "\n", "epoch", ",", "args", ",", "model", ",", "optimizer", ",", "scheduler", ",", "feature_map", "=", "feature_map", ")", "\n", "print", "(", "\n", "'Model Saved - Epoch: {}/{}, train loss: {:.6f}'", ".", "format", "(", "epoch", ",", "args", ".", "epochs", ",", "loss", ")", ")", "\n", "\n", "", "if", "dataloader_validate", "is", "not", "None", "and", "epoch", "%", "args", ".", "epochs_validate", "==", "0", ":", "\n", "            ", "loss_validate", "=", "test_data", "(", "\n", "args", ",", "model", ",", "dataloader_validate", ",", "feature_map", ")", "\n", "if", "args", ".", "log_tensorboard", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "f'{args.graph_type} Loss/validate'", ",", "loss_validate", ",", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "datetime", ".", "now", "(", ")", ",", "': Epoch: {}/{}, train - valid loss: {:.6f} | {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "loss", ",", "loss_validate", ")", ")", "\n", "\n", "", "", "", "save_model", "(", "epoch", ",", "args", ",", "model", ",", "optimizer", ",", "\n", "scheduler", ",", "feature_map", "=", "feature_map", ")", "\n", "print", "(", "'Model Saved - Epoch: {}/{}, train loss: {:.6f}'", ".", "format", "(", "epoch", ",", "args", ".", "epochs", ",", "loss", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.datasets.process_dataset.check_graph_size": [[8, 24], ["graph.number_of_nodes", "graph.number_of_nodes", "graph.number_of_edges", "graph.number_of_edges"], "function", ["None"], ["def", "check_graph_size", "(", "\n", "graph", ",", "min_num_nodes", "=", "None", ",", "max_num_nodes", "=", "None", ",", "\n", "min_num_edges", "=", "None", ",", "max_num_edges", "=", "None", "\n", ")", ":", "\n", "\n", "    ", "if", "min_num_nodes", "and", "graph", ".", "number_of_nodes", "(", ")", "<", "min_num_nodes", ":", "\n", "        ", "return", "False", "\n", "", "if", "max_num_nodes", "and", "graph", ".", "number_of_nodes", "(", ")", ">", "max_num_nodes", ":", "\n", "        ", "return", "False", "\n", "\n", "", "if", "min_num_edges", "and", "graph", ".", "number_of_edges", "(", ")", "<", "min_num_edges", ":", "\n", "        ", "return", "False", "\n", "", "if", "max_num_edges", "and", "graph", ".", "number_of_edges", "(", ")", ">", "max_num_edges", ":", "\n", "        ", "return", "False", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.datasets.process_dataset.produce_graphs_from_raw_format": [[26, 93], ["set", "open", "len", "line.strip().split.strip().split", "lines.append", "networkx.Graph", "int", "range", "int", "range", "int", "int", "nx.Graph.add_node", "nx.Graph.add_edge", "process_dataset.check_graph_size", "networkx.is_connected", "set.add", "line.strip().split.strip", "int", "int", "open", "pickle.dump", "os.path.join"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.datasets.process_dataset.check_graph_size"], ["", "def", "produce_graphs_from_raw_format", "(", "\n", "inputfile", ",", "output_path", ",", "num_graphs", "=", "None", ",", "min_num_nodes", "=", "None", ",", "\n", "max_num_nodes", "=", "None", ",", "min_num_edges", "=", "None", ",", "max_num_edges", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    :param inputfile: Path to file containing graphs in raw format\n    :param output_path: Path to store networkx graphs\n    :param num_graphs: Upper bound on number of graphs to be taken\n    :param min_num_nodes: Lower bound on number of nodes in graphs if provided\n    :param max_num_nodes: Upper bound on number of nodes in graphs if provided\n    :param min_num_edges: Lower bound on number of edges in graphs if provided\n    :param max_num_edges: Upper bound on number of edges in graphs if provided\n    :return: number of graphs produced\n    \"\"\"", "\n", "\n", "lines", "=", "[", "]", "\n", "with", "open", "(", "inputfile", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "lines", ".", "append", "(", "line", ")", "\n", "\n", "", "", "index", "=", "0", "\n", "count", "=", "0", "\n", "graphs_ids", "=", "set", "(", ")", "\n", "while", "index", "<", "len", "(", "lines", ")", ":", "\n", "        ", "if", "lines", "[", "index", "]", "[", "0", "]", "[", "1", ":", "]", "not", "in", "graphs_ids", ":", "\n", "            ", "graph_id", "=", "lines", "[", "index", "]", "[", "0", "]", "[", "1", ":", "]", "\n", "G", "=", "nx", ".", "Graph", "(", "id", "=", "graph_id", ")", "\n", "\n", "index", "+=", "1", "\n", "vert", "=", "int", "(", "lines", "[", "index", "]", "[", "0", "]", ")", "\n", "index", "+=", "1", "\n", "for", "i", "in", "range", "(", "vert", ")", ":", "\n", "                ", "G", ".", "add_node", "(", "i", ",", "label", "=", "lines", "[", "index", "]", "[", "0", "]", ")", "\n", "index", "+=", "1", "\n", "\n", "", "edges", "=", "int", "(", "lines", "[", "index", "]", "[", "0", "]", ")", "\n", "index", "+=", "1", "\n", "for", "i", "in", "range", "(", "edges", ")", ":", "\n", "                ", "G", ".", "add_edge", "(", "int", "(", "lines", "[", "index", "]", "[", "0", "]", ")", ",", "int", "(", "\n", "lines", "[", "index", "]", "[", "1", "]", ")", ",", "label", "=", "lines", "[", "index", "]", "[", "2", "]", ")", "\n", "index", "+=", "1", "\n", "\n", "", "index", "+=", "1", "\n", "\n", "if", "not", "check_graph_size", "(", "\n", "G", ",", "min_num_nodes", ",", "max_num_nodes", ",", "min_num_edges", ",", "max_num_edges", "\n", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "G", "and", "nx", ".", "is_connected", "(", "G", ")", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "output_path", ",", "'graph{}.dat'", ".", "format", "(", "count", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "G", ",", "f", ")", "\n", "\n", "", "graphs_ids", ".", "add", "(", "graph_id", ")", "\n", "count", "+=", "1", "\n", "\n", "if", "num_graphs", "and", "count", ">=", "num_graphs", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "vert", "=", "int", "(", "lines", "[", "index", "+", "1", "]", "[", "0", "]", ")", "\n", "edges", "=", "int", "(", "lines", "[", "index", "+", "2", "+", "vert", "]", "[", "0", "]", ")", "\n", "index", "+=", "vert", "+", "edges", "+", "4", "\n", "\n", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.datasets.process_dataset.create_graphs": [[96, 125], ["os.path.join", "os.path.join", "training.graphgen_training_utils.mkdir", "process_dataset.produce_graphs_from_raw_format", "print", "len", "print", "range", "os.listdir", "name.endswith"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.mkdir", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.datasets.process_dataset.produce_graphs_from_raw_format"], ["", "def", "create_graphs", "(", "args", ")", ":", "\n", "\n", "#if 'graph4code' in args.graph_type:", "\n", "    ", "base_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_path", ",", "f'{args.graph_type}/'", ")", "\n", "input_path", "=", "base_path", "+", "f'{args.graph_type}.txt'", "\n", "min_num_nodes", ",", "max_num_nodes", "=", "None", ",", "None", "\n", "min_num_edges", ",", "max_num_edges", "=", "None", ",", "None", "\n", "\n", "\n", "args", ".", "current_dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "'graphs/'", ")", "\n", "\n", "args", ".", "current_processed_dataset_path", "=", "args", ".", "current_dataset_path", "\n", "\n", "if", "args", ".", "produce_graphs", ":", "\n", "        ", "mkdir", "(", "args", ".", "current_dataset_path", ")", "\n", "\n", "# if 'graph4code' in args.graph_type:", "\n", "count", "=", "produce_graphs_from_raw_format", "(", "input_path", ",", "args", ".", "current_dataset_path", ",", "args", ".", "num_graphs", ",", "\n", "min_num_nodes", "=", "min_num_nodes", ",", "max_num_nodes", "=", "max_num_nodes", ",", "\n", "min_num_edges", "=", "min_num_edges", ",", "max_num_edges", "=", "max_num_edges", ")", "\n", "\n", "print", "(", "'Graphs produced'", ",", "count", ")", "\n", "", "else", ":", "\n", "        ", "count", "=", "len", "(", "[", "name", "for", "name", "in", "os", ".", "listdir", "(", "args", ".", "current_dataset_path", ")", "if", "name", ".", "endswith", "(", "\".dat\"", ")", "]", ")", "\n", "print", "(", "'Graphs counted'", ",", "count", ")", "\n", "\n", "\n", "", "graphs", "=", "[", "i", "for", "i", "in", "range", "(", "count", ")", "]", "\n", "return", "graphs", "\n", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.train.evaluate_loss": [[11, 19], ["len"], "function", ["None"], ["from", "graph_generation_model", ".", "train", "import", "evaluate_loss", "as", "eval_loss_dgmg", "\n", "\n", "\n", "def", "train_epoch", "(", "epoch", ",", "args", ",", "model", ",", "dataloader_train", ",", "optimizer", ",", "scheduler", ",", "feature_map", ",", "summary_writer", "=", "None", ")", ":", "\n", "# Set training mode for modules", "\n", "    ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "\n", "", "batch_count", "=", "len", "(", "dataloader_train", ")", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.train.predict_graphs": [[21, 69], ["training.graphgen_training_utils.get_model_attribute", "graph_generation_model.model.create_model", "training.graphgen_training_utils.load_model", "graph_generation_model.model.create_model.items", "range", "net.eval", "hasattr", "sampled_graph.cpu().to_networkx().to_undirected", "networkx.Graph", "sampled_graph.cpu().to_networkx().to_undirected.nodes", "graphs.append", "labeled_graph.subgraph.add_node", "labeled_graph.subgraph.add_edge", "len", "max", "labeled_graph.subgraph.subgraph", "sampled_graph.cpu().to_networkx", "labeled_graph.subgraph.nodes", "networkx.connected_components", "sampled_graph.cpu", "[].item", "[].item"], "function", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.get_model_attribute", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.create_model", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.training.graphgen_training_utils.load_model"], ["for", "batch_id", ",", "data", "in", "enumerate", "(", "dataloader_train", ")", ":", "\n", "        ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "            ", "net", ".", "to", "(", "args", ".", "device", ")", "\n", "net", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "", "loss", "=", "eval_loss_dgmg", "(", "model", ",", "data", ")", "\n", "print", "(", "datetime", ".", "now", "(", ")", ",", "f'Batch {batch_id} / {batch_count} | loss: {loss.data.item():.4f}'", ")", "\n", "with", "open", "(", "'loss_values.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f'{loss.data.item()}\\n'", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "total_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "# Clipping gradients", "\n", "if", "args", ".", "gradient_clipping", ":", "\n", "            ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "                ", "clip_grad_value_", "(", "net", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "\n", "# Update params of rnn and mlp", "\n", "", "", "for", "_", ",", "opt", "in", "optimizer", ".", "items", "(", ")", ":", "\n", "            ", "opt", ".", "step", "(", ")", "\n", "\n", "", "for", "_", ",", "sched", "in", "scheduler", ".", "items", "(", ")", ":", "\n", "            ", "sched", ".", "step", "(", ")", "\n", "\n", "", "if", "args", ".", "log_tensorboard", ":", "\n", "            ", "summary_writer", ".", "add_scalar", "(", "f'{args.graph_type} Loss/train batch'", ",", "loss", ",", "batch_id", "+", "batch_count", "*", "epoch", ")", "\n", "\n", "", "", "return", "total_loss", "/", "batch_count", "\n", "\n", "\n", "", "def", "test_data", "(", "args", ",", "model", ",", "dataloader", ",", "feature_map", ")", ":", "\n", "    ", "for", "_", ",", "net", "in", "model", ".", "items", "(", ")", ":", "\n", "        ", "net", ".", "eval", "(", ")", "\n", "\n", "", "batch_count", "=", "len", "(", "dataloader", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "total_loss", "=", "0.0", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "loss", "=", "eval_loss_dgmg", "(", "model", ",", "data", ")", "\n", "total_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "", "", "return", "total_loss", "/", "batch_count", "\n", "\n", "\n", "# Main training function", "\n", "", "def", "train", "(", "args", ",", "dataloader_train", ",", "model", ",", "feature_map", ",", "dataloader_validate", "=", "None", ")", ":", "\n", "# initialize optimizer", "\n", "    ", "optimizer", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.data.DGMG_Dataset_from_file.__init__": [[16, 49], ["range", "len", "f.close", "torch.randperm().numpy", "networkx.relabel_nodes", "range", "actions.append", "data.DGMG_Dataset_from_file.data.append", "open", "pickle.load", "len", "actions.append", "graph[].items", "actions.append", "torch.tensor().to", "torch.randperm", "range", "pickle.load.nodes", "len", "len", "actions.append", "actions.append", "torch.tensor", "str", "pickle.load.nodes", "int", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ",", "graphs_indices", ",", "feature_map", ")", ":", "\n", "# Path to folder containing dataset", "\n", "        ", "self", ".", "dataset_path", "=", "args", ".", "current_processed_dataset_path", "\n", "self", ".", "graphs_indices", "=", "graphs_indices", "\n", "self", ".", "feature_map", "=", "feature_map", "\n", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "graphs_indices", ")", ")", ":", "\n", "            ", "with", "open", "(", "self", ".", "dataset_path", "+", "'graph'", "+", "str", "(", "self", ".", "graphs_indices", "[", "idx", "]", ")", "+", "'.dat'", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "graph", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "node_map", ",", "edge_map", "=", "self", ".", "feature_map", "[", "'node_forward'", "]", ",", "self", ".", "feature_map", "[", "'edge_forward'", "]", "\n", "\n", "perm", "=", "torch", ".", "randperm", "(", "len", "(", "graph", ".", "nodes", "(", ")", ")", ")", ".", "numpy", "(", ")", "\n", "perm_map", "=", "{", "i", ":", "perm", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "perm", ")", ")", "}", "\n", "graph", "=", "nx", ".", "relabel_nodes", "(", "graph", ",", "perm_map", ")", "\n", "\n", "actions", "=", "[", "]", "\n", "for", "v", "in", "range", "(", "len", "(", "graph", ".", "nodes", "(", ")", ")", ")", ":", "\n", "                ", "actions", ".", "append", "(", "1", "+", "node_map", "[", "graph", ".", "nodes", "[", "v", "]", "[", "'label'", "]", "]", ")", "# Add node", "\n", "\n", "for", "u", ",", "val", "in", "graph", "[", "v", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "u", "<", "v", ":", "\n", "# Add edge", "\n", "                        ", "actions", ".", "append", "(", "1", ")", "\n", "actions", ".", "append", "(", "\n", "int", "(", "u", "*", "len", "(", "edge_map", ")", "+", "edge_map", "[", "val", "[", "'label'", "]", "]", ")", ")", "\n", "\n", "", "", "actions", ".", "append", "(", "0", ")", "# Stop Edge", "\n", "\n", "", "actions", ".", "append", "(", "0", ")", "# Stop Node", "\n", "self", ".", "data", ".", "append", "(", "torch", ".", "tensor", "(", "actions", ")", ".", "to", "(", "args", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.data.DGMG_Dataset_from_file.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "graphs_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.data.DGMG_Dataset_from_file.__getitem__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "idx", "]", "\n", "# with open(self.dataset_path + 'graph' + str(self.graphs_indices[idx]) + '.dat', 'rb') as f:", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.data.DGMG_Dataset_from_file.collate_batch": [[82, 84], ["None"], "methods", ["None"], ["", "def", "collate_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphEmbed.__init__": [[53, 68], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_hidden_size", ",", "device", ")", ":", "\n", "        ", "super", "(", "GraphEmbed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Setting from the paper", "\n", "self", ".", "graph_hidden_size", "=", "2", "*", "node_hidden_size", "\n", "\n", "# Embed graphs", "\n", "self", ".", "node_gating", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_hidden_size", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "self", ".", "node_to_graph", "=", "nn", ".", "Linear", "(", "\n", "node_hidden_size", ",", "self", ".", "graph_hidden_size", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphEmbed.forward": [[69, 83], ["dgl.batch", "dgl.sum_nodes", "g_list[].number_of_nodes", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.GraphEmbed.node_gating", "model.GraphEmbed.node_to_graph", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g_list", ")", ":", "\n", "# With our current batched implementation of DGMG, new nodes", "\n", "# are not added for any graph until all graphs are done with", "\n", "# adding edges starting from the last node. Therefore all graphs", "\n", "# in the graph_list should have the same number of nodes.", "\n", "\n", "        ", "if", "g_list", "[", "0", "]", ".", "number_of_nodes", "(", ")", "==", "0", ":", "\n", "            ", "return", "torch", ".", "zeros", "(", "len", "(", "g_list", ")", ",", "self", ".", "graph_hidden_size", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "bg", "=", "dgl", ".", "batch", "(", "g_list", ")", "\n", "bhv", "=", "bg", ".", "ndata", "[", "'hv'", "]", "\n", "bg", ".", "ndata", "[", "'hg'", "]", "=", "self", ".", "node_gating", "(", "bhv", ")", "*", "self", ".", "node_to_graph", "(", "bhv", ")", "\n", "\n", "return", "dgl", ".", "sum_nodes", "(", "bg", ",", "'hg'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphProp.__init__": [[86, 111], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "message_funcs.append", "model.GraphProp.reduce_funcs.append", "node_update_funcs.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "functools.partial", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_prop_rounds", ",", "node_hidden_size", ")", ":", "\n", "        ", "super", "(", "GraphProp", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_prop_rounds", "=", "num_prop_rounds", "\n", "\n", "# Setting from the paper", "\n", "self", ".", "node_activation_hidden_size", "=", "2", "*", "node_hidden_size", "\n", "\n", "message_funcs", "=", "[", "]", "\n", "node_update_funcs", "=", "[", "]", "\n", "self", ".", "reduce_funcs", "=", "[", "]", "\n", "\n", "for", "t", "in", "range", "(", "num_prop_rounds", ")", ":", "\n", "# input being [hv, hu, xuv]", "\n", "# hv, hu and xuv are of size node_hidden_size", "\n", "            ", "message_funcs", ".", "append", "(", "nn", ".", "Linear", "(", "3", "*", "node_hidden_size", ",", "\n", "self", ".", "node_activation_hidden_size", ")", ")", "\n", "\n", "self", ".", "reduce_funcs", ".", "append", "(", "partial", "(", "self", ".", "dgmg_reduce", ",", "round", "=", "t", ")", ")", "\n", "node_update_funcs", ".", "append", "(", "\n", "nn", ".", "GRUCell", "(", "self", ".", "node_activation_hidden_size", ",", "\n", "node_hidden_size", ")", ")", "\n", "\n", "", "self", ".", "message_funcs", "=", "nn", ".", "ModuleList", "(", "message_funcs", ")", "\n", "self", ".", "node_update_funcs", "=", "nn", ".", "ModuleList", "(", "node_update_funcs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphProp.dgmg_msg": [[112, 119], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "dgmg_msg", "(", "self", ",", "edges", ")", ":", "\n", "        ", "\"\"\"\n        For an edge u->v, return concat([h_u, x_uv])\n        \"\"\"", "\n", "return", "{", "'m'", ":", "torch", ".", "cat", "(", "[", "edges", ".", "src", "[", "'hv'", "]", ",", "\n", "edges", ".", "data", "[", "'he'", "]", "]", ",", "\n", "dim", "=", "1", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphProp.dgmg_reduce": [[120, 128], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hv_old.unsqueeze().expand", "m.size", "hv_old.unsqueeze"], "methods", ["None"], ["", "def", "dgmg_reduce", "(", "self", ",", "nodes", ",", "round", ")", ":", "\n", "        ", "hv_old", "=", "nodes", ".", "data", "[", "'hv'", "]", "\n", "m", "=", "nodes", ".", "mailbox", "[", "'m'", "]", "\n", "message", "=", "torch", ".", "cat", "(", "[", "\n", "hv_old", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "m", ".", "size", "(", "1", ")", ",", "-", "1", ")", ",", "m", "]", ",", "dim", "=", "2", ")", "\n", "node_activation", "=", "(", "self", ".", "message_funcs", "[", "round", "]", "(", "message", ")", ")", ".", "sum", "(", "1", ")", "\n", "\n", "return", "{", "'a'", ":", "node_activation", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.GraphProp.forward": [[129, 143], ["dgl.batch", "dgl.unbatch", "dgl.batch.number_of_edges", "range", "dgl.batch.update_all"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g_list", ")", ":", "\n", "# Merge small graphs into a large graph.", "\n", "        ", "bg", "=", "dgl", ".", "batch", "(", "g_list", ")", "\n", "\n", "if", "bg", ".", "number_of_edges", "(", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "else", ":", "\n", "            ", "for", "t", "in", "range", "(", "self", ".", "num_prop_rounds", ")", ":", "\n", "                ", "bg", ".", "update_all", "(", "message_func", "=", "self", ".", "dgmg_msg", ",", "\n", "reduce_func", "=", "self", ".", "reduce_funcs", "[", "t", "]", ")", "\n", "bg", ".", "ndata", "[", "'hv'", "]", "=", "self", ".", "node_update_funcs", "[", "t", "]", "(", "\n", "bg", ".", "ndata", "[", "'a'", "]", ",", "bg", ".", "ndata", "[", "'hv'", "]", ")", "\n", "\n", "", "", "return", "dgl", ".", "unbatch", "(", "bg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode.__init__": [[156, 182], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "graph_embed_func", ",", "node_hidden_size", ",", "num_node_types", ",", "dropout_prob", ",", "\n", "device", "\n", ")", ":", "\n", "        ", "super", "(", "AddNode", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "node_hidden_size", "=", "node_hidden_size", "\n", "self", ".", "num_node_types", "=", "num_node_types", "\n", "self", ".", "graph_op", "=", "{", "'embed'", ":", "graph_embed_func", "}", "\n", "\n", "self", ".", "stop", "=", "0", "\n", "self", ".", "add_node", "=", "nn", ".", "Linear", "(", "\n", "graph_embed_func", ".", "graph_hidden_size", ",", "1", "+", "num_node_types", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_prob", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# If to add a node, initialize its hv", "\n", "self", ".", "node_type_embed", "=", "nn", ".", "Embedding", "(", "\n", "1", "+", "num_node_types", ",", "node_hidden_size", ")", "\n", "self", ".", "initialize_hv", "=", "nn", ".", "Linear", "(", "node_hidden_size", "+", "\n", "graph_embed_func", ".", "graph_hidden_size", ",", "\n", "node_hidden_size", ")", "\n", "\n", "self", ".", "init_node_activation", "=", "torch", ".", "zeros", "(", "\n", "1", ",", "2", "*", "self", ".", "node_hidden_size", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode._initialize_node_repr": [[183, 193], ["g.number_of_nodes", "model.AddNode.initialize_hv", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "model.AddNode.node_type_embed", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "_initialize_node_repr", "(", "self", ",", "g", ",", "node_type", ",", "graph_embed", ")", ":", "\n", "        ", "num_nodes", "=", "g", ".", "number_of_nodes", "(", ")", "\n", "hv_init", "=", "self", ".", "initialize_hv", "(", "\n", "torch", ".", "cat", "(", "[", "\n", "self", ".", "node_type_embed", "(", "torch", ".", "LongTensor", "(", "\n", "[", "node_type", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", ",", "\n", "graph_embed", "]", ",", "dim", "=", "1", ")", ")", "\n", "g", ".", "nodes", "[", "num_nodes", "-", "1", "]", ".", "data", "[", "'hv'", "]", "=", "hv_init", "\n", "g", ".", "nodes", "[", "num_nodes", "-", "1", "]", ".", "data", "[", "'a'", "]", "=", "self", ".", "init_node_activation", "\n", "g", ".", "nodes", "[", "num_nodes", "-", "1", "]", ".", "data", "[", "'label'", "]", "=", "torch", ".", "LongTensor", "(", "[", "[", "node_type", "]", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode.prepare_training": [[194, 201], ["None"], "methods", ["None"], ["", "def", "prepare_training", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function will only be called during training.\n        It stores all log probabilities for AddNode actions.\n        Each element is a tensor of shape [batch_size, 1].\n        \"\"\"", "\n", "self", ".", "log_prob", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode.forward": [[202, 257], ["model.AddNode.add_node", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "enumerate", "model.AddNode.dropout", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "bool", "model.AddNode.log_prob.append", "g_non_stop.append", "g.add_nodes", "model.AddNode._initialize_node_repr", "torch.log_softmax.gather", "torch.log_softmax.gather", "torch.log_softmax.gather", "torch.log_softmax.gather", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode._initialize_node_repr"], ["", "def", "forward", "(", "self", ",", "g_list", ",", "training", ",", "a", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Decide if a new node should be added for each graph in\n        the `g_list`. If a new node is added, initialize its\n        node representations. Record graphs for which a new node\n        is added.\n\n        During training, the action is passed rather than made\n        and the log P of the action is recorded.\n\n        During inference, the action is sampled from a Categorical\n        distribution modeled.\n\n        Parameters\n        ----------\n        g_list : list\n            A list of dgl.DGLGraph objects\n        a : None or list\n            - During training, a is a list of integers specifying\n              type of node to be added (0 for no adding).\n            - During inference, a is None.\n\n        Returns\n        -------\n        g_non_stop : list\n            list of indices to specify which graphs in the\n            g_list have a new node added\n        \"\"\"", "\n", "\n", "# Graphs for which a node is added", "\n", "g_non_stop", "=", "[", "]", "\n", "\n", "batch_graph_embed", "=", "self", ".", "graph_op", "[", "'embed'", "]", "(", "g_list", ")", "\n", "\n", "batch_logit", "=", "self", ".", "add_node", "(", "self", ".", "dropout", "(", "batch_graph_embed", ")", ")", "\n", "batch_log_prob", "=", "torch", ".", "log_softmax", "(", "batch_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "not", "training", ":", "\n", "            ", "a", "=", "Categorical", "(", "logits", "=", "batch_log_prob", ")", ".", "sample", "(", ")", "\n", "\n", "", "for", "i", ",", "g", "in", "enumerate", "(", "g_list", ")", ":", "\n", "            ", "action", "=", "a", "[", "i", "]", "\n", "stop", "=", "bool", "(", "action", "==", "self", ".", "stop", ")", "\n", "\n", "if", "not", "stop", ":", "\n", "                ", "g_non_stop", ".", "append", "(", "g", ".", "index", ")", "\n", "g", ".", "add_nodes", "(", "1", ")", "\n", "self", ".", "_initialize_node_repr", "(", "g", ",", "action", ",", "\n", "batch_graph_embed", "[", "i", ":", "i", "+", "1", ",", ":", "]", ")", "\n", "\n", "", "", "if", "training", ":", "\n", "            ", "self", ".", "log_prob", ".", "append", "(", "batch_log_prob", ".", "gather", "(", "dim", "=", "1", ",", "\n", "index", "=", "torch", ".", "tensor", "(", "a", ",", "device", "=", "self", ".", "device", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", ")", ")", "\n", "\n", "", "return", "g_non_stop", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddEdge.__init__": [[260, 271], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "graph_embed_func", ",", "node_hidden_size", ",", "dropout_prob", ",", "\n", "device", "\n", ")", ":", "\n", "        ", "super", "(", "AddEdge", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "graph_op", "=", "{", "'embed'", ":", "graph_embed_func", "}", "\n", "self", ".", "add_edge", "=", "nn", ".", "Linear", "(", "graph_embed_func", ".", "graph_hidden_size", "+", "\n", "node_hidden_size", ",", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_prob", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddEdge.prepare_training": [[272, 279], ["None"], "methods", ["None"], ["", "def", "prepare_training", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function will only be called during training.\n        It stores all log probabilities for AddEdge actions.\n        Each element is a tensor of shape [batch_size, 1].\n        \"\"\"", "\n", "self", ".", "log_prob", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddEdge.forward": [[280, 333], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.AddEdge.add_edge", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "enumerate", "model.AddEdge.dropout", "torch.distributions.Bernoulli().sample().squeeze().tolist", "torch.distributions.Bernoulli().sample().squeeze().tolist", "torch.distributions.Bernoulli().sample().squeeze().tolist", "torch.distributions.Bernoulli().sample().squeeze().tolist", "model.bernoulli_action_log_prob", "model.AddEdge.log_prob.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "g_to_add_edge.append", "torch.distributions.Bernoulli().sample().squeeze", "torch.distributions.Bernoulli().sample().squeeze", "torch.distributions.Bernoulli().sample().squeeze", "torch.distributions.Bernoulli().sample().squeeze", "torch.distributions.Bernoulli().sample", "torch.distributions.Bernoulli().sample", "torch.distributions.Bernoulli().sample", "torch.distributions.Bernoulli().sample", "g.number_of_nodes", "torch.distributions.Bernoulli", "torch.distributions.Bernoulli", "torch.distributions.Bernoulli", "torch.distributions.Bernoulli"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.bernoulli_action_log_prob"], ["", "def", "forward", "(", "self", ",", "g_list", ",", "training", ",", "a", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Decide if a new edge should be added for each graph in\n        the `g_list`. Record graphs for which a new edge is to\n        be added.\n\n        During training, the action is passed rather than made\n        and the log P of the action is recorded.\n\n        During inference, the action is sampled from a Bernoulli\n        distribution modeled.\n\n        Parameters\n        ----------\n        g_list : list\n            A list of dgl.DGLGraph objects\n        a : None or list\n            - During training, a is a list of integers specifying\n              whether a new edge should be added.\n            - During inference, a is None.\n\n        Returns\n        -------\n        g_to_add_edge : list\n            list of indices to specify which graphs in the\n            g_list need a new edge to be added\n        \"\"\"", "\n", "\n", "# Graphs for which an edge is to be added.", "\n", "g_to_add_edge", "=", "[", "]", "\n", "\n", "batch_graph_embed", "=", "self", ".", "graph_op", "[", "'embed'", "]", "(", "g_list", ")", "\n", "batch_src_embed", "=", "torch", ".", "cat", "(", "[", "g", ".", "nodes", "[", "g", ".", "number_of_nodes", "(", ")", "-", "1", "]", ".", "data", "[", "'hv'", "]", "\n", "for", "g", "in", "g_list", "]", ",", "dim", "=", "0", ")", "\n", "batch_logit", "=", "self", ".", "add_edge", "(", "self", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "batch_graph_embed", ",", "\n", "batch_src_embed", "]", ",", "dim", "=", "1", ")", ")", ")", "\n", "batch_log_prob", "=", "F", ".", "logsigmoid", "(", "batch_logit", ")", "\n", "\n", "if", "not", "training", ":", "\n", "            ", "a", "=", "Bernoulli", "(", "logits", "=", "batch_log_prob", ")", ".", "sample", "(", ")", ".", "squeeze", "(", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "", "for", "i", ",", "g", "in", "enumerate", "(", "g_list", ")", ":", "\n", "            ", "action", "=", "a", "[", "i", "]", "\n", "\n", "if", "action", "==", "1", ":", "\n", "                ", "g_to_add_edge", ".", "append", "(", "g", ".", "index", ")", "\n", "\n", "", "", "if", "training", ":", "\n", "            ", "sample_log_prob", "=", "bernoulli_action_log_prob", "(", "\n", "batch_logit", ",", "a", ",", "self", ".", "device", ")", "\n", "self", ".", "log_prob", ".", "append", "(", "sample_log_prob", ")", "\n", "\n", "", "return", "g_to_add_edge", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.__init__": [[336, 348], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "node_hidden_size", ",", "num_edge_types", ",", "dropout_prob", ",", "device", "\n", ")", ":", "\n", "        ", "super", "(", "ChooseDestAndUpdate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_edge_types", "=", "num_edge_types", "\n", "self", ".", "edge_type_embed", "=", "nn", ".", "Embedding", "(", "num_edge_types", ",", "node_hidden_size", ")", "\n", "\n", "self", ".", "choose_dest", "=", "nn", ".", "Linear", "(", "2", "*", "node_hidden_size", ",", "num_edge_types", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_prob", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate._initialize_edge_repr": [[349, 355], ["model.ChooseDestAndUpdate.edge_type_embed", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "_initialize_edge_repr", "(", "self", ",", "g", ",", "src_list", ",", "dest_list", ",", "edge_types", ")", ":", "\n", "# For multiple edge types, we use an embedding module.", "\n", "        ", "edge_repr", "=", "self", ".", "edge_type_embed", "(", "\n", "torch", ".", "LongTensor", "(", "edge_types", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "g", ".", "edges", "[", "src_list", ",", "dest_list", "]", ".", "data", "[", "'he'", "]", "=", "edge_repr", "\n", "g", ".", "edges", "[", "src_list", ",", "dest_list", "]", ".", "data", "[", "'label'", "]", "=", "torch", ".", "LongTensor", "(", "edge_types", ")", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.prepare_training": [[356, 363], ["None"], "methods", ["None"], ["", "def", "prepare_training", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function will only be called during training.\n        It stores all log probabilities for ChooseDest actions.\n        Each element is a tensor of shape [1, 1].\n        \"\"\"", "\n", "self", ".", "log_prob", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.forward": [[364, 422], ["enumerate", "range", "g.nodes[].data[].expand", "model.ChooseDestAndUpdate.choose_dest().view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "g.number_of_nodes", "torch.distributions.Categorical().sample().item", "torch.distributions.Categorical().sample().item", "torch.distributions.Categorical().sample().item", "torch.distributions.Categorical().sample().item", "g.has_edges_between", "g.add_edges", "model.ChooseDestAndUpdate._initialize_edge_repr", "model.ChooseDestAndUpdate.choose_dest", "torch.log_softmax.nelement", "model.ChooseDestAndUpdate.log_prob.append", "model.ChooseDestAndUpdate.dropout", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "torch.distributions.Categorical().sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate._initialize_edge_repr"], ["", "def", "forward", "(", "self", ",", "g_list", ",", "training", ",", "d", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        For each g in g_list, add an edge (src, dest)\n        if (src, dst) does not exist. The src is just the latest\n        node in g. Initialize edge features if new edges are added.\n\n        During training, dst is passed rather than chosen and the\n        log P of the action is recorded.\n\n        During inference, dst is sampled from a Categorical\n        distribution modeled.\n\n        Parameters\n        ----------\n        g_list : list\n            A list of dgl.DGLGraph objects\n        d : None or list\n            - During training, d is a list of tuple of integers specifying dst \n              (node_index, edge_type) in encoded integer = node_index * num_edge_types + edge_type\n              for each graph in g_list.\n            - During inference, d is None.\n        \"\"\"", "\n", "\n", "for", "i", ",", "g", "in", "enumerate", "(", "g_list", ")", ":", "\n", "            ", "src", "=", "g", ".", "number_of_nodes", "(", ")", "-", "1", "\n", "possible_dests", "=", "range", "(", "src", ")", "\n", "\n", "src_embed_expand", "=", "g", ".", "nodes", "[", "src", "]", ".", "data", "[", "'hv'", "]", ".", "expand", "(", "src", ",", "-", "1", ")", "\n", "possible_dests_embed", "=", "g", ".", "nodes", "[", "possible_dests", "]", ".", "data", "[", "'hv'", "]", "\n", "\n", "dests_scores", "=", "self", ".", "choose_dest", "(", "self", ".", "dropout", "(", "\n", "torch", ".", "cat", "(", "[", "possible_dests_embed", ",", "\n", "src_embed_expand", "]", ",", "dim", "=", "1", ")", ")", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "dests_log_probs", "=", "F", ".", "log_softmax", "(", "dests_scores", ",", "dim", "=", "1", ")", "\n", "\n", "if", "not", "training", ":", "\n", "                ", "dest_enc", "=", "Categorical", "(", "logits", "=", "dests_log_probs", ")", ".", "sample", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "dest_enc", "=", "d", "[", "i", "]", "\n", "\n", "", "dest", "=", "dest_enc", "//", "self", ".", "num_edge_types", "\n", "edge_type", "=", "dest_enc", "%", "self", ".", "num_edge_types", "\n", "\n", "# Note that we are not considering multigraph here.", "\n", "if", "not", "g", ".", "has_edges_between", "(", "src", ",", "dest", ")", ":", "\n", "# For undirected graphs, we add edges for both", "\n", "# directions so that we can perform graph propagation.", "\n", "                ", "src_list", "=", "[", "src", ",", "dest", "]", "\n", "dest_list", "=", "[", "dest", ",", "src", "]", "\n", "edge_types", "=", "[", "edge_type", ",", "edge_type", "]", "\n", "\n", "g", ".", "add_edges", "(", "src_list", ",", "dest_list", ")", "\n", "self", ".", "_initialize_edge_repr", "(", "g", ",", "src_list", ",", "dest_list", ",", "edge_types", ")", "\n", "\n", "", "if", "training", ":", "\n", "                ", "if", "dests_log_probs", ".", "nelement", "(", ")", ">", "1", ":", "\n", "                    ", "self", ".", "log_prob", ".", "append", "(", "\n", "F", ".", "log_softmax", "(", "dests_scores", ",", "dim", "=", "1", ")", "[", ":", ",", "dest_enc", ":", "dest_enc", "+", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__": [[425, 458], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.Module.__init__", "GraphEmbed().to", "model.GraphProp", "AddNode().to", "AddEdge().to", "ChooseDestAndUpdate().to", "model.DGMG.init_weights", "model.GraphEmbed", "model.AddNode", "model.AddEdge", "model.ChooseDestAndUpdate"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.__init__", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "v_max", ",", "node_hidden_size", ",", "num_prop_rounds", ",", "\n", "dropout_prob", ",", "num_node_types", ",", "num_edge_types", ",", "device", "=", "torch", ".", "device", "(", "\n", "'cpu'", ")", "\n", ")", ":", "\n", "        ", "super", "(", "DGMG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Graph configuration", "\n", "self", ".", "v_max", "=", "v_max", "\n", "\n", "# Torch device", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Graph embedding module", "\n", "self", ".", "graph_embed", "=", "GraphEmbed", "(", "\n", "node_hidden_size", ",", "device", "=", "self", ".", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "# Graph propagation module", "\n", "self", ".", "graph_prop", "=", "GraphProp", "(", "num_prop_rounds", ",", "\n", "node_hidden_size", ")", "\n", "\n", "# Actions", "\n", "self", ".", "add_node_agent", "=", "AddNode", "(", "\n", "self", ".", "graph_embed", ",", "node_hidden_size", ",", "num_node_types", ",", "dropout_prob", ",", "\n", "self", ".", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "add_edge_agent", "=", "AddEdge", "(", "\n", "self", ".", "graph_embed", ",", "node_hidden_size", ",", "dropout_prob", ",", "\n", "self", ".", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "choose_dest_agent", "=", "ChooseDestAndUpdate", "(", "\n", "node_hidden_size", ",", "num_edge_types", ",", "dropout_prob", ",", "self", ".", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "# Weight initialization", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.init_weights": [[459, 467], ["model.DGMG.graph_embed.apply", "model.DGMG.graph_prop.apply", "model.DGMG.add_node_agent.apply", "model.DGMG.add_edge_agent.apply", "model.DGMG.choose_dest_agent.apply", "model.DGMG.graph_prop.message_funcs.apply"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "graph_embed", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "graph_prop", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "add_node_agent", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "add_edge_agent", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "choose_dest_agent", ".", "apply", "(", "weights_init", ")", "\n", "\n", "self", ".", "graph_prop", ".", "message_funcs", ".", "apply", "(", "dgmg_message_weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.prepare": [[468, 490], ["list", "range", "range", "dgl.graph().to", "dgl.graph().to.set_n_initializer", "dgl.graph().to.set_e_initializer", "model.DGMG.g_list.append", "model.DGMG.add_node_agent.prepare_training", "model.DGMG.add_edge_agent.prepare_training", "model.DGMG.choose_dest_agent.prepare_training", "dgl.graph"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.prepare_training", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.prepare_training", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate.prepare_training"], ["", "def", "prepare", "(", "self", ",", "batch_size", ",", "training", ")", ":", "\n", "# Track how many actions have been taken for each graph.", "\n", "        ", "self", ".", "step_count", "=", "[", "0", "]", "*", "batch_size", "\n", "self", ".", "g_list", "=", "[", "]", "\n", "# indices for graphs being generated", "\n", "self", ".", "g_active", "=", "list", "(", "range", "(", "batch_size", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "g", "=", "dgl", ".", "graph", "(", "(", "(", ")", ",", "(", ")", ")", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "g", ".", "index", "=", "i", "\n", "\n", "# If there are some features for nodes and edges,", "\n", "# zero tensors will be set for those of new nodes and edges.", "\n", "g", ".", "set_n_initializer", "(", "dgl", ".", "frame", ".", "zero_initializer", ")", "\n", "g", ".", "set_e_initializer", "(", "dgl", ".", "frame", ".", "zero_initializer", ")", "\n", "\n", "self", ".", "g_list", ".", "append", "(", "g", ")", "\n", "\n", "", "if", "training", ":", "\n", "            ", "self", ".", "add_node_agent", ".", "prepare_training", "(", ")", "\n", "self", ".", "add_edge_agent", ".", "prepare_training", "(", ")", "\n", "self", ".", "choose_dest_agent", ".", "prepare_training", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG._get_graphs": [[491, 493], ["None"], "methods", ["None"], ["", "", "def", "_get_graphs", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "[", "self", ".", "g_list", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_action_step": [[494, 510], ["old_step_count.append"], "methods", ["None"], ["", "def", "get_action_step", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"\n        This function should only be called during training.\n\n        Collect the number of actions taken for each graph\n        whose index is in the indices. After collecting\n        the number of actions, increment it by 1.\n        \"\"\"", "\n", "\n", "old_step_count", "=", "[", "]", "\n", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "old_step_count", ".", "append", "(", "self", ".", "step_count", "[", "i", "]", ")", "\n", "self", ".", "step_count", "[", "i", "]", "+=", "1", "\n", "\n", "", "return", "old_step_count", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions": [[511, 539], ["model.DGMG.get_action_step", "enumerate", "actions_t.append", "ValueError"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_action_step"], ["", "def", "get_actions", "(", "self", ",", "mode", ")", ":", "\n", "        ", "\"\"\"\n        This function should only be called during training.\n\n        Decide which graphs are related with the next batched\n        decision and extract the actions to take for each of\n        the graph.\n        \"\"\"", "\n", "\n", "if", "mode", "==", "'node'", ":", "\n", "# Graphs being generated", "\n", "            ", "indices", "=", "self", ".", "g_active", "\n", "", "elif", "mode", "==", "'edge'", ":", "\n", "# Graphs having more edges to be added", "\n", "# starting from the latest node.", "\n", "            ", "indices", "=", "self", ".", "g_to_add_edge", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected mode to be in ['node', 'edge'], \"", "\n", "\"got {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "action_indices", "=", "self", ".", "get_action_step", "(", "indices", ")", "\n", "# Actions for all graphs indexed by indices at timestep t", "\n", "actions_t", "=", "[", "]", "\n", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "indices", ")", ":", "\n", "            ", "actions_t", ".", "append", "(", "self", ".", "actions", "[", "j", "]", "[", "action_indices", "[", "i", "]", "]", ")", "\n", "\n", "", "return", "actions_t", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_node_and_update": [[540, 557], ["model.DGMG._get_graphs", "model.DGMG.add_node_agent", "len"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG._get_graphs"], ["", "def", "add_node_and_update", "(", "self", ",", "training", ",", "a", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Decide if to add a new node for each graph being generated.\n        If a new node should be added, update the graph.\n\n        The action(s) a are passed during training and\n        sampled (hence None) during inference.\n        \"\"\"", "\n", "g_list", "=", "self", ".", "_get_graphs", "(", "self", ".", "g_active", ")", "\n", "g_non_stop", "=", "self", ".", "add_node_agent", "(", "g_list", ",", "training", ",", "a", ")", "\n", "\n", "self", ".", "g_active", "=", "g_non_stop", "\n", "# For all newly added nodes we need to decide", "\n", "# if an edge is to be added for each of them.", "\n", "self", ".", "g_to_add_edge", "=", "g_non_stop", "\n", "\n", "return", "len", "(", "self", ".", "g_active", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_edge_or_not": [[558, 571], ["model.DGMG._get_graphs", "model.DGMG.add_edge_agent", "len"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG._get_graphs"], ["", "def", "add_edge_or_not", "(", "self", ",", "training", ",", "a", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Decide if a new edge should be added for each\n        graph that may need one more edge.\n\n        The action(s) a are passed during training and\n        sampled (hence None) during inference.\n        \"\"\"", "\n", "g_list", "=", "self", ".", "_get_graphs", "(", "self", ".", "g_to_add_edge", ")", "\n", "g_to_add_edge", "=", "self", ".", "add_edge_agent", "(", "g_list", ",", "training", ",", "a", ")", "\n", "self", ".", "g_to_add_edge", "=", "g_to_add_edge", "\n", "\n", "return", "len", "(", "self", ".", "g_to_add_edge", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.choose_dest_and_update": [[572, 590], ["model.DGMG._get_graphs", "model.DGMG.choose_dest_agent", "model.DGMG.graph_prop", "enumerate"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG._get_graphs"], ["", "def", "choose_dest_and_update", "(", "self", ",", "training", ",", "a", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        For each graph that requires one more edge, choose\n        destination and connect it to the latest node.\n        Add edges for both directions and update the graph.\n\n        The action(s) a are passed during training and\n        sampled (hence None) during inference.\n        \"\"\"", "\n", "g_list", "=", "self", ".", "_get_graphs", "(", "self", ".", "g_to_add_edge", ")", "\n", "self", ".", "choose_dest_agent", "(", "g_list", ",", "training", ",", "a", ")", "\n", "\n", "# Graph propagation and update node features.", "\n", "updated_g_list", "=", "self", ".", "graph_prop", "(", "g_list", ")", "\n", "\n", "for", "i", ",", "g", "in", "enumerate", "(", "updated_g_list", ")", ":", "\n", "            ", "g", ".", "index", "=", "self", ".", "g_to_add_edge", "[", "i", "]", "\n", "self", ".", "g_list", "[", "g", ".", "index", "]", "=", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_log_prob": [[591, 597], ["torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat().sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "get_log_prob", "(", "self", ")", ":", "\n", "        ", "log_prob", "=", "torch", ".", "cat", "(", "self", ".", "add_node_agent", ".", "log_prob", ")", ".", "sum", "(", ")", "+", "torch", ".", "cat", "(", "self", ".", "add_edge_agent", ".", "log_prob", ")", ".", "sum", "(", ")", "+", "torch", ".", "cat", "(", "self", ".", "choose_dest_agent", ".", "log_prob", ")", ".", "sum", "(", ")", "\n", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_train": [[598, 634], ["model.DGMG.add_node_and_update", "model.DGMG.get_log_prob", "model.DGMG.add_edge_or_not", "model.DGMG.add_node_and_update", "model.DGMG.get_actions", "model.DGMG.choose_dest_and_update", "model.DGMG.add_edge_or_not", "model.DGMG.get_actions", "model.DGMG.get_actions", "model.DGMG.get_actions", "model.DGMG.get_actions"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_node_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_log_prob", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_edge_or_not", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_node_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.choose_dest_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_edge_or_not", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.get_actions"], ["", "def", "forward_train", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Go through all decisions in actions and record their\n        log probabilities for calculating the loss.\n\n        Parameters\n        ----------\n        actions : list\n            list of decisions extracted for generating a graph using DGMG\n\n        Returns\n        -------\n        tensor of shape torch.Size([])\n            log P(Generate a batch of graphs using DGMG)\n        \"\"\"", "\n", "self", ".", "actions", "=", "actions", "\n", "\n", "stop", "=", "self", ".", "add_node_and_update", "(", "\n", "training", "=", "True", ",", "a", "=", "self", ".", "get_actions", "(", "'node'", ")", ")", "\n", "\n", "# Some graphs haven't been completely generated.", "\n", "while", "not", "stop", ":", "\n", "            ", "to_add_edge", "=", "self", ".", "add_edge_or_not", "(", "\n", "training", "=", "True", ",", "a", "=", "self", ".", "get_actions", "(", "'edge'", ")", ")", "\n", "\n", "# Some graphs need more edges to be added for the latest node.", "\n", "while", "to_add_edge", ":", "\n", "                ", "self", ".", "choose_dest_and_update", "(", "\n", "training", "=", "True", ",", "a", "=", "self", ".", "get_actions", "(", "'edge'", ")", ")", "\n", "to_add_edge", "=", "self", ".", "add_edge_or_not", "(", "\n", "training", "=", "True", ",", "a", "=", "self", ".", "get_actions", "(", "'edge'", ")", ")", "\n", "\n", "", "stop", "=", "self", ".", "add_node_and_update", "(", "\n", "training", "=", "True", ",", "a", "=", "self", ".", "get_actions", "(", "'node'", ")", ")", "\n", "\n", "", "return", "self", ".", "get_log_prob", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_inference": [[635, 665], ["model.DGMG.add_node_and_update", "model.DGMG.add_edge_or_not", "model.DGMG.add_node_and_update", "model.DGMG.g_list[].number_of_nodes", "model.DGMG.choose_dest_and_update", "model.DGMG.add_edge_or_not", "model.DGMG.g_list[].number_of_nodes"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_node_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_edge_or_not", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_node_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.choose_dest_and_update", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.add_edge_or_not"], ["", "def", "forward_inference", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate graph(s) on the fly.\n\n        Returns\n        -------\n        self.g_list : list\n            A list of dgl.DGLGraph objects.\n        \"\"\"", "\n", "stop", "=", "self", ".", "add_node_and_update", "(", "training", "=", "False", ")", "\n", "\n", "# Some graphs haven't been completely generated and their numbers of", "\n", "# nodes do not exceed the limit of self.v_max.", "\n", "while", "(", "not", "stop", ")", "and", "(", "self", ".", "g_list", "[", "self", ".", "g_active", "[", "0", "]", "]", ".", "number_of_nodes", "(", ")", "\n", "<", "self", ".", "v_max", "+", "1", ")", ":", "\n", "            ", "num_trials", "=", "0", "\n", "to_add_edge", "=", "self", ".", "add_edge_or_not", "(", "training", "=", "False", ")", "\n", "\n", "# Some graphs need more edges to be added for the latest node and", "\n", "# the number of trials does not exceed the number of maximum possible", "\n", "# edges. Note that this limit on the number of edges eliminate the", "\n", "# possibility of multi-graph and one may want to remove it.", "\n", "while", "to_add_edge", "and", "(", "num_trials", "<", "\n", "self", ".", "g_list", "[", "self", ".", "g_active", "[", "0", "]", "]", ".", "number_of_nodes", "(", ")", "-", "1", ")", ":", "\n", "                ", "self", ".", "choose_dest_and_update", "(", "training", "=", "False", ")", "\n", "num_trials", "+=", "1", "\n", "to_add_edge", "=", "self", ".", "add_edge_or_not", "(", "training", "=", "False", ")", "\n", "", "stop", "=", "self", ".", "add_node_and_update", "(", "training", "=", "False", ")", "\n", "\n", "", "return", "self", ".", "g_list", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_inference_with_starting_nodes": [[666, 697], ["model.DGMG.graph_embed", "enumerate", "model.DGMG.forward_inference", "range", "g.add_nodes", "model.DGMG.add_node_agent._initialize_node_repr", "g.add_edges", "model.DGMG.choose_dest_agent._initialize_edge_repr", "len"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_inference", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.AddNode._initialize_node_repr", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.ChooseDestAndUpdate._initialize_edge_repr"], ["", "def", "forward_inference_with_starting_nodes", "(", "self", ",", "starting_node_ids", ")", ":", "\n", "        ", "\"\"\"\n        Generate graph(s) on the fly starting with the provided list of nodes.\n        \n        Returns\n        -------\n        self.g_list : list\n            A list of dgl.DGLGraph objects.\n        \"\"\"", "\n", "# first add the starting nodes and the edges between them", "\n", "batch_graph_embed", "=", "self", ".", "graph_embed", "(", "self", ".", "g_list", ")", "\n", "for", "idx", ",", "g", "in", "enumerate", "(", "self", ".", "g_list", ")", ":", "\n", "# 1. add all nodes", "\n", "            ", "for", "node_id", "in", "starting_node_ids", ":", "\n", "                ", "g", ".", "add_nodes", "(", "1", ")", "\n", "self", ".", "add_node_agent", ".", "_initialize_node_repr", "(", "g", ",", "\n", "node_type", "=", "node_id", ",", "\n", "graph_embed", "=", "batch_graph_embed", "[", "idx", ":", "idx", "+", "1", ",", ":", "]", ")", "\n", "# 2. add edges between consecutive nodes.", "\n", "# NOTE: the original implementation adds two edges (i.e. undirected) to allow message passing. ", "\n", "# Maybe we want to change this?", "\n", "", "for", "i", "in", "range", "(", "len", "(", "starting_node_ids", ")", "-", "1", ")", ":", "\n", "# add edge between i and i + 1", "\n", "                ", "src_list", "=", "[", "i", ",", "i", "+", "1", "]", "\n", "dest_list", "=", "[", "i", "+", "1", ",", "i", "]", "\n", "edge_types", "=", "[", "0", ",", "0", "]", "# TODO: are all edges flowsTo? ", "\n", "g", ".", "add_edges", "(", "src_list", ",", "dest_list", ")", "\n", "self", ".", "choose_dest_agent", ".", "_initialize_edge_repr", "(", "g", ",", "src_list", ",", "dest_list", ",", "edge_types", ")", "\n", "\n", "# now the starting nodes are added, continue the generation process like normal", "\n", "", "", "return", "self", ".", "forward_inference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward": [[699, 712], ["model.DGMG.prepare", "len", "model.DGMG.forward_train", "model.DGMG.forward_inference_with_starting_nodes", "model.DGMG.forward_inference"], "methods", ["home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.prepare", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_train", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_inference_with_starting_nodes", "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.DGMG.forward_inference"], ["", "def", "forward", "(", "self", ",", "batch_size", "=", "32", ",", "actions", "=", "None", ",", "training", "=", "True", ",", "starting_node_ids", "=", "None", ")", ":", "\n", "        ", "if", "training", ":", "\n", "            ", "batch_size", "=", "len", "(", "actions", ")", "\n", "\n", "", "self", ".", "prepare", "(", "batch_size", ",", "training", ")", "\n", "\n", "if", "training", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "actions", ")", "\n", "", "else", ":", "\n", "            ", "if", "starting_node_ids", ":", "\n", "                ", "return", "self", ".", "forward_inference_with_starting_nodes", "(", "starting_node_ids", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "forward_inference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.weights_init": [[14, 30], ["isinstance", "torch.xavier_normal_", "torch.normal_", "isinstance", "m.parameters", "len", "torch.orthogonal_", "torch.normal_"], "function", ["None"], ["def", "weights_init", "(", "m", ")", ":", "\n", "    ", "'''\n    Code from https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5\n    Usage:\n        model = Model()\n        model.apply(weight_init)\n    '''", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "init", ".", "normal_", "(", "m", ".", "bias", ".", "data", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "GRUCell", ")", ":", "\n", "        ", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "len", "(", "param", ".", "shape", ")", ">=", "2", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "param", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "init", ".", "normal_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.dgmg_message_weight_init": [[32, 50], ["isinstance", "isinstance", "m.apply", "torch.normal_", "torch.normal_", "ValueError", "layer.apply"], "function", ["None"], ["", "", "", "", "def", "dgmg_message_weight_init", "(", "m", ")", ":", "\n", "    ", "\"\"\"\n    This is similar as the function above where we initialize linear layers from a normal distribution with std\n    1./10 as suggested by the author. This should only be used for the message passing functions, i.e. fe's in the\n    paper.\n    \"\"\"", "\n", "def", "_weight_init", "(", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "std", "=", "1.", "/", "10", ")", "\n", "init", ".", "normal_", "(", "m", ".", "bias", ".", "data", ",", "std", "=", "1.", "/", "10", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Expected the input to be of type nn.Linear!'", ")", "\n", "\n", "", "", "if", "isinstance", "(", "m", ",", "nn", ".", "ModuleList", ")", ":", "\n", "        ", "for", "layer", "in", "m", ":", "\n", "            ", "layer", ".", "apply", "(", "_weight_init", ")", "\n", "", "", "else", ":", "\n", "        ", "m", ".", "apply", "(", "_weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.bernoulli_action_log_prob": [[145, 153], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.gather", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.logsigmoid", "torch.logsigmoid", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "", "def", "bernoulli_action_log_prob", "(", "logit", ",", "action", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the log p of an action with respect to a Bernoulli\n    distribution across a batch of actions. Use logit rather than\n    prob for numerical stability.\n    \"\"\"", "\n", "log_probs", "=", "torch", ".", "cat", "(", "[", "F", ".", "logsigmoid", "(", "-", "logit", ")", ",", "F", ".", "logsigmoid", "(", "logit", ")", "]", ",", "dim", "=", "1", ")", "\n", "return", "log_probs", ".", "gather", "(", "1", ",", "torch", ".", "tensor", "(", "action", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cods-gcs_kgpip-public.graph_generation_model.model.create_model": [[714, 723], ["DGMG().to", "model.DGMG", "len", "len"], "function", ["None"], ["", "", "", "", "def", "create_model", "(", "args", ",", "feature_map", ")", ":", "\n", "    ", "generator", "=", "DGMG", "(", "v_max", "=", "feature_map", "[", "'max_nodes'", "]", ",", "node_hidden_size", "=", "args", ".", "feat_size", ",", "\n", "num_prop_rounds", "=", "args", ".", "hops", ",", "num_node_types", "=", "len", "(", "\n", "feature_map", "[", "'node_forward'", "]", ")", ",", "\n", "num_edge_types", "=", "len", "(", "feature_map", "[", "'edge_forward'", "]", ")", ",", "dropout_prob", "=", "args", ".", "dropout", ",", "\n", "device", "=", "args", ".", "device", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "\n", "return", "{", "\n", "'generator'", ":", "generator", "\n", "}", "\n"]]}