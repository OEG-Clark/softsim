{"home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizer.__init__": [[12, 24], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", ",", "d_model", ",", "commitment_cost", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", "SequenceQuantizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "codebook_size", "=", "codebook_size", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "self", ".", "codebook", "=", "nn", ".", "Embedding", "(", "self", ".", "codebook_size", ",", "self", ".", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "codebook", ".", "weight", ".", "data", "[", "padding_idx", "]", "=", "0", "\n", "\n", "", "self", ".", "commitment_cost", "=", "commitment_cost", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizer.forward": [[25, 76], ["inputs.size", "inputs.dim", "inputs.reshape", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.argmin().unsqueeze.reshape", "torch.argmin().unsqueeze.reshape", "torch.argmin().unsqueeze.reshape", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "quantizers.SequenceQuantizer.codebook.weight.t", "padding_mask.reshape().expand", "padding_mask.reshape", "torch.matmul().view.detach", "torch.matmul().view.detach", "torch.matmul().view.detach", "inputs.detach", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "padding_mask.reshape", "torch.matmul().view.detach", "torch.matmul().view.detach", "torch.matmul().view.detach", "inputs.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "commitment_cost", "=", "None", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "\n", "if", "commitment_cost", "is", "None", ":", "\n", "            ", "commitment_cost", "=", "self", ".", "commitment_cost", "\n", "\n", "# inputs can be:", "\n", "# 2-dimensional [B x E]         (already flattened)", "\n", "# 3-dimensional [B x T x E]     (e.g., batch of sentences)", "\n", "# 4-dimensional [B x S x T x E] (e.g., batch of documents)", "\n", "", "input_shape", "=", "inputs", ".", "size", "(", ")", "\n", "input_dims", "=", "inputs", ".", "dim", "(", ")", "\n", "\n", "# Flatten input", "\n", "flat_input", "=", "inputs", ".", "reshape", "(", "-", "1", ",", "self", ".", "d_model", ")", "\n", "\n", "# Calculate distances", "\n", "distances", "=", "(", "torch", ".", "sum", "(", "flat_input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "+", "torch", ".", "sum", "(", "self", ".", "codebook", ".", "weight", "**", "2", ",", "dim", "=", "1", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "flat_input", ",", "self", ".", "codebook", ".", "weight", ".", "t", "(", ")", ")", ")", "\n", "\n", "# TODO: generalize this to any padding_idx", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "# no normal token gets mapped to discrete value 0", "\n", "            ", "distances", "[", ":", ",", "0", "]", "[", "~", "padding_mask", ".", "reshape", "(", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "# all pad tokens get mapped to discrete value 0", "\n", "distances", "[", ":", ",", "1", ":", "]", "[", "padding_mask", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "self", ".", "codebook_size", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "\n", "# Encoding", "\n", "", "encoding_indices", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "encodings", "=", "torch", ".", "zeros", "(", "encoding_indices", ".", "shape", "[", "0", "]", ",", "self", ".", "codebook_size", ")", ".", "to", "(", "device", ")", "\n", "encodings", ".", "scatter_", "(", "1", ",", "encoding_indices", ",", "1", ")", "\n", "\n", "# Quantize and unflatten", "\n", "quantized", "=", "torch", ".", "matmul", "(", "encodings", ",", "self", ".", "codebook", ".", "weight", ")", ".", "view", "(", "input_shape", ")", "\n", "\n", "# Loss", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "num_nonpad_elements", "=", "torch", ".", "sum", "(", "~", "padding_mask", ")", "*", "self", ".", "d_model", "\n", "e_latent_loss", "=", "torch", ".", "sum", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "/", "num_nonpad_elements", "\n", "q_latent_loss", "=", "torch", ".", "sum", "(", "(", "quantized", "-", "inputs", ".", "detach", "(", ")", ")", "**", "2", ")", "/", "num_nonpad_elements", "\n", "", "else", ":", "\n", "            ", "e_latent_loss", "=", "torch", ".", "mean", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "\n", "q_latent_loss", "=", "torch", ".", "mean", "(", "(", "quantized", "-", "inputs", ".", "detach", "(", ")", ")", "**", "2", ")", "\n", "", "loss", "=", "q_latent_loss", "+", "commitment_cost", "*", "e_latent_loss", "\n", "\n", "quantized", "=", "inputs", "+", "(", "quantized", "-", "inputs", ")", ".", "detach", "(", ")", "\n", "avg_probs", "=", "torch", ".", "mean", "(", "encodings", ",", "dim", "=", "0", ")", "\n", "perplexity", "=", "torch", ".", "exp", "(", "-", "torch", ".", "sum", "(", "avg_probs", "*", "torch", ".", "log", "(", "avg_probs", "+", "1e-10", ")", ")", ")", "\n", "\n", "return", "quantized", ",", "encoding_indices", ".", "reshape", "(", "input_shape", "[", ":", "input_dims", "-", "1", "]", ")", ",", "loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizer.set_codebook": [[77, 79], ["quantizers.SequenceQuantizer.codebook.weight.copy_"], "methods", ["None"], ["", "def", "set_codebook", "(", "self", ",", "new_codebook", ")", ":", "\n", "        ", "self", ".", "codebook", ".", "weight", ".", "copy_", "(", "new_codebook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerEMA.__init__": [[82, 102], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "quantizers.SequenceQuantizerEMA.register_buffer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "quantizers.SequenceQuantizerEMA._ema_w.data.copy_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", ",", "d_model", ",", "commitment_cost", ",", "decay", "=", "0.99", ",", "epsilon", "=", "1e-5", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", "SequenceQuantizerEMA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "codebook_size", "=", "codebook_size", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "self", ".", "codebook", "=", "nn", ".", "Embedding", "(", "self", ".", "codebook_size", ",", "self", ".", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "codebook", ".", "weight", ".", "data", "[", "padding_idx", "]", "=", "0", "\n", "\n", "", "self", ".", "commitment_cost", "=", "commitment_cost", "\n", "\n", "self", ".", "register_buffer", "(", "'_ema_cluster_size'", ",", "torch", ".", "zeros", "(", "codebook_size", ")", ")", "\n", "self", ".", "_ema_w", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "codebook_size", ",", "self", ".", "d_model", ")", ")", "\n", "self", ".", "_ema_w", ".", "data", ".", "copy_", "(", "self", ".", "codebook", ".", "weight", ".", "data", ")", "\n", "\n", "self", ".", "_decay", "=", "decay", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerEMA.forward": [[103, 178], ["inputs.size", "inputs.dim", "inputs.reshape", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.argmin().unsqueeze.reshape", "torch.argmin().unsqueeze.reshape", "torch.argmin().unsqueeze.reshape", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.zeros().to.t", "torch.zeros().to.t", "torch.zeros().to.t", "quantizers.SequenceQuantizerEMA._ema_cluster_size.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "quantizers.SequenceQuantizerEMA.codebook.weight.t", "padding_mask.reshape().expand", "padding_mask.reshape", "torch.matmul().view.detach", "torch.matmul().view.detach", "torch.matmul().view.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "padding_mask.reshape", "torch.matmul().view.detach", "torch.matmul().view.detach", "torch.matmul().view.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "commitment_cost", "=", "None", ",", "temp", "=", "None", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "\n", "if", "commitment_cost", "is", "None", ":", "\n", "            ", "commitment_cost", "=", "self", ".", "commitment_cost", "\n", "\n", "", "if", "temp", "is", "None", ":", "\n", "            ", "temp", "=", "self", ".", "temp", "\n", "\n", "# inputs can be:", "\n", "# 2-dimensional [B x E]         (already flattened)", "\n", "# 3-dimensional [B x T x E]     (e.g., batch of sentences)", "\n", "# 4-dimensional [B x S x T x E] (e.g., batch of documents)", "\n", "", "input_shape", "=", "inputs", ".", "size", "(", ")", "\n", "input_dims", "=", "inputs", ".", "dim", "(", ")", "\n", "\n", "# Flatten input", "\n", "flat_input", "=", "inputs", ".", "reshape", "(", "-", "1", ",", "self", ".", "d_model", ")", "\n", "\n", "# Calculate distances", "\n", "distances", "=", "(", "torch", ".", "sum", "(", "flat_input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "+", "torch", ".", "sum", "(", "self", ".", "codebook", ".", "weight", "**", "2", ",", "dim", "=", "1", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "flat_input", ",", "self", ".", "codebook", ".", "weight", ".", "t", "(", ")", ")", ")", "\n", "\n", "# TODO: generalize this to any padding_idx", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "# no normal token gets mapped to discrete value 0", "\n", "            ", "distances", "[", ":", ",", "0", "]", "[", "~", "padding_mask", ".", "reshape", "(", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "# all pad tokens get mapped to discrete value 0", "\n", "distances", "[", ":", ",", "1", ":", "]", "[", "padding_mask", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "self", ".", "codebook_size", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "\n", "# Encoding", "\n", "", "encoding_indices", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "encodings", "=", "torch", ".", "zeros", "(", "encoding_indices", ".", "shape", "[", "0", "]", ",", "self", ".", "codebook_size", ")", ".", "to", "(", "device", ")", "\n", "encodings", ".", "scatter_", "(", "1", ",", "encoding_indices", ",", "1", ")", "\n", "\n", "# Quantize and unflatten", "\n", "quantized", "=", "torch", ".", "matmul", "(", "encodings", ",", "self", ".", "codebook", ".", "weight", ")", ".", "view", "(", "input_shape", ")", "\n", "\n", "# Loss", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "num_nonpad_elements", "=", "torch", ".", "sum", "(", "~", "padding_mask", ")", "*", "self", ".", "d_model", "\n", "e_latent_loss", "=", "torch", ".", "sum", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "/", "num_nonpad_elements", "\n", "", "else", ":", "\n", "            ", "e_latent_loss", "=", "torch", ".", "mean", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "\n", "", "loss", "=", "commitment_cost", "*", "e_latent_loss", "\n", "\n", "# Use EMA to update the embedding vectors", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "discard_ema_cluster_sizes", ":", "\n", "                ", "self", ".", "_ema_cluster_size", "=", "torch", ".", "sum", "(", "encodings", ",", "0", ")", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "False", "\n", "", "else", ":", "\n", "                ", "self", ".", "_ema_cluster_size", "=", "self", ".", "_ema_cluster_size", "*", "self", ".", "_decay", "+", "(", "1", "-", "self", ".", "_decay", ")", "*", "torch", ".", "sum", "(", "encodings", ",", "0", ")", "\n", "\n", "# Laplace smoothing of the cluster size", "\n", "", "n", "=", "torch", ".", "sum", "(", "self", ".", "_ema_cluster_size", ".", "data", ")", "\n", "self", ".", "_ema_cluster_size", "=", "(", "\n", "(", "self", ".", "_ema_cluster_size", "+", "self", ".", "_epsilon", ")", "\n", "/", "(", "n", "+", "self", ".", "codebook_size", "*", "self", ".", "_epsilon", ")", "*", "n", ")", "\n", "\n", "dw", "=", "torch", ".", "matmul", "(", "encodings", ".", "t", "(", ")", ",", "flat_input", ")", "\n", "self", ".", "_ema_w", "=", "nn", ".", "Parameter", "(", "self", ".", "_ema_w", "*", "self", ".", "_decay", "+", "(", "1", "-", "self", ".", "_decay", ")", "*", "dw", ")", "\n", "\n", "normalized_ema_w", "=", "self", ".", "_ema_w", "/", "self", ".", "_ema_cluster_size", ".", "unsqueeze", "(", "1", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "normalized_ema_w", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "", "self", ".", "codebook", ".", "weight", "=", "nn", ".", "Parameter", "(", "normalized_ema_w", ")", "\n", "\n", "", "quantized", "=", "inputs", "+", "(", "quantized", "-", "inputs", ")", ".", "detach", "(", ")", "\n", "avg_probs", "=", "torch", ".", "mean", "(", "encodings", ",", "dim", "=", "0", ")", "\n", "perplexity", "=", "torch", ".", "exp", "(", "-", "torch", ".", "sum", "(", "avg_probs", "*", "torch", ".", "log", "(", "avg_probs", "+", "1e-10", ")", ")", ")", "\n", "\n", "return", "quantized", ",", "encoding_indices", ".", "reshape", "(", "input_shape", "[", ":", "input_dims", "-", "1", "]", ")", ",", "loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerEMA.set_codebook": [[179, 183], ["quantizers.SequenceQuantizerEMA.codebook.weight.copy_", "quantizers.SequenceQuantizerEMA._ema_w.copy_"], "methods", ["None"], ["", "def", "set_codebook", "(", "self", ",", "new_codebook", ",", "discard_ema_cluster_sizes", "=", "False", ")", ":", "\n", "        ", "self", ".", "codebook", ".", "weight", ".", "copy_", "(", "new_codebook", ")", "\n", "self", ".", "_ema_w", ".", "copy_", "(", "new_codebook", ")", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "discard_ema_cluster_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerSoftEMA.__init__": [[186, 209], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "quantizers.SequenceQuantizerSoftEMA.register_buffer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "quantizers.SequenceQuantizerSoftEMA._ema_w.data.copy_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", ",", "d_model", ",", "commitment_cost", ",", "num_samples", "=", "10", ",", "temp", "=", "1.0", ",", "\n", "ema_decay", "=", "0.99", ",", "epsilon", "=", "1e-5", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", "SequenceQuantizerSoftEMA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "codebook_size", "=", "codebook_size", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "self", ".", "codebook", "=", "nn", ".", "Embedding", "(", "self", ".", "codebook_size", ",", "self", ".", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "codebook", ".", "weight", ".", "data", "[", "padding_idx", "]", "=", "0", "\n", "\n", "", "self", ".", "commitment_cost", "=", "commitment_cost", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "temp", "=", "temp", "\n", "\n", "self", ".", "register_buffer", "(", "'_ema_cluster_size'", ",", "torch", ".", "zeros", "(", "codebook_size", ")", ")", "\n", "self", ".", "_ema_w", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "codebook_size", ",", "self", ".", "d_model", ")", ")", "\n", "self", ".", "_ema_w", ".", "data", ".", "copy_", "(", "self", ".", "codebook", ".", "weight", ".", "data", ")", "\n", "\n", "self", ".", "_decay", "=", "ema_decay", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerSoftEMA.forward": [[210, 287], ["inputs.size", "inputs.dim", "inputs.reshape", "torch.distributions.multinomial.Multinomial", "torch.distributions.multinomial.Multinomial", "torch.distributions.multinomial.Multinomial", "torch.distributions.multinomial.Multinomial.sample().to", "torch.distributions.multinomial.Multinomial.sample().to", "torch.distributions.multinomial.Multinomial.sample().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "samples.reshape.reshape.reshape", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.distributions.multinomial.Multinomial.sample", "torch.distributions.multinomial.Multinomial.sample", "torch.distributions.multinomial.Multinomial.sample", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "quantizers.SequenceQuantizerSoftEMA._ema_cluster_size.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "list", "quantizers.SequenceQuantizerSoftEMA.codebook.weight.t", "padding_mask.reshape().expand", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "samples.reshape.reshape.t", "padding_mask.reshape", "quantized.detach", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "padding_mask.reshape", "quantized.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "commitment_cost", "=", "None", ",", "temp", "=", "None", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "\n", "if", "commitment_cost", "is", "None", ":", "\n", "            ", "commitment_cost", "=", "self", ".", "commitment_cost", "\n", "\n", "", "if", "temp", "is", "None", ":", "\n", "            ", "temp", "=", "self", ".", "temp", "\n", "\n", "# inputs can be:", "\n", "# 2-dimensional [B x E]         (already flattened)", "\n", "# 3-dimensional [B x T x E]     (e.g., batch of sentences)", "\n", "# 4-dimensional [B x S x T x E] (e.g., batch of documents)", "\n", "", "input_shape", "=", "inputs", ".", "size", "(", ")", "\n", "input_dims", "=", "inputs", ".", "dim", "(", ")", "\n", "\n", "# Flatten input", "\n", "flat_input", "=", "inputs", ".", "reshape", "(", "-", "1", ",", "self", ".", "d_model", ")", "\n", "\n", "# Calculate distances", "\n", "distances", "=", "(", "torch", ".", "sum", "(", "flat_input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "+", "torch", ".", "sum", "(", "self", ".", "codebook", ".", "weight", "**", "2", ",", "dim", "=", "1", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "flat_input", ",", "self", ".", "codebook", ".", "weight", ".", "t", "(", ")", ")", ")", "\n", "\n", "# TODO: generalize this to any padding_idx", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "# no normal token gets mapped to discrete value 0", "\n", "            ", "distances", "[", ":", ",", "0", "]", "[", "~", "padding_mask", ".", "reshape", "(", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "# all pad tokens get mapped to discrete value 0", "\n", "distances", "[", ":", ",", "1", ":", "]", "[", "padding_mask", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "self", ".", "codebook_size", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "\n", "# Define multinomial distribution and sample from it", "\n", "", "multi", "=", "Multinomial", "(", "total_count", "=", "self", ".", "num_samples", ",", "logits", "=", "-", "distances", "/", "temp", ")", "\n", "samples", "=", "multi", ".", "sample", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Soft-quantize and unflatten", "\n", "quantized", "=", "torch", ".", "matmul", "(", "samples", ",", "self", ".", "codebook", ".", "weight", ")", ".", "view", "(", "input_shape", ")", "/", "self", ".", "num_samples", "\n", "\n", "# Loss", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "num_nonpad_elements", "=", "torch", ".", "sum", "(", "~", "padding_mask", ")", "*", "self", ".", "d_model", "\n", "e_latent_loss", "=", "torch", ".", "sum", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "/", "num_nonpad_elements", "\n", "", "else", ":", "\n", "            ", "e_latent_loss", "=", "torch", ".", "mean", "(", "(", "quantized", ".", "detach", "(", ")", "-", "inputs", ")", "**", "2", ")", "\n", "", "loss", "=", "commitment_cost", "*", "e_latent_loss", "\n", "\n", "# Use EMA to update the embedding vectors", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "discard_ema_cluster_sizes", ":", "\n", "                ", "self", ".", "_ema_cluster_size", "=", "torch", ".", "sum", "(", "samples", ",", "0", ")", "/", "self", ".", "num_samples", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "False", "\n", "", "else", ":", "\n", "                ", "self", ".", "_ema_cluster_size", "=", "self", ".", "_ema_cluster_size", "*", "self", ".", "_decay", "+", "(", "1", "-", "self", ".", "_decay", ")", "*", "(", "torch", ".", "sum", "(", "samples", ",", "0", ")", "/", "self", ".", "num_samples", ")", "\n", "\n", "# Laplace smoothing of the cluster size", "\n", "", "n", "=", "torch", ".", "sum", "(", "self", ".", "_ema_cluster_size", ".", "data", ")", "\n", "self", ".", "_ema_cluster_size", "=", "(", "\n", "(", "self", ".", "_ema_cluster_size", "+", "self", ".", "_epsilon", ")", "\n", "/", "(", "n", "+", "self", ".", "codebook_size", "*", "self", ".", "_epsilon", ")", "*", "n", ")", "\n", "\n", "dw", "=", "torch", ".", "matmul", "(", "samples", ".", "t", "(", ")", ",", "flat_input", ")", "/", "self", ".", "num_samples", "\n", "self", ".", "_ema_w", "=", "nn", ".", "Parameter", "(", "self", ".", "_ema_w", "*", "self", ".", "_decay", "+", "(", "1", "-", "self", ".", "_decay", ")", "*", "dw", ")", "\n", "\n", "normalized_ema_w", "=", "self", ".", "_ema_w", "/", "self", ".", "_ema_cluster_size", ".", "unsqueeze", "(", "1", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "normalized_ema_w", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "", "self", ".", "codebook", ".", "weight", "=", "nn", ".", "Parameter", "(", "normalized_ema_w", ")", "\n", "\n", "", "quantized", "=", "inputs", "+", "(", "quantized", "-", "inputs", ")", ".", "detach", "(", ")", "\n", "avg_probs", "=", "torch", ".", "mean", "(", "samples", ",", "dim", "=", "0", ")", "/", "self", ".", "num_samples", "\n", "perplexity", "=", "torch", ".", "exp", "(", "-", "torch", ".", "sum", "(", "avg_probs", "*", "torch", ".", "log", "(", "avg_probs", "+", "1e-10", ")", ")", ")", "\n", "\n", "samples", "=", "samples", ".", "reshape", "(", "list", "(", "input_shape", "[", ":", "input_dims", "-", "1", "]", ")", "+", "[", "self", ".", "codebook_size", "]", ")", "\n", "\n", "return", "quantized", ",", "samples", ",", "loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerSoftEMA.cluster": [[288, 325], ["inputs.size", "inputs.dim", "inputs.reshape", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.argmin().unsqueeze", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "encoding_indices.reshape.reshape.reshape", "distances.reshape().detach.reshape().detach.reshape().detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "distances.reshape().detach.reshape().detach.reshape", "quantizers.SequenceQuantizerSoftEMA.codebook.weight.t", "padding_mask.reshape().expand", "padding_mask.reshape", "list", "padding_mask.reshape"], "methods", ["None"], ["", "def", "cluster", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "\n", "# inputs can be:", "\n", "# 2-dimensional [B x E]         (already flattened)", "\n", "# 3-dimensional [B x T x E]     (e.g., batch of sentences)", "\n", "# 4-dimensional [B x S x T x E] (e.g., batch of documents)", "\n", "input_shape", "=", "inputs", ".", "size", "(", ")", "\n", "input_dims", "=", "inputs", ".", "dim", "(", ")", "\n", "\n", "# Flatten input", "\n", "flat_input", "=", "inputs", ".", "reshape", "(", "-", "1", ",", "self", ".", "d_model", ")", "\n", "\n", "# Calculate distances", "\n", "distances", "=", "(", "torch", ".", "sum", "(", "flat_input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "+", "torch", ".", "sum", "(", "self", ".", "codebook", ".", "weight", "**", "2", ",", "dim", "=", "1", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "flat_input", ",", "self", ".", "codebook", ".", "weight", ".", "t", "(", ")", ")", ")", "\n", "\n", "# TODO: generalize this to any padding_idx", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "# no normal token gets mapped to discrete value 0", "\n", "            ", "distances", "[", ":", ",", "0", "]", "[", "~", "padding_mask", ".", "reshape", "(", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "# all pad tokens get mapped to discrete value 0", "\n", "distances", "[", ":", ",", "1", ":", "]", "[", "padding_mask", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "self", ".", "codebook_size", "-", "1", ")", "]", "=", "np", ".", "inf", "\n", "\n", "# Encoding", "\n", "", "encoding_indices", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "encodings", "=", "torch", ".", "zeros", "(", "encoding_indices", ".", "shape", "[", "0", "]", ",", "self", ".", "codebook_size", ")", ".", "to", "(", "device", ")", "\n", "encodings", ".", "scatter_", "(", "1", ",", "encoding_indices", ",", "1", ")", "\n", "\n", "# Quantize and unflatten", "\n", "quantized", "=", "torch", ".", "matmul", "(", "encodings", ",", "self", ".", "codebook", ".", "weight", ")", ".", "view", "(", "input_shape", ")", "\n", "\n", "encoding_indices", "=", "encoding_indices", ".", "reshape", "(", "input_shape", "[", ":", "input_dims", "-", "1", "]", ")", "\n", "distances", "=", "distances", ".", "reshape", "(", "list", "(", "input_shape", "[", ":", "-", "1", "]", ")", "+", "[", "self", ".", "codebook_size", "]", ")", ".", "detach", "(", ")", "\n", "\n", "return", "quantized", ",", "encoding_indices", ",", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.SequenceQuantizerSoftEMA.set_codebook": [[326, 330], ["quantizers.SequenceQuantizerSoftEMA.codebook.weight.copy_", "quantizers.SequenceQuantizerSoftEMA._ema_w.copy_"], "methods", ["None"], ["", "def", "set_codebook", "(", "self", ",", "new_codebook", ",", "discard_ema_cluster_sizes", "=", "False", ")", ":", "\n", "        ", "self", ".", "codebook", ".", "weight", ".", "copy_", "(", "new_codebook", ")", "\n", "self", ".", "_ema_w", ".", "copy_", "(", "new_codebook", ")", "\n", "self", ".", "discard_ema_cluster_sizes", "=", "discard_ema_cluster_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizer.__init__": [[333, 364], ["encoders.TransformerDocumentEncoder", "quantizers.SequenceQuantizer.__init__", "quantizers.SequenceQuantizer.__init__"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__", "home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", "=", "64", ",", "d_model", "=", "200", ",", "commitment_cost", "=", "0.25", ",", "\n", "nlayers", "=", "3", ",", "internal_nheads", "=", "4", ",", "output_nheads", "=", "4", ",", "d_ff", "=", "512", ",", "\n", "pooling_final_linear", "=", "True", ",", "output_resize", "=", "True", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "if", "output_resize", ":", "\n", "            ", "self", ".", "d_output", "=", "d_model", "\n", "self", ".", "pooling_final_linear", "=", "True", "\n", "super", "(", "TransformerDocumentQuantizer", ",", "self", ")", ".", "__init__", "(", "\n", "codebook_size", ",", "d_model", ",", "commitment_cost", ")", "\n", "", "else", ":", "\n", "            ", "assert", "d_model", "%", "output_nheads", "==", "0", ",", "'Number of output heads must divide d_model'", "\n", "self", ".", "d_output", "=", "d_model", "//", "output_nheads", "\n", "self", ".", "pooling_final_linear", "=", "pooling_final_linear", "\n", "super", "(", "TransformerDocumentQuantizer", ",", "self", ")", ".", "__init__", "(", "\n", "codebook_size", ",", "self", ".", "d_output", ",", "commitment_cost", ")", "\n", "", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "internal_nheads", "=", "internal_nheads", "\n", "self", ".", "output_nheads", "=", "output_nheads", "\n", "self", ".", "d_ff", "=", "d_ff", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "encoder", "=", "TransformerDocumentEncoder", "(", "\n", "d_model", "=", "d_model", ",", "\n", "sentence_nlayers", "=", "nlayers", ",", "\n", "sentence_internal_nheads", "=", "internal_nheads", ",", "\n", "sentence_output_nheads", "=", "output_nheads", ",", "\n", "sentence_d_ff", "=", "d_ff", ",", "\n", "use_single_pooling_norm", "=", "True", ",", "\n", "pooling_final_linear", "=", "self", ".", "pooling_final_linear", ",", "\n", "pooling_final_linear_size", "=", "self", ".", "d_output", ",", "\n", "pooling_same_linear", "=", "True", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizer.forward": [[365, 382], ["quantizers.TransformerDocumentQuantizer.encoder", "inputs.dim", "quantizers.SequenceQuantizer.forward", "quantizers.SequenceQuantizer.forward"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward", "home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "\n", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ",", "commitment_cost", "=", "None", ")", ":", "\n", "        ", "assert", "inputs", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must have 4 dimensions: [B x S x T x E]'", "\n", "\n", "out", "=", "self", ".", "encoder", "(", "inputs", ",", "padding_mask", ")", "\n", "if", "quantize", ":", "\n", "            ", "if", "residual_coeff", ">", "0.0", ":", "\n", "                ", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "=", "super", "(", "TransformerSentenceQuantizer", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ")", "\n", "quantized", "=", "residual_coeff", "*", "out", "+", "(", "1", "-", "residual_coeff", ")", "*", "quantized", "\n", "return", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "\n", "", "else", ":", "\n", "                ", "return", "super", "(", "TransformerDocumentQuantizer", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ")", "\n", "", "", "return", "out", ",", "None", ",", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizerEMA.__init__": [[385, 405], ["quantizers.SequenceQuantizerEMA.__init__", "encoders.TransformerDocumentEncoder"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", "=", "64", ",", "d_model", "=", "200", ",", "\n", "commitment_cost", "=", "0.25", ",", "decay", "=", "0.99", ",", "epsilon", "=", "1e-5", ",", "\n", "nlayers", "=", "3", ",", "internal_nheads", "=", "4", ",", "output_nheads", "=", "4", ",", "d_ff", "=", "512", ",", "\n", "dropout", "=", "0.1", ")", ":", "\n", "        ", "assert", "d_model", "%", "output_nheads", "==", "0", ",", "'Number of output heads must divide d_model'", "\n", "super", "(", "TransformerDocumentQuantizerEMA", ",", "self", ")", ".", "__init__", "(", "codebook_size", ",", "d_model", ",", "\n", "commitment_cost", "=", "commitment_cost", ",", "decay", "=", "decay", ",", "epsilon", "=", "epsilon", ")", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "internal_nheads", "=", "internal_nheads", "\n", "self", ".", "output_nheads", "=", "output_nheads", "\n", "self", ".", "d_ff", "=", "d_ff", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "encoder", "=", "TransformerDocumentEncoder", "(", "\n", "d_model", "=", "d_model", ",", "\n", "sentence_nlayers", "=", "nlayers", ",", "\n", "sentence_internal_nheads", "=", "internal_nheads", ",", "\n", "sentence_output_nheads", "=", "output_nheads", ",", "\n", "sentence_d_ff", "=", "d_ff", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizerEMA.forward": [[406, 423], ["quantizers.TransformerDocumentQuantizerEMA.encoder", "inputs.dim", "quantizers.SequenceQuantizerEMA.forward", "quantizers.SequenceQuantizerEMA.forward"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward", "home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "\n", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ",", "commitment_cost", "=", "None", ")", ":", "\n", "        ", "assert", "inputs", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must have 4 dimensions: [B x S x T x E]'", "\n", "\n", "out", "=", "self", ".", "encoder", "(", "inputs", ",", "padding_mask", ")", "\n", "if", "quantize", ":", "\n", "            ", "if", "residual_coeff", ">", "0.0", ":", "\n", "                ", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "=", "super", "(", "TransformerDocumentQuantizerEMA", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ")", "\n", "quantized", "=", "residual_coeff", "*", "out", "+", "(", "1", "-", "residual_coeff", ")", "*", "quantized", "\n", "return", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "\n", "", "else", ":", "\n", "                ", "return", "super", "(", "TransformerDocumentQuantizerEMA", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ")", "\n", "", "", "return", "out", ",", "None", ",", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizerSoftEMA.__init__": [[426, 447], ["quantizers.SequenceQuantizerSoftEMA.__init__", "encoders.TransformerDocumentEncoder"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "codebook_size", "=", "64", ",", "d_model", "=", "200", ",", "temp", "=", "1.0", ",", "num_samples", "=", "10", ",", "\n", "commitment_cost", "=", "0.25", ",", "ema_decay", "=", "0.99", ",", "epsilon", "=", "1e-5", ",", "\n", "nlayers", "=", "3", ",", "internal_nheads", "=", "4", ",", "output_nheads", "=", "4", ",", "d_ff", "=", "512", ",", "\n", "dropout", "=", "0.1", ")", ":", "\n", "        ", "assert", "d_model", "%", "output_nheads", "==", "0", ",", "'Number of output heads must divide d_model'", "\n", "super", "(", "TransformerDocumentQuantizerSoftEMA", ",", "self", ")", ".", "__init__", "(", "codebook_size", ",", "d_model", ",", "\n", "commitment_cost", "=", "commitment_cost", ",", "temp", "=", "temp", ",", "num_samples", "=", "num_samples", ",", "\n", "ema_decay", "=", "ema_decay", ",", "epsilon", "=", "epsilon", ")", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "internal_nheads", "=", "internal_nheads", "\n", "self", ".", "output_nheads", "=", "output_nheads", "\n", "self", ".", "d_ff", "=", "d_ff", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "encoder", "=", "TransformerDocumentEncoder", "(", "\n", "d_model", "=", "d_model", ",", "\n", "sentence_nlayers", "=", "nlayers", ",", "\n", "sentence_internal_nheads", "=", "internal_nheads", ",", "\n", "sentence_output_nheads", "=", "output_nheads", ",", "\n", "sentence_d_ff", "=", "d_ff", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizerSoftEMA.forward": [[448, 466], ["quantizers.TransformerDocumentQuantizerSoftEMA.encoder", "inputs.dim", "quantizers.SequenceQuantizerSoftEMA.forward", "quantizers.SequenceQuantizerSoftEMA.forward"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward", "home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ",", "\n", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ",", "commitment_cost", "=", "None", ",", "\n", "temp", "=", "None", ")", ":", "\n", "        ", "assert", "inputs", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must have 4 dimensions: [B x S x T x E]'", "\n", "\n", "out", "=", "self", ".", "encoder", "(", "inputs", ",", "padding_mask", ")", "\n", "if", "quantize", ":", "\n", "            ", "if", "residual_coeff", ">", "0.0", ":", "\n", "                ", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "=", "super", "(", "TransformerDocumentQuantizerSoftEMA", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ",", "temp", "=", "temp", ")", "\n", "quantized", "=", "residual_coeff", "*", "out", "+", "(", "1", "-", "residual_coeff", ")", "*", "quantized", "\n", "return", "quantized", ",", "encodings", ",", "loss", ",", "perplexity", "\n", "", "else", ":", "\n", "                ", "return", "super", "(", "TransformerDocumentQuantizerSoftEMA", ",", "self", ")", ".", "forward", "(", "out", ",", "\n", "commitment_cost", "=", "commitment_cost", ",", "temp", "=", "temp", ")", "\n", "", "", "return", "out", ",", "None", ",", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.quantizers.TransformerDocumentQuantizerSoftEMA.cluster": [[467, 476], ["quantizers.TransformerDocumentQuantizerSoftEMA.encoder", "quantizers.SequenceQuantizerSoftEMA.cluster", "inputs.dim"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.cluster"], ["", "def", "cluster", "(", "self", ",", "inputs", ",", "padding_mask", ")", ":", "\n", "        ", "assert", "inputs", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must have 4 dimensions: [B x S x T x E]'", "\n", "\n", "out", "=", "self", ".", "encoder", "(", "inputs", ",", "padding_mask", ")", "\n", "q_out", ",", "clusters", ",", "distances", "=", "super", "(", "TransformerDocumentQuantizerSoftEMA", ",", "self", ")", ".", "cluster", "(", "out", ")", "\n", "\n", "return", "out", ",", "q_out", ",", "clusters", ",", "distances", "\n", "", "", ""]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.__init__": [[10, 76], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "quantizers.TransformerDocumentQuantizerSoftEMA", "torch.TransformerDecoderLayer", "torch.TransformerDecoderLayer", "torch.TransformerDecoder", "torch.TransformerDecoder", "torch.Linear", "torch.Linear", "encoders.PositionalDocumentEncoding", "encoders.PositionalDocumentEncoding", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab_size", ":", "int", ",", "\n", "d_model", ":", "int", "=", "320", ",", "\n", "codebook_size", ":", "int", "=", "1024", ",", "\n", "commitment_cost", ":", "float", "=", "1.00", ",", "\n", "ema_decay", ":", "float", "=", "0.99", ",", "\n", "temp", ":", "float", "=", "1.0", ",", "\n", "num_samples", ":", "int", "=", "10", ",", "\n", "epsilon", ":", "float", "=", "1e-5", ",", "\n", "nlayers", ":", "int", "=", "3", ",", "\n", "internal_nheads", ":", "int", "=", "4", ",", "\n", "output_nheads", ":", "int", "=", "8", ",", "\n", "d_ff", ":", "int", "=", "512", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "use_in_pos", ":", "bool", "=", "False", ",", "\n", "use_out_pos", ":", "bool", "=", "False", ",", "\n", "padding_idx", ":", "int", "=", "0", ",", "\n", "unk_idx", ":", "int", "=", "1", ",", "\n", "bos_idx", ":", "int", "=", "2", ",", "\n", "eos_idx", ":", "int", "=", "3", ")", ":", "\n", "        ", "super", "(", "QuantizedTransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "codebook_size", "=", "codebook_size", "\n", "self", ".", "use_in_pos", "=", "use_in_pos", "\n", "self", ".", "use_out_pos", "=", "use_out_pos", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "unk_idx", "=", "unk_idx", "\n", "self", ".", "bos_idx", "=", "bos_idx", "\n", "self", ".", "eos_idx", "=", "eos_idx", "\n", "\n", "self", ".", "in_emb", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "self", ".", "out_emb", "=", "self", ".", "in_emb", "\n", "if", "use_in_pos", ":", "\n", "            ", "self", ".", "in_pos", "=", "PositionalDocumentEncoding", "(", "d_model", ",", "dropout", ")", "\n", "if", "use_out_pos", ":", "\n", "                ", "self", ".", "out_pos", "=", "self", ".", "in_pos", "\n", "", "", "elif", "use_out_pos", ":", "\n", "            ", "self", ".", "out_pos", "=", "PositionalDocumentEncoding", "(", "d_model", ",", "dropout", ")", "\n", "\n", "", "self", ".", "encoder", "=", "TransformerDocumentQuantizerSoftEMA", "(", "\n", "codebook_size", "=", "codebook_size", ",", "\n", "d_model", "=", "d_model", ",", "\n", "temp", "=", "temp", ",", "\n", "num_samples", "=", "num_samples", ",", "\n", "commitment_cost", "=", "commitment_cost", ",", "\n", "ema_decay", "=", "ema_decay", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "nlayers", "=", "nlayers", ",", "\n", "internal_nheads", "=", "internal_nheads", ",", "\n", "output_nheads", "=", "output_nheads", ",", "\n", "d_ff", "=", "d_ff", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "decoder_layer", "=", "nn", ".", "TransformerDecoderLayer", "(", "\n", "d_model", ",", "\n", "internal_nheads", ",", "\n", "dim_feedforward", "=", "d_ff", ",", "\n", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "TransformerDecoder", "(", "\n", "decoder_layer", ",", "\n", "nlayers", ",", "\n", "norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", ")", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "\n", "self", ".", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.in_embed": [[77, 82], ["qt.QuantizedTransformerModel.in_emb", "qt.QuantizedTransformerModel.in_pos"], "methods", ["None"], ["", "def", "in_embed", "(", "self", ",", "src", ")", ":", "\n", "        ", "emb", "=", "self", ".", "in_emb", "(", "src", ")", "\n", "if", "self", ".", "use_in_pos", ":", "\n", "            ", "emb", "=", "self", ".", "in_pos", "(", "emb", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.out_embed": [[83, 88], ["qt.QuantizedTransformerModel.out_emb", "qt.QuantizedTransformerModel.out_pos"], "methods", ["None"], ["", "def", "out_embed", "(", "self", ",", "tgt", ")", ":", "\n", "        ", "emb", "=", "self", ".", "out_emb", "(", "tgt", ")", "\n", "if", "self", ".", "use_out_pos", ":", "\n", "            ", "emb", "=", "self", ".", "out_pos", "(", "emb", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.encode": [[89, 108], ["torch.cat.size", "torch.cat.size", "sent_tokens.to.to.to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "qt.QuantizedTransformerModel.in_embed", "qt.QuantizedTransformerModel.encoder", "torch.cat.dim", "torch.cat.dim", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "qt.QuantizedTransformerModel.get_padding_mask", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.in_embed", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.get_padding_mask"], ["", "def", "encode", "(", "self", ",", "src", ",", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ")", ":", "\n", "        ", "assert", "src", ".", "dim", "(", ")", "==", "3", ",", "'Input (source) must be 3-dimensional [B x S x T]'", "\n", "batch_size", ",", "nsent", ",", "ntokens", "=", "src", ".", "size", "(", ")", "\n", "device", "=", "src", ".", "device", "\n", "\n", "sent_tokens", "=", "torch", ".", "ones", "(", "batch_size", ",", "nsent", ",", "1", ")", ".", "long", "(", ")", "*", "self", ".", "unk_idx", "\n", "sent_tokens", "=", "sent_tokens", ".", "to", "(", "device", ")", "\n", "\n", "src", "=", "torch", ".", "cat", "(", "[", "sent_tokens", ",", "src", "]", ",", "dim", "=", "2", ")", "\n", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "padding_mask", "=", "self", ".", "get_padding_mask", "(", "src", ")", "\n", "\n", "", "src_emb", "=", "self", ".", "in_embed", "(", "src", ")", "\n", "quantized_memory", ",", "encodings", ",", "q_loss", ",", "perplexity", "=", "self", ".", "encoder", "(", "src_emb", ",", "padding_mask", "=", "padding_mask", ",", "quantize", "=", "quantize", ",", "residual_coeff", "=", "residual_coeff", ")", "\n", "\n", "return", "quantized_memory", ",", "encodings", ",", "q_loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.decode": [[109, 142], ["tgt.reshape.reshape.size", "memory.reshape().transpose.reshape().transpose.size", "qt.QuantizedTransformerModel.out_embed().reshape().transpose", "tgt.reshape.reshape.reshape", "generate_square_subsequent_mask().to", "memory.reshape().transpose.reshape().transpose.reshape().transpose", "qt.QuantizedTransformerModel.decoder", "qt.QuantizedTransformerModel.transpose().reshape", "tgt.reshape.reshape.dim", "memory.reshape().transpose.reshape().transpose.dim", "qt.QuantizedTransformerModel.get_padding_mask", "memory_key_padding_mask.reshape.reshape.reshape", "qt.QuantizedTransformerModel.out_embed().reshape", "qt.generate_square_subsequent_mask", "memory.reshape().transpose.reshape().transpose.reshape", "qt.QuantizedTransformerModel.transpose", "qt.QuantizedTransformerModel.out_embed"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.get_padding_mask", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.generate_square_subsequent_mask", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.out_embed"], ["", "def", "decode", "(", "self", ",", "tgt", ",", "memory", ",", "memory_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ")", ":", "\n", "        ", "assert", "tgt", ".", "dim", "(", ")", "==", "3", ",", "'Input (target) must be 3-dimensional [B x S x T]'", "\n", "assert", "memory", ".", "dim", "(", ")", "==", "4", ",", "'Input (memory) must be 4-dimensional [B x S x MT x E]'", "\n", "\n", "device", "=", "tgt", ".", "device", "\n", "batch_size", ",", "nsent", ",", "ntokens", "=", "tgt", ".", "size", "(", ")", "\n", "mem_batch_size", ",", "mem_nsent", ",", "mem_ntokens", ",", "mem_emb_size", "=", "memory", ".", "size", "(", ")", "\n", "\n", "assert", "batch_size", "==", "mem_batch_size", "and", "nsent", "==", "mem_nsent", "and", "mem_emb_size", "==", "self", ".", "d_model", ",", "'Target, memory and model dimensionalities don\\'t match'", "\n", "\n", "tgt_emb", "=", "self", ".", "out_embed", "(", "tgt", ")", ".", "reshape", "(", "batch_size", "*", "nsent", ",", "ntokens", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tgt", "=", "tgt", ".", "reshape", "(", "batch_size", "*", "nsent", ",", "ntokens", ")", "\n", "tgt_mask", "=", "generate_square_subsequent_mask", "(", "ntokens", ")", ".", "to", "(", "device", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "tgt_key_padding_mask", "=", "self", ".", "get_padding_mask", "(", "tgt", ")", "\n", "\n", "", "memory", "=", "memory", ".", "reshape", "(", "mem_batch_size", "*", "mem_nsent", ",", "mem_ntokens", ",", "mem_emb_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "memory_key_padding_mask", "is", "not", "None", ":", "\n", "            ", "memory_key_padding_mask", "=", "memory_key_padding_mask", ".", "reshape", "(", "mem_batch_size", "*", "mem_nsent", ",", "mem_ntokens", ")", "\n", "\n", "", "output", "=", "self", ".", "decoder", "(", "\n", "tgt_emb", ",", "\n", "memory", ",", "\n", "tgt_mask", "=", "tgt_mask", ",", "\n", "memory_mask", "=", "memory_mask", ",", "\n", "tgt_key_padding_mask", "=", "tgt_key_padding_mask", ",", "\n", "memory_key_padding_mask", "=", "memory_key_padding_mask", ")", "\n", "return", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "batch_size", ",", "nsent", ",", "ntokens", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.forward": [[143, 154], ["src.size", "tgt.size", "qt.QuantizedTransformerModel.encode", "qt.QuantizedTransformerModel.decode", "qt.QuantizedTransformerModel.linear"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.encode", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.decode"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ")", ":", "\n", "        ", "src_batch_size", ",", "src_nsent", ",", "src_ntokens", "=", "src", ".", "size", "(", ")", "\n", "tgt_batch_size", ",", "tgt_nsent", ",", "tgt_ntokens", "=", "tgt", ".", "size", "(", ")", "\n", "assert", "src_batch_size", "==", "tgt_batch_size", "and", "src_nsent", "==", "tgt_nsent", ",", "'Size mismath between source and target'", "\n", "\n", "memory", ",", "encodings", ",", "q_loss", ",", "perplexity", "=", "self", ".", "encode", "(", "src", ",", "quantize", "=", "quantize", ",", "residual_coeff", "=", "residual_coeff", ")", "\n", "out", "=", "self", ".", "decode", "(", "tgt", ",", "memory", ")", "\n", "\n", "return", "self", ".", "linear", "(", "out", ")", ",", "encodings", ",", "q_loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.generate": [[155, 173], ["src.size", "qt.QuantizedTransformerModel.encode", "torch.LongTensor().fill_().to", "torch.LongTensor().fill_().to", "torch.LongTensor().fill_().to", "torch.LongTensor().fill_().to", "range", "src.dim", "qt.QuantizedTransformerModel.decode", "qt.QuantizedTransformerModel.linear", "qt.QuantizedTransformerModel.argmax", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.encode", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.decode"], ["", "def", "generate", "(", "self", ",", "src", ",", "maxlen", "=", "40", ",", "quantize", "=", "True", ",", "residual_coeff", "=", "0.0", ")", ":", "\n", "        ", "assert", "src", ".", "dim", "(", ")", "==", "3", ",", "'Input (source) must be 3-dimensional'", "\n", "batch_size", ",", "nsent", ",", "ntokens", "=", "src", ".", "size", "(", ")", "\n", "device", "=", "src", ".", "device", "\n", "\n", "memory", ",", "encodings", ",", "q_loss", ",", "perplexity", "=", "self", ".", "encode", "(", "src", ",", "quantize", "=", "quantize", ",", "residual_coeff", "=", "residual_coeff", ")", "\n", "\n", "# <BOS> tgt seq for generation", "\n", "tgt", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "nsent", ",", "maxlen", ")", ".", "fill_", "(", "self", ".", "padding_idx", ")", ".", "to", "(", "device", ")", "\n", "tgt", "[", ":", ",", ":", ",", "0", "]", "=", "self", ".", "bos_idx", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "maxlen", ")", ":", "\n", "            ", "out", "=", "self", ".", "decode", "(", "tgt", "[", ":", ",", ":", ",", ":", "i", "]", ",", "memory", ")", "\n", "prob", "=", "self", ".", "linear", "(", "out", ")", "\n", "decode_output", "=", "prob", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "tgt", "[", ":", ",", ":", ",", "i", "]", "=", "decode_output", "[", ":", ",", ":", ",", "-", "1", "]", "\n", "", "return", "tgt", ",", "encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.cluster": [[174, 192], ["torch.cat.size", "torch.cat.size", "sent_tokens.to.to.to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "qt.QuantizedTransformerModel.in_embed", "qt.QuantizedTransformerModel.encoder.cluster", "torch.cat.dim", "torch.cat.dim", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "qt.QuantizedTransformerModel.get_padding_mask", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.in_embed", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.cluster", "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.get_padding_mask"], ["", "def", "cluster", "(", "self", ",", "src", ")", ":", "\n", "        ", "assert", "src", ".", "dim", "(", ")", "==", "3", ",", "'Input (source) must be 3-dimensional [B x S x T]'", "\n", "batch_size", ",", "nsent", ",", "ntokens", "=", "src", ".", "size", "(", ")", "\n", "device", "=", "src", ".", "device", "\n", "\n", "sent_tokens", "=", "torch", ".", "ones", "(", "batch_size", ",", "nsent", ",", "1", ")", ".", "long", "(", ")", "*", "self", ".", "unk_idx", "\n", "sent_tokens", "=", "sent_tokens", ".", "to", "(", "device", ")", "\n", "\n", "src", "=", "torch", ".", "cat", "(", "[", "sent_tokens", ",", "src", "]", ",", "dim", "=", "2", ")", "\n", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "padding_mask", "=", "self", ".", "get_padding_mask", "(", "src", ")", "\n", "\n", "", "src_emb", "=", "self", ".", "in_embed", "(", "src", ")", "\n", "noq_out", ",", "q_out", ",", "clusters", ",", "distances", "=", "self", ".", "encoder", ".", "cluster", "(", "src_emb", ",", "padding_mask", "=", "padding_mask", ")", "\n", "\n", "return", "noq_out", ",", "q_out", ",", "clusters", ",", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.get_padding_mask": [[193, 195], ["None"], "methods", ["None"], ["", "def", "get_padding_mask", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "batch", "==", "self", ".", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.QuantizedTransformerModel.get_tgt_inputs": [[196, 201], ["batch.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones().long().to", "torch.ones().long().to", "torch.ones().long().to", "torch.ones().long().to", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "get_tgt_inputs", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_size", ",", "nsent", ",", "ntokens", "=", "batch", ".", "size", "(", ")", "\n", "bos", "=", "torch", ".", "ones", "(", "batch_size", ",", "nsent", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "device", ")", "*", "self", ".", "bos_idx", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "bos", ",", "batch", "]", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.qt.generate_square_subsequent_mask": [[203, 210], ["mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill", "float", "mask.float().masked_fill().masked_fill.float().masked_fill", "torch.triu", "torch.triu", "float", "torch.ones", "torch.ones", "mask.float().masked_fill().masked_fill.float"], "function", ["None"], ["", "", "def", "generate_square_subsequent_mask", "(", "sz", ")", ":", "\n", "    ", "\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n        Unmasked positions are filled with float(0.0).\n    \"\"\"", "\n", "mask", "=", "(", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "sz", ",", "sz", ")", ")", "==", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "masked_fill", "(", "mask", "==", "0", ",", "float", "(", "'-inf'", ")", ")", ".", "masked_fill", "(", "mask", "==", "1", ",", "float", "(", "0.0", ")", ")", "\n", "return", "mask", "\n", "", ""]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.TransformerDocumentEncoder.__init__": [[12, 40], ["torch.Module.__init__", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoder", "torch.TransformerEncoder", "torch.TransformerEncoder", "torch.TransformerEncoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["def", "__init__", "(", "self", ",", "d_model", "=", "320", ",", "sentence_nlayers", "=", "3", ",", "sentence_internal_nheads", "=", "4", ",", "\n", "sentence_d_ff", "=", "512", ",", "sentence_output_nheads", "=", "8", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "'''Parameters:\n            d_model (int): Transformer dimensionality for sentence encoder\n            sentence_nlayers (int): number of Transformer layers for sentence encoder\n            sentence_internal_nheads (int): number of attention heads for sentence encoder\n            sentence_d_ff (int): dimensionality of ff layer for sentence encoder\n            sentence_output_nheads (int): number of heads for sentence encoder\n            dropout (float): dropout probability\n        '''", "\n", "super", "(", "TransformerDocumentEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "sentence_output_nheads", "==", "0", ",", "'Number of sentence output heads must divide model dimensionality'", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "sentence_nlayers", "=", "sentence_nlayers", "\n", "self", ".", "sentence_internal_nheads", "=", "sentence_internal_nheads", "\n", "self", ".", "sentence_d_ff", "=", "sentence_d_ff", "\n", "self", ".", "sentence_output_nheads", "=", "sentence_output_nheads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "transformer_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", ",", "sentence_internal_nheads", ",", "\n", "dim_feedforward", "=", "sentence_d_ff", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "transformer_encoder", "=", "nn", ".", "TransformerEncoder", "(", "transformer_layer", ",", "\n", "num_layers", "=", "sentence_nlayers", ",", "norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", ")", "\n", "\n", "if", "sentence_output_nheads", ">", "1", ":", "\n", "            ", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "d_model", "//", "sentence_output_nheads", ",", "d_model", ")", "\n", "self", ".", "final_lnorm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.TransformerDocumentEncoder.forward": [[41, 65], ["inputs.transpose.transpose.size", "inputs.transpose.transpose.reshape", "inputs.transpose.transpose.transpose", "encoders.TransformerDocumentEncoder.transformer_encoder", "token_vecs.transpose().reshape.transpose().reshape.transpose().reshape", "token_vecs[].reshape", "inputs.transpose.transpose.dim", "padding_mask.reshape.reshape.reshape", "encoders.TransformerDocumentEncoder.final_lnorm", "token_vecs.transpose().reshape.transpose().reshape.transpose", "encoders.TransformerDocumentEncoder.final_linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "padding_mask", "=", "None", ")", ":", "\n", "        ", "'''Parameters:\n            inputs [B x S x T x E]: a batch of documents\n            padding_mask [B x S x T]: source key padding mask\n        '''", "\n", "assert", "inputs", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must have 4 dimensions: [B x S x T x E]'", "\n", "\n", "batch_size", ",", "nsent", ",", "ntokens", ",", "emb_size", "=", "inputs", ".", "size", "(", ")", "\n", "inputs", "=", "inputs", ".", "reshape", "(", "batch_size", "*", "nsent", ",", "ntokens", ",", "-", "1", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "padding_mask", "=", "padding_mask", ".", "reshape", "(", "batch_size", "*", "nsent", ",", "ntokens", ")", "\n", "\n", "", "inputs", "=", "inputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "token_vecs", "=", "self", ".", "transformer_encoder", "(", "inputs", ",", "src_key_padding_mask", "=", "padding_mask", ")", "\n", "token_vecs", "=", "token_vecs", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "batch_size", ",", "nsent", ",", "-", "1", ",", "self", ".", "d_model", ")", "\n", "\n", "sentence_vecs", "=", "token_vecs", "[", ":", ",", ":", ",", "0", ",", ":", "]", ".", "reshape", "(", "batch_size", ",", "nsent", ",", "self", ".", "sentence_output_nheads", ",", "-", "1", ")", "\n", "if", "self", ".", "sentence_output_nheads", ">", "1", ":", "\n", "            ", "sentence_vecs", "=", "self", ".", "final_lnorm", "(", "self", ".", "final_linear", "(", "sentence_vecs", ")", ")", "\n", "\n", "", "return", "sentence_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.PositionalEncoding.__init__": [[72, 91], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "encoders.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "50", ")", ":", "\n", "        ", "'''Parameters:\n            dropout (float): dropout parameter\n            dim (int): embedding size\n        '''", "\n", "if", "dim", "%", "2", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use sin/cos positional encoding with \"", "\n", "\"odd dim (got dim={:d})\"", ".", "format", "(", "dim", ")", ")", "\n", "", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.PositionalEncoding.forward": [[92, 107], ["encoders.PositionalEncoding.dropout", "math.sqrt", "encoders.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "'''Parameters:\n            emb (FloatTensor): Sequence of word vectors\n                ``(seq_len, batch_size, self.dim)``\n            step (int or NoneType): If stepwise (``seq_len = 1``), use\n                the encoding for this position.\n        '''", "\n", "\n", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "step", "is", "None", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", "step", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.PositionalDocumentEncoding.__init__": [[109, 111], ["encoders.PositionalEncoding.__init__"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "dropout", "=", "0.1", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalDocumentEncoding", ",", "self", ")", ".", "__init__", "(", "dropout", ",", "dim", ",", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.src.encoders.PositionalDocumentEncoding.forward": [[112, 122], ["super().forward.size", "super().forward.reshape().transpose", "encoders.PositionalEncoding.forward", "super().forward.transpose().reshape", "super().forward.dim", "super().forward.size", "super().forward.reshape", "super().forward.transpose"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward"], ["", "def", "forward", "(", "self", ",", "emb", ")", ":", "\n", "        ", "assert", "emb", ".", "dim", "(", ")", "==", "4", ",", "'Inputs must be 4-dimensional'", "\n", "assert", "emb", ".", "size", "(", "3", ")", "==", "self", ".", "dim", ",", "'Embedding size of input doesn\\'t match pos. encoding size'", "\n", "batch_size", ",", "nsent", ",", "ntokens", ",", "emb_size", "=", "emb", ".", "size", "(", ")", "\n", "\n", "emb", "=", "emb", ".", "reshape", "(", "batch_size", "*", "nsent", ",", "ntokens", ",", "emb_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "emb", "=", "super", "(", "PositionalDocumentEncoding", ",", "self", ")", ".", "forward", "(", "emb", ")", "\n", "return", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "batch_size", ",", "nsent", ",", "ntokens", ",", "emb_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.stangelid_qt.utils.summary.RougeEvaluator.__init__": [[63, 77], ["pyrouge.Rouge155", "summary.RougeEvaluator.r.log.setLevel", "re.compile"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "system_filename_pattern", "=", "'([0-9]*)'", ",", "\n", "model_filename_pattern", "=", "'#ID#_[012].txt'", ",", "\n", "system_dir", "=", "None", ",", "model_dir", "=", "None", ",", "\n", "log_level", "=", "logging", ".", "WARNING", ")", ":", "\n", "        ", "self", ".", "system_dir", "=", "system_dir", "\n", "self", ".", "model_dir", "=", "model_dir", "\n", "\n", "self", ".", "r", "=", "Rouge155", "(", ")", "\n", "self", ".", "r", ".", "log", ".", "setLevel", "(", "log_level", ")", "\n", "self", ".", "r", ".", "system_filename_pattern", "=", "system_filename_pattern", "\n", "self", ".", "r", ".", "model_filename_pattern", "=", "model_filename_pattern", "\n", "\n", "self", ".", "results_regex", "=", "re", ".", "compile", "(", "'(ROUGE-[12L]) Average_F: ([0-9.]*) \\(95.*?([0-9.]*) - ([0-9.]*)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.summary.RougeEvaluator.evaluate": [[78, 98], ["summary.RougeEvaluator.r.convert_and_evaluate", "summary.RougeEvaluator.results_regex.findall", "summary.RougeEvaluator.r.output_to_dict"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "system_dir", "=", "None", ",", "model_dir", "=", "None", ")", ":", "\n", "        ", "if", "system_dir", "is", "None", ":", "\n", "            ", "assert", "self", ".", "system_dir", "is", "not", "None", ",", "'no system_dir given'", "\n", "system_dir", "=", "self", ".", "system_dir", "\n", "", "if", "model_dir", "is", "None", ":", "\n", "            ", "assert", "self", ".", "model_dir", "is", "not", "None", ",", "'no model_dir given'", "\n", "model_dir", "=", "self", ".", "model_dir", "\n", "\n", "", "self", ".", "r", ".", "system_dir", "=", "system_dir", "\n", "self", ".", "r", ".", "model_dir", "=", "model_dir", "\n", "\n", "full_output", "=", "self", ".", "r", ".", "convert_and_evaluate", "(", ")", "\n", "results", "=", "self", ".", "results_regex", ".", "findall", "(", "full_output", ")", "\n", "\n", "outputs", "=", "{", "}", "\n", "outputs", "[", "'full_output'", "]", "=", "full_output", "\n", "outputs", "[", "'dict_output'", "]", "=", "self", ".", "r", ".", "output_to_dict", "(", "full_output", ")", "\n", "outputs", "[", "'short_output'", "]", "=", "'\\n'", ".", "join", "(", "[", "'  {0} {1} ({2} - {3})'", ".", "format", "(", "*", "r", ")", "for", "r", "in", "results", "]", ")", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.stangelid_qt.utils.summary.truncate_summary": [[9, 59], ["enumerate", "vectorizer.transform", "sklearn.metrics.pairwise.cosine_similarity", "summary.append", "summary_sentence_ids.append", "len", "all", "len", "sentence.split", "sentence.split", "all", "summary[].split", "len", "len", "c.isdigit", "sentence.split", "len"], "function", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split", "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split", "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split", "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split"], ["def", "truncate_summary", "(", "ranked_sentences", ",", "max_tokens", "=", "75", ",", "min_tokens", "=", "1", ",", "\n", "cut_sents", "=", "False", ",", "early_stop", "=", "True", ",", "remove_non_alpha", "=", "True", ",", "\n", "vectorizer", "=", "None", ",", "cosine_threshold", "=", "None", ")", ":", "\n", "    ", "'''Truncates a summary by iteratively adding sentences\n       until the max_tokens limit is passed. \n    '''", "\n", "count", "=", "0", "\n", "summary", "=", "[", "]", "\n", "summary_sentence_ids", "=", "[", "]", "\n", "\n", "if", "vectorizer", "is", "not", "None", ":", "\n", "        ", "assert", "cosine_threshold", ">", "0", "and", "cosine_threshold", "<=", "1", ",", "'cosine threshold should be in (0,1]'", "\n", "sentence_vecs", "=", "vectorizer", ".", "transform", "(", "ranked_sentences", ")", "\n", "similarities", "=", "cosine_similarity", "(", "sentence_vecs", ")", "\n", "\n", "", "for", "i", ",", "sentence", "in", "enumerate", "(", "ranked_sentences", ")", ":", "\n", "        ", "if", "remove_non_alpha", "and", "all", "(", "c", ".", "isdigit", "(", ")", "or", "c", "in", "PUNCT", "for", "c", "in", "sentence", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "len", "(", "sentence", ".", "split", "(", ")", ")", "<", "min_tokens", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "vectorizer", "is", "not", "None", "and", "i", ">", "0", ":", "\n", "            ", "similarities_to_existing", "=", "similarities", "[", "i", ",", "summary_sentence_ids", "]", "\n", "if", "not", "all", "(", "similarities_to_existing", "<", "cosine_threshold", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "", "summary", ".", "append", "(", "sentence", ")", "\n", "summary_sentence_ids", ".", "append", "(", "i", ")", "\n", "\n", "count", "+=", "len", "(", "sentence", ".", "split", "(", ")", ")", "\n", "if", "count", ">", "max_tokens", ":", "\n", "            ", "if", "cut_sents", ":", "\n", "                ", "last_sent", "=", "summary", "[", "-", "1", "]", ".", "split", "(", ")", "\n", "last_sent", "=", "last_sent", "[", ":", "len", "(", "last_sent", ")", "-", "count", "+", "max_tokens", "]", "\n", "if", "len", "(", "last_sent", ")", ">", "0", ":", "\n", "                    ", "summary", "[", "-", "1", "]", "=", "' '", ".", "join", "(", "last_sent", ")", "\n", "", "else", ":", "\n", "                    ", "summary", "=", "summary", "[", ":", "-", "1", "]", "\n", "", "break", "\n", "", "else", ":", "\n", "                ", "summary", "=", "summary", "[", ":", "-", "1", "]", "\n", "if", "early_stop", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "count", "-=", "len", "(", "sentence", ".", "split", "(", ")", ")", "\n", "summary_sentence_ids", "=", "summary_sentence_ids", "[", ":", "-", "1", "]", "\n", "\n", "", "", "", "", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.__init__": [[18, 78], ["collections.defaultdict", "collections.defaultdict", "sentencepiece.SentencePieceProcessor", "random.sample.ReviewDataset.sp.Load", "len", "random.sample", "random.sample.ReviewDataset.entity_ids.append", "random.sample.ReviewDataset.ids.append", "random.sample.ReviewDataset.dev_entity_ids.append", "random.sample.ReviewDataset.test_entity_ids.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "sample_size", "=", "None", ",", "spmodel", "=", "None", ",", "\n", "max_sen_len", "=", "1000", ",", "max_rev_len", "=", "1000", ")", ":", "\n", "        ", "'''Parameters:\n            data (dict): dataset in appropriate json format.\n            sample_size (int): number of entities to load\n            spmodel (str): filename of sentencepiece model\n            max_sen_len (int): maximum number of tokens/pieces in sentence\n            max_rev_len (int): maximum number of sentences in review\n        '''", "\n", "self", ".", "ids", "=", "[", "]", "\n", "self", ".", "entity_ids", "=", "[", "]", "\n", "self", ".", "reviews", "=", "defaultdict", "(", "dict", ")", "\n", "self", ".", "labels", "=", "defaultdict", "(", "dict", ")", "\n", "self", ".", "lengths", "=", "{", "}", "\n", "self", ".", "nclasses", "=", "0", "\n", "self", ".", "dev_entity_ids", "=", "None", "\n", "self", ".", "test_entity_ids", "=", "None", "\n", "self", ".", "has_splits", "=", "False", "\n", "\n", "self", ".", "max_sen_len", "=", "max_sen_len", "\n", "self", ".", "max_rev_len", "=", "max_rev_len", "\n", "\n", "if", "sample_size", "is", "not", "None", ":", "\n", "            ", "data", "=", "sample", "(", "data", ",", "sample_size", ")", "\n", "\n", "# stores unprocessed data", "\n", "", "for", "entity_data", "in", "data", ":", "\n", "            ", "entity_id", "=", "entity_data", "[", "'entity_id'", "]", "\n", "self", ".", "entity_ids", ".", "append", "(", "entity_id", ")", "\n", "\n", "if", "'split'", "in", "entity_data", ":", "\n", "                ", "if", "self", ".", "dev_entity_ids", "is", "None", ":", "\n", "                    ", "self", ".", "dev_entity_ids", "=", "[", "]", "\n", "self", ".", "test_entity_ids", "=", "[", "]", "\n", "\n", "", "if", "entity_data", "[", "'split'", "]", "==", "'dev'", ":", "\n", "                    ", "self", ".", "dev_entity_ids", ".", "append", "(", "entity_id", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "test_entity_ids", ".", "append", "(", "entity_id", ")", "\n", "\n", "", "", "for", "review_data", "in", "entity_data", "[", "'reviews'", "]", ":", "\n", "                ", "review_id", "=", "review_data", "[", "'review_id'", "]", "\n", "if", "'rating'", "in", "review_data", ":", "\n", "                    ", "label", "=", "review_data", "[", "'rating'", "]", "-", "1", "\n", "", "else", ":", "\n", "                    ", "label", "=", "0", "\n", "\n", "", "if", "label", "+", "1", ">", "self", ".", "nclasses", ":", "\n", "                    ", "self", ".", "nclasses", "=", "label", "+", "1", "\n", "\n", "", "full_id", "=", "'__'", ".", "join", "(", "[", "entity_id", ",", "review_id", "]", ")", "\n", "sentences", "=", "review_data", "[", "'sentences'", "]", "\n", "self", ".", "ids", ".", "append", "(", "full_id", ")", "\n", "self", ".", "reviews", "[", "entity_id", "]", "[", "review_id", "]", "=", "sentences", "\n", "self", ".", "labels", "[", "entity_id", "]", "[", "review_id", "]", "=", "label", "\n", "\n", "# load sentencepiece vocabulary", "\n", "", "", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "spmodel", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "sp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.__getitem__": [[79, 97], ["full_id.split", "type", "data.ReviewDataset.vectorize", "len"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split", "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.vectorize"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'''Fetches vectorized example and stores data and lengths'''", "\n", "if", "type", "(", "index", ")", "is", "int", ":", "\n", "            ", "full_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "full_id", "=", "index", "\n", "\n", "", "entity_id", ",", "review_id", "=", "full_id", ".", "split", "(", "'__'", ")", "\n", "label", "=", "self", ".", "labels", "[", "entity_id", "]", "[", "review_id", "]", "\n", "review", "=", "self", ".", "reviews", "[", "entity_id", "]", "[", "review_id", "]", "[", ":", "self", ".", "max_rev_len", "]", "\n", "vectorized_review", "=", "[", "self", ".", "vectorize", "(", "sentence", ")", "for", "sentence", "in", "review", "]", "\n", "\n", "if", "full_id", "not", "in", "self", ".", "lengths", ":", "\n", "            ", "sen_len", "=", "[", "len", "(", "sentence", ")", "for", "sentence", "in", "vectorized_review", "]", "\n", "self", ".", "lengths", "[", "full_id", "]", "=", "sen_len", "\n", "self", ".", "lengths_updated", "=", "True", "\n", "\n", "", "return", "vectorized_review", ",", "label", ",", "full_id", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.__len__": [[98, 101], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'''Returns number of examples'''", "\n", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.split": [[102, 119], ["len", "int", "int", "int", "random.shuffle", "numpy.round", "numpy.round", "numpy.round"], "methods", ["None"], ["", "def", "split", "(", "self", ",", "train", "=", "0.8", ",", "dev", "=", "0.1", ",", "test", "=", "0.1", ",", "shuf", "=", "True", ")", ":", "\n", "        ", "'''Splits dataset into train/dev/test splits'''", "\n", "if", "self", ".", "has_splits", ":", "\n", "            ", "return", "\n", "\n", "", "if", "shuf", ":", "\n", "            ", "shuffle", "(", "self", ".", "ids", ")", "\n", "\n", "", "size", "=", "len", "(", "self", ".", "ids", ")", "\n", "train_size", "=", "int", "(", "np", ".", "round", "(", "size", "*", "train", ")", ")", "\n", "dev_size", "=", "int", "(", "np", ".", "round", "(", "size", "*", "dev", ")", ")", "\n", "test_size", "=", "int", "(", "np", ".", "round", "(", "size", "*", "test", ")", ")", "\n", "\n", "self", ".", "train_ids", "=", "self", ".", "ids", "[", ":", "train_size", "]", "\n", "self", ".", "dev_ids", "=", "self", ".", "ids", "[", "train_size", ":", "train_size", "+", "dev_size", "]", "\n", "self", ".", "test_ids", "=", "self", ".", "ids", "[", "train_size", "+", "dev_size", ":", "train_size", "+", "dev_size", "+", "test_size", "]", "\n", "self", ".", "has_splits", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.vectorize": [[120, 123], ["data.ReviewDataset.sp.EncodeAsIds"], "methods", ["None"], ["", "def", "vectorize", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "'''Vectorizes a sentence using sentencepiece'''", "\n", "return", "self", ".", "sp", ".", "EncodeAsIds", "(", "sentence", ")", "[", ":", "self", ".", "max_sen_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.unvectorize": [[124, 133], ["data.ReviewDataset.sp.DecodeIds", "type", "token_ids.tolist.tolist.tolist", "token_ids.tolist.tolist.index", "data.ReviewDataset.eos_id", "len"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.eos_id"], ["", "def", "unvectorize", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "'''Returns sentence string from vectorized sentence'''", "\n", "if", "type", "(", "token_ids", ")", "!=", "'list'", ":", "\n", "            ", "token_ids", "=", "token_ids", ".", "tolist", "(", ")", "\n", "", "try", ":", "\n", "            ", "end", "=", "token_ids", ".", "index", "(", "self", ".", "eos_id", "(", ")", ")", "\n", "", "except", ":", "\n", "            ", "end", "=", "len", "(", "token_ids", ")", "+", "1", "\n", "", "return", "self", ".", "sp", ".", "DecodeIds", "(", "token_ids", "[", ":", "end", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.unvectorize_review": [[134, 140], ["sentences.append", "data.ReviewDataset.unvectorize"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.unvectorize"], ["", "def", "unvectorize_review", "(", "self", ",", "review", ")", ":", "\n", "        ", "'''Returns review string from matrix'''", "\n", "sentences", "=", "[", "]", "\n", "for", "token_ids", "in", "review", ":", "\n", "            ", "sentences", ".", "append", "(", "self", ".", "unvectorize", "(", "token_ids", ")", ")", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.pad_id": [[141, 143], ["data.ReviewDataset.sp.pad_id"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.pad_id"], ["", "def", "pad_id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "pad_id", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.unk_id": [[144, 146], ["data.ReviewDataset.sp.unk_id"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.unk_id"], ["", "def", "unk_id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "unk_id", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.bos_id": [[147, 149], ["data.ReviewDataset.sp.bos_id"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.bos_id"], ["", "def", "bos_id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "bos_id", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.eos_id": [[150, 152], ["data.ReviewDataset.sp.eos_id"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewDataset.eos_id"], ["", "def", "eos_id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "eos_id", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewSummarizationDataset.__init__": [[156, 161], ["data.ReviewDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["def", "__init__", "(", "self", ",", "data", ",", "sample_size", "=", "None", ",", "spmodel", "=", "None", ",", "\n", "max_sen_len", "=", "1000", ",", "max_rev_len", "=", "1000", ")", ":", "\n", "        ", "super", "(", "ReviewSummarizationDataset", ",", "self", ")", ".", "__init__", "(", "data", ",", "sample_size", ",", "\n", "spmodel", ",", "max_sen_len", ",", "max_rev_len", ")", "\n", "self", ".", "has_entity_splits", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewSummarizationDataset.entity_split": [[162, 182], ["int", "sorted", "random.sample", "len", "data.ReviewSummarizationDataset.reviews.keys", "len"], "methods", ["None"], ["", "def", "entity_split", "(", "self", ",", "dev_split", "=", "0.5", ",", "split_by", "=", "'alphanum'", ")", ":", "\n", "        ", "'''Splits benchmark to dev and test set'''", "\n", "if", "split_by", "==", "'presplit'", ":", "\n", "            ", "assert", "self", ".", "dev_entity_ids", "is", "not", "None", "and", "self", ".", "test_entity_ids", "is", "not", "None", ",", "'test dataset has no presplit info. use other splitting method'", "\n", "self", ".", "has_entity_splits", "=", "True", "\n", "return", "\n", "\n", "", "if", "split_by", "==", "'alphanum'", ":", "# split by arphanumeric order", "\n", "            ", "entity_ids", "=", "sorted", "(", "self", ".", "entity_ids", ")", "\n", "", "elif", "split_by", "==", "'original'", ":", "# splits by order they appeared in file", "\n", "            ", "entity_ids", "=", "self", ".", "entity_ids", "\n", "", "else", ":", "# splits randomly", "\n", "            ", "entity_ids", "=", "sample", "(", "self", ".", "reviews", ".", "keys", "(", ")", ",", "len", "(", "self", ".", "reviews", ")", ")", "\n", "\n", "", "dev_size", "=", "int", "(", "len", "(", "entity_ids", ")", "*", "dev_split", ")", "\n", "self", ".", "dev_entity_ids", "=", "entity_ids", "[", ":", "dev_size", "]", "\n", "self", ".", "test_entity_ids", "=", "entity_ids", "[", "dev_size", ":", "]", "\n", "self", ".", "has_entity_splits", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewSummarizationDataset.get_entity_batch_samplers": [[183, 200], ["data.ReviewSummarizationDataset.reviews.keys", "data.EntityReviewBucketBatchSampler"], "methods", ["None"], ["", "def", "get_entity_batch_samplers", "(", "self", ",", "batch_size", "=", "5", ",", "split", "=", "None", ",", "pct", "=", "1.0", ")", ":", "\n", "        ", "'''Returns one batch sampler per entity'''", "\n", "samplers", "=", "{", "}", "\n", "if", "split", "is", "None", ":", "\n", "            ", "entity_ids", "=", "self", ".", "reviews", ".", "keys", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "split", "==", "'dev'", "or", "split", "==", "'test'", ",", "'Unknown split (use dev/test)'", "\n", "assert", "self", ".", "has_entity_splits", ",", "'No entity split found'", "\n", "if", "split", "==", "'dev'", ":", "\n", "                ", "entity_ids", "=", "self", ".", "dev_entity_ids", "\n", "", "else", ":", "\n", "                ", "entity_ids", "=", "self", ".", "test_entity_ids", "\n", "\n", "", "", "for", "entity_id", "in", "self", ".", "reviews", ":", "\n", "            ", "samplers", "[", "entity_id", "]", "=", "EntityReviewBucketBatchSampler", "(", "self", ",", "entity_id", ",", "batch_size", ",", "pct", ")", "\n", "", "return", "samplers", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewBucketBatchSampler.__init__": [[210, 242], ["collections.defaultdict", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "len", "data.ReviewBucketBatchSampler.buckets[].append", "sorted", "data.ReviewBucketBatchSampler.buckets[].sort", "range", "max", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ",", "shuffle_batches", "=", "True", ",", "split", "=", "None", ")", ":", "\n", "        ", "'''Initializes sampler by creating and sorting buckets'''", "\n", "if", "split", "is", "None", ":", "\n", "            ", "ids", "=", "dataset", ".", "ids", "\n", "", "else", ":", "\n", "            ", "assert", "dataset", ".", "has_splits", ",", "'Dataset doesn\\'t have train/dev/test splits'", "\n", "if", "split", "==", "'train'", ":", "\n", "                ", "ids", "=", "dataset", ".", "train_ids", "\n", "", "elif", "split", "==", "'dev'", ":", "\n", "                ", "ids", "=", "dataset", ".", "dev_ids", "\n", "", "else", ":", "\n", "                ", "ids", "=", "dataset", ".", "test_ids", "\n", "\n", "", "", "lengths", "=", "dataset", ".", "lengths", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "shuffle_batches", "=", "shuffle_batches", "\n", "\n", "self", ".", "buckets", "=", "defaultdict", "(", "list", ")", "\n", "for", "full_id", "in", "tqdm", "(", "ids", ",", "disable", "=", "True", ")", ":", "\n", "            ", "if", "full_id", "not", "in", "lengths", ":", "\n", "                ", "dataset", "[", "full_id", "]", "# calls __getitem__ to load vectorized lengths", "\n", "", "rev_len", "=", "len", "(", "lengths", "[", "full_id", "]", ")", "\n", "self", ".", "buckets", "[", "rev_len", "]", ".", "append", "(", "full_id", ")", "\n", "\n", "", "self", ".", "batch_list", "=", "[", "]", "\n", "for", "bucket_len", "in", "tqdm", "(", "sorted", "(", "self", ".", "buckets", ")", ",", "disable", "=", "True", ")", ":", "\n", "# sort reviews within bucket", "\n", "            ", "self", ".", "buckets", "[", "bucket_len", "]", ".", "sort", "(", "key", "=", "lambda", "full_id", ":", "max", "(", "lengths", "[", "full_id", "]", ")", ")", "\n", "\n", "# batch_list holds the bucket length and starting index of the batch", "\n", "self", ".", "batch_list", "+=", "[", "(", "bucket_len", ",", "start_idx", ")", "\n", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "self", ".", "buckets", "[", "bucket_len", "]", ")", ",", "self", ".", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewBucketBatchSampler.__iter__": [[243, 248], ["random.shuffle"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle_batches", ":", "\n", "            ", "shuffle", "(", "self", ".", "batch_list", ")", "\n", "", "for", "bucket_len", ",", "start_idx", "in", "self", ".", "batch_list", ":", "\n", "            ", "yield", "self", ".", "buckets", "[", "bucket_len", "]", "[", "start_idx", ":", "start_idx", "+", "self", ".", "batch_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewBucketBatchSampler.__len__": [[249, 251], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "batch_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.EntityReviewBucketBatchSampler.__init__": [[260, 288], ["collections.defaultdict", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "int", "random.shuffle", "len", "data.EntityReviewBucketBatchSampler.buckets[].append", "sorted", "data.EntityReviewBucketBatchSampler.buckets[].sort", "len", "range", "max", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "entity_id", ",", "batch_size", ",", "pct", "=", "1.0", ")", ":", "\n", "        ", "'''Initializes sampler by creating and sorting buckets'''", "\n", "ids", "=", "[", "'__'", ".", "join", "(", "[", "entity_id", ",", "review_id", "]", ")", "\n", "for", "review_id", "in", "dataset", ".", "reviews", "[", "entity_id", "]", "]", "\n", "\n", "if", "pct", "<", "1.0", ":", "\n", "            ", "num_ids", "=", "int", "(", "len", "(", "ids", ")", "*", "pct", ")", "\n", "shuffle", "(", "ids", ")", "\n", "ids", "=", "ids", "[", ":", "num_ids", "]", "\n", "\n", "", "lengths", "=", "dataset", ".", "lengths", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "buckets", "=", "defaultdict", "(", "list", ")", "\n", "for", "full_id", "in", "tqdm", "(", "ids", ",", "disable", "=", "True", ")", ":", "\n", "            ", "if", "full_id", "not", "in", "lengths", ":", "\n", "                ", "dataset", "[", "full_id", "]", "# calls __getitem__ to load vectorized lengths", "\n", "", "rev_len", "=", "len", "(", "lengths", "[", "full_id", "]", ")", "\n", "self", ".", "buckets", "[", "rev_len", "]", ".", "append", "(", "full_id", ")", "\n", "\n", "", "self", ".", "batch_list", "=", "[", "]", "\n", "for", "bucket_len", "in", "tqdm", "(", "sorted", "(", "self", ".", "buckets", ")", ",", "disable", "=", "True", ")", ":", "\n", "# sort reviews within bucket", "\n", "            ", "self", ".", "buckets", "[", "bucket_len", "]", ".", "sort", "(", "key", "=", "lambda", "full_id", ":", "max", "(", "lengths", "[", "full_id", "]", ")", ")", "\n", "\n", "# batch_list holds the bucket length and starting index of the batch", "\n", "self", ".", "batch_list", "+=", "[", "(", "bucket_len", ",", "start_idx", ")", "\n", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "self", ".", "buckets", "[", "bucket_len", "]", ")", ",", "self", ".", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.EntityReviewBucketBatchSampler.__iter__": [[289, 292], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "bucket_len", ",", "start_idx", "in", "self", ".", "batch_list", ":", "\n", "            ", "yield", "self", ".", "buckets", "[", "bucket_len", "]", "[", "start_idx", ":", "start_idx", "+", "self", ".", "batch_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.EntityReviewBucketBatchSampler.__len__": [[293, 295], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "batch_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewCollator.__init__": [[301, 306], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "padding_idx", "=", "0", ",", "unk_idx", "=", "1", ",", "bos_idx", "=", "2", ",", "eos_idx", "=", "3", ")", ":", "\n", "        ", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "unk_idx", "=", "unk_idx", "\n", "self", ".", "bos_idx", "=", "bos_idx", "\n", "self", ".", "eos_idx", "=", "eos_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewCollator.collate_reviews": [[307, 319], ["zip", "max", "max", "review.extend", "torch.tensor", "torch.tensor", "len", "len", "sentence.extend", "len", "len"], "methods", ["None"], ["", "def", "collate_reviews", "(", "self", ",", "samples", ")", ":", "\n", "        ", "'''Collates samples in a batch, by adding appropriate padding'''", "\n", "reviews", ",", "labels", ",", "_", "=", "zip", "(", "*", "samples", ")", "\n", "max_tokens", "=", "max", "(", "[", "len", "(", "sentence", ")", "for", "review", "in", "reviews", "for", "sentence", "in", "review", "]", ")", "\n", "max_sentences", "=", "max", "(", "[", "len", "(", "review", ")", "for", "review", "in", "reviews", "]", ")", "\n", "\n", "for", "review", "in", "reviews", ":", "\n", "            ", "for", "sentence", "in", "review", ":", "\n", "                ", "sentence", ".", "extend", "(", "[", "self", ".", "padding_idx", "]", "*", "(", "max_tokens", "-", "len", "(", "sentence", ")", ")", ")", "\n", "", "review", ".", "extend", "(", "[", "[", "self", ".", "padding_idx", "]", "*", "max_tokens", "]", "*", "(", "max_sentences", "-", "len", "(", "review", ")", ")", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "reviews", ")", ",", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewCollator.collate_reviews_with_ids": [[320, 332], ["zip", "max", "max", "review.extend", "torch.tensor", "torch.tensor", "len", "len", "sentence.extend", "len", "len"], "methods", ["None"], ["", "def", "collate_reviews_with_ids", "(", "self", ",", "samples", ")", ":", "\n", "        ", "'''Collates samples in a batch, by adding appropriate padding'''", "\n", "reviews", ",", "labels", ",", "full_ids", "=", "zip", "(", "*", "samples", ")", "\n", "max_tokens", "=", "max", "(", "[", "len", "(", "sentence", ")", "for", "review", "in", "reviews", "for", "sentence", "in", "review", "]", ")", "\n", "max_sentences", "=", "max", "(", "[", "len", "(", "review", ")", "for", "review", "in", "reviews", "]", ")", "\n", "\n", "for", "review", "in", "reviews", ":", "\n", "            ", "for", "sentence", "in", "review", ":", "\n", "                ", "sentence", ".", "extend", "(", "[", "self", ".", "padding_idx", "]", "*", "(", "max_tokens", "-", "len", "(", "sentence", ")", ")", ")", "\n", "", "review", ".", "extend", "(", "[", "[", "self", ".", "padding_idx", "]", "*", "max_tokens", "]", "*", "(", "max_sentences", "-", "len", "(", "review", ")", ")", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "reviews", ")", ",", "torch", ".", "tensor", "(", "labels", ")", ",", "full_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.ReviewCollator.collate_reviews_generation": [[333, 364], ["zip", "max", "max", "src_review.extend", "tgt_review.extend", "gld_review.extend", "tgt_reviews.append", "gld_reviews.append", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "src_sentence.extend", "tgt_sentence.extend", "gld_sentence.extend", "tgt_review.append", "gld_review.append", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "collate_reviews_generation", "(", "self", ",", "samples", ")", ":", "\n", "        ", "'''Collates samples in a batch, by adding appropriate padding and bos/eos tokens'''", "\n", "src_reviews", ",", "labels", ",", "_", "=", "zip", "(", "*", "samples", ")", "\n", "max_tokens", "=", "max", "(", "[", "len", "(", "src_sentence", ")", "for", "src_review", "in", "src_reviews", "for", "src_sentence", "in", "src_review", "]", ")", "\n", "max_sentences", "=", "max", "(", "[", "len", "(", "src_review", ")", "for", "src_review", "in", "src_reviews", "]", ")", "\n", "\n", "tgt_reviews", "=", "[", "]", "\n", "gld_reviews", "=", "[", "]", "\n", "for", "src_review", "in", "src_reviews", ":", "\n", "            ", "tgt_review", "=", "[", "]", "\n", "gld_review", "=", "[", "]", "\n", "\n", "for", "src_sentence", "in", "src_review", ":", "\n", "                ", "tgt_sentence", "=", "[", "self", ".", "bos_idx", "]", "+", "src_sentence", "\n", "gld_sentence", "=", "src_sentence", "+", "[", "self", ".", "eos_idx", "]", "\n", "\n", "src_sentence", ".", "extend", "(", "[", "self", ".", "padding_idx", "]", "*", "(", "max_tokens", "-", "len", "(", "src_sentence", ")", ")", ")", "\n", "tgt_sentence", ".", "extend", "(", "[", "self", ".", "padding_idx", "]", "*", "(", "max_tokens", "+", "1", "-", "len", "(", "tgt_sentence", ")", ")", ")", "\n", "gld_sentence", ".", "extend", "(", "[", "self", ".", "padding_idx", "]", "*", "(", "max_tokens", "+", "1", "-", "len", "(", "gld_sentence", ")", ")", ")", "\n", "\n", "tgt_review", ".", "append", "(", "tgt_sentence", ")", "\n", "gld_review", ".", "append", "(", "gld_sentence", ")", "\n", "\n", "", "src_review", ".", "extend", "(", "[", "[", "self", ".", "padding_idx", "]", "*", "max_tokens", "]", "*", "(", "max_sentences", "-", "len", "(", "src_review", ")", ")", ")", "\n", "tgt_review", ".", "extend", "(", "[", "[", "self", ".", "padding_idx", "]", "*", "max_tokens", "]", "*", "(", "max_sentences", "-", "len", "(", "tgt_review", ")", ")", ")", "\n", "gld_review", ".", "extend", "(", "[", "[", "self", ".", "padding_idx", "]", "*", "max_tokens", "]", "*", "(", "max_sentences", "-", "len", "(", "gld_review", ")", ")", ")", "\n", "\n", "tgt_reviews", ".", "append", "(", "tgt_review", ")", "\n", "gld_reviews", ".", "append", "(", "gld_review", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "src_reviews", ")", ",", "torch", ".", "tensor", "(", "tgt_reviews", ")", ",", "torch", ".", "tensor", "(", "gld_reviews", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.spm_train": [[366, 375], ["sentencepiece.SentencePieceTrainer.Train"], "function", ["None"], ["", "", "def", "spm_train", "(", "filename", ",", "prefix", ",", "vocab_size", "=", "32000", ",", "coverage", "=", "1.0", ",", "model_type", "=", "'unigram'", ")", ":", "\n", "    ", "args", "=", "'--input={0} '", ".", "format", "(", "filename", ")", "+", "'--model_prefix={0} '", ".", "format", "(", "prefix", ")", "+", "'--vocab_size={0} '", ".", "format", "(", "vocab_size", ")", "+", "'--character_coverage={0} '", ".", "format", "(", "coverage", ")", "+", "'--model_type={0} '", ".", "format", "(", "model_type", ")", "+", "'--hard_vocab_limit=false '", "+", "'--pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3'", "\n", "spm", ".", "SentencePieceTrainer", ".", "Train", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.spm_train_sentence_limit": [[376, 387], ["sentencepiece.SentencePieceTrainer.Train"], "function", ["None"], ["", "def", "spm_train_sentence_limit", "(", "filename", ",", "prefix", ",", "max_sents", "=", "4000000", ",", "\n", "vocab_size", "=", "32000", ",", "coverage", "=", "1.0", ",", "model_type", "=", "'unigram'", ")", ":", "\n", "    ", "args", "=", "'--input={0} '", ".", "format", "(", "filename", ")", "+", "'--model_prefix={0} '", ".", "format", "(", "prefix", ")", "+", "'--vocab_size={0} '", ".", "format", "(", "vocab_size", ")", "+", "'--character_coverage={0} '", ".", "format", "(", "coverage", ")", "+", "'--model_type={0} '", ".", "format", "(", "model_type", ")", "+", "'--hard_vocab_limit=false '", "+", "'--input_sentence_size={0} --shuffle_input_sentence=true '", ".", "format", "(", "max_sents", ")", "+", "'--pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3'", "\n", "spm", ".", "SentencePieceTrainer", ".", "Train", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.data.spm_train_from_json": [[388, 410], ["open", "json.load", "open.close", "open", "print", "open.close", "print", "print", "os.remove", "os.remove", "data.spm_train", "data.spm_train_sentence_limit", "open.write"], "function", ["home.repos.pwc.inspect_result.stangelid_qt.utils.data.spm_train", "home.repos.pwc.inspect_result.stangelid_qt.utils.data.spm_train_sentence_limit"], ["", "def", "spm_train_from_json", "(", "fname_in", ",", "prefix", ",", "fname_tmp", "=", "'./spm.tmp'", ",", "\n", "max_sents", "=", "None", ",", "vocab_size", "=", "32000", ",", "coverage", "=", "1.0", ",", "model_type", "=", "'unigram'", ")", ":", "\n", "    ", "f", "=", "open", "(", "fname_in", ",", "'r'", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "fout", "=", "open", "(", "fname_tmp", ",", "'w'", ")", "\n", "print", "(", "'writing sentences to temp file'", ")", "\n", "for", "entity_data", "in", "data", ":", "\n", "        ", "for", "review_data", "in", "entity_data", "[", "'reviews'", "]", ":", "\n", "            ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "review_data", "[", "'sentences'", "]", ")", "+", "'\\n'", ")", "\n", "", "", "fout", ".", "close", "(", ")", "\n", "\n", "print", "(", "'launching spm training'", ")", "\n", "if", "max_sents", "is", "None", ":", "\n", "        ", "spm_train", "(", "fname_tmp", ",", "prefix", ",", "vocab_size", ",", "coverage", ",", "model_type", ")", "\n", "", "else", ":", "\n", "        ", "spm_train_sentence_limit", "(", "fname_tmp", ",", "prefix", ",", "max_sents", ",", "\n", "vocab_size", ",", "coverage", ",", "model_type", ")", "\n", "\n", "", "print", "(", "'cleaning up'", ")", "\n", "os", ".", "remove", "(", "fname_tmp", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.__init__": [[11, 22], ["torch.Module.__init__", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "training.LabelSmoothingLoss.register_buffer", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "smoothing_value", "=", "label_smoothing", "/", "(", "tgt_vocab_size", "-", "2", ")", "\n", "one_hot", "=", "torch", ".", "full", "(", "(", "tgt_vocab_size", ",", ")", ",", "smoothing_value", ")", "\n", "one_hot", "[", "self", ".", "ignore_index", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.training.LabelSmoothingLoss.forward": [[23, 33], ["training.LabelSmoothingLoss.one_hot.repeat", "training.LabelSmoothingLoss.scatter_", "training.LabelSmoothingLoss.masked_fill_", "torch.kl_div", "torch.kl_div", "torch.kl_div", "target.size", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "model_prob", "=", "self", ".", "one_hot", ".", "repeat", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "model_prob", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "model_prob", ".", "masked_fill_", "(", "(", "target", "==", "self", ".", "ignore_index", ")", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "\n", "return", "F", ".", "kl_div", "(", "output", ",", "model_prob", ",", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.__init__": [[41, 46], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "warmup_epochs", ",", "annealing_epochs", ",", "nbatches", ",", "min_coeff", "=", "0.0", ")", ":", "\n", "        ", "self", ".", "warmup_epochs", "=", "warmup_epochs", "\n", "self", ".", "annealing_epochs", "=", "annealing_epochs", "\n", "self", ".", "nbatches", "=", "nbatches", "\n", "self", ".", "min_coeff", "=", "min_coeff", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.training.ResidualCoefficientScheduler.get_residual_coefficient": [[47, 56], ["max", "float"], "methods", ["None"], ["", "def", "get_residual_coefficient", "(", "self", ",", "batch_idx", ",", "epoch_idx", ")", ":", "\n", "        ", "if", "epoch_idx", "<", "self", ".", "warmup_epochs", ":", "\n", "            ", "return", "1.0", "\n", "", "residual", "=", "1.0", "-", "(", "batch_idx", "+", "float", "(", "self", ".", "nbatches", ")", "*", "(", "epoch_idx", "-", "self", ".", "warmup_epochs", ")", ")", "/", "(", "self", ".", "annealing_epochs", "*", "self", ".", "nbatches", ")", "*", "(", "1.0", "-", "self", ".", "min_coeff", ")", "\n", "\n", "return", "max", "(", "self", ".", "min_coeff", ",", "residual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stangelid_qt.utils.training.lr_calc": [[58, 68], ["None"], "function", ["None"], ["", "", "def", "lr_calc", "(", "epoch", ")", ":", "\n", "    ", "'''Computes learning rate for current epoch, if learning rate\n    drop-off is enabled'''", "\n", "if", "epoch", "<", "args", ".", "lr_drop_epoch", "or", "epoch", ">=", "args", ".", "lr_drop_epoch", "+", "args", ".", "lr_rtrn_epochs", ":", "\n", "        ", "return", "args", ".", "lr_decay", "**", "epoch", "\n", "", "else", ":", "\n", "        ", "return", "(", "args", ".", "lr_decay", "**", "epoch", ")", "-", "(", "args", ".", "lr_decay", "**", "epoch", ")", "*", "(", "1", "-", "(", "epoch", "-", "args", ".", "lr_drop_epoch", ")", "/", "args", ".", "lr_rtrn_epochs", ")", "\n", "", "", ""]]}