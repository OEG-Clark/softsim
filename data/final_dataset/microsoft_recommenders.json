{"home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.qps_to_replicas": [[10, 34], ["math.ceil", "logger.info"], "function", ["None"], ["def", "qps_to_replicas", "(", "\n", "target_qps", ",", "processing_time", ",", "max_qp_replica", "=", "1", ",", "target_utilization", "=", "0.7", "\n", ")", ":", "\n", "    ", "\"\"\"Provide a rough estimate of the number of replicas to support a given\n    load (queries per second)\n\n    Args:\n        target_qps (int): target queries per second that you want to support\n        processing_time (float): the estimated amount of time (in seconds)\n            your service call takes\n        max_qp_replica (int): maximum number of concurrent queries per replica\n        target_utilization (float): proportion of CPU utilization you think is ideal\n\n    Returns:\n        int: Number of estimated replicas required to support a target number of queries per second.\n    \"\"\"", "\n", "concurrent_queries", "=", "target_qps", "*", "processing_time", "/", "target_utilization", "\n", "replicas", "=", "ceil", "(", "concurrent_queries", "/", "max_qp_replica", ")", "\n", "logger", ".", "info", "(", "\n", "\"Approximately {} replicas are estimated to support {} queries per second.\"", ".", "format", "(", "\n", "replicas", ",", "target_qps", "\n", ")", "\n", ")", "\n", "return", "replicas", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.replicas_to_qps": [[36, 57], ["math.floor", "logger.info"], "function", ["None"], ["", "def", "replicas_to_qps", "(", "\n", "num_replicas", ",", "processing_time", ",", "max_qp_replica", "=", "1", ",", "target_utilization", "=", "0.7", "\n", ")", ":", "\n", "    ", "\"\"\"Provide a rough estimate of the queries per second supported by a number of replicas\n\n    Args:\n        num_replicas (int): number of replicas\n        processing_time (float): the estimated amount of time (in seconds) your service call takes\n        max_qp_replica (int): maximum number of concurrent queries per replica\n        target_utilization (float): proportion of CPU utilization you think is ideal\n\n    Returns:\n        int: queries per second supported by the number of replicas\n    \"\"\"", "\n", "qps", "=", "floor", "(", "num_replicas", "*", "max_qp_replica", "*", "target_utilization", "/", "processing_time", ")", "\n", "logger", ".", "info", "(", "\n", "\"Approximately {} queries per second are supported by {} replicas.\"", ".", "format", "(", "\n", "qps", ",", "num_replicas", "\n", ")", "\n", ")", "\n", "return", "qps", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.nodes_to_replicas": [[59, 82], ["math.floor", "logger.info"], "function", ["None"], ["", "def", "nodes_to_replicas", "(", "n_cores_per_node", ",", "n_nodes", "=", "3", ",", "cpu_cores_per_replica", "=", "0.1", ")", ":", "\n", "    ", "\"\"\"Provide a rough estimate of the number of replicas supported by a\n    given number of nodes with n_cores_per_node cores each\n\n    Args:\n        n_cores_per_node (int): Total number of cores per node within an AKS\n            cluster that you want to use\n        n_nodes (int): Number of nodes (i.e. VMs) used in the AKS cluster\n        cpu_cores_per_replica (float): Cores assigned to each replica. This\n            can be fractional and corresponds to the\n            cpu_cores argument passed to AksWebservice.deploy_configuration()\n\n    Returns:\n        int: Total number of replicas supported by the configuration\n    \"\"\"", "\n", "n_cores_avail", "=", "(", "n_cores_per_node", "-", "0.5", ")", "*", "n_nodes", "-", "4.45", "\n", "replicas", "=", "floor", "(", "n_cores_avail", "/", "cpu_cores_per_replica", ")", "\n", "logger", ".", "info", "(", "\n", "\"Approximately {} replicas are supported by {} nodes with {} cores each.\"", ".", "format", "(", "\n", "replicas", ",", "n_nodes", ",", "n_cores_per_node", "\n", ")", "\n", ")", "\n", "return", "replicas", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook.__init__": [[242, 270], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "estimator", ",", "\n", "logger", ",", "\n", "true_df", ",", "\n", "y_col", ",", "\n", "eval_df", ",", "\n", "every_n_iter", "=", "10000", ",", "\n", "model_dir", "=", "None", ",", "\n", "batch_size", "=", "256", ",", "\n", "eval_fns", "=", "None", ",", "\n", "**", "eval_kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Evaluation log hook class\"\"\"", "\n", "self", ".", "model", "=", "estimator", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "true_df", "=", "true_df", "\n", "self", ".", "y_col", "=", "y_col", "\n", "self", ".", "eval_df", "=", "eval_df", "\n", "self", ".", "every_n_iter", "=", "every_n_iter", "\n", "self", ".", "model_dir", "=", "model_dir", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "eval_fns", "=", "eval_fns", "\n", "self", ".", "eval_kwargs", "=", "eval_kwargs", "\n", "\n", "self", ".", "summary_writer", "=", "None", "\n", "self", ".", "global_step_tensor", "=", "None", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook.begin": [[271, 279], ["tensorflow.compat.v1.summary.FileWriterCache.get", "tensorflow.compat.v1.train.get_or_create_global_step"], "methods", ["None"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "model_dir", "is", "not", "None", ":", "\n", "            ", "self", ".", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "\n", "self", ".", "model_dir", "\n", ")", "\n", "self", ".", "global_step_tensor", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook.before_run": [[280, 286], ["tensorflow.estimator.SessionRunArgs"], "methods", ["None"], ["", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "if", "self", ".", "global_step_tensor", "is", "not", "None", ":", "\n", "            ", "requests", "=", "{", "\"global_step\"", ":", "self", ".", "global_step_tensor", "}", "\n", "return", "tf", ".", "estimator", ".", "SessionRunArgs", "(", "requests", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook.after_run": [[287, 322], ["tensorflow.compat.v1.logging.get_verbosity", "tensorflow.compat.v1.logging.set_verbosity", "tensorflow.compat.v1.logging.set_verbosity", "tf_utils._TrainLogHook._log", "list", "tf_utils._TrainLogHook.eval_df.copy", "tf_utils._TrainLogHook.model.evaluate", "itertools.islice", "fn", "tf_utils._TrainLogHook._log", "tf_utils._TrainLogHook.model.predict", "len", "tf_utils.pandas_input_fn", "tf_utils.pandas_input_fn"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.wide_deep_training._log", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.evaluate", "home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.wide_deep_training._log", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn"], ["", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "global_step_tensor", "is", "not", "None", ":", "\n", "            ", "self", ".", "step", "=", "run_values", ".", "results", "[", "\"global_step\"", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "step", "+=", "1", "\n", "\n", "", "if", "self", ".", "step", "%", "self", ".", "every_n_iter", "==", "0", ":", "\n", "            ", "_prev_log_level", "=", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "get_verbosity", "(", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "ERROR", ")", "\n", "\n", "if", "self", ".", "eval_fns", "is", "None", ":", "\n", "                ", "result", "=", "self", ".", "model", ".", "evaluate", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "self", ".", "true_df", ",", "y_col", "=", "self", ".", "y_col", ",", "batch_size", "=", "self", ".", "batch_size", "\n", ")", "\n", ")", "[", "\"average_loss\"", "]", "\n", "self", ".", "_log", "(", "\"validation_loss\"", ",", "result", ")", "\n", "", "else", ":", "\n", "                ", "predictions", "=", "list", "(", "\n", "itertools", ".", "islice", "(", "\n", "self", ".", "model", ".", "predict", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "self", ".", "eval_df", ",", "batch_size", "=", "self", ".", "batch_size", "\n", ")", "\n", ")", ",", "\n", "len", "(", "self", ".", "eval_df", ")", ",", "\n", ")", "\n", ")", "\n", "prediction_df", "=", "self", ".", "eval_df", ".", "copy", "(", ")", "\n", "prediction_df", "[", "\"prediction\"", "]", "=", "[", "p", "[", "\"predictions\"", "]", "[", "0", "]", "for", "p", "in", "predictions", "]", "\n", "for", "fn", "in", "self", ".", "eval_fns", ":", "\n", "                    ", "result", "=", "fn", "(", "self", ".", "true_df", ",", "prediction_df", ",", "**", "self", ".", "eval_kwargs", ")", "\n", "self", ".", "_log", "(", "fn", ".", "__name__", ",", "result", ")", "\n", "\n", "", "", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "set_verbosity", "(", "_prev_log_level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook.end": [[323, 326], ["tf_utils._TrainLogHook.summary_writer.flush"], "methods", ["None"], ["", "", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "if", "self", ".", "summary_writer", "is", "not", "None", ":", "\n", "            ", "self", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._TrainLogHook._log": [[327, 334], ["tf_utils._TrainLogHook.logger.log", "tensorflow.compat.v1.Summary", "tf_utils._TrainLogHook.summary_writer.add_summary", "tensorflow.compat.v1.Summary.Value"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["", "", "def", "_log", "(", "self", ",", "tag", ",", "value", ")", ":", "\n", "        ", "self", ".", "logger", ".", "log", "(", "tag", ",", "value", ")", "\n", "if", "self", ".", "summary_writer", "is", "not", "None", ":", "\n", "            ", "summary", "=", "tf", ".", "compat", ".", "v1", ".", "Summary", "(", "\n", "value", "=", "[", "tf", ".", "compat", ".", "v1", ".", "Summary", ".", "Value", "(", "tag", "=", "tag", ",", "simple_value", "=", "value", ")", "]", "\n", ")", "\n", "self", ".", "summary_writer", ".", "add_summary", "(", "summary", ",", "self", ".", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.__init__": [[339, 342], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializer\"\"\"", "\n", "self", ".", "_log", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log": [[343, 353], ["tf_utils.MetricsLogger._log[].append"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "metric", ",", "value", ")", ":", "\n", "        ", "\"\"\"Log metrics. Each metric's log will be stored in the corresponding list.\n\n        Args:\n            metric (str): Metric name.\n            value (float): Value.\n        \"\"\"", "\n", "if", "metric", "not", "in", "self", ".", "_log", ":", "\n", "            ", "self", ".", "_log", "[", "metric", "]", "=", "[", "]", "\n", "", "self", ".", "_log", "[", "metric", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.get_log": [[354, 361], ["None"], "methods", ["None"], ["", "def", "get_log", "(", "self", ")", ":", "\n", "        ", "\"\"\"Getter\n\n        Returns:\n            dict: Log metrics.\n        \"\"\"", "\n", "return", "self", ".", "_log", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn_for_saved_model": [[25, 56], ["feat_name_type.values", "df.iterrows", "len", "tensorflow.train.Example", "feat_name_type.items", "tf.train.Example.SerializeToString", "tensorflow.constant", "feat.int64_list.value.extend", "feat.float_list.value.extend", "feat.float_list.value.extend"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["def", "pandas_input_fn_for_saved_model", "(", "df", ",", "feat_name_type", ")", ":", "\n", "    ", "\"\"\"Pandas input function for TensorFlow SavedModel.\n\n    Args:\n        df (pandas.DataFrame): Data containing features.\n        feat_name_type (dict): Feature name and type spec. E.g.\n            `{'userID': int, 'itemID': int, 'rating': float}`\n\n    Returns:\n        func: Input function\n\n    \"\"\"", "\n", "for", "feat_type", "in", "feat_name_type", ".", "values", "(", ")", ":", "\n", "        ", "assert", "feat_type", "in", "(", "int", ",", "float", ",", "list", ")", "\n", "\n", "", "def", "input_fn", "(", ")", ":", "\n", "        ", "examples", "=", "[", "None", "]", "*", "len", "(", "df", ")", "\n", "for", "i", ",", "sample", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "            ", "ex", "=", "tf", ".", "train", ".", "Example", "(", ")", "\n", "for", "feat_name", ",", "feat_type", "in", "feat_name_type", ".", "items", "(", ")", ":", "\n", "                ", "feat", "=", "ex", ".", "features", ".", "feature", "[", "feat_name", "]", "\n", "if", "feat_type", "==", "int", ":", "\n", "                    ", "feat", ".", "int64_list", ".", "value", ".", "extend", "(", "[", "sample", "[", "feat_name", "]", "]", ")", "\n", "", "elif", "feat_type", "==", "float", ":", "\n", "                    ", "feat", ".", "float_list", ".", "value", ".", "extend", "(", "[", "sample", "[", "feat_name", "]", "]", ")", "\n", "", "elif", "feat_type", "==", "list", ":", "\n", "                    ", "feat", ".", "float_list", ".", "value", ".", "extend", "(", "sample", "[", "feat_name", "]", ")", "\n", "", "", "examples", "[", "i", "]", "=", "ex", ".", "SerializeToString", "(", ")", "\n", "", "return", "{", "\"inputs\"", ":", "tf", ".", "constant", "(", "examples", ")", "}", "\n", "\n", "", "return", "input_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn": [[58, 101], ["df.copy", "isinstance", "tf_utils._dataset", "df.copy.pop", "numpy.array", "np.array.tolist"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._dataset"], ["", "def", "pandas_input_fn", "(", "\n", "df", ",", "y_col", "=", "None", ",", "batch_size", "=", "128", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "seed", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"Pandas input function for TensorFlow high-level API Estimator.\n    This function returns a `tf.data.Dataset` function.\n\n    .. note::\n\n        `tf.estimator.inputs.pandas_input_fn` cannot handle array/list column properly.\n        For more information, see https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn\n\n    Args:\n        df (pandas.DataFrame): Data containing features.\n        y_col (str): Label column name if df has it.\n        batch_size (int): Batch size for the input function.\n        num_epochs (int): Number of epochs to iterate over data. If `None`, it will run forever.\n        shuffle (bool): If True, shuffles the data queue.\n        seed (int): Random seed for shuffle.\n\n    Returns:\n        tf.data.Dataset: Function.\n    \"\"\"", "\n", "\n", "X_df", "=", "df", ".", "copy", "(", ")", "\n", "if", "y_col", "is", "not", "None", ":", "\n", "        ", "y", "=", "X_df", ".", "pop", "(", "y_col", ")", ".", "values", "\n", "", "else", ":", "\n", "        ", "y", "=", "None", "\n", "\n", "", "X", "=", "{", "}", "\n", "for", "col", "in", "X_df", ".", "columns", ":", "\n", "        ", "values", "=", "X_df", "[", "col", "]", ".", "values", "\n", "if", "isinstance", "(", "values", "[", "0", "]", ",", "(", "list", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "values", "=", "np", ".", "array", "(", "values", ".", "tolist", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "X", "[", "col", "]", "=", "values", "\n", "\n", "", "return", "lambda", ":", "_dataset", "(", "\n", "x", "=", "X", ",", "\n", "y", "=", "y", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils._dataset": [[104, 120], ["dataset.shuffle.repeat().batch", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "dataset.shuffle.shuffle", "warnings.warn", "dataset.shuffle.repeat"], "function", ["None"], ["", "def", "_dataset", "(", "x", ",", "y", "=", "None", ",", "batch_size", "=", "128", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "seed", "=", "None", ")", ":", "\n", "    ", "if", "y", "is", "None", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "x", ",", "y", ")", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "\n", "1000", ",", "seed", "=", "seed", ",", "reshuffle_each_iteration", "=", "True", "# buffer size = 1000", "\n", ")", "\n", "", "elif", "seed", "is", "not", "None", ":", "\n", "        ", "import", "warnings", "\n", "\n", "warnings", ".", "warn", "(", "\"Seed was set but `shuffle=False`. Seed will be ignored.\"", ")", "\n", "\n", "", "return", "dataset", ".", "repeat", "(", "num_epochs", ")", ".", "batch", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer": [[122, 155], ["name.lower.lower", "optimizer_class", "kwargs.get", "kwargs.get", "KeyError", "kwargs.get", "list"], "function", ["None"], ["", "def", "build_optimizer", "(", "name", ",", "lr", "=", "0.001", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Get an optimizer for TensorFlow high-level API Estimator.\n\n    Available options are: `adadelta`, `adagrad`, `adam`, `ftrl`, `momentum`, `rmsprop` or `sgd`.\n\n    Args:\n        name (str): Optimizer name.\n        lr (float): Learning rate\n        kwargs: Optimizer arguments as key-value pairs\n\n    Returns:\n        tf.train.Optimizer: Tensorflow optimizer.\n    \"\"\"", "\n", "name", "=", "name", ".", "lower", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "optimizer_class", "=", "OPTIMIZERS", "[", "name", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "KeyError", "(", "\"Optimizer name should be one of: {}\"", ".", "format", "(", "list", "(", "OPTIMIZERS", ")", ")", ")", "\n", "\n", "# Set parameters", "\n", "", "params", "=", "{", "}", "\n", "if", "name", "==", "\"ftrl\"", ":", "\n", "        ", "params", "[", "\"l1_regularization_strength\"", "]", "=", "kwargs", ".", "get", "(", "\n", "\"l1_regularization_strength\"", ",", "0.0", "\n", ")", "\n", "params", "[", "\"l2_regularization_strength\"", "]", "=", "kwargs", ".", "get", "(", "\n", "\"l2_regularization_strength\"", ",", "0.0", "\n", ")", "\n", "", "elif", "name", "==", "\"momentum\"", "or", "name", "==", "\"rmsprop\"", ":", "\n", "        ", "params", "[", "\"momentum\"", "]", "=", "kwargs", ".", "get", "(", "\"momentum\"", ",", "0.0", ")", "\n", "\n", "", "return", "optimizer_class", "(", "learning_rate", "=", "lr", ",", "**", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.export_model": [[157, 186], ["tensorflow.compat.v1.logging.set_verbosity", "tensorflow_estimator.python.estimator.export.export.build_supervised_input_receiver_fn_from_input_fn", "tensorflow_estimator.python.estimator.export.export.build_supervised_input_receiver_fn_from_input_fn", "tensorflow.estimator.export.build_parsing_serving_input_receiver_fn", "model.experimental_export_all_saved_models", "model.experimental_export_all_saved_models.decode", "tensorflow.feature_column.make_parse_example_spec"], "function", ["None"], ["", "def", "export_model", "(", "model", ",", "train_input_fn", ",", "eval_input_fn", ",", "tf_feat_cols", ",", "base_dir", ")", ":", "\n", "    ", "\"\"\"Export TensorFlow estimator (model).\n\n    Args:\n        model (tf.estimator.Estimator): Model to export.\n        train_input_fn (function): Training input function to create data receiver spec.\n        eval_input_fn (function): Evaluation input function to create data receiver spec.\n        tf_feat_cols (list(tf.feature_column)): Feature columns.\n        base_dir (str): Base directory to export the model.\n\n    Returns:\n        str: Exported model path\n    \"\"\"", "\n", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "compat", ".", "v1", ".", "logging", ".", "ERROR", ")", "\n", "train_rcvr_fn", "=", "build_supervised_input_receiver_fn_from_input_fn", "(", "train_input_fn", ")", "\n", "eval_rcvr_fn", "=", "build_supervised_input_receiver_fn_from_input_fn", "(", "eval_input_fn", ")", "\n", "serve_rcvr_fn", "=", "tf", ".", "estimator", ".", "export", ".", "build_parsing_serving_input_receiver_fn", "(", "\n", "tf", ".", "feature_column", ".", "make_parse_example_spec", "(", "tf_feat_cols", ")", "\n", ")", "\n", "rcvr_fn_map", "=", "{", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "train_rcvr_fn", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "eval_rcvr_fn", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "serve_rcvr_fn", ",", "\n", "}", "\n", "exported_path", "=", "model", ".", "experimental_export_all_saved_models", "(", "\n", "export_dir_base", "=", "base_dir", ",", "input_receiver_fn_map", "=", "rcvr_fn_map", "\n", ")", "\n", "\n", "return", "exported_path", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.evaluation_log_hook": [[188, 238], ["tf_utils._TrainLogHook"], "function", ["None"], ["", "def", "evaluation_log_hook", "(", "\n", "estimator", ",", "\n", "logger", ",", "\n", "true_df", ",", "\n", "y_col", ",", "\n", "eval_df", ",", "\n", "every_n_iter", "=", "10000", ",", "\n", "model_dir", "=", "None", ",", "\n", "batch_size", "=", "256", ",", "\n", "eval_fns", "=", "None", ",", "\n", "**", "eval_kwargs", "\n", ")", ":", "\n", "    ", "\"\"\"Evaluation log hook for TensorFlow high-level API Estimator.\n\n    .. note::\n       TensorFlow Estimator model uses the last checkpoint weights for evaluation or prediction.\n       In order to get the most up-to-date evaluation results while training,\n       set model's `save_checkpoints_steps` to be equal or greater than hook's `every_n_iter`.\n\n    Args:\n        estimator (tf.estimator.Estimator): Model to evaluate.\n        logger (Logger): Custom logger to log the results.\n            E.g., define a subclass of Logger for AzureML logging.\n        true_df (pd.DataFrame): Ground-truth data.\n        y_col (str): Label column name in true_df\n        eval_df (pd.DataFrame): Evaluation data without label column.\n        every_n_iter (int): Evaluation frequency (steps).\n        model_dir (str): Model directory to save the summaries to. If None, does not record.\n        batch_size (int): Number of samples fed into the model at a time.\n            Note, the batch size doesn't affect on evaluation results.\n        eval_fns (iterable of functions): List of evaluation functions that have signature of\n            (true_df, prediction_df, **eval_kwargs)->(float). If None, loss is calculated on true_df.\n        eval_kwargs: Evaluation function's keyword arguments.\n            Note, prediction column name should be 'prediction'\n\n    Returns:\n        tf.train.SessionRunHook: Session run hook to evaluate the model while training.\n    \"\"\"", "\n", "\n", "return", "_TrainLogHook", "(", "\n", "estimator", ",", "\n", "logger", ",", "\n", "true_df", ",", "\n", "y_col", ",", "\n", "eval_df", ",", "\n", "every_n_iter", ",", "\n", "model_dir", ",", "\n", "batch_size", ",", "\n", "eval_fns", ",", "\n", "**", "eval_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.exponential_decay": [[12, 26], ["numpy.minimum", "numpy.power"], "function", ["None"], ["def", "exponential_decay", "(", "value", ",", "max_val", ",", "half_life", ")", ":", "\n", "    ", "\"\"\"Compute decay factor for a given value based on an exponential decay.\n\n    Values greater than `max_val` will be set to 1.\n\n    Args:\n        value (numeric): Value to calculate decay factor\n        max_val (numeric): Value at which decay factor will be 1\n        half_life (numeric): Value at which decay factor will be 0.5\n\n    Returns:\n        float: Decay factor\n    \"\"\"", "\n", "return", "np", ".", "minimum", "(", "1.0", ",", "np", ".", "power", "(", "0.5", ",", "(", "max_val", "-", "value", ")", "/", "half_life", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.jaccard": [[28, 51], ["cooccurrence.diagonal", "numpy.expand_dims", "numpy.expand_dims", "numpy.array", "numpy.errstate"], "function", ["None"], ["", "def", "jaccard", "(", "cooccurrence", ")", ":", "\n", "    ", "\"\"\"Helper method to calculate the Jaccard similarity of a matrix of co-occurrences.\n    When comparing Jaccard with count co-occurrence and lift similarity, count favours\n    predictability, meaning that the most popular items will be recommended most of\n    the time. Lift, by contrast, favours discoverability/serendipity, meaning that an\n    item that is less popular overall but highly favoured by a small subset of users\n    is more likely to be recommended. Jaccard is a compromise between the two.\n\n    Args:\n        cooccurrence (numpy.ndarray): the symmetric matrix of co-occurrences of items.\n\n    Returns:\n        numpy.ndarray: The matrix of Jaccard similarities between any two items.\n    \"\"\"", "\n", "\n", "diag", "=", "cooccurrence", ".", "diagonal", "(", ")", "\n", "diag_rows", "=", "np", ".", "expand_dims", "(", "diag", ",", "axis", "=", "0", ")", "\n", "diag_cols", "=", "np", ".", "expand_dims", "(", "diag", ",", "axis", "=", "1", ")", "\n", "\n", "with", "np", ".", "errstate", "(", "invalid", "=", "\"ignore\"", ",", "divide", "=", "\"ignore\"", ")", ":", "\n", "        ", "result", "=", "cooccurrence", "/", "(", "diag_rows", "+", "diag_cols", "-", "cooccurrence", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.lift": [[53, 74], ["cooccurrence.diagonal", "numpy.expand_dims", "numpy.expand_dims", "numpy.array", "numpy.errstate"], "function", ["None"], ["", "def", "lift", "(", "cooccurrence", ")", ":", "\n", "    ", "\"\"\"Helper method to calculate the Lift of a matrix of co-occurrences. In comparison\n    with basic co-occurrence and Jaccard similarity, lift favours discoverability and\n    serendipity, as opposed to co-occurrence that favours the most popular items, and\n    Jaccard that is a compromise between the two.\n\n    Args:\n        cooccurrence (numpy.ndarray): The symmetric matrix of co-occurrences of items.\n\n    Returns:\n        numpy.ndarray: The matrix of Lifts between any two items.\n    \"\"\"", "\n", "\n", "diag", "=", "cooccurrence", ".", "diagonal", "(", ")", "\n", "diag_rows", "=", "np", ".", "expand_dims", "(", "diag", ",", "axis", "=", "0", ")", "\n", "diag_cols", "=", "np", ".", "expand_dims", "(", "diag", ",", "axis", "=", "1", ")", "\n", "\n", "with", "np", ".", "errstate", "(", "invalid", "=", "\"ignore\"", ",", "divide", "=", "\"ignore\"", ")", ":", "\n", "        ", "result", "=", "cooccurrence", "/", "(", "diag_rows", "*", "diag_cols", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items": [[76, 114], ["isinstance", "min", "scores.todense.todense", "logger.warning", "numpy.arange", "numpy.argpartition", "numpy.argsort", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "get_top_k_scored_items", "(", "scores", ",", "top_k", ",", "sort_top_k", "=", "False", ")", ":", "\n", "    ", "\"\"\"Extract top K items from a matrix of scores for each user-item pair, optionally sort results per user.\n\n    Args:\n        scores (numpy.ndarray): Score matrix (users x items).\n        top_k (int): Number of top items to recommend.\n        sort_top_k (bool): Flag to sort top k results.\n\n    Returns:\n        numpy.ndarray, numpy.ndarray:\n        - Indices into score matrix for each users top items.\n        - Scores corresponding to top items.\n\n    \"\"\"", "\n", "\n", "# ensure we're working with a dense ndarray", "\n", "if", "isinstance", "(", "scores", ",", "sparse", ".", "spmatrix", ")", ":", "\n", "        ", "scores", "=", "scores", ".", "todense", "(", ")", "\n", "\n", "", "if", "scores", ".", "shape", "[", "1", "]", "<", "top_k", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Number of items is less than top_k, limiting top_k to number of items\"", "\n", ")", "\n", "", "k", "=", "min", "(", "top_k", ",", "scores", ".", "shape", "[", "1", "]", ")", "\n", "\n", "test_user_idx", "=", "np", ".", "arange", "(", "scores", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", "\n", "\n", "# get top K items and scores", "\n", "# this determines the un-ordered top-k item indices for each user", "\n", "top_items", "=", "np", ".", "argpartition", "(", "scores", ",", "-", "k", ",", "axis", "=", "1", ")", "[", ":", ",", "-", "k", ":", "]", "\n", "top_scores", "=", "scores", "[", "test_user_idx", ",", "top_items", "]", "\n", "\n", "if", "sort_top_k", ":", "\n", "        ", "sort_ind", "=", "np", ".", "argsort", "(", "-", "top_scores", ")", "\n", "top_items", "=", "top_items", "[", "test_user_idx", ",", "sort_ind", "]", "\n", "top_scores", "=", "top_scores", "[", "test_user_idx", ",", "sort_ind", "]", "\n", "\n", "", "return", "np", ".", "array", "(", "top_items", ")", ",", "np", ".", "array", "(", "top_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.binarize": [[116, 127], ["numpy.where"], "function", ["None"], ["", "def", "binarize", "(", "a", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Binarize the values.\n\n    Args:\n        a (numpy.ndarray): Input array that needs to be binarized.\n        threshold (float): Threshold below which all values are set to 0, else 1.\n\n    Returns:\n        numpy.ndarray: Binarized array.\n    \"\"\"", "\n", "return", "np", ".", "where", "(", "a", ">", "threshold", ",", "1.0", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.rescale": [[129, 151], ["data.min", "data.max"], "function", ["None"], ["", "def", "rescale", "(", "data", ",", "new_min", "=", "0", ",", "new_max", "=", "1", ",", "data_min", "=", "None", ",", "data_max", "=", "None", ")", ":", "\n", "    ", "\"\"\"Rescale/normalize the data to be within the range `[new_min, new_max]`\n    If data_min and data_max are explicitly provided, they will be used\n    as the old min/max values instead of taken from the data.\n\n    .. note::\n        This is same as the `scipy.MinMaxScaler` with the exception that we can override\n        the min/max of the old scale.\n\n    Args:\n        data (numpy.ndarray): 1d scores vector or 2d score matrix (users x items).\n        new_min (int|float): The minimum of the newly scaled data.\n        new_max (int|float): The maximum of the newly scaled data.\n        data_min (None|number): The minimum of the passed data [if omitted it will be inferred].\n        data_max (None|number): The maximum of the passed data [if omitted it will be inferred].\n\n    Returns:\n        numpy.ndarray: The newly scaled/normalized data.\n    \"\"\"", "\n", "data_min", "=", "data", ".", "min", "(", ")", "if", "data_min", "is", "None", "else", "data_min", "\n", "data_max", "=", "data", ".", "max", "(", ")", "if", "data_max", "is", "None", "else", "data_max", "\n", "return", "(", "data", "-", "data_min", ")", "/", "(", "data_max", "-", "data_min", ")", "*", "(", "new_max", "-", "new_min", ")", "+", "new_min", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.__init__": [[28, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_timer", "=", "default_timer", "\n", "self", ".", "_interval", "=", "0", "\n", "self", ".", "running", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.__enter__": [[33, 36], ["timer.Timer.start"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.__exit__": [[37, 39], ["timer.Timer.stop"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.stop"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.__str__": [[40, 42], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"{:0.4f}\"", ".", "format", "(", "self", ".", "interval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start": [[43, 47], ["timer.Timer._timer"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Start the timer.\"\"\"", "\n", "self", ".", "init", "=", "self", ".", "_timer", "(", ")", "\n", "self", ".", "running", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.stop": [[48, 57], ["timer.Timer._timer", "ValueError"], "methods", ["None"], ["", "def", "stop", "(", "self", ")", ":", "\n", "        ", "\"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"", "\n", "self", ".", "end", "=", "self", ".", "_timer", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "_interval", "=", "self", ".", "end", "-", "self", ".", "init", "\n", "self", ".", "running", "=", "False", "\n", "", "except", "AttributeError", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Timer has not been initialized: use start() or the contextual form with Timer() as t:\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.interval": [[59, 70], ["ValueError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "interval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get time interval in seconds.\n\n        Returns:\n            float: Seconds.\n        \"\"\"", "\n", "if", "self", ".", "running", ":", "\n", "            ", "raise", "ValueError", "(", "\"Timer has not been stopped, please use stop().\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_interval", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_jupyter": [[7, 22], ["get_ipython"], "function", ["None"], ["def", "is_jupyter", "(", ")", ":", "\n", "    ", "\"\"\"Check if the module is running on Jupyter notebook/console.\n\n    Returns:\n        bool: True if the module is running on Jupyter notebook or Jupyter console,\n        False otherwise.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "shell_name", "=", "get_ipython", "(", ")", ".", "__class__", ".", "__name__", "\n", "if", "shell_name", "==", "\"ZMQInteractiveShell\"", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "", "", "except", "NameError", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_databricks": [[24, 38], ["os.path.realpath"], "function", ["None"], ["", "", "def", "is_databricks", "(", ")", ":", "\n", "    ", "\"\"\"Check if the module is running on Databricks.\n\n    Returns:\n        bool: True if the module is running on Databricks notebook,\n        False otherwise.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "os", ".", "path", ".", "realpath", "(", "\".\"", ")", "==", "\"/databricks/driver\"", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "", "", "except", "NameError", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.plot.line_graph": [[4, 80], ["isinstance", "matplotlib.subplot", "isinstance", "matplotlib.plot", "enumerate", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.legend", "matplotlib.subplots_adjust", "matplotlib.figure", "zip", "len", "len", "isinstance", "matplotlib.plot", "matplotlib.axvline", "matplotlib.figure", "range", "zip", "len", "range", "len"], "function", ["None"], ["def", "line_graph", "(", "\n", "values", ",", "\n", "labels", ",", "\n", "x_guides", "=", "None", ",", "\n", "x_name", "=", "None", ",", "\n", "y_name", "=", "None", ",", "\n", "x_min_max", "=", "None", ",", "\n", "y_min_max", "=", "None", ",", "\n", "legend_loc", "=", "None", ",", "\n", "subplot", "=", "None", ",", "\n", "plot_size", "=", "(", "5", ",", "5", ")", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Plot line graph(s).\n\n    Args:\n        values (list(list(float or tuple)) or list(float or tuple): List of graphs or a graph to plot\n            E.g. a graph = list(y) or list((y,x))\n        labels (list(str) or str): List of labels or a label for graph.\n            If labels is a string, this function assumes the values is a single graph.\n        x_guides (list(int)): List of guidelines (a vertical dotted line)\n        x_name (str): x axis label\n        y_name (str): y axis label\n        x_min_max (list or tuple): Min and max value of the x axis\n        y_min_max (list or tuple): Min and max value of the y axis\n        legend_loc (str): legend location\n        subplot (list or tuple): `matplotlib.pyplot.subplot` format. E.g. to draw 1 x 2 subplot,\n            pass `(1,2,1)` for the first subplot and `(1,2,2)` for the second subplot.\n        plot_size (list or tuple): Plot size (width, height)\n    \"\"\"", "\n", "if", "subplot", ":", "\n", "# Setup figure only once", "\n", "        ", "if", "subplot", "[", "2", "]", "==", "1", ":", "\n", "            ", "if", "plot_size", ":", "\n", "                ", "plt", ".", "figure", "(", "\n", "figsize", "=", "(", "\n", "plot_size", "[", "0", "]", "\n", "*", "subplot", "[", "1", "]", ",", "# fig width = plot width * num columns", "\n", "plot_size", "[", "1", "]", "\n", "*", "subplot", "[", "0", "]", ",", "# fig height = plot height * num rows", "\n", ")", "\n", ")", "\n", "", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0.5", ")", "\n", "", "plt", ".", "subplot", "(", "*", "subplot", ")", "\n", "", "else", ":", "\n", "        ", "if", "plot_size", ":", "\n", "            ", "plt", ".", "figure", "(", "figsize", "=", "plot_size", ")", "\n", "\n", "", "", "if", "isinstance", "(", "labels", ",", "str", ")", ":", "\n", "        ", "if", "isinstance", "(", "values", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "y", ",", "x", "=", "values", ",", "range", "(", "len", "(", "values", ")", ")", "\n", "", "else", ":", "\n", "            ", "y", ",", "x", "=", "zip", "(", "*", "values", ")", "\n", "", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "labels", ",", "lw", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "values", ")", "==", "len", "(", "labels", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "values", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "y", ",", "x", "=", "v", ",", "range", "(", "len", "(", "v", ")", ")", "\n", "", "else", ":", "\n", "                ", "y", ",", "x", "=", "zip", "(", "*", "v", ")", "\n", "", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "labels", "[", "i", "]", ",", "lw", "=", "1", ")", "\n", "\n", "", "", "if", "x_guides", ":", "\n", "        ", "for", "x", "in", "x_guides", ":", "\n", "            ", "plt", ".", "axvline", "(", "x", "=", "x", ",", "color", "=", "\"gray\"", ",", "lw", "=", "1", ",", "linestyle", "=", "\"--\"", ")", "\n", "\n", "", "", "if", "x_name", ":", "\n", "        ", "plt", ".", "xlabel", "(", "x_name", ")", "\n", "", "if", "y_name", ":", "\n", "        ", "plt", ".", "ylabel", "(", "y_name", ")", "\n", "", "if", "x_min_max", ":", "\n", "        ", "plt", ".", "xlim", "(", "*", "x_min_max", ")", "\n", "", "if", "y_min_max", ":", "\n", "        ", "plt", ".", "ylim", "(", "*", "y_min_max", ")", "\n", "", "if", "legend_loc", ":", "\n", "        ", "plt", ".", "legend", "(", "loc", "=", "legend_loc", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_number_gpus": [[18, 28], ["len"], "function", ["None"], ["def", "get_number_gpus", "(", ")", ":", "\n", "    ", "\"\"\"Get the number of GPUs in the system.\n\n    Returns:\n        int: Number of GPUs.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "return", "len", "(", "cuda", ".", "gpus", ")", "\n", "", "except", "CudaSupportError", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_gpu_info": [[30, 52], ["numba.cuda.current_context().get_memory_info", "gpus.append", "gpu.name.decode", "numba.cuda.current_context"], "function", ["None"], ["", "", "def", "get_gpu_info", "(", ")", ":", "\n", "    ", "\"\"\"Get information of GPUs.\n\n    Returns:\n        list: List of gpu information dictionary as with `device_name`, `total_memory` (in Mb) and `free_memory` (in Mb).\n        Returns an empty list if there is no cuda device available.\n    \"\"\"", "\n", "gpus", "=", "[", "]", "\n", "try", ":", "\n", "        ", "for", "gpu", "in", "cuda", ".", "gpus", ":", "\n", "            ", "with", "gpu", ":", "\n", "                ", "meminfo", "=", "cuda", ".", "current_context", "(", ")", ".", "get_memory_info", "(", ")", "\n", "g", "=", "{", "\n", "\"device_name\"", ":", "gpu", ".", "name", ".", "decode", "(", "\"ASCII\"", ")", ",", "\n", "\"total_memory\"", ":", "meminfo", "[", "1", "]", "/", "1048576", ",", "# Mb", "\n", "\"free_memory\"", ":", "meminfo", "[", "0", "]", "/", "1048576", ",", "# Mb", "\n", "}", "\n", "gpus", ".", "append", "(", "g", ")", "\n", "", "", "", "except", "CudaSupportError", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "gpus", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.clear_memory_all_gpus": [[54, 62], ["logger.info", "numba.cuda.current_context().deallocations.clear", "numba.cuda.current_context"], "function", ["None"], ["", "def", "clear_memory_all_gpus", "(", ")", ":", "\n", "    ", "\"\"\"Clear memory of all GPUs.\"\"\"", "\n", "try", ":", "\n", "        ", "for", "gpu", "in", "cuda", ".", "gpus", ":", "\n", "            ", "with", "gpu", ":", "\n", "                ", "cuda", ".", "current_context", "(", ")", ".", "deallocations", ".", "clear", "(", ")", "\n", "", "", "", "except", "CudaSupportError", ":", "\n", "        ", "logger", ".", "info", "(", "\"No CUDA available\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_cuda_version": [[64, 84], ["NotImplementedError", "os.path.isfile", "ValueError", "open", "f.read().replace", "f.read"], "function", ["None"], ["", "", "def", "get_cuda_version", "(", "unix_path", "=", "DEFAULT_CUDA_PATH_LINUX", ")", ":", "\n", "    ", "\"\"\"Get CUDA version.\n\n    Args:\n        unix_path (str): Path to CUDA version file in Linux/Mac.\n\n    Returns:\n        str: Version of the library.\n    \"\"\"", "\n", "if", "sys", ".", "platform", "==", "\"win32\"", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement this!\"", ")", "\n", "", "elif", "sys", ".", "platform", "in", "[", "\"linux\"", ",", "\"darwin\"", "]", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "unix_path", ")", ":", "\n", "            ", "with", "open", "(", "unix_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "data", "=", "f", ".", "read", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "", "return", "data", "\n", "", "else", ":", "\n", "            ", "return", "\"No CUDA in this machine\"", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not in Windows, Linux or Mac\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_cudnn_version": [[86, 132], ["gpu_utils.get_cudnn_version.find_cudnn_in_headers"], "function", ["None"], ["", "", "def", "get_cudnn_version", "(", ")", ":", "\n", "    ", "\"\"\"Get the CuDNN version.\n\n    Returns:\n        str: Version of the library.\n\n    \"\"\"", "\n", "\n", "def", "find_cudnn_in_headers", "(", "candidates", ")", ":", "\n", "        ", "for", "c", "in", "candidates", ":", "\n", "            ", "file", "=", "glob", ".", "glob", "(", "c", ")", "\n", "if", "file", ":", "\n", "                ", "break", "\n", "", "", "if", "file", ":", "\n", "            ", "with", "open", "(", "file", "[", "0", "]", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "version", "=", "\"\"", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "if", "\"#define CUDNN_MAJOR\"", "in", "line", ":", "\n", "                        ", "version", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "if", "\"#define CUDNN_MINOR\"", "in", "line", ":", "\n", "                        ", "version", "+=", "\".\"", "+", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "if", "\"#define CUDNN_PATCHLEVEL\"", "in", "line", ":", "\n", "                        ", "version", "+=", "\".\"", "+", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "if", "version", ":", "\n", "                ", "return", "version", "\n", "", "else", ":", "\n", "                ", "return", "\"Cannot find CUDNN version\"", "\n", "", "", "else", ":", "\n", "            ", "return", "\"No CUDNN in this machine\"", "\n", "\n", "", "", "if", "sys", ".", "platform", "==", "\"win32\"", ":", "\n", "        ", "candidates", "=", "[", "\n", "\"C:\\\\NVIDIA\\\\cuda\\\\include\\\\cudnn.h\"", ",", "\n", "\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v*\\\\include\\\\cudnn.h\"", ",", "\n", "]", "\n", "", "elif", "sys", ".", "platform", "==", "\"linux\"", ":", "\n", "        ", "candidates", "=", "[", "\n", "\"/usr/include/x86_64-linux-gnu/cudnn_v*.h\"", ",", "\n", "\"/usr/local/cuda/include/cudnn.h\"", ",", "\n", "\"/usr/include/cudnn.h\"", ",", "\n", "]", "\n", "", "elif", "sys", ".", "platform", "==", "\"darwin\"", ":", "\n", "        ", "candidates", "=", "[", "\"/usr/local/cuda/include/cudnn.h\"", ",", "\"/usr/include/cudnn.h\"", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not in Windows, Linux or Mac\"", ")", "\n", "", "return", "find_cudnn_in_headers", "(", "candidates", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_memory_management.start_watching_memory": [[39, 46], ["IPython.get_ipython", "IPython.get_ipython.events.register", "IPython.get_ipython.events.register"], "function", ["None"], ["", "def", "start_watching_memory", "(", ")", ":", "\n", "    ", "\"\"\"Register memory profiling tools to IPython instance.\"\"\"", "\n", "global", "watching_memory", "\n", "watching_memory", "=", "True", "\n", "ip", "=", "get_ipython", "(", ")", "\n", "ip", ".", "events", ".", "register", "(", "\"post_run_cell\"", ",", "watch_memory", ")", "\n", "ip", ".", "events", ".", "register", "(", "\"pre_run_cell\"", ",", "pre_run_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_memory_management.stop_watching_memory": [[48, 63], ["IPython.get_ipython", "IPython.get_ipython.events.unregister", "IPython.get_ipython.events.unregister", "print", "print"], "function", ["None"], ["", "def", "stop_watching_memory", "(", ")", ":", "\n", "    ", "\"\"\"Unregister memory profiling tools from IPython instance.\"\"\"", "\n", "global", "watching_memory", "\n", "watching_memory", "=", "False", "\n", "ip", "=", "get_ipython", "(", ")", "\n", "try", ":", "\n", "        ", "ip", ".", "events", ".", "unregister", "(", "\"post_run_cell\"", ",", "watch_memory", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "print", "(", "\"ERROR: problem when unregistering\"", ")", "\n", "pass", "\n", "", "try", ":", "\n", "        ", "ip", ".", "events", ".", "unregister", "(", "\"pre_run_cell\"", ",", "pre_run_cell", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "print", "(", "\"ERROR: problem when unregistering\"", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_memory_management.watch_memory": [[65, 93], ["output_template.format", "memory_profiler.memory_usage", "time.time", "len", "print", "str", "psutil.virtual_memory"], "function", ["None"], ["", "", "def", "watch_memory", "(", ")", ":", "\n", "    ", "\"\"\"Bring in the global memory usage value from the previous iteration\"\"\"", "\n", "global", "previous_call_memory_usage", ",", "keep_watching", ",", "watching_memory", ",", "input_cells", "\n", "new_memory_usage", "=", "memory_profiler", ".", "memory_usage", "(", ")", "[", "0", "]", "\n", "memory_delta", "=", "new_memory_usage", "-", "previous_call_memory_usage", "\n", "keep_watching", "=", "False", "\n", "total_memory", "=", "psutil", ".", "virtual_memory", "(", ")", "[", "0", "]", "/", "1024", "/", "1024", "# in Mb", "\n", "# calculate time delta using global t1 (from the pre-run event) and current time", "\n", "time_delta_secs", "=", "time", ".", "time", "(", ")", "-", "t1", "\n", "num_commands", "=", "len", "(", "input_cells", ")", "-", "1", "\n", "cmd", "=", "\"In [{}]\"", ".", "format", "(", "num_commands", ")", "\n", "# convert the results into a pretty string", "\n", "output_template", "=", "(", "\n", "\"{cmd} used {memory_delta:0.4f} Mb RAM in \"", "\n", "\"{time_delta:0.2f}s, total RAM usage \"", "\n", "\"{memory_usage:0.2f} Mb, total RAM \"", "\n", "\"memory {total_memory:0.2f} Mb\"", "\n", ")", "\n", "output", "=", "output_template", ".", "format", "(", "\n", "time_delta", "=", "time_delta_secs", ",", "\n", "cmd", "=", "cmd", ",", "\n", "memory_delta", "=", "memory_delta", ",", "\n", "memory_usage", "=", "new_memory_usage", ",", "\n", "total_memory", "=", "total_memory", ",", "\n", ")", "\n", "if", "watching_memory", ":", "\n", "        ", "print", "(", "str", "(", "output", ")", ")", "\n", "", "previous_call_memory_usage", "=", "new_memory_usage", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_memory_management.pre_run_cell": [[95, 99], ["time.time"], "function", ["None"], ["", "def", "pre_run_cell", "(", ")", ":", "\n", "    ", "\"\"\"Capture current time before we execute the current command\"\"\"", "\n", "global", "t1", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.invert_dictionary": [[8, 23], ["dictionary.items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["def", "invert_dictionary", "(", "dictionary", ")", ":", "\n", "    ", "\"\"\"Invert a dictionary\n\n    .. note::\n\n        If the dictionary has unique keys and unique values, the inversion would be perfect. However, if there are\n        repeated values, the inversion can take different keys\n\n    Args:\n        dictionary (dict): A dictionary\n\n    Returns:\n        dict: inverted dictionary\n    \"\"\"", "\n", "return", "{", "v", ":", "k", "for", "k", ",", "v", "in", "dictionary", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.get_physical_memory": [[25, 32], ["psutil.virtual_memory"], "function", ["None"], ["", "def", "get_physical_memory", "(", ")", ":", "\n", "    ", "\"\"\"Get the physical memory in GBs.\n\n    Returns:\n        float: Physical memory in GBs.\n    \"\"\"", "\n", "return", "psutil", ".", "virtual_memory", "(", ")", "[", "0", "]", "/", "1073741824", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.get_number_processors": [[34, 47], ["os.cpu_count", "multiprocessing.cpu_count"], "function", ["None"], ["", "def", "get_number_processors", "(", ")", ":", "\n", "    ", "\"\"\"Get the number of processors in a CPU.\n\n    Returns:\n        int: Number of processors.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "num", "=", "os", ".", "cpu_count", "(", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "import", "multiprocessing", "# force exception in case multiprocessing is not installed", "\n", "\n", "num", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "", "return", "num", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.spark_utils.start_or_get_spark": [[19, 70], ["spark_opts.append", "eval", "config.items", "spark_opts.append", "spark_opts.append", "isinstance"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["def", "start_or_get_spark", "(", "\n", "app_name", "=", "\"Sample\"", ",", "\n", "url", "=", "\"local[*]\"", ",", "\n", "memory", "=", "\"10g\"", ",", "\n", "config", "=", "None", ",", "\n", "packages", "=", "None", ",", "\n", "jars", "=", "None", ",", "\n", "repositories", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Start Spark if not started\n\n    Args:\n        app_name (str): set name of the application\n        url (str): URL for spark master\n        memory (str): size of memory for spark driver\n        config (dict): dictionary of configuration options\n        packages (list): list of packages to install\n        jars (list): list of jar files to add\n        repositories (list): list of maven repositories\n\n    Returns:\n        object: Spark context.\n    \"\"\"", "\n", "\n", "submit_args", "=", "\"\"", "\n", "if", "packages", "is", "not", "None", ":", "\n", "        ", "submit_args", "=", "\"--packages {} \"", ".", "format", "(", "\",\"", ".", "join", "(", "packages", ")", ")", "\n", "", "if", "jars", "is", "not", "None", ":", "\n", "        ", "submit_args", "+=", "\"--jars {} \"", ".", "format", "(", "\",\"", ".", "join", "(", "jars", ")", ")", "\n", "", "if", "repositories", "is", "not", "None", ":", "\n", "        ", "submit_args", "+=", "\"--repositories {}\"", ".", "format", "(", "\",\"", ".", "join", "(", "repositories", ")", ")", "\n", "", "if", "submit_args", ":", "\n", "        ", "os", ".", "environ", "[", "\"PYSPARK_SUBMIT_ARGS\"", "]", "=", "\"{} pyspark-shell\"", ".", "format", "(", "submit_args", ")", "\n", "\n", "", "spark_opts", "=", "[", "\n", "'SparkSession.builder.appName(\"{}\")'", ".", "format", "(", "app_name", ")", ",", "\n", "'master(\"{}\")'", ".", "format", "(", "url", ")", ",", "\n", "]", "\n", "\n", "if", "config", "is", "not", "None", ":", "\n", "        ", "for", "key", ",", "raw_value", "in", "config", ".", "items", "(", ")", ":", "\n", "            ", "value", "=", "(", "\n", "'\"{}\"'", ".", "format", "(", "raw_value", ")", "if", "isinstance", "(", "raw_value", ",", "str", ")", "else", "raw_value", "\n", ")", "\n", "spark_opts", ".", "append", "(", "'config(\"{key}\", {value})'", ".", "format", "(", "key", "=", "key", ",", "value", "=", "value", ")", ")", "\n", "\n", "", "", "if", "config", "is", "None", "or", "\"spark.driver.memory\"", "not", "in", "config", ":", "\n", "        ", "spark_opts", ".", "append", "(", "'config(\"spark.driver.memory\", \"{}\")'", ".", "format", "(", "memory", ")", ")", "\n", "\n", "", "spark_opts", ".", "append", "(", "\"getOrCreate()\"", ")", "\n", "return", "eval", "(", "\".\"", ".", "join", "(", "spark_opts", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.data_helper.load_paper_reference": [[12, 32], ["print", "open", "os.path.basename", "rd.readline", "rd.readline.strip().split", "paper2reference_list[].append", "len", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["def", "load_paper_reference", "(", "infile", ")", ":", "\n", "    ", "r\"\"\"\n    Returns:\n       A dictionary of paperid to its list of reference_paper_IDs:\n           {PaperID, [Reference_Paper_ID01, eference_Paper_ID02, ...]}\n    \"\"\"", "\n", "print", "(", "\"loading {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "infile", ")", ")", ")", "\n", "paper2reference_list", "=", "{", "}", "\n", "with", "open", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "len", "(", "words", ")", "<", "2", ":", "\n", "                ", "continue", "\n", "", "if", "words", "[", "0", "]", "not", "in", "paper2reference_list", ":", "\n", "                ", "paper2reference_list", "[", "words", "[", "0", "]", "]", "=", "[", "]", "\n", "", "paper2reference_list", "[", "words", "[", "0", "]", "]", ".", "append", "(", "words", "[", "1", "]", ")", "\n", "", "", "return", "paper2reference_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.data_helper.load_paper_date": [[34, 57], ["print", "open", "os.path.basename", "rd.readline", "rd.readline.strip().split", "datetime.datetime.strptime", "datetime.datetime.strptime", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_paper_date", "(", "infile", ")", ":", "\n", "    ", "r\"\"\"\n    Returns:\n      A dictionary of paperid to its publication date\n         {PaperID, DateTime}\n    \"\"\"", "\n", "print", "(", "\"loading {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "infile", ")", ")", ")", "\n", "paper2date", "=", "{", "}", "\n", "with", "open", "(", "infile", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "words", "[", "8", "]", ":", "\n", "                ", "paper2date", "[", "words", "[", "0", "]", "]", "=", "datetime", ".", "strptime", "(", "\n", "words", "[", "8", "]", ",", "\"%m/%d/%Y %I:%M:%S %p\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "paper2date", "[", "words", "[", "0", "]", "]", "=", "datetime", ".", "strptime", "(", "\n", "\"1/1/1970 12:00:00 AM\"", ",", "\"%m/%d/%Y %I:%M:%S %p\"", "\n", ")", "\n", "", "", "", "return", "paper2date", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.data_helper.load_author_paperlist": [[77, 95], ["print", "open", "os.path.basename", "rd.readline", "rd.readline.strip().split", "author2paper_list[].append", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_author_paperlist", "(", "infile", ")", ":", "\n", "    ", "r\"\"\"\n    Returns:\n      A dictionary of authorID to her paper_list\n         {AuthorID, [PaperID01, PaperID02, ...]}\n    \"\"\"", "\n", "print", "(", "\"loading {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "infile", ")", ")", ")", "\n", "author2paper_list", "=", "{", "}", "\n", "with", "open", "(", "infile", ",", "\"r\"", ",", "newline", "=", "\"\\r\\n\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "words", "[", "1", "]", "not", "in", "author2paper_list", ":", "\n", "                ", "author2paper_list", "[", "words", "[", "1", "]", "]", "=", "[", "]", "\n", "", "author2paper_list", "[", "words", "[", "1", "]", "]", ".", "append", "(", "words", "[", "0", "]", ")", "\n", "", "", "return", "author2paper_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.data_helper.load_paper_author_relation": [[97, 122], ["print", "open", "os.path.basename", "rd.readline", "rd.readline.strip().split", "int", "author2paper_list[].append", "set", "paper2author_set[].add", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_paper_author_relation", "(", "infile", ")", ":", "\n", "    ", "r\"\"\"\n    Returns two objects:\n      A dictionary of authorID to her paper_list\n         {AuthorID, a list of (PaperID, AuthorSequenceNumber)}\n      A dictionary of paperID to its author set\n         {PaperID,  a set of AuthorID}\n    \"\"\"", "\n", "print", "(", "\"loading {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "infile", ")", ")", ")", "\n", "author2paper_list", "=", "{", "}", "\n", "paper2author_set", "=", "{", "}", "\n", "with", "open", "(", "infile", ",", "\"r\"", ",", "newline", "=", "\"\\r\\n\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "order", "=", "int", "(", "words", "[", "3", "]", ")", "\n", "if", "words", "[", "1", "]", "not", "in", "author2paper_list", ":", "\n", "                ", "author2paper_list", "[", "words", "[", "1", "]", "]", "=", "[", "]", "\n", "", "author2paper_list", "[", "words", "[", "1", "]", "]", ".", "append", "(", "(", "words", "[", "0", "]", ",", "order", ")", ")", "\n", "if", "words", "[", "0", "]", "not", "in", "paper2author_set", ":", "\n", "                ", "paper2author_set", "[", "words", "[", "0", "]", "]", "=", "set", "(", ")", "\n", "paper2author_set", "[", "words", "[", "0", "]", "]", ".", "add", "(", "words", "[", "1", "]", ")", "\n", "", "", "", "return", "author2paper_list", ",", "paper2author_set", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.__init__": [[17, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_full_path": [[21, 23], ["None"], "methods", ["None"], ["", "def", "get_full_path", "(", "self", ",", "stream_name", ")", ":", "\n", "        ", "return", "self", ".", "root", "+", "stream_name", "+", "\".txt\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_header": [[25, 27], ["None"], "methods", ["None"], ["", "def", "get_header", "(", "self", ",", "stream_name", ")", ":", "\n", "        ", "return", "self", ".", "streams", "[", "stream_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_type": [[29, 41], ["field.split", "fieldtype.endswith", "date_columns.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "get_type", "(", "self", ",", "stream_name", ")", ":", "\n", "        ", "date_columns", "=", "[", "]", "\n", "schema", "=", "{", "}", "\n", "for", "field", "in", "self", ".", "streams", "[", "stream_name", "]", ":", "\n", "            ", "fieldname", ",", "fieldtype", "=", "field", ".", "split", "(", "\":\"", ")", "\n", "nullable", "=", "fieldtype", ".", "endswith", "(", "\"?\"", ")", "\n", "if", "nullable", ":", "\n", "                ", "fieldtype", "=", "fieldtype", "[", ":", "-", "1", "]", "\n", "", "if", "fieldtype", "==", "\"DateTime\"", ":", "\n", "                ", "date_columns", ".", "append", "(", "fieldname", ")", "\n", "", "schema", "[", "fieldname", "]", "=", "self", ".", "datatypedict", "[", "fieldtype", "]", "\n", "", "return", "schema", ",", "date_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_name": [[43, 49], ["field.split", "names.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "get_name", "(", "self", ",", "stream_name", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "for", "field", "in", "self", ".", "streams", "[", "stream_name", "]", ":", "\n", "            ", "fieldname", ",", "fieldtype", "=", "field", ".", "split", "(", "\":\"", ")", "\n", "names", ".", "append", "(", "fieldname", ")", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_data_frame": [[51, 62], ["PandasMagClass.MicrosoftAcademicGraph.get_name", "PandasMagClass.MicrosoftAcademicGraph.get_type", "pandas.read_csv", "PandasMagClass.MicrosoftAcademicGraph.get_full_path"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_name", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_type", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.PandasMagClass.MicrosoftAcademicGraph.get_full_path"], ["", "def", "get_data_frame", "(", "self", ",", "stream_name", ")", ":", "\n", "        ", "column_name", "=", "self", ".", "get_name", "(", "stream_name", ")", "\n", "column_type", ",", "date_columns", "=", "self", ".", "get_type", "(", "stream_name", ")", "\n", "return", "pd", ".", "read_csv", "(", "\n", "filepath_or_buffer", "=", "self", ".", "get_full_path", "(", "stream_name", ")", ",", "\n", "parse_dates", "=", "date_columns", ",", "\n", "low_memory", "=", "False", ",", "\n", "names", "=", "column_name", ",", "\n", "dtype", "=", "column_type", ",", "\n", "date_parser", "=", "self", ".", "date_parse_func", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_paper_content": [[22, 107], ["print", "print", "print", "print", "len", "len", "codecs.open", "time.time", "open", "time.time", "paper2content.items", "os.path.basename", "rd.readline", "rd.readline.strip().split", "task_helper.convert2id", "paper2content[].append", "info.sort", "wt.write", "print", "int", "print", "line.strip().split.extend", "entities.extend", "len", "rd.readline.strip", "list2string", "list2string", "clip[].split", "clip[].split", "len", "range", "line.strip().split.append", "entities.append", "time.time", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.convert2id", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.list2string", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.list2string", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["def", "gen_paper_content", "(", "\n", "InFile_PaperTitleAbs_bySentence", ",", "\n", "OutFileName", ",", "\n", "word2idx", ",", "\n", "entity2idx", ",", "\n", "field", "=", "[", "\"Title\"", "]", ",", "\n", "doc_len", "=", "10", ",", "\n", ")", ":", "\n", "    ", "if", "len", "(", "word2idx", ")", "==", "0", ":", "\n", "        ", "word2idx", "[", "\"NULL\"", "]", "=", "0", "\n", "", "if", "len", "(", "entity2idx", ")", "==", "0", ":", "\n", "        ", "entity2idx", "[", "\"NULL\"", "]", "=", "0", "\n", "\n", "", "paper2content", "=", "{", "}", "\n", "print", "(", "\n", "\"loading file {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "InFile_PaperTitleAbs_bySentence", ")", ")", "\n", ")", "\n", "with", "codecs", ".", "open", "(", "InFile_PaperTitleAbs_bySentence", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "rd", ":", "\n", "        ", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rloading line: {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "paperid", ",", "category", ",", "position", ",", "sentence", ",", "fieldOfStudy", "=", "(", "\n", "words", "[", "0", "]", ",", "\n", "words", "[", "1", "]", ",", "\n", "int", "(", "words", "[", "2", "]", ")", ",", "\n", "words", "[", "3", "]", ",", "\n", "words", "[", "4", "]", ",", "\n", ")", "\n", "if", "category", "not", "in", "field", ":", "\n", "                ", "continue", "\n", "", "if", "paperid", "not", "in", "paper2content", ":", "\n", "                ", "paper2content", "[", "paperid", "]", "=", "[", "]", "\n", "", "if", "category", "==", "\"Abstract\"", ":", "\n", "                ", "position", "+=", "1000", "\n", "\n", "", "words", ",", "entities", "=", "convert2id", "(", "sentence", ",", "fieldOfStudy", ",", "word2idx", ",", "entity2idx", ")", "\n", "paper2content", "[", "paperid", "]", ".", "append", "(", "\n", "(", "position", ",", "list2string", "(", "words", ",", "\",\"", ")", ",", "list2string", "(", "entities", ",", "\",\"", ")", ")", "\n", ")", "\n", "", "", "print", "(", "\" \"", ")", "\n", "\n", "print", "(", "\"parsing into feature file  ...\"", ")", "\n", "with", "open", "(", "OutFileName", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "for", "paperid", ",", "info", "in", "paper2content", ".", "items", "(", ")", ":", "\n", "            ", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rparsed paper count: {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "\n", "", "words", "=", "[", "]", "\n", "entities", "=", "[", "]", "\n", "info", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "for", "clip", "in", "info", ":", "\n", "                ", "words", ".", "extend", "(", "clip", "[", "1", "]", ".", "split", "(", "\",\"", ")", ")", "\n", "entities", ".", "extend", "(", "clip", "[", "2", "]", ".", "split", "(", "\",\"", ")", ")", "\n", "", "if", "len", "(", "words", ")", ">", "doc_len", ":", "\n", "                ", "words", "=", "words", "[", "0", ":", "doc_len", "]", "\n", "entities", "=", "entities", "[", "0", ":", "doc_len", "]", "\n", "", "elif", "len", "(", "words", ")", "<", "doc_len", ":", "\n", "                ", "for", "_", "in", "range", "(", "doc_len", "-", "len", "(", "words", ")", ")", ":", "\n", "                    ", "words", ".", "append", "(", "\"0\"", ")", "\n", "entities", ".", "append", "(", "\"0\"", ")", "\n", "", "", "wt", ".", "write", "(", "\n", "\"{0} {1} {2}\\n\"", ".", "format", "(", "paperid", ",", "\",\"", ".", "join", "(", "words", ")", ",", "\",\"", ".", "join", "(", "entities", ")", ")", "\n", ")", "\n", "", "", "print", "(", ")", "\n", "return", "word2idx", ",", "entity2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.parse_entities": [[109, 121], ["fieldOfStudy.split", "clip.strip().split", "add2dict", "range", "int", "int", "clip.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict"], ["", "def", "parse_entities", "(", "fieldOfStudy", ",", "entity2idx", ",", "cnt", ")", ":", "\n", "    ", "res", "=", "[", "0", "]", "*", "cnt", "\n", "if", "fieldOfStudy", ":", "\n", "        ", "clips", "=", "fieldOfStudy", ".", "split", "(", "\",\"", ")", "\n", "for", "clip", "in", "clips", ":", "\n", "            ", "tokens", "=", "clip", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "\n", "field_id", "=", "tokens", "[", "0", "]", "\n", "field_idx", "=", "add2dict", "(", "field_id", ",", "entity2idx", ")", "\n", "start", ",", "end", "=", "int", "(", "tokens", "[", "1", "]", ")", ",", "int", "(", "tokens", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "start", ",", "end", "+", "1", ")", ":", "\n", "                ", "res", "[", "i", "]", "=", "field_idx", "\n", "", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.convert2id": [[123, 128], ["sentence.split", "task_helper.parse_entities", "add2dict", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.parse_entities", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict"], ["", "def", "convert2id", "(", "sentence", ",", "fieldOfStudy", ",", "word2idx", ",", "entity2idx", ")", ":", "\n", "    ", "words", "=", "sentence", ".", "split", "(", "\" \"", ")", "\n", "word_idx", "=", "[", "add2dict", "(", "word", ",", "word2idx", ")", "for", "word", "in", "words", "]", "\n", "entity_idx", "=", "parse_entities", "(", "fieldOfStudy", ",", "entity2idx", ",", "len", "(", "word_idx", ")", ")", "\n", "return", "word_idx", ",", "entity_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_knowledge_relations": [[130, 157], ["print", "os.path.join", "print", "dump_dict_as_txt", "dump_dict_as_txt", "open", "open", "wt.write", "os.path.join", "os.path.join", "os.path.basename", "rd.readline", "rd.readline.strip().split", "add2dict", "add2dict", "add2dict", "lines.append", "wt.write", "len", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.dump_dict_as_txt", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.dump_dict_as_txt", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict"], ["", "def", "gen_knowledge_relations", "(", "\n", "InFile_RelatedFieldOfStudy", ",", "OutFile_dirname", ",", "entity2idx", ",", "relation2idx", "\n", ")", ":", "\n", "    ", "print", "(", "\n", "\"processing file {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "InFile_RelatedFieldOfStudy", ")", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "OutFile_relation_triples", "=", "os", ".", "path", ".", "join", "(", "OutFile_dirname", ",", "\"train2id.txt\"", ")", "\n", "lines", "=", "[", "]", "\n", "with", "open", "(", "InFile_RelatedFieldOfStudy", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "field_idx01", "=", "add2dict", "(", "words", "[", "0", "]", ",", "entity2idx", ")", "\n", "field_idx02", "=", "add2dict", "(", "words", "[", "2", "]", ",", "entity2idx", ")", "\n", "relation_name", "=", "\"{0}_TO_{1}\"", ".", "format", "(", "words", "[", "1", "]", ",", "words", "[", "3", "]", ")", "\n", "relation_idx", "=", "add2dict", "(", "relation_name", ",", "relation2idx", ")", "\n", "lines", ".", "append", "(", "\"{0} {1} {2}\\n\"", ".", "format", "(", "field_idx01", ",", "field_idx02", ",", "relation_idx", ")", ")", "\n", "", "", "print", "(", "\"done.\"", ")", "\n", "with", "open", "(", "OutFile_relation_triples", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", ")", "as", "wt", ":", "\n", "        ", "wt", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "len", "(", "lines", ")", ")", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "wt", ".", "write", "(", "line", ")", "\n", "", "", "dump_dict_as_txt", "(", "entity2idx", ",", "os", ".", "path", ".", "join", "(", "OutFile_dirname", ",", "\"entity2id.txt\"", ")", ")", "\n", "dump_dict_as_txt", "(", "relation2idx", ",", "os", ".", "path", ".", "join", "(", "OutFile_dirname", ",", "\"relation2id.txt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_indexed_sentence_collection": [[159, 196], ["print", "open", "open", "time.time", "os.path.basename", "rd.readline", "rd.readline.strip().split", "sentence.split", "wt.write", "print", "int", "add2dict", "rd.readline.strip", "list2string", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.list2string"], ["", "def", "gen_indexed_sentence_collection", "(", "\n", "InFile_PaperTitleAbs_bySentence", ",", "OutFileName", ",", "word2idx", "\n", ")", ":", "\n", "    ", "print", "(", "\n", "\"loading file {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "InFile_PaperTitleAbs_bySentence", ")", ")", "\n", ")", "\n", "with", "open", "(", "\n", "InFile_PaperTitleAbs_bySentence", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", "\n", ")", "as", "rd", ",", "open", "(", "OutFileName", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", ")", "as", "wt", ":", "\n", "        ", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rloading line: {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "paperid", ",", "category", ",", "position", ",", "sentence", ",", "fieldOfStudy", "=", "(", "\n", "words", "[", "0", "]", ",", "\n", "words", "[", "1", "]", ",", "\n", "int", "(", "words", "[", "2", "]", ")", ",", "\n", "words", "[", "3", "]", ",", "\n", "words", "[", "4", "]", ",", "\n", ")", "\n", "\n", "if", "not", "sentence", ":", "\n", "                ", "continue", "\n", "", "tokens", "=", "sentence", ".", "split", "(", "\" \"", ")", "\n", "word_idx", "=", "[", "add2dict", "(", "token", ",", "word2idx", ")", "for", "token", "in", "tokens", "]", "\n", "wt", ".", "write", "(", "list2string", "(", "word_idx", ",", "\" \"", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_sentence_collection": [[198, 234], ["print", "open", "open", "time.time", "os.path.basename", "rd.readline", "rd.readline.strip().split", "wt.write", "sentence.split", "print", "int", "add2dict", "rd.readline.strip", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict"], ["", "", "", "def", "gen_sentence_collection", "(", "InFile_PaperTitleAbs_bySentence", ",", "OutFileName", ",", "word2idx", ")", ":", "\n", "    ", "print", "(", "\n", "\"loading file {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "InFile_PaperTitleAbs_bySentence", ")", ")", "\n", ")", "\n", "with", "open", "(", "\n", "InFile_PaperTitleAbs_bySentence", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", "\n", ")", "as", "rd", ",", "open", "(", "OutFileName", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\\r\\n\"", ")", "as", "wt", ":", "\n", "        ", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rloading line: {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "words", "=", "line", ".", "strip", "(", "\"\\r\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "paperid", ",", "category", ",", "position", ",", "sentence", ",", "fieldOfStudy", "=", "(", "\n", "words", "[", "0", "]", ",", "\n", "words", "[", "1", "]", ",", "\n", "int", "(", "words", "[", "2", "]", ")", ",", "\n", "words", "[", "3", "]", ",", "\n", "words", "[", "4", "]", ",", "\n", ")", "\n", "\n", "if", "not", "sentence", ":", "\n", "                ", "continue", "\n", "", "wt", ".", "write", "(", "sentence", "+", "\"\\n\"", ")", "\n", "\n", "for", "token", "in", "sentence", ".", "split", "(", "\" \"", ")", ":", "\n", "                ", "add2dict", "(", "token", ",", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.get_author_reference_list": [[236, 274], ["print", "time.time", "author2paper_list.items", "print", "cited_paper_info.sort", "print", "len", "cited_paper2cited_date.items", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "", "", "", "def", "get_author_reference_list", "(", "author2paper_list", ",", "paper2reference_list", ",", "paper2date", ")", ":", "\n", "    ", "print", "(", "\"parsing user's reference list ...\"", ")", "\n", "author2reference_list", "=", "{", "}", "\n", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "for", "author", ",", "paper_list", "in", "author2paper_list", ".", "items", "(", ")", ":", "\n", "        ", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"\\rparsed user count: {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "cited_paper2cited_date", "=", "{", "}", "\n", "for", "paper", "in", "paper_list", ":", "\n", "            ", "if", "paper", "not", "in", "paper2date", "or", "paper", "not", "in", "paper2reference_list", ":", "\n", "                ", "continue", "\n", "", "date", "=", "paper2date", "[", "paper", "]", "\n", "reference_list", "=", "paper2reference_list", "[", "paper", "]", "\n", "for", "cited_paper", "in", "reference_list", ":", "\n", "                ", "if", "cited_paper", "not", "in", "paper2date", ":", "\n", "                    ", "continue", "\n", "", "if", "cited_paper", "not", "in", "cited_paper2cited_date", ":", "\n", "                    ", "cited_paper2cited_date", "[", "cited_paper", "]", "=", "date", "\n", "", "else", ":", "\n", "                    ", "if", "cited_paper2cited_date", "[", "cited_paper", "]", "<", "date", ":", "\n", "                        ", "cited_paper2cited_date", "[", "cited_paper", "]", "=", "date", "\n", "", "", "", "", "if", "len", "(", "cited_paper2cited_date", ")", "<=", "0", ":", "\n", "            ", "continue", "\n", "", "cited_paper_info", "=", "[", "\n", "(", "key", ",", "paper2date", "[", "key", "]", ",", "value", ")", "\n", "for", "key", ",", "value", "in", "cited_paper2cited_date", ".", "items", "(", ")", "\n", "]", "\n", "cited_paper_info", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "author2reference_list", "[", "author", "]", "=", "cited_paper_info", "\n", "", "print", "(", ")", "\n", "return", "author2reference_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.output_author2reference_list": [[276, 289], ["print", "open", "author2reference_list.items", "wt.write", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "output_author2reference_list", "(", "author2reference_list", ",", "filename", ")", ":", "\n", "    ", "print", "(", "\"outputing author reference list\"", ")", "\n", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "for", "author", ",", "ref_list", "in", "author2reference_list", ".", "items", "(", ")", ":", "\n", "            ", "paper_list", "=", "[", "a", "[", "0", "]", "for", "a", "in", "ref_list", "]", "\n", "paper_publich_date_list", "=", "[", "str", "(", "a", "[", "1", "]", ")", "for", "a", "in", "ref_list", "]", "\n", "paper_cited_date_list", "=", "[", "str", "(", "a", "[", "2", "]", ")", "for", "a", "in", "ref_list", "]", "\n", "wt", ".", "write", "(", "\n", "\"{0}\\t{1}\\t{2}\\t{3}\\n\"", ".", "format", "(", "\n", "author", ",", "\n", "\",\"", ".", "join", "(", "paper_list", ")", ",", "\n", "\",\"", ".", "join", "(", "paper_publich_date_list", ")", ",", "\n", "\",\"", ".", "join", "(", "paper_cited_date_list", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.sample_negative_and_write_to_file": [[293, 332], ["print", "open", "time.time", "len", "sample.split", "words[].split", "wt.write", "reparameter_sampling", "print", "wt.write", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.reparameter_sampling"], ["", "", "", "def", "sample_negative_and_write_to_file", "(", "\n", "outfilename", ",", "\n", "samples", ",", "\n", "neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "remove_false_negative", "=", "False", ",", "\n", "process_id", "=", "0", ",", "\n", "process_num", "=", "4", ",", "\n", ")", ":", "\n", "    ", "with", "open", "(", "outfilename", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "_cnt", ",", "_total", "=", "0", ",", "len", "(", "samples", ")", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "for", "sample", "in", "samples", ":", "\n", "            ", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rsampling process {3}:  {0} / {1}, time elapses: {2:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "_total", ",", "time", ".", "time", "(", ")", "-", "_t0", ",", "process_id", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "if", "_cnt", "%", "process_num", "!=", "process_id", ":", "\n", "                ", "continue", "\n", "", "words", "=", "sample", ".", "split", "(", "\"%\"", ")", "\n", "label", ",", "user_tag", ",", "item_id", "=", "words", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "wt", ".", "write", "(", "sample", "+", "\"\\n\"", ")", "\n", "sampled_items_indices", "=", "reparameter_sampling", "(", "neg_cnt", ",", "sample_probs", ")", "\n", "for", "sampled_item_idx", "in", "sampled_items_indices", ":", "\n", "                ", "sampled_item", "=", "item_list", "[", "sampled_item_idx", "]", "\n", "if", "(", "\n", "not", "remove_false_negative", "\n", "or", "(", "words", "[", "1", "]", ",", "sampled_item", ")", "not", "in", "positive_pairs", "\n", ")", ":", "\n", "                    ", "wt", ".", "write", "(", "\n", "\"{0} {1} {2}%{3}\\n\"", ".", "format", "(", "0", ",", "user_tag", ",", "sampled_item", ",", "words", "[", "1", "]", ")", "\n", ")", "\n", "", "", "", "", "print", "(", "\"\\tsampling process {0} done.\"", ".", "format", "(", "process_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.get_normalized_item_freq": [[334, 342], ["list", "sum", "numpy.asarray", "item2cnt.keys", "item2cnt.values", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["", "def", "get_normalized_item_freq", "(", "item2cnt", ")", ":", "\n", "    ", "keys", "=", "list", "(", "item2cnt", ".", "keys", "(", ")", ")", "\n", "values", "=", "[", "]", "\n", "total_value", "=", "sum", "(", "item2cnt", ".", "values", "(", ")", ")", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "values", ".", "append", "(", "item2cnt", "[", "key", "]", "*", "1.0", "/", "total_value", ")", "\n", "", "values", "=", "np", ".", "asarray", "(", "values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "keys", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_has_feature_items": [[344, 354], ["set", "open", "rd.readline", "rd.readline.strip().split", "set.add", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_has_feature_items", "(", "InFile_paper_feature", ")", ":", "\n", "    ", "item_set", "=", "set", "(", ")", "\n", "with", "open", "(", "InFile_paper_feature", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "item_set", ".", "add", "(", "words", "[", "0", "]", ")", "\n", "", "", "return", "item_set", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_experiment_splits": [[356, 485], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "task_helper.load_has_feature_items", "set", "print", "time.time", "print", "random.shuffle", "task_helper.get_normalized_item_freq", "print", "task_helper.sample_negative_and_write_to_file_wrapper", "print", "task_helper.sample_negative_and_write_to_file_wrapper", "print", "task_helper.sample_negative_and_write_to_file_wrapper", "print", "dump_dict_as_txt", "os.path.exists", "os.mkdir", "random.sample", "set", "open", "open", "os.path.join", "int", "rd.readline", "rd.readline.strip().split", "words[].split", "len", "range", "len", "len", "len", "item2cnt.items", "print", "set.add", "wt.write", "len", "rd.readline.strip", "train_samples.append", "test_samples.append", "time.time", "valid_samples.append", "train_samples.append"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_has_feature_items", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.get_normalized_item_freq", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.sample_negative_and_write_to_file_wrapper", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.sample_negative_and_write_to_file_wrapper", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.sample_negative_and_write_to_file_wrapper", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.dump_dict_as_txt", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "gen_experiment_splits", "(", "\n", "file_Author2ReferencePapers", ",", "\n", "OutFile_dir", ",", "\n", "InFile_paper_feature", ",", "\n", "tag", ",", "\n", "item_ratio", "=", "1.0", ",", "\n", "process_num", "=", "1", ",", "\n", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "OutFile_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "OutFile_dir", ")", "\n", "\n", "", "user_behavior_file", "=", "os", ".", "path", ".", "join", "(", "OutFile_dir", ",", "\"user_history_{0}.txt\"", ".", "format", "(", "tag", ")", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "OutFile_dir", ",", "\"train_{0}.txt\"", ".", "format", "(", "tag", ")", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "OutFile_dir", ",", "\"valid_{0}.txt\"", ".", "format", "(", "tag", ")", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "OutFile_dir", ",", "\"test_{0}.txt\"", ".", "format", "(", "tag", ")", ")", "\n", "\n", "item_set", "=", "load_has_feature_items", "(", "InFile_paper_feature", ")", "\n", "if", "item_ratio", "<", "1.0", ":", "\n", "        ", "_selected_items", "=", "random", ".", "sample", "(", "item_set", ",", "int", "(", "len", "(", "item_set", ")", "*", "item_ratio", ")", ")", "\n", "item_set", "=", "set", "(", "_selected_items", ")", "\n", "\n", "", "_min_seq_len", "=", "2", "\n", "_min_test_seq_len", "=", "6", "\n", "_max_instance_per_user", "=", "20", "\n", "train_neg_cnt", "=", "4", "\n", "test_neg_cnt", "=", "19", "\n", "\n", "train_samples", ",", "valid_samples", ",", "test_samples", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "item2cnt", "=", "{", "}", "\n", "positive_pairs", "=", "set", "(", ")", "\n", "print", "(", "\"expanding user behaviors...\"", ")", "\n", "_cnt", "=", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "file_Author2ReferencePapers", ",", "\"r\"", ")", "as", "rd", ",", "open", "(", "\n", "user_behavior_file", ",", "\"w\"", "\n", ")", "as", "wt", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rprocessing user number : {0}, time elapses: {1:.1f}s\"", ".", "format", "(", "\n", "_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\" \"", ",", "\n", ")", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "act_items", "=", "words", "[", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "act_items", "=", "[", "_item", "for", "_item", "in", "act_items", "if", "_item", "in", "item_set", "]", "\n", "act_items_len", "=", "len", "(", "act_items", ")", "\n", "if", "act_items_len", "<=", "_min_seq_len", ":", "\n", "                ", "continue", "\n", "", "for", "act_item", "in", "act_items", ":", "\n", "                ", "positive_pairs", ".", "add", "(", "(", "words", "[", "0", "]", ",", "act_item", ")", ")", "\n", "\n", "", "user_behavior", "=", "\"\"", "\n", "for", "i", "in", "range", "(", "1", ",", "act_items_len", ")", ":", "\n", "                ", "if", "i", "==", "1", ":", "\n", "                    ", "user_behavior", "=", "act_items", "[", "i", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "user_behavior", "+=", "\",\"", "+", "act_items", "[", "i", "-", "1", "]", "\n", "\n", "", "if", "act_items_len", "-", "2", "-", "_max_instance_per_user", ">", "i", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "act_items", "[", "i", "]", "not", "in", "item2cnt", ":", "\n", "                    ", "item2cnt", "[", "act_items", "[", "i", "]", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "item2cnt", "[", "act_items", "[", "i", "]", "]", "+=", "1", "\n", "\n", "", "user_tag", "=", "\"{0}_{1}\"", ".", "format", "(", "words", "[", "0", "]", ",", "i", ")", "\n", "wt", ".", "write", "(", "\"{0} {1}\\n\"", ".", "format", "(", "user_tag", ",", "user_behavior", ")", ")", "\n", "instance", "=", "\"{0} {1} {2}%{3}\"", ".", "format", "(", "1", ",", "user_tag", ",", "act_items", "[", "i", "]", ",", "words", "[", "0", "]", ")", "\n", "if", "act_items_len", "<=", "_min_test_seq_len", ":", "\n", "                    ", "train_samples", ".", "append", "(", "instance", ")", "\n", "", "else", ":", "\n", "                    ", "if", "i", "==", "act_items_len", "-", "1", ":", "\n", "                        ", "test_samples", ".", "append", "(", "instance", ")", "\n", "", "elif", "i", "==", "act_items_len", "-", "2", ":", "\n", "                        ", "valid_samples", ".", "append", "(", "instance", ")", "\n", "", "else", ":", "\n", "                        ", "train_samples", ".", "append", "(", "instance", ")", "\n", "", "", "", "", "", "print", "(", "\n", "\"done. \\nsample number in train / valid / test is {0} / {1} / {2}\"", ".", "format", "(", "\n", "len", "(", "train_samples", ")", ",", "len", "(", "valid_samples", ")", ",", "len", "(", "test_samples", ")", "\n", ")", "\n", ")", "\n", "\n", "random", ".", "shuffle", "(", "train_samples", ")", "\n", "\n", "## only keep items which have features", "\n", "item2cnt", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "item2cnt", ".", "items", "(", ")", "if", "k", "in", "item_set", "}", "\n", "\n", "item_list", ",", "sample_probs", "=", "get_normalized_item_freq", "(", "item2cnt", ")", "\n", "print", "(", "\"negative sampling for train...\"", ")", "\n", "sample_negative_and_write_to_file_wrapper", "(", "\n", "train_file", ",", "\n", "train_samples", ",", "\n", "train_neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "process_num", "=", "process_num", ",", "\n", ")", "\n", "print", "(", "\"negative sampling for validation...\"", ")", "\n", "sample_negative_and_write_to_file_wrapper", "(", "\n", "valid_file", ",", "\n", "valid_samples", ",", "\n", "train_neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "process_num", "=", "process_num", ",", "\n", ")", "\n", "print", "(", "\"negative sampling for test...\"", ")", "\n", "sample_negative_and_write_to_file_wrapper", "(", "\n", "test_file", ",", "\n", "test_samples", ",", "\n", "test_neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "process_num", "=", "process_num", ",", "\n", ")", "\n", "print", "(", "\"done.\"", ")", "\n", "\n", "dump_dict_as_txt", "(", "item2cnt", ",", "os", ".", "path", ".", "join", "(", "OutFile_dir", ",", "\"item2freq.tsv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.sample_negative_and_write_to_file_wrapper": [[487, 530], ["range", "multiprocessing.Process", "multiprocessing.Process.start", "p_list.append", "multiprocessing.Process.join", "open", "range", "os.remove", "open", "rd.readline", "len", "wt.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start"], ["", "def", "sample_negative_and_write_to_file_wrapper", "(", "\n", "otuput_file", ",", "\n", "pos_samples", ",", "\n", "neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "process_num", "=", "1", ",", "\n", ")", ":", "\n", "    ", "p_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "process_num", ")", ":", "\n", "        ", "outfile", "=", "otuput_file", "+", "\"_part{0}\"", ".", "format", "(", "i", ")", "\n", "p", "=", "Process", "(", "\n", "target", "=", "sample_negative_and_write_to_file", ",", "\n", "args", "=", "(", "\n", "outfile", ",", "\n", "pos_samples", ",", "\n", "neg_cnt", ",", "\n", "positive_pairs", ",", "\n", "item_list", ",", "\n", "sample_probs", ",", "\n", "False", ",", "\n", "i", ",", "\n", "process_num", ",", "\n", ")", ",", "\n", ")", "\n", "p", ".", "start", "(", ")", "\n", "p_list", ".", "append", "(", "p", ")", "\n", "", "for", "p", "in", "p_list", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n", "### merge files and delete temporary files.", "\n", "", "with", "open", "(", "otuput_file", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "for", "i", "in", "range", "(", "process_num", ")", ":", "\n", "            ", "infile", "=", "otuput_file", "+", "\"_part{0}\"", ".", "format", "(", "i", ")", "\n", "with", "open", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "                ", "while", "True", ":", "\n", "                    ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                        ", "break", "\n", "", "if", "len", "(", "line", ")", ">", "1", ":", "\n", "                        ", "wt", ".", "write", "(", "line", ")", "\n", "", "", "", "os", ".", "remove", "(", "infile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.normalize_score": [[532, 550], ["pair2CocitedCnt.items", "math.sqrt", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "", "", "def", "normalize_score", "(", "pair2CocitedCnt", ",", "paper2cited_list", ",", "min_k", "=", "10", ",", "min_score", "=", "0.1", ")", ":", "\n", "    ", "res", "=", "{", "}", "\n", "for", "pair", ",", "cnt", "in", "pair2CocitedCnt", ".", "items", "(", ")", ":", "\n", "        ", "if", "pair", "[", "0", "]", "not", "in", "paper2cited_list", "or", "pair", "[", "1", "]", "not", "in", "paper2cited_list", ":", "\n", "            ", "continue", "\n", "", "if", "(", "\n", "len", "(", "paper2cited_list", "[", "pair", "[", "0", "]", "]", ")", "<", "min_k", "\n", "or", "len", "(", "paper2cited_list", "[", "pair", "[", "1", "]", "]", ")", "<", "min_k", "\n", ")", ":", "\n", "            ", "continue", "\n", "", "sim", "=", "math", ".", "sqrt", "(", "\n", "cnt", "\n", "*", "cnt", "\n", "/", "(", "4", "*", "len", "(", "paper2cited_list", "[", "pair", "[", "0", "]", "]", ")", "*", "len", "(", "paper2cited_list", "[", "pair", "[", "1", "]", "]", ")", ")", "\n", ")", "\n", "if", "sim", ">", "min_score", ":", "\n", "            ", "res", "[", "pair", "]", "=", "sim", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_paper_cocitation": [[552, 617], ["load_paper_reference", "reverse_dict_list", "time.time", "reverse_dict_list.items", "print", "time.time", "load_paper_reference.items", "print", "len", "len", "task_helper.normalize_score", "task_helper.normalize_score", "print", "print", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.data_helper.load_paper_reference", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.reverse_dict_list", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.normalize_score", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.normalize_score"], ["", "def", "gen_paper_cocitation", "(", "InFile_PaperReference", ",", "norm", "=", "True", ")", ":", "\n", "    ", "paper2reference_list", "=", "load_paper_reference", "(", "InFile_PaperReference", ")", "\n", "paper2cited_list", "=", "reverse_dict_list", "(", "paper2reference_list", ")", "\n", "\n", "pair2CocitedCnt", "=", "{", "}", "\n", "total_cnt", ",", "cur_cnt", "=", "len", "(", "paper2cited_list", ")", ",", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "for", "paperid", ",", "who_cite_it_list", "in", "paper2cited_list", ".", "items", "(", ")", ":", "\n", "        ", "cur_cnt", "+=", "1", "\n", "if", "cur_cnt", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"\\rprocess paper num {0} / {1}...time elapses: {2:.1f}s\"", ".", "format", "(", "\n", "cur_cnt", ",", "total_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\"\"", ",", "\n", ")", "\n", "", "for", "source_paperid", "in", "who_cite_it_list", ":", "\n", "            ", "if", "source_paperid", "not", "in", "paper2reference_list", ":", "\n", "                ", "continue", "\n", "", "for", "its_reference_list", "in", "paper2reference_list", "[", "source_paperid", "]", ":", "\n", "                ", "if", "paperid", "!=", "its_reference_list", ":", "\n", "                    ", "pair", "=", "(", "\n", "(", "paperid", ",", "its_reference_list", ")", "\n", "if", "paperid", "<", "its_reference_list", "\n", "else", "(", "its_reference_list", ",", "paperid", ")", "\n", ")", "\n", "if", "pair", "not", "in", "pair2CocitedCnt", ":", "\n", "                        ", "pair2CocitedCnt", "[", "pair", "]", "=", "0", "\n", "", "pair2CocitedCnt", "[", "pair", "]", "+=", "1", "\n", "", "", "", "", "print", "(", "\"\\tDone.\"", ")", "\n", "\n", "pair2CoReferenceCnt", "=", "{", "}", "\n", "total_cnt", ",", "cur_cnt", "=", "len", "(", "paper2reference_list", ")", ",", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "for", "paperid", ",", "its_reference_list", "in", "paper2reference_list", ".", "items", "(", ")", ":", "\n", "        ", "cur_cnt", "+=", "1", "\n", "if", "cur_cnt", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"\\rprocess paper num {0} / {1}...time elapses: {2:.1f}s\"", ".", "format", "(", "\n", "cur_cnt", ",", "total_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\"\"", ",", "\n", ")", "\n", "", "for", "reference_paperid", "in", "its_reference_list", ":", "\n", "            ", "if", "reference_paperid", "not", "in", "paper2cited_list", ":", "\n", "                ", "continue", "\n", "", "for", "its_cited_list", "in", "paper2cited_list", "[", "reference_paperid", "]", ":", "\n", "                ", "if", "paperid", "!=", "its_cited_list", ":", "\n", "                    ", "pair", "=", "(", "\n", "(", "paperid", ",", "its_cited_list", ")", "\n", "if", "paperid", "<", "its_cited_list", "\n", "else", "(", "its_cited_list", ",", "paperid", ")", "\n", ")", "\n", "if", "pair", "not", "in", "pair2CoReferenceCnt", ":", "\n", "                        ", "pair2CoReferenceCnt", "[", "pair", "]", "=", "0", "\n", "", "pair2CoReferenceCnt", "[", "pair", "]", "+=", "1", "\n", "", "", "", "", "print", "(", "\"\\tDone.\"", ")", "\n", "\n", "if", "norm", ":", "\n", "        ", "pair2CocitedCnt", "=", "normalize_score", "(", "pair2CocitedCnt", ",", "paper2cited_list", ",", "10", ",", "0.145", ")", "\n", "pair2CoReferenceCnt", "=", "normalize_score", "(", "\n", "pair2CoReferenceCnt", ",", "paper2reference_list", ",", "10", ",", "0.311", "\n", ")", "\n", "\n", "", "return", "pair2CocitedCnt", ",", "pair2CoReferenceCnt", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.year_delta_check": [[619, 624], ["math.fabs"], "function", ["None"], ["", "def", "year_delta_check", "(", "paper01", ",", "paper02", ",", "paper2date", ",", "threshold", "=", "365", ")", ":", "\n", "    ", "if", "paper01", "in", "paper2date", "and", "paper02", "in", "paper2date", ":", "\n", "        ", "if", "math", ".", "fabs", "(", "(", "paper2date", "[", "paper01", "]", "-", "paper2date", "[", "paper02", "]", ")", ".", "days", ")", "<=", "threshold", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.author_overlap_check": [[626, 633], ["len", "len", "len", "paper2author_list[].intersection"], "function", ["None"], ["", "def", "author_overlap_check", "(", "paper01", ",", "paper02", ",", "paper2author_list", ",", "threshold", "=", "0.5", ")", ":", "\n", "    ", "if", "paper01", "in", "paper2author_list", "and", "paper02", "in", "paper2author_list", ":", "\n", "        ", "n", ",", "m", "=", "len", "(", "paper2author_list", "[", "paper01", "]", ")", ",", "len", "(", "paper2author_list", "[", "paper02", "]", ")", "\n", "k", "=", "len", "(", "paper2author_list", "[", "paper01", "]", ".", "intersection", "(", "paper2author_list", "[", "paper02", "]", ")", ")", "\n", "if", "k", "/", "n", ">=", "threshold", "or", "k", "/", "m", ">=", "threshold", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_paper_pairs_from_same_author": [[635, 666], ["time.time", "len", "open", "author2paper_list.items", "len", "range", "print", "range", "task_helper.year_delta_check", "task_helper.author_overlap_check", "wt.write", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.year_delta_check", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.author_overlap_check"], ["", "def", "gen_paper_pairs_from_same_author", "(", "\n", "author2paper_list", ",", "paper2author_list", ",", "paper2date", ",", "outfile", ",", "item_set", "\n", ")", ":", "\n", "    ", "total_cnt", ",", "cur_cnt", "=", "len", "(", "author2paper_list", ")", ",", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "outfile", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "for", "author", ",", "paper_list", "in", "author2paper_list", ".", "items", "(", ")", ":", "\n", "            ", "cur_cnt", "+=", "1", "\n", "if", "cur_cnt", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rprocess author num {0} / {1}...time elapses: {2:.1f}s\"", ".", "format", "(", "\n", "cur_cnt", ",", "total_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\"\"", ",", "\n", ")", "\n", "", "paper_list", "=", "[", "p", "for", "p", "in", "paper_list", "if", "p", "[", "1", "]", "==", "1", "]", "\n", "n", "=", "len", "(", "paper_list", ")", "\n", "if", "n", "<=", "1", ":", "\n", "                ", "continue", "\n", "", "for", "i", "in", "range", "(", "n", "-", "1", ")", ":", "\n", "                ", "if", "paper_list", "[", "i", "]", "[", "0", "]", "not", "in", "item_set", ":", "\n", "                    ", "continue", "\n", "", "for", "j", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "                    ", "if", "paper_list", "[", "j", "]", "[", "0", "]", "not", "in", "item_set", ":", "\n", "                        ", "continue", "\n", "", "if", "year_delta_check", "(", "\n", "paper_list", "[", "i", "]", "[", "0", "]", ",", "paper_list", "[", "j", "]", "[", "0", "]", ",", "paper2date", "\n", ")", "and", "author_overlap_check", "(", "\n", "paper_list", "[", "i", "]", "[", "0", "]", ",", "paper_list", "[", "j", "]", "[", "0", "]", ",", "paper2author_list", "\n", ")", ":", "\n", "                        ", "wt", ".", "write", "(", "\"{0},{1}\\n\"", ".", "format", "(", "paper_list", "[", "i", "]", "[", "0", "]", ",", "paper_list", "[", "j", "]", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_negative_instances": [[668, 695], ["list", "len", "print", "time.time", "print", "open", "rd.readlines", "len", "open", "os.path.basename", "line.strip().split", "wt.write", "wt.write", "range", "print", "wt.write", "line.strip", "random.randint", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "", "", "", "def", "gen_negative_instances", "(", "item_set", ",", "infile", ",", "outfile", ",", "neg_num", ")", ":", "\n", "    ", "item_list", "=", "list", "(", "item_set", ")", "\n", "item_num", "=", "len", "(", "item_set", ")", "\n", "print", "(", "\"negative sampling for file {0}...\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "infile", ")", ")", ")", "\n", "with", "open", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "lines", "=", "rd", ".", "readlines", "(", ")", "\n", "", "total_cnt", ",", "cur_cnt", "=", "len", "(", "lines", ")", ",", "0", "\n", "_t0", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "outfile", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "for", "line", "in", "lines", ":", "\n", "            ", "cur_cnt", "+=", "1", "\n", "if", "cur_cnt", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\n", "\"\\rprocess line num {0} / {1}...time elapses: {2:.1f}s\"", ".", "format", "(", "\n", "cur_cnt", ",", "total_cnt", ",", "time", ".", "time", "(", ")", "-", "_t0", "\n", ")", ",", "\n", "end", "=", "\"\"", ",", "\n", ")", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "\n", "wt", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "words", "[", "0", "]", ")", ")", "\n", "wt", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "words", "[", "1", "]", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "neg_num", ")", ":", "\n", "                ", "item", "=", "item_list", "[", "random", ".", "randint", "(", "0", ",", "item_num", "-", "1", ")", "]", "\n", "wt", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "item", ")", ")", "\n", "", "", "", "print", "(", "\"\\tdone.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.split_train_valid_file": [[697, 720], ["set", "list", "random.shuffle", "open", "open", "open", "os.path.join", "os.path.join", "line.strip().split", "list.add", "random.random", "wt_train.write", "wt_valid.write", "line.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "split_train_valid_file", "(", "infile_list", ",", "outdir", ",", "ratio", "=", "0.8", ")", ":", "\n", "    ", "gt_pairs", "=", "set", "(", ")", "\n", "for", "infile", "in", "infile_list", ":", "\n", "        ", "with", "open", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "pair", "=", "(", "\n", "(", "words", "[", "0", "]", ",", "words", "[", "1", "]", ")", "\n", "if", "words", "[", "0", "]", "<", "words", "[", "1", "]", "\n", "else", "(", "words", "[", "1", "]", ",", "words", "[", "0", "]", ")", "\n", ")", "\n", "gt_pairs", ".", "add", "(", "pair", ")", "\n", "\n", "", "", "", "gt_pairs", "=", "list", "(", "gt_pairs", ")", "\n", "random", ".", "shuffle", "(", "gt_pairs", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "outdir", ",", "\"item2item_train.txt\"", ")", ",", "\"w\"", ")", "as", "wt_train", ",", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "outdir", ",", "\"item2item_valid.txt\"", ")", ",", "\"w\"", "\n", ")", "as", "wt_valid", ":", "\n", "        ", "for", "p", "in", "gt_pairs", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "ratio", ":", "\n", "                ", "wt_train", ".", "write", "(", "\"{0},{1}\\n\"", ".", "format", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "wt_valid", ".", "write", "(", "\"{0},{1}\\n\"", ".", "format", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_np_from_txt": [[723, 734], ["numpy.asarray", "open", "open", "numpy.save", "rd.readline", "np.asarray.append", "float", "rd.readline.strip().split", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "", "def", "load_np_from_txt", "(", "transE_vecfile", ",", "np_file", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "transE_vecfile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "data", ".", "append", "(", "[", "float", "(", "a", ")", "for", "a", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "delimiter", ")", "]", ")", "\n", "", "", "data", "=", "np", ".", "asarray", "(", "data", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "open", "(", "np_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "np", ".", "save", "(", "f", ",", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.format_knowledge_embeddings": [[736, 740], ["numpy.loadtxt", "open", "numpy.save"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "", "def", "format_knowledge_embeddings", "(", "transE_vecfile", ",", "np_file", ")", ":", "\n", "    ", "data", "=", "np", ".", "loadtxt", "(", "transE_vecfile", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "with", "open", "(", "np_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "np", ".", "save", "(", "f", ",", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.format_word_embeddings": [[742, 773], ["len", "open", "pickle.load", "open", "open", "numpy.save", "rd.readline", "rd.readline.strip().split", "numpy.zeros", "range", "rd.readline.strip", "int", "int", "ValueError", "float"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "format_word_embeddings", "(", "word_vecfile", ",", "word2id_file", ",", "np_file", ")", ":", "\n", "    ", "with", "open", "(", "word2id_file", ",", "\"rb\"", ")", "as", "rd", ":", "\n", "        ", "word2id", "=", "pickle", ".", "load", "(", "rd", ")", "\n", "", "wordcnt", "=", "len", "(", "word2id", ")", "\n", "\n", "word_embeddings", "=", "None", "\n", "line_idx", "=", "0", "\n", "with", "open", "(", "word_vecfile", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "line_idx", "+=", "1", "\n", "if", "line_idx", "==", "1", ":", "\n", "                ", "_wordcnt", ",", "_emb_size", "=", "int", "(", "words", "[", "0", "]", ")", ",", "int", "(", "words", "[", "1", "]", ")", "\n", "if", "_wordcnt", "+", "1", "!=", "wordcnt", ":", "#  the 0-th word is 'NULL'", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Word number doesn't match in word2id ({0}) and word2embedding file ({1})!\"", ".", "format", "(", "\n", "wordcnt", ",", "_wordcnt", "\n", ")", "\n", ")", "\n", "", "word_embeddings", "=", "np", ".", "zeros", "(", "\n", "shape", "=", "(", "_wordcnt", "+", "1", ",", "_emb_size", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "", "else", ":", "\n", "                ", "_idx", "=", "word2id", "[", "words", "[", "0", "]", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "_emb_size", "+", "1", ")", ":", "\n", "                    ", "word_embeddings", "[", "_idx", "]", "[", "i", "-", "1", "]", "=", "float", "(", "words", "[", "i", "]", ")", "\n", "", "", "", "", "with", "open", "(", "np_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "np", ".", "save", "(", "f", ",", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.gen_context_embedding": [[775, 818], ["open", "open.close", "open", "open.readline", "open.readlines", "open.close", "numpy.zeros", "numpy.savetxt", "list", "triple.strip().split", "kg_neighbor_dict[].add", "kg_neighbor_dict[].add", "line.strip().split", "map", "set", "set", "numpy.mean", "str", "triple.strip", "context_vecs.append", "numpy.asarray", "line.strip", "int"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "gen_context_embedding", "(", "entity_file", ",", "context_file", ",", "kg_file", ",", "dim", ")", ":", "\n", "# load embedding_vec", "\n", "    ", "entity_index", "=", "0", "\n", "entity_dict", "=", "{", "}", "\n", "fp_entity", "=", "open", "(", "entity_file", ",", "\"r\"", ")", "\n", "for", "line", "in", "fp_entity", ":", "\n", "        ", "linesplit", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "[", ":", "dim", "]", "\n", "linesplit", "=", "list", "(", "map", "(", "float", ",", "linesplit", ")", ")", "\n", "entity_dict", "[", "str", "(", "entity_index", ")", "]", "=", "linesplit", "\n", "entity_index", "+=", "1", "\n", "", "fp_entity", ".", "close", "(", ")", "\n", "\n", "# build neighbor for entity in entity_dict", "\n", "fp_kg", "=", "open", "(", "kg_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "triple_num", "=", "fp_kg", ".", "readline", "(", ")", "\n", "triples", "=", "fp_kg", ".", "readlines", "(", ")", "\n", "kg_neighbor_dict", "=", "{", "}", "\n", "for", "triple", "in", "triples", ":", "\n", "        ", "linesplit", "=", "triple", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "head", "=", "linesplit", "[", "0", "]", "\n", "tail", "=", "linesplit", "[", "1", "]", "\n", "if", "head", "not", "in", "kg_neighbor_dict", ":", "\n", "            ", "kg_neighbor_dict", "[", "head", "]", "=", "set", "(", ")", "\n", "", "kg_neighbor_dict", "[", "head", "]", ".", "add", "(", "tail", ")", "\n", "\n", "if", "tail", "not", "in", "kg_neighbor_dict", ":", "\n", "            ", "kg_neighbor_dict", "[", "tail", "]", "=", "set", "(", ")", "\n", "", "kg_neighbor_dict", "[", "tail", "]", ".", "add", "(", "head", ")", "\n", "", "fp_kg", ".", "close", "(", ")", "\n", "\n", "context_embeddings", "=", "np", ".", "zeros", "(", "[", "entity_index", ",", "dim", "]", ")", "\n", "\n", "for", "entity", "in", "entity_dict", ":", "\n", "        ", "if", "entity", "in", "kg_neighbor_dict", ":", "\n", "            ", "context_entity", "=", "kg_neighbor_dict", "[", "entity", "]", "\n", "context_vecs", "=", "[", "]", "\n", "for", "c_entity", "in", "context_entity", ":", "\n", "                ", "context_vecs", ".", "append", "(", "entity_dict", "[", "c_entity", "]", ")", "\n", "\n", "", "context_vec", "=", "np", ".", "mean", "(", "np", ".", "asarray", "(", "context_vecs", ")", ",", "axis", "=", "0", ")", "\n", "context_embeddings", "[", "int", "(", "entity", ")", "]", "=", "context_vec", "\n", "\n", "", "", "np", ".", "savetxt", "(", "context_file", ",", "context_embeddings", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_instance_file": [[821, 842], ["print", "set", "print", "open", "os.path.basename", "rd.readline", "rd.readline.strip().split", "words[].split", "set.add", "target_triples.append", "target_triples.append", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_instance_file", "(", "filename", ",", "target_triples", ",", "label", "=", "None", ")", ":", "\n", "    ", "print", "(", "\"load_instance_file: {0}  \"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "filename", ")", ")", ",", "end", "=", "\" \"", ")", "\n", "user_hist_keys", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"%\"", ")", "\n", "tokens", "=", "words", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "if", "label", ":", "\n", "                ", "target_triples", ".", "append", "(", "\n", "(", "words", "[", "1", "]", ",", "tokens", "[", "2", "]", ",", "label", ")", "\n", ")", "# (userid, itemid, label)", "\n", "", "else", ":", "\n", "                ", "target_triples", ".", "append", "(", "\n", "(", "words", "[", "1", "]", ",", "tokens", "[", "2", "]", ",", "tokens", "[", "0", "]", ")", "\n", ")", "# (userid, itemid, label)", "\n", "", "user_hist_keys", ".", "add", "(", "tokens", "[", "1", "]", ")", "\n", "", "", "print", "(", "\"done.\"", ")", "\n", "return", "user_hist_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.write_to_file": [[844, 848], ["open", "wt.write"], "function", ["None"], ["", "def", "write_to_file", "(", "filename", ",", "triples", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "wt", ":", "\n", "        ", "for", "t", "in", "triples", ":", "\n", "            ", "wt", ".", "write", "(", "\"{0} {1} {2}\\n\"", ".", "format", "(", "t", "[", "0", "]", ",", "t", "[", "1", "]", ",", "t", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_user_behaviors": [[850, 863], ["open", "rd.readline", "rd.readline.strip().split", "words[].split", "words[].split", "train_triples.append", "rd.readline.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "load_user_behaviors", "(", "user_behavior_file", ",", "train_triples", ",", "user_behavior_keys", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "user_behavior_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "if", "user_behavior_keys", "and", "not", "words", "[", "0", "]", "in", "user_behavior_keys", ":", "\n", "                ", "continue", "\n", "", "userid", "=", "words", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "items", "=", "words", "[", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "for", "item", "in", "items", ":", "\n", "                ", "train_triples", ".", "append", "(", "(", "userid", ",", "item", ",", "\"1\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.prepare_dataset": [[865, 889], ["task_helper.load_instance_file", "task_helper.load_instance_file", "task_helper.load_instance_file", "task_helper.load_user_behaviors", "task_helper.write_to_file", "task_helper.write_to_file", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_instance_file", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_instance_file", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_instance_file", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_user_behaviors", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.write_to_file", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.write_to_file"], ["", "", "", "", "def", "prepare_dataset", "(", "output_folder", ",", "input_folder", ",", "tag", ")", ":", "\n", "    ", "train_triples", ",", "valid_triples", "=", "[", "]", ",", "[", "]", "\n", "\n", "training_user_hist_keys", "=", "load_instance_file", "(", "\n", "os", ".", "path", ".", "join", "(", "input_folder", ",", "\"train_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "train_triples", "\n", ")", "\n", "load_instance_file", "(", "\n", "os", ".", "path", ".", "join", "(", "input_folder", ",", "\"valid_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "valid_triples", "\n", ")", "\n", "load_instance_file", "(", "\n", "os", ".", "path", ".", "join", "(", "input_folder", ",", "\"test_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "valid_triples", ",", "label", "=", "\"0\"", "\n", ")", "\n", "\n", "load_user_behaviors", "(", "\n", "os", ".", "path", ".", "join", "(", "input_folder", ",", "\"user_history_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "\n", "train_triples", ",", "\n", "training_user_hist_keys", ",", "\n", ")", "\n", "\n", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"lightgcn_train_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "train_triples", "\n", ")", "\n", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"lightgcn_valid_{0}.txt\"", ".", "format", "(", "tag", ")", ")", ",", "valid_triples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.group_labels": [[892, 914], ["list", "zip", "set", "group_labels[].append", "group_preds[].append", "all_labels.append", "all_preds.append"], "function", ["None"], ["", "def", "group_labels", "(", "labels", ",", "preds", ",", "group_keys", ")", ":", "\n", "    ", "\"\"\"Devide labels and preds into several group according to values in group keys.\n    Args:\n        labels (list): ground truth label list.\n        preds (list): prediction score list.\n        group_keys (list): group key list.\n    Returns:\n        all_labels: labels after group.\n        all_preds: preds after group.\n    \"\"\"", "\n", "all_keys", "=", "list", "(", "set", "(", "group_keys", ")", ")", "\n", "group_labels", "=", "{", "k", ":", "[", "]", "for", "k", "in", "all_keys", "}", "\n", "group_preds", "=", "{", "k", ":", "[", "]", "for", "k", "in", "all_keys", "}", "\n", "for", "l", ",", "p", ",", "k", "in", "zip", "(", "labels", ",", "preds", ",", "group_keys", ")", ":", "\n", "        ", "group_labels", "[", "k", "]", ".", "append", "(", "l", ")", "\n", "group_preds", "[", "k", "]", ".", "append", "(", "p", ")", "\n", "", "all_labels", "=", "[", "]", "\n", "all_preds", "=", "[", "]", "\n", "for", "k", "in", "all_keys", ":", "\n", "        ", "all_labels", ".", "append", "(", "group_labels", "[", "k", "]", ")", "\n", "all_preds", ".", "append", "(", "group_preds", "[", "k", "]", ")", "\n", "", "return", "all_labels", ",", "all_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.task_helper.load_emb_file": [[916, 927], ["open", "rd.readline", "rd.readline.strip().split", "numpy.asarray", "float", "rd.readline.strip", "words[].split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_emb_file", "(", "emb_file", ")", ":", "\n", "    ", "res", "=", "{", "}", "\n", "with", "open", "(", "emb_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "values", "=", "[", "float", "(", "a", ")", "for", "a", "in", "words", "[", "1", "]", ".", "split", "(", "\" \"", ")", "]", "\n", "res", "[", "words", "[", "0", "]", "]", "=", "np", ".", "asarray", "(", "values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "return", "res", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.add2dict": [[8, 12], ["len"], "function", ["None"], ["def", "add2dict", "(", "value", ",", "d", ")", ":", "\n", "    ", "if", "value", "not", "in", "d", ":", "\n", "        ", "d", "[", "value", "]", "=", "len", "(", "d", ")", "\n", "", "return", "d", "[", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.create_dir": [[14, 17], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "create_dir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.list2string": [[19, 21], ["sep.join", "str"], "function", ["None"], ["", "", "def", "list2string", "(", "li", ",", "sep", "=", "\",\"", ")", ":", "\n", "    ", "return", "sep", ".", "join", "(", "[", "str", "(", "a", ")", "for", "a", "in", "li", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.dump_dict_as_txt": [[23, 28], ["open", "wt.write", "d.items", "wt.write", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "dump_dict_as_txt", "(", "d", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "wt", ":", "\n", "        ", "wt", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "len", "(", "d", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "wt", ".", "write", "(", "\"{0}\\t{1}\\n\"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.reparameter_sampling": [[30, 41], ["numpy.random.uniform", "numpy.log", "numpy.log", "numpy.argpartition", "numpy.log"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["", "", "", "def", "reparameter_sampling", "(", "sample_size", ",", "probabilities", ")", ":", "\n", "    ", "r\"\"\"\n    Faster sampling algorithm, gumbel softmax trick.\n    :param sample_size:\n    :param probabilities:\n    :return:  index of sampled items (unbiased)\n    \"\"\"", "\n", "random_values", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "probabilities", ".", "shape", ")", "\n", "random_values", "=", "np", ".", "log", "(", "-", "np", ".", "log", "(", "random_values", ")", ")", "# gives gumbel random variable", "\n", "shifted_probabilities", "=", "random_values", "-", "np", ".", "log", "(", "probabilities", ")", "\n", "return", "np", ".", "argpartition", "(", "shifted_probabilities", ",", "sample_size", ")", "[", ":", "sample_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general.reverse_dict_list": [[43, 51], ["id2list.items", "res[].append"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "reverse_dict_list", "(", "id2list", ")", ":", "\n", "    ", "res", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "id2list", ".", "items", "(", ")", ":", "\n", "        ", "for", "id", "in", "value", ":", "\n", "            ", "if", "id", "not", "in", "res", ":", "\n", "                ", "res", "[", "id", "]", "=", "[", "]", "\n", "", "res", "[", "id", "]", ".", "append", "(", "key", ")", "\n", "", "", "return", "res", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.target_matrices": [[20, 45], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "target_matrices", "(", "scope", "=", "\"module\"", ")", ":", "\n", "    ", "J1", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.5", "]", ",", "[", "0.0", ",", "1.0", ",", "0.33333", "]", ",", "[", "0.5", ",", "0.33333", ",", "1.0", "]", "]", ")", "\n", "J2", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "1.0", ",", "0.0", ",", "0.0", ",", "0.2", "]", ",", "\n", "[", "0.0", ",", "1.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", ",", "0.5", "]", ",", "\n", "[", "0.2", ",", "0.0", ",", "0.5", ",", "1.0", "]", ",", "\n", "]", "\n", ")", "\n", "L1", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.5", "]", ",", "[", "0.0", ",", "0.5", ",", "0.25", "]", ",", "[", "0.5", ",", "0.25", ",", "0.5", "]", "]", ")", "\n", "L2", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "0.5", ",", "0.0", ",", "0.0", ",", "0.125", "]", ",", "\n", "[", "0.0", ",", "0.33333", ",", "0.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "0.5", ",", "0.25", "]", ",", "\n", "[", "0.125", ",", "0.0", ",", "0.25", ",", "0.25", "]", ",", "\n", "]", "\n", ")", "\n", "return", "{", "\n", "\"jaccard1\"", ":", "pytest", ".", "approx", "(", "J1", ",", "TOL", ")", ",", "\n", "\"jaccard2\"", ":", "pytest", ".", "approx", "(", "J2", ",", "TOL", ")", ",", "\n", "\"lift1\"", ":", "pytest", ".", "approx", "(", "L1", ",", "TOL", ")", ",", "\n", "\"lift2\"", ":", "pytest", ".", "approx", "(", "L2", ",", "TOL", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.cooccurrence1": [[48, 51], ["pytest.fixture", "numpy.array"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "cooccurrence1", "(", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "1.0", "]", ",", "[", "0.0", ",", "2.0", ",", "1.0", "]", ",", "[", "1.0", ",", "1.0", ",", "2.0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.cooccurrence2": [[53, 61], ["pytest.fixture", "numpy.array"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "cooccurrence2", "(", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "\n", "[", "\n", "[", "2.0", ",", "0.0", ",", "0.0", ",", "1.0", "]", ",", "\n", "[", "0.0", ",", "3.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "2.0", ",", "2.0", "]", ",", "\n", "[", "1.0", ",", "0.0", ",", "2.0", ",", "4.0", "]", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.scores": [[65, 68], ["pytest.fixture", "numpy.array"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "scores", "(", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "[", "5", ",", "4", ",", "3", ",", "2", ",", "1", "]", ",", "[", "1", ",", "5", ",", "3", ",", "4", ",", "2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_python_jaccard": [[70, 78], ["recommenders.utils.python_utils.jaccard", "recommenders.utils.python_utils.jaccard", "type", "type"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.jaccard", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.jaccard"], ["", "def", "test_python_jaccard", "(", "cooccurrence1", ",", "cooccurrence2", ",", "target_matrices", ")", ":", "\n", "    ", "J1", "=", "jaccard", "(", "cooccurrence1", ")", "\n", "assert", "type", "(", "J1", ")", "==", "np", ".", "ndarray", "\n", "assert", "J1", "==", "target_matrices", "[", "\"jaccard1\"", "]", "\n", "\n", "J2", "=", "jaccard", "(", "cooccurrence2", ")", "\n", "assert", "type", "(", "J2", ")", "==", "np", ".", "ndarray", "\n", "assert", "J2", "==", "target_matrices", "[", "\"jaccard2\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_python_lift": [[80, 88], ["recommenders.utils.python_utils.lift", "recommenders.utils.python_utils.lift", "type", "type"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.lift", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.lift"], ["", "def", "test_python_lift", "(", "cooccurrence1", ",", "cooccurrence2", ",", "target_matrices", ")", ":", "\n", "    ", "L1", "=", "lift", "(", "cooccurrence1", ")", "\n", "assert", "type", "(", "L1", ")", "==", "np", ".", "ndarray", "\n", "assert", "L1", "==", "target_matrices", "[", "\"lift1\"", "]", "\n", "\n", "L2", "=", "lift", "(", "cooccurrence2", ")", "\n", "assert", "type", "(", "L2", ")", "==", "np", ".", "ndarray", "\n", "assert", "L2", "==", "target_matrices", "[", "\"lift2\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_exponential_decay": [[90, 95], ["numpy.array", "numpy.array", "recommenders.utils.python_utils.exponential_decay", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.exponential_decay"], ["", "def", "test_exponential_decay", "(", ")", ":", "\n", "    ", "values", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", ")", "\n", "expected", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.35355339", ",", "0.5", ",", "0.70710678", ",", "1.0", ",", "1.0", "]", ")", "\n", "actual", "=", "exponential_decay", "(", "value", "=", "values", ",", "max_val", "=", "5", ",", "half_life", "=", "2", ")", "\n", "assert", "np", ".", "allclose", "(", "actual", ",", "expected", ",", "atol", "=", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_get_top_k_scored_items": [[97, 104], ["recommenders.utils.python_utils.get_top_k_scored_items", "numpy.array_equal", "numpy.array_equal", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "test_get_top_k_scored_items", "(", "scores", ")", ":", "\n", "    ", "top_items", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "scores", ",", "top_k", "=", "3", ",", "sort_top_k", "=", "True", "\n", ")", "\n", "\n", "assert", "np", ".", "array_equal", "(", "top_items", ",", "np", ".", "array", "(", "[", "[", "4", ",", "3", ",", "2", "]", ",", "[", "0", ",", "1", ",", "2", "]", ",", "[", "1", ",", "3", ",", "2", "]", "]", ")", ")", "\n", "assert", "np", ".", "array_equal", "(", "top_scores", ",", "np", ".", "array", "(", "[", "[", "5", ",", "4", ",", "3", "]", ",", "[", "5", ",", "4", ",", "3", "]", ",", "[", "5", ",", "4", ",", "3", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_binarize": [[106, 111], ["numpy.array", "numpy.array", "numpy.array_equal", "recommenders.utils.python_utils.binarize"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.binarize"], ["", "def", "test_binarize", "(", ")", ":", "\n", "    ", "data", "=", "np", ".", "array", "(", "[", "[", "2", ",", "7", ",", "0", "]", ",", "[", "8", ",", "2", ",", "9", "]", ",", "[", "9", ",", "9", ",", "4", "]", "]", ")", "\n", "threshold", "=", "3", "\n", "expected", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "0", "]", ",", "[", "1", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "binarize", "(", "data", ",", "threshold", ")", ",", "expected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_python_utils.test_rescale": [[113, 132], ["numpy.array", "numpy.allclose", "numpy.array", "numpy.allclose", "numpy.array", "numpy.tile", "numpy.tile", "numpy.allclose", "recommenders.utils.python_utils.rescale", "recommenders.utils.python_utils.rescale", "recommenders.utils.python_utils.rescale", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.rescale", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.rescale", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.rescale"], ["", "def", "test_rescale", "(", "scores", ")", ":", "\n", "    ", "expected", "=", "np", ".", "array", "(", "\n", "[", "[", "0", ",", "0.25", ",", "0.5", ",", "0.75", ",", "1", "]", ",", "[", "1", ",", "0.75", ",", "0.5", ",", "0.25", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0.5", ",", "0.75", ",", "0.25", "]", "]", "\n", ")", "\n", "assert", "np", ".", "allclose", "(", "expected", ",", "rescale", "(", "scores", ",", "0", ",", "1", ")", ")", "\n", "\n", "expected", "=", "np", ".", "array", "(", "[", "[", "3", ",", "5", ",", "7", ",", "9", ",", "11.0", "]", ",", "[", "11", ",", "9", ",", "7", ",", "5", ",", "3", "]", ",", "[", "3", ",", "11", ",", "7", ",", "9", ",", "5", "]", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "expected", ",", "rescale", "(", "scores", ",", "1", ",", "11", ",", "0", ",", "5", ")", ")", "\n", "\n", "expected", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "0", ",", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ",", "\n", "[", "0.625", ",", "0.5", ",", "0.375", ",", "0.25", ",", "0.125", "]", ",", "\n", "[", "0", ",", "1", ",", "0.5", ",", "0.75", ",", "0.25", "]", ",", "\n", "]", "\n", ")", "\n", "data_min", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "[", "1", ",", "0", ",", "1", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "scores", ".", "shape", "[", "1", "]", ")", "\n", "data_max", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "[", "6", ",", "8", ",", "5", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "scores", ".", "shape", "[", "1", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "expected", ",", "rescale", "(", "scores", ",", "0", ",", "1", ",", "data_min", ",", "data_max", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_get_gpu_info": [[22, 25], ["len", "recommenders.utils.gpu_utils.get_gpu_info"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_gpu_info"], ["@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_get_gpu_info", "(", ")", ":", "\n", "    ", "assert", "len", "(", "get_gpu_info", "(", ")", ")", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_get_number_gpus": [[27, 30], ["recommenders.utils.gpu_utils.get_number_gpus"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_number_gpus"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_get_number_gpus", "(", ")", ":", "\n", "    ", "assert", "get_number_gpus", "(", ")", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_clear_memory_all_gpus": [[32, 36], ["pytest.mark.skip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"TODO: Implement this\"", ")", "\n", "def", "test_clear_memory_all_gpus", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_get_cuda_version": [[38, 42], ["pytest.mark.skipif", "recommenders.utils.gpu_utils.get_cuda_version"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_cuda_version"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"Not implemented on Windows\"", ")", "\n", "def", "test_get_cuda_version", "(", ")", ":", "\n", "    ", "assert", "get_cuda_version", "(", ")", ">", "\"9.0.0\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_get_cudnn_version": [[44, 47], ["recommenders.utils.gpu_utils.get_cudnn_version"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_cudnn_version"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_get_cudnn_version", "(", ")", ":", "\n", "    ", "assert", "get_cudnn_version", "(", ")", ">", "\"7.0.0\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_cudnn_enabled": [[49, 52], ["None"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_cudnn_enabled", "(", ")", ":", "\n", "    ", "assert", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "==", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_tensorflow_gpu": [[54, 57], ["tf.test.is_gpu_available"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_tensorflow_gpu", "(", ")", ":", "\n", "    ", "assert", "tf", ".", "test", ".", "is_gpu_available", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_gpu_utils.test_pytorch_gpu": [[59, 62], ["torch.cuda.is_available"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_pytorch_gpu", "(", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.t": [[13, 16], ["pytest.fixture", "recommenders.utils.timer.Timer"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"function\"", ")", "\n", "def", "t", "(", ")", ":", "\n", "    ", "return", "Timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.test_no_time": [[18, 21], ["None"], "function", ["None"], ["", "def", "test_no_time", "(", "t", ")", ":", "\n", "    ", "assert", "t", ".", "interval", "==", "0", "\n", "assert", "t", ".", "running", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.test_stop_before_start": [[23, 26], ["pytest.raises", "t.stop"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.stop"], ["", "def", "test_stop_before_start", "(", "t", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "t", ".", "stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.test_interval_before_stop": [[28, 32], ["t.start", "pytest.raises"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start"], ["", "", "def", "test_interval_before_stop", "(", "t", ")", ":", "\n", "    ", "t", ".", "start", "(", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "t", ".", "interval", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.test_timer": [[34, 46], ["t.start", "time.sleep", "t.stop", "pytest.approx", "recommenders.utils.timer.Timer", "time.sleep", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.stop"], ["", "", "def", "test_timer", "(", "t", ")", ":", "\n", "    ", "t", ".", "start", "(", ")", "\n", "assert", "t", ".", "running", "is", "True", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "t", ".", "stop", "(", ")", "\n", "assert", "t", ".", "running", "is", "False", "\n", "assert", "t", ".", "interval", "==", "pytest", ".", "approx", "(", "1", ",", "abs", "=", "TOL", ")", "\n", "with", "Timer", "(", ")", "as", "t2", ":", "\n", "        ", "assert", "t2", ".", "running", "is", "True", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "", "assert", "t2", ".", "interval", "==", "pytest", ".", "approx", "(", "1", ",", "abs", "=", "TOL", ")", "\n", "assert", "t2", ".", "running", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_timer.test_timer_format": [[48, 51], ["str", "str"], "function", ["None"], ["", "def", "test_timer_format", "(", "t", ")", ":", "\n", "    ", "assert", "str", "(", "t", ")", "==", "\"0.0000\"", "\n", "assert", "str", "(", "t", ".", "interval", ")", "==", "\"0\"", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_notebook_utils.test_is_jupyter": [[15, 34], ["pathlib.Path().absolute().parent.joinpath", "pm.execute_notebook", "sb.read_notebook", "recommenders.utils.notebook_utils.is_jupyter", "recommenders.utils.notebook_utils.is_databricks", "pathlib.Path().absolute", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_jupyter", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_databricks"], ["@", "pytest", ".", "mark", ".", "notebooks", "\n", "def", "test_is_jupyter", "(", "output_notebook", ",", "kernel_name", ")", ":", "\n", "# Test on the terminal", "\n", "    ", "assert", "is_jupyter", "(", ")", "is", "False", "\n", "assert", "is_databricks", "(", ")", "is", "False", "\n", "\n", "# Test on Jupyter notebook", "\n", "path", "=", "Path", "(", "__file__", ")", ".", "absolute", "(", ")", ".", "parent", ".", "joinpath", "(", "\"test_notebook_utils.ipynb\"", ")", "\n", "pm", ".", "execute_notebook", "(", "\n", "path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", ")", "\n", "nb", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", "\n", "df", "=", "nb", ".", "scraps", ".", "dataframe", "\n", "result_is_jupyter", "=", "df", ".", "loc", "[", "df", "[", "\"name\"", "]", "==", "\"is_jupyter\"", ",", "\"data\"", "]", ".", "values", "[", "0", "]", "\n", "assert", "result_is_jupyter", "# is True not allowed", "\n", "result_is_databricks", "=", "df", ".", "loc", "[", "df", "[", "\"name\"", "]", "==", "\"is_databricks\"", ",", "\"data\"", "]", ".", "values", "[", "0", "]", "\n", "assert", "not", "result_is_databricks", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_k8s_utils.test_qps_to_replicas": [[11, 14], ["recommenders.utils.k8s_utils.qps_to_replicas"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.qps_to_replicas"], ["def", "test_qps_to_replicas", "(", ")", ":", "\n", "    ", "replicas", "=", "qps_to_replicas", "(", "target_qps", "=", "25", ",", "processing_time", "=", "0.1", ")", "\n", "assert", "replicas", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_k8s_utils.test_replicas_to_qps": [[16, 19], ["recommenders.utils.k8s_utils.replicas_to_qps"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.replicas_to_qps"], ["", "def", "test_replicas_to_qps", "(", ")", ":", "\n", "    ", "qps", "=", "replicas_to_qps", "(", "num_replicas", "=", "4", ",", "processing_time", "=", "0.1", ")", "\n", "assert", "qps", "==", "27", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_k8s_utils.test_nodes_to_replicas": [[21, 26], ["recommenders.utils.k8s_utils.nodes_to_replicas"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.k8s_utils.nodes_to_replicas"], ["", "def", "test_nodes_to_replicas", "(", ")", ":", "\n", "    ", "max_replicas", "=", "nodes_to_replicas", "(", "\n", "n_cores_per_node", "=", "4", ",", "n_nodes", "=", "3", ",", "cpu_cores_per_replica", "=", "0.1", "\n", ")", "\n", "assert", "max_replicas", "==", "60", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_tf_utils.pd_df": [[40, 60], ["pytest.fixture", "pandas.DataFrame", "pd.DataFrame.drop_duplicates", "pd.DataFrame.drop_duplicates"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "pd_df", "(", ")", ":", "\n", "    ", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "4", ",", "5", "]", ",", "\n", "ITEM_FEAT_COL", ":", "[", "\n", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "2", ",", "2", ",", "2", "]", ",", "\n", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "4", ",", "4", ",", "4", "]", ",", "\n", "[", "5", ",", "5", ",", "5", "]", ",", "\n", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", "]", ",", "\n", "}", "\n", ")", "\n", "users", "=", "df", ".", "drop_duplicates", "(", "DEFAULT_USER_COL", ")", "[", "DEFAULT_USER_COL", "]", ".", "values", "\n", "items", "=", "df", ".", "drop_duplicates", "(", "DEFAULT_ITEM_COL", ")", "[", "DEFAULT_ITEM_COL", "]", ".", "values", "\n", "return", "df", ",", "users", ",", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_tf_utils.test_pandas_input_fn": [[62, 107], ["tf.compat.v1.data.make_one_shot_iterator().get_next", "tf.compat.v1.data.make_one_shot_iterator().get_next", "tf.compat.v1.data.make_one_shot_iterator().get_next", "pandas_input_fn", "tf.compat.v1.Session", "sess.run", "sess.run.items", "pandas_input_fn", "tf.compat.v1.Session", "sess.run", "print", "sess.run.items", "pandas_input_fn", "tf.compat.v1.Session", "sess.run", "tf.compat.v1.data.make_one_shot_iterator", "len", "len", "tf.compat.v1.data.make_one_shot_iterator", "len", "len", "tf.compat.v1.data.make_one_shot_iterator", "len", "len", "numpy.array_equal", "len", "len", "len", "numpy.array_equal", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_pandas_input_fn", "(", "pd_df", ")", ":", "\n", "    ", "df", ",", "_", ",", "_", "=", "pd_df", "\n", "\n", "# check dataset", "\n", "dataset", "=", "pandas_input_fn", "(", "df", ")", "(", ")", "\n", "batch", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_one_shot_iterator", "(", "dataset", ")", ".", "get_next", "(", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "features", "=", "sess", ".", "run", "(", "batch", ")", "\n", "\n", "# check the input function returns all the columns", "\n", "assert", "len", "(", "features", ")", "==", "len", "(", "df", ".", "columns", ")", "\n", "\n", "for", "k", ",", "v", "in", "features", ".", "items", "(", ")", ":", "\n", "            ", "assert", "k", "in", "df", ".", "columns", ".", "values", "\n", "# check if a list feature column converted correctly", "\n", "if", "len", "(", "v", ".", "shape", ")", "==", "1", ":", "\n", "                ", "assert", "np", ".", "array_equal", "(", "v", ",", "df", "[", "k", "]", ".", "values", ")", "\n", "", "elif", "len", "(", "v", ".", "shape", ")", "==", "2", ":", "\n", "                ", "assert", "v", ".", "shape", "[", "1", "]", "==", "len", "(", "df", "[", "k", "]", "[", "0", "]", ")", "\n", "\n", "# check dataset with shuffles", "\n", "", "", "", "dataset", "=", "pandas_input_fn", "(", "df", ",", "shuffle", "=", "True", ",", "seed", "=", "SEED", ")", "(", ")", "\n", "batch", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_one_shot_iterator", "(", "dataset", ")", ".", "get_next", "(", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "features", "=", "sess", ".", "run", "(", "batch", ")", "\n", "print", "(", "features", ")", "\n", "# check the input function returns all the columns", "\n", "assert", "len", "(", "features", ")", "==", "len", "(", "df", ".", "columns", ")", "\n", "\n", "for", "k", ",", "v", "in", "features", ".", "items", "(", ")", ":", "\n", "            ", "assert", "k", "in", "df", ".", "columns", ".", "values", "\n", "# check if a list feature column converted correctly", "\n", "if", "len", "(", "v", ".", "shape", ")", "==", "1", ":", "\n", "                ", "assert", "not", "np", ".", "array_equal", "(", "v", ",", "df", "[", "k", "]", ".", "values", ")", "\n", "", "elif", "len", "(", "v", ".", "shape", ")", "==", "2", ":", "\n", "                ", "assert", "v", ".", "shape", "[", "1", "]", "==", "len", "(", "df", "[", "k", "]", "[", "0", "]", ")", "\n", "\n", "# check dataset w/ label", "\n", "", "", "", "dataset_with_label", "=", "pandas_input_fn", "(", "df", ",", "y_col", "=", "DEFAULT_RATING_COL", ")", "(", ")", "\n", "batch", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_one_shot_iterator", "(", "dataset_with_label", ")", ".", "get_next", "(", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "features", ",", "label", "=", "sess", ".", "run", "(", "batch", ")", "\n", "assert", "(", "\n", "len", "(", "features", ")", "==", "len", "(", "df", ".", "columns", ")", "-", "1", "\n", ")", "# label should not be in the features", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_tf_utils.test_build_optimizer": [[110, 132], ["build_optimizer", "isinstance", "build_optimizer", "isinstance", "build_optimizer", "isinstance", "build_optimizer", "isinstance", "build_optimizer", "isinstance", "build_optimizer", "isinstance", "build_optimizer", "isinstance"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.build_optimizer"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_build_optimizer", "(", ")", ":", "\n", "    ", "adadelta", "=", "build_optimizer", "(", "\"Adadelta\"", ")", "\n", "assert", "isinstance", "(", "adadelta", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdadeltaOptimizer", ")", "\n", "\n", "adagrad", "=", "build_optimizer", "(", "\"Adagrad\"", ")", "\n", "assert", "isinstance", "(", "adagrad", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdagradOptimizer", ")", "\n", "\n", "adam", "=", "build_optimizer", "(", "\"Adam\"", ")", "\n", "assert", "isinstance", "(", "adam", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", ")", "\n", "\n", "ftrl", "=", "build_optimizer", "(", "\"Ftrl\"", ",", "**", "{", "\"l1_regularization_strength\"", ":", "0.001", "}", ")", "\n", "assert", "isinstance", "(", "ftrl", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "FtrlOptimizer", ")", "\n", "\n", "momentum", "=", "build_optimizer", "(", "\"Momentum\"", ",", "**", "{", "\"momentum\"", ":", "0.5", "}", ")", "\n", "assert", "isinstance", "(", "momentum", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "MomentumOptimizer", ")", "\n", "\n", "rmsprop", "=", "build_optimizer", "(", "\"RMSProp\"", ")", "\n", "assert", "isinstance", "(", "rmsprop", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "RMSPropOptimizer", ")", "\n", "\n", "sgd", "=", "build_optimizer", "(", "\"SGD\"", ")", "\n", "assert", "isinstance", "(", "sgd", ",", "tf", ".", "compat", ".", "v1", ".", "train", ".", "GradientDescentOptimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_tf_utils.test_evaluation_log_hook": [[134, 184], ["build_feature_columns", "build_model", "MetricsLogger", "build_model.train", "tf.compat.v1.summary.FileWriterCache.get", "tf.compat.v1.summary.FileWriterCache.get.close", "evaluation_log_hook", "MetricsLogger.get_log", "len", "pandas_input_fn", "data.drop", "MetricsLogger.get_log"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.evaluation_log_hook", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.get_log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.get_log"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_evaluation_log_hook", "(", "pd_df", ",", "tmp", ")", ":", "\n", "    ", "data", ",", "users", ",", "items", "=", "pd_df", "\n", "\n", "# Run hook 10 times", "\n", "hook_frequency", "=", "10", "\n", "train_steps", "=", "10", "\n", "\n", "_", ",", "deep_columns", "=", "build_feature_columns", "(", "users", ",", "items", ",", "model_type", "=", "\"deep\"", ")", "\n", "\n", "model", "=", "build_model", "(", "\n", "tmp", ",", "\n", "deep_columns", "=", "deep_columns", ",", "\n", "save_checkpoints_steps", "=", "train_steps", "//", "hook_frequency", ",", "\n", ")", "\n", "\n", "evaluation_logger", "=", "MetricsLogger", "(", ")", "\n", "\n", "# Train a model w/ the hook", "\n", "hooks", "=", "[", "\n", "evaluation_log_hook", "(", "\n", "model", ",", "\n", "logger", "=", "evaluation_logger", ",", "\n", "true_df", "=", "data", ",", "\n", "y_col", "=", "DEFAULT_RATING_COL", ",", "\n", "eval_df", "=", "data", ".", "drop", "(", "DEFAULT_RATING_COL", ",", "axis", "=", "1", ")", ",", "\n", "every_n_iter", "=", "train_steps", "//", "hook_frequency", ",", "\n", "model_dir", "=", "tmp", ",", "\n", "eval_fns", "=", "[", "rmse", "]", ",", "\n", ")", "\n", "]", "\n", "model", ".", "train", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "data", ",", "\n", "y_col", "=", "DEFAULT_RATING_COL", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_epochs", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", ",", "\n", "hooks", "=", "hooks", ",", "\n", "steps", "=", "train_steps", ",", "\n", ")", "\n", "\n", "# Check if hook logged the given metric", "\n", "assert", "rmse", ".", "__name__", "in", "evaluation_logger", ".", "get_log", "(", ")", "\n", "assert", "len", "(", "evaluation_logger", ".", "get_log", "(", ")", "[", "rmse", ".", "__name__", "]", ")", "==", "hook_frequency", "\n", "\n", "# Close the event file so that the model folder can be cleaned up.", "\n", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "model", ".", "model_dir", ")", "\n", "summary_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_tf_utils.test_pandas_input_fn_for_saved_model": [[186, 237], ["os.path.join", "os.path.join", "build_feature_columns", "build_model", "pandas_input_fn", "build_model.train", "export_model", "tf.saved_model.load", "data.drop", "data.drop.reset_index", "list", "tf.compat.v1.summary.FileWriterCache.get", "tf.compat.v1.summary.FileWriterCache.get.close", "itertools.islice", "pandas_input_fn", "len", "pandas_input_fn_for_saved_model"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.export_model", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn_for_saved_model"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_pandas_input_fn_for_saved_model", "(", "pd_df", ",", "tmp", ")", ":", "\n", "    ", "\"\"\"Test `export_model` and `pandas_input_fn_for_saved_model`\"\"\"", "\n", "data", ",", "users", ",", "items", "=", "pd_df", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"model\"", ")", "\n", "export_dir", "=", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"export\"", ")", "\n", "\n", "_", ",", "deep_columns", "=", "build_feature_columns", "(", "users", ",", "items", ",", "model_type", "=", "\"deep\"", ")", "\n", "\n", "# Train a model", "\n", "model", "=", "build_model", "(", "\n", "model_dir", ",", "\n", "deep_columns", "=", "deep_columns", ",", "\n", ")", "\n", "train_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "data", ",", "y_col", "=", "DEFAULT_RATING_COL", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "None", ",", "shuffle", "=", "True", "\n", ")", "\n", "model", ".", "train", "(", "input_fn", "=", "train_fn", ",", "steps", "=", "1", ")", "\n", "\n", "# Test export_model function", "\n", "exported_path", "=", "export_model", "(", "\n", "model", "=", "model", ",", "\n", "train_input_fn", "=", "train_fn", ",", "\n", "eval_input_fn", "=", "pandas_input_fn", "(", "df", "=", "data", ",", "y_col", "=", "DEFAULT_RATING_COL", ")", ",", "\n", "tf_feat_cols", "=", "deep_columns", ",", "\n", "base_dir", "=", "export_dir", ",", "\n", ")", "\n", "saved_model", "=", "tf", ".", "saved_model", ".", "load", "(", "exported_path", ",", "tags", "=", "\"serve\"", ")", "\n", "\n", "# Test pandas_input_fn_for_saved_model with the saved model", "\n", "test", "=", "data", ".", "drop", "(", "DEFAULT_RATING_COL", ",", "axis", "=", "1", ")", "\n", "test", ".", "reset_index", "(", "drop", "=", "True", ",", "inplace", "=", "True", ")", "\n", "list", "(", "\n", "itertools", ".", "islice", "(", "\n", "saved_model", ".", "signatures", "[", "\"predict\"", "]", "(", "\n", "examples", "=", "pandas_input_fn_for_saved_model", "(", "\n", "df", "=", "test", ",", "\n", "feat_name_type", "=", "{", "\n", "DEFAULT_USER_COL", ":", "int", ",", "\n", "DEFAULT_ITEM_COL", ":", "int", ",", "\n", "ITEM_FEAT_COL", ":", "list", ",", "\n", "}", ",", "\n", ")", "(", ")", "[", "\"inputs\"", "]", "\n", ")", ",", "\n", "len", "(", "test", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# Close the event file so that the model folder can be cleaned up.", "\n", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "model", ".", "model_dir", ")", "\n", "summary_writer", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_general_utils.test_invert_dictionary": [[7, 11], ["recommenders.utils.general_utils.invert_dictionary"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.invert_dictionary"], ["def", "test_invert_dictionary", "(", ")", ":", "\n", "    ", "d", "=", "{", "\"a\"", ":", "1", ",", "\"b\"", ":", "2", "}", "\n", "d_inv", "=", "invert_dictionary", "(", "d", ")", "\n", "assert", "d_inv", "==", "{", "1", ":", "\"a\"", ",", "2", ":", "\"b\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_general_utils.test_get_number_processors": [[13, 15], ["recommenders.utils.general_utils.get_number_processors"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.get_number_processors"], ["", "def", "test_get_number_processors", "(", ")", ":", "\n", "    ", "assert", "get_number_processors", "(", ")", ">=", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.utils.test_plot.test_line_graph": [[11, 37], ["recommenders.utils.plot.line_graph", "matplotlib.close", "recommenders.utils.plot.line_graph", "matplotlib.close", "recommenders.utils.plot.line_graph", "matplotlib.close"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.plot.line_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.plot.line_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.plot.line_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close"], ["def", "test_line_graph", "(", ")", ":", "\n", "    ", "\"\"\"Naive test to run the function without errors\"\"\"", "\n", "# Multiple graphs", "\n", "line_graph", "(", "\n", "values", "=", "[", "[", "1", ",", "2", ",", "3", "]", ",", "[", "3", ",", "2", ",", "1", "]", "]", ",", "\n", "labels", "=", "[", "\"Train\"", ",", "\"Valid\"", "]", ",", "\n", "x_guides", "=", "[", "0", ",", "1", "]", ",", "\n", "x_name", "=", "\"Epoch\"", ",", "\n", "y_name", "=", "\"Accuracy\"", ",", "\n", "legend_loc", "=", "\"best\"", ",", "\n", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "# Single graph as a subplot", "\n", "line_graph", "(", "values", "=", "[", "1", ",", "2", ",", "3", "]", ",", "labels", "=", "\"Train\"", ",", "subplot", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "# Single graph with x values", "\n", "line_graph", "(", "\n", "values", "=", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "3", ",", "3", ")", "]", ",", "\n", "labels", "=", "\"Train\"", ",", "\n", "x_min_max", "=", "(", "0", ",", "5", ")", ",", "\n", "y_min_max", "=", "(", "0", ",", "5", ")", ",", "\n", "plot_size", "=", "(", "5", ",", "5", ")", ",", "\n", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.load_pandas_df": [[29, 62], ["recommenders.datasets.download_utils.download_path", "criteo.download_criteo", "criteo.extract_criteo", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.download_criteo", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.extract_criteo"], ["def", "load_pandas_df", "(", "size", "=", "\"sample\"", ",", "local_cache_path", "=", "None", ",", "header", "=", "DEFAULT_HEADER", ")", ":", "\n", "    ", "\"\"\"Loads the Criteo DAC dataset as `pandas.DataFrame`. This function download, untar, and load the dataset.\n\n    The dataset consists of a portion of Criteo\u2019s traffic over a period\n    of 24 days. Each row corresponds to a display ad served by Criteo and the first\n    column indicates whether this ad has been clicked or not.\n\n    There are 13 features taking integer values (mostly count features) and 26\n    categorical features. The values of the categorical features have been hashed\n    onto 32 bits for anonymization purposes.\n\n    The schema is:\n\n    .. code-block:: python\n\n        <label> <integer feature 1> ... <integer feature 13> <categorical feature 1> ... <categorical feature 26>\n\n    More details (need to accept user terms to see the information):\n    http://labs.criteo.com/2013/12/download-terabyte-click-logs/\n\n    Args:\n        size (str): Dataset size. It can be \"sample\" or \"full\".\n        local_cache_path (str): Path where to cache the tar.gz file locally\n        header (list): Dataset header names.\n\n    Returns:\n        pandas.DataFrame: Criteo DAC sample dataset.\n    \"\"\"", "\n", "with", "download_path", "(", "local_cache_path", ")", "as", "path", ":", "\n", "        ", "filepath", "=", "download_criteo", "(", "size", ",", "path", ")", "\n", "filepath", "=", "extract_criteo", "(", "size", ",", "filepath", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "filepath", ",", "sep", "=", "\"\\t\"", ",", "header", "=", "None", ",", "names", "=", "header", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.load_spark_df": [[64, 124], ["recommenders.datasets.download_utils.download_path", "criteo.download_criteo", "criteo.extract_criteo", "recommenders.utils.notebook_utils.is_databricks", "criteo.get_spark_schema", "spark.read.csv", "spark.read.csv.cache().count", "dbutils.fs.cp", "spark.read.csv.cache", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.download_criteo", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.extract_criteo", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_databricks", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.get_spark_schema"], ["", "def", "load_spark_df", "(", "\n", "spark", ",", "\n", "size", "=", "\"sample\"", ",", "\n", "header", "=", "DEFAULT_HEADER", ",", "\n", "local_cache_path", "=", "None", ",", "\n", "dbfs_datapath", "=", "\"dbfs:/FileStore/dac\"", ",", "\n", "dbutils", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads the Criteo DAC dataset as `pySpark.DataFrame`.\n\n    The dataset consists of a portion of Criteo\u2019s traffic over a period\n    of 24 days. Each row corresponds to a display ad served by Criteo and the first\n    column is indicates whether this ad has been clicked or not.\n\n    There are 13 features taking integer values (mostly count features) and 26\n    categorical features. The values of the categorical features have been hashed\n    onto 32 bits for anonymization purposes.\n\n    The schema is:\n\n    .. code-block:: python\n\n        <label> <integer feature 1> ... <integer feature 13> <categorical feature 1> ... <categorical feature 26>\n\n    More details (need to accept user terms to see the information):\n    http://labs.criteo.com/2013/12/download-terabyte-click-logs/\n\n    Args:\n        spark (pySpark.SparkSession): Spark session.\n        size (str): Dataset size. It can be \"sample\" or \"full\".\n        local_cache_path (str): Path where to cache the tar.gz file locally.\n        header (list): Dataset header names.\n        dbfs_datapath (str): Where to store the extracted files on Databricks.\n        dbutils (Databricks.dbutils): Databricks utility object.\n\n    Returns:\n        pyspark.sql.DataFrame: Criteo DAC training dataset.\n    \"\"\"", "\n", "with", "download_path", "(", "local_cache_path", ")", "as", "path", ":", "\n", "        ", "filepath", "=", "download_criteo", "(", "size", ",", "path", ")", "\n", "filepath", "=", "extract_criteo", "(", "size", ",", "filepath", ")", "\n", "\n", "if", "is_databricks", "(", ")", ":", "\n", "            ", "try", ":", "\n", "# Driver node's file path", "\n", "                ", "node_path", "=", "\"file:\"", "+", "filepath", "\n", "# needs to be on dbfs to load", "\n", "dbutils", ".", "fs", ".", "cp", "(", "node_path", ",", "dbfs_datapath", ",", "recurse", "=", "True", ")", "\n", "path", "=", "dbfs_datapath", "\n", "", "except", "Exception", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"To use on a Databricks notebook, dbutils object should be passed as an argument\"", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "path", "=", "filepath", "\n", "\n", "", "schema", "=", "get_spark_schema", "(", "header", ")", "\n", "df", "=", "spark", ".", "read", ".", "csv", "(", "path", ",", "schema", "=", "schema", ",", "sep", "=", "\"\\t\"", ",", "header", "=", "False", ")", "\n", "df", ".", "cache", "(", ")", ".", "count", "(", ")", "# trigger execution to overcome spark's lazy evaluation", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.download_criteo": [[126, 139], ["recommenders.datasets.download_utils.maybe_download"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "def", "download_criteo", "(", "size", "=", "\"sample\"", ",", "work_directory", "=", "\".\"", ")", ":", "\n", "    ", "\"\"\"Download criteo dataset as a compressed file.\n\n    Args:\n        size (str): Size of criteo dataset. It can be \"full\" or \"sample\".\n        work_directory (str): Working directory.\n\n    Returns:\n        str: Path of the downloaded file.\n\n    \"\"\"", "\n", "url", "=", "CRITEO_URL", "[", "size", "]", "\n", "return", "maybe_download", "(", "url", ",", "work_directory", "=", "work_directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.extract_criteo": [[141, 164], ["os.path.join", "os.path.dirname", "os.path.join", "tarfile.open", "tar.extractall"], "function", ["None"], ["", "def", "extract_criteo", "(", "size", ",", "compressed_file", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract Criteo dataset tar.\n\n    Args:\n        size (str): Size of Criteo dataset. It can be \"full\" or \"sample\".\n        compressed_file (str): Path to compressed file.\n        path (str): Path to extract the file.\n\n    Returns:\n        str: Path to the extracted file.\n\n    \"\"\"", "\n", "if", "path", "is", "None", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "dirname", "(", "compressed_file", ")", "\n", "extracted_dir", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "\"dac\"", ")", "\n", "", "else", ":", "\n", "        ", "extracted_dir", "=", "path", "\n", "\n", "", "with", "tarfile", ".", "open", "(", "compressed_file", ")", "as", "tar", ":", "\n", "        ", "tar", ".", "extractall", "(", "extracted_dir", ")", "\n", "\n", "", "filename_selector", "=", "{", "\"sample\"", ":", "\"dac_sample.txt\"", ",", "\"full\"", ":", "\"train.txt\"", "}", "\n", "return", "os", ".", "path", ".", "join", "(", "extracted_dir", ",", "filename_selector", "[", "size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.get_spark_schema": [[166, 185], ["StructType", "range", "range", "StructType.add", "StructType.add", "StructField", "StructField", "IntegerType", "StringType"], "function", ["None"], ["", "def", "get_spark_schema", "(", "header", "=", "DEFAULT_HEADER", ")", ":", "\n", "    ", "\"\"\"Get Spark schema from header.\n\n    Args:\n        header (list): Dataset header names.\n\n    Returns:\n        pyspark.sql.types.StructType: Spark schema.\n    \"\"\"", "\n", "# create schema", "\n", "schema", "=", "StructType", "(", ")", "\n", "# do label + ints", "\n", "n_ints", "=", "14", "\n", "for", "i", "in", "range", "(", "n_ints", ")", ":", "\n", "        ", "schema", ".", "add", "(", "StructField", "(", "header", "[", "i", "]", ",", "IntegerType", "(", ")", ")", ")", "\n", "# do categoricals", "\n", "", "for", "i", "in", "range", "(", "26", ")", ":", "\n", "        ", "schema", ".", "add", "(", "StructField", "(", "header", "[", "i", "+", "n_ints", "]", ",", "StringType", "(", ")", ")", ")", "\n", "", "return", "schema", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.process_split_ratio": [[18, 50], ["isinstance", "isinstance", "ValueError", "any", "TypeError", "ValueError", "math.fsum", "math.fsum"], "function", ["None"], ["", "def", "process_split_ratio", "(", "ratio", ")", ":", "\n", "    ", "\"\"\"Generate split ratio lists.\n\n    Args:\n        ratio (float or list): a float number that indicates split ratio or a list of float\n        numbers that indicate split ratios (if it is a multi-split).\n\n    Returns:\n        tuple:\n        - bool: A boolean variable multi that indicates if the splitting is multi or single.\n        - list: A list of normalized split ratios.\n    \"\"\"", "\n", "if", "isinstance", "(", "ratio", ",", "float", ")", ":", "\n", "        ", "if", "ratio", "<=", "0", "or", "ratio", ">=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Split ratio has to be between 0 and 1\"", ")", "\n", "\n", "", "multi", "=", "False", "\n", "", "elif", "isinstance", "(", "ratio", ",", "list", ")", ":", "\n", "        ", "if", "any", "(", "[", "x", "<=", "0", "for", "x", "in", "ratio", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"All split ratios in the ratio list should be larger than 0.\"", "\n", ")", "\n", "\n", "# normalize split ratios if they are not summed to 1", "\n", "", "if", "math", ".", "fsum", "(", "ratio", ")", "!=", "1.0", ":", "\n", "            ", "ratio", "=", "[", "x", "/", "math", ".", "fsum", "(", "ratio", ")", "for", "x", "in", "ratio", "]", "\n", "\n", "", "multi", "=", "True", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"Split ratio should be either float or a list of floats.\"", ")", "\n", "\n", "", "return", "multi", ",", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas": [[52, 84], ["split_utils._get_column_name", "data.groupby().filter", "ValueError", "data.groupby", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils._get_column_name"], ["", "def", "min_rating_filter_pandas", "(", "\n", "data", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Filter rating DataFrame for each user with minimum rating.\n\n    Filter rating data frame with minimum number of ratings for user/item is usually useful to\n    generate a new data frame with warm user/item. The warmth is defined by min_rating argument. For\n    example, a user is called warm if he has rated at least 4 items.\n\n    Args:\n        data (pandas.DataFrame): DataFrame of user-item tuples. Columns of user and item\n            should be present in the DataFrame while other columns like rating,\n            timestamp, etc. can be optional.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to\n            filter with min_rating.\n        col_user (str): column name of user ID.\n        col_item (str): column name of item ID.\n\n    Returns:\n        pandas.DataFrame: DataFrame with at least columns of user and item that has been filtered by the given specifications.\n    \"\"\"", "\n", "split_by_column", "=", "_get_column_name", "(", "filter_by", ",", "col_user", ",", "col_item", ")", "\n", "\n", "if", "min_rating", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"min_rating should be integer and larger than or equal to 1.\"", ")", "\n", "\n", "", "return", "data", ".", "groupby", "(", "split_by_column", ")", ".", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">=", "min_rating", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_spark": [[86, 127], ["split_utils._get_column_name", "ValueError", "Window.partitionBy", "data.withColumn().where().drop.withColumn().where().drop", "data.withColumn().where().drop.withColumn().where", "data.withColumn().where().drop.withColumn", "F.col", "F.count().over", "F.count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils._get_column_name"], ["", "def", "min_rating_filter_spark", "(", "\n", "data", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Filter rating DataFrame for each user with minimum rating.\n\n    Filter rating data frame with minimum number of ratings for user/item is usually useful to\n    generate a new data frame with warm user/item. The warmth is defined by min_rating argument. For\n    example, a user is called warm if he has rated at least 4 items.\n\n    Args:\n        data (pyspark.sql.DataFrame): DataFrame of user-item tuples. Columns of user and item\n            should be present in the DataFrame while other columns like rating,\n            timestamp, etc. can be optional.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to\n            filter with min_rating.\n        col_user (str): column name of user ID.\n        col_item (str): column name of item ID.\n\n    Returns:\n        pyspark.sql.DataFrame: DataFrame with at least columns of user and item that has been filtered by the given specifications.\n    \"\"\"", "\n", "\n", "split_by_column", "=", "_get_column_name", "(", "filter_by", ",", "col_user", ",", "col_item", ")", "\n", "\n", "if", "min_rating", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"min_rating should be integer and larger than or equal to 1.\"", ")", "\n", "\n", "", "if", "min_rating", ">", "1", ":", "\n", "        ", "window", "=", "Window", ".", "partitionBy", "(", "split_by_column", ")", "\n", "data", "=", "(", "\n", "data", ".", "withColumn", "(", "\"_count\"", ",", "F", ".", "count", "(", "split_by_column", ")", ".", "over", "(", "window", ")", ")", "\n", ".", "where", "(", "F", ".", "col", "(", "\"_count\"", ")", ">=", "min_rating", ")", "\n", ".", "drop", "(", "\"_count\"", ")", "\n", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils._get_column_name": [[129, 136], ["ValueError"], "function", ["None"], ["", "def", "_get_column_name", "(", "name", ",", "col_user", ",", "col_item", ")", ":", "\n", "    ", "if", "name", "==", "\"user\"", ":", "\n", "        ", "return", "col_user", "\n", "", "elif", "name", "==", "\"item\"", ":", "\n", "        ", "return", "col_item", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"name should be either 'user' or 'item'.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios": [[138, 169], ["numpy.split", "range", "math.fsum", "ValueError", "numpy.cumsum().tolist", "data.sample.sample", "len", "round", "numpy.cumsum", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "", "def", "split_pandas_data_with_ratios", "(", "data", ",", "ratios", ",", "seed", "=", "42", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"Helper function to split pandas DataFrame with given ratios\n\n    .. note::\n\n        Implementation referenced from `this source <https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test>`_.\n\n    Args:\n        data (pandas.DataFrame): Pandas data frame to be split.\n        ratios (list of floats): list of ratios for split. The ratios have to sum to 1.\n        seed (int): random seed.\n        shuffle (bool): whether data will be shuffled when being split.\n\n    Returns:\n        list: List of pd.DataFrame split by the given specifications.\n    \"\"\"", "\n", "if", "math", ".", "fsum", "(", "ratios", ")", "!=", "1.0", ":", "\n", "        ", "raise", "ValueError", "(", "\"The ratios have to sum to 1\"", ")", "\n", "\n", "", "split_index", "=", "np", ".", "cumsum", "(", "ratios", ")", ".", "tolist", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "data", "=", "data", ".", "sample", "(", "frac", "=", "1", ",", "random_state", "=", "seed", ")", "\n", "\n", "", "splits", "=", "np", ".", "split", "(", "data", ",", "[", "round", "(", "x", "*", "len", "(", "data", ")", ")", "for", "x", "in", "split_index", "]", ")", "\n", "\n", "# Add split index (this makes splitting by group more efficient).", "\n", "for", "i", "in", "range", "(", "len", "(", "ratios", ")", ")", ":", "\n", "        ", "splits", "[", "i", "]", "[", "\"split_index\"", "]", "=", "i", "\n", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.filter_k_core": [[171, 201], ["logger.info", "data.copy", "min_rating_filter_pandas.sort_values", "len", "len", "logger.info", "len", "len", "df_inp[].unique", "df_inp[].unique", "data[].unique", "data[].unique", "split_utils.min_rating_filter_pandas", "split_utils.min_rating_filter_pandas", "[].count", "[].count", "len", "len", "min_rating_filter_pandas.groupby", "min_rating_filter_pandas.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas"], ["", "def", "filter_k_core", "(", "data", ",", "core_num", "=", "0", ",", "col_user", "=", "\"userID\"", ",", "col_item", "=", "\"itemID\"", ")", ":", "\n", "    ", "\"\"\"Filter rating dataframe for minimum number of users and items by\n    repeatedly applying min_rating_filter until the condition is satisfied.\n\n    \"\"\"", "\n", "num_users", ",", "num_items", "=", "len", "(", "data", "[", "col_user", "]", ".", "unique", "(", ")", ")", ",", "len", "(", "data", "[", "col_item", "]", ".", "unique", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Original: %d users and %d items\"", ",", "num_users", ",", "num_items", ")", "\n", "df_inp", "=", "data", ".", "copy", "(", ")", "\n", "\n", "if", "core_num", ">", "0", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "df_inp", "=", "min_rating_filter_pandas", "(", "\n", "df_inp", ",", "min_rating", "=", "core_num", ",", "filter_by", "=", "\"item\"", "\n", ")", "\n", "df_inp", "=", "min_rating_filter_pandas", "(", "\n", "df_inp", ",", "min_rating", "=", "core_num", ",", "filter_by", "=", "\"user\"", "\n", ")", "\n", "count_u", "=", "df_inp", ".", "groupby", "(", "col_user", ")", "[", "col_item", "]", ".", "count", "(", ")", "\n", "count_i", "=", "df_inp", ".", "groupby", "(", "col_item", ")", "[", "col_user", "]", ".", "count", "(", ")", "\n", "if", "(", "\n", "len", "(", "count_i", "[", "count_i", "<", "core_num", "]", ")", "==", "0", "\n", "and", "len", "(", "count_u", "[", "count_u", "<", "core_num", "]", ")", "==", "0", "\n", ")", ":", "\n", "                ", "break", "\n", "", "", "", "df_inp", "=", "df_inp", ".", "sort_values", "(", "by", "=", "[", "col_user", "]", ")", "\n", "num_users", "=", "len", "(", "df_inp", "[", "col_user", "]", ".", "unique", "(", ")", ")", "\n", "num_items", "=", "len", "(", "df_inp", "[", "col_item", "]", ".", "unique", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Final: %d users and %d items\"", ",", "num_users", ",", "num_items", ")", "\n", "\n", "return", "df_inp", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download": [[18, 62], ["retrying.retry", "os.makedirs", "os.path.join", "os.path.exists", "requests.get", "log.info", "os.stat", "url.split", "log.info", "int", "math.ceil", "log.error", "requests.get.raise_for_status", "os.remove", "IOError", "requests.get.headers.get", "open", "tqdm.tqdm", "requests.get.iter_content", "file.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["@", "retry", "(", "wait_random_min", "=", "1000", ",", "wait_random_max", "=", "5000", ",", "stop_max_attempt_number", "=", "5", ")", "\n", "def", "maybe_download", "(", "url", ",", "filename", "=", "None", ",", "work_directory", "=", "\".\"", ",", "expected_bytes", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download a file if it is not already downloaded.\n\n    Args:\n        filename (str): File name.\n        work_directory (str): Working directory.\n        url (str): URL of the file to download.\n        expected_bytes (int): Expected file size in bytes.\n\n    Returns:\n        str: File path of the file downloaded.\n    \"\"\"", "\n", "if", "filename", "is", "None", ":", "\n", "        ", "filename", "=", "url", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "", "os", ".", "makedirs", "(", "work_directory", ",", "exist_ok", "=", "True", ")", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "work_directory", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "r", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "if", "r", ".", "status_code", "==", "200", ":", "\n", "            ", "log", ".", "info", "(", "f\"Downloading {url}\"", ")", "\n", "total_size", "=", "int", "(", "r", ".", "headers", ".", "get", "(", "\"content-length\"", ",", "0", ")", ")", "\n", "block_size", "=", "1024", "\n", "num_iterables", "=", "math", ".", "ceil", "(", "total_size", "/", "block_size", ")", "\n", "with", "open", "(", "filepath", ",", "\"wb\"", ")", "as", "file", ":", "\n", "                ", "for", "data", "in", "tqdm", "(", "\n", "r", ".", "iter_content", "(", "block_size", ")", ",", "\n", "total", "=", "num_iterables", ",", "\n", "unit", "=", "\"KB\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", ")", ":", "\n", "                    ", "file", ".", "write", "(", "data", ")", "\n", "", "", "", "else", ":", "\n", "            ", "log", ".", "error", "(", "f\"Problem downloading {url}\"", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "log", ".", "info", "(", "f\"File {filepath} already downloaded\"", ")", "\n", "", "if", "expected_bytes", "is", "not", "None", ":", "\n", "        ", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "if", "statinfo", ".", "st_size", "!=", "expected_bytes", ":", "\n", "            ", "os", ".", "remove", "(", "filepath", ")", "\n", "raise", "IOError", "(", "f\"Failed to verify {filepath}\"", ")", "\n", "\n", "", "", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path": [[64, 89], ["tempfile.TemporaryDirectory", "os.path.realpath", "tempfile.TemporaryDirectory.cleanup"], "function", ["None"], ["", "@", "contextmanager", "\n", "def", "download_path", "(", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return a path to download data. If `path=None`, then it yields a temporal path that is eventually deleted,\n    otherwise the real path of the input.\n\n    Args:\n        path (str): Path to download data.\n\n    Returns:\n        str: Real path where the data is stored.\n\n    Examples:\n        >>> with download_path() as path:\n        >>> ... maybe_download(url=\"http://example.com/file.zip\", work_directory=path)\n\n    \"\"\"", "\n", "if", "path", "is", "None", ":", "\n", "        ", "tmp_dir", "=", "TemporaryDirectory", "(", ")", "\n", "try", ":", "\n", "            ", "yield", "tmp_dir", ".", "name", "\n", "", "finally", ":", "\n", "            ", "tmp_dir", ".", "cleanup", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "realpath", "(", "path", ")", "\n", "yield", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.unzip_file": [[91, 104], ["zipfile.ZipFile", "zipfile.ZipFile.namelist", "zipfile.ZipFile.extract", "os.remove"], "function", ["None"], ["", "", "def", "unzip_file", "(", "zip_src", ",", "dst_dir", ",", "clean_zip_file", "=", "False", ")", ":", "\n", "    ", "\"\"\"Unzip a file\n\n    Args:\n        zip_src (str): Zip file.\n        dst_dir (str): Destination folder.\n        clean_zip_file (bool): Whether or not to clean the zip file.\n    \"\"\"", "\n", "fz", "=", "zipfile", ".", "ZipFile", "(", "zip_src", ",", "\"r\"", ")", "\n", "for", "file", "in", "fz", ".", "namelist", "(", ")", ":", "\n", "        ", "fz", ".", "extract", "(", "file", ",", "dst_dir", ")", "\n", "", "if", "clean_zip_file", ":", "\n", "        ", "os", ".", "remove", "(", "zip_src", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_random_split": [[19, 45], ["recommenders.datasets.split_utils.process_split_ratio", "recommenders.datasets.split_utils.split_pandas_data_with_ratios", "sklearn.model_selection.train_test_split", "x.drop"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.process_split_ratio", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios"], ["def", "python_random_split", "(", "data", ",", "ratio", "=", "0.75", ",", "seed", "=", "42", ")", ":", "\n", "    ", "\"\"\"Pandas random splitter.\n\n    The splitter randomly splits the input data.\n\n    Args:\n        data (pandas.DataFrame): Pandas DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two halves and the ratio argument indicates the ratio\n            of training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n        seed (int): Seed.\n\n    Returns:\n        list: Splits of the input data as pandas.DataFrame.\n    \"\"\"", "\n", "multi_split", ",", "ratio", "=", "process_split_ratio", "(", "ratio", ")", "\n", "\n", "if", "multi_split", ":", "\n", "        ", "splits", "=", "split_pandas_data_with_ratios", "(", "data", ",", "ratio", ",", "shuffle", "=", "True", ",", "seed", "=", "seed", ")", "\n", "splits_new", "=", "[", "x", ".", "drop", "(", "\"split_index\"", ",", "axis", "=", "1", ")", "for", "x", "in", "splits", "]", "\n", "\n", "return", "splits_new", "\n", "", "else", ":", "\n", "        ", "return", "sk_split", "(", "data", ",", "test_size", "=", "None", ",", "train_size", "=", "ratio", ",", "random_state", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters._do_stratification": [[47, 120], ["recommenders.datasets.split_utils.process_split_ratio", "pandas.concat", "ValueError", "ValueError", "ValueError", "ValueError", "recommenders.datasets.split_utils.min_rating_filter_pandas", "recommenders.datasets.split_utils.min_rating_filter_pandas.sort_values().groupby", "recommenders.datasets.split_utils.min_rating_filter_pandas.groupby", "recommenders.datasets.split_utils.split_pandas_data_with_ratios", "pandas.concat", "splits.append", "splits_all[].drop", "ValueError", "range", "recommenders.datasets.split_utils.min_rating_filter_pandas.sort_values", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.process_split_ratio", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios"], ["", "", "def", "_do_stratification", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "is_random", "=", "True", ",", "\n", "seed", "=", "42", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", ")", ":", "\n", "# A few preliminary checks.", "\n", "    ", "if", "not", "(", "filter_by", "==", "\"user\"", "or", "filter_by", "==", "\"item\"", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"filter_by should be either 'user' or 'item'.\"", ")", "\n", "\n", "", "if", "min_rating", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"min_rating should be integer and larger than or equal to 1.\"", ")", "\n", "\n", "", "if", "col_user", "not", "in", "data", ".", "columns", ":", "\n", "        ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing User Col\"", ")", "\n", "\n", "", "if", "col_item", "not", "in", "data", ".", "columns", ":", "\n", "        ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing Item Col\"", ")", "\n", "\n", "", "if", "not", "is_random", ":", "\n", "        ", "if", "col_timestamp", "not", "in", "data", ".", "columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing Timestamp Col\"", ")", "\n", "\n", "", "", "multi_split", ",", "ratio", "=", "process_split_ratio", "(", "ratio", ")", "\n", "\n", "split_by_column", "=", "col_user", "if", "filter_by", "==", "\"user\"", "else", "col_item", "\n", "\n", "ratio", "=", "ratio", "if", "multi_split", "else", "[", "ratio", ",", "1", "-", "ratio", "]", "\n", "\n", "if", "min_rating", ">", "1", ":", "\n", "        ", "data", "=", "min_rating_filter_pandas", "(", "\n", "data", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", ")", "\n", "\n", "# Split by each group and aggregate splits together.", "\n", "", "splits", "=", "[", "]", "\n", "\n", "# If it is for chronological splitting, the split will be performed in a random way.", "\n", "df_grouped", "=", "(", "\n", "data", ".", "sort_values", "(", "col_timestamp", ")", ".", "groupby", "(", "split_by_column", ")", "\n", "if", "is_random", "is", "False", "\n", "else", "data", ".", "groupby", "(", "split_by_column", ")", "\n", ")", "\n", "\n", "for", "_", ",", "group", "in", "df_grouped", ":", "\n", "        ", "group_splits", "=", "split_pandas_data_with_ratios", "(", "\n", "group", ",", "ratio", ",", "shuffle", "=", "is_random", ",", "seed", "=", "seed", "\n", ")", "\n", "\n", "# Concatenate the list of split dataframes.", "\n", "concat_group_splits", "=", "pd", ".", "concat", "(", "group_splits", ")", "\n", "\n", "splits", ".", "append", "(", "concat_group_splits", ")", "\n", "\n", "# Concatenate splits for all the groups together.", "\n", "", "splits_all", "=", "pd", ".", "concat", "(", "splits", ")", "\n", "\n", "# Take split by split_index", "\n", "splits_list", "=", "[", "\n", "splits_all", "[", "splits_all", "[", "\"split_index\"", "]", "==", "x", "]", ".", "drop", "(", "\"split_index\"", ",", "axis", "=", "1", ")", "\n", "for", "x", "in", "range", "(", "len", "(", "ratio", ")", ")", "\n", "]", "\n", "\n", "return", "splits_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_chrono_split": [[122, 164], ["python_splitters._do_stratification"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters._do_stratification"], ["", "def", "python_chrono_split", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Pandas chronological splitter.\n\n    This function splits data in a chronological manner. That is, for each user / item, the\n    split function takes proportions of ratings which is specified by the split ratio(s).\n    The split is stratified.\n\n    Args:\n        data (pandas.DataFrame): Pandas DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two halves and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n        seed (int): Seed.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to\n            filter with min_rating.\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n        col_timestamp (str): column name of timestamps.\n\n    Returns:\n        list: Splits of the input data as pandas.DataFrame.\n    \"\"\"", "\n", "return", "_do_stratification", "(", "\n", "data", ",", "\n", "ratio", "=", "ratio", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_timestamp", "=", "col_timestamp", ",", "\n", "is_random", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_stratified_split": [[167, 207], ["python_splitters._do_stratification"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters._do_stratification"], ["", "def", "python_stratified_split", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Pandas stratified splitter.\n\n    For each user / item, the split function takes proportions of ratings which is\n    specified by the split ratio(s). The split is stratified.\n\n    Args:\n        data (pandas.DataFrame): Pandas DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two halves and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n        seed (int): Seed.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to\n            filter with min_rating.\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n\n    Returns:\n        list: Splits of the input data as pandas.DataFrame.\n    \"\"\"", "\n", "return", "_do_stratification", "(", "\n", "data", ",", "\n", "ratio", "=", "ratio", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "is_random", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.numpy_stratified_split": [[210, 282], ["numpy.random.seed", "int", "X.copy", "X.copy", "numpy.sum", "numpy.around().astype", "range", "[].tolist", "numpy.random.choice", "list", "numpy.around", "set().difference", "set", "numpy.asarray", "set", "numpy.where"], "function", ["None"], ["", "def", "numpy_stratified_split", "(", "X", ",", "ratio", "=", "0.75", ",", "seed", "=", "42", ")", ":", "\n", "    ", "\"\"\"Split the user/item affinity matrix (sparse matrix) into train and test set matrices while maintaining\n    local (i.e. per user) ratios.\n\n    Main points :\n\n    1. In a typical recommender problem, different users rate a different number of items,\n    and therefore the user/affinity matrix has a sparse structure with variable number\n    of zeroes (unrated items) per row (user). Cutting a total amount of ratings will\n    result in a non-homogeneous distribution between train and test set, i.e. some test\n    users may have many ratings while other very little if none.\n\n    2. In an unsupervised learning problem, no explicit answer is given. For this reason\n    the split needs to be implemented in a different way then in supervised learningself.\n    In the latter, one typically split the dataset by rows (by examples), ending up with\n    the same number of features but different number of examples in the train/test setself.\n    This scheme does not work in the unsupervised case, as part of the rated items needs to\n    be used as a test set for fixed number of users.\n\n    Solution:\n\n    1. Instead of cutting a total percentage, for each user we cut a relative ratio of the rated\n    items. For example, if user1 has rated 4 items and user2 10, cutting 25% will correspond to\n    1 and 2.6 ratings in the test set, approximated as 1 and 3 according to the round() function.\n    In this way, the 0.75 ratio is satisfied both locally and globally, preserving the original\n    distribution of ratings across the train and test set.\n\n    2. It is easy (and fast) to satisfy this requirements by creating the test via element subtraction\n    from the original dataset X. We first create two copies of X; for each user we select a random\n    sample of local size ratio (point 1) and erase the remaining ratings, obtaining in this way the\n    train set matrix Xtst. The train set matrix is obtained in the opposite way.\n\n    Args:\n        X (numpy.ndarray, int): a sparse matrix to be split\n        ratio (float): fraction of the entire dataset to constitute the train set\n        seed (int): random seed\n\n    Returns:\n        numpy.ndarray, numpy.ndarray:\n        - Xtr: The train set user/item affinity matrix.\n        - Xtst: The test set user/item affinity matrix.\n    \"\"\"", "\n", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "# set the random seed", "\n", "test_cut", "=", "int", "(", "(", "1", "-", "ratio", ")", "*", "100", ")", "# percentage of ratings to go in the test set", "\n", "\n", "# initialize train and test set matrices", "\n", "Xtr", "=", "X", ".", "copy", "(", ")", "\n", "Xtst", "=", "X", ".", "copy", "(", ")", "\n", "\n", "# find the number of rated movies per user", "\n", "rated", "=", "np", ".", "sum", "(", "Xtr", "!=", "0", ",", "axis", "=", "1", ")", "\n", "\n", "# for each user, cut down a test_size% for the test set", "\n", "tst", "=", "np", ".", "around", "(", "(", "rated", "*", "test_cut", ")", "/", "100", ")", ".", "astype", "(", "int", ")", "\n", "\n", "for", "u", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "# For each user obtain the index of rated movies", "\n", "        ", "idx", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "Xtr", "[", "u", "]", "!=", "0", ")", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "\n", "# extract a random subset of size n from the set of rated movies without repetition", "\n", "idx_tst", "=", "np", ".", "random", ".", "choice", "(", "idx", ",", "tst", "[", "u", "]", ",", "replace", "=", "False", ")", "\n", "idx_train", "=", "list", "(", "set", "(", "idx", ")", ".", "difference", "(", "set", "(", "idx_tst", ")", ")", ")", "\n", "\n", "# change the selected rated movies to unrated in the train set", "\n", "Xtr", "[", "u", ",", "idx_tst", "]", "=", "0", "\n", "# set the movies that appear already in the train set as 0", "\n", "Xtst", "[", "u", ",", "idx_train", "]", "=", "0", "\n", "\n", "", "del", "idx", ",", "idx_train", ",", "idx_tst", "\n", "\n", "return", "Xtr", ",", "Xtst", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.__init__": [[43, 73], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sep", ",", "\n", "path", ",", "\n", "has_header", "=", "False", ",", "\n", "item_sep", "=", "None", ",", "\n", "item_path", "=", "None", ",", "\n", "item_has_header", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"MovieLens data format container as a different size of MovieLens data file\n        has a different format\n\n        Args:\n            sep (str): Rating data delimiter\n            path (str): Rating data path within the original zip file\n            has_header (bool): Whether the rating data contains a header line or not\n            item_sep (str): Item data delimiter\n            item_path (str): Item data path within the original zip file\n            item_has_header (bool): Whether the item data contains a header line or not\n        \"\"\"", "\n", "\n", "# Rating file", "\n", "self", ".", "_sep", "=", "sep", "\n", "self", ".", "_path", "=", "path", "\n", "self", ".", "_has_header", "=", "has_header", "\n", "\n", "# Item file", "\n", "self", ".", "_item_sep", "=", "item_sep", "\n", "self", ".", "_item_path", "=", "item_path", "\n", "self", ".", "_item_has_header", "=", "item_has_header", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.separator": [[74, 77], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "separator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sep", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.path": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "path", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.has_header": [[82, 85], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_header", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_has_header", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.item_separator": [[86, 89], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "item_separator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_item_sep", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.item_path": [[90, 93], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "item_path", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_item_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._DataFormat.item_has_header": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "item_has_header", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_item_has_header", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df": [[606, 642], ["cls.to_schema", "random.seed", "schema.remove_columns.remove_columns.example", "schema.remove_columns.remove_columns.remove_columns", "schema.remove_columns.remove_columns.remove_columns", "schema.remove_columns.remove_columns.remove_columns", "pandera.Check.unique_columns", "pandera.Check.unique_columns", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.unique_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.unique_columns"], ["@", "classmethod", "\n", "def", "get_df", "(", "\n", "cls", ",", "\n", "size", ":", "int", "=", "3", ",", "\n", "seed", ":", "int", "=", "100", ",", "\n", "keep_first_n_cols", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "keep_title_col", ":", "bool", "=", "False", ",", "\n", "keep_genre_col", ":", "bool", "=", "False", ",", "\n", ")", "->", "pd", ".", "DataFrame", ":", "\n", "        ", "\"\"\"Return fake movielens dataset as a Pandas Dataframe with specified rows.\n\n        Args:\n            size (int): number of rows to generate\n            seed (int, optional): seeding the pseudo-number generation. Defaults to 100.\n            keep_first_n_cols (int, optional): keep the first n default movielens columns.\n            keep_title_col (bool): remove the title column if False. Defaults to True.\n            keep_genre_col (bool): remove the genre column if False. Defaults to True.\n\n        Returns:\n            pandas.DataFrame: a mock dataset\n        \"\"\"", "\n", "schema", "=", "cls", ".", "to_schema", "(", ")", "\n", "if", "keep_first_n_cols", "is", "not", "None", ":", "\n", "            ", "if", "keep_first_n_cols", "<", "1", "or", "keep_first_n_cols", ">", "len", "(", "DEFAULT_HEADER", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Invalid value for 'keep_first_n_cols': {keep_first_n_cols}. Valid range: [1-{len(DEFAULT_HEADER)}]\"", "\n", ")", "\n", "", "schema", "=", "schema", ".", "remove_columns", "(", "DEFAULT_HEADER", "[", "keep_first_n_cols", ":", "]", ")", "\n", "", "if", "not", "keep_title_col", ":", "\n", "            ", "schema", "=", "schema", ".", "remove_columns", "(", "[", "DEFAULT_TITLE_COL", "]", ")", "\n", "", "if", "not", "keep_genre_col", ":", "\n", "            ", "schema", "=", "schema", ".", "remove_columns", "(", "[", "DEFAULT_GENRE_COL", "]", ")", "\n", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "schema", ".", "checks", "=", "[", "pa", ".", "Check", ".", "unique_columns", "(", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", ")", "]", "\n", "return", "schema", ".", "example", "(", "size", "=", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_spark_df": [[643, 689], ["cls.get_df", "recommenders.datasets.download_utils.download_path", "os.path.join", "cls.get_df.to_csv", "spark.read.csv", "spark_df.drop.drop.cache", "spark_df.drop.drop.count", "spark_df.drop.drop.drop", "spark_df.drop.drop.drop", "cls._get_spark_deserialization_schema"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema._get_spark_deserialization_schema"], ["", "@", "classmethod", "\n", "def", "get_spark_df", "(", "\n", "cls", ",", "\n", "spark", ",", "\n", "size", ":", "int", "=", "3", ",", "\n", "seed", ":", "int", "=", "100", ",", "\n", "keep_title_col", ":", "bool", "=", "False", ",", "\n", "keep_genre_col", ":", "bool", "=", "False", ",", "\n", "tmp_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return fake movielens dataset as a Spark Dataframe with specified rows\n\n        Args:\n            spark (SparkSession): spark session to load the dataframe into\n            size (int): number of rows to generate\n            seed (int): seeding the pseudo-number generation. Defaults to 100.\n            keep_title_col (bool): remove the title column if False. Defaults to False.\n            keep_genre_col (bool): remove the genre column if False. Defaults to False.\n            tmp_path (str, optional): path to store files for serialization purpose\n                when transferring data from python to java.\n                If None, a temporal path is used instead\n\n        Returns:\n            pyspark.sql.DataFrame: a mock dataset\n        \"\"\"", "\n", "pandas_df", "=", "cls", ".", "get_df", "(", "\n", "size", "=", "size", ",", "seed", "=", "seed", ",", "keep_title_col", "=", "True", ",", "keep_genre_col", "=", "True", "\n", ")", "\n", "\n", "# generate temp folder", "\n", "with", "download_path", "(", "tmp_path", ")", "as", "tmp_folder", ":", "\n", "            ", "filepath", "=", "os", ".", "path", ".", "join", "(", "tmp_folder", ",", "f\"mock_movielens_{size}.csv\"", ")", "\n", "# serialize the pandas.df as a csv to avoid the expensive java <-> python communication", "\n", "pandas_df", ".", "to_csv", "(", "filepath", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "spark_df", "=", "spark", ".", "read", ".", "csv", "(", "\n", "filepath", ",", "schema", "=", "cls", ".", "_get_spark_deserialization_schema", "(", ")", "\n", ")", "\n", "# Cache and force trigger action since data-file might be removed.", "\n", "spark_df", ".", "cache", "(", ")", "\n", "spark_df", ".", "count", "(", ")", "\n", "\n", "", "if", "not", "keep_title_col", ":", "\n", "            ", "spark_df", "=", "spark_df", ".", "drop", "(", "DEFAULT_TITLE_COL", ")", "\n", "", "if", "not", "keep_genre_col", ":", "\n", "            ", "spark_df", "=", "spark_df", ".", "drop", "(", "DEFAULT_GENRE_COL", ")", "\n", "", "return", "spark_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema._get_spark_deserialization_schema": [[690, 700], ["StructType", "StructField", "StructField", "StructField", "StructField", "StructField", "StructField", "IntegerType", "IntegerType", "FloatType", "StringType", "StringType", "StringType"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_spark_deserialization_schema", "(", "cls", ")", ":", "\n", "        ", "return", "StructType", "(", "\n", "[", "\n", "StructField", "(", "DEFAULT_USER_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_ITEM_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_RATING_COL", ",", "FloatType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_TIMESTAMP_COL", ",", "StringType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_TITLE_COL", ",", "StringType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_GENRE_COL", ",", "StringType", "(", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_pandas_df": [[152, 252], ["size.lower.lower", "ValueError", "movielens.MockMovielensSchema.get_df", "recommenders.datasets.download_utils.download_path", "os.path.join", "movielens._maybe_download_and_extract", "movielens._load_item_df", "pandas.read_csv", "len", "ValueError", "len", "df[].astype", "df.merge.merge", "len", "warnings.warn", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._maybe_download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._load_item_df"], ["def", "load_pandas_df", "(", "\n", "size", "=", "\"100k\"", ",", "\n", "header", "=", "None", ",", "\n", "local_cache_path", "=", "None", ",", "\n", "title_col", "=", "None", ",", "\n", "genres_col", "=", "None", ",", "\n", "year_col", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads the MovieLens dataset as pd.DataFrame.\n\n    Download the dataset from https://files.grouplens.org/datasets/movielens, unzip, and load.\n    To load movie information only, you can use load_item_df function.\n\n    Args:\n        size (str): Size of the data to load. One of (\"100k\", \"1m\", \"10m\", \"20m\", \"mock100\").\n        header (list or tuple or None): Rating dataset header.\n            If `size` is set to any of 'MOCK_DATA_FORMAT', this parameter is ignored and data is rendered using the 'DEFAULT_HEADER' instead.\n        local_cache_path (str): Path (directory or a zip file) to cache the downloaded zip file.\n            If None, all the intermediate files will be stored in a temporary directory and removed after use.\n            If `size` is set to any of 'MOCK_DATA_FORMAT', this parameter is ignored.\n        title_col (str): Movie title column name. If None, the column will not be loaded.\n        genres_col (str): Genres column name. Genres are '|' separated string.\n            If None, the column will not be loaded.\n        year_col (str): Movie release year column name. If None, the column will not be loaded.\n            If `size` is set to any of 'MOCK_DATA_FORMAT', this parameter is ignored.\n\n    Returns:\n        pandas.DataFrame: Movie rating dataset.\n\n\n    **Examples**\n\n    .. code-block:: python\n\n        # To load just user-id, item-id, and ratings from MovieLens-1M dataset,\n        df = load_pandas_df('1m', ('UserId', 'ItemId', 'Rating'))\n\n        # To load rating's timestamp together,\n        df = load_pandas_df('1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'))\n\n        # To load movie's title, genres, and released year info along with the ratings data,\n        df = load_pandas_df('1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'),\n            title_col='Title',\n            genres_col='Genres',\n            year_col='Year'\n        )\n    \"\"\"", "\n", "size", "=", "size", ".", "lower", "(", ")", "\n", "if", "size", "not", "in", "DATA_FORMAT", "and", "size", "not", "in", "MOCK_DATA_FORMAT", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_MOVIE_LENS_SIZE", ")", "\n", "\n", "", "if", "header", "is", "None", ":", "\n", "        ", "header", "=", "DEFAULT_HEADER", "\n", "", "elif", "len", "(", "header", ")", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_HEADER", ")", "\n", "", "elif", "len", "(", "header", ")", ">", "4", ":", "\n", "        ", "warnings", ".", "warn", "(", "WARNING_MOVIE_LENS_HEADER", ")", "\n", "header", "=", "header", "[", ":", "4", "]", "\n", "\n", "", "if", "size", "in", "MOCK_DATA_FORMAT", ":", "\n", "# generate fake data", "\n", "        ", "return", "MockMovielensSchema", ".", "get_df", "(", "\n", "keep_first_n_cols", "=", "len", "(", "header", ")", ",", "\n", "keep_title_col", "=", "(", "title_col", "is", "not", "None", ")", ",", "\n", "keep_genre_col", "=", "(", "genres_col", "is", "not", "None", ")", ",", "\n", "**", "MOCK_DATA_FORMAT", "[", "\n", "size", "\n", "]", ",", "# supply the rest of the kwarg with the dictionary", "\n", ")", "\n", "\n", "", "movie_col", "=", "header", "[", "1", "]", "\n", "\n", "with", "download_path", "(", "local_cache_path", ")", "as", "path", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"ml-{}.zip\"", ".", "format", "(", "size", ")", ")", "\n", "datapath", ",", "item_datapath", "=", "_maybe_download_and_extract", "(", "size", ",", "filepath", ")", "\n", "\n", "# Load movie features such as title, genres, and release year", "\n", "item_df", "=", "_load_item_df", "(", "\n", "size", ",", "item_datapath", ",", "movie_col", ",", "title_col", ",", "genres_col", ",", "year_col", "\n", ")", "\n", "\n", "# Load rating data", "\n", "df", "=", "pd", ".", "read_csv", "(", "\n", "datapath", ",", "\n", "sep", "=", "DATA_FORMAT", "[", "size", "]", ".", "separator", ",", "\n", "engine", "=", "\"python\"", ",", "\n", "names", "=", "header", ",", "\n", "usecols", "=", "[", "*", "range", "(", "len", "(", "header", ")", ")", "]", ",", "\n", "header", "=", "0", "if", "DATA_FORMAT", "[", "size", "]", ".", "has_header", "else", "None", ",", "\n", ")", "\n", "\n", "# Convert 'rating' type to float", "\n", "if", "len", "(", "header", ")", ">", "2", ":", "\n", "            ", "df", "[", "header", "[", "2", "]", "]", "=", "df", "[", "header", "[", "2", "]", "]", ".", "astype", "(", "float", ")", "\n", "\n", "# Merge rating df w/ item_df", "\n", "", "if", "item_df", "is", "not", "None", ":", "\n", "            ", "df", "=", "df", ".", "merge", "(", "item_df", ",", "on", "=", "header", "[", "1", "]", ")", "\n", "\n", "", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_item_df": [[254, 289], ["size.lower.lower", "ValueError", "recommenders.datasets.download_utils.download_path", "os.path.join", "movielens._maybe_download_and_extract", "movielens._load_item_df"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._maybe_download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._load_item_df"], ["", "def", "load_item_df", "(", "\n", "size", "=", "\"100k\"", ",", "\n", "local_cache_path", "=", "None", ",", "\n", "movie_col", "=", "DEFAULT_ITEM_COL", ",", "\n", "title_col", "=", "None", ",", "\n", "genres_col", "=", "None", ",", "\n", "year_col", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads Movie info.\n\n    Args:\n        size (str): Size of the data to load. One of (\"100k\", \"1m\", \"10m\", \"20m\").\n        local_cache_path (str): Path (directory or a zip file) to cache the downloaded zip file.\n            If None, all the intermediate files will be stored in a temporary directory and removed after use.\n        movie_col (str): Movie id column name.\n        title_col (str): Movie title column name. If None, the column will not be loaded.\n        genres_col (str): Genres column name. Genres are '|' separated string.\n            If None, the column will not be loaded.\n        year_col (str): Movie release year column name. If None, the column will not be loaded.\n\n    Returns:\n        pandas.DataFrame: Movie information data, such as title, genres, and release year.\n    \"\"\"", "\n", "size", "=", "size", ".", "lower", "(", ")", "\n", "if", "size", "not", "in", "DATA_FORMAT", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_MOVIE_LENS_SIZE", ")", "\n", "\n", "", "with", "download_path", "(", "local_cache_path", ")", "as", "path", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"ml-{}.zip\"", ".", "format", "(", "size", ")", ")", "\n", "_", ",", "item_datapath", "=", "_maybe_download_and_extract", "(", "size", ",", "filepath", ")", "\n", "item_df", "=", "_load_item_df", "(", "\n", "size", ",", "item_datapath", ",", "movie_col", ",", "title_col", ",", "genres_col", ",", "year_col", "\n", ")", "\n", "\n", "", "return", "item_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._load_item_df": [[291, 354], ["pandas.read_csv", "item_header.append", "usecols.append", "item_df[].values.tolist", "item_df[].map", "pd.read_csv.drop", "item_df[].map", "pd.read_csv.rename", "item_header.extend", "usecols.extend", "item_header.append", "usecols.append", "re.split", "pd.read_csv.drop", "parsed[].isdecimal", "len", "str", "range", "range", "enumerate"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_load_item_df", "(", "size", ",", "item_datapath", ",", "movie_col", ",", "title_col", ",", "genres_col", ",", "year_col", ")", ":", "\n", "    ", "\"\"\"Loads Movie info\"\"\"", "\n", "if", "title_col", "is", "None", "and", "genres_col", "is", "None", "and", "year_col", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "item_header", "=", "[", "movie_col", "]", "\n", "usecols", "=", "[", "0", "]", "\n", "\n", "# Year is parsed from title", "\n", "if", "title_col", "is", "not", "None", "or", "year_col", "is", "not", "None", ":", "\n", "        ", "item_header", ".", "append", "(", "\"title_year\"", ")", "\n", "usecols", ".", "append", "(", "1", ")", "\n", "\n", "", "genres_header_100k", "=", "None", "\n", "if", "genres_col", "is", "not", "None", ":", "\n", "# 100k data's movie genres are encoded as a binary array (the last 19 fields)", "\n", "# For details, see https://files.grouplens.org/datasets/movielens/ml-100k-README.txt", "\n", "        ", "if", "size", "==", "\"100k\"", ":", "\n", "            ", "genres_header_100k", "=", "[", "*", "(", "str", "(", "i", ")", "for", "i", "in", "range", "(", "19", ")", ")", "]", "\n", "item_header", ".", "extend", "(", "genres_header_100k", ")", "\n", "usecols", ".", "extend", "(", "[", "*", "range", "(", "5", ",", "24", ")", "]", ")", "# genres columns", "\n", "", "else", ":", "\n", "            ", "item_header", ".", "append", "(", "genres_col", ")", "\n", "usecols", ".", "append", "(", "2", ")", "# genres column", "\n", "\n", "", "", "item_df", "=", "pd", ".", "read_csv", "(", "\n", "item_datapath", ",", "\n", "sep", "=", "DATA_FORMAT", "[", "size", "]", ".", "item_separator", ",", "\n", "engine", "=", "\"python\"", ",", "\n", "names", "=", "item_header", ",", "\n", "usecols", "=", "usecols", ",", "\n", "header", "=", "0", "if", "DATA_FORMAT", "[", "size", "]", ".", "item_has_header", "else", "None", ",", "\n", "encoding", "=", "\"ISO-8859-1\"", ",", "\n", ")", "\n", "\n", "# Convert 100k data's format: '0|0|1|...' to 'Action|Romance|...\"", "\n", "if", "genres_header_100k", "is", "not", "None", ":", "\n", "        ", "item_df", "[", "genres_col", "]", "=", "item_df", "[", "genres_header_100k", "]", ".", "values", ".", "tolist", "(", ")", "\n", "item_df", "[", "genres_col", "]", "=", "item_df", "[", "genres_col", "]", ".", "map", "(", "\n", "lambda", "l", ":", "\"|\"", ".", "join", "(", "[", "GENRES", "[", "i", "]", "for", "i", ",", "v", "in", "enumerate", "(", "l", ")", "if", "v", "==", "1", "]", ")", "\n", ")", "\n", "\n", "item_df", ".", "drop", "(", "genres_header_100k", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "# Parse year from movie title. Note, MovieLens title format is \"title (year)\"", "\n", "# Note, there are very few records that are missing the year info.", "\n", "", "if", "year_col", "is", "not", "None", ":", "\n", "\n", "        ", "def", "parse_year", "(", "t", ")", ":", "\n", "            ", "parsed", "=", "re", ".", "split", "(", "\"[()]\"", ",", "t", ")", "\n", "if", "len", "(", "parsed", ")", ">", "2", "and", "parsed", "[", "-", "2", "]", ".", "isdecimal", "(", ")", ":", "\n", "                ", "return", "parsed", "[", "-", "2", "]", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "item_df", "[", "year_col", "]", "=", "item_df", "[", "\"title_year\"", "]", ".", "map", "(", "parse_year", ")", "\n", "if", "title_col", "is", "None", ":", "\n", "            ", "item_df", ".", "drop", "(", "\"title_year\"", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "", "", "if", "title_col", "is", "not", "None", ":", "\n", "        ", "item_df", ".", "rename", "(", "columns", "=", "{", "\"title_year\"", ":", "title_col", "}", ",", "inplace", "=", "True", ")", "\n", "\n", "", "return", "item_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df": [[356, 495], ["size.lower.lower", "movielens._get_schema", "ValueError", "movielens.MockMovielensSchema.get_spark_df", "len", "ValueError", "recommenders.datasets.download_utils.download_path", "os.path.join", "movielens._maybe_download_and_extract", "movielens._load_item_df", "recommenders.utils.notebook_utils.is_databricks", "df.join.cache", "df.join.count", "spark.createDataFrame", "dbutils.fs.mv", "len", "spark.sparkContext.textFile", "spark.sparkContext.textFile.map().map", "spark.createDataFrame", "spark.read.csv", "df.join.join", "ValueError", "spark.sparkContext.textFile.map", "l.split", "int", "int", "float", "int", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._get_schema", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_spark_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._maybe_download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._load_item_df", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.notebook_utils.is_databricks", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_spark_df", "(", "\n", "spark", ",", "\n", "size", "=", "\"100k\"", ",", "\n", "header", "=", "None", ",", "\n", "schema", "=", "None", ",", "\n", "local_cache_path", "=", "None", ",", "\n", "dbutils", "=", "None", ",", "\n", "title_col", "=", "None", ",", "\n", "genres_col", "=", "None", ",", "\n", "year_col", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads the MovieLens dataset as `pyspark.sql.DataFrame`.\n\n    Download the dataset from https://files.grouplens.org/datasets/movielens, unzip, and load as `pyspark.sql.DataFrame`.\n\n    To load movie information only, you can use `load_item_df` function.\n\n    Args:\n        spark (pyspark.SparkSession): Spark session.\n        size (str): Size of the data to load. One of (\"100k\", \"1m\", \"10m\", \"20m\", \"mock100\").\n        header (list or tuple): Rating dataset header.\n            If `schema` is provided or `size` is set to any of 'MOCK_DATA_FORMAT', this argument is ignored.\n        schema (pyspark.StructType): Dataset schema.\n            If `size` is set to any of 'MOCK_DATA_FORMAT', data is rendered in the 'MockMovielensSchema' instead.\n        local_cache_path (str): Path (directory or a zip file) to cache the downloaded zip file.\n            If None, all the intermediate files will be stored in a temporary directory and removed after use.\n        dbutils (Databricks.dbutils): Databricks utility object\n            If `size` is set to any of 'MOCK_DATA_FORMAT', this parameter is ignored.\n        title_col (str): Title column name. If None, the column will not be loaded.\n        genres_col (str): Genres column name. Genres are '|' separated string.\n            If None, the column will not be loaded.\n        year_col (str): Movie release year column name. If None, the column will not be loaded.\n            If `size` is set to any of 'MOCK_DATA_FORMAT', this parameter is ignored.\n\n    Returns:\n        pyspark.sql.DataFrame: Movie rating dataset.\n\n    **Examples**\n\n    .. code-block:: python\n\n        # To load just user-id, item-id, and ratings from MovieLens-1M dataset:\n        spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating'))\n\n        # The schema can be defined as well:\n        schema = StructType([\n            StructField(DEFAULT_USER_COL, IntegerType()),\n            StructField(DEFAULT_ITEM_COL, IntegerType()),\n            StructField(DEFAULT_RATING_COL, FloatType()),\n            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n            ])\n        spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating'), schema=schema)\n\n        # To load rating's timestamp together:\n        spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'))\n\n        # To load movie's title, genres, and released year info along with the ratings data:\n        spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'),\n            title_col='Title',\n            genres_col='Genres',\n            year_col='Year'\n        )\n\n        # On DataBricks, pass the dbutils argument as follows:\n        spark_df = load_spark_df(spark, dbutils=dbutils)\n    \"\"\"", "\n", "size", "=", "size", ".", "lower", "(", ")", "\n", "if", "size", "not", "in", "DATA_FORMAT", "and", "size", "not", "in", "MOCK_DATA_FORMAT", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_MOVIE_LENS_SIZE", ")", "\n", "\n", "", "if", "size", "in", "MOCK_DATA_FORMAT", ":", "\n", "# generate fake data", "\n", "        ", "return", "MockMovielensSchema", ".", "get_spark_df", "(", "\n", "spark", ",", "\n", "keep_title_col", "=", "(", "title_col", "is", "not", "None", ")", ",", "\n", "keep_genre_col", "=", "(", "genres_col", "is", "not", "None", ")", ",", "\n", "**", "MOCK_DATA_FORMAT", "[", "\n", "size", "\n", "]", ",", "# supply the rest of the kwarg with the dictionary", "\n", ")", "\n", "\n", "", "schema", "=", "_get_schema", "(", "header", ",", "schema", ")", "\n", "if", "len", "(", "schema", ")", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_HEADER", ")", "\n", "\n", "", "movie_col", "=", "schema", "[", "1", "]", ".", "name", "\n", "\n", "with", "download_path", "(", "local_cache_path", ")", "as", "path", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"ml-{}.zip\"", ".", "format", "(", "size", ")", ")", "\n", "datapath", ",", "item_datapath", "=", "_maybe_download_and_extract", "(", "size", ",", "filepath", ")", "\n", "spark_datapath", "=", "\"file:///\"", "+", "datapath", "# shorten form of file://localhost/", "\n", "\n", "# Load movie features such as title, genres, and release year.", "\n", "# Since the file size is small, we directly load as pd.DataFrame from the driver node", "\n", "# and then convert into pyspark.sql.DataFrame", "\n", "item_pd_df", "=", "_load_item_df", "(", "\n", "size", ",", "item_datapath", ",", "movie_col", ",", "title_col", ",", "genres_col", ",", "year_col", "\n", ")", "\n", "item_df", "=", "spark", ".", "createDataFrame", "(", "item_pd_df", ")", "if", "item_pd_df", "is", "not", "None", "else", "None", "\n", "\n", "if", "is_databricks", "(", ")", ":", "\n", "            ", "if", "dbutils", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"\"\"\n                    To use on a Databricks, dbutils object should be passed as an argument.\n                    E.g. load_spark_df(spark, dbutils=dbutils)\n                \"\"\"", "\n", ")", "\n", "\n", "# Move rating file to DBFS in order to load into pyspark.sql.DataFrame", "\n", "", "dbfs_datapath", "=", "\"dbfs:/tmp/\"", "+", "datapath", "\n", "dbutils", ".", "fs", ".", "mv", "(", "spark_datapath", ",", "dbfs_datapath", ")", "\n", "spark_datapath", "=", "dbfs_datapath", "\n", "\n", "# pyspark's read csv currently doesn't support multi-character delimiter, thus we manually handle that", "\n", "", "separator", "=", "DATA_FORMAT", "[", "size", "]", ".", "separator", "\n", "if", "len", "(", "separator", ")", ">", "1", ":", "\n", "            ", "raw_data", "=", "spark", ".", "sparkContext", ".", "textFile", "(", "spark_datapath", ")", "\n", "data_rdd", "=", "raw_data", ".", "map", "(", "lambda", "l", ":", "l", ".", "split", "(", "separator", ")", ")", ".", "map", "(", "\n", "lambda", "c", ":", "[", "int", "(", "c", "[", "0", "]", ")", ",", "int", "(", "c", "[", "1", "]", ")", ",", "float", "(", "c", "[", "2", "]", ")", ",", "int", "(", "c", "[", "3", "]", ")", "]", "[", ":", "len", "(", "schema", ")", "]", "\n", ")", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "data_rdd", ",", "schema", ")", "\n", "", "else", ":", "\n", "            ", "df", "=", "spark", ".", "read", ".", "csv", "(", "\n", "spark_datapath", ",", "\n", "schema", "=", "schema", ",", "\n", "sep", "=", "separator", ",", "\n", "header", "=", "DATA_FORMAT", "[", "size", "]", ".", "has_header", ",", "\n", ")", "\n", "\n", "# Merge rating df w/ item_df", "\n", "", "if", "item_df", "is", "not", "None", ":", "\n", "            ", "df", "=", "df", ".", "join", "(", "item_df", ",", "movie_col", ",", "\"left\"", ")", "\n", "\n", "# Cache and force trigger action since data-file might be removed.", "\n", "", "df", ".", "cache", "(", ")", "\n", "df", ".", "count", "(", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._get_schema": [[497, 525], ["StructType", "len", "StructType.add().add().add().add", "warnings.warn", "len", "warnings.warn", "len", "len", "warnings.warn", "StructField", "StructType.add().add().add", "LongType", "StructField", "StructType.add().add", "FloatType", "StructField", "StructType.add", "IntegerType", "StructField", "IntegerType"], "function", ["None"], ["", "def", "_get_schema", "(", "header", ",", "schema", ")", ":", "\n", "    ", "if", "schema", "is", "None", "or", "len", "(", "schema", ")", "==", "0", ":", "\n", "# Use header to generate schema", "\n", "        ", "if", "header", "is", "None", "or", "len", "(", "header", ")", "==", "0", ":", "\n", "            ", "header", "=", "DEFAULT_HEADER", "\n", "", "elif", "len", "(", "header", ")", ">", "4", ":", "\n", "            ", "warnings", ".", "warn", "(", "WARNING_MOVIE_LENS_HEADER", ")", "\n", "header", "=", "header", "[", ":", "4", "]", "\n", "\n", "", "schema", "=", "StructType", "(", ")", "\n", "try", ":", "\n", "            ", "(", "\n", "schema", ".", "add", "(", "StructField", "(", "header", "[", "0", "]", ",", "IntegerType", "(", ")", ")", ")", "\n", ".", "add", "(", "StructField", "(", "header", "[", "1", "]", ",", "IntegerType", "(", ")", ")", ")", "\n", ".", "add", "(", "StructField", "(", "header", "[", "2", "]", ",", "FloatType", "(", ")", ")", ")", "\n", ".", "add", "(", "StructField", "(", "header", "[", "3", "]", ",", "LongType", "(", ")", ")", ")", "\n", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "pass", "\n", "", "", "else", ":", "\n", "        ", "if", "header", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "WARNING_HAVE_SCHEMA_AND_HEADER", ")", "\n", "\n", "", "if", "len", "(", "schema", ")", ">", "4", ":", "\n", "            ", "warnings", ".", "warn", "(", "WARNING_MOVIE_LENS_HEADER", ")", "\n", "schema", "=", "schema", "[", ":", "4", "]", "\n", "\n", "", "", "return", "schema", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens._maybe_download_and_extract": [[527, 543], ["os.path.split", "os.path.split", "os.path.join", "os.path.split", "os.path.join", "os.path.exists", "os.makedirs", "movielens.download_movielens", "movielens.extract_movielens", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.download_movielens", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.extract_movielens"], ["", "def", "_maybe_download_and_extract", "(", "size", ",", "dest_path", ")", ":", "\n", "    ", "\"\"\"Downloads and extracts MovieLens rating and item datafiles if they don\u2019t already exist\"\"\"", "\n", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "dest_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirs", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirs", ")", "\n", "\n", "", "_", ",", "rating_filename", "=", "os", ".", "path", ".", "split", "(", "DATA_FORMAT", "[", "size", "]", ".", "path", ")", "\n", "rating_path", "=", "os", ".", "path", ".", "join", "(", "dirs", ",", "rating_filename", ")", "\n", "_", ",", "item_filename", "=", "os", ".", "path", ".", "split", "(", "DATA_FORMAT", "[", "size", "]", ".", "item_path", ")", "\n", "item_path", "=", "os", ".", "path", ".", "join", "(", "dirs", ",", "item_filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "rating_path", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "item_path", ")", ":", "\n", "        ", "download_movielens", "(", "size", ",", "dest_path", ")", "\n", "extract_movielens", "(", "size", ",", "rating_path", ",", "item_path", ",", "dest_path", ")", "\n", "\n", "", "return", "rating_path", ",", "item_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.download_movielens": [[545, 558], ["os.path.split", "recommenders.datasets.download_utils.maybe_download", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "def", "download_movielens", "(", "size", ",", "dest_path", ")", ":", "\n", "    ", "\"\"\"Downloads MovieLens datafile.\n\n    Args:\n        size (str): Size of the data to load. One of (\"100k\", \"1m\", \"10m\", \"20m\").\n        dest_path (str): File path for the downloaded file\n    \"\"\"", "\n", "if", "size", "not", "in", "DATA_FORMAT", ":", "\n", "        ", "raise", "ValueError", "(", "ERROR_MOVIE_LENS_SIZE", ")", "\n", "\n", "", "url", "=", "\"https://files.grouplens.org/datasets/movielens/ml-\"", "+", "size", "+", "\".zip\"", "\n", "dirs", ",", "file", "=", "os", ".", "path", ".", "split", "(", "dest_path", ")", "\n", "maybe_download", "(", "url", ",", "file", ",", "work_directory", "=", "dirs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.extract_movielens": [[560, 577], ["zipfile.ZipFile", "z.open", "open", "shutil.copyfileobj", "z.open", "open", "shutil.copyfileobj"], "function", ["None"], ["", "def", "extract_movielens", "(", "size", ",", "rating_path", ",", "item_path", ",", "zip_path", ")", ":", "\n", "    ", "\"\"\"Extract MovieLens rating and item datafiles from the MovieLens raw zip file.\n\n    To extract all files instead of just rating and item datafiles,\n    use ZipFile's extractall(path) instead.\n\n    Args:\n        size (str): Size of the data to load. One of (\"100k\", \"1m\", \"10m\", \"20m\").\n        rating_path (str): Destination path for rating datafile\n        item_path (str): Destination path for item datafile\n        zip_path (str): zipfile path\n    \"\"\"", "\n", "with", "ZipFile", "(", "zip_path", ",", "\"r\"", ")", "as", "z", ":", "\n", "        ", "with", "z", ".", "open", "(", "DATA_FORMAT", "[", "size", "]", ".", "path", ")", "as", "zf", ",", "open", "(", "rating_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "shutil", ".", "copyfileobj", "(", "zf", ",", "f", ")", "\n", "", "with", "z", ".", "open", "(", "DATA_FORMAT", "[", "size", "]", ".", "item_path", ")", "as", "zf", ",", "open", "(", "item_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "shutil", ".", "copyfileobj", "(", "zf", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.unique_columns": [[580, 583], ["pandera.register_check_method", "df[].duplicated().any", "df[].duplicated"], "function", ["None"], ["", "", "", "@", "extensions", ".", "register_check_method", "(", "statistics", "=", "[", "\"columns\"", "]", ",", "supported_types", "=", "pd", ".", "DataFrame", ")", "\n", "def", "unique_columns", "(", "df", ",", "*", ",", "columns", ")", ":", "\n", "    ", "return", "not", "df", "[", "columns", "]", ".", "duplicated", "(", ")", ".", "any", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.__init__": [[26, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "df", ",", "\n", "items_list", "=", "None", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_pred", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "save_path", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize class parameters\n\n        Args:\n            df (pandas.DataFrame): a dataframe containing the data\n            items_list (numpy.ndarray): a list of unique items to use (if provided)\n            col_user (str): default name for user column\n            col_item (str): default name for item column\n            col_rating (str): default name for rating columns\n            save_path (str): default path to save item/user maps\n        \"\"\"", "\n", "self", ".", "df", "=", "df", "# dataframe", "\n", "self", ".", "items_list", "=", "items_list", "# list of unique items", "\n", "\n", "# pandas DF parameters", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_pred", "=", "col_pred", "\n", "\n", "# Options to save the model for future use", "\n", "self", ".", "save_path", "=", "save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix._gen_index": [[58, 108], ["sparse.AffinityMatrix.df.sort_values", "sparse.AffinityMatrix.df_[].unique", "len", "len", "sparse.AffinityMatrix.df_[].map", "sparse.AffinityMatrix.df_[].map", "sparse.AffinityMatrix.df_[].unique", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "def", "_gen_index", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate the user/item index:\n        map_users, map_items: dictionaries mapping the original user/item index to matrix indices\n        map_back_users, map_back_items: dictionaries to map back the matrix elements to the original\n        dataframe indices\n\n        Basic mechanics:\n        As a first step we retieve the unique elements in the dataset. In this way we can take care\n        of either completely missing rows (a user with no ratings) or completely missing columns\n        (an item that has not being reviewed by anyone). The original indices in the dataframe are\n        then mapped to an ordered, contiguous integer series to generate a compact matrix representation.\n        Functions to map back to the original indices are also provided and can be saved in order to use\n        a pretrained model.\n        \"\"\"", "\n", "# sort entries by user index", "\n", "self", ".", "df_", "=", "self", ".", "df", ".", "sort_values", "(", "by", "=", "[", "self", ".", "col_user", "]", ")", "\n", "\n", "# find unique user and item index", "\n", "unique_users", "=", "self", ".", "df_", "[", "self", ".", "col_user", "]", ".", "unique", "(", ")", "\n", "\n", "if", "self", ".", "items_list", "is", "not", "None", ":", "\n", "            ", "unique_items", "=", "self", ".", "items_list", "# use this list if provided", "\n", "", "else", ":", "\n", "            ", "unique_items", "=", "self", ".", "df_", "[", "\n", "self", ".", "col_item", "\n", "]", ".", "unique", "(", ")", "# otherwise use unique items from DF", "\n", "\n", "", "self", ".", "Nusers", "=", "len", "(", "unique_users", ")", "\n", "self", ".", "Nitems", "=", "len", "(", "unique_items", ")", "\n", "\n", "# create a dictionary to map unique users/items to hashed values to generate the matrix", "\n", "self", ".", "map_users", "=", "{", "x", ":", "i", "for", "i", ",", "x", "in", "enumerate", "(", "unique_users", ")", "}", "\n", "self", ".", "map_items", "=", "{", "x", ":", "i", "for", "i", ",", "x", "in", "enumerate", "(", "unique_items", ")", "}", "\n", "\n", "# map back functions used to get back the original dataframe", "\n", "self", ".", "map_back_users", "=", "{", "i", ":", "x", "for", "i", ",", "x", "in", "enumerate", "(", "unique_users", ")", "}", "\n", "self", ".", "map_back_items", "=", "{", "i", ":", "x", "for", "i", ",", "x", "in", "enumerate", "(", "unique_items", ")", "}", "\n", "\n", "self", ".", "df_", ".", "loc", "[", ":", ",", "\"hashedItems\"", "]", "=", "self", ".", "df_", "[", "self", ".", "col_item", "]", ".", "map", "(", "self", ".", "map_items", ")", "\n", "self", ".", "df_", ".", "loc", "[", ":", ",", "\"hashedUsers\"", "]", "=", "self", ".", "df_", "[", "self", ".", "col_user", "]", ".", "map", "(", "self", ".", "map_users", ")", "\n", "\n", "# optionally save the inverse dictionary to work with trained models", "\n", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "\n", "            ", "np", ".", "save", "(", "self", ".", "save_path", "+", "\"/user_dict\"", ",", "self", ".", "map_users", ")", "\n", "np", ".", "save", "(", "self", ".", "save_path", "+", "\"/item_dict\"", ",", "self", ".", "map_items", ")", "\n", "\n", "np", ".", "save", "(", "self", ".", "save_path", "+", "\"/user_back_dict\"", ",", "self", ".", "map_back_users", ")", "\n", "np", ".", "save", "(", "self", ".", "save_path", "+", "\"/item_back_dict\"", ",", "self", ".", "map_back_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.gen_affinity_matrix": [[109, 144], ["log.info", "sparse.AffinityMatrix._gen_index", "scipy.sparse.coo_matrix().toarray", "log.info", "scipy.sparse.coo_matrix"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix._gen_index"], ["", "", "def", "gen_affinity_matrix", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate the user/item affinity matrix.\n\n        As a first step, two new columns are added to the input DF, containing the index maps\n        generated by the gen_index() method. The new indices, together with the ratings, are\n        then used to generate the user/item affinity matrix using scipy's sparse matrix method\n        coo_matrix; for reference see:\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html.\n        The input format is: `coo_matrix((data, (rows, columns)), shape=(rows, columns))`\n\n        Returns:\n            scipy.sparse.coo_matrix: User-affinity matrix of dimensions (Nusers, Nitems) in numpy format.\n            Unrated movies are assigned a value of 0.\n        \"\"\"", "\n", "\n", "log", ".", "info", "(", "\"Generating the user/item affinity matrix...\"", ")", "\n", "\n", "self", ".", "_gen_index", "(", ")", "\n", "\n", "ratings", "=", "self", ".", "df_", "[", "self", ".", "col_rating", "]", "# ratings", "\n", "itm_id", "=", "self", ".", "df_", "[", "\"hashedItems\"", "]", "# itm_id serving as columns", "\n", "usr_id", "=", "self", ".", "df_", "[", "\"hashedUsers\"", "]", "# usr_id serving as rows", "\n", "\n", "# generate a sparse matrix representation using scipy's coo_matrix and convert to array format", "\n", "self", ".", "AM", "=", "coo_matrix", "(", "\n", "(", "ratings", ",", "(", "usr_id", ",", "itm_id", ")", ")", ",", "shape", "=", "(", "self", ".", "Nusers", ",", "self", ".", "Nitems", ")", "\n", ")", ".", "toarray", "(", ")", "\n", "\n", "zero", "=", "(", "self", ".", "AM", "==", "0", ")", ".", "sum", "(", ")", "# number of unrated items", "\n", "total", "=", "self", ".", "AM", ".", "shape", "[", "0", "]", "*", "self", ".", "AM", ".", "shape", "[", "1", "]", "# number of elements in the matrix", "\n", "sparsness", "=", "zero", "/", "total", "*", "100", "# Percentage of zeros in the matrix", "\n", "\n", "log", ".", "info", "(", "\"Matrix generated, sparseness percentage: %d\"", "%", "sparsness", ")", "\n", "\n", "return", "self", ".", "AM", ",", "self", ".", "map_users", ",", "self", ".", "map_items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse": [[145, 186], ["range", "list", "list", "pandas.DataFrame.from_dict", "out_df[].map", "out_df[].map", "numpy.asanyarray().flatten", "userids.extend", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "range", "range", "numpy.asanyarray", "len", "numpy.where"], "methods", ["None"], ["", "def", "map_back_sparse", "(", "self", ",", "X", ",", "kind", ")", ":", "\n", "        ", "\"\"\"Map back the user/affinity matrix to a pd dataframe\n\n        Args:\n            X (numpy.ndarray, int32): user/item affinity matrix\n            kind (string): specify if the output values are ratings or predictions\n        Returns:\n            pandas.DataFrame: the generated pandas dataframe\n        \"\"\"", "\n", "m", ",", "n", "=", "X", ".", "shape", "\n", "\n", "# 1) Create a DF from a sparse matrix", "\n", "# obtain the non zero items", "\n", "items", "=", "[", "np", ".", "asanyarray", "(", "np", ".", "where", "(", "X", "[", "i", ",", ":", "]", "!=", "0", ")", ")", ".", "flatten", "(", ")", "for", "i", "in", "range", "(", "m", ")", "]", "\n", "ratings", "=", "[", "X", "[", "i", ",", "items", "[", "i", "]", "]", "for", "i", "in", "range", "(", "m", ")", "]", "# obtain the non-zero ratings", "\n", "\n", "# Creates user ids following the DF format", "\n", "userids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "m", ")", ":", "\n", "            ", "userids", ".", "extend", "(", "[", "i", "]", "*", "len", "(", "items", "[", "i", "]", ")", ")", "\n", "\n", "# Flatten the lists to follow the DF input format", "\n", "", "items", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "items", ")", ")", "\n", "ratings", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "ratings", ")", ")", "\n", "\n", "if", "kind", "==", "\"ratings\"", ":", "\n", "            ", "col_out", "=", "self", ".", "col_rating", "\n", "", "else", ":", "\n", "            ", "col_out", "=", "self", ".", "col_pred", "\n", "\n", "# create a df", "\n", "", "out_df", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "\n", "{", "self", ".", "col_user", ":", "userids", ",", "self", ".", "col_item", ":", "items", ",", "col_out", ":", "ratings", "}", "\n", ")", "\n", "\n", "# 2) map back user/item ids to their original value", "\n", "\n", "out_df", "[", "self", ".", "col_user", "]", "=", "out_df", "[", "self", ".", "col_user", "]", ".", "map", "(", "self", ".", "map_back_users", ")", "\n", "out_df", "[", "self", ".", "col_item", "]", "=", "out_df", "[", "self", ".", "col_item", "]", ".", "map", "(", "self", ".", "map_back_items", ")", "\n", "\n", "return", "out_df", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.get_review_data": [[20, 31], ["amazon_reviews.download_and_extract", "amazon_reviews._reviews_preprocessing", "reviews_file.split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._reviews_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["def", "get_review_data", "(", "reviews_file", ")", ":", "\n", "    ", "\"\"\"Downloads amazon review data (only), prepares in the required format\n    and stores in the same location\n\n    Args:\n        reviews_file (str): Filename for downloaded reviews dataset.\n    \"\"\"", "\n", "reviews_name", "=", "reviews_file", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# *.json (for url)", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "reviews_output", "=", "_reviews_preprocessing", "(", "reviews_file", ")", "\n", "return", "reviews_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.data_preprocessing": [[33, 68], ["amazon_reviews._reviews_preprocessing", "amazon_reviews._meta_preprocessing", "amazon_reviews._create_instance", "amazon_reviews._create_item2cate", "amazon_reviews._get_sampled_data", "amazon_reviews._data_processing", "amazon_reviews._create_vocab", "amazon_reviews._negative_sampling_offline", "amazon_reviews._data_generating", "amazon_reviews._data_generating_no_history_expanding"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._reviews_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._meta_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_instance", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_item2cate", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._get_sampled_data", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._data_processing", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_vocab", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._negative_sampling_offline", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._data_generating", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._data_generating_no_history_expanding"], ["", "def", "data_preprocessing", "(", "\n", "reviews_file", ",", "\n", "meta_file", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "sample_rate", "=", "0.01", ",", "\n", "valid_num_ngs", "=", "4", ",", "\n", "test_num_ngs", "=", "9", ",", "\n", "is_history_expanding", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Create data for training, validation and testing from original dataset\n\n    Args:\n        reviews_file (str): Reviews dataset downloaded from former operations.\n        meta_file (str): Meta dataset downloaded from former operations.\n    \"\"\"", "\n", "reviews_output", "=", "_reviews_preprocessing", "(", "reviews_file", ")", "\n", "meta_output", "=", "_meta_preprocessing", "(", "meta_file", ")", "\n", "instance_output", "=", "_create_instance", "(", "reviews_output", ",", "meta_output", ")", "\n", "_create_item2cate", "(", "instance_output", ")", "\n", "sampled_instance_file", "=", "_get_sampled_data", "(", "instance_output", ",", "sample_rate", "=", "sample_rate", ")", "\n", "preprocessed_output", "=", "_data_processing", "(", "sampled_instance_file", ")", "\n", "if", "is_history_expanding", ":", "\n", "        ", "_data_generating", "(", "preprocessed_output", ",", "train_file", ",", "valid_file", ",", "test_file", ")", "\n", "", "else", ":", "\n", "        ", "_data_generating_no_history_expanding", "(", "\n", "preprocessed_output", ",", "train_file", ",", "valid_file", ",", "test_file", "\n", ")", "\n", "", "_create_vocab", "(", "train_file", ",", "user_vocab", ",", "item_vocab", ",", "cate_vocab", ")", "\n", "_negative_sampling_offline", "(", "\n", "sampled_instance_file", ",", "valid_file", ",", "test_file", ",", "valid_num_ngs", ",", "test_num_ngs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_vocab": [[71, 135], ["open", "logger.info", "sorted", "sorted", "sorted", "_pickle.dump", "_pickle.dump", "_pickle.dump", "line.strip().split", "mid_list.split", "cat_list.split", "user_dict.items", "item_dict.items", "cat_dict.items", "open", "open", "open", "len", "line.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "_create_vocab", "(", "train_file", ",", "user_vocab", ",", "item_vocab", ",", "cate_vocab", ")", ":", "\n", "\n", "    ", "f_train", "=", "open", "(", "train_file", ",", "\"r\"", ")", "\n", "\n", "user_dict", "=", "{", "}", "\n", "item_dict", "=", "{", "}", "\n", "cat_dict", "=", "{", "}", "\n", "\n", "logger", ".", "info", "(", "\"vocab generating...\"", ")", "\n", "for", "line", "in", "f_train", ":", "\n", "        ", "arr", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "uid", "=", "arr", "[", "1", "]", "\n", "mid", "=", "arr", "[", "2", "]", "\n", "cat", "=", "arr", "[", "3", "]", "\n", "mid_list", "=", "arr", "[", "5", "]", "\n", "cat_list", "=", "arr", "[", "6", "]", "\n", "\n", "if", "uid", "not", "in", "user_dict", ":", "\n", "            ", "user_dict", "[", "uid", "]", "=", "0", "\n", "", "user_dict", "[", "uid", "]", "+=", "1", "\n", "if", "mid", "not", "in", "item_dict", ":", "\n", "            ", "item_dict", "[", "mid", "]", "=", "0", "\n", "", "item_dict", "[", "mid", "]", "+=", "1", "\n", "if", "cat", "not", "in", "cat_dict", ":", "\n", "            ", "cat_dict", "[", "cat", "]", "=", "0", "\n", "", "cat_dict", "[", "cat", "]", "+=", "1", "\n", "if", "len", "(", "mid_list", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "for", "m", "in", "mid_list", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "if", "m", "not", "in", "item_dict", ":", "\n", "                ", "item_dict", "[", "m", "]", "=", "0", "\n", "", "item_dict", "[", "m", "]", "+=", "1", "\n", "", "for", "c", "in", "cat_list", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "if", "c", "not", "in", "cat_dict", ":", "\n", "                ", "cat_dict", "[", "c", "]", "=", "0", "\n", "", "cat_dict", "[", "c", "]", "+=", "1", "\n", "\n", "", "", "sorted_user_dict", "=", "sorted", "(", "user_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "sorted_item_dict", "=", "sorted", "(", "item_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "sorted_cat_dict", "=", "sorted", "(", "cat_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "uid_voc", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "key", ",", "value", "in", "sorted_user_dict", ":", "\n", "        ", "uid_voc", "[", "key", "]", "=", "index", "\n", "index", "+=", "1", "\n", "\n", "", "mid_voc", "=", "{", "}", "\n", "mid_voc", "[", "\"default_mid\"", "]", "=", "0", "\n", "index", "=", "1", "\n", "for", "key", ",", "value", "in", "sorted_item_dict", ":", "\n", "        ", "mid_voc", "[", "key", "]", "=", "index", "\n", "index", "+=", "1", "\n", "\n", "", "cat_voc", "=", "{", "}", "\n", "cat_voc", "[", "\"default_cat\"", "]", "=", "0", "\n", "index", "=", "1", "\n", "for", "key", ",", "value", "in", "sorted_cat_dict", ":", "\n", "        ", "cat_voc", "[", "key", "]", "=", "index", "\n", "index", "+=", "1", "\n", "\n", "", "cPickle", ".", "dump", "(", "uid_voc", ",", "open", "(", "user_vocab", ",", "\"wb\"", ")", ")", "\n", "cPickle", ".", "dump", "(", "mid_voc", ",", "open", "(", "item_vocab", ",", "\"wb\"", ")", ")", "\n", "cPickle", ".", "dump", "(", "cat_voc", ",", "open", "(", "cate_vocab", ",", "\"wb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._negative_sampling_offline": [[137, 190], ["pandas.read_csv", "list", "logger.info", "open", "logger.info", "open", "open", "f.readlines", "open.write", "line.strip().split", "set", "open", "f.readlines", "open.write", "line.strip().split", "set", "random.choice", "set.add", "open.write", "random.choice", "set.add", "open.write", "line.strip", "line.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_negative_sampling_offline", "(", "\n", "instance_input_file", ",", "valid_file", ",", "test_file", ",", "valid_neg_nums", "=", "4", ",", "test_neg_nums", "=", "49", "\n", ")", ":", "\n", "\n", "    ", "columns", "=", "[", "\"label\"", ",", "\"user_id\"", ",", "\"item_id\"", ",", "\"timestamp\"", ",", "\"cate_id\"", "]", "\n", "ns_df", "=", "pd", ".", "read_csv", "(", "instance_input_file", ",", "sep", "=", "\"\\t\"", ",", "names", "=", "columns", ")", "\n", "items_with_popular", "=", "list", "(", "ns_df", "[", "\"item_id\"", "]", ")", "\n", "\n", "global", "item2cate", "\n", "\n", "# valid negative sampling", "\n", "logger", ".", "info", "(", "\"start valid negative sampling\"", ")", "\n", "with", "open", "(", "valid_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "valid_lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "write_valid", "=", "open", "(", "valid_file", ",", "\"w\"", ")", "\n", "for", "line", "in", "valid_lines", ":", "\n", "        ", "write_valid", ".", "write", "(", "line", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "positive_item", "=", "words", "[", "2", "]", "\n", "count", "=", "0", "\n", "neg_items", "=", "set", "(", ")", "\n", "while", "count", "<", "valid_neg_nums", ":", "\n", "            ", "neg_item", "=", "random", ".", "choice", "(", "items_with_popular", ")", "\n", "if", "neg_item", "==", "positive_item", "or", "neg_item", "in", "neg_items", ":", "\n", "                ", "continue", "\n", "", "count", "+=", "1", "\n", "neg_items", ".", "add", "(", "neg_item", ")", "\n", "words", "[", "0", "]", "=", "\"0\"", "\n", "words", "[", "2", "]", "=", "neg_item", "\n", "words", "[", "3", "]", "=", "item2cate", "[", "neg_item", "]", "\n", "write_valid", ".", "write", "(", "\"\\t\"", ".", "join", "(", "words", ")", "+", "\"\\n\"", ")", "\n", "\n", "# test negative sampling", "\n", "", "", "logger", ".", "info", "(", "\"start test negative sampling\"", ")", "\n", "with", "open", "(", "test_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "test_lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "write_test", "=", "open", "(", "test_file", ",", "\"w\"", ")", "\n", "for", "line", "in", "test_lines", ":", "\n", "        ", "write_test", ".", "write", "(", "line", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "positive_item", "=", "words", "[", "2", "]", "\n", "count", "=", "0", "\n", "neg_items", "=", "set", "(", ")", "\n", "while", "count", "<", "test_neg_nums", ":", "\n", "            ", "neg_item", "=", "random", ".", "choice", "(", "items_with_popular", ")", "\n", "if", "neg_item", "==", "positive_item", "or", "neg_item", "in", "neg_items", ":", "\n", "                ", "continue", "\n", "", "count", "+=", "1", "\n", "neg_items", ".", "add", "(", "neg_item", ")", "\n", "words", "[", "0", "]", "=", "\"0\"", "\n", "words", "[", "2", "]", "=", "neg_item", "\n", "words", "[", "3", "]", "=", "item2cate", "[", "neg_item", "]", "\n", "write_test", ".", "write", "(", "\"\\t\"", ".", "join", "(", "words", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._data_generating": [[192, 264], ["open", "open", "open", "open", "logger.info", "line.strip().split", "int", "len", "movie_id_list.append", "cate_list.append", "dt_list.append", "line.strip", "len", "len", "len", "fo.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "_data_generating", "(", "input_file", ",", "train_file", ",", "valid_file", ",", "test_file", ",", "min_sequence", "=", "1", ")", ":", "\n", "    ", "\"\"\"produce train, valid and test file from processed_output file\n    Each user's behavior sequence will be unfolded and produce multiple lines in trian file.\n    Like, user's behavior sequence: 12345, and this function will write into train file:\n    1, 12, 123, 1234, 12345\n    \"\"\"", "\n", "f_input", "=", "open", "(", "input_file", ",", "\"r\"", ")", "\n", "f_train", "=", "open", "(", "train_file", ",", "\"w\"", ")", "\n", "f_valid", "=", "open", "(", "valid_file", ",", "\"w\"", ")", "\n", "f_test", "=", "open", "(", "test_file", ",", "\"w\"", ")", "\n", "logger", ".", "info", "(", "\"data generating...\"", ")", "\n", "last_user_id", "=", "None", "\n", "for", "line", "in", "f_input", ":", "\n", "        ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "tfile", "=", "line_split", "[", "0", "]", "\n", "label", "=", "int", "(", "line_split", "[", "1", "]", ")", "\n", "user_id", "=", "line_split", "[", "2", "]", "\n", "movie_id", "=", "line_split", "[", "3", "]", "\n", "date_time", "=", "line_split", "[", "4", "]", "\n", "category", "=", "line_split", "[", "5", "]", "\n", "\n", "if", "tfile", "==", "\"train\"", ":", "\n", "            ", "fo", "=", "f_train", "\n", "", "elif", "tfile", "==", "\"valid\"", ":", "\n", "            ", "fo", "=", "f_valid", "\n", "", "elif", "tfile", "==", "\"test\"", ":", "\n", "            ", "fo", "=", "f_test", "\n", "", "if", "user_id", "!=", "last_user_id", ":", "\n", "            ", "movie_id_list", "=", "[", "]", "\n", "cate_list", "=", "[", "]", "\n", "dt_list", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "history_clk_num", "=", "len", "(", "movie_id_list", ")", "\n", "cat_str", "=", "\"\"", "\n", "mid_str", "=", "\"\"", "\n", "dt_str", "=", "\"\"", "\n", "for", "c1", "in", "cate_list", ":", "\n", "                ", "cat_str", "+=", "c1", "+", "\",\"", "\n", "", "for", "mid", "in", "movie_id_list", ":", "\n", "                ", "mid_str", "+=", "mid", "+", "\",\"", "\n", "", "for", "dt_time", "in", "dt_list", ":", "\n", "                ", "dt_str", "+=", "dt_time", "+", "\",\"", "\n", "", "if", "len", "(", "cat_str", ")", ">", "0", ":", "\n", "                ", "cat_str", "=", "cat_str", "[", ":", "-", "1", "]", "\n", "", "if", "len", "(", "mid_str", ")", ">", "0", ":", "\n", "                ", "mid_str", "=", "mid_str", "[", ":", "-", "1", "]", "\n", "", "if", "len", "(", "dt_str", ")", ">", "0", ":", "\n", "                ", "dt_str", "=", "dt_str", "[", ":", "-", "1", "]", "\n", "", "if", "history_clk_num", ">=", "min_sequence", ":", "\n", "                ", "fo", ".", "write", "(", "\n", "line_split", "[", "1", "]", "\n", "+", "\"\\t\"", "\n", "+", "user_id", "\n", "+", "\"\\t\"", "\n", "+", "movie_id", "\n", "+", "\"\\t\"", "\n", "+", "category", "\n", "+", "\"\\t\"", "\n", "+", "date_time", "\n", "+", "\"\\t\"", "\n", "+", "mid_str", "\n", "+", "\"\\t\"", "\n", "+", "cat_str", "\n", "+", "\"\\t\"", "\n", "+", "dt_str", "\n", "+", "\"\\n\"", "\n", ")", "\n", "", "", "last_user_id", "=", "user_id", "\n", "if", "label", ":", "\n", "            ", "movie_id_list", ".", "append", "(", "movie_id", ")", "\n", "cate_list", ".", "append", "(", "category", ")", "\n", "dt_list", ".", "append", "(", "date_time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._data_generating_no_history_expanding": [[266, 353], ["open", "open", "open", "open", "logger.info", "line.strip().split", "int", "movie_id_list.append", "cate_list.append", "dt_list.append", "line.strip", "len", "len", "len", "len", "fo.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "_data_generating_no_history_expanding", "(", "\n", "input_file", ",", "train_file", ",", "valid_file", ",", "test_file", ",", "min_sequence", "=", "1", "\n", ")", ":", "\n", "    ", "\"\"\"Produce train, valid and test file from processed_output file\n    Each user's behavior sequence will only produce one line in train file.\n    Like, user's behavior sequence: 12345, and this function will write into train file: 12345\n    \"\"\"", "\n", "f_input", "=", "open", "(", "input_file", ",", "\"r\"", ")", "\n", "f_train", "=", "open", "(", "train_file", ",", "\"w\"", ")", "\n", "f_valid", "=", "open", "(", "valid_file", ",", "\"w\"", ")", "\n", "f_test", "=", "open", "(", "test_file", ",", "\"w\"", ")", "\n", "logger", ".", "info", "(", "\"data generating...\"", ")", "\n", "\n", "last_user_id", "=", "None", "\n", "last_movie_id", "=", "None", "\n", "last_category", "=", "None", "\n", "last_datetime", "=", "None", "\n", "last_tfile", "=", "None", "\n", "for", "line", "in", "f_input", ":", "\n", "        ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "tfile", "=", "line_split", "[", "0", "]", "\n", "label", "=", "int", "(", "line_split", "[", "1", "]", ")", "\n", "user_id", "=", "line_split", "[", "2", "]", "\n", "movie_id", "=", "line_split", "[", "3", "]", "\n", "date_time", "=", "line_split", "[", "4", "]", "\n", "category", "=", "line_split", "[", "5", "]", "\n", "\n", "if", "last_tfile", "==", "\"train\"", ":", "\n", "            ", "fo", "=", "f_train", "\n", "", "elif", "last_tfile", "==", "\"valid\"", ":", "\n", "            ", "fo", "=", "f_valid", "\n", "", "elif", "last_tfile", "==", "\"test\"", ":", "\n", "            ", "fo", "=", "f_test", "\n", "", "if", "user_id", "!=", "last_user_id", "or", "tfile", "==", "\"valid\"", "or", "tfile", "==", "\"test\"", ":", "\n", "            ", "if", "last_user_id", "is", "not", "None", ":", "\n", "                ", "history_clk_num", "=", "len", "(", "\n", "movie_id_list", "# noqa: F821 undefined name 'movie_id_list'", "\n", ")", "\n", "cat_str", "=", "\"\"", "\n", "mid_str", "=", "\"\"", "\n", "dt_str", "=", "\"\"", "\n", "for", "c1", "in", "cate_list", "[", ":", "-", "1", "]", ":", "# noqa: F821 undefined name 'cate_list'", "\n", "                    ", "cat_str", "+=", "c1", "+", "\",\"", "\n", "", "for", "mid", "in", "movie_id_list", "[", "# noqa: F821 undefined name 'movie_id_list'", "\n", ":", "-", "1", "\n", "]", ":", "\n", "                    ", "mid_str", "+=", "mid", "+", "\",\"", "\n", "", "for", "dt_time", "in", "dt_list", "[", ":", "-", "1", "]", ":", "# noqa: F821 undefined name 'dt_list'", "\n", "                    ", "dt_str", "+=", "dt_time", "+", "\",\"", "\n", "", "if", "len", "(", "cat_str", ")", ">", "0", ":", "\n", "                    ", "cat_str", "=", "cat_str", "[", ":", "-", "1", "]", "\n", "", "if", "len", "(", "mid_str", ")", ">", "0", ":", "\n", "                    ", "mid_str", "=", "mid_str", "[", ":", "-", "1", "]", "\n", "", "if", "len", "(", "dt_str", ")", ">", "0", ":", "\n", "                    ", "dt_str", "=", "dt_str", "[", ":", "-", "1", "]", "\n", "", "if", "history_clk_num", ">", "min_sequence", ":", "\n", "                    ", "fo", ".", "write", "(", "\n", "line_split", "[", "1", "]", "\n", "+", "\"\\t\"", "\n", "+", "last_user_id", "\n", "+", "\"\\t\"", "\n", "+", "last_movie_id", "\n", "+", "\"\\t\"", "\n", "+", "last_category", "\n", "+", "\"\\t\"", "\n", "+", "last_datetime", "\n", "+", "\"\\t\"", "\n", "+", "mid_str", "\n", "+", "\"\\t\"", "\n", "+", "cat_str", "\n", "+", "\"\\t\"", "\n", "+", "dt_str", "\n", "+", "\"\\n\"", "\n", ")", "\n", "", "", "if", "tfile", "==", "\"train\"", "or", "last_user_id", "is", "None", ":", "\n", "                ", "movie_id_list", "=", "[", "]", "\n", "cate_list", "=", "[", "]", "\n", "dt_list", "=", "[", "]", "\n", "", "", "last_user_id", "=", "user_id", "\n", "last_movie_id", "=", "movie_id", "\n", "last_category", "=", "category", "\n", "last_datetime", "=", "date_time", "\n", "last_tfile", "=", "tfile", "\n", "if", "label", ":", "\n", "            ", "movie_id_list", ".", "append", "(", "movie_id", ")", "\n", "cate_list", ".", "append", "(", "category", ")", "\n", "dt_list", ".", "append", "(", "date_time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_item2cate": [[355, 364], ["logger.info", "pandas.read_csv", "[].to_dict", "pd.read_csv.set_index"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "", "def", "_create_item2cate", "(", "instance_file", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"creating item2cate dict\"", ")", "\n", "global", "item2cate", "\n", "instance_df", "=", "pd", ".", "read_csv", "(", "\n", "instance_file", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "names", "=", "[", "\"label\"", ",", "\"user_id\"", ",", "\"item_id\"", ",", "\"timestamp\"", ",", "\"cate_id\"", "]", ",", "\n", ")", "\n", "item2cate", "=", "instance_df", ".", "set_index", "(", "\"item_id\"", ")", "[", "\"cate_id\"", "]", ".", "to_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._get_sampled_data": [[366, 383], ["logger.info", "pandas.read_csv", "ns_df[].nunique", "list", "ns_df_sample.to_csv", "str", "set", "int", "random.choice", "items_sample.add", "ns_df[].isin"], "function", ["None"], ["", "def", "_get_sampled_data", "(", "instance_file", ",", "sample_rate", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"getting sampled data...\"", ")", "\n", "global", "item2cate", "\n", "output_file", "=", "instance_file", "+", "\"_\"", "+", "str", "(", "sample_rate", ")", "\n", "columns", "=", "[", "\"label\"", ",", "\"user_id\"", ",", "\"item_id\"", ",", "\"timestamp\"", ",", "\"cate_id\"", "]", "\n", "ns_df", "=", "pd", ".", "read_csv", "(", "instance_file", ",", "sep", "=", "\"\\t\"", ",", "names", "=", "columns", ")", "\n", "items_num", "=", "ns_df", "[", "\"item_id\"", "]", ".", "nunique", "(", ")", "\n", "items_with_popular", "=", "list", "(", "ns_df", "[", "\"item_id\"", "]", ")", "\n", "items_sample", ",", "count", "=", "set", "(", ")", ",", "0", "\n", "while", "count", "<", "int", "(", "items_num", "*", "sample_rate", ")", ":", "\n", "        ", "random_item", "=", "random", ".", "choice", "(", "items_with_popular", ")", "\n", "if", "random_item", "not", "in", "items_sample", ":", "\n", "            ", "items_sample", ".", "add", "(", "random_item", ")", "\n", "count", "+=", "1", "\n", "", "", "ns_df_sample", "=", "ns_df", "[", "ns_df", "[", "\"item_id\"", "]", ".", "isin", "(", "items_sample", ")", "]", "\n", "ns_df_sample", ".", "to_csv", "(", "output_file", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "None", ",", "header", "=", "None", ")", "\n", "return", "output_file", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._meta_preprocessing": [[385, 396], ["logger.info", "open", "open", "open.close", "open.close", "eval", "open.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "_meta_preprocessing", "(", "meta_readfile", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"start meta preprocessing...\"", ")", "\n", "meta_writefile", "=", "meta_readfile", "+", "\"_output\"", "\n", "meta_r", "=", "open", "(", "meta_readfile", ",", "\"r\"", ")", "\n", "meta_w", "=", "open", "(", "meta_writefile", ",", "\"w\"", ")", "\n", "for", "line", "in", "meta_r", ":", "\n", "        ", "line_new", "=", "eval", "(", "line", ")", "\n", "meta_w", ".", "write", "(", "line_new", "[", "\"asin\"", "]", "+", "\"\\t\"", "+", "line_new", "[", "\"categories\"", "]", "[", "0", "]", "[", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "", "meta_r", ".", "close", "(", ")", "\n", "meta_w", ".", "close", "(", ")", "\n", "return", "meta_writefile", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._reviews_preprocessing": [[398, 416], ["logger.info", "open", "open", "open.close", "open.close", "eval", "open.write", "line.strip", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "_reviews_preprocessing", "(", "reviews_readfile", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"start reviews preprocessing...\"", ")", "\n", "reviews_writefile", "=", "reviews_readfile", "+", "\"_output\"", "\n", "reviews_r", "=", "open", "(", "reviews_readfile", ",", "\"r\"", ")", "\n", "reviews_w", "=", "open", "(", "reviews_writefile", ",", "\"w\"", ")", "\n", "for", "line", "in", "reviews_r", ":", "\n", "        ", "line_new", "=", "eval", "(", "line", ".", "strip", "(", ")", ")", "\n", "reviews_w", ".", "write", "(", "\n", "str", "(", "line_new", "[", "\"reviewerID\"", "]", ")", "\n", "+", "\"\\t\"", "\n", "+", "str", "(", "line_new", "[", "\"asin\"", "]", ")", "\n", "+", "\"\\t\"", "\n", "+", "str", "(", "line_new", "[", "\"unixReviewTime\"", "]", ")", "\n", "+", "\"\\n\"", "\n", ")", "\n", "", "reviews_r", ".", "close", "(", ")", "\n", "reviews_w", ".", "close", "(", ")", "\n", "return", "reviews_writefile", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._create_instance": [[418, 457], ["logger.info", "os.path.split", "os.path.join", "open", "open", "open", "open.close", "open.close", "open.close", "line.strip.strip", "line.strip.split", "user_dict[].append", "item_list.append", "line.strip.strip", "line.strip.split", "sorted", "line.strip.split", "float", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_create_instance", "(", "reviews_file", ",", "meta_file", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"start create instances...\"", ")", "\n", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "reviews_file", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "dirs", ",", "\"instance_output\"", ")", "\n", "\n", "f_reviews", "=", "open", "(", "reviews_file", ",", "\"r\"", ")", "\n", "user_dict", "=", "{", "}", "\n", "item_list", "=", "[", "]", "\n", "for", "line", "in", "f_reviews", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "reviews_things", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "reviews_things", "[", "0", "]", "not", "in", "user_dict", ":", "\n", "            ", "user_dict", "[", "reviews_things", "[", "0", "]", "]", "=", "[", "]", "\n", "", "user_dict", "[", "reviews_things", "[", "0", "]", "]", ".", "append", "(", "(", "line", ",", "float", "(", "reviews_things", "[", "-", "1", "]", ")", ")", ")", "\n", "item_list", ".", "append", "(", "reviews_things", "[", "1", "]", ")", "\n", "\n", "", "f_meta", "=", "open", "(", "meta_file", ",", "\"r\"", ")", "\n", "meta_dict", "=", "{", "}", "\n", "for", "line", "in", "f_meta", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "meta_things", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "meta_things", "[", "0", "]", "not", "in", "meta_dict", ":", "\n", "            ", "meta_dict", "[", "meta_things", "[", "0", "]", "]", "=", "meta_things", "[", "1", "]", "\n", "\n", "", "", "f_output", "=", "open", "(", "output_file", ",", "\"w\"", ")", "\n", "for", "user_behavior", "in", "user_dict", ":", "\n", "        ", "sorted_user_behavior", "=", "sorted", "(", "user_dict", "[", "user_behavior", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "for", "line", ",", "_", "in", "sorted_user_behavior", ":", "\n", "            ", "user_things", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "asin", "=", "user_things", "[", "1", "]", "\n", "if", "asin", "in", "meta_dict", ":", "\n", "                ", "f_output", ".", "write", "(", "\"1\"", "+", "\"\\t\"", "+", "line", "+", "\"\\t\"", "+", "meta_dict", "[", "asin", "]", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "f_output", ".", "write", "(", "\"1\"", "+", "\"\\t\"", "+", "line", "+", "\"\\t\"", "+", "\"default_cat\"", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "f_reviews", ".", "close", "(", ")", "\n", "f_meta", ".", "close", "(", ")", "\n", "f_output", ".", "close", "(", ")", "\n", "return", "output_file", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._data_processing": [[459, 497], ["logger.info", "os.path.split", "os.path.join", "open", "open", "open.seek", "line.strip.strip", "line.strip.strip", "line.strip.split", "line.strip.split", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_data_processing", "(", "input_file", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"start data processing...\"", ")", "\n", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "input_file", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "dirs", ",", "\"preprocessed_output\"", ")", "\n", "\n", "f_input", "=", "open", "(", "input_file", ",", "\"r\"", ")", "\n", "f_output", "=", "open", "(", "output_file", ",", "\"w\"", ")", "\n", "user_count", "=", "{", "}", "\n", "for", "line", "in", "f_input", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "user", "=", "line", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", "\n", "if", "user", "not", "in", "user_count", ":", "\n", "            ", "user_count", "[", "user", "]", "=", "0", "\n", "", "user_count", "[", "user", "]", "+=", "1", "\n", "", "f_input", ".", "seek", "(", "0", ")", "\n", "i", "=", "0", "\n", "last_user", "=", "None", "\n", "for", "line", "in", "f_input", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "user", "=", "line", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", "\n", "if", "user", "==", "last_user", ":", "\n", "            ", "if", "i", "<", "user_count", "[", "user", "]", "-", "2", ":", "\n", "                ", "f_output", ".", "write", "(", "\"train\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "elif", "i", "<", "user_count", "[", "user", "]", "-", "1", ":", "\n", "                ", "f_output", ".", "write", "(", "\"valid\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "f_output", ".", "write", "(", "\"test\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "", "else", ":", "\n", "            ", "last_user", "=", "user", "\n", "i", "=", "0", "\n", "if", "i", "<", "user_count", "[", "user", "]", "-", "2", ":", "\n", "                ", "f_output", ".", "write", "(", "\"train\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "elif", "i", "<", "user_count", "[", "user", "]", "-", "1", ":", "\n", "                ", "f_output", ".", "write", "(", "\"valid\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "f_output", ".", "write", "(", "\"test\"", "+", "\"\\t\"", "+", "line", "+", "\"\\n\"", ")", "\n", "", "", "i", "+=", "1", "\n", "", "return", "output_file", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract": [[499, 519], ["os.path.split", "os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "amazon_reviews._download_reviews", "amazon_reviews._extract_reviews"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._download_reviews", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._extract_reviews"], ["", "def", "download_and_extract", "(", "name", ",", "dest_path", ")", ":", "\n", "    ", "\"\"\"Downloads and extracts Amazon reviews and meta datafiles if they don\u2019t already exist\n\n    Args:\n        name (str): Category of reviews.\n        dest_path (str): File path for the downloaded file.\n\n    Returns:\n        str: File path for the extracted file.\n    \"\"\"", "\n", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "dest_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirs", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirs", ")", "\n", "\n", "", "file_path", "=", "os", ".", "path", ".", "join", "(", "dirs", ",", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "        ", "_download_reviews", "(", "name", ",", "dest_path", ")", "\n", "_extract_reviews", "(", "file_path", ",", "dest_path", ")", "\n", "\n", "", "return", "file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._download_reviews": [[521, 537], ["os.path.split", "recommenders.datasets.download_utils.maybe_download"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "def", "_download_reviews", "(", "name", ",", "dest_path", ")", ":", "\n", "    ", "\"\"\"Downloads Amazon reviews datafile.\n\n    Args:\n        name (str): Category of reviews\n        dest_path (str): File path for the downloaded file\n    \"\"\"", "\n", "\n", "url", "=", "(", "\n", "\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\"", "\n", "+", "name", "\n", "+", "\".gz\"", "\n", ")", "\n", "\n", "dirs", ",", "file", "=", "os", ".", "path", ".", "split", "(", "dest_path", ")", "\n", "maybe_download", "(", "url", ",", "file", "+", "\".gz\"", ",", "work_directory", "=", "dirs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._extract_reviews": [[539, 551], ["gzip.open", "open", "shutil.copyfileobj"], "function", ["None"], ["", "def", "_extract_reviews", "(", "file_path", ",", "zip_path", ")", ":", "\n", "    ", "\"\"\"Extract Amazon reviews and meta datafiles from the raw zip files.\n\n    To extract all files,\n    use ZipFile's extractall(path) instead.\n\n    Args:\n        file_path (str): Destination path for datafile\n        zip_path (str): zipfile path\n    \"\"\"", "\n", "with", "gzip", ".", "open", "(", "zip_path", "+", "\".gz\"", ",", "\"rb\"", ")", "as", "zf", ",", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "zf", ",", "f", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_random_split": [[23, 46], ["recommenders.datasets.split_utils.process_split_ratio", "data.randomSplit", "data.randomSplit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.process_split_ratio"], ["def", "spark_random_split", "(", "data", ",", "ratio", "=", "0.75", ",", "seed", "=", "42", ")", ":", "\n", "    ", "\"\"\"Spark random splitter.\n\n    Randomly split the data into several splits.\n\n    Args:\n        data (pyspark.sql.DataFrame): Spark DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two halves and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list\n            is provided and the ratios are not summed to 1, they will be normalized.\n        seed (int): Seed.\n\n    Returns:\n        list: Splits of the input data as pyspark.sql.DataFrame.\n    \"\"\"", "\n", "multi_split", ",", "ratio", "=", "process_split_ratio", "(", "ratio", ")", "\n", "\n", "if", "multi_split", ":", "\n", "        ", "return", "data", ".", "randomSplit", "(", "ratio", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "        ", "return", "data", ".", "randomSplit", "(", "[", "ratio", ",", "1", "-", "ratio", "]", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters._do_stratification_spark": [[48, 147], ["Window.partitionBy", "Window.partitionBy().orderBy", "data.withColumn.withColumn().withColumn().drop", "data.withColumn.persist().count", "recommenders.datasets.split_utils.process_split_ratio", "numpy.cumsum", "ValueError", "ValueError", "ValueError", "ValueError", "recommenders.datasets.split_utils.min_rating_filter_spark", "data.withColumn.withColumn", "F.col", "F.col", "splits.append", "ValueError", "F.rand", "Window.partitionBy", "data.withColumn.withColumn().withColumn", "data.withColumn.persist", "F.col", "data.withColumn.filter().drop", "F.col", "data.withColumn.withColumn", "F.row_number().over", "F.col", "data.withColumn.filter", "F.count().over", "F.row_number", "F.count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.process_split_ratio", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_spark"], ["", "", "def", "_do_stratification_spark", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "is_partitioned", "=", "True", ",", "\n", "is_random", "=", "True", ",", "\n", "seed", "=", "42", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Helper function to perform stratified splits.\n\n    This function splits data in a stratified manner. That is, the same values for the\n    filter_by column are retained in each split, but the corresponding set of entries\n    are divided according to the ratio provided.\n\n    Args:\n        data (pyspark.sql.DataFrame): Spark DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two sets and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to filter\n            with min_rating.\n        is_partitioned (bool): flag to partition data by filter_by column\n        is_random (bool): flag to make split randomly or use timestamp column\n        seed (int): Seed.\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n        col_timestamp (str): column name of timestamps.\n\n    Args:\n\n    Returns:\n    \"\"\"", "\n", "# A few preliminary checks.", "\n", "if", "filter_by", "not", "in", "[", "\"user\"", ",", "\"item\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"filter_by should be either 'user' or 'item'.\"", ")", "\n", "\n", "", "if", "min_rating", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"min_rating should be integer and larger than or equal to 1.\"", ")", "\n", "\n", "", "if", "col_user", "not", "in", "data", ".", "columns", ":", "\n", "        ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing User Col\"", ")", "\n", "\n", "", "if", "col_item", "not", "in", "data", ".", "columns", ":", "\n", "        ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing Item Col\"", ")", "\n", "\n", "", "if", "not", "is_random", ":", "\n", "        ", "if", "col_timestamp", "not", "in", "data", ".", "columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of data not valid. Missing Timestamp Col\"", ")", "\n", "\n", "", "", "if", "min_rating", ">", "1", ":", "\n", "        ", "data", "=", "min_rating_filter_spark", "(", "\n", "data", "=", "data", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", ")", "\n", "\n", "", "split_by", "=", "col_user", "if", "filter_by", "==", "\"user\"", "else", "col_item", "\n", "partition_by", "=", "split_by", "if", "is_partitioned", "else", "[", "]", "\n", "\n", "col_random", "=", "\"_random\"", "\n", "if", "is_random", ":", "\n", "        ", "data", "=", "data", ".", "withColumn", "(", "col_random", ",", "F", ".", "rand", "(", "seed", "=", "seed", ")", ")", "\n", "order_by", "=", "F", ".", "col", "(", "col_random", ")", "\n", "", "else", ":", "\n", "        ", "order_by", "=", "F", ".", "col", "(", "col_timestamp", ")", "\n", "\n", "", "window_count", "=", "Window", ".", "partitionBy", "(", "partition_by", ")", "\n", "window_spec", "=", "Window", ".", "partitionBy", "(", "partition_by", ")", ".", "orderBy", "(", "order_by", ")", "\n", "\n", "data", "=", "(", "\n", "data", ".", "withColumn", "(", "\"_count\"", ",", "F", ".", "count", "(", "split_by", ")", ".", "over", "(", "window_count", ")", ")", "\n", ".", "withColumn", "(", "\"_rank\"", ",", "F", ".", "row_number", "(", ")", ".", "over", "(", "window_spec", ")", "/", "F", ".", "col", "(", "\"_count\"", ")", ")", "\n", ".", "drop", "(", "\"_count\"", ",", "col_random", ")", "\n", ")", "\n", "# Persist to avoid duplicate rows in splits caused by lazy evaluation", "\n", "data", ".", "persist", "(", "StorageLevel", ".", "MEMORY_AND_DISK_2", ")", ".", "count", "(", ")", "\n", "\n", "multi_split", ",", "ratio", "=", "process_split_ratio", "(", "ratio", ")", "\n", "ratio", "=", "ratio", "if", "multi_split", "else", "[", "ratio", ",", "1", "-", "ratio", "]", "\n", "\n", "splits", "=", "[", "]", "\n", "prev_split", "=", "None", "\n", "for", "split", "in", "np", ".", "cumsum", "(", "ratio", ")", ":", "\n", "        ", "condition", "=", "F", ".", "col", "(", "\"_rank\"", ")", "<=", "split", "\n", "if", "prev_split", "is", "not", "None", ":", "\n", "            ", "condition", "&=", "F", ".", "col", "(", "\"_rank\"", ")", ">", "prev_split", "\n", "", "splits", ".", "append", "(", "data", ".", "filter", "(", "condition", ")", ".", "drop", "(", "\"_rank\"", ")", ")", "\n", "prev_split", "=", "split", "\n", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_chrono_split": [[149, 193], ["spark_splitters._do_stratification_spark"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters._do_stratification_spark"], ["", "def", "spark_chrono_split", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", "no_partition", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Spark chronological splitter.\n\n    This function splits data in a chronological manner. That is, for each user / item, the\n    split function takes proportions of ratings which is specified by the split ratio(s).\n    The split is stratified.\n\n    Args:\n        data (pyspark.sql.DataFrame): Spark DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two sets and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to filter\n            with min_rating.\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n        col_timestamp (str): column name of timestamps.\n        no_partition (bool): set to enable more accurate and less efficient splitting.\n\n    Returns:\n        list: Splits of the input data as pyspark.sql.DataFrame.\n    \"\"\"", "\n", "\n", "return", "_do_stratification_spark", "(", "\n", "data", "=", "data", ",", "\n", "ratio", "=", "ratio", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "is_random", "=", "False", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_timestamp", "=", "col_timestamp", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_stratified_split": [[196, 237], ["spark_splitters._do_stratification_spark"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters._do_stratification_spark"], ["", "def", "spark_stratified_split", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "min_rating", "=", "1", ",", "\n", "filter_by", "=", "\"user\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Spark stratified splitter.\n\n    For each user / item, the split function takes proportions of ratings which is\n    specified by the split ratio(s). The split is stratified.\n\n    Args:\n        data (pyspark.sql.DataFrame): Spark DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two halves and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n            Earlier indexed splits will have earlier times\n            (e.g. the latest time per user or item in split[0] <= the earliest time per user or item in split[1])\n        seed (int): Seed.\n        min_rating (int): minimum number of ratings for user or item.\n        filter_by (str): either \"user\" or \"item\", depending on which of the two is to filter\n            with min_rating.\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n\n    Returns:\n        list: Splits of the input data as pyspark.sql.DataFrame.\n    \"\"\"", "\n", "return", "_do_stratification_spark", "(", "\n", "data", "=", "data", ",", "\n", "ratio", "=", "ratio", ",", "\n", "min_rating", "=", "min_rating", ",", "\n", "filter_by", "=", "filter_by", ",", "\n", "seed", "=", "seed", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_timestamp_split": [[240, 277], ["spark_splitters._do_stratification_spark"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters._do_stratification_spark"], ["", "def", "spark_timestamp_split", "(", "\n", "data", ",", "\n", "ratio", "=", "0.75", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Spark timestamp based splitter.\n\n    The splitter splits the data into sets by timestamps without stratification on either user or item.\n    The ratios are applied on the timestamp column which is divided accordingly into several partitions.\n\n    Args:\n        data (pyspark.sql.DataFrame): Spark DataFrame to be split.\n        ratio (float or list): Ratio for splitting data. If it is a single float number\n            it splits data into two sets and the ratio argument indicates the ratio of\n            training data set; if it is a list of float numbers, the splitter splits\n            data into several portions corresponding to the split ratios. If a list is\n            provided and the ratios are not summed to 1, they will be normalized.\n            Earlier indexed splits will have earlier times\n            (e.g. the latest time in split[0] <= the earliest time in split[1])\n        col_user (str): column name of user IDs.\n        col_item (str): column name of item IDs.\n        col_timestamp (str): column name of timestamps. Float number represented in\n        seconds since Epoch.\n\n    Returns:\n        list: Splits of the input data as pyspark.sql.DataFrame.\n    \"\"\"", "\n", "return", "_do_stratification_spark", "(", "\n", "data", "=", "data", ",", "\n", "ratio", "=", "ratio", ",", "\n", "is_random", "=", "False", ",", "\n", "is_partitioned", "=", "False", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_timestamp", "=", "col_timestamp", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.cosmos_cli.find_collection": [[6, 31], ["list", "client.QueryCollections", "len"], "function", ["None"], ["def", "find_collection", "(", "client", ",", "dbid", ",", "id", ")", ":", "\n", "    ", "\"\"\"Find whether or not a CosmosDB collection exists.\n\n    Args:\n        client (object): A pydocumentdb client object.\n        dbid (str): Database ID.\n        id (str): Collection ID.\n\n    Returns:\n        bool: True if the collection exists, False otherwise.\n    \"\"\"", "\n", "database_link", "=", "\"dbs/\"", "+", "dbid", "\n", "collections", "=", "list", "(", "\n", "client", ".", "QueryCollections", "(", "\n", "database_link", ",", "\n", "{", "\n", "\"query\"", ":", "\"SELECT * FROM r WHERE r.id=@id\"", ",", "\n", "\"parameters\"", ":", "[", "{", "\"name\"", ":", "\"@id\"", ",", "\"value\"", ":", "id", "}", "]", ",", "\n", "}", ",", "\n", ")", "\n", ")", "\n", "if", "len", "(", "collections", ")", ">", "0", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.cosmos_cli.read_collection": [[33, 54], ["client.ReadCollection", "print", "pydocumentdb.HTTPFailure"], "function", ["None"], ["", "", "def", "read_collection", "(", "client", ",", "dbid", ",", "id", ")", ":", "\n", "    ", "\"\"\"Read a CosmosDB collection.\n\n    Args:\n        client (object): A pydocumentdb client object.\n        dbid (str): Database ID.\n        id (str): Collection ID.\n\n    Returns:\n        object: A collection.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "database_link", "=", "\"dbs/\"", "+", "dbid", "\n", "collection_link", "=", "database_link", "+", "\"/colls/{0}\"", ".", "format", "(", "id", ")", "\n", "collection", "=", "client", ".", "ReadCollection", "(", "collection_link", ")", "\n", "return", "collection", "\n", "", "except", "errors", ".", "DocumentDBError", "as", "e", ":", "\n", "        ", "if", "e", ".", "status_code", "==", "404", ":", "\n", "            ", "print", "(", "\"A collection with id '{0}' does not exist\"", ".", "format", "(", "id", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "errors", ".", "HTTPFailure", "(", "e", ".", "status_code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.cosmos_cli.read_database": [[56, 75], ["client.ReadDatabase", "print", "pydocumentdb.HTTPFailure"], "function", ["None"], ["", "", "", "def", "read_database", "(", "client", ",", "id", ")", ":", "\n", "    ", "\"\"\"Read a CosmosDB database.\n\n    Args:\n        client (object): A pydocumentdb client object.\n        id (str): Database ID.\n\n    Returns:\n        object: A database.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "database_link", "=", "\"dbs/\"", "+", "id", "\n", "database", "=", "client", ".", "ReadDatabase", "(", "database_link", ")", "\n", "return", "database", "\n", "", "except", "errors", ".", "DocumentDBError", "as", "e", ":", "\n", "        ", "if", "e", ".", "status_code", "==", "404", ":", "\n", "            ", "print", "(", "\"A database with id '{0}' does not exist\"", ".", "format", "(", "id", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "errors", ".", "HTTPFailure", "(", "e", ".", "status_code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.cosmos_cli.find_database": [[77, 99], ["list", "client.QueryDatabases", "len"], "function", ["None"], ["", "", "", "def", "find_database", "(", "client", ",", "id", ")", ":", "\n", "    ", "\"\"\"Find whether or not a CosmosDB database exists.\n\n    Args:\n        client (object): A pydocumentdb client object.\n        id (str): Database ID.\n\n    Returns:\n        bool: True if the database exists, False otherwise.\n    \"\"\"", "\n", "databases", "=", "list", "(", "\n", "client", ".", "QueryDatabases", "(", "\n", "{", "\n", "\"query\"", ":", "\"SELECT * FROM r WHERE r.id=@id\"", ",", "\n", "\"parameters\"", ":", "[", "{", "\"name\"", ":", "\"@id\"", ",", "\"value\"", ":", "id", "}", "]", ",", "\n", "}", "\n", ")", "\n", ")", "\n", "if", "len", "(", "databases", ")", ">", "0", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_mind": [[51, 69], ["ValueError", "recommenders.datasets.download_utils.download_path", "recommenders.datasets.download_utils.maybe_download", "recommenders.datasets.download_utils.maybe_download"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["def", "download_mind", "(", "size", "=", "\"small\"", ",", "dest_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download MIND dataset\n\n    Args:\n        size (str): Dataset size. One of [\"small\", \"large\"]\n        dest_path (str): Download path. If path is None, it will download the dataset on a temporal path\n\n    Returns:\n        str, str: Path to train and validation sets.\n    \"\"\"", "\n", "size_options", "=", "[", "\"small\"", ",", "\"large\"", ",", "\"demo\"", "]", "\n", "if", "size", "not", "in", "size_options", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Wrong size option, available options are {size_options}\"", ")", "\n", "", "url_train", ",", "url_valid", "=", "URL_MIND", "[", "size", "]", "\n", "with", "download_path", "(", "dest_path", ")", "as", "path", ":", "\n", "        ", "train_path", "=", "maybe_download", "(", "url", "=", "url_train", ",", "work_directory", "=", "path", ")", "\n", "valid_path", "=", "maybe_download", "(", "url", "=", "url_valid", ",", "work_directory", "=", "path", ")", "\n", "", "return", "train_path", ",", "valid_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.extract_mind": [[71, 95], ["os.path.basename", "os.path.join", "os.path.join", "recommenders.datasets.download_utils.unzip_file", "recommenders.datasets.download_utils.unzip_file"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.unzip_file", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.unzip_file"], ["", "def", "extract_mind", "(", "\n", "train_zip", ",", "\n", "valid_zip", ",", "\n", "train_folder", "=", "\"train\"", ",", "\n", "valid_folder", "=", "\"valid\"", ",", "\n", "clean_zip_file", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Extract MIND dataset\n\n    Args:\n        train_zip (str): Path to train zip file\n        valid_zip (str): Path to valid zip file\n        train_folder (str): Destination forder for train set\n        valid_folder (str): Destination forder for validation set\n\n    Returns:\n        str, str: Train and validation folders\n    \"\"\"", "\n", "root_folder", "=", "os", ".", "path", ".", "basename", "(", "train_zip", ")", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "train_folder", ")", "\n", "valid_path", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "valid_folder", ")", "\n", "unzip_file", "(", "train_zip", ",", "train_path", ",", "clean_zip_file", "=", "clean_zip_file", ")", "\n", "unzip_file", "(", "valid_zip", ",", "valid_path", ",", "clean_zip_file", "=", "clean_zip_file", ")", "\n", "return", "train_path", ",", "valid_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.read_clickhistory": [[97, 127], ["range", "open", "f.readlines", "len", "lines[].strip().split", "click.split", "imps.split.split", "sessions.append", "os.path.join", "lines[].strip", "pos.append", "neg.append", "imp.split", "imp.split", "imp.split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "read_clickhistory", "(", "path", ",", "filename", ")", ":", "\n", "    ", "\"\"\"Read click history file\n\n    Args:\n        path (str): Folder path\n        filename (str): Filename\n\n    Returns:\n        list, dict:\n        - A list of user session with user_id, clicks, positive and negative interactions.\n        - A dictionary with user_id click history.\n    \"\"\"", "\n", "userid_history", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "sessions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "lines", ")", ")", ":", "\n", "        ", "_", ",", "userid", ",", "imp_time", ",", "click", ",", "imps", "=", "lines", "[", "i", "]", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "clicks", "=", "click", ".", "split", "(", "\" \"", ")", "\n", "pos", "=", "[", "]", "\n", "neg", "=", "[", "]", "\n", "imps", "=", "imps", ".", "split", "(", "\" \"", ")", "\n", "for", "imp", "in", "imps", ":", "\n", "            ", "if", "imp", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "==", "\"1\"", ":", "\n", "                ", "pos", ".", "append", "(", "imp", ".", "split", "(", "\"-\"", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "neg", ".", "append", "(", "imp", ".", "split", "(", "\"-\"", ")", "[", "0", "]", ")", "\n", "", "", "userid_history", "[", "userid", "]", "=", "clicks", "\n", "sessions", ".", "append", "(", "[", "userid", ",", "clicks", ",", "pos", ",", "neg", "]", ")", "\n", "", "return", "sessions", ",", "userid_history", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind._newsample": [[129, 134], ["len", "random.sample", "random.sample", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "def", "_newsample", "(", "nnn", ",", "ratio", ")", ":", "\n", "    ", "if", "ratio", ">", "len", "(", "nnn", ")", ":", "\n", "        ", "return", "random", ".", "sample", "(", "nnn", "*", "(", "ratio", "//", "len", "(", "nnn", ")", "+", "1", ")", ",", "ratio", ")", "\n", "", "else", ":", "\n", "        ", "return", "random", ".", "sample", "(", "nnn", ",", "ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.get_train_input": [[136, 159], ["open", "range", "open.close", "os.path.isfile", "len", "range", "logger.info", "FileNotFoundError", "len", "mind._newsample", "open.write", "open.write"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind._newsample"], ["", "", "def", "get_train_input", "(", "session", ",", "train_file_path", ",", "npratio", "=", "4", ")", ":", "\n", "    ", "\"\"\"Generate train file.\n\n    Args:\n        session (list): List of user session with user_id, clicks, positive and negative interactions.\n        train_file_path (str): Path to file.\n        npration (int): Ratio for negative sampling.\n    \"\"\"", "\n", "fp_train", "=", "open", "(", "train_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "sess_id", "in", "range", "(", "len", "(", "session", ")", ")", ":", "\n", "        ", "sess", "=", "session", "[", "sess_id", "]", "\n", "userid", ",", "_", ",", "poss", ",", "negs", "=", "sess", "\n", "for", "i", "in", "range", "(", "len", "(", "poss", ")", ")", ":", "\n", "            ", "pos", "=", "poss", "[", "i", "]", "\n", "neg", "=", "_newsample", "(", "negs", ",", "npratio", ")", "\n", "fp_train", ".", "write", "(", "\"1 \"", "+", "\"train_\"", "+", "userid", "+", "\" \"", "+", "pos", "+", "\"\\n\"", ")", "\n", "for", "neg_ins", "in", "neg", ":", "\n", "                ", "fp_train", ".", "write", "(", "\"0 \"", "+", "\"train_\"", "+", "userid", "+", "\" \"", "+", "neg_ins", "+", "\"\\n\"", ")", "\n", "", "", "", "fp_train", ".", "close", "(", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "train_file_path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Train file {train_file_path} successfully generated\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"Error when generating {train_file_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.get_valid_input": [[161, 184], ["open", "range", "open.close", "os.path.isfile", "len", "range", "range", "logger.info", "FileNotFoundError", "len", "open.write", "len", "open.write", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close"], ["", "", "def", "get_valid_input", "(", "session", ",", "valid_file_path", ")", ":", "\n", "    ", "\"\"\"Generate validation file.\n\n    Args:\n        session (list): List of user session with user_id, clicks, positive and negative interactions.\n        valid_file_path (str): Path to file.\n    \"\"\"", "\n", "fp_valid", "=", "open", "(", "valid_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "sess_id", "in", "range", "(", "len", "(", "session", ")", ")", ":", "\n", "        ", "userid", ",", "_", ",", "poss", ",", "negs", "=", "session", "[", "sess_id", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "poss", ")", ")", ":", "\n", "            ", "fp_valid", ".", "write", "(", "\n", "\"1 \"", "+", "\"valid_\"", "+", "userid", "+", "\" \"", "+", "poss", "[", "i", "]", "+", "\"%\"", "+", "str", "(", "sess_id", ")", "+", "\"\\n\"", "\n", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "negs", ")", ")", ":", "\n", "            ", "fp_valid", ".", "write", "(", "\n", "\"0 \"", "+", "\"valid_\"", "+", "userid", "+", "\" \"", "+", "negs", "[", "i", "]", "+", "\"%\"", "+", "str", "(", "sess_id", ")", "+", "\"\\n\"", "\n", ")", "\n", "", "", "fp_valid", ".", "close", "(", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "valid_file_path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Validation file {valid_file_path} successfully generated\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"Error when generating {valid_file_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.get_user_history": [[186, 208], ["open", "open.close", "os.path.isfile", "open.write", "open.write", "logger.info", "FileNotFoundError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close"], ["", "", "def", "get_user_history", "(", "train_history", ",", "valid_history", ",", "user_history_path", ")", ":", "\n", "    ", "\"\"\"Generate user history file.\n\n    Args:\n        train_history (list): Train history.\n        valid_history (list): Validation history\n        user_history_path (str): Path to file.\n    \"\"\"", "\n", "fp_user_history", "=", "open", "(", "user_history_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "userid", "in", "train_history", ":", "\n", "        ", "fp_user_history", ".", "write", "(", "\n", "\"train_\"", "+", "userid", "+", "\" \"", "+", "\",\"", ".", "join", "(", "train_history", "[", "userid", "]", ")", "+", "\"\\n\"", "\n", ")", "\n", "", "for", "userid", "in", "valid_history", ":", "\n", "        ", "fp_user_history", ".", "write", "(", "\n", "\"valid_\"", "+", "userid", "+", "\" \"", "+", "\",\"", ".", "join", "(", "valid_history", "[", "userid", "]", ")", "+", "\"\\n\"", "\n", ")", "\n", "", "fp_user_history", ".", "close", "(", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "user_history_path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"User history file {user_history_path} successfully generated\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"Error when generating {user_history_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind._read_news": [[210, 222], ["open", "f.readlines", "line.strip().split", "tokenizer.tokenize", "json.loads", "splitted[].lower", "news_entities[].append", "line.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "_read_news", "(", "filepath", ",", "news_words", ",", "news_entities", ",", "tokenizer", ")", ":", "\n", "    ", "with", "open", "(", "filepath", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "for", "line", "in", "lines", ":", "\n", "        ", "splitted", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "news_words", "[", "splitted", "[", "0", "]", "]", "=", "tokenizer", ".", "tokenize", "(", "splitted", "[", "3", "]", ".", "lower", "(", ")", ")", "\n", "news_entities", "[", "splitted", "[", "0", "]", "]", "=", "[", "]", "\n", "for", "entity", "in", "json", ".", "loads", "(", "splitted", "[", "6", "]", ")", ":", "\n", "            ", "news_entities", "[", "splitted", "[", "0", "]", "]", ".", "append", "(", "\n", "(", "entity", "[", "\"SurfaceForms\"", "]", ",", "entity", "[", "\"WikidataId\"", "]", ")", "\n", ")", "\n", "", "", "return", "news_words", ",", "news_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.get_words_and_entities": [[224, 244], ["nltk.tokenize.RegexpTokenizer", "mind._read_news", "mind._read_news"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind._read_news", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind._read_news"], ["", "def", "get_words_and_entities", "(", "train_news", ",", "valid_news", ")", ":", "\n", "    ", "\"\"\"Load words and entities\n\n    Args:\n        train_news (str): News train file.\n        valid_news (str): News validation file.\n\n    Returns:\n        dict, dict: Words and entities dictionaries.\n    \"\"\"", "\n", "news_words", "=", "{", "}", "\n", "news_entities", "=", "{", "}", "\n", "tokenizer", "=", "RegexpTokenizer", "(", "r\"\\w+\"", ")", "\n", "news_words", ",", "news_entities", "=", "_read_news", "(", "\n", "train_news", ",", "news_words", ",", "news_entities", ",", "tokenizer", "\n", ")", "\n", "news_words", ",", "news_entities", "=", "_read_news", "(", "\n", "valid_news", ",", "news_words", ",", "news_entities", ",", "tokenizer", "\n", ")", "\n", "return", "news_words", ",", "news_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_and_extract_glove": [[246, 260], ["recommenders.datasets.download_utils.maybe_download", "os.path.join", "recommenders.datasets.download_utils.unzip_file"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.unzip_file"], ["", "def", "download_and_extract_glove", "(", "dest_path", ")", ":", "\n", "    ", "\"\"\"Download and extract the Glove embedding\n\n    Args:\n        dest_path (str): Destination directory path for the downloaded file\n\n    Returns:\n        str: File path where Glove was extracted.\n    \"\"\"", "\n", "url", "=", "\"http://nlp.stanford.edu/data/glove.6B.zip\"", "\n", "filepath", "=", "maybe_download", "(", "url", "=", "url", ",", "work_directory", "=", "dest_path", ")", "\n", "glove_path", "=", "os", ".", "path", ".", "join", "(", "dest_path", ",", "\"glove\"", ")", "\n", "unzip_file", "(", "filepath", ",", "glove_path", ",", "clean_zip_file", "=", "False", ")", "\n", "return", "glove_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.generate_embeddings": [[262, 395], ["logger.info", "mind.download_and_extract_glove", "set", "logger.info", "open", "open.close", "logger.info", "open", "open.close", "logger.info", "open", "open.close", "logger.info", "logger.info", "numpy.zeros", "logger.info", "numpy.zeros", "os.path.join", "logger.info", "open", "os.path.join", "logger.info", "numpy.save", "os.path.join", "logger.info", "numpy.save", "ValueError", "os.path.join", "line.split", "set.add", "numpy.asarray", "line.split", "numpy.asarray", "line.split", "numpy.asarray", "range", "open.write", "str", "list", "list", "list", "len", "map", "map", "map", "range", "range", "str", "str", "surface.split", "list", "map", "surface_word.lower", "list", "map"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_and_extract_glove", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "generate_embeddings", "(", "\n", "data_path", ",", "\n", "news_words", ",", "\n", "news_entities", ",", "\n", "train_entities", ",", "\n", "valid_entities", ",", "\n", "max_sentence", "=", "10", ",", "\n", "word_embedding_dim", "=", "100", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Generate embeddings.\n\n    Args:\n        data_path (str): Data path.\n        news_words (dict): News word dictionary.\n        news_entities (dict): News entity dictionary.\n        train_entities (str): Train entity file.\n        valid_entities (str): Validation entity file.\n        max_sentence (int): Max sentence size.\n        word_embedding_dim (int): Word embedding dimension.\n\n    Returns:\n        str, str, str: File paths to news, word and entity embeddings.\n    \"\"\"", "\n", "embedding_dimensions", "=", "[", "50", ",", "100", ",", "200", ",", "300", "]", "\n", "if", "word_embedding_dim", "not", "in", "embedding_dimensions", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Wrong embedding dimension, available options are {embedding_dimensions}\"", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Downloading glove...\"", ")", "\n", "glove_path", "=", "download_and_extract_glove", "(", "data_path", ")", "\n", "\n", "word_set", "=", "set", "(", ")", "\n", "word_embedding_dict", "=", "{", "}", "\n", "entity_embedding_dict", "=", "{", "}", "\n", "\n", "logger", ".", "info", "(", "f\"Loading glove with embedding dimension {word_embedding_dim}...\"", ")", "\n", "glove_file", "=", "\"glove.6B.\"", "+", "str", "(", "word_embedding_dim", ")", "+", "\"d.txt\"", "\n", "fp_pretrain_vec", "=", "open", "(", "os", ".", "path", ".", "join", "(", "glove_path", ",", "glove_file", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "line", "in", "fp_pretrain_vec", ":", "\n", "        ", "linesplit", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "word_set", ".", "add", "(", "linesplit", "[", "0", "]", ")", "\n", "word_embedding_dict", "[", "linesplit", "[", "0", "]", "]", "=", "np", ".", "asarray", "(", "list", "(", "map", "(", "float", ",", "linesplit", "[", "1", ":", "]", ")", ")", ")", "\n", "", "fp_pretrain_vec", ".", "close", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Reading train entities...\"", ")", "\n", "fp_entity_vec_train", "=", "open", "(", "train_entities", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "line", "in", "fp_entity_vec_train", ":", "\n", "        ", "linesplit", "=", "line", ".", "split", "(", ")", "\n", "entity_embedding_dict", "[", "linesplit", "[", "0", "]", "]", "=", "np", ".", "asarray", "(", "\n", "list", "(", "map", "(", "float", ",", "linesplit", "[", "1", ":", "]", ")", ")", "\n", ")", "\n", "", "fp_entity_vec_train", ".", "close", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Reading valid entities...\"", ")", "\n", "fp_entity_vec_valid", "=", "open", "(", "valid_entities", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "line", "in", "fp_entity_vec_valid", ":", "\n", "        ", "linesplit", "=", "line", ".", "split", "(", ")", "\n", "entity_embedding_dict", "[", "linesplit", "[", "0", "]", "]", "=", "np", ".", "asarray", "(", "\n", "list", "(", "map", "(", "float", ",", "linesplit", "[", "1", ":", "]", ")", ")", "\n", ")", "\n", "", "fp_entity_vec_valid", ".", "close", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Generating word and entity indexes...\"", ")", "\n", "word_dict", "=", "{", "}", "\n", "word_index", "=", "1", "\n", "news_word_string_dict", "=", "{", "}", "\n", "news_entity_string_dict", "=", "{", "}", "\n", "entity2index", "=", "{", "}", "\n", "entity_index", "=", "1", "\n", "for", "doc_id", "in", "news_words", ":", "\n", "        ", "news_word_string_dict", "[", "doc_id", "]", "=", "[", "0", "for", "n", "in", "range", "(", "max_sentence", ")", "]", "\n", "news_entity_string_dict", "[", "doc_id", "]", "=", "[", "0", "for", "n", "in", "range", "(", "max_sentence", ")", "]", "\n", "surfaceform_entityids", "=", "news_entities", "[", "doc_id", "]", "\n", "for", "item", "in", "surfaceform_entityids", ":", "\n", "            ", "if", "item", "[", "1", "]", "not", "in", "entity2index", "and", "item", "[", "1", "]", "in", "entity_embedding_dict", ":", "\n", "                ", "entity2index", "[", "item", "[", "1", "]", "]", "=", "entity_index", "\n", "entity_index", "=", "entity_index", "+", "1", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "news_words", "[", "doc_id", "]", ")", ")", ":", "\n", "            ", "if", "news_words", "[", "doc_id", "]", "[", "i", "]", "in", "word_embedding_dict", ":", "\n", "                ", "if", "news_words", "[", "doc_id", "]", "[", "i", "]", "not", "in", "word_dict", ":", "\n", "                    ", "word_dict", "[", "news_words", "[", "doc_id", "]", "[", "i", "]", "]", "=", "word_index", "\n", "word_index", "=", "word_index", "+", "1", "\n", "news_word_string_dict", "[", "doc_id", "]", "[", "i", "]", "=", "word_dict", "[", "news_words", "[", "doc_id", "]", "[", "i", "]", "]", "\n", "", "else", ":", "\n", "                    ", "news_word_string_dict", "[", "doc_id", "]", "[", "i", "]", "=", "word_dict", "[", "news_words", "[", "doc_id", "]", "[", "i", "]", "]", "\n", "", "for", "item", "in", "surfaceform_entityids", ":", "\n", "                    ", "for", "surface", "in", "item", "[", "0", "]", ":", "\n", "                        ", "for", "surface_word", "in", "surface", ".", "split", "(", "\" \"", ")", ":", "\n", "                            ", "if", "news_words", "[", "doc_id", "]", "[", "i", "]", "==", "surface_word", ".", "lower", "(", ")", ":", "\n", "                                ", "if", "item", "[", "1", "]", "in", "entity_embedding_dict", ":", "\n", "                                    ", "news_entity_string_dict", "[", "doc_id", "]", "[", "i", "]", "=", "entity2index", "[", "\n", "item", "[", "1", "]", "\n", "]", "\n", "", "", "", "", "", "", "if", "i", "==", "max_sentence", "-", "1", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "logger", ".", "info", "(", "\"Generating word embeddings...\"", ")", "\n", "word_embeddings", "=", "np", ".", "zeros", "(", "[", "word_index", ",", "word_embedding_dim", "]", ")", "\n", "for", "word", "in", "word_dict", ":", "\n", "        ", "word_embeddings", "[", "word_dict", "[", "word", "]", "]", "=", "word_embedding_dict", "[", "word", "]", "\n", "\n", "", "logger", ".", "info", "(", "\"Generating entity embeddings...\"", ")", "\n", "entity_embeddings", "=", "np", ".", "zeros", "(", "[", "entity_index", ",", "word_embedding_dim", "]", ")", "\n", "for", "entity", "in", "entity2index", ":", "\n", "        ", "entity_embeddings", "[", "entity2index", "[", "entity", "]", "]", "=", "entity_embedding_dict", "[", "entity", "]", "\n", "\n", "", "news_feature_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"doc_feature.txt\"", ")", "\n", "logger", ".", "info", "(", "f\"Saving word and entity features in {news_feature_path}\"", ")", "\n", "fp_doc_string", "=", "open", "(", "news_feature_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "doc_id", "in", "news_word_string_dict", ":", "\n", "        ", "fp_doc_string", ".", "write", "(", "\n", "doc_id", "\n", "+", "\" \"", "\n", "+", "\",\"", ".", "join", "(", "list", "(", "map", "(", "str", ",", "news_word_string_dict", "[", "doc_id", "]", ")", ")", ")", "\n", "+", "\" \"", "\n", "+", "\",\"", ".", "join", "(", "list", "(", "map", "(", "str", ",", "news_entity_string_dict", "[", "doc_id", "]", ")", ")", ")", "\n", "+", "\"\\n\"", "\n", ")", "\n", "\n", "", "word_embeddings_path", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"word_embeddings_5w_\"", "+", "str", "(", "word_embedding_dim", ")", "+", "\".npy\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Saving word embeddings in {word_embeddings_path}\"", ")", "\n", "np", ".", "save", "(", "word_embeddings_path", ",", "word_embeddings", ")", "\n", "\n", "entity_embeddings_path", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"entity_embeddings_5w_\"", "+", "str", "(", "word_embedding_dim", ")", "+", "\".npy\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Saving word embeddings in {entity_embeddings_path}\"", ")", "\n", "np", ".", "save", "(", "entity_embeddings_path", ",", "entity_embeddings", ")", "\n", "\n", "return", "news_feature_path", ",", "word_embeddings_path", ",", "entity_embeddings_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.load_glove_matrix": [[397, 424], ["numpy.zeros", "open", "tqdm.tqdm", "os.path.join", "l.split.split", "l[].decode", "len", "len", "numpy.array", "exist_word.append", "float"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "load_glove_matrix", "(", "path_emb", ",", "word_dict", ",", "word_embedding_dim", ")", ":", "\n", "    ", "\"\"\"Load pretrained embedding metrics of words in word_dict\n\n    Args:\n        path_emb (string): Folder path of downloaded glove file\n        word_dict (dict): word dictionary\n        word_embedding_dim: dimention of word embedding vectors\n\n    Returns:\n        numpy.ndarray, list: pretrained word embedding metrics, words can be found in glove files\n    \"\"\"", "\n", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word_dict", ")", "+", "1", ",", "word_embedding_dim", ")", ")", "\n", "exist_word", "=", "[", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_emb", ",", "f\"glove.6B.{word_embedding_dim}d.txt\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "tqdm", "(", "f", ")", ":", "# noqa: E741 ambiguous variable name 'l'", "\n", "            ", "l", "=", "l", ".", "split", "(", ")", "# noqa: E741 ambiguous variable name 'l'", "\n", "word", "=", "l", "[", "0", "]", ".", "decode", "(", ")", "\n", "if", "len", "(", "word", ")", "!=", "0", ":", "\n", "                ", "if", "word", "in", "word_dict", ":", "\n", "                    ", "wordvec", "=", "[", "float", "(", "x", ")", "for", "x", "in", "l", "[", "1", ":", "]", "]", "\n", "index", "=", "word_dict", "[", "word", "]", "\n", "embedding_matrix", "[", "index", "]", "=", "np", ".", "array", "(", "wordvec", ")", "\n", "exist_word", ".", "append", "(", "word", ")", "\n", "\n", "", "", "", "", "return", "embedding_matrix", ",", "exist_word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.word_tokenize": [[426, 442], ["re.compile", "isinstance", "re.compile.findall", "sent.lower"], "function", ["None"], ["", "def", "word_tokenize", "(", "sent", ")", ":", "\n", "    ", "\"\"\"Tokenize a sententence\n\n    Args:\n        sent: the sentence need to be tokenized\n\n    Returns:\n        list: words in the sentence\n    \"\"\"", "\n", "\n", "# treat consecutive words or special punctuation as words", "\n", "pat", "=", "re", ".", "compile", "(", "r\"[\\w]+|[.,!?;|]\"", ")", "\n", "if", "isinstance", "(", "sent", ",", "str", ")", ":", "\n", "        ", "return", "pat", ".", "findall", "(", "sent", ".", "lower", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.get_session": [[18, 35], ["requests.Session"], "function", ["None"], ["def", "get_session", "(", "session", "=", "None", ")", ":", "\n", "    ", "\"\"\"Get session object\n\n    Args:\n        session (requests.Session): request session object\n\n    Returns:\n        requests.Session: request session object\n    \"\"\"", "\n", "\n", "if", "session", "is", "None", ":", "\n", "        ", "global", "SESSION", "\n", "if", "SESSION", "is", "None", ":", "\n", "            ", "SESSION", "=", "requests", ".", "Session", "(", ")", "\n", "", "session", "=", "SESSION", "\n", "\n", "", "return", "session", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.find_wikidata_id": [[37, 88], ["retrying.retry", "wikidata.get_session", "dict", "dict", "get_session.get", "get_session.get", "bytes", "logger.error", "logger.error", "session.get.json", "str", "session.get.json"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.get_session", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["", "@", "retry", "(", "wait_random_min", "=", "1000", ",", "wait_random_max", "=", "5000", ",", "stop_max_attempt_number", "=", "5", ")", "\n", "def", "find_wikidata_id", "(", "name", ",", "limit", "=", "1", ",", "session", "=", "None", ")", ":", "\n", "    ", "\"\"\"Find the entity ID in wikidata from a title string.\n\n    Args:\n        name (str): A string with search terms (eg. \"Batman (1989) film\")\n        limit (int): Number of results to return\n        session (requests.Session): requests session to reuse connections\n\n    Returns:\n        str: wikidata entityID corresponding to the title string. 'entityNotFound' will be returned if no page is found\n    \"\"\"", "\n", "\n", "session", "=", "get_session", "(", "session", "=", "session", ")", "\n", "\n", "params", "=", "dict", "(", "\n", "action", "=", "\"query\"", ",", "\n", "list", "=", "\"search\"", ",", "\n", "srsearch", "=", "bytes", "(", "name", ",", "encoding", "=", "\"utf8\"", ")", ",", "\n", "srlimit", "=", "limit", ",", "\n", "srprop", "=", "\"\"", ",", "\n", "format", "=", "\"json\"", ",", "\n", ")", "\n", "\n", "try", ":", "\n", "        ", "response", "=", "session", ".", "get", "(", "API_URL_WIKIPEDIA", ",", "params", "=", "params", ")", "\n", "page_id", "=", "response", ".", "json", "(", ")", "[", "\"query\"", "]", "[", "\"search\"", "]", "[", "0", "]", "[", "\"pageid\"", "]", "\n", "", "except", "Exception", ":", "\n", "# TODO: distinguish between connection error and entity not found", "\n", "        ", "logger", ".", "error", "(", "\"ENTITY NOT FOUND\"", ")", "\n", "return", "\"entityNotFound\"", "\n", "\n", "", "params", "=", "dict", "(", "\n", "action", "=", "\"query\"", ",", "\n", "prop", "=", "\"pageprops\"", ",", "\n", "ppprop", "=", "\"wikibase_item\"", ",", "\n", "pageids", "=", "[", "page_id", "]", ",", "\n", "format", "=", "\"json\"", ",", "\n", ")", "\n", "\n", "try", ":", "\n", "        ", "response", "=", "session", ".", "get", "(", "API_URL_WIKIPEDIA", ",", "params", "=", "params", ")", "\n", "entity_id", "=", "response", ".", "json", "(", ")", "[", "\"query\"", "]", "[", "\"pages\"", "]", "[", "str", "(", "page_id", ")", "]", "[", "\"pageprops\"", "]", "[", "\n", "\"wikibase_item\"", "\n", "]", "\n", "", "except", "Exception", ":", "\n", "# TODO: distinguish between connection error and entity not found", "\n", "        ", "logger", ".", "error", "(", "\"ENTITY NOT FOUND\"", ")", "\n", "return", "\"entityNotFound\"", "\n", "\n", "", "return", "entity_id", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_links": [[90, 146], ["retrying.retry", "wikidata.get_session", "get_session.get().json", "logger.error", "get_session.get", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.get_session", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["", "@", "retry", "(", "wait_random_min", "=", "1000", ",", "wait_random_max", "=", "5000", ",", "stop_max_attempt_number", "=", "5", ")", "\n", "def", "query_entity_links", "(", "entity_id", ",", "session", "=", "None", ")", ":", "\n", "    ", "\"\"\"Query all linked pages from a wikidata entityID\n\n    Args:\n        entity_id (str): A wikidata entity ID\n        session (requests.Session): requests session to reuse connections\n\n    Returns:\n        json: Dictionary with linked pages.\n    \"\"\"", "\n", "query", "=", "(", "\n", "\"\"\"\n    PREFIX entity: <http://www.wikidata.org/entity/>\n    #partial results\n\n    SELECT ?propUrl ?propLabel ?valUrl ?valLabel\n    WHERE\n    {\n        hint:Query hint:optimizer 'None' .\n        {\tBIND(entity:\"\"\"", "\n", "+", "entity_id", "\n", "+", "\"\"\" AS ?valUrl) .\n            BIND(\"N/A\" AS ?propUrl ) .\n            BIND(\"identity\"@en AS ?propLabel ) .\n        }\n        UNION\n        {\tentity:\"\"\"", "\n", "+", "entity_id", "\n", "+", "\"\"\" ?propUrl ?valUrl .\n            ?property ?ref ?propUrl .\n            ?property rdf:type wikibase:Property .\n            ?property rdfs:label ?propLabel\n        }\n\n        ?valUrl rdfs:label ?valLabel\n        FILTER (LANG(?valLabel) = 'en') .\n        OPTIONAL{ ?valUrl wdt:P18 ?picture .}\n        FILTER (lang(?propLabel) = 'en' )\n    }\n    ORDER BY ?propUrl ?valUrl\n    LIMIT 500\n    \"\"\"", "\n", ")", "\n", "\n", "session", "=", "get_session", "(", "session", "=", "session", ")", "\n", "\n", "try", ":", "\n", "        ", "data", "=", "session", ".", "get", "(", "\n", "API_URL_WIKIDATA", ",", "params", "=", "dict", "(", "query", "=", "query", ",", "format", "=", "\"json\"", ")", "\n", ")", ".", "json", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "# noqa: F841", "\n", "        ", "logger", ".", "error", "(", "\"ENTITY NOT FOUND\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.read_linked_entities": [[148, 166], ["c.get().get().replace", "c.get().get", "data.get().get", "c.get().get", "c.get", "data.get", "c.get"], "function", ["None"], ["", "def", "read_linked_entities", "(", "data", ")", ":", "\n", "    ", "\"\"\"Obtain lists of liken entities (IDs and names) from dictionary\n\n    Args:\n        data (json): dictionary with linked pages\n\n    Returns:\n        list, list:\n        - List of liked entityIDs.\n        - List of liked entity names.\n    \"\"\"", "\n", "\n", "return", "[", "\n", "(", "\n", "c", ".", "get", "(", "\"valUrl\"", ")", ".", "get", "(", "\"value\"", ")", ".", "replace", "(", "\"http://www.wikidata.org/entity/\"", ",", "\"\"", ")", ",", "\n", "c", ".", "get", "(", "\"valLabel\"", ")", ".", "get", "(", "\"value\"", ")", ",", "\n", ")", "\n", "for", "c", "in", "data", ".", "get", "(", "\"results\"", ",", "{", "}", ")", ".", "get", "(", "\"bindings\"", ",", "[", "]", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_description": [[169, 207], ["retrying.retry", "wikidata.get_session", "get_session.get", "logger.error", "dict", "session.get.json"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.get_session", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["", "@", "retry", "(", "wait_random_min", "=", "1000", ",", "wait_random_max", "=", "5000", ",", "stop_max_attempt_number", "=", "5", ")", "\n", "def", "query_entity_description", "(", "entity_id", ",", "session", "=", "None", ")", ":", "\n", "    ", "\"\"\"Query entity wikidata description from entityID\n\n    Args:\n        entity_id (str): A wikidata page ID.\n        session (requests.Session): requests session to reuse connections\n\n    Returns:\n        str: Wikidata short description of the entityID\n        descriptionNotFound' will be returned if no description is found\n    \"\"\"", "\n", "query", "=", "(", "\n", "\"\"\"\n    PREFIX wd: <http://www.wikidata.org/entity/>\n    PREFIX schema: <http://schema.org/>\n\n    SELECT ?o\n    WHERE\n    {\n      wd:\"\"\"", "\n", "+", "entity_id", "\n", "+", "\"\"\" schema:description ?o.\n      FILTER ( lang(?o) = \"en\" )\n    }\n    \"\"\"", "\n", ")", "\n", "\n", "session", "=", "get_session", "(", "session", "=", "session", ")", "\n", "\n", "try", ":", "\n", "        ", "r", "=", "session", ".", "get", "(", "API_URL_WIKIDATA", ",", "params", "=", "dict", "(", "query", "=", "query", ",", "format", "=", "\"json\"", ")", ")", "\n", "description", "=", "r", ".", "json", "(", ")", "[", "\"results\"", "]", "[", "\"bindings\"", "]", "[", "0", "]", "[", "\"o\"", "]", "[", "\"value\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "# noqa: F841", "\n", "        ", "logger", ".", "error", "(", "\"DESCRIPTION NOT FOUND\"", ")", "\n", "return", "\"descriptionNotFound\"", "\n", "\n", "", "return", "description", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.search_wikidata": [[209, 251], ["enumerate", "pandas.DataFrame", "wikidata.find_wikidata_id", "wikidata.query_entity_links", "wikidata.read_linked_entities", "print", "wikidata.query_entity_description", "dict", "results.append", "extras.items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.find_wikidata_id", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_links", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.read_linked_entities", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_description", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "search_wikidata", "(", "names", ",", "extras", "=", "None", ",", "describe", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create DataFrame of Wikidata search results\n\n    Args:\n        names (list[str]): List of names to search for\n        extras (dict(str: list)): Optional extra items to assign to results for corresponding name\n        describe (bool): Optional flag to include description of entity\n        verbose (bool): Optional flag to print out intermediate data\n\n    Returns:\n        pandas.DataFrame: Wikipedia results for all names with found entities\n\n    \"\"\"", "\n", "\n", "results", "=", "[", "]", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "        ", "entity_id", "=", "find_wikidata_id", "(", "name", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"name: {name}, entity_id: {id}\"", ".", "format", "(", "name", "=", "name", ",", "id", "=", "entity_id", ")", ")", "\n", "\n", "", "if", "entity_id", "==", "\"entityNotFound\"", ":", "\n", "            ", "continue", "\n", "\n", "", "json_links", "=", "query_entity_links", "(", "entity_id", ")", "\n", "related_links", "=", "read_linked_entities", "(", "json_links", ")", "\n", "description", "=", "query_entity_description", "(", "entity_id", ")", "if", "describe", "else", "\"\"", "\n", "\n", "for", "related_entity", ",", "related_name", "in", "related_links", ":", "\n", "            ", "result", "=", "dict", "(", "\n", "name", "=", "name", ",", "\n", "original_entity", "=", "entity_id", ",", "\n", "linked_entities", "=", "related_entity", ",", "\n", "name_linked_entities", "=", "related_name", ",", "\n", ")", "\n", "if", "describe", ":", "\n", "                ", "result", "[", "\"description\"", "]", "=", "description", "\n", "", "if", "extras", "is", "not", "None", ":", "\n", "                ", "for", "field", ",", "lst", "in", "extras", ".", "items", "(", ")", ":", "\n", "                    ", "result", "[", "field", "]", "=", "lst", "[", "idx", "]", "\n", "", "", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "return", "pd", ".", "DataFrame", "(", "results", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df": [[9, 37], ["pandas.read_csv"], "function", ["None"], ["def", "load_pandas_df", "(", "\n", "azure_storage_account_name", "=", "\"azureopendatastorage\"", ",", "\n", "azure_storage_sas_token", "=", "\"\"", ",", "\n", "container_name", "=", "\"covid19temp\"", ",", "\n", "metadata_filename", "=", "\"metadata.csv\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads the Azure Open Research COVID-19 dataset as a pd.DataFrame.\n\n    The Azure COVID-19 Open Research Dataset may be found at https://azure.microsoft.com/en-us/services/open-datasets/catalog/covid-19-open-research/\n\n    Args:\n        azure_storage_account_name (str): Azure storage account name.\n        azure_storage_sas_token (str): Azure storage SAS token.\n        container_name (str): Azure storage container name.\n        metadata_filename (str): Name of file containing top-level metadata for the dataset.\n\n    Returns:\n        metadata (pandas.DataFrame): Metadata dataframe.\n    \"\"\"", "\n", "\n", "# Load into dataframe", "\n", "uri", "=", "\"https://{acct}.blob.core.windows.net/{container}/{filename}{sas}\"", ".", "format", "(", "\n", "acct", "=", "azure_storage_account_name", ",", "\n", "container", "=", "container_name", ",", "\n", "filename", "=", "metadata_filename", ",", "\n", "sas", "=", "azure_storage_sas_token", ",", "\n", ")", "\n", "return", "pd", ".", "read_csv", "(", "uri", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_duplicates": [[39, 61], ["df.drop.reset_index", "df.drop.drop", "numpy.where", "df.drop.duplicated"], "function", ["None"], ["", "def", "remove_duplicates", "(", "df", ",", "cols", ")", ":", "\n", "    ", "\"\"\"Remove duplicated entries.\n\n    Args:\n        df (pd.DataFrame): Pandas dataframe.\n        cols (list of str): Name of columns in which to look for duplicates.\n\n    Returns:\n        df (pandas.DataFrame): Pandas dataframe with duplicate rows dropped.\n\n    \"\"\"", "\n", "for", "col", "in", "cols", ":", "\n", "# Reset index", "\n", "        ", "df", "=", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# Find where the identifier variable is duplicated", "\n", "dup_rows", "=", "np", ".", "where", "(", "df", ".", "duplicated", "(", "[", "col", "]", ")", ")", "[", "0", "]", "\n", "\n", "# Drop duplicated rows", "\n", "df", "=", "df", ".", "drop", "(", "dup_rows", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_nan": [[63, 82], ["df[].replace", "df[].notna"], "function", ["None"], ["", "def", "remove_nan", "(", "df", ",", "cols", ")", ":", "\n", "    ", "\"\"\"Remove rows with NaN values in specified column.\n\n    Args:\n        df (pandas.DataFrame): Pandas dataframe.\n        cols (list of str): Name of columns in which to look for NaN.\n\n    Returns:\n        df (pandas.DataFrame): Pandas dataframe with invalid rows dropped.\n\n    \"\"\"", "\n", "for", "col", "in", "cols", ":", "\n", "# Convert any empty string cells to nan", "\n", "        ", "df", "[", "col", "]", ".", "replace", "(", "\"\"", ",", "np", ".", "nan", ",", "inplace", "=", "True", ")", "\n", "\n", "# Remove NaN rows", "\n", "df", "=", "df", "[", "df", "[", "col", "]", ".", "notna", "(", ")", "]", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.clean_dataframe": [[84, 103], ["covid_utils.remove_duplicates", "covid_utils.remove_nan"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_duplicates", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_nan"], ["", "def", "clean_dataframe", "(", "df", ")", ":", "\n", "    ", "\"\"\"Clean up the dataframe.\n\n    Args:\n        df (pandas.DataFrame): Pandas dataframe.\n\n    Returns:\n        df (pandas.DataFrame): Cleaned pandas dataframe.\n    \"\"\"", "\n", "\n", "# Remove duplicated rows", "\n", "cols", "=", "[", "\"cord_uid\"", ",", "\"doi\"", "]", "\n", "df", "=", "remove_duplicates", "(", "df", ",", "cols", ")", "\n", "\n", "# Remove rows without values in specified columns", "\n", "cols", "=", "[", "\"cord_uid\"", ",", "\"doi\"", ",", "\"title\"", ",", "\"license\"", ",", "\"url\"", "]", "\n", "df", "=", "remove_nan", "(", "df", ",", "cols", ")", "\n", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.retrieve_text": [[105, 141], ["requests.get().json", "requests.get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["", "def", "retrieve_text", "(", "\n", "entry", ",", "\n", "container_name", ",", "\n", "azure_storage_account_name", "=", "\"azureopendatastorage\"", ",", "\n", "azure_storage_sas_token", "=", "\"\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Retrieve body text from article of interest.\n\n    Args:\n        entry (pd.Series): A single row from the dataframe (df.iloc[n]).\n        container_name (str): Azure storage container name.\n        azure_storage_account_name (str): Azure storage account name.\n        azure_storage_sas_token (str): Azure storage SAS token.\n\n    Results:\n        text (str): Full text of the blob as a single string.\n    \"\"\"", "\n", "\n", "try", ":", "\n", "        ", "filename", "=", "entry", "[", "\"pdf_json_files\"", "]", "or", "entry", "[", "\"pmc_json_files\"", "]", "\n", "\n", "# Extract text", "\n", "uri", "=", "\"https://{acct}.blob.core.windows.net/{container}/{filename}{sas}\"", ".", "format", "(", "\n", "acct", "=", "azure_storage_account_name", ",", "\n", "container", "=", "container_name", ",", "\n", "filename", "=", "filename", ",", "\n", "sas", "=", "azure_storage_sas_token", ",", "\n", ")", "\n", "\n", "data", "=", "requests", ".", "get", "(", "uri", ",", "headers", "=", "{", "\"Content-type\"", ":", "\"application/json\"", "}", ")", ".", "json", "(", ")", "\n", "text", "=", "\" \"", ".", "join", "(", "[", "paragraph", "[", "\"text\"", "]", "for", "paragraph", "in", "data", "[", "\"body_text\"", "]", "]", ")", "\n", "\n", "", "except", "Exception", ":", "\n", "        ", "text", "=", "\"\"", "\n", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.get_public_domain_text": [[143, 192], ["df.drop.reset_index", "df.drop.apply", "df.drop.drop", "df_full.reset_index.reset_index", "numpy.where", "covid_utils.retrieve_text"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.retrieve_text"], ["", "def", "get_public_domain_text", "(", "\n", "df", ",", "\n", "container_name", ",", "\n", "azure_storage_account_name", "=", "\"azureopendatastorage\"", ",", "\n", "azure_storage_sas_token", "=", "\"\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get all public domain text.\n\n    Args:\n        df (pandas.DataFrame): Metadata dataframe for public domain text.\n        container_name (str): Azure storage container name.\n        azure_storage_account_name (str): Azure storage account name.\n        azure_storage_sas_token (str): Azure storage SAS token.\n\n    Returns:\n        df_full (pandas.DataFrame): Dataframe with select metadata and full article text.\n    \"\"\"", "\n", "# reset index", "\n", "df", "=", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# Add in full_text", "\n", "df", "[", "\"full_text\"", "]", "=", "df", ".", "apply", "(", "\n", "lambda", "row", ":", "retrieve_text", "(", "\n", "row", ",", "container_name", ",", "azure_storage_account_name", ",", "azure_storage_sas_token", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "# Remove rows with empty full_text", "\n", "empty_rows", "=", "np", ".", "where", "(", "df", "[", "\"full_text\"", "]", "==", "\"\"", ")", "[", "0", "]", "\n", "df", "=", "df", ".", "drop", "(", "empty_rows", ")", "\n", "\n", "# Only keep columns of interest", "\n", "df_full", "=", "df", "[", "\n", "[", "\n", "\"cord_uid\"", ",", "\n", "\"doi\"", ",", "\n", "\"title\"", ",", "\n", "\"publish_time\"", ",", "\n", "\"authors\"", ",", "\n", "\"journal\"", ",", "\n", "\"url\"", ",", "\n", "\"abstract\"", ",", "\n", "\"full_text\"", ",", "\n", "]", "\n", "]", "\n", "df_full", "=", "df_full", ".", "reset_index", "(", ")", "\n", "\n", "return", "df_full", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.LibffmConverter.__init__": [[143, 149], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "        ", "self", ".", "filepath", "=", "filepath", "\n", "self", ".", "col_rating", "=", "None", "\n", "self", ".", "field_names", "=", "None", "\n", "self", ".", "field_count", "=", "None", "\n", "self", ".", "feature_count", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.LibffmConverter.fit": [[150, 181], ["list", "all", "TypeError", "TypeError", "df.drop", "numpy.issubdtype"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "df", ",", "col_rating", "=", "DEFAULT_RATING_COL", ")", ":", "\n", "        ", "\"\"\"Fit the dataframe for libffm format.\n        This method does nothing but check the validity of the input columns\n\n        Args:\n            df (pandas.DataFrame): input Pandas dataframe.\n            col_rating (str): rating of the data.\n\n        Return:\n            object: the instance of the converter\n        \"\"\"", "\n", "\n", "# Check column types.", "\n", "types", "=", "df", ".", "dtypes", "\n", "if", "not", "all", "(", "\n", "[", "\n", "x", "==", "object", "or", "np", ".", "issubdtype", "(", "x", ",", "np", ".", "integer", ")", "or", "x", "==", "np", ".", "float", "\n", "for", "x", "in", "types", "\n", "]", "\n", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input columns should be only object and/or numeric types.\"", ")", "\n", "\n", "", "if", "col_rating", "not", "in", "df", ".", "columns", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"Column of {} is not in input dataframe columns\"", ".", "format", "(", "col_rating", ")", "\n", ")", "\n", "\n", "", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "field_names", "=", "list", "(", "df", ".", "drop", "(", "col_rating", ",", "axis", "=", "1", ")", ".", "columns", ")", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.LibffmConverter.transform": [[182, 241], ["len", "enumerate", "column_names.insert", "ValueError", "all", "ValueError", "isinstance", "df[].apply", "numpy.savetxt", "pandas_df_utils.LibffmConverter.transform._convert"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Tranform an input dataset with the same schema (column names and dtypes) to libffm format\n        by using the fitted converter.\n\n        Args:\n            df (pandas.DataFrame): input Pandas dataframe.\n\n        Return:\n            pandas.DataFrame: Output libffm format dataframe.\n        \"\"\"", "\n", "if", "self", ".", "col_rating", "not", "in", "df", ".", "columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Input dataset does not contain the label column {} in the fitting dataset\"", ".", "format", "(", "\n", "self", ".", "col_rating", "\n", ")", "\n", ")", "\n", "\n", "", "if", "not", "all", "(", "[", "x", "in", "df", ".", "columns", "for", "x", "in", "self", ".", "field_names", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Not all columns in the input dataset appear in the fitting dataset\"", "\n", ")", "\n", "\n", "# Encode field-feature.", "\n", "", "idx", "=", "1", "\n", "self", ".", "field_feature_dict", "=", "{", "}", "\n", "for", "field", "in", "self", ".", "field_names", ":", "\n", "            ", "for", "feature", "in", "df", "[", "field", "]", ".", "values", ":", "\n", "# Check whether (field, feature) tuple exists in the dict or not.", "\n", "# If not, put them into the key-values of the dict and count the index.", "\n", "                ", "if", "(", "field", ",", "feature", ")", "not", "in", "self", ".", "field_feature_dict", ":", "\n", "                    ", "self", ".", "field_feature_dict", "[", "(", "field", ",", "feature", ")", "]", "=", "idx", "\n", "if", "df", "[", "field", "]", ".", "dtype", "==", "object", ":", "\n", "                        ", "idx", "+=", "1", "\n", "", "", "", "if", "df", "[", "field", "]", ".", "dtype", "!=", "object", ":", "\n", "                ", "idx", "+=", "1", "\n", "\n", "", "", "self", ".", "field_count", "=", "len", "(", "self", ".", "field_names", ")", "\n", "self", ".", "feature_count", "=", "idx", "-", "1", "\n", "\n", "def", "_convert", "(", "field", ",", "feature", ",", "field_index", ",", "field_feature_index_dict", ")", ":", "\n", "            ", "field_feature_index", "=", "field_feature_index_dict", "[", "(", "field", ",", "feature", ")", "]", "\n", "if", "isinstance", "(", "feature", ",", "str", ")", ":", "\n", "                ", "feature", "=", "1", "\n", "", "return", "\"{}:{}:{}\"", ".", "format", "(", "field_index", ",", "field_feature_index", ",", "feature", ")", "\n", "\n", "", "for", "col_index", ",", "col", "in", "enumerate", "(", "self", ".", "field_names", ")", ":", "\n", "            ", "df", "[", "col", "]", "=", "df", "[", "col", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "_convert", "(", "col", ",", "x", ",", "col_index", "+", "1", ",", "self", ".", "field_feature_dict", ")", "\n", ")", "\n", "\n", "# Move rating column to the first.", "\n", "", "column_names", "=", "self", ".", "field_names", "[", ":", "]", "\n", "column_names", ".", "insert", "(", "0", ",", "self", ".", "col_rating", ")", "\n", "df", "=", "df", "[", "column_names", "]", "\n", "\n", "if", "self", ".", "filepath", "is", "not", "None", ":", "\n", "            ", "np", ".", "savetxt", "(", "self", ".", "filepath", ",", "df", ".", "values", ",", "delimiter", "=", "\" \"", ",", "fmt", "=", "\"%s\"", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.LibffmConverter.fit_transform": [[242, 253], ["pandas_df_utils.LibffmConverter.fit().transform", "pandas_df_utils.LibffmConverter.fit"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "fit_transform", "(", "self", ",", "df", ",", "col_rating", "=", "DEFAULT_RATING_COL", ")", ":", "\n", "        ", "\"\"\"Do fit and transform in a row\n\n        Args:\n            df (pandas.DataFrame): input Pandas dataframe.\n            col_rating (str): rating of the data.\n\n        Return:\n            pandas.DataFrame: Output libffm format dataframe.\n        \"\"\"", "\n", "return", "self", ".", "fit", "(", "df", ",", "col_rating", "=", "col_rating", ")", ".", "transform", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.LibffmConverter.get_params": [[254, 264], ["None"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get parameters (attributes) of the libffm converter\n\n        Return:\n            dict: A dictionary that contains parameters field count, feature count, and file path.\n        \"\"\"", "\n", "return", "{", "\n", "\"field count\"", ":", "self", ".", "field_count", ",", "\n", "\"feature count\"", ":", "self", ".", "feature_count", ",", "\n", "\"file path\"", ":", "self", ".", "filepath", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.PandasHash.__init__": [[418, 428], ["isinstance", "TypeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pandas_object", ")", ":", "\n", "        ", "\"\"\"Initialize class\n\n        Args:\n            pandas_object (pandas.DataFrame|pandas.Series): pandas object\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "pandas_object", ",", "(", "pd", ".", "DataFrame", ",", "pd", ".", "Series", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Can only wrap pandas DataFrame or Series objects\"", ")", "\n", "", "self", ".", "pandas_object", "=", "pandas_object", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.PandasHash.__eq__": [[429, 440], ["hash", "hash"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Overwrite equality comparison\n\n        Args:\n            other (pandas.DataFrame|pandas.Series): pandas object to compare\n\n        Returns:\n            bool: whether other object is the same as this one\n        \"\"\"", "\n", "\n", "return", "hash", "(", "self", ")", "==", "hash", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.PandasHash.__hash__": [[441, 454], ["tuple", "isinstance", "hash", "pandas_df_utils.PandasHash.pandas_object.values.tobytes", "tuple", "tuple"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Overwrite hash operator for use with pandas objects\n\n        Returns:\n            int: hashed value of object\n        \"\"\"", "\n", "\n", "hashable", "=", "tuple", "(", "self", ".", "pandas_object", ".", "values", ".", "tobytes", "(", ")", ")", "\n", "if", "isinstance", "(", "self", ".", "pandas_object", ",", "pd", ".", "DataFrame", ")", ":", "\n", "            ", "hashable", "+=", "tuple", "(", "self", ".", "pandas_object", ".", "columns", ")", "\n", "", "else", ":", "\n", "            ", "hashable", "+=", "tuple", "(", "self", ".", "pandas_object", ".", "name", ")", "\n", "", "return", "hash", "(", "hashable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.user_item_pairs": [[20, 63], ["user_df.merge", "user_df.drop", "item_df.drop", "users_items.sample().reset_index.drop", "pandas_df_utils.filter_by", "users_items.sample().reset_index.sample().reset_index", "users_items.sample().reset_index.sample"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.filter_by", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["def", "user_item_pairs", "(", "\n", "user_df", ",", "\n", "item_df", ",", "\n", "user_col", "=", "DEFAULT_USER_COL", ",", "\n", "item_col", "=", "DEFAULT_ITEM_COL", ",", "\n", "user_item_filter_df", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get all pairs of users and items data.\n\n    Args:\n        user_df (pandas.DataFrame): User data containing unique user ids and maybe their features.\n        item_df (pandas.DataFrame): Item data containing unique item ids and maybe their features.\n        user_col (str): User id column name.\n        item_col (str): Item id column name.\n        user_item_filter_df (pd.DataFrame): User-item pairs to be used as a filter.\n        shuffle (bool): If True, shuffles the result.\n        seed (int): Random seed for shuffle\n\n    Returns:\n        pandas.DataFrame: All pairs of user-item from user_df and item_df, excepting the pairs in user_item_filter_df.\n    \"\"\"", "\n", "\n", "# Get all user-item pairs", "\n", "user_df", "[", "\"key\"", "]", "=", "1", "\n", "item_df", "[", "\"key\"", "]", "=", "1", "\n", "users_items", "=", "user_df", ".", "merge", "(", "item_df", ",", "on", "=", "\"key\"", ")", "\n", "\n", "user_df", ".", "drop", "(", "\"key\"", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "item_df", ".", "drop", "(", "\"key\"", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "users_items", ".", "drop", "(", "\"key\"", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "# Filter", "\n", "if", "user_item_filter_df", "is", "not", "None", ":", "\n", "        ", "users_items", "=", "filter_by", "(", "users_items", ",", "user_item_filter_df", ",", "[", "user_col", ",", "item_col", "]", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "users_items", "=", "users_items", ".", "sample", "(", "frac", "=", "1", ",", "random_state", "=", "seed", ")", ".", "reset_index", "(", "\n", "drop", "=", "True", "\n", ")", "\n", "\n", "", "return", "users_items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.filter_by": [[65, 82], ["df.set_index().index.isin", "filter_by_df.set_index", "df.set_index"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "def", "filter_by", "(", "df", ",", "filter_by_df", ",", "filter_by_cols", ")", ":", "\n", "    ", "\"\"\"From the input DataFrame `df`, remove the records whose target column `filter_by_cols` values are\n    exist in the filter-by DataFrame `filter_by_df`.\n\n    Args:\n        df (pandas.DataFrame): Source dataframe.\n        filter_by_df (pandas.DataFrame): Filter dataframe.\n        filter_by_cols (iterable of str): Filter columns.\n\n    Returns:\n        pandas.DataFrame: Dataframe filtered by `filter_by_df` on `filter_by_cols`.\n\n    \"\"\"", "\n", "\n", "return", "df", ".", "loc", "[", "\n", "~", "df", ".", "set_index", "(", "filter_by_cols", ")", ".", "index", ".", "isin", "(", "\n", "filter_by_df", ".", "set_index", "(", "filter_by_cols", ")", ".", "index", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler": [[267, 355], ["df[].unique", "numpy.random.default_rng", "df.copy", "df.copy.groupby().apply().reset_index().rename", "len", "max", "min", "np.random.default_rng.choice", "pandas.DataFrame", "pandas.concat", "round", "len", "numpy.setdiff1d", "df.copy.groupby().apply().reset_index", "df.copy.groupby().apply", "df.copy.groupby"], "function", ["None"], ["", "", "def", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_label", "=", "DEFAULT_LABEL_COL", ",", "\n", "col_feedback", "=", "\"feedback\"", ",", "\n", "ratio_neg_per_user", "=", "1", ",", "\n", "pos_value", "=", "1", ",", "\n", "neg_value", "=", "0", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Utility function to sample negative feedback from user-item interaction dataset.\n    This negative sampling function will take the user-item interaction data to create\n    binarized feedback, i.e., 1 and 0 indicate positive and negative feedback,\n    respectively.\n\n    Negative sampling is used in the literature frequently to generate negative samples\n    from a user-item interaction data.\n\n    See for example the `neural collaborative filtering paper <https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf>`_.\n\n    Args:\n        df (pandas.DataFrame): input data that contains user-item tuples.\n        col_user (str): user id column name.\n        col_item (str): item id column name.\n        col_label (str): label column name in df.\n        col_feedback (str): feedback column name in the returned data frame; it is used for the generated column\n            of positive and negative feedback.\n        ratio_neg_per_user (int): ratio of negative feedback w.r.t to the number of positive feedback for each user.\n            If the samples exceed the number of total possible negative feedback samples, it will be reduced to the\n            number of all the possible samples.\n        pos_value (float): value of positive feedback.\n        neg_value (float): value of negative feedback.\n        inplace (bool):\n        seed (int): seed for the random state of the sampling function.\n\n    Returns:\n        pandas.DataFrame: Data with negative feedback.\n\n    Examples:\n        >>> import pandas as pd\n        >>> df = pd.DataFrame({\n            'userID': [1, 2, 3],\n            'itemID': [1, 2, 3],\n            'rating': [5, 5, 5]\n        })\n        >>> df_neg_sampled = negative_feedback_sampler(\n            df, col_user='userID', col_item='itemID', ratio_neg_per_user=1\n        )\n        >>> df_neg_sampled\n        userID  itemID  feedback\n        1   1   1\n        1   2   0\n        2   2   1\n        2   1   0\n        3   3   1\n        3   1   0\n    \"\"\"", "\n", "# Get all of the users and items.", "\n", "items", "=", "df", "[", "col_item", "]", ".", "unique", "(", ")", "\n", "rng", "=", "np", ".", "random", ".", "default_rng", "(", "seed", "=", "seed", ")", "\n", "\n", "def", "sample_items", "(", "user_df", ")", ":", "\n", "# Sample negative items for the data frame restricted to a specific user", "\n", "        ", "n_u", "=", "len", "(", "user_df", ")", "\n", "neg_sample_size", "=", "max", "(", "round", "(", "n_u", "*", "ratio_neg_per_user", ")", ",", "1", ")", "\n", "# Draw (n_u + neg_sample_size) items and keep neg_sample_size of these", "\n", "# that are not already in user_df. This requires a set difference from items_sample", "\n", "# instead of items, which is more efficient when len(items) is large.", "\n", "sample_size", "=", "min", "(", "n_u", "+", "neg_sample_size", ",", "len", "(", "items", ")", ")", "\n", "items_sample", "=", "rng", ".", "choice", "(", "items", ",", "sample_size", ",", "replace", "=", "False", ")", "\n", "new_items", "=", "np", ".", "setdiff1d", "(", "items_sample", ",", "user_df", "[", "col_item", "]", ")", "[", ":", "neg_sample_size", "]", "\n", "new_df", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\n", "col_user", ":", "user_df", ".", "name", ",", "\n", "col_item", ":", "new_items", ",", "\n", "col_label", ":", "neg_value", ",", "\n", "}", "\n", ")", "\n", "return", "pd", ".", "concat", "(", "[", "user_df", ",", "new_df", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "res_df", "=", "df", ".", "copy", "(", ")", "\n", "res_df", "[", "col_label", "]", "=", "pos_value", "\n", "return", "(", "\n", "res_df", ".", "groupby", "(", "col_user", ")", "\n", ".", "apply", "(", "sample_items", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ".", "rename", "(", "columns", "=", "{", "col_label", ":", "col_feedback", "}", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns": [[358, 376], ["logger.error"], "function", ["None"], ["", "def", "has_columns", "(", "df", ",", "columns", ")", ":", "\n", "    ", "\"\"\"Check if DataFrame has necessary columns\n\n    Args:\n        df (pandas.DataFrame): DataFrame\n        columns (list(str): columns to check for\n\n    Returns:\n        bool: True if DataFrame has specified columns.\n    \"\"\"", "\n", "\n", "result", "=", "True", "\n", "for", "column", "in", "columns", ":", "\n", "        ", "if", "column", "not", "in", "df", ".", "columns", ":", "\n", "            ", "logger", ".", "error", "(", "\"Missing column: {} in DataFrame\"", ".", "format", "(", "column", ")", ")", "\n", "result", "=", "False", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype": [[378, 410], ["any", "set().symmetric_difference", "logger.error", "pandas_df_utils.has_columns", "pandas_df_utils.has_columns", "logger.error", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns"], ["", "def", "has_same_base_dtype", "(", "df_1", ",", "df_2", ",", "columns", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check if specified columns have the same base dtypes across both DataFrames\n\n    Args:\n        df_1 (pandas.DataFrame): first DataFrame\n        df_2 (pandas.DataFrame): second DataFrame\n        columns (list(str)): columns to check, None checks all columns\n\n    Returns:\n        bool: True if DataFrames columns have the same base dtypes.\n    \"\"\"", "\n", "\n", "if", "columns", "is", "None", ":", "\n", "        ", "if", "any", "(", "set", "(", "df_1", ".", "columns", ")", ".", "symmetric_difference", "(", "set", "(", "df_2", ".", "columns", ")", ")", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Cannot test all columns because they are not all shared across DataFrames\"", "\n", ")", "\n", "return", "False", "\n", "", "columns", "=", "df_1", ".", "columns", "\n", "\n", "", "if", "not", "(", "\n", "has_columns", "(", "df", "=", "df_1", ",", "columns", "=", "columns", ")", "and", "has_columns", "(", "df", "=", "df_2", ",", "columns", "=", "columns", ")", "\n", ")", ":", "\n", "        ", "return", "False", "\n", "\n", "", "result", "=", "True", "\n", "for", "column", "in", "columns", ":", "\n", "        ", "if", "df_1", "[", "column", "]", ".", "dtype", ".", "type", ".", "__base__", "!=", "df_2", "[", "column", "]", ".", "dtype", ".", "type", ".", "__base__", ":", "\n", "            ", "logger", ".", "error", "(", "\"Columns {} do not have the same base datatype\"", ".", "format", "(", "column", ")", ")", "\n", "result", "=", "False", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df": [[456, 499], ["functools.wraps", "functools.lru_cache", "isinstance", "pandas_df_utils.PandasHash", "isinstance", "tuple", "cached_wrapper"], "function", ["None"], ["", "", "def", "lru_cache_df", "(", "maxsize", ",", "typed", "=", "False", ")", ":", "\n", "    ", "\"\"\"Least-recently-used cache decorator for pandas Dataframes.\n\n    Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can\n    save time when an expensive or I/O bound function is periodically called with the same arguments.\n\n    Inspired in the `lru_cache function <https://docs.python.org/3/library/functools.html#functools.lru_cache>`_.\n\n    Args:\n        maxsize (int|None): max size of cache, if set to None cache is boundless\n        typed (bool): arguments of different types are cached separately\n    \"\"\"", "\n", "\n", "def", "to_pandas_hash", "(", "val", ")", ":", "\n", "        ", "\"\"\"Return PandaHash object if input is a DataFrame otherwise return input unchanged\"\"\"", "\n", "return", "PandasHash", "(", "val", ")", "if", "isinstance", "(", "val", ",", "pd", ".", "DataFrame", ")", "else", "val", "\n", "\n", "", "def", "from_pandas_hash", "(", "val", ")", ":", "\n", "        ", "\"\"\"Extract DataFrame if input is PandaHash object otherwise return input unchanged\"\"\"", "\n", "return", "val", ".", "pandas_object", "if", "isinstance", "(", "val", ",", "PandasHash", ")", "else", "val", "\n", "\n", "", "def", "decorating_function", "(", "user_function", ")", ":", "\n", "        ", "@", "wraps", "(", "user_function", ")", "\n", "def", "wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# convert DataFrames in args and kwargs to PandaHash objects", "\n", "            ", "args", "=", "tuple", "(", "[", "to_pandas_hash", "(", "a", ")", "for", "a", "in", "args", "]", ")", "\n", "kwargs", "=", "{", "k", ":", "to_pandas_hash", "(", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "}", "\n", "return", "cached_wrapper", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "@", "lru_cache", "(", "maxsize", "=", "maxsize", ",", "typed", "=", "typed", ")", "\n", "def", "cached_wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# get DataFrames from PandaHash objects in args and kwargs", "\n", "            ", "args", "=", "tuple", "(", "[", "from_pandas_hash", "(", "a", ")", "for", "a", "in", "args", "]", ")", "\n", "kwargs", "=", "{", "k", ":", "from_pandas_hash", "(", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "}", "\n", "return", "user_function", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# retain lru_cache attributes", "\n", "", "wrapper", ".", "cache_info", "=", "cached_wrapper", ".", "cache_info", "\n", "wrapper", ".", "cache_clear", "=", "cached_wrapper", ".", "cache_clear", "\n", "\n", "return", "wrapper", "\n", "\n", "", "return", "decorating_function", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_mind.test_download_mind": [[12, 19], ["recommenders.datasets.mind.download_mind", "os.stat", "os.stat"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_mind"], ["@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_download_mind", "(", "tmp_path", ")", ":", "\n", "    ", "train_path", ",", "valid_path", "=", "download_mind", "(", "size", "=", "\"large\"", ",", "dest_path", "=", "tmp_path", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "train_path", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "530196631", "\n", "statinfo", "=", "os", ".", "stat", "(", "valid_path", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "103456245", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_mind.test_extract_mind": [[21, 43], ["recommenders.datasets.mind.download_mind", "recommenders.datasets.mind.extract_mind", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_mind", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.extract_mind"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_extract_mind", "(", "tmp", ")", ":", "\n", "    ", "train_zip", ",", "valid_zip", "=", "download_mind", "(", "size", "=", "\"large\"", ",", "dest_path", "=", "tmp", ")", "\n", "train_path", ",", "valid_path", "=", "extract_mind", "(", "train_zip", ",", "valid_zip", ")", "\n", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"behaviors.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1373844151", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"entity_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "40305151", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"news.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "84881998", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"relation_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1044588", "\n", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"behaviors.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "230662527", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"entity_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "31958202", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"news.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "59055351", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"relation_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1044588", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_mind.test_mind_utils_integration": [[45, 66], ["papermill.execute_notebook", "scrapbook.read_notebook().scraps.dataframe.set_index", "dict", "scrapbook.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "notebooks", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_mind_utils_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "tmp", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"mind_utils\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "mind_type", "=", "\"small\"", ",", "word_embedding_dim", "=", "300", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"vert_num\"", "]", "==", "17", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"subvert_num\"", "]", "==", "17", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"word_num\"", "]", "==", "23404", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"word_num_all\"", "]", "==", "41074", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"embedding_exist_num\"", "]", "==", "22408", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"embedding_exist_num_all\"", "]", "==", "37634", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"uid2index\"", "]", "==", "5000", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_criteo.test_criteo_load_pandas_df": [[9, 15], ["recommenders.datasets.criteo.load_pandas_df", "criteo.load_pandas_df.loc[].equals", "pandas.Series"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_criteo_load_pandas_df", "(", "criteo_first_row", ")", ":", "\n", "    ", "df", "=", "criteo", ".", "load_pandas_df", "(", "size", "=", "\"full\"", ")", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "45840617", "\n", "assert", "df", ".", "shape", "[", "1", "]", "==", "40", "\n", "assert", "df", ".", "loc", "[", "0", "]", ".", "equals", "(", "pd", ".", "Series", "(", "criteo_first_row", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_criteo.test_criteo_load_spark_df": [[17, 25], ["recommenders.datasets.criteo.load_spark_df", "[].asDict", "criteo.load_spark_df.count", "len", "criteo.load_spark_df.limit().collect", "criteo.load_spark_df.limit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_criteo_load_spark_df", "(", "spark", ",", "criteo_first_row", ")", ":", "\n", "    ", "df", "=", "criteo", ".", "load_spark_df", "(", "spark", ",", "size", "=", "\"full\"", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "45840617", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "40", "\n", "first_row", "=", "df", ".", "limit", "(", "1", ")", ".", "collect", "(", ")", "[", "0", "]", ".", "asDict", "(", ")", "\n", "assert", "first_row", "==", "criteo_first_row", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_pandas_df": [[25, 110], ["pytest.mark.parametrize", "recommenders.datasets.movielens.load_pandas_df", "recommenders.datasets.movielens.load_pandas_df", "len", "len", "len", "len", "pytest.warns", "recommenders.datasets.movielens.load_pandas_df", "len", "len", "os.listdir", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_samples, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "1000209", ",", "\n", "3883", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Animation|Children's|Comedy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10000054", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "20000263", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_pandas_df", "(", "\n", "size", ",", "\n", "num_samples", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test MovieLens dataset load as pd.DataFrame\"\"\"", "\n", "# Test if correct data are loaded", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", "\n", "df", "=", "load_pandas_df", "(", "size", "=", "size", ",", "local_cache_path", "=", "tmp", ",", "header", "=", "header", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "len", "(", "header", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "\n", "# Test title, genres, and released year load", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ",", "\"e\"", "]", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_pandas_df", "(", "\n", "size", "=", "size", ",", "\n", "header", "=", "header", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "title_col", "=", "\"Title\"", ",", "\n", "genres_col", "=", "\"Genres\"", ",", "\n", "year_col", "=", "\"Year\"", ",", "\n", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "assert", "(", "\n", "len", "(", "df", ".", "columns", ")", "==", "7", "\n", ")", "# 4 header columns (user, item, rating, timestamp) and 3 feature columns", "\n", "assert", "\"e\"", "not", "in", "df", ".", "columns", "# only the first 4 header columns are used", "\n", "# Get two records of the same items and check if the item-features are the same.", "\n", "head", "=", "df", ".", "loc", "[", "df", "[", "\"b\"", "]", "==", "movie_example", "]", "[", ":", "2", "]", "\n", "title", "=", "head", "[", "\"Title\"", "]", ".", "values", "\n", "assert", "title", "[", "0", "]", "==", "title", "[", "1", "]", "\n", "assert", "title", "[", "0", "]", "==", "title_example", "\n", "genres", "=", "head", "[", "\"Genres\"", "]", ".", "values", "\n", "assert", "genres", "[", "0", "]", "==", "genres", "[", "1", "]", "\n", "assert", "genres", "[", "0", "]", "==", "genres_example", "\n", "year", "=", "head", "[", "\"Year\"", "]", ".", "values", "\n", "assert", "year", "[", "0", "]", "==", "year", "[", "1", "]", "\n", "assert", "year", "[", "0", "]", "==", "year_example", "\n", "\n", "# Test default arguments", "\n", "", "df", "=", "load_pandas_df", "(", "size", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "# user, item, rating and timestamp", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_item_df": [[112, 166], ["pytest.mark.parametrize", "recommenders.datasets.movielens.load_item_df", "recommenders.datasets.movielens.load_item_df", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_item_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_item_df"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\"1m\"", ",", "3883", ",", "1", ",", "\"Toy Story (1995)\"", ",", "\"Animation|Children's|Comedy\"", ",", "\"1995\"", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_item_df", "(", "\n", "size", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test movielens item data load (not rating data)\"\"\"", "\n", "df", "=", "load_item_df", "(", "size", ",", "local_cache_path", "=", "tmp", ",", "title_col", "=", "\"title\"", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_movies", "\n", "# movie_col and title_col should be loaded", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "2", "\n", "assert", "df", "[", "\"title\"", "]", "[", "0", "]", "==", "title_example", "\n", "\n", "# Test title and genres", "\n", "df", "=", "load_item_df", "(", "\n", "size", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "movie_col", "=", "\"item\"", ",", "\n", "genres_col", "=", "\"genres\"", ",", "\n", "year_col", "=", "\"year\"", ",", "\n", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_movies", "\n", "# movile_col, genres_col and year_col", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "3", "\n", "\n", "assert", "df", "[", "\"item\"", "]", "[", "0", "]", "==", "movie_example", "\n", "assert", "df", "[", "\"genres\"", "]", "[", "0", "]", "==", "genres_example", "\n", "assert", "df", "[", "\"year\"", "]", "[", "0", "]", "==", "year_example", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_spark_df": [[168, 267], ["pytest.mark.parametrize", "StructType", "recommenders.datasets.movielens.load_spark_df", "pytest.warns", "recommenders.datasets.movielens.load_spark_df", "pytest.warns", "recommenders.datasets.movielens.load_spark_df", "recommenders.datasets.movielens.load_spark_df.filter().limit", "df.filter().limit.select().collect", "df.filter().limit.select().collect", "df.filter().limit.select().collect", "recommenders.datasets.movielens.load_spark_df.count", "len", "StructField", "StructField", "recommenders.datasets.movielens.load_spark_df.count", "len", "len", "len", "recommenders.datasets.movielens.load_spark_df.count", "len", "IntegerType", "IntegerType", "os.listdir", "recommenders.datasets.movielens.load_spark_df.filter", "df.filter().limit.select", "df.filter().limit.select", "df.filter().limit.select", "col"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_samples, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "1000209", ",", "\n", "3883", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Animation|Children's|Comedy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10000054", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "20000263", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_spark_df", "(", "\n", "size", ",", "\n", "num_samples", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", "spark", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test MovieLens dataset load into pySpark.DataFrame\"\"\"", "\n", "\n", "# Test if correct data are loaded", "\n", "header", "=", "[", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "schema", "=", "StructType", "(", "\n", "[", "\n", "StructField", "(", "\"u\"", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "\"m\"", ",", "IntegerType", "(", ")", ")", ",", "\n", "]", "\n", ")", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_spark_df", "(", "\n", "spark", ",", "size", "=", "size", ",", "local_cache_path", "=", "tmp", ",", "header", "=", "header", ",", "schema", "=", "schema", "\n", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "num_samples", "\n", "# Test if schema is used when both schema and header are provided", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "len", "(", "schema", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "\n", "# Test title, genres, and released year load", "\n", "", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ",", "\"e\"", "]", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_spark_df", "(", "\n", "spark", ",", "\n", "size", "=", "size", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "header", "=", "header", ",", "\n", "title_col", "=", "\"Title\"", ",", "\n", "genres_col", "=", "\"Genres\"", ",", "\n", "year_col", "=", "\"Year\"", ",", "\n", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "num_samples", "\n", "assert", "(", "\n", "len", "(", "df", ".", "columns", ")", "==", "7", "\n", ")", "# 4 header columns (user, item, rating, timestamp) and 3 feature columns", "\n", "assert", "\"e\"", "not", "in", "df", ".", "columns", "# only the first 4 header columns are used", "\n", "# Get two records of the same items and check if the item-features are the same.", "\n", "head", "=", "df", ".", "filter", "(", "col", "(", "\"b\"", ")", "==", "movie_example", ")", ".", "limit", "(", "2", ")", "\n", "title", "=", "head", ".", "select", "(", "\"Title\"", ")", ".", "collect", "(", ")", "\n", "assert", "title", "[", "0", "]", "[", "0", "]", "==", "title", "[", "1", "]", "[", "0", "]", "\n", "assert", "title", "[", "0", "]", "[", "0", "]", "==", "title_example", "\n", "genres", "=", "head", ".", "select", "(", "\"Genres\"", ")", ".", "collect", "(", ")", "\n", "assert", "genres", "[", "0", "]", "[", "0", "]", "==", "genres", "[", "1", "]", "[", "0", "]", "\n", "assert", "genres", "[", "0", "]", "[", "0", "]", "==", "genres_example", "\n", "year", "=", "head", ".", "select", "(", "\"Year\"", ")", ".", "collect", "(", ")", "\n", "assert", "year", "[", "0", "]", "[", "0", "]", "==", "year", "[", "1", "]", "[", "0", "]", "\n", "assert", "year", "[", "0", "]", "[", "0", "]", "==", "year_example", "\n", "\n", "# Test default arguments", "\n", "", "df", "=", "load_spark_df", "(", "spark", ",", "size", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "num_samples", "\n", "# user, item, rating and timestamp", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_download_and_extract_movielens": [[269, 287], ["pytest.mark.parametrize", "os.path.join", "recommenders.datasets.movielens.download_movielens", "os.path.exists", "os.path.join", "os.path.join", "recommenders.datasets.movielens.extract_movielens", "os.path.exists", "os.path.exists", "len", "len", "os.listdir", "os.listdir"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.download_movielens", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.extract_movielens"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"size\"", ",", "[", "\"1m\"", ",", "\"10m\"", ",", "\"20m\"", "]", ")", "\n", "def", "test_download_and_extract_movielens", "(", "size", ",", "tmp", ")", ":", "\n", "    ", "\"\"\"Test movielens data download and extract\"\"\"", "\n", "zip_path", "=", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"ml.zip\"", ")", "\n", "download_movielens", "(", "size", ",", "dest_path", "=", "zip_path", ")", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "1", "\n", "assert", "os", ".", "path", ".", "exists", "(", "zip_path", ")", "\n", "\n", "rating_path", "=", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"rating.dat\"", ")", "\n", "item_path", "=", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"item.dat\"", ")", "\n", "extract_movielens", "(", "\n", "size", ",", "rating_path", "=", "rating_path", ",", "item_path", "=", "item_path", ",", "zip_path", "=", "zip_path", "\n", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "assert", "os", ".", "path", ".", "exists", "(", "rating_path", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "item_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.spark_dataset": [[34, 46], ["pytest.fixture", "spark.createDataFrame", "pandas.DataFrame", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.datetime64", "recommenders.utils.constants.DEFAULT_TIMESTAMP_COL"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "spark_dataset", "(", "spark", ")", ":", "\n", "    ", "\"\"\"Get spark dataframe\"\"\"", "\n", "\n", "return", "spark", ".", "createDataFrame", "(", "\n", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "5", ",", "NUM_ROWS", ")", ",", "\n", "DEFAULT_ITEM_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "15", ",", "NUM_ROWS", ")", ",", "\n", "DEFAULT_RATING_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "5", ",", "NUM_ROWS", ")", ",", "\n", "DEFAULT_TIMESTAMP_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "1000", ",", "NUM_ROWS", ")", "\n", "+", "np", ".", "datetime64", "(", "\"2018-01-01\"", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.test_min_rating_filter": [[51, 65], ["min_rating_filter_spark", "min_rating_filter_spark", "all", "all", "min_rating_filter_spark.groupBy().count().collect", "min_rating_filter_spark.groupBy().count().collect", "min_rating_filter_spark.groupBy().count", "min_rating_filter_spark.groupBy().count", "min_rating_filter_spark.groupBy", "min_rating_filter_spark.groupBy"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_spark", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_spark"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_min_rating_filter", "(", "spark_dataset", ")", ":", "\n", "    ", "dfs_user", "=", "min_rating_filter_spark", "(", "spark_dataset", ",", "min_rating", "=", "5", ",", "filter_by", "=", "\"user\"", ")", "\n", "dfs_item", "=", "min_rating_filter_spark", "(", "spark_dataset", ",", "min_rating", "=", "5", ",", "filter_by", "=", "\"item\"", ")", "\n", "\n", "user_rating_counts", "=", "[", "\n", "x", "[", "\"count\"", "]", ">=", "5", "for", "x", "in", "dfs_user", ".", "groupBy", "(", "DEFAULT_USER_COL", ")", ".", "count", "(", ")", ".", "collect", "(", ")", "\n", "]", "\n", "item_rating_counts", "=", "[", "\n", "x", "[", "\"count\"", "]", ">=", "5", "for", "x", "in", "dfs_item", ".", "groupBy", "(", "DEFAULT_ITEM_COL", ")", ".", "count", "(", ")", ".", "collect", "(", ")", "\n", "]", "\n", "\n", "assert", "all", "(", "user_rating_counts", ")", "\n", "assert", "all", "(", "item_rating_counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.test_random_splitter": [[67, 85], ["spark_random_split", "spark_random_split", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "splits[].count", "splits[].count", "splits[].count", "splits[].count", "splits[].count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_random_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_random_split"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_random_splitter", "(", "spark_dataset", ")", ":", "\n", "    ", "\"\"\"Test random splitter for Spark dataframes.\n\n    NOTE: some split results may not match exactly with the ratios, which may\n    be owing to the limited number of rows in the testing data. A approximate\n    match with certain level of tolerance is therefore used instead for tests.\"\"\"", "\n", "\n", "splits", "=", "spark_random_split", "(", "spark_dataset", ",", "ratio", "=", "RATIOS", "[", "0", "]", ",", "seed", "=", "SEED", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "abs", "=", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "1", "-", "RATIOS", "[", "0", "]", ",", "abs", "=", "TOL", ")", "\n", "\n", "splits", "=", "spark_random_split", "(", "spark_dataset", ",", "ratio", "=", "RATIOS", ",", "seed", "=", "SEED", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "abs", "=", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "1", "]", ",", "abs", "=", "TOL", ")", "\n", "assert", "splits", "[", "2", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "2", "]", ",", "abs", "=", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.test_chrono_splitter": [[87, 116], ["spark_chrono_split", "splits[].select().distinct().rdd.map().collect", "splits[].select().distinct().rdd.map().collect", "test_spark_splitter._if_later", "spark_chrono_split", "test_spark_splitter._if_later", "test_spark_splitter._if_later", "pytest.approx", "pytest.approx", "set", "set", "pytest.approx", "pytest.approx", "pytest.approx", "splits[].count", "splits[].count", "splits[].select().distinct().rdd.map", "splits[].select().distinct().rdd.map", "splits[].count", "splits[].count", "splits[].count", "splits[].select().distinct", "splits[].select().distinct", "splits[].select", "splits[].select"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_chrono_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter._if_later", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_chrono_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter._if_later", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter._if_later"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_chrono_splitter", "(", "spark_dataset", ")", ":", "\n", "    ", "splits", "=", "spark_chrono_split", "(", "\n", "spark_dataset", ",", "ratio", "=", "RATIOS", "[", "0", "]", ",", "filter_by", "=", "\"user\"", ",", "min_rating", "=", "10", "\n", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "1", "-", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "\n", "# Test if both contains the same user list. This is because chrono split is stratified.", "\n", "users_train", "=", "(", "\n", "splits", "[", "0", "]", ".", "select", "(", "DEFAULT_USER_COL", ")", ".", "distinct", "(", ")", ".", "rdd", ".", "map", "(", "lambda", "r", ":", "r", "[", "0", "]", ")", ".", "collect", "(", ")", "\n", ")", "\n", "users_test", "=", "(", "\n", "splits", "[", "1", "]", ".", "select", "(", "DEFAULT_USER_COL", ")", ".", "distinct", "(", ")", ".", "rdd", ".", "map", "(", "lambda", "r", ":", "r", "[", "0", "]", ")", ".", "collect", "(", ")", "\n", ")", "\n", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_test", ")", "\n", "\n", "assert", "_if_later", "(", "splits", "[", "0", "]", ",", "splits", "[", "1", "]", ")", "\n", "\n", "splits", "=", "spark_chrono_split", "(", "spark_dataset", ",", "ratio", "=", "RATIOS", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "1", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "2", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "2", "]", ",", "TOL", ")", "\n", "\n", "assert", "_if_later", "(", "splits", "[", "0", "]", ",", "splits", "[", "1", "]", ")", "\n", "assert", "_if_later", "(", "splits", "[", "1", "]", ",", "splits", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.test_stratified_splitter": [[118, 160], ["spark_dataset.dropDuplicates.dropDuplicates", "spark_stratified_split", "spark_stratified_split", "splits[].select().distinct().rdd.map().collect", "splits[].select().distinct().rdd.map().collect", "spark_stratified_split", "spark_stratified_split", "pytest.approx", "pytest.approx", "splits[].intersect().count", "spark_dataset.dropDuplicates.repartition", "splits[].intersect().count", "set", "set", "pytest.approx", "pytest.approx", "pytest.approx", "splits[].intersect().count", "splits[].intersect().count", "splits[].intersect().count", "spark_dataset.dropDuplicates.repartition", "splits[].intersect().count", "splits[].intersect().count", "splits[].intersect().count", "splits[].count", "splits[].count", "splits[].select().distinct().rdd.map", "splits[].select().distinct().rdd.map", "splits[].count", "splits[].count", "splits[].count", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].intersect", "splits[].select().distinct", "splits[].select().distinct", "splits[].select", "splits[].select"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_stratified_split"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_stratified_splitter", "(", "spark_dataset", ")", ":", "\n", "    ", "spark_dataset", "=", "spark_dataset", ".", "dropDuplicates", "(", ")", "\n", "\n", "splits", "=", "spark_stratified_split", "(", "\n", "spark_dataset", ",", "ratio", "=", "RATIOS", "[", "0", "]", ",", "filter_by", "=", "\"user\"", ",", "min_rating", "=", "10", "\n", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "1", "-", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "\n", "# Test if there is intersection", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "1", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "splits", "=", "spark_stratified_split", "(", "\n", "spark_dataset", ".", "repartition", "(", "4", ")", ",", "ratio", "=", "RATIOS", "[", "0", "]", ",", "filter_by", "=", "\"user\"", ",", "min_rating", "=", "10", "\n", ")", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "1", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "\n", "# Test if both contains the same user list. This is because stratified split is stratified.", "\n", "users_train", "=", "(", "\n", "splits", "[", "0", "]", ".", "select", "(", "DEFAULT_USER_COL", ")", ".", "distinct", "(", ")", ".", "rdd", ".", "map", "(", "lambda", "r", ":", "r", "[", "0", "]", ")", ".", "collect", "(", ")", "\n", ")", "\n", "users_test", "=", "(", "\n", "splits", "[", "1", "]", ".", "select", "(", "DEFAULT_USER_COL", ")", ".", "distinct", "(", ")", ".", "rdd", ".", "map", "(", "lambda", "r", ":", "r", "[", "0", "]", ")", ".", "collect", "(", ")", "\n", ")", "\n", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_test", ")", "\n", "\n", "splits", "=", "spark_stratified_split", "(", "spark_dataset", ",", "ratio", "=", "RATIOS", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "1", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "2", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "2", "]", ",", "TOL", ")", "\n", "\n", "# Test if there is intersection", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "1", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "2", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "assert", "splits", "[", "1", "]", ".", "intersect", "(", "splits", "[", "2", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "splits", "=", "spark_stratified_split", "(", "spark_dataset", ".", "repartition", "(", "9", ")", ",", "ratio", "=", "RATIOS", ")", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "1", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "assert", "splits", "[", "0", "]", ".", "intersect", "(", "splits", "[", "2", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "assert", "splits", "[", "1", "]", ".", "intersect", "(", "splits", "[", "2", "]", ")", ".", "count", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter.test_timestamp_splitter": [[162, 193], ["spark_dataset.withColumn", "spark_timestamp_split", "spark_timestamp_split", "col().cast", "pytest.approx", "pytest.approx", "splits[].agg().first", "splits[].agg().first", "pytest.approx", "pytest.approx", "pytest.approx", "splits[].agg().first", "splits[].agg().first", "splits[].agg().first", "splits[].agg().first", "splits[].count", "splits[].count", "splits[].count", "splits[].count", "splits[].count", "col", "splits[].agg", "splits[].agg", "splits[].agg", "splits[].agg", "splits[].agg", "splits[].agg", "F.max", "F.min", "F.max", "F.min", "F.max", "F.min"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_timestamp_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.spark_splitters.spark_timestamp_split"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_timestamp_splitter", "(", "spark_dataset", ")", ":", "\n", "    ", "dfs_rating", "=", "spark_dataset", ".", "withColumn", "(", "\n", "DEFAULT_TIMESTAMP_COL", ",", "col", "(", "DEFAULT_TIMESTAMP_COL", ")", ".", "cast", "(", "\"float\"", ")", "\n", ")", "\n", "\n", "splits", "=", "spark_timestamp_split", "(", "\n", "dfs_rating", ",", "ratio", "=", "RATIOS", "[", "0", "]", ",", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", "\n", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "1", "-", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "\n", "max_split0", "=", "splits", "[", "0", "]", ".", "agg", "(", "F", ".", "max", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "min_split1", "=", "splits", "[", "1", "]", ".", "agg", "(", "F", ".", "min", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "assert", "max_split0", "<=", "min_split1", "\n", "\n", "# Test multi split", "\n", "splits", "=", "spark_timestamp_split", "(", "dfs_rating", ",", "ratio", "=", "RATIOS", ")", "\n", "\n", "assert", "splits", "[", "0", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "0", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "1", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "1", "]", ",", "TOL", ")", "\n", "assert", "splits", "[", "2", "]", ".", "count", "(", ")", "/", "NUM_ROWS", "==", "pytest", ".", "approx", "(", "RATIOS", "[", "2", "]", ",", "TOL", ")", "\n", "\n", "max_split0", "=", "splits", "[", "0", "]", ".", "agg", "(", "F", ".", "max", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "min_split1", "=", "splits", "[", "1", "]", ".", "agg", "(", "F", ".", "min", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "assert", "max_split0", "<=", "min_split1", "\n", "\n", "max_split1", "=", "splits", "[", "1", "]", ".", "agg", "(", "F", ".", "max", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "min_split2", "=", "splits", "[", "2", "]", ".", "agg", "(", "F", ".", "min", "(", "DEFAULT_TIMESTAMP_COL", ")", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "assert", "max_split1", "<=", "min_split2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_spark_splitter._if_later": [[195, 212], ["data1.groupBy().agg", "data2.groupBy().agg", "data1.groupBy().agg.join().select", "all", "F.max().alias", "F.min().alias", "data1.groupBy", "data2.groupBy", "data1.groupBy().agg.join", "F.col", "F.col", "F.max", "F.min", "max_times.join().select.collect"], "function", ["None"], ["", "def", "_if_later", "(", "data1", ",", "data2", ")", ":", "\n", "    ", "\"\"\"Helper function to test if records in data1 are earlier than that in data2.\n    Returns:\n        bool: True or False indicating if data1 is earlier than data2.\n    \"\"\"", "\n", "\n", "max_times", "=", "data1", ".", "groupBy", "(", "DEFAULT_USER_COL", ")", ".", "agg", "(", "\n", "F", ".", "max", "(", "DEFAULT_TIMESTAMP_COL", ")", ".", "alias", "(", "\"max\"", ")", "\n", ")", "\n", "min_times", "=", "data2", ".", "groupBy", "(", "DEFAULT_USER_COL", ")", ".", "agg", "(", "\n", "F", ".", "min", "(", "DEFAULT_TIMESTAMP_COL", ")", ".", "alias", "(", "\"min\"", ")", "\n", ")", "\n", "all_times", "=", "max_times", ".", "join", "(", "min_times", ",", "on", "=", "DEFAULT_USER_COL", ")", ".", "select", "(", "\n", "(", "F", ".", "col", "(", "\"max\"", ")", "<=", "F", ".", "col", "(", "\"min\"", ")", ")", "\n", ")", "\n", "\n", "return", "all", "(", "[", "x", "[", "0", "]", "for", "x", "in", "all_times", ".", "collect", "(", ")", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_specs": [[28, 40], ["pytest.fixture"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "test_specs", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"number_of_rows\"", ":", "1000", ",", "\n", "\"seed\"", ":", "123", ",", "\n", "\"ratio\"", ":", "0.6", ",", "\n", "\"ratios\"", ":", "[", "0.2", ",", "0.3", ",", "0.5", "]", ",", "\n", "\"split_numbers\"", ":", "[", "2", ",", "3", ",", "5", "]", ",", "\n", "\"tolerance\"", ":", "0.01", ",", "\n", "\"number_of_items\"", ":", "50", ",", "\n", "\"number_of_users\"", ":", "20", ",", "\n", "\"fluctuation\"", ":", "0.02", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.python_dataset": [[43, 71], ["pytest.fixture", "numpy.random.seed", "pandas.DataFrame", "numpy.arange", "range", "random_dates.append", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "test_python_splitter.python_dataset.random_date_generator"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_dataset", "(", "test_specs", ")", ":", "\n", "    ", "def", "random_date_generator", "(", "start_date", ",", "range_in_days", ")", ":", "\n", "        ", "\"\"\"Helper function to generate random timestamps.\n\n        Reference: https://stackoverflow.com/questions/41006182/generate-random-dates-within-a-range-in-numpy\n        \"\"\"", "\n", "days_to_add", "=", "np", ".", "arange", "(", "0", ",", "range_in_days", ")", "\n", "random_dates", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "range_in_days", ")", ":", "\n", "            ", "random_date", "=", "np", ".", "datetime64", "(", "start_date", ")", "+", "np", ".", "random", ".", "choice", "(", "days_to_add", ")", "\n", "random_dates", ".", "append", "(", "random_date", ")", "\n", "\n", "", "return", "random_dates", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", "test_specs", "[", "\"seed\"", "]", ")", "\n", "\n", "rating", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "5", ",", "test_specs", "[", "\"number_of_rows\"", "]", ")", ",", "\n", "DEFAULT_ITEM_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "15", ",", "test_specs", "[", "\"number_of_rows\"", "]", ")", ",", "\n", "DEFAULT_RATING_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "6", ",", "test_specs", "[", "\"number_of_rows\"", "]", ")", ",", "\n", "DEFAULT_TIMESTAMP_COL", ":", "random_date_generator", "(", "\n", "\"2018-01-01\"", ",", "test_specs", "[", "\"number_of_rows\"", "]", "\n", ")", ",", "\n", "}", "\n", ")", "\n", "return", "rating", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.python_int_dataset": [[73, 82], ["pytest.fixture", "numpy.random.seed", "numpy.random.randint"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_int_dataset", "(", "test_specs", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "test_specs", "[", "\"seed\"", "]", ")", "\n", "\n", "# generates the user/item affinity matrix. Ratings are in the interval [0, 5), with 0s denoting unrated items", "\n", "return", "np", ".", "random", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "6", ",", "\n", "size", "=", "(", "test_specs", "[", "\"number_of_users\"", "]", ",", "test_specs", "[", "\"number_of_items\"", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.python_float_dataset": [[85, 95], ["pytest.fixture", "numpy.random.seed", "numpy.random.random"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_float_dataset", "(", "test_specs", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "test_specs", "[", "\"seed\"", "]", ")", "\n", "\n", "# generates the user/item affinity matrix. Ratings are in the interval [0, 5), with 0s denoting unrated items.", "\n", "return", "(", "\n", "np", ".", "random", ".", "random", "(", "\n", "size", "=", "(", "test_specs", "[", "\"number_of_users\"", "]", ",", "test_specs", "[", "\"number_of_items\"", "]", ")", "\n", ")", "\n", "*", "5", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_split_pandas_data": [[98, 114], ["recommenders.datasets.split_utils.split_pandas_data_with_ratios", "recommenders.datasets.split_utils.split_pandas_data_with_ratios", "len", "len", "len", "round", "len", "round", "len", "round", "pytest.raises", "recommenders.datasets.split_utils.split_pandas_data_with_ratios"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.split_pandas_data_with_ratios"], ["", "def", "test_split_pandas_data", "(", "pandas_dummy_timestamp", ")", ":", "\n", "    ", "splits", "=", "split_pandas_data_with_ratios", "(", "pandas_dummy_timestamp", ",", "ratios", "=", "[", "0.5", ",", "0.5", "]", ")", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "==", "5", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "==", "5", "\n", "\n", "splits", "=", "split_pandas_data_with_ratios", "(", "\n", "pandas_dummy_timestamp", ",", "ratios", "=", "[", "0.12", ",", "0.36", ",", "0.52", "]", "\n", ")", "\n", "shape", "=", "pandas_dummy_timestamp", ".", "shape", "[", "0", "]", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "==", "round", "(", "shape", "*", "0.12", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "==", "round", "(", "shape", "*", "0.36", ")", "\n", "assert", "len", "(", "splits", "[", "2", "]", ")", "==", "round", "(", "shape", "*", "0.52", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "splits", "=", "split_pandas_data_with_ratios", "(", "\n", "pandas_dummy_timestamp", ",", "ratios", "=", "[", "0.6", ",", "0.2", ",", "0.4", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_min_rating_filter": [[117, 144], ["pandas.DataFrame", "recommenders.datasets.split_utils.min_rating_filter_pandas", "recommenders.datasets.split_utils.min_rating_filter_pandas", "test_python_splitter.test_min_rating_filter.count_filtered_rows"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.split_utils.min_rating_filter_pandas"], ["", "", "def", "test_min_rating_filter", "(", ")", ":", "\n", "    ", "python_dataset", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "4", ",", "4", ",", "4", ",", "4", ",", "5", ",", "5", ",", "5", ",", "5", ",", "5", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "5", ",", "5", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "np", ".", "random", ".", "randint", "(", "1", ",", "6", ",", "15", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "def", "count_filtered_rows", "(", "data", ",", "filter_by", "=", "\"user\"", ")", ":", "\n", "        ", "split_by_column", "=", "DEFAULT_USER_COL", "if", "filter_by", "==", "\"user\"", "else", "DEFAULT_ITEM_COL", "\n", "data_grouped", "=", "data", ".", "groupby", "(", "split_by_column", ")", "\n", "\n", "row_counts", "=", "[", "]", "\n", "for", "name", ",", "group", "in", "data_grouped", ":", "\n", "            ", "data_group", "=", "data_grouped", ".", "get_group", "(", "name", ")", "\n", "row_counts", ".", "append", "(", "data_group", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "return", "row_counts", "\n", "\n", "", "df_user", "=", "min_rating_filter_pandas", "(", "python_dataset", ",", "min_rating", "=", "3", ",", "filter_by", "=", "\"user\"", ")", "\n", "df_item", "=", "min_rating_filter_pandas", "(", "python_dataset", ",", "min_rating", "=", "2", ",", "filter_by", "=", "\"item\"", ")", "\n", "user_rating_counts", "=", "count_filtered_rows", "(", "df_user", ",", "filter_by", "=", "\"user\"", ")", "\n", "item_rating_counts", "=", "count_filtered_rows", "(", "df_item", ",", "filter_by", "=", "\"item\"", ")", "\n", "\n", "assert", "all", "(", "u", ">=", "3", "for", "u", "in", "user_rating_counts", ")", "\n", "assert", "all", "(", "i", ">=", "2", "for", "i", "in", "item_rating_counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_random_splitter": [[146, 205], ["recommenders.datasets.python_splitters.python_random_split", "recommenders.datasets.python_splitters.python_random_split", "recommenders.datasets.python_splitters.python_random_split", "recommenders.datasets.python_splitters.python_random_split", "pytest.approx", "pytest.approx", "len", "pytest.approx", "pytest.approx", "pytest.approx", "len", "pytest.approx", "pytest.approx", "pytest.approx", "len", "len", "len", "set", "set", "len", "len", "len", "set", "set", "len", "len", "len", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_random_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_random_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_random_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_random_split"], ["", "def", "test_random_splitter", "(", "test_specs", ",", "python_dataset", ")", ":", "\n", "    ", "\"\"\"NOTE: some split results may not match exactly with the ratios, which may be owing to the  limited number of\n    rows in the testing data. A approximate match with certain level of tolerance is therefore used instead for tests.\n    \"\"\"", "\n", "splits", "=", "python_random_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratio\"", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "1", "-", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "", "splits", "=", "python_random_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratios\"", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", ")", "==", "3", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "0", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "1", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "2", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "2", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "", "splits", "=", "python_random_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"split_numbers\"", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", ")", "==", "3", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "0", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "1", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "2", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "2", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "# check values sum to 1", "\n", "", "splits", "=", "python_random_split", "(", "\n", "python_dataset", ",", "ratio", "=", "[", "0.7", ",", "0.2", ",", "0.1", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "\n", "assert", "(", "len", "(", "splits", ")", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_chrono_splitter": [[207, 307], ["recommenders.datasets.python_splitters.python_chrono_split", "[].unique", "[].unique", "[].groupby().max", "[].groupby().min", "[].groupby().max.join", "all", "recommenders.datasets.python_splitters.python_chrono_split", "[].unique", "[].unique", "[].unique", "[].groupby().max", "[].groupby().min", "[].groupby().max.join", "all", "[].groupby().max", "[].groupby().min", "[].groupby().max.join", "all", "pytest.approx", "pytest.approx", "set", "set", "len", "pytest.approx", "pytest.approx", "pytest.approx", "set", "set", "set", "set", "len", "len", "set", "set", "[].groupby", "[].groupby", "len", "len", "len", "set", "set", "[].groupby", "[].groupby", "[].groupby", "[].groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_chrono_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_chrono_split"], ["", "def", "test_chrono_splitter", "(", "test_specs", ",", "python_dataset", ")", ":", "\n", "    ", "splits", "=", "python_chrono_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratio\"", "]", ",", "min_rating", "=", "10", ",", "filter_by", "=", "\"user\"", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "1", "-", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "# Test if both contains the same user list. This is because chrono split is stratified.", "\n", "", "users_train", "=", "splits", "[", "0", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "users_test", "=", "splits", "[", "1", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_test", ")", "\n", "\n", "# Test all time stamps in test are later than that in train for all users.", "\n", "# This is for single-split case.", "\n", "max_train_times", "=", "(", "\n", "splits", "[", "0", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "max", "(", ")", "\n", ")", "\n", "min_test_times", "=", "(", "\n", "splits", "[", "1", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "min", "(", ")", "\n", ")", "\n", "check_times", "=", "max_train_times", ".", "join", "(", "min_test_times", ",", "lsuffix", "=", "\"_0\"", ",", "rsuffix", "=", "\"_1\"", ")", "\n", "assert", "all", "(", "\n", "(", "\n", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_0\"", "]", "\n", "<", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_1\"", "]", "\n", ")", ".", "values", "\n", ")", "\n", "\n", "# Test multi-split case", "\n", "splits", "=", "python_chrono_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratios\"", "]", ",", "min_rating", "=", "10", ",", "filter_by", "=", "\"user\"", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", ")", "==", "3", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "0", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "1", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "2", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "2", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "# Test if all splits contain the same user list. This is because chrono split is stratified.", "\n", "", "users_train", "=", "splits", "[", "0", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "users_test", "=", "splits", "[", "1", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "users_val", "=", "splits", "[", "2", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_test", ")", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_val", ")", "\n", "\n", "# Test if timestamps are correctly split. This is for multi-split case.", "\n", "max_train_times", "=", "(", "\n", "splits", "[", "0", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "max", "(", ")", "\n", ")", "\n", "min_test_times", "=", "(", "\n", "splits", "[", "1", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "min", "(", ")", "\n", ")", "\n", "check_times", "=", "max_train_times", ".", "join", "(", "min_test_times", ",", "lsuffix", "=", "\"_0\"", ",", "rsuffix", "=", "\"_1\"", ")", "\n", "assert", "all", "(", "\n", "(", "\n", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_0\"", "]", "\n", "<", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_1\"", "]", "\n", ")", ".", "values", "\n", ")", "\n", "\n", "max_test_times", "=", "(", "\n", "splits", "[", "1", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "max", "(", ")", "\n", ")", "\n", "min_val_times", "=", "(", "\n", "splits", "[", "2", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_TIMESTAMP_COL", "]", "]", "\n", ".", "groupby", "(", "DEFAULT_USER_COL", ")", "\n", ".", "min", "(", ")", "\n", ")", "\n", "check_times", "=", "max_test_times", ".", "join", "(", "min_val_times", ",", "lsuffix", "=", "\"_1\"", ",", "rsuffix", "=", "\"_2\"", ")", "\n", "assert", "all", "(", "\n", "(", "\n", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_1\"", "]", "\n", "<", "check_times", "[", "DEFAULT_TIMESTAMP_COL", "+", "\"_2\"", "]", "\n", ")", ".", "values", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_stratified_splitter": [[311, 349], ["recommenders.datasets.python_splitters.python_stratified_split", "[].unique", "[].unique", "recommenders.datasets.python_splitters.python_stratified_split", "pytest.approx", "pytest.approx", "set", "set", "len", "pytest.approx", "pytest.approx", "pytest.approx", "len", "len", "set", "set", "len", "len", "len", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_stratified_split"], ["", "def", "test_stratified_splitter", "(", "test_specs", ",", "python_dataset", ")", ":", "\n", "    ", "splits", "=", "python_stratified_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratio\"", "]", ",", "min_rating", "=", "10", ",", "filter_by", "=", "\"user\"", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "1", "-", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n", "# Test if both contains the same user list. This is because stratified split is stratified.", "\n", "", "users_train", "=", "splits", "[", "0", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "users_test", "=", "splits", "[", "1", "]", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "\n", "assert", "set", "(", "users_train", ")", "==", "set", "(", "users_test", ")", "\n", "\n", "splits", "=", "python_stratified_split", "(", "\n", "python_dataset", ",", "ratio", "=", "test_specs", "[", "\"ratios\"", "]", ",", "min_rating", "=", "10", ",", "filter_by", "=", "\"user\"", "\n", ")", "\n", "\n", "assert", "len", "(", "splits", ")", "==", "3", "\n", "assert", "len", "(", "splits", "[", "0", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "0", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "1", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "1", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "assert", "len", "(", "splits", "[", "2", "]", ")", "/", "test_specs", "[", "\"number_of_rows\"", "]", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratios\"", "]", "[", "2", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "assert", "set", "(", "split", ".", "columns", ")", "==", "set", "(", "python_dataset", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_int_numpy_stratified_splitter": [[351, 392], ["recommenders.datasets.python_splitters.numpy_stratified_split", "numpy.sum", "numpy.sum", "numpy.sum", "pytest.approx", "pytest.approx", "np.sum.sum", "np.sum.sum", "np.sum.sum", "np.sum.sum"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.numpy_stratified_split"], ["", "", "def", "test_int_numpy_stratified_splitter", "(", "test_specs", ",", "python_int_dataset", ")", ":", "\n", "# generate a syntetic dataset", "\n", "    ", "X", "=", "python_int_dataset", "\n", "\n", "# the splitter returns (in order): train and test user/affinity matrices, train and test datafarmes and user/items to matrix maps", "\n", "Xtr", ",", "Xtst", "=", "numpy_stratified_split", "(", "\n", "X", ",", "ratio", "=", "test_specs", "[", "\"ratio\"", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "\n", "# check that the generated matrices have the correct dimensions", "\n", "assert", "(", "Xtr", ".", "shape", "[", "0", "]", "==", "X", ".", "shape", "[", "0", "]", ")", "&", "(", "Xtr", ".", "shape", "[", "1", "]", "==", "X", ".", "shape", "[", "1", "]", ")", "\n", "assert", "(", "Xtst", ".", "shape", "[", "0", "]", "==", "X", ".", "shape", "[", "0", "]", ")", "&", "(", "Xtst", ".", "shape", "[", "1", "]", "==", "X", ".", "shape", "[", "1", "]", ")", "\n", "\n", "X_rated", "=", "np", ".", "sum", "(", "X", "!=", "0", ",", "axis", "=", "1", ")", "# number of total rated items per user", "\n", "Xtr_rated", "=", "np", ".", "sum", "(", "Xtr", "!=", "0", ",", "axis", "=", "1", ")", "# number of rated items in the train set", "\n", "Xtst_rated", "=", "np", ".", "sum", "(", "Xtst", "!=", "0", ",", "axis", "=", "1", ")", "# number of rated items in the test set", "\n", "\n", "# global split: check that the all dataset is split in the correct ratio", "\n", "assert", "Xtr_rated", ".", "sum", "(", ")", "/", "(", "X_rated", ".", "sum", "(", ")", ")", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "assert", "Xtst_rated", ".", "sum", "(", ")", "/", "(", "X_rated", ".", "sum", "(", ")", ")", "==", "pytest", ".", "approx", "(", "\n", "1", "-", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "# This implementation of the stratified splitter performs a random split at the single user level. Here we check", "\n", "# that also this more stringent condition is verified. Note that user to user fluctuations in the split ratio", "\n", "# are stronger than for the entire dataset due to the random nature of the per user splitting.", "\n", "# For this reason we allow a slightly bigger tolerance, as specified in the test_specs()", "\n", "\n", "assert", "(", "\n", "Xtr_rated", "/", "X_rated", "<=", "test_specs", "[", "\"ratio\"", "]", "+", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", ".", "all", "(", ")", "&", "(", "\n", "Xtr_rated", "/", "X_rated", ">=", "test_specs", "[", "\"ratio\"", "]", "-", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", ".", "all", "(", ")", "\n", "\n", "assert", "(", "\n", "Xtst_rated", "/", "X_rated", "<=", "(", "1", "-", "test_specs", "[", "\"ratio\"", "]", ")", "+", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", ".", "all", "(", ")", "&", "(", "\n", "Xtst_rated", "/", "X_rated", ">=", "(", "1", "-", "test_specs", "[", "\"ratio\"", "]", ")", "-", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", ".", "all", "(", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_python_splitter.test_float_numpy_stratified_splitter": [[395, 434], ["recommenders.datasets.python_splitters.numpy_stratified_split", "numpy.sum", "numpy.sum", "numpy.sum", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "np.sum.sum", "np.sum.sum", "np.sum.sum", "np.sum.sum"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.numpy_stratified_split"], ["", "def", "test_float_numpy_stratified_splitter", "(", "test_specs", ",", "python_float_dataset", ")", ":", "\n", "# generate a syntetic dataset", "\n", "    ", "X", "=", "python_float_dataset", "\n", "\n", "# the splitter returns (in order): train and test user/affinity matrices, train and test datafarmes and user/items to matrix maps", "\n", "Xtr", ",", "Xtst", "=", "numpy_stratified_split", "(", "\n", "X", ",", "ratio", "=", "test_specs", "[", "\"ratio\"", "]", ",", "seed", "=", "test_specs", "[", "\"seed\"", "]", "\n", ")", "\n", "\n", "# Tests", "\n", "# check that the generated matrices have the correct dimensions", "\n", "assert", "(", "Xtr", ".", "shape", "[", "0", "]", "==", "X", ".", "shape", "[", "0", "]", ")", "&", "(", "Xtr", ".", "shape", "[", "1", "]", "==", "X", ".", "shape", "[", "1", "]", ")", "\n", "\n", "assert", "(", "Xtst", ".", "shape", "[", "0", "]", "==", "X", ".", "shape", "[", "0", "]", ")", "&", "(", "Xtst", ".", "shape", "[", "1", "]", "==", "X", ".", "shape", "[", "1", "]", ")", "\n", "\n", "X_rated", "=", "np", ".", "sum", "(", "X", "!=", "0", ",", "axis", "=", "1", ")", "# number of total rated items per user", "\n", "Xtr_rated", "=", "np", ".", "sum", "(", "Xtr", "!=", "0", ",", "axis", "=", "1", ")", "# number of rated items in the train set", "\n", "Xtst_rated", "=", "np", ".", "sum", "(", "Xtst", "!=", "0", ",", "axis", "=", "1", ")", "# number of rated items in the test set", "\n", "\n", "# global split: check that the all dataset is split in the correct ratio", "\n", "assert", "Xtr_rated", ".", "sum", "(", ")", "/", "(", "X_rated", ".", "sum", "(", ")", ")", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "assert", "Xtst_rated", ".", "sum", "(", ")", "/", "(", "X_rated", ".", "sum", "(", ")", ")", "==", "pytest", ".", "approx", "(", "\n", "1", "-", "test_specs", "[", "\"ratio\"", "]", ",", "test_specs", "[", "\"tolerance\"", "]", "\n", ")", "\n", "\n", "# This implementation of the stratified splitter performs a random split at the single user level. Here we check", "\n", "# that also this more stringent condition is verified. Note that user to user fluctuations in the split ratio", "\n", "# are stronger than for the entire dataset due to the random nature of the per user splitting.", "\n", "# For this reason we allow a slightly bigger tolerance, as specified in the test_specs()", "\n", "\n", "assert", "Xtr_rated", "/", "X_rated", "==", "pytest", ".", "approx", "(", "\n", "test_specs", "[", "\"ratio\"", "]", ",", "rel", "=", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", "\n", "\n", "assert", "Xtst_rated", "/", "X_rated", "==", "pytest", ".", "approx", "(", "\n", "(", "1", "-", "test_specs", "[", "\"ratio\"", "]", ")", ",", "rel", "=", "test_specs", "[", "\"fluctuation\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_sparse.test_specs": [[17, 20], ["pytest.fixture"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "test_specs", "(", ")", ":", "\n", "    ", "return", "{", "\"number_of_items\"", ":", "50", ",", "\"number_of_users\"", ":", "20", ",", "\"seed\"", ":", "123", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_sparse.python_dataset": [[23, 81], ["pytest.fixture", "numpy.random.seed", "numpy.random.randint", "range", "numpy.reshape", "pandas.DataFrame.from_dict", "numpy.arange", "range", "userids.extend", "random_dates.append", "test_sparse.python_dataset.random_date_generator"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_dataset", "(", "test_specs", ")", ":", "\n", "\n", "    ", "\"\"\"Get Python labels\"\"\"", "\n", "\n", "def", "random_date_generator", "(", "start_date", ",", "range_in_days", ")", ":", "\n", "        ", "\"\"\"Helper function to generate random timestamps.\n\n        Reference: https://stackoverflow.com/questions/41006182/generate-random-dates-within-a-range-in-numpy\n        \"\"\"", "\n", "\n", "days_to_add", "=", "np", ".", "arange", "(", "0", ",", "range_in_days", ")", "\n", "random_dates", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "range_in_days", ")", ":", "\n", "            ", "random_date", "=", "np", ".", "datetime64", "(", "start_date", ")", "+", "np", ".", "random", ".", "choice", "(", "days_to_add", ")", "\n", "random_dates", ".", "append", "(", "random_date", ")", "\n", "\n", "", "return", "random_dates", "\n", "\n", "# fix the the random seed", "\n", "", "np", ".", "random", ".", "seed", "(", "test_specs", "[", "\"seed\"", "]", ")", "\n", "\n", "# generates the user/item affinity matrix. Ratings are from 1 to 5, with 0s denoting unrated items", "\n", "X", "=", "np", ".", "random", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "6", ",", "\n", "size", "=", "(", "test_specs", "[", "\"number_of_users\"", "]", ",", "test_specs", "[", "\"number_of_items\"", "]", ")", ",", "\n", ")", "\n", "\n", "# In the main code, input data are passed as pandas dataframe. Below we generate such df from the above matrix", "\n", "userids", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "test_specs", "[", "\"number_of_users\"", "]", "+", "1", ")", ":", "\n", "        ", "userids", ".", "extend", "(", "[", "i", "]", "*", "test_specs", "[", "\"number_of_items\"", "]", ")", "\n", "\n", "", "itemids", "=", "[", "i", "for", "i", "in", "range", "(", "1", ",", "test_specs", "[", "\"number_of_items\"", "]", "+", "1", ")", "]", "*", "test_specs", "[", "\n", "\"number_of_users\"", "\n", "]", "\n", "ratings", "=", "np", ".", "reshape", "(", "X", ",", "-", "1", ")", "\n", "\n", "# create dataframe", "\n", "results", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "userids", ",", "\n", "DEFAULT_ITEM_COL", ":", "itemids", ",", "\n", "DEFAULT_RATING_COL", ":", "ratings", ",", "\n", "DEFAULT_TIMESTAMP_COL", ":", "random_date_generator", "(", "\n", "\"2018-01-01\"", ",", "\n", "test_specs", "[", "\"number_of_users\"", "]", "*", "test_specs", "[", "\"number_of_items\"", "]", ",", "\n", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# here we eliminate the missing ratings to obtain a standard form of the df as that of real data.", "\n", "results", "=", "results", "[", "results", ".", "rating", "!=", "0", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_sparse.test_df_to_sparse": [[83, 100], ["recommenders.datasets.sparse.AffinityMatrix", "recommenders.datasets.sparse.AffinityMatrix.gen_affinity_matrix", "python_dataset.userID.unique", "python_dataset.itemID.unique"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.gen_affinity_matrix"], ["", "def", "test_df_to_sparse", "(", "test_specs", ",", "python_dataset", ")", ":", "\n", "# initialize the splitter", "\n", "    ", "header", "=", "{", "\n", "\"col_user\"", ":", "DEFAULT_USER_COL", ",", "\n", "\"col_item\"", ":", "DEFAULT_ITEM_COL", ",", "\n", "\"col_rating\"", ":", "DEFAULT_RATING_COL", ",", "\n", "}", "\n", "\n", "# instantiate the affinity matrix", "\n", "am", "=", "AffinityMatrix", "(", "df", "=", "python_dataset", ",", "**", "header", ")", "\n", "\n", "# obtain the sparse matrix representation of the input dataframe", "\n", "X", ",", "_", ",", "_", "=", "am", ".", "gen_affinity_matrix", "(", ")", "\n", "\n", "# check that the generated matrix has the correct dimensions", "\n", "assert", "(", "X", ".", "shape", "[", "0", "]", "==", "python_dataset", ".", "userID", ".", "unique", "(", ")", ".", "shape", "[", "0", "]", ")", "&", "(", "\n", "X", ".", "shape", "[", "1", "]", "==", "python_dataset", ".", "itemID", ".", "unique", "(", ")", ".", "shape", "[", "0", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_sparse.test_sparse_to_df": [[103, 134], ["recommenders.datasets.sparse.AffinityMatrix", "recommenders.datasets.sparse.AffinityMatrix.gen_affinity_matrix", "recommenders.datasets.sparse.AffinityMatrix.map_back_sparse", "am.map_back_sparse.userID.values.all", "python_dataset.sort_values().userID.values.all", "am.map_back_sparse.itemID.values.all", "python_dataset.sort_values().itemID.values.all", "am.map_back_sparse.rating.values.all", "python_dataset.sort_values().rating.values.all", "python_dataset.sort_values", "python_dataset.sort_values", "python_dataset.sort_values"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.gen_affinity_matrix", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse"], ["", "def", "test_sparse_to_df", "(", "test_specs", ",", "python_dataset", ")", ":", "\n", "# initialize the splitter", "\n", "    ", "header", "=", "{", "\n", "\"col_user\"", ":", "DEFAULT_USER_COL", ",", "\n", "\"col_item\"", ":", "DEFAULT_ITEM_COL", ",", "\n", "\"col_rating\"", ":", "DEFAULT_RATING_COL", ",", "\n", "}", "\n", "\n", "# instantiate the the affinity matrix", "\n", "am", "=", "AffinityMatrix", "(", "df", "=", "python_dataset", ",", "**", "header", ")", "\n", "\n", "# generate the sparse matrix representation", "\n", "X", ",", "_", ",", "_", "=", "am", ".", "gen_affinity_matrix", "(", ")", "\n", "\n", "# use the inverse function to generate a pandas df from a sparse matrix ordered by userID", "\n", "DF", "=", "am", ".", "map_back_sparse", "(", "X", ",", "kind", "=", "\"ratings\"", ")", "\n", "\n", "# tests: check that the two dataframes have the same elements in the same positions.", "\n", "assert", "(", "\n", "DF", ".", "userID", ".", "values", ".", "all", "(", ")", "\n", "==", "python_dataset", ".", "sort_values", "(", "by", "=", "[", "\"userID\"", "]", ")", ".", "userID", ".", "values", ".", "all", "(", ")", "\n", ")", "\n", "\n", "assert", "(", "\n", "DF", ".", "itemID", ".", "values", ".", "all", "(", ")", "\n", "==", "python_dataset", ".", "sort_values", "(", "by", "=", "[", "\"userID\"", "]", ")", ".", "itemID", ".", "values", ".", "all", "(", ")", "\n", ")", "\n", "\n", "assert", "(", "\n", "DF", ".", "rating", ".", "values", ".", "all", "(", ")", "\n", "==", "python_dataset", ".", "sort_values", "(", "by", "=", "[", "\"userID\"", "]", ")", ".", "rating", ".", "values", ".", "all", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.df": [[18, 46], ["pytest.fixture", "pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "df", "(", ")", ":", "\n", "    ", "mock_metadata", "=", "{", "\n", "\"cord_uid\"", ":", "[", "\"ej795nks\"", ",", "\"\"", ",", "np", ".", "nan", ",", "\"adygntbe\"", ",", "\"adygntbe\"", "]", ",", "\n", "\"doi\"", ":", "[", "\n", "\"10.1289/ehp.7117\"", ",", "\n", "np", ".", "nan", ",", "\n", "\"10.1371/journal.pmed.0030149\"", ",", "\n", "\"\"", ",", "\n", "\"10.1016/s0140-6736(03)13507-6\"", ",", "\n", "]", ",", "\n", "\"title\"", ":", "[", "\n", "\"Understanding the Spatial Clustering of\"", ",", "\n", "\"The Application of the Haddon Matrix to\"", ",", "\n", "\"Cynomolgus Macaque as an Animal Model for\"", ",", "\n", "\"SARS: screening, disease associations\"", ",", "\n", "\"SARS: screening, disease associations\"", ",", "\n", "]", ",", "\n", "\"license\"", ":", "[", "\"cc0\"", ",", "\"cc0\"", ",", "\"cc0\"", ",", "\"no-cc\"", ",", "\"els-covid\"", "]", ",", "\n", "\"url\"", ":", "[", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11\"", ",", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12\"", ",", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC13\"", ",", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7\"", ",", "\n", "\"https://doi.org/10.1016/s0140-6736(03)13507-6\"", ",", "\n", "]", ",", "\n", "}", "\n", "return", "pd", ".", "DataFrame", "(", "mock_metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.test_remove_duplicates": [[48, 51], ["recommenders.datasets.covid_utils.remove_duplicates", "recommenders.datasets.covid_utils.remove_duplicates.duplicated"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_duplicates"], ["", "def", "test_remove_duplicates", "(", "df", ")", ":", "\n", "    ", "output", "=", "remove_duplicates", "(", "df", ",", "cols", "=", "[", "\"cord_uid\"", ",", "\"doi\"", ",", "\"title\"", ",", "\"license\"", ",", "\"url\"", "]", ")", "\n", "assert", "True", "not", "in", "output", ".", "duplicated", "(", "[", "\"cord_uid\"", "]", ")", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.test_remove_nan": [[53, 56], ["recommenders.datasets.covid_utils.remove_nan"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.remove_nan"], ["", "def", "test_remove_nan", "(", "df", ")", ":", "\n", "    ", "output", "=", "remove_nan", "(", "df", ",", "cols", "=", "[", "\"cord_uid\"", ",", "\"doi\"", ",", "\"title\"", ",", "\"license\"", ",", "\"url\"", "]", ")", "\n", "assert", "np", ".", "nan", "not", "in", "output", "[", "\"cord_uid\"", "]", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.test_clean_dataframe": [[58, 61], ["recommenders.datasets.covid_utils.clean_dataframe", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.clean_dataframe"], ["", "def", "test_clean_dataframe", "(", "df", ")", ":", "\n", "    ", "output", "=", "clean_dataframe", "(", "df", ")", "\n", "assert", "len", "(", "df", ")", ">", "len", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.test_retrieve_text": [[63, 74], ["MockResponse", "unittest.mock.patch", "recommenders.datasets.covid_utils.retrieve_text", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.retrieve_text"], ["", "def", "test_retrieve_text", "(", ")", ":", "\n", "    ", "def", "mock_get", "(", "uri", ",", "headers", ")", ":", "\n", "        ", "class", "MockResponse", ":", "\n", "            ", "def", "json", "(", "self", ")", ":", "\n", "                ", "return", "dict", "(", "body_text", "=", "[", "dict", "(", "text", "=", "\"test\"", ")", "]", ")", "\n", "\n", "", "", "return", "MockResponse", "(", ")", "\n", "\n", "", "with", "patch", "(", "\"recommenders.datasets.covid_utils.requests.get\"", ",", "side_effect", "=", "mock_get", ")", ":", "\n", "        ", "result", "=", "retrieve_text", "(", "entry", "=", "dict", "(", "pdf_json_files", "=", "\"a\"", ")", ",", "container_name", "=", "\"test\"", ")", "\n", "", "assert", "\"test\"", "==", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_covid_utils.test_get_public_domain_text": [[76, 94], ["all", "unittest.mock.patch", "recommenders.datasets.covid_utils.get_public_domain_text"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.get_public_domain_text"], ["", "def", "test_get_public_domain_text", "(", "df", ")", ":", "\n", "    ", "df", "[", "\"publish_time\"", "]", "=", "\"\"", "\n", "df", "[", "\"authors\"", "]", "=", "\"\"", "\n", "df", "[", "\"journal\"", "]", "=", "\"\"", "\n", "df", "[", "\"abstract\"", "]", "=", "\"\"", "\n", "\n", "def", "mock_retrieve_text", "(", "\n", "row", ",", "container_name", ",", "azure_storage_account_name", ",", "azure_storage_sas_token", "\n", ")", ":", "\n", "        ", "return", "\"full text\"", "\n", "\n", "", "with", "patch", "(", "\n", "\"recommenders.datasets.covid_utils.retrieve_text\"", ",", "\n", "side_effect", "=", "mock_retrieve_text", ",", "\n", ")", ":", "\n", "        ", "full", "=", "get_public_domain_text", "(", "df", ",", "container_name", "=", "\"test\"", ")", "\n", "\n", "", "assert", "all", "(", "full", "[", "\"full_text\"", "]", "==", "[", "\"full text\"", "]", "*", "5", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.q": [[15, 21], ["pytest.fixture"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "q", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"correct\"", ":", "\"the lord of the rings\"", ",", "\n", "\"not_correct\"", ":", "\"yXzCGhyFfWatQAPxeuRd09RqqWAMsCYRxZcxUDv\"", ",", "\n", "\"entity_id\"", ":", "\"Q15228\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.test_find_wikidata_id": [[24, 27], ["recommenders.datasets.wikidata.find_wikidata_id", "recommenders.datasets.wikidata.find_wikidata_id"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.find_wikidata_id", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.find_wikidata_id"], ["", "def", "test_find_wikidata_id", "(", "q", ")", ":", "\n", "    ", "assert", "find_wikidata_id", "(", "q", "[", "\"correct\"", "]", ")", "==", "\"Q15228\"", "\n", "assert", "find_wikidata_id", "(", "q", "[", "\"not_correct\"", "]", ")", "==", "\"entityNotFound\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.test_query_entity_links": [[29, 34], ["pytest.mark.skip", "recommenders.datasets.wikidata.query_entity_links"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_links"], ["", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"Wikidata API is unstable\"", ")", "\n", "def", "test_query_entity_links", "(", "q", ")", ":", "\n", "    ", "resp", "=", "query_entity_links", "(", "q", "[", "\"entity_id\"", "]", ")", "\n", "assert", "\"head\"", "in", "resp", "\n", "assert", "\"results\"", "in", "resp", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.test_read_linked_entities": [[36, 41], ["pytest.mark.skip", "recommenders.datasets.wikidata.query_entity_links", "recommenders.datasets.wikidata.read_linked_entities", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_links", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.read_linked_entities"], ["", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"Wikidata API is unstable\"", ")", "\n", "def", "test_read_linked_entities", "(", "q", ")", ":", "\n", "    ", "resp", "=", "query_entity_links", "(", "q", "[", "\"entity_id\"", "]", ")", "\n", "related_links", "=", "read_linked_entities", "(", "resp", ")", "\n", "assert", "len", "(", "related_links", ")", ">", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.test_query_entity_description": [[43, 47], ["pytest.mark.skip", "recommenders.datasets.wikidata.query_entity_description"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.wikidata.query_entity_description"], ["", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"Wikidata API is unstable\"", ")", "\n", "def", "test_query_entity_description", "(", "q", ")", ":", "\n", "    ", "desc", "=", "query_entity_description", "(", "q", "[", "\"entity_id\"", "]", ")", "\n", "assert", "desc", "==", "\"1954\u20131955 fantasy novel by J. R. R. Tolkien\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_wikidata.test_search_wikidata": [[49, 52], ["None"], "function", ["None"], ["", "def", "test_search_wikidata", "(", ")", ":", "\n", "# TODO", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__has_default_col_names": [[20, 25], ["pytest.mark.parametrize", "recommenders.datasets.movielens.MockMovielensSchema.example"], "function", ["None"], ["from", "pyspark", ".", "sql", ".", "functions", "import", "col", "\n", "", "except", "ImportError", ":", "\n", "    ", "pass", "# skip this import if we are in pure python environment", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "integration", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_df_remove_default_col__return_success": [[27, 34], ["pytest.mark.parametrize", "recommenders.datasets.movielens.MockMovielensSchema.get_df", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df"], ["\"size, num_samples, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "1000209", ",", "\n", "3883", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_df_invalid_param__return_failure": [[36, 40], ["pytest.mark.parametrize", "pytest.raises", "recommenders.datasets.movielens.MockMovielensSchema.get_df"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df"], ["\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10000054", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_df__return_success": [[42, 64], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "recommenders.datasets.movielens.MockMovielensSchema.get_df", "type", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df"], ["1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "20000263", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_pandas_df", "(", "\n", "size", ",", "\n", "num_samples", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_spark_df__return_success": [[66, 87], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "recommenders.datasets.movielens.MockMovielensSchema.get_spark_df", "MockMovielensSchema.get_spark_df.count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_spark_df"], ["tmp", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test MovieLens dataset load as pd.DataFrame\"\"\"", "\n", "# Test if correct data are loaded", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", "\n", "df", "=", "load_pandas_df", "(", "size", "=", "size", ",", "local_cache_path", "=", "tmp", ",", "header", "=", "header", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "len", "(", "header", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "\n", "# Test title, genres, and released year load", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ",", "\"e\"", "]", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_pandas_df", "(", "\n", "size", "=", "size", ",", "\n", "header", "=", "header", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "title_col", "=", "\"Title\"", ",", "\n", "genres_col", "=", "\"Genres\"", ",", "\n", "year_col", "=", "\"Year\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_spark_df__store_tmp_file": [[89, 94], ["recommenders.datasets.movielens.MockMovielensSchema.get_spark_df", "os.path.exists", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_spark_df"], ["assert", "(", "\n", "len", "(", "df", ".", "columns", ")", "==", "7", "\n", ")", "# 4 header columns (user, item, rating, timestamp) and 3 feature columns", "\n", "assert", "\"e\"", "not", "in", "df", ".", "columns", "# only the first 4 header columns are used", "\n", "# Get two records of the same items and check if the item-features are the same.", "\n", "head", "=", "df", ".", "loc", "[", "df", "[", "\"b\"", "]", "==", "movie_example", "]", "[", ":", "2", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_schema__get_spark_df__data_serialization_default_param": [[96, 107], ["mocker.spy", "recommenders.datasets.movielens.MockMovielensSchema.get_spark_df", "mocker.spy.assert_called_once", "MockMovielensSchema.get_spark_df.count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_spark_df"], ["assert", "title", "[", "0", "]", "==", "title", "[", "1", "]", "\n", "assert", "title", "[", "0", "]", "==", "title_example", "\n", "genres", "=", "head", "[", "\"Genres\"", "]", ".", "values", "\n", "assert", "genres", "[", "0", "]", "==", "genres", "[", "1", "]", "\n", "assert", "genres", "[", "0", "]", "==", "genres_example", "\n", "year", "=", "head", "[", "\"Year\"", "]", ".", "values", "\n", "assert", "year", "[", "0", "]", "==", "year", "[", "1", "]", "\n", "assert", "year", "[", "0", "]", "==", "year_example", "\n", "\n", "# Test default arguments", "\n", "", "df", "=", "load_pandas_df", "(", "size", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_mock_movielens_data__no_name_collision": [[109, 117], ["set", "set", "set.intersection", "recommenders.datasets.movielens.DATA_FORMAT.keys", "recommenders.datasets.movielens.MOCK_DATA_FORMAT.keys"], "function", ["None"], ["assert", "len", "(", "df", ".", "columns", ")", "==", "4", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\"1m\"", ",", "3883", ",", "1", ",", "\"Toy Story (1995)\"", ",", "\"Animation|Children's|Comedy\"", ",", "\"1995\"", ")", ",", "\n", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_spark_df_mock_100__with_default_param__succeed": [[119, 123], ["recommenders.datasets.movielens.load_spark_df", "recommenders.datasets.movielens.load_spark_df.count"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], ["10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_pandas_df_mock_100__with_default_param__succeed": [[125, 130], ["recommenders.datasets.movielens.load_pandas_df", "type", "len", "df[].duplicated().any", "df[].duplicated"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["(", "\n", "\"20m\"", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_spark_df_mock_100__with_custom_param__succeed": [[132, 142], ["recommenders.datasets.movielens.load_spark_df", "recommenders.datasets.movielens.load_spark_df.count", "recommenders.datasets.movielens.load_spark_df.take", "recommenders.datasets.movielens.load_spark_df.take"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], [")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_item_df", "(", "\n", "size", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_movielens.test_load_pandas_df_mock_100__with_custom_param__succeed": [[144, 153], ["recommenders.datasets.movielens.load_pandas_df", "type", "type", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["    ", "\"\"\"Test movielens item data load (not rating data)\"\"\"", "\n", "df", "=", "load_item_df", "(", "size", ",", "local_cache_path", "=", "tmp", ",", "title_col", "=", "\"title\"", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_movies", "\n", "# movie_col and title_col should be loaded", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "2", "\n", "assert", "df", "[", "\"title\"", "]", "[", "0", "]", "==", "title_example", "\n", "\n", "# Test title and genres", "\n", "df", "=", "load_item_df", "(", "\n", "size", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.files_fixtures": [[12, 17], ["None"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "files_fixtures", "(", ")", ":", "\n", "    ", "file_url", "=", "\"https://raw.githubusercontent.com/Microsoft/Recommenders/main/LICENSE\"", "\n", "filepath", "=", "\"license.txt\"", "\n", "return", "file_url", ",", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.test_maybe_download": [[19, 27], ["os.path.exists", "recommenders.datasets.download_utils.maybe_download", "os.path.exists", "os.remove", "recommenders.datasets.download_utils.maybe_download.split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "test_maybe_download", "(", "files_fixtures", ")", ":", "\n", "    ", "file_url", ",", "filepath", "=", "files_fixtures", "\n", "if", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "os", ".", "remove", "(", "filepath", ")", "\n", "\n", "", "downloaded_filepath", "=", "maybe_download", "(", "file_url", ",", "\"license.txt\"", ",", "expected_bytes", "=", "1162", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "downloaded_filepath", ")", "\n", "assert", "downloaded_filepath", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "==", "\"license.txt\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.test_maybe_download_wrong_bytes": [[29, 40], ["caplog.clear", "caplog.set_level", "os.path.exists", "os.remove", "pytest.raises", "recommenders.datasets.download_utils.maybe_download"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "def", "test_maybe_download_wrong_bytes", "(", "caplog", ",", "files_fixtures", ")", ":", "\n", "    ", "caplog", ".", "clear", "(", ")", "\n", "caplog", ".", "set_level", "(", "logging", ".", "INFO", ")", "\n", "\n", "file_url", ",", "filepath", "=", "files_fixtures", "\n", "if", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "os", ".", "remove", "(", "filepath", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "IOError", ")", ":", "\n", "        ", "filepath", "=", "maybe_download", "(", "file_url", ",", "\"license.txt\"", ",", "expected_bytes", "=", "0", ")", "\n", "assert", "\"Failed to verify license.txt\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.test_maybe_download_maybe": [[42, 54], ["caplog.clear", "caplog.set_level", "os.path.exists", "recommenders.datasets.download_utils.maybe_download", "os.path.exists", "recommenders.datasets.download_utils.maybe_download", "os.remove"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "", "def", "test_maybe_download_maybe", "(", "caplog", ",", "files_fixtures", ")", ":", "\n", "    ", "caplog", ".", "clear", "(", ")", "\n", "caplog", ".", "set_level", "(", "logging", ".", "INFO", ")", "\n", "\n", "file_url", ",", "filepath", "=", "files_fixtures", "\n", "if", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "os", ".", "remove", "(", "filepath", ")", "\n", "\n", "", "downloaded_filepath", "=", "maybe_download", "(", "file_url", ",", "\"license.txt\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "downloaded_filepath", ")", "\n", "maybe_download", "(", "file_url", ",", "\"license.txt\"", ")", "\n", "assert", "\"File ./license.txt already downloaded\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.test_maybe_download_retry": [[56, 64], ["caplog.clear", "caplog.set_level", "pytest.raises", "recommenders.datasets.download_utils.maybe_download"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download"], ["", "def", "test_maybe_download_retry", "(", "caplog", ")", ":", "\n", "    ", "caplog", ".", "clear", "(", ")", "\n", "caplog", ".", "set_level", "(", "logging", ".", "INFO", ")", "\n", "with", "pytest", ".", "raises", "(", "requests", ".", "exceptions", ".", "HTTPError", ")", ":", "\n", "        ", "maybe_download", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/non_existing_file.zip\"", "\n", ")", "\n", "assert", "\"Problem downloading\"", "in", "caplog", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_dataset.test_download_path": [[66, 77], ["tempfile.TemporaryDirectory", "os.path.isdir", "recommenders.datasets.download_utils.download_path", "os.path.isdir", "os.path.isdir", "recommenders.datasets.download_utils.download_path", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.download_path"], ["", "", "def", "test_download_path", "(", ")", ":", "\n", "# Check that the temporal path is created and deleted", "\n", "    ", "with", "download_path", "(", ")", "as", "path", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "path", ")", "\n", "", "assert", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", "\n", "\n", "# Check the behavior when a path is provided", "\n", "tmp_dir", "=", "TemporaryDirectory", "(", ")", "\n", "with", "download_path", "(", "tmp_dir", ".", "name", ")", "as", "path", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "path", ")", "\n", "", "assert", "os", ".", "path", ".", "isdir", "(", "path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.user_item_dataset": [[20, 32], ["pytest.fixture", "pandas.DataFrame", "pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "user_item_dataset", "(", ")", ":", "\n", "    ", "\"\"\"Get users and items dataframe\"\"\"", "\n", "user_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"user_id\"", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\"user_age\"", ":", "[", "23", ",", "24", ",", "25", ",", "26", ",", "27", "]", "}", "\n", ")", "\n", "\n", "item_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"item_id\"", ":", "[", "6", ",", "7", ",", "8", "]", ",", "\"item_feat\"", ":", "[", "[", "0.1", ",", "0.1", "]", ",", "[", "0.2", ",", "0.2", "]", ",", "[", "0.3", ",", "0.3", "]", "]", "}", "\n", ")", "\n", "\n", "return", "user_df", ",", "item_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_negative_feedback_sampler": [[34, 126], ["pandas.DataFrame", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "pandas.DataFrame", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "numpy.all", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "numpy.all", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts().to_dict", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts().to_dict", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts().to_dict", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts().to_dict", "set", "set", "sample_df[].unique", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.sort_values", "pd.DataFrame.sort_values", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.feedback.value_counts", "recommenders.datasets.pandas_df_utils.negative_feedback_sampler.sort_values", "pd.DataFrame.sort_values"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.negative_feedback_sampler"], ["", "def", "test_negative_feedback_sampler", "(", ")", ":", "\n", "    ", "df", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\"userID\"", ":", "[", "1", ",", "2", ",", "3", "]", ",", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", "]", ",", "\"rating\"", ":", "[", "5", ",", "5", ",", "5", "]", "}", "\n", ")", "\n", "\n", "# Test ratio < 1", "\n", "sample_df", "=", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_label", "=", "\"rating\"", ",", "\n", "ratio_neg_per_user", "=", "0.5", ",", "\n", ")", "\n", "assert", "sample_df", ".", "shape", "==", "(", "6", ",", "3", ")", "\n", "assert", "sample_df", ".", "feedback", ".", "value_counts", "(", ")", ".", "to_dict", "(", ")", "==", "{", "0", ":", "3", ",", "1", ":", "3", "}", "\n", "for", "i", "in", "[", "1", ",", "2", ",", "3", "]", ":", "\n", "        ", "assert", "(", "\n", "sample_df", "[", "\n", "(", "sample_df", ".", "userID", "==", "i", ")", "&", "(", "sample_df", ".", "itemID", "==", "i", ")", "\n", "]", ".", "feedback", ".", "values", "[", "0", "]", "\n", "==", "1", "\n", ")", "\n", "\n", "# Test ratio == 1", "\n", "", "sample_df", "=", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_label", "=", "\"rating\"", ",", "\n", "ratio_neg_per_user", "=", "1", ",", "\n", ")", "\n", "assert", "sample_df", ".", "shape", "==", "(", "6", ",", "3", ")", "\n", "assert", "sample_df", ".", "feedback", ".", "value_counts", "(", ")", ".", "to_dict", "(", ")", "==", "{", "0", ":", "3", ",", "1", ":", "3", "}", "\n", "for", "i", "in", "[", "1", ",", "2", ",", "3", "]", ":", "\n", "        ", "assert", "(", "\n", "sample_df", "[", "\n", "(", "sample_df", ".", "userID", "==", "i", ")", "&", "(", "sample_df", ".", "itemID", "==", "i", ")", "\n", "]", ".", "feedback", ".", "values", "[", "0", "]", "\n", "==", "1", "\n", ")", "\n", "\n", "", "res_df", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\n", "\"userID\"", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", ",", "2", ",", "3", ",", "1", ",", "3", ",", "1", ",", "2", "]", ",", "\n", "\"feedback\"", ":", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "# Test ratio > 1", "\n", "sample_df", "=", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_label", "=", "\"rating\"", ",", "\n", "ratio_neg_per_user", "=", "2", ",", "\n", ")", "\n", "assert", "sample_df", ".", "shape", "==", "(", "9", ",", "3", ")", "\n", "assert", "sample_df", ".", "feedback", ".", "value_counts", "(", ")", ".", "to_dict", "(", ")", "==", "{", "0", ":", "6", ",", "1", ":", "3", "}", "\n", "assert", "np", ".", "all", "(", "\n", "sample_df", ".", "sort_values", "(", "[", "\"userID\"", ",", "\"itemID\"", "]", ")", ".", "values", "\n", "==", "res_df", ".", "sort_values", "(", "[", "\"userID\"", ",", "\"itemID\"", "]", ")", ".", "values", "\n", ")", "\n", "\n", "# Test too large ratio", "\n", "sample_df", "=", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_label", "=", "\"rating\"", ",", "\n", "ratio_neg_per_user", "=", "3", ",", "\n", ")", "\n", "assert", "sample_df", ".", "shape", "==", "(", "9", ",", "3", ")", "\n", "assert", "sample_df", ".", "feedback", ".", "value_counts", "(", ")", ".", "to_dict", "(", ")", "==", "{", "0", ":", "6", ",", "1", ":", "3", "}", "\n", "assert", "np", ".", "all", "(", "\n", "sample_df", ".", "sort_values", "(", "[", "\"userID\"", ",", "\"itemID\"", "]", ")", ".", "values", "\n", "==", "res_df", ".", "sort_values", "(", "[", "\"userID\"", ",", "\"itemID\"", "]", ")", ".", "values", "\n", ")", "\n", "\n", "# Test other options", "\n", "sample_df", "=", "negative_feedback_sampler", "(", "\n", "df", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_label", "=", "\"rating\"", ",", "\n", "col_feedback", "=", "\"test_feedback\"", ",", "\n", "pos_value", "=", "2.4", ",", "\n", "neg_value", "=", "0.2", ",", "\n", "ratio_neg_per_user", "=", "3", ",", "\n", ")", "\n", "assert", "sample_df", ".", "columns", "[", "2", "]", "==", "\"test_feedback\"", "\n", "assert", "set", "(", "sample_df", "[", "\"test_feedback\"", "]", ".", "unique", "(", ")", ")", "==", "set", "(", "[", "2.4", ",", "0.2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_filter_by": [[128, 145], ["pandas.DataFrame", "pandas.DataFrame", "recommenders.datasets.pandas_df_utils.filter_by", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.filter_by"], ["", "def", "test_filter_by", "(", ")", ":", "\n", "    ", "user_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"user_id\"", ":", "[", "1", ",", "9", ",", "3", ",", "5", ",", "5", ",", "1", "]", ",", "\"item_id\"", ":", "[", "1", ",", "6", ",", "7", ",", "6", ",", "8", ",", "9", "]", "}", "\n", ")", "\n", "\n", "seen_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"user_id\"", ":", "[", "1", ",", "2", ",", "4", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "filtered_df", "=", "filter_by", "(", "user_df", ",", "seen_df", ",", "[", "\"user_id\"", "]", ")", "\n", "\n", "# Check filtered out number", "\n", "assert", "len", "(", "filtered_df", ")", "==", "len", "(", "user_df", ")", "-", "2", "\n", "# Check filtered out record", "\n", "assert", "len", "(", "filtered_df", ".", "loc", "[", "(", "user_df", "[", "\"user_id\"", "]", "==", "1", ")", "]", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_csv_to_libffm": [[147, 231], ["pandas.DataFrame", "tempfile.TemporaryDirectory", "os.path.join", "recommenders.datasets.pandas_df_utils.LibffmConverter().fit", "LibffmConverter().fit.transform", "pd.DataFrame.copy", "os.path.isfile", "LibffmConverter().fit.get_params", "pandas.DataFrame", "LibffmConverter().fit.transform", "pytest.raises", "recommenders.datasets.pandas_df_utils.LibffmConverter().fit", "converter.transform.iloc[].values.tolist", "converter.transform.iloc[].values.tolist", "open", "f.readline", "converter.transform.iloc[].values.tolist", "converter.transform.iloc[].values.tolist", "recommenders.datasets.pandas_df_utils.LibffmConverter", "recommenders.datasets.pandas_df_utils.LibffmConverter"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform", "home.repos.pwc.inspect_result.microsoft_recommenders.nni.svd_training.get_params", "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "test_csv_to_libffm", "(", ")", ":", "\n", "    ", "df_feature", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"rating\"", ":", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", ",", "\n", "\"field1\"", ":", "[", "\"xxx1\"", ",", "\"xxx2\"", ",", "\"xxx4\"", ",", "\"xxx4\"", ",", "\"xxx4\"", "]", ",", "\n", "\"field2\"", ":", "[", "3", ",", "4", ",", "5", ",", "6", ",", "7", "]", ",", "\n", "\"field3\"", ":", "[", "1.0", ",", "2.0", ",", "3.0", ",", "4.0", ",", "5.0", "]", ",", "\n", "\"field4\"", ":", "[", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "with", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "td", ",", "\"test\"", ")", "\n", "\n", "converter", "=", "LibffmConverter", "(", "filepath", "=", "filepath", ")", ".", "fit", "(", "df_feature", ")", "\n", "df_feature_libffm", "=", "converter", ".", "transform", "(", "df_feature", ")", "\n", "\n", "# Check the input column types. For example, a bool type is not allowed.", "\n", "df_feature_wrong_type", "=", "df_feature", ".", "copy", "(", ")", "\n", "df_feature_wrong_type", "[", "\"field4\"", "]", "=", "True", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", "as", "e", ":", "\n", "            ", "LibffmConverter", "(", ")", ".", "fit", "(", "df_feature_wrong_type", ")", "\n", "assert", "(", "\n", "e", ".", "value", "==", "\"Input columns should be only object and/or numeric types.\"", "\n", ")", "\n", "\n", "# Check if the dim is the same.", "\n", "", "assert", "df_feature_libffm", ".", "shape", "==", "df_feature", ".", "shape", "\n", "\n", "# Check if the columns are converted successfully.", "\n", "assert", "df_feature_libffm", ".", "iloc", "[", "0", ",", ":", "]", ".", "values", ".", "tolist", "(", ")", "==", "[", "\n", "1", ",", "\n", "\"1:1:1\"", ",", "\n", "\"2:4:3\"", ",", "\n", "\"3:5:1.0\"", ",", "\n", "\"4:6:1\"", ",", "\n", "]", "\n", "\n", "# Check if the duplicated column entries are indexed correctly.", "\n", "# It should skip counting the duplicated features in a field column.", "\n", "assert", "df_feature_libffm", ".", "iloc", "[", "-", "1", ",", ":", "]", ".", "values", ".", "tolist", "(", ")", "==", "[", "\n", "1", ",", "\n", "\"1:3:1\"", ",", "\n", "\"2:4:7\"", ",", "\n", "\"3:5:5.0\"", ",", "\n", "\"4:10:1\"", ",", "\n", "]", "\n", "\n", "# Check if the file is written successfully.", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "filepath", ")", "\n", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "line", "=", "f", ".", "readline", "(", ")", "\n", "assert", "line", "==", "\"1 1:1:1 2:4:3 3:5:1.0 4:6:1\\n\"", "\n", "\n", "# Parameters in the transformation should be reported correctly.", "\n", "", "params", "=", "converter", ".", "get_params", "(", ")", "\n", "assert", "params", "==", "{", "\"field count\"", ":", "4", ",", "\"feature count\"", ":", "10", ",", "\"file path\"", ":", "filepath", "}", "\n", "\n", "# Dataset with the same columns should be transformable with a fitted converter.", "\n", "df_feature_new", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"rating\"", ":", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "\"field1\"", ":", "[", "\"xxx1\"", ",", "\"xxx2\"", ",", "\"xxx4\"", ",", "\"xxx4\"", ",", "\"xxx4\"", ",", "\"xxx3\"", "]", ",", "\n", "\"field2\"", ":", "[", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", "]", ",", "\n", "\"field3\"", ":", "[", "1.0", ",", "2.0", ",", "3.0", ",", "4.0", ",", "5.0", ",", "6.0", "]", ",", "\n", "\"field4\"", ":", "[", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\"6\"", "]", ",", "\n", "}", "\n", ")", "\n", "df_feature_new_libffm", "=", "converter", ".", "transform", "(", "df_feature_new", ")", "\n", "\n", "assert", "df_feature_new_libffm", ".", "iloc", "[", "0", ",", ":", "]", ".", "values", ".", "tolist", "(", ")", "==", "[", "\n", "1", ",", "\n", "\"1:1:1\"", ",", "\n", "\"2:5:3\"", ",", "\n", "\"3:6:1.0\"", ",", "\n", "\"4:7:1\"", ",", "\n", "]", "\n", "assert", "df_feature_new_libffm", ".", "iloc", "[", "-", "1", ",", ":", "]", ".", "values", ".", "tolist", "(", ")", "==", "[", "\n", "1", ",", "\n", "\"1:4:1\"", ",", "\n", "\"2:5:8\"", ",", "\n", "\"3:6:6.0\"", ",", "\n", "\"4:12:1\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_has_columns": [[234, 242], ["pandas.DataFrame", "pandas.DataFrame", "recommenders.datasets.pandas_df_utils.has_columns", "recommenders.datasets.pandas_df_utils.has_columns", "recommenders.datasets.pandas_df_utils.has_columns", "dict", "dict", "recommenders.datasets.pandas_df_utils.has_columns"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns"], ["", "", "def", "test_has_columns", "(", ")", ":", "\n", "    ", "df_1", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "df_2", "=", "pd", ".", "DataFrame", "(", "dict", "(", "b", "=", "[", "7", ",", "8", ",", "9", "]", ",", "a", "=", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "\n", "assert", "has_columns", "(", "df_1", ",", "[", "\"a\"", "]", ")", "\n", "assert", "has_columns", "(", "df_2", ",", "[", "\"a\"", "]", ")", "\n", "assert", "has_columns", "(", "df_2", ",", "[", "\"a\"", ",", "\"b\"", "]", ")", "\n", "assert", "not", "has_columns", "(", "df_2", ",", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_has_same_base_dtype": [[244, 272], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "dict", "dict", "dict", "dict", "dict", "dict", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "recommenders.datasets.pandas_df_utils.has_same_base_dtype"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype"], ["", "def", "test_has_same_base_dtype", "(", ")", ":", "\n", "    ", "arr_int32", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "arr_int64", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "arr_float32", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr_float64", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "arr_str", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", "\n", "\n", "df_1", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_int32", ",", "b", "=", "arr_int64", ")", ")", "\n", "df_2", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_int64", ",", "b", "=", "arr_int32", ")", ")", "\n", "df_3", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_float32", ",", "b", "=", "arr_int32", ")", ")", "\n", "df_4", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_float64", ",", "b", "=", "arr_float64", ")", ")", "\n", "df_5", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_float64", ",", "b", "=", "arr_float64", ",", "c", "=", "arr_float64", ")", ")", "\n", "df_6", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "arr_str", ")", ")", "\n", "\n", "# all columns match", "\n", "assert", "has_same_base_dtype", "(", "df_1", ",", "df_2", ")", "\n", "# specific column matches", "\n", "assert", "has_same_base_dtype", "(", "df_3", ",", "df_4", ",", "columns", "=", "[", "\"a\"", "]", ")", "\n", "# some column types do not match", "\n", "assert", "not", "has_same_base_dtype", "(", "df_3", ",", "df_4", ")", "\n", "# column types do not match", "\n", "assert", "not", "has_same_base_dtype", "(", "df_1", ",", "df_3", ",", "columns", "=", "[", "\"a\"", "]", ")", "\n", "# all columns are not shared", "\n", "assert", "not", "has_same_base_dtype", "(", "df_4", ",", "df_5", ")", "\n", "# column types do not match", "\n", "assert", "not", "has_same_base_dtype", "(", "df_5", ",", "df_6", ",", "columns", "=", "[", "\"a\"", "]", ")", "\n", "# assert string columns match", "\n", "assert", "has_same_base_dtype", "(", "df_6", ",", "df_6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.test_pandas_df_utils.test_lru_cache_df": [[274, 317], ["pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "recommenders.datasets.pandas_df_utils.lru_cache_df", "test_pandas_df_utils.test_lru_cache_df.cached_func"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df"], ["", "def", "test_lru_cache_df", "(", ")", ":", "\n", "    ", "df1", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "[", "1", ",", "2", ",", "3", "]", ",", "b", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", ")", ")", "\n", "df2", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "[", "1", ",", "2", ",", "3", "]", ",", "c", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", ")", ")", "\n", "df3", "=", "pd", ".", "DataFrame", "(", "dict", "(", "a", "=", "[", "1", ",", "2", ",", "3", "]", ",", "b", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"d\"", "]", ")", ")", "\n", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "2", ")", "\n", "def", "cached_func", "(", "df", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "assert", "\"CacheInfo(hits=0, misses=0, maxsize=2, currsize=0)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df1", ")", "\n", "assert", "\"CacheInfo(hits=0, misses=1, maxsize=2, currsize=1)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df1", ")", "\n", "assert", "\"CacheInfo(hits=1, misses=1, maxsize=2, currsize=1)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df2", ")", "\n", "assert", "\"CacheInfo(hits=1, misses=2, maxsize=2, currsize=2)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df2", ")", "\n", "assert", "\"CacheInfo(hits=2, misses=2, maxsize=2, currsize=2)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df3", ")", "\n", "assert", "\"CacheInfo(hits=2, misses=3, maxsize=2, currsize=2)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df1", ")", "\n", "assert", "\"CacheInfo(hits=2, misses=4, maxsize=2, currsize=2)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", "(", "df3", ")", "\n", "assert", "\"CacheInfo(hits=3, misses=4, maxsize=2, currsize=2)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n", "cached_func", ".", "cache_clear", "(", ")", "\n", "assert", "\"CacheInfo(hits=0, misses=0, maxsize=2, currsize=0)\"", "==", "str", "(", "\n", "cached_func", ".", "cache_info", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.parameter_sweep.generate_param_grid": [[9, 57], ["params.items", "sorted", "zip", "itertools.product", "isinstance", "param_new.items", "dict", "dict.update", "params_exp.append", "zip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["def", "generate_param_grid", "(", "params", ")", ":", "\n", "    ", "\"\"\"Generator of parameter grids.\n    Generate parameter lists from a parameter dictionary in the form of:\n\n    .. code-block:: python\n\n       {\n           \"param1\": [value1, value2],\n           \"param2\": [value1, value2]\n       }\n\n    to:\n\n    .. code-block:: python\n\n       [\n           {\"param1\": value1, \"param2\": value1},\n           {\"param1\": value2, \"param2\": value1},\n           {\"param1\": value1, \"param2\": value2},\n           {\"param1\": value2, \"param2\": value2}\n       ]\n\n    Args:\n        param_dict (dict): dictionary of parameters and values (in a list).\n\n    Return:\n        list: A list of parameter dictionary string that can be fed directly into\n        model builder as keyword arguments.\n    \"\"\"", "\n", "param_new", "=", "{", "}", "\n", "param_fixed", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "            ", "param_new", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "            ", "param_fixed", "[", "key", "]", "=", "value", "\n", "\n", "", "", "items", "=", "sorted", "(", "param_new", ".", "items", "(", ")", ")", "\n", "keys", ",", "values", "=", "zip", "(", "*", "items", ")", "\n", "\n", "params_exp", "=", "[", "]", "\n", "for", "v", "in", "product", "(", "*", "values", ")", ":", "\n", "        ", "param_exp", "=", "dict", "(", "zip", "(", "keys", ",", "v", ")", ")", "\n", "param_exp", ".", "update", "(", "param_fixed", ")", "\n", "params_exp", ".", "append", "(", "param_exp", ")", "\n", "\n", "", "return", "params_exp", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponse.__init__": [[24, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "content", ",", "error", ")", ":", "\n", "        ", "self", ".", "_content", "=", "content", "\n", "self", ".", "_error", "=", "error", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponse.json": [[28, 30], ["None"], "methods", ["None"], ["", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"status\"", ":", "self", ".", "_content", ",", "\"errors\"", ":", "[", "self", ".", "_error", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.__init__": [[39, 41], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "content", ")", ":", "\n", "        ", "self", ".", "_content", "=", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json": [[42, 44], ["None"], "methods", ["None"], ["", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_content", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get": [[32, 35], ["url.startswith", "test_nni_utils.MockResponse"], "function", ["None"], ["", "", "def", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", ":", "\n", "    ", "assert", "url", ".", "startswith", "(", "NNI_STATUS_URL", ")", "\n", "return", "MockResponse", "(", "content", ",", "error", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_trials_get": [[46, 49], ["url.startswith", "test_nni_utils.MockResponseTrials"], "function", ["None"], ["", "", "def", "mocked_trials_get", "(", "url", ",", "content", ")", ":", "\n", "    ", "assert", "url", ".", "startswith", "(", "NNI_TRIAL_JOBS_URL", ")", "\n", "return", "MockResponseTrials", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mock_exception": [[51, 53], ["Exception"], "function", ["None"], ["", "def", "mock_exception", "(", ")", ":", "\n", "    ", "raise", "Exception", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_get_experiment_status": [[55, 65], ["pytest.mark.skipif", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.get_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_get_experiment_status", "(", ")", ":", "\n", "    ", "content", "=", "\"some_status\"", "\n", "error", "=", "\"\"", "\n", "with", "patch", "(", "\n", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", "\n", ")", ":", "\n", "        ", "nni_status", "=", "get_experiment_status", "(", "NNI_STATUS_URL", ")", "\n", "assert", "nni_status", "[", "\"status\"", "]", "==", "\"some_status\"", "\n", "assert", "nni_status", "[", "\"errors\"", "]", "==", "[", "\"\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_experiment_status_done": [[67, 75], ["pytest.mark.skipif", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_experiment_status_done", "(", ")", ":", "\n", "    ", "content", "=", "\"DONE\"", "\n", "error", "=", "\"\"", "\n", "with", "patch", "(", "\n", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", "\n", ")", ":", "\n", "        ", "check_experiment_status", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_experiment_status_tuner_no_more_trial": [[77, 85], ["pytest.mark.skipif", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_experiment_status_tuner_no_more_trial", "(", ")", ":", "\n", "    ", "content", "=", "\"TUNER_NO_MORE_TRIAL\"", "\n", "error", "=", "\"\"", "\n", "with", "patch", "(", "\n", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", "\n", ")", ":", "\n", "        ", "check_experiment_status", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_experiment_status_running": [[87, 98], ["pytest.mark.skipif", "pytest.raises", "str", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_experiment_status_running", "(", ")", ":", "\n", "    ", "content", "=", "\"RUNNING\"", "\n", "error", "=", "\"\"", "\n", "with", "pytest", ".", "raises", "(", "TimeoutError", ")", "as", "excinfo", ":", "\n", "        ", "with", "patch", "(", "\n", "\"requests.get\"", ",", "\n", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", ",", "\n", ")", ":", "\n", "            ", "check_experiment_status", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "", "", "assert", "\"check_experiment_status() timed out\"", "==", "str", "(", "excinfo", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_experiment_status_no_more_trial": [[100, 111], ["pytest.mark.skipif", "pytest.raises", "str", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_experiment_status_no_more_trial", "(", ")", ":", "\n", "    ", "content", "=", "\"NO_MORE_TRIAL\"", "\n", "error", "=", "\"\"", "\n", "with", "pytest", ".", "raises", "(", "TimeoutError", ")", "as", "excinfo", ":", "\n", "        ", "with", "patch", "(", "\n", "\"requests.get\"", ",", "\n", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", ",", "\n", ")", ":", "\n", "            ", "check_experiment_status", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "", "", "assert", "\"check_experiment_status() timed out\"", "==", "str", "(", "excinfo", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_experiment_status_failed": [[113, 126], ["pytest.mark.skipif", "pytest.raises", "str", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_experiment_status", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_experiment_status_failed", "(", ")", ":", "\n", "    ", "content", "=", "\"some_failed_status\"", "\n", "error", "=", "\"NNI_ERROR\"", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", "as", "excinfo", ":", "\n", "        ", "with", "patch", "(", "\n", "\"requests.get\"", ",", "\n", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", ",", "\n", ")", ":", "\n", "            ", "check_experiment_status", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "", "", "assert", "(", "\n", "\"NNI experiment failed to complete with status some_failed_status - NNI_ERROR\"", "\n", "==", "str", "(", "excinfo", ".", "value", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_stopped_timeout": [[129, 140], ["pytest.mark.skipif", "pytest.raises", "str", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_stopped", "test_nni_utils.mocked_status_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_stopped", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_status_get"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_stopped_timeout", "(", ")", ":", "\n", "    ", "content", "=", "\"some_status\"", "\n", "error", "=", "\"\"", "\n", "with", "pytest", ".", "raises", "(", "TimeoutError", ")", "as", "excinfo", ":", "\n", "        ", "with", "patch", "(", "\n", "\"requests.get\"", ",", "\n", "side_effect", "=", "lambda", "url", ":", "mocked_status_get", "(", "url", ",", "content", ",", "error", ")", ",", "\n", ")", ":", "\n", "            ", "check_stopped", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "", "", "assert", "\"check_stopped() timed out\"", "==", "str", "(", "excinfo", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_stopped": [[142, 146], ["pytest.mark.skipif", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_stopped"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_stopped"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_stopped", "(", ")", ":", "\n", "    ", "with", "patch", "(", "\"requests.get\"", ",", "side_effect", "=", "mock_exception", ")", ":", "\n", "        ", "check_stopped", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_metrics_written": [[148, 153], ["pytest.mark.skipif", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_metrics_written", "test_nni_utils.mocked_trials_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_metrics_written", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_trials_get"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_metrics_written", "(", ")", ":", "\n", "    ", "content", "=", "[", "{", "\"finalMetricData\"", ":", "None", "}", ",", "{", "\"finalMetricData\"", ":", "None", "}", "]", "\n", "with", "patch", "(", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_trials_get", "(", "url", ",", "content", ")", ")", ":", "\n", "        ", "check_metrics_written", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_check_metrics_written_timeout": [[155, 164], ["pytest.mark.skipif", "pytest.raises", "str", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.check_metrics_written", "test_nni_utils.mocked_trials_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_metrics_written", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_trials_get"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_check_metrics_written_timeout", "(", ")", ":", "\n", "    ", "content", "=", "[", "{", "\"logPath\"", ":", "\"/p\"", "}", ",", "{", "\"logPath\"", ":", "\"/q\"", "}", "]", "\n", "with", "pytest", ".", "raises", "(", "TimeoutError", ")", "as", "excinfo", ":", "\n", "        ", "with", "patch", "(", "\n", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_trials_get", "(", "url", ",", "content", ")", "\n", ")", ":", "\n", "            ", "check_metrics_written", "(", "wait", "=", "0.1", ",", "max_retries", "=", "1", ")", "\n", "", "", "assert", "\"check_metrics_written() timed out\"", "==", "str", "(", "excinfo", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.test_get_trials": [[166, 220], ["pytest.mark.skipif", "tempfile.TemporaryDirectory", "tempfile.TemporaryDirectory", "open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump", "unittest.mock.patch", "recommenders.tuning.nni.nni_utils.get_trials", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "test_nni_utils.mocked_trials_get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_trials", "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.mocked_trials_get"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"nni not installable on windows\"", ")", "\n", "def", "test_get_trials", "(", ")", ":", "\n", "    ", "with", "TemporaryDirectory", "(", ")", "as", "tmp_dir1", ",", "TemporaryDirectory", "(", ")", "as", "tmp_dir2", ":", "\n", "\n", "        ", "mock_trials", "=", "[", "\n", "{", "\n", "\"finalMetricData\"", ":", "[", "\n", "{", "\"data\"", ":", "'\"{\\\\\"rmse\\\\\": 0.8, \\\\\"default\\\\\": 0.3}\"'", "}", "\n", "]", ",", "\n", "\"logPath\"", ":", "\"file://localhost:{}\"", ".", "format", "(", "tmp_dir1", ")", ",", "\n", "}", ",", "\n", "{", "\n", "\"finalMetricData\"", ":", "[", "\n", "{", "\"data\"", ":", "'\"{\\\\\"rmse\\\\\": 0.9, \\\\\"default\\\\\": 0.2}\"'", "}", "\n", "]", ",", "\n", "\"logPath\"", ":", "\"file://localhost:{}\"", ".", "format", "(", "tmp_dir2", ")", ",", "\n", "}", ",", "\n", "]", "\n", "metrics1", "=", "{", "\"rmse\"", ":", "0.8", ",", "\"precision_at_k\"", ":", "0.3", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir1", ",", "\"metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "metrics1", ",", "f", ")", "\n", "", "params1", "=", "{", "\n", "\"parameter_id\"", ":", "1", ",", "\n", "\"parameter_source\"", ":", "\"algorithm\"", ",", "\n", "\"parameters\"", ":", "{", "\"n_factors\"", ":", "100", ",", "\"reg\"", ":", "0.1", "}", ",", "\n", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir1", ",", "\"parameter.cfg\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "params1", ",", "f", ")", "\n", "", "metrics2", "=", "{", "\"rmse\"", ":", "0.9", ",", "\"precision_at_k\"", ":", "0.2", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir2", ",", "\"metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "metrics2", ",", "f", ")", "\n", "", "params2", "=", "{", "\n", "\"parameter_id\"", ":", "2", ",", "\n", "\"parameter_source\"", ":", "\"algorithm\"", ",", "\n", "\"parameters\"", ":", "{", "\"n_factors\"", ":", "50", ",", "\"reg\"", ":", "0.02", "}", ",", "\n", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir2", ",", "\"parameter.cfg\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "params2", ",", "f", ")", "\n", "\n", "", "with", "patch", "(", "\n", "\"requests.get\"", ",", "side_effect", "=", "lambda", "url", ":", "mocked_trials_get", "(", "url", ",", "mock_trials", ")", "\n", ")", ":", "\n", "            ", "trials", ",", "best_metrics", ",", "best_params", ",", "best_trial_path", "=", "get_trials", "(", "\n", "optimize_mode", "=", "\"maximize\"", "\n", ")", "\n", "\n", "", "expected_trials", "=", "[", "\n", "(", "{", "\"rmse\"", ":", "0.8", ",", "\"default\"", ":", "0.3", "}", ",", "tmp_dir1", ")", ",", "\n", "(", "{", "\"rmse\"", ":", "0.9", ",", "\"default\"", ":", "0.2", "}", ",", "tmp_dir2", ")", ",", "\n", "]", "\n", "assert", "trials", "==", "expected_trials", "\n", "assert", "best_metrics", "==", "metrics1", "\n", "assert", "best_params", "==", "params1", "\n", "assert", "best_trial_path", "==", "tmp_dir1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_sweep.parameter_dictionary": [[10, 15], ["pytest.fixture"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "parameter_dictionary", "(", ")", ":", "\n", "    ", "params", "=", "{", "\"param1\"", ":", "[", "1", ",", "2", ",", "3", "]", ",", "\"param2\"", ":", "[", "4", ",", "5", ",", "6", "]", ",", "\"param3\"", ":", "1", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_sweep.test_param_sweep": [[17, 30], ["recommenders.tuning.parameter_sweep.generate_param_grid"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tuning.parameter_sweep.generate_param_grid"], ["", "def", "test_param_sweep", "(", "parameter_dictionary", ")", ":", "\n", "    ", "params_grid", "=", "generate_param_grid", "(", "parameter_dictionary", ")", "\n", "\n", "assert", "params_grid", "==", "[", "\n", "{", "\"param1\"", ":", "1", ",", "\"param2\"", ":", "4", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "1", ",", "\"param2\"", ":", "5", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "1", ",", "\"param2\"", ":", "6", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "2", ",", "\"param2\"", ":", "4", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "2", ",", "\"param2\"", ":", "5", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "2", ",", "\"param2\"", ":", "6", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "3", ",", "\"param2\"", ":", "4", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "3", ",", "\"param2\"", ":", "5", ",", "\"param3\"", ":", "1", "}", ",", "\n", "{", "\"param1\"", ":", "3", ",", "\"param2\"", ":", "6", ",", "\"param3\"", ":", "1", "}", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_ncf_utils.mock_model": [[11, 23], ["pytest.fixture", "unittest.mock.Mock"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "mock_model", "(", ")", ":", "\n", "    ", "def", "mock_predict", "(", "*", "args", ",", "is_list", "=", "False", ")", ":", "\n", "        ", "\"\"\" Mock model predict method\"\"\"", "\n", "if", "is_list", ":", "\n", "            ", "return", "[", "0", "]", "*", "DATA_SIZE", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n", "", "", "mock_model", "=", "Mock", "(", ")", "\n", "mock_model", ".", "predict", ".", "side_effect", "=", "mock_predict", "\n", "return", "mock_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_ncf_utils.fake_movielens_df": [[25, 28], ["pytest.fixture", "recommenders.datasets.movielens.MockMovielensSchema.get_df"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.MockMovielensSchema.get_df"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "fake_movielens_df", "(", ")", ":", "\n", "    ", "return", "MockMovielensSchema", ".", "get_df", "(", "size", "=", "DATA_SIZE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_ncf_utils.test_compute_test_results__return_success": [[30, 40], ["recommenders.tuning.nni.ncf_utils.compute_test_results"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_utils.compute_test_results"], ["", "def", "test_compute_test_results__return_success", "(", "mock_model", ",", "fake_movielens_df", ")", ":", "\n", "    ", "mock_metric_func", "=", "\"lambda *args, **kwargs: 0\"", "\n", "compute_test_results", "(", "\n", "mock_model", ",", "\n", "fake_movielens_df", ",", "\n", "fake_movielens_df", ",", "\n", "[", "mock_metric_func", "]", ",", "\n", "[", "mock_metric_func", "]", ",", "\n", ")", "\n", "assert", "mock_model", ".", "predict", ".", "is_called", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training._update_metrics": [[21, 28], ["logger.debug"], "function", ["None"], ["def", "_update_metrics", "(", "metrics_dict", ",", "metric", ",", "params", ",", "result", ")", ":", "\n", "    ", "logger", ".", "debug", "(", "\"%s@%d = %g\"", ",", "metric", ",", "params", "[", "\"k\"", "]", ",", "result", ")", "\n", "if", "metric", "==", "params", "[", "\"primary_metric\"", "]", ":", "\n", "        ", "metrics_dict", "[", "\"default\"", "]", "=", "result", "\n", "", "else", ":", "\n", "        ", "metrics_dict", "[", "metric", "]", "=", "result", "\n", "", "return", "metrics_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training.ncf_training": [[30, 120], ["logger.debug", "pandas.read_pickle", "pandas.read_pickle", "recommenders.models.ncf.dataset.Dataset", "recommenders.models.ncf.ncf_singlenode.NCF", "recommenders.models.ncf.ncf_singlenode.NCF.fit", "logger.debug", "nni.report_final_result", "os.environ.get", "len", "pandas.DataFrame", "predictions.astype.astype", "len", "list", "pd.read_pickle.userID.unique", "pandas.DataFrame", "pandas.merge", "merged[].drop", "ValueError", "open", "_update_metrics.copy", "metrics_dict.copy.pop", "json.dump", "os.path.join", "os.path.join", "ncf_training._update_metrics", "pd.read_pickle.itemID.unique", "users.extend", "items.extend", "preds.extend", "ncf_training._update_metrics", "len", "len", "os.path.join", "recommenders.models.ncf.ncf_singlenode.NCF.predict", "pd.read_pickle.iterrows", "getattr", "len", "list", "getattr", "recommenders.models.ncf.ncf_singlenode.NCF.predict", "pd.merge.rating.isnull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training._update_metrics", "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training._update_metrics", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "ncf_training", "(", "params", ")", ":", "\n", "    ", "\"\"\"\n    Train NCF using the given hyper-parameters\n    \"\"\"", "\n", "logger", ".", "debug", "(", "\"Start training...\"", ")", "\n", "train_data", "=", "pd", ".", "read_pickle", "(", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"train_datapath\"", "]", ")", "\n", ")", "\n", "validation_data", "=", "pd", ".", "read_pickle", "(", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"validation_datapath\"", "]", ")", "\n", ")", "\n", "\n", "data", "=", "NCFDataset", "(", "train", "=", "train_data", ",", "test", "=", "validation_data", ",", "seed", "=", "DEFAULT_SEED", ")", "\n", "\n", "model", "=", "NCF", "(", "\n", "n_users", "=", "data", ".", "n_users", ",", "\n", "n_items", "=", "data", ".", "n_items", ",", "\n", "model_type", "=", "\"NeuMF\"", ",", "\n", "n_factors", "=", "params", "[", "\"n_factors\"", "]", ",", "\n", "layer_sizes", "=", "[", "16", ",", "8", ",", "4", "]", ",", "\n", "n_epochs", "=", "params", "[", "\"n_epochs\"", "]", ",", "\n", "learning_rate", "=", "params", "[", "\"learning_rate\"", "]", ",", "\n", "verbose", "=", "params", "[", "\"verbose\"", "]", ",", "\n", "seed", "=", "DEFAULT_SEED", ",", "\n", ")", "\n", "\n", "model", ".", "fit", "(", "data", ")", "\n", "\n", "logger", ".", "debug", "(", "\"Evaluating...\"", ")", "\n", "\n", "metrics_dict", "=", "{", "}", "\n", "rating_metrics", "=", "params", "[", "\"rating_metrics\"", "]", "\n", "if", "len", "(", "rating_metrics", ")", ">", "0", ":", "\n", "        ", "predictions", "=", "[", "\n", "[", "row", ".", "userID", ",", "row", ".", "itemID", ",", "model", ".", "predict", "(", "row", ".", "userID", ",", "row", ".", "itemID", ")", "]", "\n", "for", "(", "_", ",", "row", ")", "in", "validation_data", ".", "iterrows", "(", ")", "\n", "]", "\n", "\n", "predictions", "=", "pd", ".", "DataFrame", "(", "\n", "predictions", ",", "columns", "=", "[", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "]", "\n", ")", "\n", "predictions", "=", "predictions", ".", "astype", "(", "\n", "{", "\"userID\"", ":", "\"int64\"", ",", "\"itemID\"", ":", "\"int64\"", ",", "\"prediction\"", ":", "\"float64\"", "}", "\n", ")", "\n", "\n", "for", "metric", "in", "rating_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "validation_data", ",", "predictions", ")", "\n", "metrics_dict", "=", "_update_metrics", "(", "metrics_dict", ",", "metric", ",", "params", ",", "result", ")", "\n", "\n", "", "", "ranking_metrics", "=", "params", "[", "\"ranking_metrics\"", "]", "\n", "if", "len", "(", "ranking_metrics", ")", ">", "0", ":", "\n", "        ", "users", ",", "items", ",", "preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "item", "=", "list", "(", "train_data", ".", "itemID", ".", "unique", "(", ")", ")", "\n", "for", "user", "in", "train_data", ".", "userID", ".", "unique", "(", ")", ":", "\n", "            ", "user", "=", "[", "user", "]", "*", "len", "(", "item", ")", "\n", "users", ".", "extend", "(", "user", ")", "\n", "items", ".", "extend", "(", "item", ")", "\n", "preds", ".", "extend", "(", "list", "(", "model", ".", "predict", "(", "user", ",", "item", ",", "is_list", "=", "True", ")", ")", ")", "\n", "\n", "", "all_predictions", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\"userID\"", ":", "users", ",", "\"itemID\"", ":", "items", ",", "\"prediction\"", ":", "preds", "}", "\n", ")", "\n", "\n", "merged", "=", "pd", ".", "merge", "(", "\n", "train_data", ",", "all_predictions", ",", "on", "=", "[", "\"userID\"", ",", "\"itemID\"", "]", ",", "how", "=", "\"outer\"", "\n", ")", "\n", "all_predictions", "=", "merged", "[", "merged", ".", "rating", ".", "isnull", "(", ")", "]", ".", "drop", "(", "\"rating\"", ",", "axis", "=", "1", ")", "\n", "for", "metric", "in", "ranking_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "\n", "validation_data", ",", "\n", "all_predictions", ",", "\n", "col_prediction", "=", "\"prediction\"", ",", "\n", "k", "=", "params", "[", "\"k\"", "]", ",", "\n", ")", "\n", "metrics_dict", "=", "_update_metrics", "(", "metrics_dict", ",", "metric", ",", "params", ",", "result", ")", "\n", "\n", "", "", "if", "len", "(", "ranking_metrics", ")", "==", "0", "and", "len", "(", "rating_metrics", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"No metrics were specified.\"", ")", "\n", "\n", "# Report the metrics", "\n", "", "nni", ".", "report_final_result", "(", "metrics_dict", ")", "\n", "\n", "# Save the metrics in a JSON file", "\n", "output_dir", "=", "os", ".", "environ", ".", "get", "(", "\"NNI_OUTPUT_DIR\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"metrics.json\"", ")", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "temp_dict", "=", "metrics_dict", ".", "copy", "(", ")", "\n", "temp_dict", "[", "params", "[", "\"primary_metric\"", "]", "]", "=", "temp_dict", ".", "pop", "(", "\"default\"", ")", "\n", "json", ".", "dump", "(", "temp_dict", ",", "fp", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training.get_params": [[122, 152], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_params", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Data path", "\n", "parser", ".", "add_argument", "(", "\n", "\"--datastore\"", ",", "type", "=", "str", ",", "dest", "=", "\"datastore\"", ",", "help", "=", "\"Datastore path\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"train_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"validation_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--surprise-reader\"", ",", "type", "=", "str", ",", "dest", "=", "\"surprise_reader\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--usercol\"", ",", "type", "=", "str", ",", "dest", "=", "\"usercol\"", ",", "default", "=", "\"userID\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--itemcol\"", ",", "type", "=", "str", ",", "dest", "=", "\"itemcol\"", ",", "default", "=", "\"itemID\"", ")", "\n", "# Metrics", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rating-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"rating_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ranking-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"ranking_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "dest", "=", "\"k\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--remove-seen\"", ",", "dest", "=", "\"remove_seen\"", ",", "action", "=", "\"store_false\"", ")", "\n", "# Training parameters", "\n", "parser", ".", "add_argument", "(", "\"--random-state\"", ",", "type", "=", "int", ",", "dest", "=", "\"random_state\"", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "dest", "=", "\"verbose\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_epochs\"", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "\"--biased\"", ",", "dest", "=", "\"biased\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--primary-metric\"", ",", "dest", "=", "\"primary_metric\"", ",", "default", "=", "\"rmse\"", ")", "\n", "# Hyperparameters to be tuned", "\n", "parser", ".", "add_argument", "(", "\"--n_factors\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_factors\"", ",", "default", "=", "100", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_training.main": [[154, 157], ["logger.debug", "logger.debug", "str"], "function", ["None"], ["", "def", "main", "(", "params", ")", ":", "\n", "    ", "logger", ".", "debug", "(", "\"Args: %s\"", ",", "str", "(", "params", ")", ")", "\n", "logger", ".", "debug", "(", "\"Number of epochs %d\"", ",", "params", "[", "\"n_epochs\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_experiment_status": [[20, 30], ["requests.get().json", "requests.get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["def", "get_experiment_status", "(", "status_url", "=", "NNI_STATUS_URL", ")", ":", "\n", "    ", "\"\"\"Helper method. Gets the experiment status from the REST endpoint.\n\n    Args:\n        status_url (str): URL for the REST endpoint\n\n    Returns:\n        dict: status of the experiment\n    \"\"\"", "\n", "return", "requests", ".", "get", "(", "status_url", ")", ".", "json", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status": [[32, 56], ["nni_utils.get_experiment_status", "time.sleep", "TimeoutError", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_experiment_status"], ["", "def", "check_experiment_status", "(", "wait", "=", "WAITING_TIME", ",", "max_retries", "=", "MAX_RETRIES", ")", ":", "\n", "    ", "\"\"\"Checks the status of the current experiment on the NNI REST endpoint.\n\n    Waits until the tuning has completed.\n\n    Args:\n        wait (numeric) : time to wait in seconds\n        max_retries (int): max number of retries\n    \"\"\"", "\n", "i", "=", "0", "\n", "while", "i", "<", "max_retries", ":", "\n", "        ", "nni_status", "=", "get_experiment_status", "(", "NNI_STATUS_URL", ")", "\n", "if", "nni_status", "[", "\"status\"", "]", "in", "[", "\"DONE\"", ",", "\"TUNER_NO_MORE_TRIAL\"", "]", ":", "\n", "            ", "break", "\n", "", "elif", "nni_status", "[", "\"status\"", "]", "not", "in", "[", "\"RUNNING\"", ",", "\"NO_MORE_TRIAL\"", "]", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"NNI experiment failed to complete with status {} - {}\"", ".", "format", "(", "\n", "nni_status", "[", "\"status\"", "]", ",", "nni_status", "[", "\"errors\"", "]", "[", "0", "]", "\n", ")", "\n", ")", "\n", "", "time", ".", "sleep", "(", "wait", ")", "\n", "i", "+=", "1", "\n", "", "if", "i", "==", "max_retries", ":", "\n", "        ", "raise", "TimeoutError", "(", "\"check_experiment_status() timed out\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_stopped": [[58, 76], ["time.sleep", "TimeoutError", "nni_utils.get_experiment_status"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_experiment_status"], ["", "", "def", "check_stopped", "(", "wait", "=", "WAITING_TIME", ",", "max_retries", "=", "MAX_RETRIES", ")", ":", "\n", "    ", "\"\"\"Checks that there is no NNI experiment active (the URL is not accessible).\n    This method should be called after `nnictl stop` for verification.\n\n    Args:\n        wait (numeric) : time to wait in seconds\n        max_retries (int): max number of retries\n    \"\"\"", "\n", "i", "=", "0", "\n", "while", "i", "<", "max_retries", ":", "\n", "        ", "try", ":", "\n", "            ", "get_experiment_status", "(", "NNI_STATUS_URL", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "break", "\n", "", "time", ".", "sleep", "(", "wait", ")", "\n", "i", "+=", "1", "\n", "", "if", "i", "==", "max_retries", ":", "\n", "        ", "raise", "TimeoutError", "(", "\"check_stopped() timed out\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_metrics_written": [[78, 94], ["requests.get().json", "all", "time.sleep", "TimeoutError", "requests.get"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json"], ["", "", "def", "check_metrics_written", "(", "wait", "=", "WAITING_TIME", ",", "max_retries", "=", "MAX_RETRIES", ")", ":", "\n", "    ", "\"\"\"Waits until the metrics have been written to the trial logs.\n\n    Args:\n        wait (numeric) : time to wait in seconds\n        max_retries (int): max number of retries\n    \"\"\"", "\n", "i", "=", "0", "\n", "while", "i", "<", "max_retries", ":", "\n", "        ", "all_trials", "=", "requests", ".", "get", "(", "NNI_TRIAL_JOBS_URL", ")", ".", "json", "(", ")", "\n", "if", "all", "(", "[", "\"finalMetricData\"", "in", "trial", "for", "trial", "in", "all_trials", "]", ")", ":", "\n", "            ", "break", "\n", "", "time", ".", "sleep", "(", "wait", ")", "\n", "i", "+=", "1", "\n", "", "if", "i", "==", "max_retries", ":", "\n", "        ", "raise", "TimeoutError", "(", "\"check_metrics_written() timed out\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.get_trials": [[96, 129], ["requests.get().json", "sorted", "ValueError", "open", "json.load", "open", "json.load", "requests.get", "ast.literal_eval", "os.path.join", "os.path.join", "ast.literal_eval", "trial[].split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tuning.test_nni_utils.MockResponseTrials.json", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "get_trials", "(", "optimize_mode", ")", ":", "\n", "    ", "\"\"\"Obtain information about the trials of the current experiment via the REST endpoint.\n\n    Args:\n        optimize_mode (str): One of \"minimize\", \"maximize\". Determines how to obtain the best default metric.\n\n    Returns:\n         list: Trials info, list of (metrics, log path)\n         dict: Metrics for the best choice of hyperparameters\n         dict: Best hyperparameters\n         str: Log path for the best trial\n    \"\"\"", "\n", "if", "optimize_mode", "not", "in", "[", "\"minimize\"", ",", "\"maximize\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"optimize_mode should equal either minimize or maximize\"", ")", "\n", "", "all_trials", "=", "requests", ".", "get", "(", "NNI_TRIAL_JOBS_URL", ")", ".", "json", "(", ")", "\n", "trials", "=", "[", "\n", "(", "\n", "ast", ".", "literal_eval", "(", "ast", ".", "literal_eval", "(", "trial", "[", "\"finalMetricData\"", "]", "[", "0", "]", "[", "\"data\"", "]", ")", ")", ",", "\n", "trial", "[", "\"logPath\"", "]", ".", "split", "(", "\":\"", ")", "[", "-", "1", "]", ",", "\n", ")", "\n", "for", "trial", "in", "all_trials", "\n", "]", "\n", "sorted_trials", "=", "sorted", "(", "\n", "trials", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", "[", "\"default\"", "]", ",", "reverse", "=", "(", "optimize_mode", "==", "\"maximize\"", ")", "\n", ")", "\n", "best_trial_path", "=", "sorted_trials", "[", "0", "]", "[", "1", "]", "\n", "\n", "# Read the metrics from the trial directory in order to get the name of the default metric", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "best_trial_path", ",", "\"metrics.json\"", ")", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "best_metrics", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "best_trial_path", ",", "\"parameter.cfg\"", ")", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "best_params", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "return", "trials", ",", "best_metrics", ",", "best_params", ",", "best_trial_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.stop_nni": [[131, 137], ["subprocess.run", "nni_utils.check_stopped", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_stopped"], ["", "def", "stop_nni", "(", ")", ":", "\n", "    ", "\"\"\"Stop nni experiment\"\"\"", "\n", "proc", "=", "subprocess", ".", "run", "(", "[", "sys", ".", "prefix", "+", "\"/bin/nnictl\"", ",", "\"stop\"", "]", ")", "\n", "if", "proc", ".", "returncode", "!=", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"'nnictl stop' failed with code %d\"", "%", "proc", ".", "returncode", ")", "\n", "", "check_stopped", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.start_nni": [[139, 155], ["os.environ.copy", "subprocess.run", "nni_utils.check_experiment_status", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.nni.nni_utils.check_experiment_status"], ["", "def", "start_nni", "(", "config_path", ",", "wait", "=", "WAITING_TIME", ",", "max_retries", "=", "MAX_RETRIES", ")", ":", "\n", "    ", "\"\"\"Start nni experiment given a configuration yaml file.\n\n    Args:\n        config_path (str): Configuration yaml file.\n        wait (numeric) : time to wait in seconds\n        max_retries (int): max number of retries\n    \"\"\"", "\n", "nni_env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "nni_env", "[", "\"PATH\"", "]", "=", "sys", ".", "prefix", "+", "\"/bin:\"", "+", "nni_env", "[", "\"PATH\"", "]", "\n", "proc", "=", "subprocess", ".", "run", "(", "\n", "[", "sys", ".", "prefix", "+", "\"/bin/nnictl\"", ",", "\"create\"", ",", "\"--config\"", ",", "config_path", "]", ",", "env", "=", "nni_env", "\n", ")", "\n", "if", "proc", ".", "returncode", "!=", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"'nnictl create' failed with code %d\"", "%", "proc", ".", "returncode", ")", "\n", "", "check_experiment_status", "(", "wait", "=", "wait", ",", "max_retries", "=", "max_retries", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.svd_training.svd_training": [[24, 115], ["logger.debug", "pandas.read_pickle", "pandas.read_pickle", "surprise.SVD", "surprise.Dataset.load_from_df().build_full_trainset", "surprise.SVD.fit", "logger.debug", "nni.report_final_result", "os.environ.get", "os.path.join", "os.path.join", "len", "recommenders.models.surprise.surprise_utils.predict", "len", "recommenders.models.surprise.surprise_utils.compute_ranking_predictions", "ValueError", "open", "metrics_dict.copy", "metrics_dict.copy.pop", "json.dump", "surprise.Dataset.load_from_df", "logger.debug", "logger.debug", "len", "len", "os.path.join", "getattr", "getattr", "surprise.Reader"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions"], ["def", "svd_training", "(", "params", ")", ":", "\n", "    ", "\"\"\"\n    Train Surprise SVD using the given hyper-parameters\n    \"\"\"", "\n", "logger", ".", "debug", "(", "\"Start training...\"", ")", "\n", "train_data", "=", "pd", ".", "read_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"train_datapath\"", "]", ")", "\n", ")", "\n", "validation_data", "=", "pd", ".", "read_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"validation_datapath\"", "]", ")", "\n", ")", "\n", "\n", "svd_params", "=", "{", "\n", "p", ":", "params", "[", "p", "]", "\n", "for", "p", "in", "[", "\n", "\"random_state\"", ",", "\n", "\"n_epochs\"", ",", "\n", "\"verbose\"", ",", "\n", "\"biased\"", ",", "\n", "\"n_factors\"", ",", "\n", "\"init_mean\"", ",", "\n", "\"init_std_dev\"", ",", "\n", "\"lr_all\"", ",", "\n", "\"reg_all\"", ",", "\n", "\"lr_bu\"", ",", "\n", "\"lr_bi\"", ",", "\n", "\"lr_pu\"", ",", "\n", "\"lr_qi\"", ",", "\n", "\"reg_bu\"", ",", "\n", "\"reg_bi\"", ",", "\n", "\"reg_pu\"", ",", "\n", "\"reg_qi\"", ",", "\n", "]", "\n", "}", "\n", "svd", "=", "surprise", ".", "SVD", "(", "**", "svd_params", ")", "\n", "\n", "train_set", "=", "surprise", ".", "Dataset", ".", "load_from_df", "(", "\n", "train_data", ",", "reader", "=", "surprise", ".", "Reader", "(", "params", "[", "\"surprise_reader\"", "]", ")", "\n", ")", ".", "build_full_trainset", "(", ")", "\n", "svd", ".", "fit", "(", "train_set", ")", "\n", "\n", "logger", ".", "debug", "(", "\"Evaluating...\"", ")", "\n", "\n", "metrics_dict", "=", "{", "}", "\n", "rating_metrics", "=", "params", "[", "\"rating_metrics\"", "]", "\n", "if", "len", "(", "rating_metrics", ")", ">", "0", ":", "\n", "        ", "predictions", "=", "predict", "(", "\n", "svd", ",", "validation_data", ",", "usercol", "=", "params", "[", "\"usercol\"", "]", ",", "itemcol", "=", "params", "[", "\"itemcol\"", "]", "\n", ")", "\n", "for", "metric", "in", "rating_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "validation_data", ",", "predictions", ")", "\n", "logger", ".", "debug", "(", "\"%s = %g\"", ",", "metric", ",", "result", ")", "\n", "if", "metric", "==", "params", "[", "\"primary_metric\"", "]", ":", "\n", "                ", "metrics_dict", "[", "\"default\"", "]", "=", "result", "\n", "", "else", ":", "\n", "                ", "metrics_dict", "[", "metric", "]", "=", "result", "\n", "\n", "", "", "", "ranking_metrics", "=", "params", "[", "\"ranking_metrics\"", "]", "\n", "if", "len", "(", "ranking_metrics", ")", ">", "0", ":", "\n", "        ", "all_predictions", "=", "compute_ranking_predictions", "(", "\n", "svd", ",", "\n", "train_data", ",", "\n", "usercol", "=", "params", "[", "\"usercol\"", "]", ",", "\n", "itemcol", "=", "params", "[", "\"itemcol\"", "]", ",", "\n", "remove_seen", "=", "params", "[", "\"remove_seen\"", "]", ",", "\n", ")", "\n", "k", "=", "params", "[", "\"k\"", "]", "\n", "for", "metric", "in", "ranking_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "\n", "validation_data", ",", "all_predictions", ",", "col_prediction", "=", "\"prediction\"", ",", "k", "=", "k", "\n", ")", "\n", "logger", ".", "debug", "(", "\"%s@%d = %g\"", ",", "metric", ",", "k", ",", "result", ")", "\n", "if", "metric", "==", "params", "[", "\"primary_metric\"", "]", ":", "\n", "                ", "metrics_dict", "[", "\"default\"", "]", "=", "result", "\n", "", "else", ":", "\n", "                ", "metrics_dict", "[", "metric", "]", "=", "result", "\n", "\n", "", "", "", "if", "len", "(", "ranking_metrics", ")", "==", "0", "and", "len", "(", "rating_metrics", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"No metrics were specified.\"", ")", "\n", "\n", "# Report the metrics", "\n", "", "nni", ".", "report_final_result", "(", "metrics_dict", ")", "\n", "\n", "# Save the metrics in a JSON file", "\n", "output_dir", "=", "os", ".", "environ", ".", "get", "(", "\"NNI_OUTPUT_DIR\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"metrics.json\"", ")", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "temp_dict", "=", "metrics_dict", ".", "copy", "(", ")", "\n", "temp_dict", "[", "params", "[", "\"primary_metric\"", "]", "]", "=", "temp_dict", ".", "pop", "(", "\"default\"", ")", "\n", "json", ".", "dump", "(", "temp_dict", ",", "fp", ")", "\n", "\n", "", "return", "svd", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.svd_training.get_params": [[117, 160], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_params", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Data path", "\n", "parser", ".", "add_argument", "(", "\n", "\"--datastore\"", ",", "type", "=", "str", ",", "dest", "=", "\"datastore\"", ",", "help", "=", "\"Datastore path\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"train_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"validation_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--surprise-reader\"", ",", "type", "=", "str", ",", "dest", "=", "\"surprise_reader\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--usercol\"", ",", "type", "=", "str", ",", "dest", "=", "\"usercol\"", ",", "default", "=", "\"userID\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--itemcol\"", ",", "type", "=", "str", ",", "dest", "=", "\"itemcol\"", ",", "default", "=", "\"itemID\"", ")", "\n", "# Metrics", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rating-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"rating_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ranking-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"ranking_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "dest", "=", "\"k\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--remove-seen\"", ",", "dest", "=", "\"remove_seen\"", ",", "action", "=", "\"store_false\"", ")", "\n", "# Training parameters", "\n", "parser", ".", "add_argument", "(", "\"--random-state\"", ",", "type", "=", "int", ",", "dest", "=", "\"random_state\"", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "dest", "=", "\"verbose\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_epochs\"", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "\"--biased\"", ",", "dest", "=", "\"biased\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--primary-metric\"", ",", "dest", "=", "\"primary_metric\"", ",", "default", "=", "\"rmse\"", ")", "\n", "# Hyperparameters to be tuned", "\n", "parser", ".", "add_argument", "(", "\"--n_factors\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_factors\"", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--init_mean\"", ",", "type", "=", "float", ",", "dest", "=", "\"init_mean\"", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--init_std_dev\"", ",", "type", "=", "float", ",", "dest", "=", "\"init_std_dev\"", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_all\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_all\"", ",", "default", "=", "0.005", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_all\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_all\"", ",", "default", "=", "0.02", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_bu\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_bu\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_bi\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_bi\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_pu\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_pu\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_qi\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_qi\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_bu\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_bu\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_bi\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_bi\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_pu\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_pu\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_qi\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_qi\"", ",", "default", "=", "None", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.svd_training.main": [[162, 170], ["logger.debug", "logger.debug", "svd_training.svd_training", "os.environ.get", "surprise.dump.dump", "str", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.svd_training.svd_training"], ["", "def", "main", "(", "params", ")", ":", "\n", "    ", "logger", ".", "debug", "(", "\"Args: %s\"", ",", "str", "(", "params", ")", ")", "\n", "logger", ".", "debug", "(", "\"Number of epochs %d\"", ",", "params", "[", "\"n_epochs\"", "]", ")", "\n", "\n", "svd", "=", "svd_training", "(", "params", ")", "\n", "# Save SVD model to the output directory for later use", "\n", "output_dir", "=", "os", ".", "environ", ".", "get", "(", "\"NNI_OUTPUT_DIR\"", ")", "\n", "surprise", ".", "dump", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"model.dump\"", ")", ",", "algo", "=", "svd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_utils.compute_test_results": [[9, 64], ["pandas.DataFrame", "predictions.astype.astype", "list", "train.userID.unique", "pandas.DataFrame", "pandas.merge", "merged[].drop", "train.itemID.unique", "users.extend", "items.extend", "preds.extend", "model.predict", "test.iterrows", "eval", "len", "list", "eval", "model.predict", "pd.merge.rating.isnull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["def", "compute_test_results", "(", "\n", "model", ",", "train", ",", "test", ",", "rating_metrics", ",", "ranking_metrics", ",", "k", "=", "DEFAULT_K", "\n", ")", ":", "\n", "    ", "\"\"\"Compute the test results using a trained NCF model.\n\n    Args:\n        model (object): TF model.\n        train (pandas.DataFrame): Train set.\n        test (pandas.DataFrame): Test set.\n        rating_metrics (list): List of rating metrics.\n        ranking_metrics (list): List of ranking metrics.\n        k (int): top K recommendations\n\n    Returns:\n        dict: Test results.\n\n    \"\"\"", "\n", "test_results", "=", "{", "}", "\n", "\n", "# Rating Metrics", "\n", "predictions", "=", "[", "\n", "[", "row", ".", "userID", ",", "row", ".", "itemID", ",", "model", ".", "predict", "(", "row", ".", "userID", ",", "row", ".", "itemID", ")", "]", "\n", "for", "(", "_", ",", "row", ")", "in", "test", ".", "iterrows", "(", ")", "\n", "]", "\n", "\n", "predictions", "=", "pd", ".", "DataFrame", "(", "predictions", ",", "columns", "=", "[", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "]", ")", "\n", "predictions", "=", "predictions", ".", "astype", "(", "\n", "{", "\"userID\"", ":", "\"int64\"", ",", "\"itemID\"", ":", "\"int64\"", ",", "\"prediction\"", ":", "\"float64\"", "}", "\n", ")", "\n", "\n", "for", "metric", "in", "rating_metrics", ":", "\n", "        ", "test_results", "[", "metric", "]", "=", "eval", "(", "metric", ")", "(", "test", ",", "predictions", ")", "\n", "\n", "# Ranking Metrics", "\n", "", "users", ",", "items", ",", "preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "item", "=", "list", "(", "train", ".", "itemID", ".", "unique", "(", ")", ")", "\n", "for", "user", "in", "train", ".", "userID", ".", "unique", "(", ")", ":", "\n", "        ", "user", "=", "[", "user", "]", "*", "len", "(", "item", ")", "\n", "users", ".", "extend", "(", "user", ")", "\n", "items", ".", "extend", "(", "item", ")", "\n", "preds", ".", "extend", "(", "list", "(", "model", ".", "predict", "(", "user", ",", "item", ",", "is_list", "=", "True", ")", ")", ")", "\n", "\n", "", "all_predictions", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\"userID\"", ":", "users", ",", "\"itemID\"", ":", "items", ",", "\"prediction\"", ":", "preds", "}", "\n", ")", "\n", "\n", "merged", "=", "pd", ".", "merge", "(", "train", ",", "all_predictions", ",", "on", "=", "[", "\"userID\"", ",", "\"itemID\"", "]", ",", "how", "=", "\"outer\"", ")", "\n", "all_predictions", "=", "merged", "[", "merged", ".", "rating", ".", "isnull", "(", ")", "]", ".", "drop", "(", "\"rating\"", ",", "axis", "=", "1", ")", "\n", "\n", "for", "metric", "in", "ranking_metrics", ":", "\n", "        ", "test_results", "[", "metric", "]", "=", "eval", "(", "metric", ")", "(", "\n", "test", ",", "all_predictions", ",", "col_prediction", "=", "\"prediction\"", ",", "k", "=", "k", "\n", ")", "\n", "\n", "", "return", "test_results", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.nni.ncf_utils.combine_metrics_dicts": [[66, 79], ["pandas.DataFrame", "df.append.append", "pandas.DataFrame"], "function", ["None"], ["", "def", "combine_metrics_dicts", "(", "*", "metrics", ")", ":", "\n", "    ", "\"\"\"Combine metrics from dicts.\n\n    Args:\n        metrics (dict): Metrics\n\n    Returns:\n        pandas.DataFrame: Dataframe with metrics combined.\n    \"\"\"", "\n", "df", "=", "pd", ".", "DataFrame", "(", "metrics", "[", "0", "]", ",", "index", "=", "[", "0", "]", ")", "\n", "for", "metric", "in", "metrics", "[", "1", ":", "]", ":", "\n", "        ", "df", "=", "df", ".", "append", "(", "pd", ".", "DataFrame", "(", "metric", ",", "index", "=", "[", "0", "]", ")", ",", "sort", "=", "False", ")", "\n", "", "return", "df", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel.__init__": [[26, 41], ["naml.NAMLModel._init_embedding", "recommenders.models.newsrec.models.base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization steps for NAML.\n        Compared with the BaseModel, NAML need word embedding.\n        After creating word embedding matrix, BaseModel's __init__ method will be called.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as filter_num are there.\n            iterator_creator_train (object): NAML data loader class for train data.\n            iterator_creator_test (object): NAML data loader class for test and validation data\n        \"\"\"", "\n", "\n", "self", ".", "word2vec_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "wordEmb_file", ")", "\n", "self", ".", "hparam", "=", "hparams", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._get_input_label_from_iter": [[42, 55], ["None"], "methods", ["None"], ["", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "input_feat", "=", "[", "\n", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_ab_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_vert_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_subvert_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_ab_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_vert_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_subvert_batch\"", "]", ",", "\n", "]", "\n", "input_label", "=", "batch_data", "[", "\"labels\"", "]", "\n", "return", "input_feat", ",", "input_label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._get_user_feature_from_iter": [[56, 72], ["numpy.concatenate"], "methods", ["None"], ["", "def", "_get_user_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"get input of user encoder\n        Args:\n            batch_data: input batch data from user iterator\n\n        Returns:\n            numpy.ndarray: input user feature (clicked title batch)\n        \"\"\"", "\n", "input_feature", "=", "[", "\n", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_ab_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_vert_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_subvert_batch\"", "]", ",", "\n", "]", "\n", "input_feature", "=", "np", ".", "concatenate", "(", "input_feature", ",", "axis", "=", "-", "1", ")", "\n", "return", "input_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._get_news_feature_from_iter": [[73, 89], ["numpy.concatenate"], "methods", ["None"], ["", "def", "_get_news_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"get input of news encoder\n        Args:\n            batch_data: input batch data from news iterator\n\n        Returns:\n            numpy.ndarray: input news feature (candidate title batch)\n        \"\"\"", "\n", "input_feature", "=", "[", "\n", "batch_data", "[", "\"candidate_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_ab_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_vert_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_subvert_batch\"", "]", ",", "\n", "]", "\n", "input_feature", "=", "np", ".", "concatenate", "(", "input_feature", ",", "axis", "=", "-", "1", ")", "\n", "return", "input_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_graph": [[90, 100], ["naml.NAMLModel._build_naml"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_naml"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build NAML model and scorer.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "\n", "model", ",", "scorer", "=", "self", ".", "_build_naml", "(", ")", "\n", "return", "model", ",", "scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_userencoder": [[101, 127], ["tensorflow.Input", "tensorflow.Model", "tensorflow.keras.layers.TimeDistributed", "recommenders.models.newsrec.models.layers.AttLayer2"], "methods", ["None"], ["", "def", "_build_userencoder", "(", "self", ",", "newsencoder", ")", ":", "\n", "        ", "\"\"\"The main function to create user encoder of NAML.\n\n        Args:\n            newsencoder (object): the news encoder of NAML.\n\n        Return:\n            object: the user encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "his_input_title_body_verts", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", "+", "hparams", ".", "body_size", "+", "2", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "\n", "click_news_presents", "=", "layers", ".", "TimeDistributed", "(", "newsencoder", ")", "(", "\n", "his_input_title_body_verts", "\n", ")", "\n", "user_present", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "\n", "click_news_presents", "\n", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "\n", "his_input_title_body_verts", ",", "user_present", ",", "name", "=", "\"user_encoder\"", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_newsencoder": [[128, 176], ["tensorflow.Input", "tensorflow.Model", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "naml.NAMLModel._build_titleencoder", "naml.NAMLModel._build_bodyencoder", "naml.NAMLModel._build_vertencoder", "naml.NAMLModel._build_subvertencoder", "tensorflow.keras.layers.Concatenate", "recommenders.models.newsrec.models.layers.AttLayer2"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_titleencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_bodyencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_vertencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_subvertencoder"], ["", "def", "_build_newsencoder", "(", "self", ",", "embedding_layer", ")", ":", "\n", "        ", "\"\"\"The main function to create news encoder of NAML.\n        news encoder in composed of title encoder, body encoder, vert encoder and subvert encoder\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the news encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "input_title_body_verts", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "title_size", "+", "hparams", ".", "body_size", "+", "2", ",", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "\n", "sequences_input_title", "=", "layers", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", ":", "hparams", ".", "title_size", "]", ")", "(", "\n", "input_title_body_verts", "\n", ")", "\n", "sequences_input_body", "=", "layers", ".", "Lambda", "(", "\n", "lambda", "x", ":", "x", "[", ":", ",", "hparams", ".", "title_size", ":", "hparams", ".", "title_size", "+", "hparams", ".", "body_size", "]", "\n", ")", "(", "input_title_body_verts", ")", "\n", "input_vert", "=", "layers", ".", "Lambda", "(", "\n", "lambda", "x", ":", "x", "[", "\n", ":", ",", "\n", "hparams", ".", "title_size", "\n", "+", "hparams", ".", "body_size", ":", "hparams", ".", "title_size", "\n", "+", "hparams", ".", "body_size", "\n", "+", "1", ",", "\n", "]", "\n", ")", "(", "input_title_body_verts", ")", "\n", "input_subvert", "=", "layers", ".", "Lambda", "(", "\n", "lambda", "x", ":", "x", "[", ":", ",", "hparams", ".", "title_size", "+", "hparams", ".", "body_size", "+", "1", ":", "]", "\n", ")", "(", "input_title_body_verts", ")", "\n", "\n", "title_repr", "=", "self", ".", "_build_titleencoder", "(", "embedding_layer", ")", "(", "sequences_input_title", ")", "\n", "body_repr", "=", "self", ".", "_build_bodyencoder", "(", "embedding_layer", ")", "(", "sequences_input_body", ")", "\n", "vert_repr", "=", "self", ".", "_build_vertencoder", "(", ")", "(", "input_vert", ")", "\n", "subvert_repr", "=", "self", ".", "_build_subvertencoder", "(", ")", "(", "input_subvert", ")", "\n", "\n", "concate_repr", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "2", ")", "(", "\n", "[", "title_repr", ",", "body_repr", ",", "vert_repr", ",", "subvert_repr", "]", "\n", ")", "\n", "news_repr", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "\n", "concate_repr", "\n", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "input_title_body_verts", ",", "news_repr", ",", "name", "=", "\"news_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_titleencoder": [[177, 205], ["tensorflow.Input", "embedding_layer", "tensorflow.Model", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Dropout", "recommenders.models.newsrec.models.layers.AttLayer2", "tensorflow.keras.layers.Reshape", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform"], "methods", ["None"], ["", "def", "_build_titleencoder", "(", "self", ",", "embedding_layer", ")", ":", "\n", "        ", "\"\"\"build title encoder of NAML news encoder.\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the title encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "sequences_input_title", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "title_size", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "embedded_sequences_title", "=", "embedding_layer", "(", "sequences_input_title", ")", "\n", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "embedded_sequences_title", ")", "\n", "y", "=", "layers", ".", "Conv1D", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "window_size", ",", "\n", "activation", "=", "hparams", ".", "cnn_activation", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "y", ")", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "y", ")", "\n", "pred_title", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "y", ")", "\n", "pred_title", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "hparams", ".", "filter_num", ")", ")", "(", "pred_title", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "sequences_input_title", ",", "pred_title", ",", "name", "=", "\"title_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_bodyencoder": [[206, 234], ["tensorflow.Input", "embedding_layer", "tensorflow.Model", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Dropout", "recommenders.models.newsrec.models.layers.AttLayer2", "tensorflow.keras.layers.Reshape", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform"], "methods", ["None"], ["", "def", "_build_bodyencoder", "(", "self", ",", "embedding_layer", ")", ":", "\n", "        ", "\"\"\"build body encoder of NAML news encoder.\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the body encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "sequences_input_body", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "body_size", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "embedded_sequences_body", "=", "embedding_layer", "(", "sequences_input_body", ")", "\n", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "embedded_sequences_body", ")", "\n", "y", "=", "layers", ".", "Conv1D", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "window_size", ",", "\n", "activation", "=", "hparams", ".", "cnn_activation", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "y", ")", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "y", ")", "\n", "pred_body", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "y", ")", "\n", "pred_body", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "hparams", ".", "filter_num", ")", ")", "(", "pred_body", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "sequences_input_body", ",", "pred_body", ",", "name", "=", "\"body_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_vertencoder": [[235, 259], ["tensorflow.Input", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding.", "tensorflow.Model", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Reshape", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform"], "methods", ["None"], ["", "def", "_build_vertencoder", "(", "self", ")", ":", "\n", "        ", "\"\"\"build vert encoder of NAML news encoder.\n\n        Return:\n            object: the vert encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "input_vert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "vert_embedding", "=", "layers", ".", "Embedding", "(", "\n", "hparams", ".", "vert_num", ",", "hparams", ".", "vert_emb_dim", ",", "trainable", "=", "True", "\n", ")", "\n", "\n", "vert_emb", "=", "vert_embedding", "(", "input_vert", ")", "\n", "pred_vert", "=", "layers", ".", "Dense", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "activation", "=", "hparams", ".", "dense_activation", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "vert_emb", ")", "\n", "pred_vert", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "hparams", ".", "filter_num", ")", ")", "(", "pred_vert", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "input_vert", ",", "pred_vert", ",", "name", "=", "\"vert_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_subvertencoder": [[260, 284], ["tensorflow.Input", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding.", "tensorflow.Model", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Reshape", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform"], "methods", ["None"], ["", "def", "_build_subvertencoder", "(", "self", ")", ":", "\n", "        ", "\"\"\"build subvert encoder of NAML news encoder.\n\n        Return:\n            object: the subvert encoder of NAML.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "input_subvert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "subvert_embedding", "=", "layers", ".", "Embedding", "(", "\n", "hparams", ".", "subvert_num", ",", "hparams", ".", "subvert_emb_dim", ",", "trainable", "=", "True", "\n", ")", "\n", "\n", "subvert_emb", "=", "subvert_embedding", "(", "input_subvert", ")", "\n", "pred_subvert", "=", "layers", ".", "Dense", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "activation", "=", "hparams", ".", "dense_activation", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "subvert_emb", ")", "\n", "pred_subvert", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "hparams", ".", "filter_num", ")", ")", "(", "pred_subvert", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "input_subvert", ",", "pred_subvert", ",", "name", "=", "\"subvert_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.naml.NAMLModel._build_naml": [[285, 397], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.keras.layers.Embedding", "naml.NAMLModel._build_newsencoder", "naml.NAMLModel._build_userencoder", "naml.NAMLModel.userencoder", "naml.NAMLModel.newsencoder", "tensorflow.Model", "tensorflow.Model", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.TimeDistributed", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_newsencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_userencoder"], ["", "def", "_build_naml", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create NAML's logic. The core of NAML\n        is a user encoder and a news encoder.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and predict.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "his_input_body", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "body_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "his_input_vert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "his_size", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "his_input_subvert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "his_size", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "pred_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_body", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "hparams", ".", "body_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_vert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "pred_input_subvert", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "pred_input_title_one", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "\n", "1", ",", "\n", "hparams", ".", "title_size", ",", "\n", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "pred_input_body_one", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "\n", "1", ",", "\n", "hparams", ".", "body_size", ",", "\n", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "pred_input_vert_one", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "pred_input_subvert_one", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "his_title_body_verts", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "1", ")", "(", "\n", "[", "his_input_title", ",", "his_input_body", ",", "his_input_vert", ",", "his_input_subvert", "]", "\n", ")", "\n", "\n", "pred_title_body_verts", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "1", ")", "(", "\n", "[", "pred_input_title", ",", "pred_input_body", ",", "pred_input_vert", ",", "pred_input_subvert", "]", "\n", ")", "\n", "\n", "pred_title_body_verts_one", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "1", ")", "(", "\n", "[", "\n", "pred_input_title_one", ",", "\n", "pred_input_body_one", ",", "\n", "pred_input_vert_one", ",", "\n", "pred_input_subvert_one", ",", "\n", "]", "\n", ")", "\n", "pred_title_body_verts_one", "=", "layers", ".", "Reshape", "(", "(", "-", "1", ",", ")", ")", "(", "pred_title_body_verts_one", ")", "\n", "\n", "embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "self", ".", "word2vec_embedding", ".", "shape", "[", "0", "]", ",", "\n", "hparams", ".", "word_emb_dim", ",", "\n", "weights", "=", "[", "self", ".", "word2vec_embedding", "]", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "newsencoder", "=", "self", ".", "_build_newsencoder", "(", "embedding_layer", ")", "\n", "self", ".", "userencoder", "=", "self", ".", "_build_userencoder", "(", "self", ".", "newsencoder", ")", "\n", "\n", "user_present", "=", "self", ".", "userencoder", "(", "his_title_body_verts", ")", "\n", "news_present", "=", "layers", ".", "TimeDistributed", "(", "self", ".", "newsencoder", ")", "(", "pred_title_body_verts", ")", "\n", "news_present_one", "=", "self", ".", "newsencoder", "(", "pred_title_body_verts_one", ")", "\n", "\n", "preds", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present", ",", "user_present", "]", ")", "\n", "preds", "=", "layers", ".", "Activation", "(", "activation", "=", "\"softmax\"", ")", "(", "preds", ")", "\n", "\n", "pred_one", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present_one", ",", "user_present", "]", ")", "\n", "pred_one", "=", "layers", ".", "Activation", "(", "activation", "=", "\"sigmoid\"", ")", "(", "pred_one", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "\n", "[", "\n", "his_input_title", ",", "\n", "his_input_body", ",", "\n", "his_input_vert", ",", "\n", "his_input_subvert", ",", "\n", "pred_input_title", ",", "\n", "pred_input_body", ",", "\n", "pred_input_vert", ",", "\n", "pred_input_subvert", ",", "\n", "]", ",", "\n", "preds", ",", "\n", ")", "\n", "\n", "scorer", "=", "keras", ".", "Model", "(", "\n", "[", "\n", "his_input_title", ",", "\n", "his_input_body", ",", "\n", "his_input_vert", ",", "\n", "his_input_subvert", ",", "\n", "pred_input_title_one", ",", "\n", "pred_input_body_one", ",", "\n", "pred_input_vert_one", ",", "\n", "pred_input_subvert_one", ",", "\n", "]", ",", "\n", "pred_one", ",", "\n", ")", "\n", "\n", "return", "model", ",", "scorer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel.__init__": [[27, 48], ["nrms.NRMSModel._init_embedding", "recommenders.models.newsrec.models.base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "iterator_creator", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialization steps for NRMS.\n        Compared with the BaseModel, NRMS need word embedding.\n        After creating word embedding matrix, BaseModel's __init__ method will be called.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\n            iterator_creator_train (object): NRMS data loader class for train data.\n            iterator_creator_test (object): NRMS data loader class for test and validation data\n        \"\"\"", "\n", "self", ".", "word2vec_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "wordEmb_file", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "hparams", ",", "\n", "iterator_creator", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._get_input_label_from_iter": [[50, 66], ["None"], "methods", ["None"], ["", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"get input and labels for trainning from iterator\n\n        Args:\n            batch data: input batch data from iterator\n\n        Returns:\n            list: input feature fed into model (clicked_title_batch & candidate_title_batch)\n            numpy.ndarray: labels\n        \"\"\"", "\n", "input_feat", "=", "[", "\n", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_title_batch\"", "]", ",", "\n", "]", "\n", "input_label", "=", "batch_data", "[", "\"labels\"", "]", "\n", "return", "input_feat", ",", "input_label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._get_user_feature_from_iter": [[67, 76], ["None"], "methods", ["None"], ["", "def", "_get_user_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"get input of user encoder\n        Args:\n            batch_data: input batch data from user iterator\n\n        Returns:\n            numpy.ndarray: input user feature (clicked title batch)\n        \"\"\"", "\n", "return", "batch_data", "[", "\"clicked_title_batch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._get_news_feature_from_iter": [[77, 86], ["None"], "methods", ["None"], ["", "def", "_get_news_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"get input of news encoder\n        Args:\n            batch_data: input batch data from news iterator\n\n        Returns:\n            numpy.ndarray: input news feature (candidate title batch)\n        \"\"\"", "\n", "return", "batch_data", "[", "\"candidate_title_batch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._build_graph": [[87, 96], ["nrms.NRMSModel._build_nrms"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._build_nrms"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build NRMS model and scorer.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "model", ",", "scorer", "=", "self", ".", "_build_nrms", "(", ")", "\n", "return", "model", ",", "scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._build_userencoder": [[97, 119], ["tensorflow.Input", "tensorflow.Model", "tensorflow.keras.layers.TimeDistributed", "recommenders.models.newsrec.models.layers.SelfAttention", "recommenders.models.newsrec.models.layers.AttLayer2"], "methods", ["None"], ["", "def", "_build_userencoder", "(", "self", ",", "titleencoder", ")", ":", "\n", "        ", "\"\"\"The main function to create user encoder of NRMS.\n\n        Args:\n            titleencoder (object): the news encoder of NRMS.\n\n        Return:\n            object: the user encoder of NRMS.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "\n", "click_title_presents", "=", "layers", ".", "TimeDistributed", "(", "titleencoder", ")", "(", "his_input_title", ")", "\n", "y", "=", "SelfAttention", "(", "hparams", ".", "head_num", ",", "hparams", ".", "head_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "\n", "[", "click_title_presents", "]", "*", "3", "\n", ")", "\n", "user_present", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "y", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "his_input_title", ",", "user_present", ",", "name", "=", "\"user_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._build_newsencoder": [[120, 141], ["tensorflow.Input", "embedding_layer", "tensorflow.Model", "tensorflow.keras.layers.Dropout", "recommenders.models.newsrec.models.layers.SelfAttention", "tensorflow.keras.layers.Dropout", "recommenders.models.newsrec.models.layers.AttLayer2"], "methods", ["None"], ["", "def", "_build_newsencoder", "(", "self", ",", "embedding_layer", ")", ":", "\n", "        ", "\"\"\"The main function to create news encoder of NRMS.\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the news encoder of NRMS.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "sequences_input_title", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "title_size", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "embedded_sequences_title", "=", "embedding_layer", "(", "sequences_input_title", ")", "\n", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "embedded_sequences_title", ")", "\n", "y", "=", "SelfAttention", "(", "hparams", ".", "head_num", ",", "hparams", ".", "head_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "[", "y", ",", "y", ",", "y", "]", ")", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "y", ")", "\n", "pred_title", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "y", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "sequences_input_title", ",", "pred_title", ",", "name", "=", "\"news_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.nrms.NRMSModel._build_nrms": [[142, 194], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.keras.layers.Embedding", "nrms.NRMSModel._build_newsencoder", "nrms.NRMSModel._build_userencoder", "nrms.NRMSModel.userencoder", "nrms.NRMSModel.newsencoder", "tensorflow.Model", "tensorflow.Model", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.TimeDistributed", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_newsencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_userencoder"], ["", "def", "_build_nrms", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create NRMS's logic. The core of NRMS\n        is a user encoder and a news encoder.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title_one", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "\n", "1", ",", "\n", "hparams", ".", "title_size", ",", "\n", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "pred_title_one_reshape", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "title_size", ",", ")", ")", "(", "\n", "pred_input_title_one", "\n", ")", "\n", "\n", "embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "self", ".", "word2vec_embedding", ".", "shape", "[", "0", "]", ",", "\n", "hparams", ".", "word_emb_dim", ",", "\n", "weights", "=", "[", "self", ".", "word2vec_embedding", "]", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "\n", "titleencoder", "=", "self", ".", "_build_newsencoder", "(", "embedding_layer", ")", "\n", "self", ".", "userencoder", "=", "self", ".", "_build_userencoder", "(", "titleencoder", ")", "\n", "self", ".", "newsencoder", "=", "titleencoder", "\n", "\n", "user_present", "=", "self", ".", "userencoder", "(", "his_input_title", ")", "\n", "news_present", "=", "layers", ".", "TimeDistributed", "(", "self", ".", "newsencoder", ")", "(", "pred_input_title", ")", "\n", "news_present_one", "=", "self", ".", "newsencoder", "(", "pred_title_one_reshape", ")", "\n", "\n", "preds", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present", ",", "user_present", "]", ")", "\n", "preds", "=", "layers", ".", "Activation", "(", "activation", "=", "\"softmax\"", ")", "(", "preds", ")", "\n", "\n", "pred_one", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present_one", ",", "user_present", "]", ")", "\n", "pred_one", "=", "layers", ".", "Activation", "(", "activation", "=", "\"sigmoid\"", ")", "(", "pred_one", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "[", "his_input_title", ",", "pred_input_title", "]", ",", "preds", ")", "\n", "scorer", "=", "keras", ".", "Model", "(", "[", "his_input_title", ",", "pred_input_title_one", "]", ",", "pred_one", ")", "\n", "\n", "return", "model", ",", "scorer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.AttLayer2.__init__": [[17, 27], ["tensorflow.compat.v1.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "dim", "=", "200", ",", "seed", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialization steps for AttLayer2.\n\n        Args:\n            dim (int): attention hidden dim\n        \"\"\"", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "seed", "=", "seed", "\n", "super", "(", "AttLayer2", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.AttLayer2.build": [[28, 57], ["tensorflow.compat.v1.keras.layers.AttLayer2.add_weight", "tensorflow.compat.v1.keras.layers.AttLayer2.add_weight", "tensorflow.compat.v1.keras.layers.AttLayer2.add_weight", "super().build", "len", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMV2Cell.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Initialization for variables in AttLayer2\n        There are there variables in AttLayer2, i.e. W, b and q.\n\n        Args:\n            input_shape (object): shape of input tensor.\n        \"\"\"", "\n", "\n", "assert", "len", "(", "input_shape", ")", "==", "3", "\n", "dim", "=", "self", ".", "dim", "\n", "self", ".", "W", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"W\"", ",", "\n", "shape", "=", "(", "int", "(", "input_shape", "[", "-", "1", "]", ")", ",", "dim", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "self", ".", "b", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"b\"", ",", "\n", "shape", "=", "(", "dim", ",", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "self", ".", "q", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"q\"", ",", "\n", "shape", "=", "(", "dim", ",", "1", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "super", "(", "AttLayer2", ",", "self", ")", ".", "build", "(", "input_shape", ")", "# be sure you call this somewhere!", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.AttLayer2.call": [[58, 85], ["tensorflow.compat.v1.keras.backend.tanh", "tensorflow.compat.v1.keras.backend.dot", "tensorflow.compat.v1.keras.backend.squeeze", "tensorflow.compat.v1.keras.backend.expand_dims", "tensorflow.compat.v1.keras.backend.sum", "tensorflow.compat.v1.keras.backend.exp", "tensorflow.compat.v1.keras.backend.dot", "tensorflow.compat.v1.keras.backend.exp", "tensorflow.compat.v1.keras.backend.cast", "tensorflow.compat.v1.keras.backend.sum", "tensorflow.compat.v1.keras.backend.epsilon"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mask", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Core implemention of soft attention\n\n        Args:\n            inputs (object): input tensor.\n\n        Returns:\n            object: weighted sum of input tensors.\n        \"\"\"", "\n", "\n", "attention", "=", "K", ".", "tanh", "(", "K", ".", "dot", "(", "inputs", ",", "self", ".", "W", ")", "+", "self", ".", "b", ")", "\n", "attention", "=", "K", ".", "dot", "(", "attention", ",", "self", ".", "q", ")", "\n", "\n", "attention", "=", "K", ".", "squeeze", "(", "attention", ",", "axis", "=", "2", ")", "\n", "\n", "if", "mask", "is", "None", ":", "\n", "            ", "attention", "=", "K", ".", "exp", "(", "attention", ")", "\n", "", "else", ":", "\n", "            ", "attention", "=", "K", ".", "exp", "(", "attention", ")", "*", "K", ".", "cast", "(", "mask", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "", "attention_weight", "=", "attention", "/", "(", "\n", "K", ".", "sum", "(", "attention", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "+", "K", ".", "epsilon", "(", ")", "\n", ")", "\n", "\n", "attention_weight", "=", "K", ".", "expand_dims", "(", "attention_weight", ")", "\n", "weighted_input", "=", "inputs", "*", "attention_weight", "\n", "return", "K", ".", "sum", "(", "weighted_input", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.AttLayer2.compute_mask": [[86, 97], ["None"], "methods", ["None"], ["", "def", "compute_mask", "(", "self", ",", "input", ",", "input_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compte output mask value\n\n        Args:\n            input (object): input tensor.\n            input_mask: input mask\n\n        Returns:\n            object: output mask.\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.AttLayer2.compute_output_shape": [[98, 108], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Compute shape of output tensor\n\n        Args:\n            input_shape (tuple): shape of input tensor.\n\n        Returns:\n            tuple: shape of output tensor.\n        \"\"\"", "\n", "return", "input_shape", "[", "0", "]", ",", "input_shape", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.__init__": [[122, 137], ["tensorflow.compat.v1.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "multiheads", ",", "head_dim", ",", "seed", "=", "0", ",", "mask_right", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialization steps for AttLayer2.\n\n        Args:\n            multiheads (int): The number of heads.\n            head_dim (object): Dimension of each head.\n            mask_right (boolean): Whether to mask right words.\n        \"\"\"", "\n", "\n", "self", ".", "multiheads", "=", "multiheads", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "output_dim", "=", "multiheads", "*", "head_dim", "\n", "self", ".", "mask_right", "=", "mask_right", "\n", "self", ".", "seed", "=", "seed", "\n", "super", "(", "SelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.compute_output_shape": [[138, 146], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Compute shape of output tensor.\n\n        Returns:\n            tuple: output shape tuple.\n        \"\"\"", "\n", "\n", "return", "(", "input_shape", "[", "0", "]", "[", "0", "]", ",", "input_shape", "[", "0", "]", "[", "1", "]", ",", "self", ".", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.build": [[147, 177], ["tensorflow.compat.v1.keras.layers.SelfAttention.add_weight", "tensorflow.compat.v1.keras.layers.SelfAttention.add_weight", "tensorflow.compat.v1.keras.layers.SelfAttention.add_weight", "super().build", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.glorot_uniform", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMV2Cell.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Initialization for variables in SelfAttention.\n        There are three variables in SelfAttention, i.e. WQ, WK ans WV.\n        WQ is used for linear transformation of query.\n        WK is used for linear transformation of key.\n        WV is used for linear transformation of value.\n\n        Args:\n            input_shape (object): shape of input tensor.\n        \"\"\"", "\n", "\n", "self", ".", "WQ", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"WQ\"", ",", "\n", "shape", "=", "(", "int", "(", "input_shape", "[", "0", "]", "[", "-", "1", "]", ")", ",", "self", ".", "output_dim", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "self", ".", "WK", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"WK\"", ",", "\n", "shape", "=", "(", "int", "(", "input_shape", "[", "1", "]", "[", "-", "1", "]", ")", ",", "self", ".", "output_dim", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "self", ".", "WV", "=", "self", ".", "add_weight", "(", "\n", "name", "=", "\"WV\"", ",", "\n", "shape", "=", "(", "int", "(", "input_shape", "[", "2", "]", "[", "-", "1", "]", ")", ",", "self", ".", "output_dim", ")", ",", "\n", "initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "super", "(", "SelfAttention", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.Mask": [[178, 202], ["tensorflow.compat.v1.keras.backend.one_hot", "range", "tensorflow.compat.v1.keras.backend.cumsum", "tensorflow.compat.v1.keras.backend.expand_dims", "len", "tensorflow.compat.v1.keras.backend.shape"], "methods", ["None"], ["", "def", "Mask", "(", "self", ",", "inputs", ",", "seq_len", ",", "mode", "=", "\"add\"", ")", ":", "\n", "        ", "\"\"\"Mask operation used in multi-head self attention\n\n        Args:\n            seq_len (object): sequence length of inputs.\n            mode (str): mode of mask.\n\n        Returns:\n            object: tensors after masking.\n        \"\"\"", "\n", "\n", "if", "seq_len", "is", "None", ":", "\n", "            ", "return", "inputs", "\n", "", "else", ":", "\n", "            ", "mask", "=", "K", ".", "one_hot", "(", "indices", "=", "seq_len", "[", ":", ",", "0", "]", ",", "num_classes", "=", "K", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", "\n", "mask", "=", "1", "-", "K", ".", "cumsum", "(", "mask", ",", "axis", "=", "1", ")", "\n", "\n", "for", "_", "in", "range", "(", "len", "(", "inputs", ".", "shape", ")", "-", "2", ")", ":", "\n", "                ", "mask", "=", "K", ".", "expand_dims", "(", "mask", ",", "2", ")", "\n", "\n", "", "if", "mode", "==", "\"mul\"", ":", "\n", "                ", "return", "inputs", "*", "mask", "\n", "", "elif", "mode", "==", "\"add\"", ":", "\n", "                ", "return", "inputs", "-", "(", "1", "-", "mask", ")", "*", "1e12", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.call": [[203, 258], ["tensorflow.compat.v1.keras.backend.dot", "tensorflow.compat.v1.keras.backend.reshape", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.backend.dot", "tensorflow.compat.v1.keras.backend.reshape", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.backend.dot", "tensorflow.compat.v1.keras.backend.reshape", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.layers.SelfAttention.Mask", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.backend.softmax", "tensorflow.compat.v1.linalg.einsum", "tensorflow.compat.v1.keras.backend.permute_dimensions", "tensorflow.compat.v1.keras.backend.reshape", "tensorflow.compat.v1.keras.layers.SelfAttention.Mask", "len", "tensorflow.compat.v1.linalg.einsum", "tensorflow.compat.v1.keras.backend.sqrt", "tensorflow.compat.v1.keras.backend.ones_like", "tensorflow.compat.v1.keras.backend.tf.matrix_band_part", "len", "tensorflow.compat.v1.keras.backend.cast", "tensorflow.compat.v1.keras.backend.shape", "tensorflow.compat.v1.keras.backend.shape", "tensorflow.compat.v1.keras.backend.shape", "tensorflow.compat.v1.keras.backend.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.Mask", "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.Mask"], ["", "", "", "def", "call", "(", "self", ",", "QKVs", ")", ":", "\n", "        ", "\"\"\"Core logic of multi-head self attention.\n\n        Args:\n            QKVs (list): inputs of multi-head self attention i.e. query, key and value.\n\n        Returns:\n            object: ouput tensors.\n        \"\"\"", "\n", "if", "len", "(", "QKVs", ")", "==", "3", ":", "\n", "            ", "Q_seq", ",", "K_seq", ",", "V_seq", "=", "QKVs", "\n", "Q_len", ",", "V_len", "=", "None", ",", "None", "\n", "", "elif", "len", "(", "QKVs", ")", "==", "5", ":", "\n", "            ", "Q_seq", ",", "K_seq", ",", "V_seq", ",", "Q_len", ",", "V_len", "=", "QKVs", "\n", "", "Q_seq", "=", "K", ".", "dot", "(", "Q_seq", ",", "self", ".", "WQ", ")", "\n", "Q_seq", "=", "K", ".", "reshape", "(", "\n", "Q_seq", ",", "shape", "=", "(", "-", "1", ",", "K", ".", "shape", "(", "Q_seq", ")", "[", "1", "]", ",", "self", ".", "multiheads", ",", "self", ".", "head_dim", ")", "\n", ")", "\n", "Q_seq", "=", "K", ".", "permute_dimensions", "(", "Q_seq", ",", "pattern", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "K_seq", "=", "K", ".", "dot", "(", "K_seq", ",", "self", ".", "WK", ")", "\n", "K_seq", "=", "K", ".", "reshape", "(", "\n", "K_seq", ",", "shape", "=", "(", "-", "1", ",", "K", ".", "shape", "(", "K_seq", ")", "[", "1", "]", ",", "self", ".", "multiheads", ",", "self", ".", "head_dim", ")", "\n", ")", "\n", "K_seq", "=", "K", ".", "permute_dimensions", "(", "K_seq", ",", "pattern", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "V_seq", "=", "K", ".", "dot", "(", "V_seq", ",", "self", ".", "WV", ")", "\n", "V_seq", "=", "K", ".", "reshape", "(", "\n", "V_seq", ",", "shape", "=", "(", "-", "1", ",", "K", ".", "shape", "(", "V_seq", ")", "[", "1", "]", ",", "self", ".", "multiheads", ",", "self", ".", "head_dim", ")", "\n", ")", "\n", "V_seq", "=", "K", ".", "permute_dimensions", "(", "V_seq", ",", "pattern", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "A", "=", "einsum", "(", "\"abij, abkj -> abik\"", ",", "Q_seq", ",", "K_seq", ")", "/", "K", ".", "sqrt", "(", "\n", "K", ".", "cast", "(", "self", ".", "head_dim", ",", "dtype", "=", "\"float32\"", ")", "\n", ")", "\n", "A", "=", "K", ".", "permute_dimensions", "(", "\n", "A", ",", "pattern", "=", "(", "0", ",", "3", ",", "2", ",", "1", ")", "\n", ")", "# A.shape=[batch_size,K_sequence_length,Q_sequence_length,self.multiheads]", "\n", "\n", "A", "=", "self", ".", "Mask", "(", "A", ",", "V_len", ",", "\"add\"", ")", "\n", "A", "=", "K", ".", "permute_dimensions", "(", "A", ",", "pattern", "=", "(", "0", ",", "3", ",", "2", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "mask_right", ":", "\n", "            ", "ones", "=", "K", ".", "ones_like", "(", "A", "[", ":", "1", ",", ":", "1", "]", ")", "\n", "lower_triangular", "=", "K", ".", "tf", ".", "matrix_band_part", "(", "ones", ",", "num_lower", "=", "-", "1", ",", "num_upper", "=", "0", ")", "\n", "mask", "=", "(", "ones", "-", "lower_triangular", ")", "*", "1e12", "\n", "A", "=", "A", "-", "mask", "\n", "", "A", "=", "K", ".", "softmax", "(", "A", ")", "\n", "\n", "O_seq", "=", "einsum", "(", "\"abij, abjk -> abik\"", ",", "A", ",", "V_seq", ")", "\n", "O_seq", "=", "K", ".", "permute_dimensions", "(", "O_seq", ",", "pattern", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "O_seq", "=", "K", ".", "reshape", "(", "O_seq", ",", "shape", "=", "(", "-", "1", ",", "K", ".", "shape", "(", "O_seq", ")", "[", "1", "]", ",", "self", ".", "output_dim", ")", ")", "\n", "O_seq", "=", "self", ".", "Mask", "(", "O_seq", ",", "Q_len", ",", "\"mul\"", ")", "\n", "return", "O_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.SelfAttention.get_config": [[259, 274], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"add multiheads, multiheads and mask_right into layer config.\n\n        Returns:\n            dict: config of SelfAttention layer.\n        \"\"\"", "\n", "config", "=", "super", "(", "SelfAttention", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "\n", "{", "\n", "\"multiheads\"", ":", "self", ".", "multiheads", ",", "\n", "\"head_dim\"", ":", "self", ".", "head_dim", ",", "\n", "\"mask_right\"", ":", "self", ".", "mask_right", ",", "\n", "}", "\n", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.ComputeMasking.__init__": [[312, 314], ["tensorflow.compat.v1.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ComputeMasking", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.ComputeMasking.call": [[315, 318], ["tensorflow.compat.v1.keras.backend.not_equal", "tensorflow.compat.v1.keras.backend.cast", "tensorflow.compat.v1.keras.backend.floatx"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "mask", "=", "K", ".", "not_equal", "(", "inputs", ",", "0", ")", "\n", "return", "K", ".", "cast", "(", "mask", ",", "K", ".", "floatx", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.ComputeMasking.compute_output_shape": [[319, 321], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.OverwriteMasking.__init__": [[333, 335], ["tensorflow.compat.v1.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OverwriteMasking", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.OverwriteMasking.build": [[336, 338], ["super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMV2Cell.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", "OverwriteMasking", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.OverwriteMasking.call": [[339, 341], ["tensorflow.compat.v1.keras.backend.expand_dims"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "inputs", "[", "0", "]", "*", "K", ".", "expand_dims", "(", "inputs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.OverwriteMasking.compute_output_shape": [[342, 344], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.PersonalizedAttentivePooling": [[276, 303], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Model", "tensorflow.compat.v1.keras.layers.Dropout", "tensorflow.compat.v1.keras.layers.Dense", "tensorflow.compat.v1.keras.layers.Dot", "tensorflow.compat.v1.keras.layers.Activation", "tensorflow.compat.v1.keras.layers.Dot", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.Zeros"], "function", ["None"], ["", "", "def", "PersonalizedAttentivePooling", "(", "dim1", ",", "dim2", ",", "dim3", ",", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"Soft alignment attention implement.\n\n    Attributes:\n        dim1 (int): first dimention of value shape.\n        dim2 (int): second dimention of value shape.\n        dim3 (int): shape of query\n\n    Returns:\n        object: weighted summary of inputs value.\n    \"\"\"", "\n", "vecs_input", "=", "keras", ".", "Input", "(", "shape", "=", "(", "dim1", ",", "dim2", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "query_input", "=", "keras", ".", "Input", "(", "shape", "=", "(", "dim3", ",", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "user_vecs", "=", "layers", ".", "Dropout", "(", "0.2", ")", "(", "vecs_input", ")", "\n", "user_att", "=", "layers", ".", "Dense", "(", "\n", "dim3", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "seed", ")", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", ")", "(", "user_vecs", ")", "\n", "user_att2", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "query_input", ",", "user_att", "]", ")", "\n", "user_att2", "=", "layers", ".", "Activation", "(", "\"softmax\"", ")", "(", "user_att2", ")", "\n", "user_vec", "=", "layers", ".", "Dot", "(", "(", "1", ",", "1", ")", ")", "(", "[", "user_vecs", ",", "user_att2", "]", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "[", "vecs_input", ",", "query_input", "]", ",", "user_vec", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel.__init__": [[25, 40], ["npa.NPAModel._init_embedding", "recommenders.models.newsrec.models.base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization steps for MANL.\n        Compared with the BaseModel, NPA need word embedding.\n        After creating word embedding matrix, BaseModel's __init__ method will be called.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as filter_num are there.\n            iterator_creator_train (object): NPA data loader class for train data.\n            iterator_creator_test (object): NPA data loader class for test and validation data\n        \"\"\"", "\n", "\n", "self", ".", "word2vec_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "wordEmb_file", ")", "\n", "self", ".", "hparam", "=", "hparams", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._get_input_label_from_iter": [[41, 49], ["None"], "methods", ["None"], ["", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "input_feat", "=", "[", "\n", "batch_data", "[", "\"user_index_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_title_batch\"", "]", ",", "\n", "]", "\n", "input_label", "=", "batch_data", "[", "\"labels\"", "]", "\n", "return", "input_feat", ",", "input_label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._build_graph": [[50, 60], ["npa.NPAModel._build_npa"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._build_npa"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build NPA model and scorer.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "\n", "model", ",", "scorer", "=", "self", ".", "_build_npa", "(", ")", "\n", "return", "model", ",", "scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._build_userencoder": [[61, 97], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Model", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.TimeDistributed", "tensorflow.keras.layers.Reshape", "user_embedding_layer", "recommenders.models.newsrec.models.layers.PersonalizedAttentivePooling", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.PersonalizedAttentivePooling"], ["", "def", "_build_userencoder", "(", "self", ",", "titleencoder", ",", "user_embedding_layer", ")", ":", "\n", "        ", "\"\"\"The main function to create user encoder of NPA.\n\n        Args:\n            titleencoder (object): the news encoder of NPA.\n\n        Return:\n            object: the user encoder of NPA.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "user_indexes", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "nuser_id", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "1", ")", ")", "(", "user_indexes", ")", "\n", "repeat_uids", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "2", ")", "(", "[", "nuser_id", "]", "*", "hparams", ".", "his_size", ")", "\n", "his_title_uid", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "1", ")", "(", "[", "his_input_title", ",", "repeat_uids", "]", ")", "\n", "\n", "click_title_presents", "=", "layers", ".", "TimeDistributed", "(", "titleencoder", ")", "(", "his_title_uid", ")", "\n", "\n", "u_emb", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "user_emb_dim", ",", ")", ")", "(", "\n", "user_embedding_layer", "(", "user_indexes", ")", "\n", ")", "\n", "user_present", "=", "PersonalizedAttentivePooling", "(", "\n", "hparams", ".", "his_size", ",", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "attention_hidden_dim", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "(", "[", "click_title_presents", ",", "layers", ".", "Dense", "(", "hparams", ".", "attention_hidden_dim", ")", "(", "u_emb", ")", "]", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "\n", "[", "his_input_title", ",", "user_indexes", "]", ",", "user_present", ",", "name", "=", "\"user_encoder\"", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._build_newsencoder": [[98, 145], ["tensorflow.Input", "embedding_layer", "tensorflow.Model", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Reshape", "user_embedding_layer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Dropout", "recommenders.models.newsrec.models.layers.PersonalizedAttentivePooling", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.layers.PersonalizedAttentivePooling"], ["", "def", "_build_newsencoder", "(", "self", ",", "embedding_layer", ",", "user_embedding_layer", ")", ":", "\n", "        ", "\"\"\"The main function to create news encoder of NPA.\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the news encoder of NPA.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "sequence_title_uindex", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "title_size", "+", "1", ",", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "\n", "sequences_input_title", "=", "layers", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", ":", "hparams", ".", "title_size", "]", ")", "(", "\n", "sequence_title_uindex", "\n", ")", "\n", "user_index", "=", "layers", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", "hparams", ".", "title_size", ":", "]", ")", "(", "\n", "sequence_title_uindex", "\n", ")", "\n", "\n", "u_emb", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "user_emb_dim", ",", ")", ")", "(", "\n", "user_embedding_layer", "(", "user_index", ")", "\n", ")", "\n", "embedded_sequences_title", "=", "embedding_layer", "(", "sequences_input_title", ")", "\n", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "embedded_sequences_title", ")", "\n", "y", "=", "layers", ".", "Conv1D", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "window_size", ",", "\n", "activation", "=", "hparams", ".", "cnn_activation", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "y", ")", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "y", ")", "\n", "\n", "pred_title", "=", "PersonalizedAttentivePooling", "(", "\n", "hparams", ".", "title_size", ",", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "attention_hidden_dim", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "(", "[", "y", ",", "layers", ".", "Dense", "(", "hparams", ".", "attention_hidden_dim", ")", "(", "u_emb", ")", "]", ")", "\n", "\n", "# pred_title = Reshape((1, feature_size))(pred_title)", "\n", "model", "=", "keras", ".", "Model", "(", "sequence_title_uindex", ",", "pred_title", ",", "name", "=", "\"news_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.npa.NPAModel._build_npa": [[146, 220], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "npa.NPAModel._build_newsencoder", "npa.NPAModel._build_userencoder", "npa.NPAModel.", "newsencoder", "tensorflow.Model", "tensorflow.Model", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "len", "tensorflow.keras.layers.TimeDistributed", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dot", "tensorflow.keras.layers.Activation"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_newsencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_userencoder"], ["", "def", "_build_npa", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create NPA's logic. The core of NPA\n        is a user encoder and a news encoder.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and predict.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title_one", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "\n", "1", ",", "\n", "hparams", ".", "title_size", ",", "\n", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "pred_title_one_reshape", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "title_size", ",", ")", ")", "(", "\n", "pred_input_title_one", "\n", ")", "\n", "user_indexes", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "nuser_index", "=", "layers", ".", "Reshape", "(", "(", "1", ",", "1", ")", ")", "(", "user_indexes", ")", "\n", "repeat_uindex", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "2", ")", "(", "\n", "[", "nuser_index", "]", "*", "(", "hparams", ".", "npratio", "+", "1", ")", "\n", ")", "\n", "pred_title_uindex", "=", "layers", ".", "Concatenate", "(", "axis", "=", "-", "1", ")", "(", "\n", "[", "pred_input_title", ",", "repeat_uindex", "]", "\n", ")", "\n", "pred_title_uindex_one", "=", "layers", ".", "Concatenate", "(", ")", "(", "\n", "[", "pred_title_one_reshape", ",", "user_indexes", "]", "\n", ")", "\n", "\n", "embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "self", ".", "word2vec_embedding", ".", "shape", "[", "0", "]", ",", "\n", "hparams", ".", "word_emb_dim", ",", "\n", "weights", "=", "[", "self", ".", "word2vec_embedding", "]", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "\n", "user_embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "len", "(", "self", ".", "train_iterator", ".", "uid2index", ")", ",", "\n", "hparams", ".", "user_emb_dim", ",", "\n", "trainable", "=", "True", ",", "\n", "embeddings_initializer", "=", "\"zeros\"", ",", "\n", ")", "\n", "\n", "titleencoder", "=", "self", ".", "_build_newsencoder", "(", "embedding_layer", ",", "user_embedding_layer", ")", "\n", "userencoder", "=", "self", ".", "_build_userencoder", "(", "titleencoder", ",", "user_embedding_layer", ")", "\n", "newsencoder", "=", "titleencoder", "\n", "\n", "user_present", "=", "userencoder", "(", "[", "his_input_title", ",", "user_indexes", "]", ")", "\n", "\n", "news_present", "=", "layers", ".", "TimeDistributed", "(", "newsencoder", ")", "(", "pred_title_uindex", ")", "\n", "news_present_one", "=", "newsencoder", "(", "pred_title_uindex_one", ")", "\n", "\n", "preds", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present", ",", "user_present", "]", ")", "\n", "preds", "=", "layers", ".", "Activation", "(", "activation", "=", "\"softmax\"", ")", "(", "preds", ")", "\n", "\n", "pred_one", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present_one", ",", "user_present", "]", ")", "\n", "pred_one", "=", "layers", ".", "Activation", "(", "activation", "=", "\"sigmoid\"", ")", "(", "pred_one", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "[", "user_indexes", ",", "his_input_title", ",", "pred_input_title", "]", ",", "preds", ")", "\n", "scorer", "=", "keras", ".", "Model", "(", "\n", "[", "user_indexes", ",", "his_input_title", ",", "pred_input_title_one", "]", ",", "pred_one", "\n", ")", "\n", "\n", "return", "model", ",", "scorer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel.__init__": [[29, 44], ["lstur.LSTURModel._init_embedding", "recommenders.models.newsrec.models.base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization steps for LSTUR.\n        Compared with the BaseModel, LSTUR need word embedding.\n        After creating word embedding matrix, BaseModel's __init__ method will be called.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as type and gru_unit are there.\n            iterator_creator_train (object): LSTUR data loader class for train data.\n            iterator_creator_test (object): LSTUR data loader class for test and validation data\n        \"\"\"", "\n", "\n", "self", ".", "word2vec_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "wordEmb_file", ")", "\n", "self", ".", "hparam", "=", "hparams", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._get_input_label_from_iter": [[45, 53], ["None"], "methods", ["None"], ["", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "input_feat", "=", "[", "\n", "batch_data", "[", "\"user_index_batch\"", "]", ",", "\n", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "\n", "batch_data", "[", "\"candidate_title_batch\"", "]", ",", "\n", "]", "\n", "input_label", "=", "batch_data", "[", "\"labels\"", "]", "\n", "return", "input_feat", ",", "input_label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._get_user_feature_from_iter": [[54, 56], ["None"], "methods", ["None"], ["", "def", "_get_user_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "return", "[", "batch_data", "[", "\"clicked_title_batch\"", "]", ",", "batch_data", "[", "\"user_index_batch\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._get_news_feature_from_iter": [[57, 59], ["None"], "methods", ["None"], ["", "def", "_get_news_feature_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "return", "batch_data", "[", "\"candidate_title_batch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_graph": [[60, 70], ["lstur.LSTURModel._build_lstur"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_lstur"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build LSTUR model and scorer.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "\n", "model", ",", "scorer", "=", "self", ".", "_build_lstur", "(", ")", "\n", "return", "model", ",", "scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_userencoder": [[71, 127], ["tensorflow.Input", "tensorflow.Input", "tensorflow.compat.v1.keras.layers.Embedding", "tensorflow.Model", "len", "tensorflow.compat.v1.keras.layers.Reshape", "tensorflow.compat.v1.keras.layers.Embedding.", "tensorflow.compat.v1.keras.layers.TimeDistributed", "tensorflow.compat.v1.keras.layers.GRU", "tensorflow.compat.v1.keras.layers.Masking", "tensorflow.compat.v1.keras.layers.GRU", "tensorflow.compat.v1.keras.layers.Concatenate", "tensorflow.compat.v1.keras.layers.Dense", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.Zeros", "tensorflow.compat.v1.keras.layers.Masking", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.glorot_uniform", "tensorflow.initializers.Zeros", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform"], "methods", ["None"], ["", "def", "_build_userencoder", "(", "self", ",", "titleencoder", ",", "type", "=", "\"ini\"", ")", ":", "\n", "        ", "\"\"\"The main function to create user encoder of LSTUR.\n\n        Args:\n            titleencoder (object): the news encoder of LSTUR.\n\n        Return:\n            object: the user encoder of LSTUR.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "user_indexes", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "user_embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "len", "(", "self", ".", "train_iterator", ".", "uid2index", ")", ",", "\n", "hparams", ".", "gru_unit", ",", "\n", "trainable", "=", "True", ",", "\n", "embeddings_initializer", "=", "\"zeros\"", ",", "\n", ")", "\n", "\n", "long_u_emb", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "gru_unit", ",", ")", ")", "(", "\n", "user_embedding_layer", "(", "user_indexes", ")", "\n", ")", "\n", "click_title_presents", "=", "layers", ".", "TimeDistributed", "(", "titleencoder", ")", "(", "his_input_title", ")", "\n", "\n", "if", "type", "==", "\"ini\"", ":", "\n", "            ", "user_present", "=", "layers", ".", "GRU", "(", "\n", "hparams", ".", "gru_unit", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "recurrent_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", ")", "(", "\n", "layers", ".", "Masking", "(", "mask_value", "=", "0.0", ")", "(", "click_title_presents", ")", ",", "\n", "initial_state", "=", "[", "long_u_emb", "]", ",", "\n", ")", "\n", "", "elif", "type", "==", "\"con\"", ":", "\n", "            ", "short_uemb", "=", "layers", ".", "GRU", "(", "\n", "hparams", ".", "gru_unit", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "recurrent_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", ")", "(", "layers", ".", "Masking", "(", "mask_value", "=", "0.0", ")", "(", "click_title_presents", ")", ")", "\n", "\n", "user_present", "=", "layers", ".", "Concatenate", "(", ")", "(", "[", "short_uemb", ",", "long_u_emb", "]", ")", "\n", "user_present", "=", "layers", ".", "Dense", "(", "\n", "hparams", ".", "gru_unit", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "user_present", ")", "\n", "\n", "", "model", "=", "keras", ".", "Model", "(", "\n", "[", "his_input_title", ",", "user_indexes", "]", ",", "user_present", ",", "name", "=", "\"user_encoder\"", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_newsencoder": [[128, 159], ["tensorflow.Input", "embedding_layer", "print", "print", "tensorflow.Model", "tensorflow.compat.v1.keras.layers.Dropout", "tensorflow.compat.v1.keras.layers.Conv1D", "tensorflow.compat.v1.keras.layers.Dropout", "tensorflow.compat.v1.keras.layers.Masking", "recommenders.models.newsrec.models.layers.AttLayer2", "recommenders.models.newsrec.models.layers.OverwriteMasking", "tensorflow.initializers.Zeros", "tensorflow.initializers.glorot_uniform", "recommenders.models.newsrec.models.layers.ComputeMasking"], "methods", ["None"], ["", "def", "_build_newsencoder", "(", "self", ",", "embedding_layer", ")", ":", "\n", "        ", "\"\"\"The main function to create news encoder of LSTUR.\n\n        Args:\n            embedding_layer (object): a word embedding layer.\n\n        Return:\n            object: the news encoder of LSTUR.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "sequences_input_title", "=", "keras", ".", "Input", "(", "shape", "=", "(", "hparams", ".", "title_size", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "embedded_sequences_title", "=", "embedding_layer", "(", "sequences_input_title", ")", "\n", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "embedded_sequences_title", ")", "\n", "y", "=", "layers", ".", "Conv1D", "(", "\n", "hparams", ".", "filter_num", ",", "\n", "hparams", ".", "window_size", ",", "\n", "activation", "=", "hparams", ".", "cnn_activation", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "bias_initializer", "=", "keras", ".", "initializers", ".", "Zeros", "(", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", ",", "\n", ")", "(", "y", ")", "\n", "print", "(", "y", ")", "\n", "y", "=", "layers", ".", "Dropout", "(", "hparams", ".", "dropout", ")", "(", "y", ")", "\n", "y", "=", "layers", ".", "Masking", "(", ")", "(", "\n", "OverwriteMasking", "(", ")", "(", "[", "y", ",", "ComputeMasking", "(", ")", "(", "sequences_input_title", ")", "]", ")", "\n", ")", "\n", "pred_title", "=", "AttLayer2", "(", "hparams", ".", "attention_hidden_dim", ",", "seed", "=", "self", ".", "seed", ")", "(", "y", ")", "\n", "print", "(", "pred_title", ")", "\n", "model", "=", "keras", ".", "Model", "(", "sequences_input_title", ",", "pred_title", ",", "name", "=", "\"news_encoder\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_lstur": [[160, 213], ["tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.Input", "tensorflow.compat.v1.keras.layers.Embedding", "lstur.LSTURModel._build_newsencoder", "lstur.LSTURModel._build_userencoder", "lstur.LSTURModel.userencoder", "lstur.LSTURModel.newsencoder", "tensorflow.Model", "tensorflow.Model", "tensorflow.compat.v1.keras.layers.Reshape", "tensorflow.compat.v1.keras.layers.TimeDistributed", "tensorflow.compat.v1.keras.layers.Dot", "tensorflow.compat.v1.keras.layers.Activation", "tensorflow.compat.v1.keras.layers.Dot", "tensorflow.compat.v1.keras.layers.Activation"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_newsencoder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._build_userencoder"], ["", "def", "_build_lstur", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create LSTUR's logic. The core of LSTUR\n        is a user encoder and a news encoder.\n\n        Returns:\n            object: a model used to train.\n            object: a model used to evaluate and inference.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "\n", "his_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "his_size", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "hparams", ".", "npratio", "+", "1", ",", "hparams", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "pred_input_title_one", "=", "keras", ".", "Input", "(", "\n", "shape", "=", "(", "\n", "1", ",", "\n", "hparams", ".", "title_size", ",", "\n", ")", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "pred_title_reshape", "=", "layers", ".", "Reshape", "(", "(", "hparams", ".", "title_size", ",", ")", ")", "(", "pred_input_title_one", ")", "\n", "user_indexes", "=", "keras", ".", "Input", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "embedding_layer", "=", "layers", ".", "Embedding", "(", "\n", "self", ".", "word2vec_embedding", ".", "shape", "[", "0", "]", ",", "\n", "hparams", ".", "word_emb_dim", ",", "\n", "weights", "=", "[", "self", ".", "word2vec_embedding", "]", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "\n", "titleencoder", "=", "self", ".", "_build_newsencoder", "(", "embedding_layer", ")", "\n", "self", ".", "userencoder", "=", "self", ".", "_build_userencoder", "(", "titleencoder", ",", "type", "=", "hparams", ".", "type", ")", "\n", "self", ".", "newsencoder", "=", "titleencoder", "\n", "\n", "user_present", "=", "self", ".", "userencoder", "(", "[", "his_input_title", ",", "user_indexes", "]", ")", "\n", "news_present", "=", "layers", ".", "TimeDistributed", "(", "self", ".", "newsencoder", ")", "(", "pred_input_title", ")", "\n", "news_present_one", "=", "self", ".", "newsencoder", "(", "pred_title_reshape", ")", "\n", "\n", "preds", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present", ",", "user_present", "]", ")", "\n", "preds", "=", "layers", ".", "Activation", "(", "activation", "=", "\"softmax\"", ")", "(", "preds", ")", "\n", "\n", "pred_one", "=", "layers", ".", "Dot", "(", "axes", "=", "-", "1", ")", "(", "[", "news_present_one", ",", "user_present", "]", ")", "\n", "pred_one", "=", "layers", ".", "Activation", "(", "activation", "=", "\"sigmoid\"", ")", "(", "pred_one", ")", "\n", "\n", "model", "=", "keras", ".", "Model", "(", "[", "user_indexes", ",", "his_input_title", ",", "pred_input_title", "]", ",", "preds", ")", "\n", "scorer", "=", "keras", ".", "Model", "(", "\n", "[", "user_indexes", ",", "his_input_title", ",", "pred_input_title_one", "]", ",", "pred_one", "\n", ")", "\n", "\n", "return", "model", ",", "scorer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.__init__": [[20, 74], ["tensorflow.compat.v1.set_random_seed", "numpy.random.seed", "iterator_creator", "tensorflow.compat.v1.GPUOptions", "tensorflow.compat.v1.Session", "base_model.BaseModel.sess.run", "tensorflow.Graph", "base_model.BaseModel.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "base_model.BaseModel._get_initializer", "base_model.BaseModel._build_graph", "base_model.BaseModel._get_pred", "base_model.BaseModel._get_loss", "tensorflow.compat.v1.train.Saver", "base_model.BaseModel._build_train_opt", "tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.global_variables_initializer", "base_model.BaseModel._add_summaries", "hparams.values", "tensorflow.compat.v1.ConfigProto"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_initializer", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._get_pred", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_loss", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._build_train_opt", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._add_summaries", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "iterator_creator", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializing the model. Create common logics which are needed by all deeprec models, such as loss function,\n        parameter set.\n\n        Args:\n            hparams (HParams): A HParams object, holds the entire set of hyperparameters.\n            iterator_creator (object): An iterator to load the data.\n            graph (object): An optional graph.\n            seed (int): Random seed.\n        \"\"\"", "\n", "self", ".", "seed", "=", "seed", "\n", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "self", ".", "train_iterator", "=", "iterator_creator", "(", "\n", "hparams", ",", "\n", "hparams", ".", "npratio", ",", "\n", "col_spliter", "=", "\"\\t\"", ",", "\n", ")", "\n", "self", ".", "test_iterator", "=", "iterator_creator", "(", "\n", "hparams", ",", "\n", "col_spliter", "=", "\"\\t\"", ",", "\n", ")", "\n", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "support_quick_scoring", "=", "hparams", ".", "support_quick_scoring", "\n", "\n", "# set GPU use with on demand growth", "\n", "gpu_options", "=", "tf", ".", "compat", ".", "v1", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "\n", "config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", ")", "\n", "\n", "# set this TensorFlow session as the default session for Keras", "\n", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "backend", ".", "set_session", "(", "sess", ")", "\n", "\n", "# IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras!", "\n", "# Otherwise, their weights will be unavailable in the threads after the session there has been set", "\n", "self", ".", "model", ",", "self", ".", "scorer", "=", "self", ".", "_build_graph", "(", ")", "\n", "\n", "self", ".", "loss", "=", "self", ".", "_get_loss", "(", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._init_embedding": [[79, 90], ["numpy.load"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "_init_embedding", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"Load pre-trained embeddings as a constant tensor.\n\n        Args:\n            file_path (str): the pre-trained glove embeddings file path.\n\n        Returns:\n            numpy.ndarray: A constant numpy array.\n        \"\"\"", "\n", "\n", "return", "np", ".", "load", "(", "file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._build_graph": [[75, 79], ["None"], "methods", ["None"], ["self", ".", "train_optimizer", "=", "self", ".", "_get_opt", "(", ")", "\n", "\n", "self", ".", "model", ".", "compile", "(", "loss", "=", "self", ".", "loss", ",", "optimizer", "=", "self", ".", "train_optimizer", ")", "\n", "\n", "", "def", "_init_embedding", "(", "self", ",", "file_path", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_input_label_from_iter": [[96, 100], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"Subclass will implement this\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_loss": [[80, 90], ["base_model.BaseModel._compute_data_loss", "base_model.BaseModel._compute_regular_loss", "tensorflow.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._compute_data_loss", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._compute_regular_loss"], ["        ", "\"\"\"Load pre-trained embeddings as a constant tensor.\n\n        Args:\n            file_path (str): the pre-trained glove embeddings file path.\n\n        Returns:\n            numpy.ndarray: A constant numpy array.\n        \"\"\"", "\n", "\n", "return", "np", ".", "load", "(", "file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_opt": [[115, 127], ["tensorflow.compat.v1.keras.optimizers.Adam"], "methods", ["None"], ["", "def", "_get_opt", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the optimizer according to configuration. Usually we will use Adam.\n        Returns:\n            object: An optimizer.\n        \"\"\"", "\n", "lr", "=", "self", ".", "hparams", ".", "learning_rate", "\n", "optimizer", "=", "self", ".", "hparams", ".", "optimizer", "\n", "\n", "if", "optimizer", "==", "\"adam\"", ":", "\n", "            ", "train_opt", "=", "keras", ".", "optimizers", ".", "Adam", "(", "lr", "=", "lr", ")", "\n", "\n", "", "return", "train_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_pred": [[91, 113], ["tensorflow.identity", "tensorflow.identity", "tensorflow.sigmoid", "ValueError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Subclass will implement this.\"\"\"", "\n", "pass", "\n", "\n", "", "@", "abc", ".", "abstractmethod", "\n", "def", "_get_input_label_from_iter", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "\"\"\"Subclass will implement this\"\"\"", "\n", "pass", "\n", "\n", "", "def", "_get_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make loss function, consists of data loss and regularization loss\n\n        Returns:\n            object: Loss function or loss function name\n        \"\"\"", "\n", "if", "self", ".", "hparams", ".", "loss", "==", "\"cross_entropy_loss\"", ":", "\n", "            ", "data_loss", "=", "\"categorical_crossentropy\"", "\n", "", "elif", "self", ".", "hparams", ".", "loss", "==", "\"log_loss\"", ":", "\n", "            ", "data_loss", "=", "\"binary_crossentropy\"", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"this loss not defined {0}\"", ".", "format", "(", "self", ".", "hparams", ".", "loss", ")", ")", "\n", "", "return", "data_loss", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.train": [[367, 388], ["sess.run"], "methods", ["None"], ["", "def", "run_news", "(", "self", ",", "news_filename", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"newsencoder\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"model must have attribute newsencoder\"", ")", "\n", "\n", "", "news_indexes", "=", "[", "]", "\n", "news_vecs", "=", "[", "]", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_news_from_file", "(", "news_filename", ")", "\n", ")", ":", "\n", "            ", "news_index", ",", "news_vec", "=", "self", ".", "news", "(", "batch_data_input", ")", "\n", "news_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "news_index", ",", "-", "1", ")", ")", "\n", "news_vecs", ".", "extend", "(", "news_vec", ")", "\n", "\n", "", "return", "dict", "(", "zip", "(", "news_indexes", ",", "news_vecs", ")", ")", "\n", "\n", "", "def", "run_slow_eval", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_data_from_file", "(", "news_filename", ",", "behaviors_file", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.eval": [[390, 403], ["sess.run"], "methods", ["None"], ["            ", "step_pred", ",", "step_labels", ",", "step_imp_index", "=", "self", ".", "eval", "(", "batch_data_input", ")", "\n", "preds", ".", "extend", "(", "np", ".", "reshape", "(", "step_pred", ",", "-", "1", ")", ")", "\n", "labels", ".", "extend", "(", "np", ".", "reshape", "(", "step_labels", ",", "-", "1", ")", ")", "\n", "imp_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "step_imp_index", ",", "-", "1", ")", ")", "\n", "\n", "", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "=", "self", ".", "group_labels", "(", "\n", "labels", ",", "preds", ",", "imp_indexes", "\n", ")", "\n", "return", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "\n", "\n", "", "def", "run_fast_eval", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "news_vecs", "=", "self", ".", "run_news", "(", "news_filename", ")", "\n", "user_vecs", "=", "self", ".", "run_user", "(", "news_filename", ",", "behaviors_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.fit": [[436, 541], ["range", "tensorflow.compat.v1.summary.FileWriter", "time.time", "base_model.BaseModel.iterator.load_data_from_file", "time.time", "time.time", "base_model.BaseModel.run_eval", "time.time", "print", "base_model.BaseModel.writer.close", "base_model.BaseModel.train", "base_model.BaseModel.run_eval", "print", "print", "base_model.BaseModel.writer.add_summary", "print", "os.path.exists", "os.makedirs", "os.path.join", "base_model.BaseModel.saver.save", "str", "str", "sorted", "str", "str", "str", "base_model.BaseModel.items", "str", "sorted", "str", "base_model.BaseModel.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.group_labels": [[542, 567], ["list", "zip", "set", "group_labels[].append", "group_preds[].append", "all_labels.append", "all_preds.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_eval": [[568, 596], ["base_model.BaseModel.iterator.load_data_from_file", "recommenders.models.deeprec.deeprec_utils.cal_metric", "base_model.BaseModel.eval", "preds.extend", "labels.extend", "imp_indexs.extend", "base_model.BaseModel.hparams.values", "base_model.BaseModel.group_labels", "recommenders.models.deeprec.deeprec_utils.cal_metric", "recommenders.models.deeprec.deeprec_utils.cal_metric.update", "numpy.reshape", "numpy.reshape", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.group_labels", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.user": [[338, 344], ["base_model.BaseModel._get_user_feature_from_iter", "base_model.BaseModel.userencoder.predict_on_batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._get_user_feature_from_iter"], ["", "def", "user", "(", "self", ",", "batch_user_input", ")", ":", "\n", "        ", "user_input", "=", "self", ".", "_get_user_feature_from_iter", "(", "batch_user_input", ")", "\n", "user_vec", "=", "self", ".", "userencoder", ".", "predict_on_batch", "(", "user_input", ")", "\n", "user_index", "=", "batch_user_input", "[", "\"impr_index_batch\"", "]", "\n", "\n", "return", "user_index", ",", "user_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.news": [[345, 351], ["base_model.BaseModel._get_news_feature_from_iter", "base_model.BaseModel.newsencoder.predict_on_batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.lstur.LSTURModel._get_news_feature_from_iter"], ["", "def", "news", "(", "self", ",", "batch_news_input", ")", ":", "\n", "        ", "news_input", "=", "self", ".", "_get_news_feature_from_iter", "(", "batch_news_input", ")", "\n", "news_vec", "=", "self", ".", "newsencoder", ".", "predict_on_batch", "(", "news_input", ")", "\n", "news_index", "=", "batch_news_input", "[", "\"news_index_batch\"", "]", "\n", "\n", "return", "news_index", ",", "news_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_user": [[352, 366], ["tqdm.tqdm.tqdm", "dict", "hasattr", "ValueError", "base_model.BaseModel.test_iterator.load_user_from_file", "base_model.BaseModel.user", "user_indexes.extend", "user_vecs.extend", "zip", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_user_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.user"], ["", "def", "run_user", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"userencoder\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"model must have attribute userencoder\"", ")", "\n", "\n", "", "user_indexes", "=", "[", "]", "\n", "user_vecs", "=", "[", "]", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_user_from_file", "(", "news_filename", ",", "behaviors_file", ")", "\n", ")", ":", "\n", "            ", "user_index", ",", "user_vec", "=", "self", ".", "user", "(", "batch_data_input", ")", "\n", "user_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "user_index", ",", "-", "1", ")", ")", "\n", "user_vecs", ".", "extend", "(", "user_vec", ")", "\n", "\n", "", "return", "dict", "(", "zip", "(", "user_indexes", ",", "user_vecs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_news": [[367, 381], ["tqdm.tqdm.tqdm", "dict", "hasattr", "ValueError", "base_model.BaseModel.test_iterator.load_news_from_file", "base_model.BaseModel.news", "news_indexes.extend", "news_vecs.extend", "zip", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_news_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.news"], ["", "def", "run_news", "(", "self", ",", "news_filename", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"newsencoder\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"model must have attribute newsencoder\"", ")", "\n", "\n", "", "news_indexes", "=", "[", "]", "\n", "news_vecs", "=", "[", "]", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_news_from_file", "(", "news_filename", ")", "\n", ")", ":", "\n", "            ", "news_index", ",", "news_vec", "=", "self", ".", "news", "(", "batch_data_input", ")", "\n", "news_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "news_index", ",", "-", "1", ")", ")", "\n", "news_vecs", ".", "extend", "(", "news_vec", ")", "\n", "\n", "", "return", "dict", "(", "zip", "(", "news_indexes", ",", "news_vecs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_slow_eval": [[382, 399], ["tqdm.tqdm.tqdm", "base_model.BaseModel.group_labels", "base_model.BaseModel.test_iterator.load_data_from_file", "base_model.BaseModel.eval", "preds.extend", "labels.extend", "imp_indexes.extend", "numpy.reshape", "numpy.reshape", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.group_labels", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "run_slow_eval", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_data_from_file", "(", "news_filename", ",", "behaviors_file", ")", "\n", ")", ":", "\n", "            ", "step_pred", ",", "step_labels", ",", "step_imp_index", "=", "self", ".", "eval", "(", "batch_data_input", ")", "\n", "preds", ".", "extend", "(", "np", ".", "reshape", "(", "step_pred", ",", "-", "1", ")", ")", "\n", "labels", ".", "extend", "(", "np", ".", "reshape", "(", "step_labels", ",", "-", "1", ")", ")", "\n", "imp_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "step_imp_index", ",", "-", "1", ")", ")", "\n", "\n", "", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "=", "self", ".", "group_labels", "(", "\n", "labels", ",", "preds", ",", "imp_indexes", "\n", ")", "\n", "return", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_fast_eval": [[400, 426], ["base_model.BaseModel.run_news", "base_model.BaseModel.run_user", "tqdm.tqdm.tqdm", "base_model.BaseModel.test_iterator.load_impression_from_file", "numpy.dot", "group_impr_indexes.append", "group_labels.append", "group_preds.append", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_news", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.run_user", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_impression_from_file"], ["", "def", "run_fast_eval", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "news_vecs", "=", "self", ".", "run_news", "(", "news_filename", ")", "\n", "user_vecs", "=", "self", ".", "run_user", "(", "news_filename", ",", "behaviors_file", ")", "\n", "\n", "self", ".", "news_vecs", "=", "news_vecs", "\n", "self", ".", "user_vecs", "=", "user_vecs", "\n", "\n", "group_impr_indexes", "=", "[", "]", "\n", "group_labels", "=", "[", "]", "\n", "group_preds", "=", "[", "]", "\n", "\n", "for", "(", "\n", "impr_index", ",", "\n", "news_index", ",", "\n", "user_index", ",", "\n", "label", ",", "\n", ")", "in", "tqdm", "(", "self", ".", "test_iterator", ".", "load_impression_from_file", "(", "behaviors_file", ")", ")", ":", "\n", "            ", "pred", "=", "np", ".", "dot", "(", "\n", "np", ".", "stack", "(", "[", "news_vecs", "[", "i", "]", "for", "i", "in", "news_index", "]", ",", "axis", "=", "0", ")", ",", "\n", "user_vecs", "[", "impr_index", "]", ",", "\n", ")", "\n", "group_impr_indexes", ".", "append", "(", "impr_index", ")", "\n", "group_labels", ".", "append", "(", "label", ")", "\n", "group_preds", ".", "append", "(", "pred", ")", "\n", "\n", "", "return", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_graph": [[24, 72], ["numpy.ones_like", "numpy.array", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "xDeepFM.XDeepFMModel.embed_params.append", "xDeepFM.XDeepFMModel._build_embedding", "print", "print", "print", "print", "xDeepFM.XDeepFMModel._build_linear", "xDeepFM.XDeepFMModel._build_fm", "xDeepFM.XDeepFMModel._build_dnn", "xDeepFM.XDeepFMModel._build_CIN", "xDeepFM.XDeepFMModel._build_fast_CIN"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_linear", "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_fm", "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_dnn", "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_CIN", "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_fast_CIN"], ["def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create xdeepfm's logic.\n\n        Returns:\n            object: The prediction score made by the model.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "self", ".", "keep_prob_train", "=", "1", "-", "np", ".", "array", "(", "hparams", ".", "dropout", ")", "\n", "self", ".", "keep_prob_test", "=", "np", ".", "ones_like", "(", "hparams", ".", "dropout", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"XDeepFM\"", ")", "as", "scope", ":", "# noqa: F841", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"embedding\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "escope", ":", "# noqa: F841", "\n", "                ", "self", ".", "embedding", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"embedding_layer\"", ",", "\n", "shape", "=", "[", "hparams", ".", "FEATURE_COUNT", ",", "hparams", ".", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "self", ".", "embed_params", ".", "append", "(", "self", ".", "embedding", ")", "\n", "embed_out", ",", "embed_layer_size", "=", "self", ".", "_build_embedding", "(", ")", "\n", "\n", "", "logit", "=", "0", "\n", "\n", "if", "hparams", ".", "use_Linear_part", ":", "\n", "                ", "print", "(", "\"Add linear part.\"", ")", "\n", "logit", "=", "logit", "+", "self", ".", "_build_linear", "(", ")", "\n", "\n", "", "if", "hparams", ".", "use_FM_part", ":", "\n", "                ", "print", "(", "\"Add FM part.\"", ")", "\n", "logit", "=", "logit", "+", "self", ".", "_build_fm", "(", ")", "\n", "\n", "", "if", "hparams", ".", "use_CIN_part", ":", "\n", "                ", "print", "(", "\"Add CIN part.\"", ")", "\n", "if", "hparams", ".", "fast_CIN_d", "<=", "0", ":", "\n", "                    ", "logit", "=", "logit", "+", "self", ".", "_build_CIN", "(", "\n", "embed_out", ",", "res", "=", "True", ",", "direct", "=", "False", ",", "bias", "=", "False", ",", "is_masked", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "logit", "=", "logit", "+", "self", ".", "_build_fast_CIN", "(", "\n", "embed_out", ",", "res", "=", "True", ",", "direct", "=", "False", ",", "bias", "=", "False", "\n", ")", "\n", "\n", "", "", "if", "hparams", ".", "use_DNN_part", ":", "\n", "                ", "print", "(", "\"Add DNN part.\"", ")", "\n", "logit", "=", "logit", "+", "self", ".", "_build_dnn", "(", "embed_out", ",", "embed_layer_size", ")", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_embedding": [[73, 103], ["tensorflow.SparseTensor", "tensorflow.SparseTensor", "tensorflow.nn.embedding_lookup_sparse", "tensorflow.reshape"], "methods", ["None"], ["", "", "def", "_build_embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"The field embedding layer. MLP requires fixed-length vectors as input.\n        This function makes sum pooling of feature embeddings for each field.\n\n        Returns:\n            embedding:  The result of field embedding layer, with size of #_fields * #_dim.\n            embedding_size: #_fields * #_dim\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "fm_sparse_index", "=", "tf", ".", "SparseTensor", "(", "\n", "self", ".", "iterator", ".", "dnn_feat_indices", ",", "\n", "self", ".", "iterator", ".", "dnn_feat_values", ",", "\n", "self", ".", "iterator", ".", "dnn_feat_shape", ",", "\n", ")", "\n", "fm_sparse_weight", "=", "tf", ".", "SparseTensor", "(", "\n", "self", ".", "iterator", ".", "dnn_feat_indices", ",", "\n", "self", ".", "iterator", ".", "dnn_feat_weights", ",", "\n", "self", ".", "iterator", ".", "dnn_feat_shape", ",", "\n", ")", "\n", "w_fm_nn_input_orgin", "=", "tf", ".", "nn", ".", "embedding_lookup_sparse", "(", "\n", "params", "=", "self", ".", "embedding", ",", "\n", "sp_ids", "=", "fm_sparse_index", ",", "\n", "sp_weights", "=", "fm_sparse_weight", ",", "\n", "combiner", "=", "\"sum\"", ",", "\n", ")", "\n", "embedding", "=", "tf", ".", "reshape", "(", "\n", "w_fm_nn_input_orgin", ",", "[", "-", "1", ",", "hparams", ".", "dim", "*", "hparams", ".", "FIELD_COUNT", "]", "\n", ")", "\n", "embedding_size", "=", "hparams", ".", "FIELD_COUNT", "*", "hparams", ".", "dim", "\n", "return", "embedding", ",", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_linear": [[104, 134], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.SparseTensor", "tensorflow.add", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel.layer_params.append", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "tensorflow.sparse.sparse_dense_matmul", "tensorflow.compat.v1.zeros_initializer"], "methods", ["None"], ["", "def", "_build_linear", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct the linear part for the model.\n        This is a linear regression.\n\n        Returns:\n            object: Prediction score made by linear regression.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"linear_part\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "scope", ":", "# noqa: F841", "\n", "            ", "w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w\"", ",", "shape", "=", "[", "self", ".", "hparams", ".", "FEATURE_COUNT", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b\"", ",", "\n", "shape", "=", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "x", "=", "tf", ".", "SparseTensor", "(", "\n", "self", ".", "iterator", ".", "fm_feat_indices", ",", "\n", "self", ".", "iterator", ".", "fm_feat_values", ",", "\n", "self", ".", "iterator", ".", "fm_feat_shape", ",", "\n", ")", "\n", "linear_output", "=", "tf", ".", "add", "(", "tf", ".", "sparse", ".", "sparse_dense_matmul", "(", "x", ",", "w", ")", ",", "b", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "w", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "b", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"linear_part/w\"", ",", "w", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"linear_part/b\"", ",", "b", ")", "\n", "return", "linear_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_fm": [[135, 160], ["tensorflow.compat.v1.variable_scope", "tensorflow.SparseTensor", "tensorflow.SparseTensor", "tensorflow.pow", "tensorflow.reduce_sum", "tensorflow.pow", "tensorflow.sparse.sparse_dense_matmul", "tensorflow.sparse.sparse_dense_matmul", "tensorflow.pow"], "methods", ["None"], ["", "", "def", "_build_fm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct the factorization machine part for the model.\n        This is a traditional 2-order FM module.\n\n        Returns:\n            object: Prediction score made by factorization machine.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"fm_part\"", ")", "as", "scope", ":", "# noqa: F841", "\n", "            ", "x", "=", "tf", ".", "SparseTensor", "(", "\n", "self", ".", "iterator", ".", "fm_feat_indices", ",", "\n", "self", ".", "iterator", ".", "fm_feat_values", ",", "\n", "self", ".", "iterator", ".", "fm_feat_shape", ",", "\n", ")", "\n", "xx", "=", "tf", ".", "SparseTensor", "(", "\n", "self", ".", "iterator", ".", "fm_feat_indices", ",", "\n", "tf", ".", "pow", "(", "self", ".", "iterator", ".", "fm_feat_values", ",", "2", ")", ",", "\n", "self", ".", "iterator", ".", "fm_feat_shape", ",", "\n", ")", "\n", "fm_output", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "pow", "(", "tf", ".", "sparse", ".", "sparse_dense_matmul", "(", "x", ",", "self", ".", "embedding", ")", ",", "2", ")", "\n", "-", "tf", ".", "sparse", ".", "sparse_dense_matmul", "(", "xx", ",", "tf", ".", "pow", "(", "self", ".", "embedding", ",", "2", ")", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "True", ",", "\n", ")", "\n", "return", "fm_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_CIN": [[161, 294], ["tensorflow.reshape", "field_nums.append", "hidden_nn_layers.append", "tensorflow.split", "int", "tensorflow.compat.v1.variable_scope", "enumerate", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel.layer_params.append", "tensorflow.split", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.compat.v1.get_variable", "tensorflow.nn.conv1d", "xDeepFM.XDeepFMModel._activate", "tensorflow.transpose", "final_result.append", "hidden_nn_layers.append", "xDeepFM.XDeepFMModel.cross_params.append", "tensorflow.reduce_sum", "tensorflow.compat.v1.nn.xw_plus_b", "int", "tensorflow.ones", "tensorflow.reshape", "tensorflow.compat.v1.get_variable", "tensorflow.nn.bias_add", "xDeepFM.XDeepFMModel.cross_params.append", "tensorflow.compat.v1.layers.batch_normalization", "field_nums.append", "field_nums.append", "tensorflow.compat.v1.zeros_initializer", "tensorflow.linalg.band_part", "tensorflow.linalg.tensor_diag", "tensorflow.multiply", "int", "tensorflow.split", "int", "int", "str", "tensorflow.ones", "tensorflow.compat.v1.zeros_initializer", "len", "str", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._activate", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "_build_CIN", "(", "\n", "self", ",", "nn_input", ",", "res", "=", "False", ",", "direct", "=", "False", ",", "bias", "=", "False", ",", "is_masked", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Construct the compressed interaction network.\n        This component provides explicit and vector-wise higher-order feature interactions.\n\n        Args:\n            nn_input (object): The output of field-embedding layer. This is the input for CIN.\n            res (bool): Whether use residual structure to fuse the results from each layer of CIN.\n            direct (bool): If true, then all hidden units are connected to both next layer and output layer;\n                    otherwise, half of hidden units are connected to next layer and the other half will be connected to output layer.\n            bias (bool): Whether to add bias term when calculating the feature maps.\n            is_masked (bool): Controls whether to remove self-interaction in the first layer of CIN.\n\n        Returns:\n            object: Prediction score made by CIN.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "hidden_nn_layers", "=", "[", "]", "\n", "field_nums", "=", "[", "]", "\n", "final_len", "=", "0", "\n", "field_num", "=", "hparams", ".", "FIELD_COUNT", "\n", "nn_input", "=", "tf", ".", "reshape", "(", "nn_input", ",", "shape", "=", "[", "-", "1", ",", "int", "(", "field_num", ")", ",", "hparams", ".", "dim", "]", ")", "\n", "field_nums", ".", "append", "(", "int", "(", "field_num", ")", ")", "\n", "hidden_nn_layers", ".", "append", "(", "nn_input", ")", "\n", "final_result", "=", "[", "]", "\n", "split_tensor0", "=", "tf", ".", "split", "(", "hidden_nn_layers", "[", "0", "]", ",", "hparams", ".", "dim", "*", "[", "1", "]", ",", "2", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"exfm_part\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "scope", ":", "# noqa: F841", "\n", "            ", "for", "idx", ",", "layer_size", "in", "enumerate", "(", "hparams", ".", "cross_layer_sizes", ")", ":", "\n", "                ", "split_tensor", "=", "tf", ".", "split", "(", "hidden_nn_layers", "[", "-", "1", "]", ",", "hparams", ".", "dim", "*", "[", "1", "]", ",", "2", ")", "\n", "dot_result_m", "=", "tf", ".", "matmul", "(", "\n", "split_tensor0", ",", "split_tensor", ",", "transpose_b", "=", "True", "\n", ")", "# shape :  (Dim, Batch, FieldNum, HiddenNum), a.k.a (D,B,F,H)", "\n", "dot_result_o", "=", "tf", ".", "reshape", "(", "\n", "dot_result_m", ",", "\n", "shape", "=", "[", "hparams", ".", "dim", ",", "-", "1", ",", "field_nums", "[", "0", "]", "*", "field_nums", "[", "-", "1", "]", "]", ",", "\n", ")", "# shape: (D,B,FH)", "\n", "dot_result", "=", "tf", ".", "transpose", "(", "a", "=", "dot_result_o", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# (B,D,FH)", "\n", "\n", "filters", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"f_\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "1", ",", "field_nums", "[", "-", "1", "]", "*", "field_nums", "[", "0", "]", ",", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "if", "is_masked", "and", "idx", "==", "0", ":", "\n", "                    ", "ones", "=", "tf", ".", "ones", "(", "[", "field_nums", "[", "0", "]", ",", "field_nums", "[", "0", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "mask_matrix", "=", "tf", ".", "linalg", ".", "band_part", "(", "\n", "ones", ",", "0", ",", "-", "1", "\n", ")", "-", "tf", ".", "linalg", ".", "tensor_diag", "(", "tf", ".", "ones", "(", "field_nums", "[", "0", "]", ")", ")", "\n", "mask_matrix", "=", "tf", ".", "reshape", "(", "\n", "mask_matrix", ",", "shape", "=", "[", "1", ",", "field_nums", "[", "0", "]", "*", "field_nums", "[", "0", "]", "]", "\n", ")", "\n", "\n", "dot_result", "=", "tf", ".", "multiply", "(", "dot_result", ",", "mask_matrix", ")", "*", "2", "\n", "self", ".", "dot_result", "=", "dot_result", "\n", "\n", "", "curr_out", "=", "tf", ".", "nn", ".", "conv1d", "(", "\n", "input", "=", "dot_result", ",", "filters", "=", "filters", ",", "stride", "=", "1", ",", "padding", "=", "\"VALID\"", "\n", ")", "# shape : (B,D,H`)", "\n", "\n", "if", "bias", ":", "\n", "                    ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"f_b\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "curr_out", "=", "tf", ".", "nn", ".", "bias_add", "(", "curr_out", ",", "b", ")", "\n", "self", ".", "cross_params", ".", "append", "(", "b", ")", "\n", "\n", "", "if", "hparams", ".", "enable_BN", "is", "True", ":", "\n", "                    ", "curr_out", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "batch_normalization", "(", "\n", "curr_out", ",", "\n", "momentum", "=", "0.95", ",", "\n", "epsilon", "=", "0.0001", ",", "\n", "training", "=", "self", ".", "is_train_stage", ",", "\n", ")", "\n", "\n", "", "curr_out", "=", "self", ".", "_activate", "(", "curr_out", ",", "hparams", ".", "cross_activation", ")", "\n", "\n", "curr_out", "=", "tf", ".", "transpose", "(", "a", "=", "curr_out", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# shape : (B,H,D)", "\n", "\n", "if", "direct", ":", "\n", "                    ", "direct_connect", "=", "curr_out", "\n", "next_hidden", "=", "curr_out", "\n", "final_len", "+=", "layer_size", "\n", "field_nums", ".", "append", "(", "int", "(", "layer_size", ")", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "idx", "!=", "len", "(", "hparams", ".", "cross_layer_sizes", ")", "-", "1", ":", "\n", "                        ", "next_hidden", ",", "direct_connect", "=", "tf", ".", "split", "(", "\n", "curr_out", ",", "2", "*", "[", "int", "(", "layer_size", "/", "2", ")", "]", ",", "1", "\n", ")", "\n", "final_len", "+=", "int", "(", "layer_size", "/", "2", ")", "\n", "", "else", ":", "\n", "                        ", "direct_connect", "=", "curr_out", "\n", "next_hidden", "=", "0", "\n", "final_len", "+=", "layer_size", "\n", "", "field_nums", ".", "append", "(", "int", "(", "layer_size", "/", "2", ")", ")", "\n", "\n", "", "final_result", ".", "append", "(", "direct_connect", ")", "\n", "hidden_nn_layers", ".", "append", "(", "next_hidden", ")", "\n", "\n", "self", ".", "cross_params", ".", "append", "(", "filters", ")", "\n", "\n", "", "result", "=", "tf", ".", "concat", "(", "final_result", ",", "axis", "=", "1", ")", "\n", "result", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "result", ",", "axis", "=", "-", "1", ")", "# shape : (B,H)", "\n", "\n", "if", "res", ":", "\n", "                ", "base_score", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "result", ",", "axis", "=", "1", ",", "keepdims", "=", "True", "\n", ")", "# (B,1)", "\n", "", "else", ":", "\n", "                ", "base_score", "=", "0", "\n", "\n", "", "w_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_output\"", ",", "shape", "=", "[", "final_len", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "b_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_output\"", ",", "\n", "shape", "=", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "w_nn_output", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "b_nn_output", ")", "\n", "exFM_out", "=", "base_score", "+", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "result", ",", "w_nn_output", ",", "b_nn_output", "\n", ")", "\n", "return", "exFM_out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_fast_CIN": [[295, 452], ["tensorflow.reshape", "tensorflow.transpose", "field_nums.append", "hidden_nn_layers.append", "int", "tensorflow.compat.v1.variable_scope", "enumerate", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel._activate", "final_result.append", "hidden_nn_layers.append", "tensorflow.reduce_sum", "tensorflow.compat.v1.nn.xw_plus_b", "int", "tensorflow.compat.v1.get_variable", "xDeepFM.XDeepFMModel.cross_params.append", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "xDeepFM.XDeepFMModel.cross_params.append", "xDeepFM.XDeepFMModel.cross_params.append", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_variable", "tensorflow.nn.bias_add", "xDeepFM.XDeepFMModel.cross_params.append", "tensorflow.compat.v1.layers.batch_normalization", "field_nums.append", "tensorflow.compat.v1.zeros_initializer", "tensorflow.multiply", "int", "tensorflow.split", "int", "field_nums.append", "field_nums.append", "str", "tensorflow.pow", "tensorflow.pow", "str", "str", "tensorflow.compat.v1.zeros_initializer", "len", "int", "int", "str", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._activate", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "_build_fast_CIN", "(", "self", ",", "nn_input", ",", "res", "=", "False", ",", "direct", "=", "False", ",", "bias", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct the compressed interaction network with reduced parameters.\n        This component provides explicit and vector-wise higher-order feature interactions.\n        Parameters from the filters are reduced via a matrix decomposition method.\n        Fast CIN is more space and time efficient than CIN.\n\n        Args:\n            nn_input (object): The output of field-embedding layer. This is the input for CIN.\n            res (bool): Whether use residual structure to fuse the results from each layer of CIN.\n            direct (bool): If true, then all hidden units are connected to both next layer and output layer;\n                    otherwise, half of hidden units are connected to next layer and the other half will be connected to output layer.\n            bias (bool): Whether to add bias term when calculating the feature maps.\n\n        Returns:\n            object: Prediction score made by fast CIN.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "hidden_nn_layers", "=", "[", "]", "\n", "field_nums", "=", "[", "]", "\n", "final_len", "=", "0", "\n", "field_num", "=", "hparams", ".", "FIELD_COUNT", "\n", "fast_CIN_d", "=", "hparams", ".", "fast_CIN_d", "\n", "nn_input", "=", "tf", ".", "reshape", "(", "\n", "nn_input", ",", "shape", "=", "[", "-", "1", ",", "int", "(", "field_num", ")", ",", "hparams", ".", "dim", "]", "\n", ")", "# (B,F,D)", "\n", "nn_input", "=", "tf", ".", "transpose", "(", "a", "=", "nn_input", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# (B,D,F)", "\n", "field_nums", ".", "append", "(", "int", "(", "field_num", ")", ")", "\n", "hidden_nn_layers", ".", "append", "(", "nn_input", ")", "\n", "final_result", "=", "[", "]", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"exfm_part\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "scope", ":", "# noqa: F841", "\n", "            ", "for", "idx", ",", "layer_size", "in", "enumerate", "(", "hparams", ".", "cross_layer_sizes", ")", ":", "\n", "                ", "if", "idx", "==", "0", ":", "\n", "                    ", "fast_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"fast_CIN_w_\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "1", ",", "field_nums", "[", "0", "]", ",", "fast_CIN_d", "*", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "self", ".", "cross_params", ".", "append", "(", "fast_w", ")", "\n", "dot_result_1", "=", "tf", ".", "nn", ".", "conv1d", "(", "\n", "input", "=", "nn_input", ",", "filters", "=", "fast_w", ",", "stride", "=", "1", ",", "padding", "=", "\"VALID\"", "\n", ")", "# shape: (B,D,d*H)", "\n", "dot_result_2", "=", "tf", ".", "nn", ".", "conv1d", "(", "\n", "input", "=", "tf", ".", "pow", "(", "nn_input", ",", "2", ")", ",", "\n", "filters", "=", "tf", ".", "pow", "(", "fast_w", ",", "2", ")", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", ")", "# shape: ((B,D,d*H)", "\n", "dot_result", "=", "tf", ".", "reshape", "(", "\n", "0.5", "*", "(", "dot_result_1", "-", "dot_result_2", ")", ",", "\n", "shape", "=", "[", "-", "1", ",", "hparams", ".", "dim", ",", "layer_size", ",", "fast_CIN_d", "]", ",", "\n", ")", "\n", "curr_out", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "dot_result", ",", "axis", "=", "3", ",", "keepdims", "=", "False", "\n", ")", "# shape: ((B,D,H)", "\n", "", "else", ":", "\n", "                    ", "fast_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"fast_CIN_w_\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "1", ",", "field_nums", "[", "0", "]", ",", "fast_CIN_d", "*", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "fast_v", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"fast_CIN_v_\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "1", ",", "field_nums", "[", "-", "1", "]", ",", "fast_CIN_d", "*", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "self", ".", "cross_params", ".", "append", "(", "fast_w", ")", "\n", "self", ".", "cross_params", ".", "append", "(", "fast_v", ")", "\n", "\n", "dot_result_1", "=", "tf", ".", "nn", ".", "conv1d", "(", "\n", "input", "=", "nn_input", ",", "filters", "=", "fast_w", ",", "stride", "=", "1", ",", "padding", "=", "\"VALID\"", "\n", ")", "# shape: ((B,D,d*H)", "\n", "dot_result_2", "=", "tf", ".", "nn", ".", "conv1d", "(", "\n", "input", "=", "hidden_nn_layers", "[", "-", "1", "]", ",", "\n", "filters", "=", "fast_v", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", ")", "# shape: ((B,D,d*H)", "\n", "dot_result", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "multiply", "(", "dot_result_1", ",", "dot_result_2", ")", ",", "\n", "shape", "=", "[", "-", "1", ",", "hparams", ".", "dim", ",", "layer_size", ",", "fast_CIN_d", "]", ",", "\n", ")", "\n", "curr_out", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "dot_result", ",", "axis", "=", "3", ",", "keepdims", "=", "False", "\n", ")", "# shape: ((B,D,H)", "\n", "\n", "", "if", "bias", ":", "\n", "                    ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"f_b\"", "+", "str", "(", "idx", ")", ",", "\n", "shape", "=", "[", "1", ",", "1", ",", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "curr_out", "=", "tf", ".", "nn", ".", "bias_add", "(", "curr_out", ",", "b", ")", "\n", "self", ".", "cross_params", ".", "append", "(", "b", ")", "\n", "\n", "", "if", "hparams", ".", "enable_BN", "is", "True", ":", "\n", "                    ", "curr_out", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "batch_normalization", "(", "\n", "curr_out", ",", "\n", "momentum", "=", "0.95", ",", "\n", "epsilon", "=", "0.0001", ",", "\n", "training", "=", "self", ".", "is_train_stage", ",", "\n", ")", "\n", "\n", "", "curr_out", "=", "self", ".", "_activate", "(", "curr_out", ",", "hparams", ".", "cross_activation", ")", "\n", "\n", "if", "direct", ":", "\n", "                    ", "direct_connect", "=", "curr_out", "\n", "next_hidden", "=", "curr_out", "\n", "final_len", "+=", "layer_size", "\n", "field_nums", ".", "append", "(", "int", "(", "layer_size", ")", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "idx", "!=", "len", "(", "hparams", ".", "cross_layer_sizes", ")", "-", "1", ":", "\n", "                        ", "next_hidden", ",", "direct_connect", "=", "tf", ".", "split", "(", "\n", "curr_out", ",", "2", "*", "[", "int", "(", "layer_size", "/", "2", ")", "]", ",", "2", "\n", ")", "\n", "final_len", "+=", "int", "(", "layer_size", "/", "2", ")", "\n", "field_nums", ".", "append", "(", "int", "(", "layer_size", "/", "2", ")", ")", "\n", "", "else", ":", "\n", "                        ", "direct_connect", "=", "curr_out", "\n", "next_hidden", "=", "0", "\n", "final_len", "+=", "layer_size", "\n", "field_nums", ".", "append", "(", "int", "(", "layer_size", ")", ")", "\n", "\n", "", "", "final_result", ".", "append", "(", "direct_connect", ")", "\n", "hidden_nn_layers", ".", "append", "(", "next_hidden", ")", "\n", "\n", "", "result", "=", "tf", ".", "concat", "(", "final_result", ",", "axis", "=", "2", ")", "\n", "result", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "result", ",", "axis", "=", "1", ",", "keepdims", "=", "False", ")", "# (B,H)", "\n", "\n", "if", "res", ":", "\n", "                ", "base_score", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "result", ",", "axis", "=", "1", ",", "keepdims", "=", "True", "\n", ")", "# (B,1)", "\n", "", "else", ":", "\n", "                ", "base_score", "=", "0", "\n", "\n", "", "w_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_output\"", ",", "shape", "=", "[", "final_len", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "b_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_output\"", ",", "\n", "shape", "=", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "w_nn_output", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "b_nn_output", ")", "\n", "exFM_out", "=", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "result", ",", "w_nn_output", ",", "b_nn_output", ")", "+", "base_score", "\n", ")", "\n", "\n", "", "return", "exFM_out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.xDeepFM.XDeepFMModel._build_dnn": [[453, 535], ["hidden_nn_layers.append", "tensorflow.compat.v1.variable_scope", "enumerate", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel.layer_params.append", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.nn.xw_plus_b", "xDeepFM.XDeepFMModel._active_layer", "hidden_nn_layers.append", "xDeepFM.XDeepFMModel.layer_params.append", "xDeepFM.XDeepFMModel.layer_params.append", "str", "tensorflow.compat.v1.layers.batch_normalization", "tensorflow.compat.v1.zeros_initializer", "str", "str", "tensorflow.compat.v1.zeros_initializer", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._active_layer"], ["", "def", "_build_dnn", "(", "self", ",", "embed_out", ",", "embed_layer_size", ")", ":", "\n", "        ", "\"\"\"Construct the MLP part for the model.\n        This components provides implicit higher-order feature interactions.\n\n        Args:\n            embed_out (object): The output of field-embedding layer. This is the input for DNN.\n            embed_layer_size (object): Shape of the embed_out\n\n        Returns:\n            object: Prediction score made by fast CIN.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "w_fm_nn_input", "=", "embed_out", "\n", "last_layer_size", "=", "embed_layer_size", "\n", "layer_idx", "=", "0", "\n", "hidden_nn_layers", "=", "[", "]", "\n", "hidden_nn_layers", ".", "append", "(", "w_fm_nn_input", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"nn_part\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "scope", ":", "\n", "            ", "for", "idx", ",", "layer_size", "in", "enumerate", "(", "hparams", ".", "layer_sizes", ")", ":", "\n", "                ", "curr_w_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "\n", "shape", "=", "[", "last_layer_size", ",", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "curr_b_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "\n", "shape", "=", "[", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"nn_part/\"", "+", "\"w_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "curr_w_nn_layer", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"nn_part/\"", "+", "\"b_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "curr_b_nn_layer", "\n", ")", "\n", "curr_hidden_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "hidden_nn_layers", "[", "layer_idx", "]", ",", "curr_w_nn_layer", ",", "curr_b_nn_layer", "\n", ")", "\n", "scope", "=", "\"nn_part\"", "+", "str", "(", "idx", ")", "# noqa: F841", "\n", "activation", "=", "hparams", ".", "activation", "[", "idx", "]", "\n", "\n", "if", "hparams", ".", "enable_BN", "is", "True", ":", "\n", "                    ", "curr_hidden_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "batch_normalization", "(", "\n", "curr_hidden_nn_layer", ",", "\n", "momentum", "=", "0.95", ",", "\n", "epsilon", "=", "0.0001", ",", "\n", "training", "=", "self", ".", "is_train_stage", ",", "\n", ")", "\n", "\n", "", "curr_hidden_nn_layer", "=", "self", ".", "_active_layer", "(", "\n", "logit", "=", "curr_hidden_nn_layer", ",", "activation", "=", "activation", ",", "layer_idx", "=", "idx", "\n", ")", "\n", "hidden_nn_layers", ".", "append", "(", "curr_hidden_nn_layer", ")", "\n", "layer_idx", "+=", "1", "\n", "last_layer_size", "=", "layer_size", "\n", "self", ".", "layer_params", ".", "append", "(", "curr_w_nn_layer", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "curr_b_nn_layer", ")", "\n", "\n", "", "w_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_output\"", ",", "shape", "=", "[", "last_layer_size", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "b_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_output\"", ",", "\n", "shape", "=", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"nn_part/\"", "+", "\"w_nn_output\"", "+", "str", "(", "layer_idx", ")", ",", "w_nn_output", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"nn_part/\"", "+", "\"b_nn_output\"", "+", "str", "(", "layer_idx", ")", ",", "b_nn_output", "\n", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "w_nn_output", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "b_nn_output", ")", "\n", "nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "hidden_nn_layers", "[", "-", "1", "]", ",", "w_nn_output", ",", "b_nn_output", "\n", ")", "\n", "return", "nn_output", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN.__init__": [[22, 79], ["tensorflow.Graph", "recommenders.models.deeprec.models.base_model.BaseModel.__init__", "dkn.DKN.graph.as_default", "tensorflow.compat.v1.name_scope", "dkn.DKN._init_embedding", "tensorflow.Variable", "dkn.DKN._init_embedding", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.nn.tanh", "tensorflow.Variable", "dkn.DKN._init_embedding", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.nn.tanh", "tensorflow.Variable", "tensorflow.random.uniform", "tensorflow.zeros", "tensorflow.constant", "tensorflow.random.uniform", "tensorflow.zeros", "tensorflow.constant", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ")", ":", "\n", "        ", "\"\"\"Initialization steps for DKN.\n        Compared with the BaseModel, DKN requires two different pre-computed embeddings,\n        i.e. word embedding and entity embedding.\n        After creating these two embedding variables, BaseModel's `__init__` method will be called.\n\n        Args:\n            hparams (object): Global hyper-parameters.\n            iterator_creator (object): DKN data loader class.\n        \"\"\"", "\n", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"embedding\"", ")", ":", "\n", "                ", "word2vec_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "wordEmb_file", ")", "\n", "self", ".", "embedding", "=", "tf", ".", "Variable", "(", "\n", "word2vec_embedding", ",", "trainable", "=", "True", ",", "name", "=", "\"word\"", "\n", ")", "\n", "\n", "if", "hparams", ".", "use_entity", ":", "\n", "                    ", "e_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "entityEmb_file", ")", "\n", "W", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "hparams", ".", "entity_dim", ",", "hparams", ".", "dim", "]", ",", "-", "1", ",", "1", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "hparams", ".", "dim", "]", ")", ",", "trainable", "=", "True", ")", "\n", "self", ".", "entity_embedding", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "matmul", "(", "e_embedding", ",", "W", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "entity_embedding", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "constant", "(", "\n", "0.0", ",", "\n", "shape", "=", "[", "hparams", ".", "entity_size", ",", "hparams", ".", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"entity\"", ",", "\n", ")", "\n", "\n", "", "if", "hparams", ".", "use_context", ":", "\n", "                    ", "c_embedding", "=", "self", ".", "_init_embedding", "(", "hparams", ".", "contextEmb_file", ")", "\n", "W", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "hparams", ".", "entity_dim", ",", "hparams", ".", "dim", "]", ",", "-", "1", ",", "1", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "hparams", ".", "dim", "]", ")", ",", "trainable", "=", "True", ")", "\n", "self", ".", "context_embedding", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "matmul", "(", "c_embedding", ",", "W", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "context_embedding", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "constant", "(", "\n", "0.0", ",", "\n", "shape", "=", "[", "hparams", ".", "entity_size", ",", "hparams", ".", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"context\"", ",", "\n", ")", "\n", "\n", "", "", "", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "graph", "=", "self", ".", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._init_embedding": [[80, 90], ["tensorflow.constant", "numpy.load().astype", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "_init_embedding", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"Load pre-trained embeddings as a constant tensor.\n\n        Args:\n            file_path (str): the pre-trained embeddings filename.\n\n        Returns:\n            object: A constant tensor.\n        \"\"\"", "\n", "return", "tf", ".", "constant", "(", "np", ".", "load", "(", "file_path", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._l2_loss": [[91, 114], ["tensorflow.zeros", "tensorflow.add", "tensorflow.multiply", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.nn.l2_loss", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss"], "methods", ["None"], ["", "def", "_l2_loss", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "self", ".", "hparams", "\n", "l2_loss", "=", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# embedding_layer l2 loss", "\n", "l2_loss", "=", "tf", ".", "add", "(", "\n", "l2_loss", ",", "tf", ".", "multiply", "(", "hparams", ".", "embed_l2", ",", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "embedding", ")", ")", "\n", ")", "\n", "if", "hparams", ".", "use_entity", ":", "\n", "            ", "l2_loss", "=", "tf", ".", "add", "(", "\n", "l2_loss", ",", "\n", "tf", ".", "multiply", "(", "hparams", ".", "embed_l2", ",", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "entity_embedding", ")", ")", ",", "\n", ")", "\n", "", "if", "hparams", ".", "use_entity", "and", "hparams", ".", "use_context", ":", "\n", "            ", "l2_loss", "=", "tf", ".", "add", "(", "\n", "l2_loss", ",", "\n", "tf", ".", "multiply", "(", "hparams", ".", "embed_l2", ",", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "context_embedding", ")", ")", ",", "\n", ")", "\n", "", "params", "=", "self", ".", "layer_params", "\n", "for", "param", "in", "params", ":", "\n", "            ", "l2_loss", "=", "tf", ".", "add", "(", "\n", "l2_loss", ",", "tf", ".", "multiply", "(", "hparams", ".", "layer_l2", ",", "tf", ".", "nn", ".", "l2_loss", "(", "param", ")", ")", "\n", ")", "\n", "", "return", "l2_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._l1_loss": [[115, 143], ["tensorflow.zeros", "tensorflow.add", "tensorflow.multiply", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.norm", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.norm", "tensorflow.norm", "tensorflow.norm"], "methods", ["None"], ["", "def", "_l1_loss", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "self", ".", "hparams", "\n", "l1_loss", "=", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# embedding_layer l2 loss", "\n", "l1_loss", "=", "tf", ".", "add", "(", "\n", "l1_loss", ",", "\n", "tf", ".", "multiply", "(", "hparams", ".", "embed_l1", ",", "tf", ".", "norm", "(", "tensor", "=", "self", ".", "embedding", ",", "ord", "=", "1", ")", ")", ",", "\n", ")", "\n", "if", "hparams", ".", "use_entity", ":", "\n", "            ", "l1_loss", "=", "tf", ".", "add", "(", "\n", "l1_loss", ",", "\n", "tf", ".", "multiply", "(", "\n", "hparams", ".", "embed_l1", ",", "tf", ".", "norm", "(", "tensor", "=", "self", ".", "entity_embedding", ",", "ord", "=", "1", ")", "\n", ")", ",", "\n", ")", "\n", "", "if", "hparams", ".", "use_entity", "and", "hparams", ".", "use_context", ":", "\n", "            ", "l1_loss", "=", "tf", ".", "add", "(", "\n", "l1_loss", ",", "\n", "tf", ".", "multiply", "(", "\n", "hparams", ".", "embed_l1", ",", "tf", ".", "norm", "(", "tensor", "=", "self", ".", "context_embedding", ",", "ord", "=", "1", ")", "\n", ")", ",", "\n", ")", "\n", "", "params", "=", "self", ".", "layer_params", "\n", "for", "param", "in", "params", ":", "\n", "            ", "l1_loss", "=", "tf", ".", "add", "(", "\n", "l1_loss", ",", "tf", ".", "multiply", "(", "hparams", ".", "layer_l1", ",", "tf", ".", "norm", "(", "tensor", "=", "param", ",", "ord", "=", "1", ")", ")", "\n", ")", "\n", "", "return", "l1_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._build_graph": [[144, 151], ["numpy.ones_like", "numpy.array", "tensorflow.compat.v1.variable_scope", "dkn.DKN._build_dkn"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._build_dkn"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "self", ".", "hparams", "\n", "self", ".", "keep_prob_train", "=", "1", "-", "np", ".", "array", "(", "hparams", ".", "dropout", ")", "\n", "self", ".", "keep_prob_test", "=", "np", ".", "ones_like", "(", "hparams", ".", "dropout", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"DKN\"", ")", ":", "\n", "            ", "logit", "=", "self", ".", "_build_dkn", "(", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._build_dkn": [[152, 222], ["dkn.DKN._build_pair_attention", "tensorflow.concat", "hidden_nn_layers.append", "tensorflow.compat.v1.variable_scope", "enumerate", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.nn.xw_plus_b", "dkn.DKN._active_layer", "hidden_nn_layers.append", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "tensorflow.compat.v1.layers.batch_normalization", "str", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._build_pair_attention", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._active_layer"], ["", "", "def", "_build_dkn", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create DKN's logic.\n\n        Returns:\n            object: Prediction score made by the DKN model.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "# build attention model for clicked news and candidate news", "\n", "click_news_embed_batch", ",", "candidate_news_embed_batch", "=", "self", ".", "_build_pair_attention", "(", "\n", "self", ".", "iterator", ".", "candidate_news_index_batch", ",", "\n", "self", ".", "iterator", ".", "candidate_news_entity_index_batch", ",", "\n", "self", ".", "iterator", ".", "click_news_index_batch", ",", "\n", "self", ".", "iterator", ".", "click_news_entity_index_batch", ",", "\n", "hparams", ",", "\n", ")", "\n", "\n", "nn_input", "=", "tf", ".", "concat", "(", "\n", "[", "click_news_embed_batch", ",", "candidate_news_embed_batch", "]", ",", "axis", "=", "1", "\n", ")", "\n", "\n", "dnn_channel_part", "=", "2", "\n", "last_layer_size", "=", "dnn_channel_part", "*", "self", ".", "num_filters_total", "\n", "layer_idx", "=", "0", "\n", "hidden_nn_layers", "=", "[", "]", "\n", "hidden_nn_layers", ".", "append", "(", "nn_input", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"nn_part\"", ",", "initializer", "=", "self", ".", "initializer", ")", ":", "\n", "            ", "for", "idx", ",", "layer_size", "in", "enumerate", "(", "hparams", ".", "layer_sizes", ")", ":", "\n", "                ", "curr_w_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "\n", "shape", "=", "[", "last_layer_size", ",", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "curr_b_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_layer\"", "+", "str", "(", "layer_idx", ")", ",", "\n", "shape", "=", "[", "layer_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "curr_hidden_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "hidden_nn_layers", "[", "layer_idx", "]", ",", "curr_w_nn_layer", ",", "curr_b_nn_layer", "\n", ")", "\n", "if", "hparams", ".", "enable_BN", "is", "True", ":", "\n", "                    ", "curr_hidden_nn_layer", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "batch_normalization", "(", "\n", "curr_hidden_nn_layer", ",", "\n", "momentum", "=", "0.95", ",", "\n", "epsilon", "=", "0.0001", ",", "\n", "training", "=", "self", ".", "is_train_stage", ",", "\n", ")", "\n", "\n", "", "activation", "=", "hparams", ".", "activation", "[", "idx", "]", "\n", "curr_hidden_nn_layer", "=", "self", ".", "_active_layer", "(", "\n", "logit", "=", "curr_hidden_nn_layer", ",", "activation", "=", "activation", "\n", ")", "\n", "hidden_nn_layers", ".", "append", "(", "curr_hidden_nn_layer", ")", "\n", "layer_idx", "+=", "1", "\n", "last_layer_size", "=", "layer_size", "\n", "self", ".", "layer_params", ".", "append", "(", "curr_w_nn_layer", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "curr_b_nn_layer", ")", "\n", "\n", "", "w_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"w_nn_output\"", ",", "shape", "=", "[", "last_layer_size", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "b_nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b_nn_output\"", ",", "shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "w_nn_output", ")", "\n", "self", ".", "layer_params", ".", "append", "(", "b_nn_output", ")", "\n", "nn_output", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "hidden_nn_layers", "[", "-", "1", "]", ",", "w_nn_output", ",", "b_nn_output", "\n", ")", "\n", "return", "nn_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._build_pair_attention": [[223, 348], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.compat.v1.variable_scope", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.compat.v1.variable_scope", "dkn.DKN._kims_cnn", "dkn.DKN._kims_cnn", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.add", "tensorflow.concat", "tensorflow.reshape", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.nn.xw_plus_b", "dkn.DKN._active_layer", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.reshape", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.zeros_like", "tensorflow.compat.v1.layers.batch_normalization", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "tensorflow.multiply", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._kims_cnn", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._kims_cnn", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._active_layer"], ["", "", "def", "_build_pair_attention", "(", "\n", "self", ",", "\n", "candidate_word_batch", ",", "\n", "candidate_entity_batch", ",", "\n", "click_word_batch", ",", "\n", "click_entity_batch", ",", "\n", "hparams", ",", "\n", ")", ":", "\n", "        ", "\"\"\"This function learns the candidate news article's embedding and user embedding.\n        User embedding is generated from click history and also depends on the candidate news article via attention mechanism.\n        Article embedding is generated via KCNN module.\n        Args:\n            candidate_word_batch (object): tensor word indices for constructing news article\n            candidate_entity_batch (object): tensor entity values for constructing news article\n            click_word_batch (object): tensor word indices for constructing user clicked history\n            click_entity_batch (object): tensor entity indices for constructing user clicked history\n            hparams (object): global hyper-parameters\n        Returns:\n            click_field_embed_final_batch: user embedding\n            news_field_embed_final_batch: candidate news article embedding\n\n        \"\"\"", "\n", "doc_size", "=", "hparams", ".", "doc_size", "\n", "attention_hidden_sizes", "=", "hparams", ".", "attention_layer_sizes", "\n", "\n", "clicked_words", "=", "tf", ".", "reshape", "(", "click_word_batch", ",", "shape", "=", "[", "-", "1", ",", "doc_size", "]", ")", "\n", "clicked_entities", "=", "tf", ".", "reshape", "(", "click_entity_batch", ",", "shape", "=", "[", "-", "1", ",", "doc_size", "]", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"attention_net\"", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", "as", "scope", ":", "# noqa: F841", "\n", "\n", "# use kims cnn to get conv embedding", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"kcnn\"", ",", "initializer", "=", "self", ".", "initializer", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", "\n", ")", "as", "cnn_scope", ":", "# noqa: F841", "\n", "                ", "news_field_embed", "=", "self", ".", "_kims_cnn", "(", "\n", "candidate_word_batch", ",", "candidate_entity_batch", ",", "hparams", "\n", ")", "\n", "click_field_embed", "=", "self", ".", "_kims_cnn", "(", "\n", "clicked_words", ",", "clicked_entities", ",", "hparams", "\n", ")", "\n", "click_field_embed", "=", "tf", ".", "reshape", "(", "\n", "click_field_embed", ",", "\n", "shape", "=", "[", "\n", "-", "1", ",", "\n", "hparams", ".", "history_size", ",", "\n", "hparams", ".", "num_filters", "*", "len", "(", "hparams", ".", "filter_sizes", ")", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "", "avg_strategy", "=", "False", "\n", "if", "avg_strategy", ":", "\n", "                ", "click_field_embed_final", "=", "tf", ".", "reduce_mean", "(", "\n", "input_tensor", "=", "click_field_embed", ",", "axis", "=", "1", ",", "keepdims", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "                ", "news_field_embed", "=", "tf", ".", "expand_dims", "(", "news_field_embed", ",", "1", ")", "\n", "news_field_embed_repeat", "=", "tf", ".", "add", "(", "\n", "tf", ".", "zeros_like", "(", "click_field_embed", ")", ",", "news_field_embed", "\n", ")", "\n", "attention_x", "=", "tf", ".", "concat", "(", "\n", "axis", "=", "-", "1", ",", "values", "=", "[", "click_field_embed", ",", "news_field_embed_repeat", "]", "\n", ")", "\n", "attention_x", "=", "tf", ".", "reshape", "(", "\n", "attention_x", ",", "shape", "=", "[", "-", "1", ",", "self", ".", "num_filters_total", "*", "2", "]", "\n", ")", "\n", "attention_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"attention_hidden_w\"", ",", "\n", "shape", "=", "[", "self", ".", "num_filters_total", "*", "2", ",", "attention_hidden_sizes", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "attention_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"attention_hidden_b\"", ",", "\n", "shape", "=", "[", "attention_hidden_sizes", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "curr_attention_layer", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "attention_x", ",", "attention_w", ",", "attention_b", "\n", ")", "\n", "\n", "if", "hparams", ".", "enable_BN", "is", "True", ":", "\n", "                    ", "curr_attention_layer", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "batch_normalization", "(", "\n", "curr_attention_layer", ",", "\n", "momentum", "=", "0.95", ",", "\n", "epsilon", "=", "0.0001", ",", "\n", "training", "=", "self", ".", "is_train_stage", ",", "\n", ")", "\n", "\n", "", "activation", "=", "hparams", ".", "attention_activation", "\n", "curr_attention_layer", "=", "self", ".", "_active_layer", "(", "\n", "logit", "=", "curr_attention_layer", ",", "activation", "=", "activation", "\n", ")", "\n", "attention_output_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"attention_output_w\"", ",", "\n", "shape", "=", "[", "attention_hidden_sizes", ",", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "attention_output_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"attention_output_b\"", ",", "shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "attention_weight", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "curr_attention_layer", ",", "attention_output_w", ",", "attention_output_b", "\n", ")", "\n", "attention_weight", "=", "tf", ".", "reshape", "(", "\n", "attention_weight", ",", "shape", "=", "[", "-", "1", ",", "hparams", ".", "history_size", ",", "1", "]", "\n", ")", "\n", "norm_attention_weight", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_weight", ",", "axis", "=", "1", ")", "\n", "click_field_embed_final", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "multiply", "(", "click_field_embed", ",", "norm_attention_weight", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "True", ",", "\n", ")", "\n", "if", "attention_w", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "attention_w", ")", "\n", "", "if", "attention_b", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "attention_b", ")", "\n", "", "if", "attention_output_w", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "attention_output_w", ")", "\n", "", "if", "attention_output_b", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "attention_output_b", ")", "\n", "", "", "self", ".", "news_field_embed_final_batch", "=", "tf", ".", "squeeze", "(", "news_field_embed", ")", "\n", "click_field_embed_final_batch", "=", "tf", ".", "squeeze", "(", "click_field_embed_final", ")", "\n", "\n", "", "return", "click_field_embed_final_batch", ",", "self", ".", "news_field_embed_final_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._kims_cnn": [[349, 441], ["tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "enumerate", "tensorflow.concat", "tensorflow.reshape", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.concat", "len", "tensorflow.nn.embedding_lookup", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.conv2d", "tensorflow.nn.relu", "tensorflow.nn.max_pool2d", "pooled_outputs.append", "dkn.DKN.layer_params.append", "dkn.DKN.layer_params.append", "tensorflow.nn.bias_add", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "str", "str"], "methods", ["None"], ["", "def", "_kims_cnn", "(", "self", ",", "word", ",", "entity", ",", "hparams", ")", ":", "\n", "        ", "\"\"\"The KCNN module. KCNN is an extension of traditional CNN that incorporates symbolic knowledge from\n        a knowledge graph into sentence representation learning.\n        Args:\n            word (object): word indices for the sentence.\n            entity (object): entity indices for the sentence. Entities are aligned with words in the sentence.\n            hparams (object): global hyper-parameters.\n\n        Returns:\n            object: Sentence representation.\n        \"\"\"", "\n", "# kims cnn parameter", "\n", "filter_sizes", "=", "hparams", ".", "filter_sizes", "\n", "num_filters", "=", "hparams", ".", "num_filters", "\n", "\n", "dim", "=", "hparams", ".", "dim", "\n", "embedded_chars", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "embedding", ",", "ids", "=", "word", ")", "\n", "if", "hparams", ".", "use_entity", "and", "hparams", ".", "use_context", ":", "\n", "            ", "entity_embedded_chars", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "entity_embedding", ",", "ids", "=", "entity", "\n", ")", "\n", "context_embedded_chars", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "context_embedding", ",", "ids", "=", "entity", "\n", ")", "\n", "concat", "=", "tf", ".", "concat", "(", "\n", "[", "embedded_chars", ",", "entity_embedded_chars", ",", "context_embedded_chars", "]", ",", "axis", "=", "-", "1", "\n", ")", "\n", "", "elif", "hparams", ".", "use_entity", ":", "\n", "            ", "entity_embedded_chars", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "entity_embedding", ",", "ids", "=", "entity", "\n", ")", "\n", "concat", "=", "tf", ".", "concat", "(", "[", "embedded_chars", ",", "entity_embedded_chars", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "concat", "=", "embedded_chars", "\n", "", "concat_expanded", "=", "tf", ".", "expand_dims", "(", "concat", ",", "-", "1", ")", "\n", "\n", "# Create a convolution + maxpool layer for each filter size", "\n", "pooled_outputs", "=", "[", "]", "\n", "for", "i", ",", "filter_size", "in", "enumerate", "(", "filter_sizes", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\n", "\"conv-maxpool-%s\"", "%", "filter_size", ",", "initializer", "=", "self", ".", "initializer", "\n", ")", ":", "\n", "# Convolution Layer", "\n", "                ", "if", "hparams", ".", "use_entity", "and", "hparams", ".", "use_context", ":", "\n", "                    ", "filter_shape", "=", "[", "filter_size", ",", "dim", "*", "3", ",", "1", ",", "num_filters", "]", "\n", "", "elif", "hparams", ".", "use_entity", ":", "\n", "                    ", "filter_shape", "=", "[", "filter_size", ",", "dim", "*", "2", ",", "1", ",", "num_filters", "]", "\n", "", "else", ":", "\n", "                    ", "filter_shape", "=", "[", "filter_size", ",", "dim", ",", "1", ",", "num_filters", "]", "\n", "", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"W\"", "+", "\"_filter_size_\"", "+", "str", "(", "filter_size", ")", ",", "\n", "shape", "=", "filter_shape", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "(", "\"uniform\"", "if", "False", "else", "\"truncated_normal\"", ")", ",", "\n", ")", ",", "\n", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"b\"", "+", "\"_filter_size_\"", "+", "str", "(", "filter_size", ")", ",", "\n", "shape", "=", "[", "num_filters", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "if", "W", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "W", ")", "\n", "", "if", "b", "not", "in", "self", ".", "layer_params", ":", "\n", "                    ", "self", ".", "layer_params", ".", "append", "(", "b", ")", "\n", "", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "\n", "input", "=", "concat_expanded", ",", "\n", "filters", "=", "W", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", "name", "=", "\"conv\"", ",", "\n", ")", "\n", "# Apply nonlinearity", "\n", "h", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "b", ")", ",", "name", "=", "\"relu\"", ")", "\n", "# Maxpooling over the outputs", "\n", "pooled", "=", "tf", ".", "nn", ".", "max_pool2d", "(", "\n", "h", ",", "\n", "ksize", "=", "[", "1", ",", "hparams", ".", "doc_size", "-", "filter_size", "+", "1", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", "name", "=", "\"pool\"", ",", "\n", ")", "\n", "pooled_outputs", ".", "append", "(", "pooled", ")", "\n", "# Combine all the pooled features", "\n", "# self.num_filters_total is the kims cnn output dimension", "\n", "", "", "self", ".", "num_filters_total", "=", "num_filters", "*", "len", "(", "filter_sizes", ")", "\n", "h_pool", "=", "tf", ".", "concat", "(", "pooled_outputs", ",", "axis", "=", "-", "1", ")", "\n", "h_pool_flat", "=", "tf", ".", "reshape", "(", "h_pool", ",", "[", "-", "1", ",", "self", ".", "num_filters_total", "]", ")", "\n", "return", "h_pool_flat", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN.infer_embedding": [[442, 455], ["sess.run"], "methods", ["None"], ["", "def", "infer_embedding", "(", "self", ",", "sess", ",", "feed_dict", ")", ":", "\n", "        ", "\"\"\"Infer document embedding in feed_dict with current model.\n\n        Args:\n            sess (object): The model session object.\n            feed_dict (dict): Feed values for evaluation. This is a dictionary that maps graph elements to values.\n\n        Returns:\n            list: News embedding in a batch.\n        \"\"\"", "\n", "feed_dict", "[", "self", ".", "layer_keeps", "]", "=", "self", ".", "keep_prob_test", "\n", "feed_dict", "[", "self", ".", "is_train_stage", "]", "=", "False", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "news_field_embed_final_batch", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN.run_get_embedding": [[456, 487], ["tensorflow.io.gfile.GFile", "dkn.DKN.iterator.load_infer_data_from_file", "range", "dkn.DKN.infer_embedding", "wt.write", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.load_infer_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.infer_embedding"], ["", "def", "run_get_embedding", "(", "self", ",", "infile_name", ",", "outfile_name", ")", ":", "\n", "        ", "\"\"\"infer document embedding with current model.\n\n        Args:\n            infile_name (str): Input file name, format is [Newsid] [w1,w2,w3...] [e1,e2,e3...]\n            outfile_name (str): Output file name, format is [Newsid] [embedding]\n\n        Returns:\n            object: An instance of self.\n        \"\"\"", "\n", "load_sess", "=", "self", ".", "sess", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "outfile_name", ",", "\"w\"", ")", "as", "wt", ":", "\n", "            ", "for", "(", "\n", "batch_data_input", ",", "\n", "newsid_list", ",", "\n", "data_size", ",", "\n", ")", "in", "self", ".", "iterator", ".", "load_infer_data_from_file", "(", "infile_name", ")", ":", "\n", "                ", "news_embedding", "=", "self", ".", "infer_embedding", "(", "load_sess", ",", "batch_data_input", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "data_size", ")", ":", "\n", "                    ", "wt", ".", "write", "(", "\n", "newsid_list", "[", "i", "]", "\n", "+", "\" \"", "\n", "+", "\",\"", ".", "join", "(", "\n", "[", "\n", "str", "(", "embedding_value", ")", "\n", "for", "embedding_value", "in", "news_embedding", "[", "i", "]", "\n", "]", "\n", ")", "\n", "+", "\"\\n\"", "\n", ")", "\n", "", "", "", "return", "self", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._compute_data_loss": [[21, 25], ["tensorflow.reduce_sum", "tensorflow.math.log"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["def", "_compute_data_loss", "(", "self", ")", ":", "\n", "        ", "logits", "=", "self", ".", "pred", "\n", "data_loss", "=", "-", "1", "*", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "math", ".", "log", "(", "logits", "[", ":", ",", "0", "]", "+", "1e-10", ")", ")", "\n", "return", "data_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._build_dkn": [[26, 63], ["dkn_item2item.DKNItem2Item._build_doc_embedding", "tensorflow.math.l2_normalize", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.math.multiply", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._build_doc_embedding"], ["", "def", "_build_dkn", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create DKN's logic.\n\n        Returns:\n            object: Prediction of item2item relation scores made by the DKN model, in the shape of (`batch_size`, `num_negative` + 1).\n        \"\"\"", "\n", "news_field_embed_final_batch", "=", "self", ".", "_build_doc_embedding", "(", "\n", "self", ".", "iterator", ".", "candidate_news_index_batch", ",", "\n", "self", ".", "iterator", ".", "candidate_news_entity_index_batch", ",", "\n", ")", "\n", "\n", "self", ".", "news_field_embed_final_batch", "=", "tf", ".", "math", ".", "l2_normalize", "(", "\n", "news_field_embed_final_batch", ",", "axis", "=", "-", "1", ",", "epsilon", "=", "1e-12", "\n", ")", "\n", "\n", "item_embs_train", "=", "tf", ".", "reshape", "(", "\n", "self", ".", "news_field_embed_final_batch", ",", "\n", "[", "\n", "-", "1", ",", "\n", "self", ".", "iterator", ".", "neg_num", "+", "2", ",", "\n", "self", ".", "news_field_embed_final_batch", ".", "shape", "[", "-", "1", "]", ",", "\n", "]", ",", "\n", ")", "# (B, group, D)", "\n", "\n", "item_embs_source", "=", "item_embs_train", "[", ":", ",", "0", ",", ":", "]", "# get the source item", "\n", "item_embs_source", "=", "tf", ".", "expand_dims", "(", "item_embs_source", ",", "1", ")", "\n", "\n", "item_embs_target", "=", "item_embs_train", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "item_relation", "=", "tf", ".", "math", ".", "multiply", "(", "item_embs_target", ",", "item_embs_source", ")", "\n", "item_relation", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "item_relation", ",", "axis", "=", "-", "1", "\n", ")", "# (B, neg_num + 1)", "\n", "\n", "self", ".", "pred_logits", "=", "item_relation", "\n", "\n", "return", "self", ".", "pred_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._get_pred": [[64, 66], ["tensorflow.nn.softmax"], "methods", ["None"], ["", "def", "_get_pred", "(", "self", ",", "logit", ",", "task", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "softmax", "(", "logit", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item._build_doc_embedding": [[67, 89], ["tensorflow.compat.v1.variable_scope", "dkn_item2item.DKNItem2Item._kims_cnn", "tensorflow.compat.v1.get_variable", "tensorflow.tanh", "dkn_item2item.DKNItem2Item.layer_params.append", "tensorflow.matmul", "tensorflow.compat.v1.keras.initializers.VarianceScaling"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn.DKN._kims_cnn"], ["", "def", "_build_doc_embedding", "(", "self", ",", "candidate_word_batch", ",", "candidate_entity_batch", ")", ":", "\n", "        ", "\"\"\"\n        To make the document embedding be dense, we add one tanh layer on top of the `kims_cnn` module.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"kcnn\"", ",", "initializer", "=", "self", ".", "initializer", ")", ":", "\n", "            ", "news_field_embed", "=", "self", ".", "_kims_cnn", "(", "\n", "candidate_word_batch", ",", "candidate_entity_batch", ",", "self", ".", "hparams", "\n", ")", "\n", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"W_doc_trans\"", ",", "\n", "shape", "=", "(", "news_field_embed", ".", "shape", "[", "-", "1", "]", ",", "self", ".", "num_filters_total", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "(", "\"uniform\"", "if", "False", "else", "\"truncated_normal\"", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "W", "not", "in", "self", ".", "layer_params", ":", "\n", "                ", "self", ".", "layer_params", ".", "append", "(", "W", ")", "\n", "", "news_field_embed", "=", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "news_field_embed", ",", "W", ")", ")", "\n", "", "return", "news_field_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval": [[90, 106], ["sess.run", "numpy.zeros_like"], "methods", ["None"], ["", "def", "eval", "(", "self", ",", "sess", ",", "feed_dict", ")", ":", "\n", "        ", "\"\"\"Evaluate the data in `feed_dict` with current model.\n\n        Args:\n            sess (object): The model session object.\n            feed_dict (dict): Feed values for evaluation. This is a dictionary that maps graph elements to values.\n\n        Returns:\n            numpy.ndarray, numpy.ndarray: A tuple with predictions and labels arrays.\n        \"\"\"", "\n", "feed_dict", "[", "self", ".", "layer_keeps", "]", "=", "self", ".", "keep_prob_test", "\n", "feed_dict", "[", "self", ".", "is_train_stage", "]", "=", "False", "\n", "preds", "=", "sess", ".", "run", "(", "self", ".", "pred", ",", "feed_dict", "=", "feed_dict", ")", "\n", "labels", "=", "np", ".", "zeros_like", "(", "preds", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "labels", "[", ":", ",", "0", "]", "=", "1", "\n", "return", "(", "preds", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.run_eval": [[107, 132], ["dkn_item2item.DKNItem2Item.iterator.load_data_from_file", "recommenders.models.deeprec.deeprec_utils.cal_metric", "dkn_item2item.DKNItem2Item.eval", "group_preds.extend", "group_labels.extend"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "run_eval", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Evaluate the given file and returns some evaluation metrics.\n\n        Args:\n            filename (str): A file name that will be evaluated.\n\n        Returns:\n            dict: A dictionary containing evaluation metrics.\n        \"\"\"", "\n", "load_sess", "=", "self", ".", "sess", "\n", "group_preds", "=", "[", "]", "\n", "group_labels", "=", "[", "]", "\n", "\n", "for", "(", "\n", "batch_data_input", ",", "\n", "newsid_list", ",", "\n", "data_size", ",", "\n", ")", "in", "self", ".", "iterator", ".", "load_data_from_file", "(", "filename", ")", ":", "\n", "            ", "if", "batch_data_input", ":", "\n", "                ", "step_pred", ",", "step_labels", "=", "self", ".", "eval", "(", "load_sess", ",", "batch_data_input", ")", "\n", "group_preds", ".", "extend", "(", "step_pred", ")", "\n", "group_labels", ".", "extend", "(", "step_labels", ")", "\n", "\n", "", "", "res", "=", "cal_metric", "(", "group_labels", ",", "group_preds", ",", "self", ".", "hparams", ".", "pairwise_metrics", ")", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._add_summaries": [[114, 120], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge_all"], "methods", ["None"], ["\n", "", "def", "_get_opt", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the optimizer according to configuration. Usually we will use Adam.\n        Returns:\n            object: An optimizer.\n        \"\"\"", "\n", "lr", "=", "self", ".", "hparams", ".", "learning_rate", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._l2_loss": [[121, 134], ["tensorflow.zeros", "tensorflow.add", "tensorflow.add", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss"], "methods", ["None"], ["optimizer", "=", "self", ".", "hparams", ".", "optimizer", "\n", "\n", "if", "optimizer", "==", "\"adam\"", ":", "\n", "            ", "train_opt", "=", "keras", ".", "optimizers", ".", "Adam", "(", "lr", "=", "lr", ")", "\n", "\n", "", "return", "train_opt", "\n", "\n", "", "def", "_get_pred", "(", "self", ",", "logit", ",", "task", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._l1_loss": [[135, 150], ["tensorflow.zeros", "tensorflow.add", "tensorflow.add", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.norm", "tensorflow.norm"], "methods", ["None"], ["\n", "if", "task", "==", "\"regression\"", ":", "\n", "            ", "pred", "=", "tf", ".", "identity", "(", "logit", ")", "\n", "", "elif", "task", "==", "\"classification\"", ":", "\n", "            ", "pred", "=", "tf", ".", "sigmoid", "(", "logit", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"method must be regression or classification, but now is {0}\"", ".", "format", "(", "\n", "task", "\n", ")", "\n", ")", "\n", "", "return", "pred", "\n", "\n", "", "def", "train", "(", "self", ",", "train_batch_data", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._cross_l_loss": [[151, 168], ["tensorflow.zeros", "tensorflow.add", "tensorflow.add", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.norm", "tensorflow.norm"], "methods", ["None"], ["        ", "\"\"\"Go through the optimization step once with training data in feed_dict.\n\n        Args:\n            sess (object): The model session object.\n            feed_dict (dict): Feed values to train the model. This is a dictionary that maps graph elements to values.\n\n        Returns:\n            list: A list of values, including update operation, total loss, data loss, and merged summary.\n        \"\"\"", "\n", "train_input", ",", "train_label", "=", "self", ".", "_get_input_label_from_iter", "(", "train_batch_data", ")", "\n", "rslt", "=", "self", ".", "model", ".", "train_on_batch", "(", "train_input", ",", "train_label", ")", "\n", "return", "rslt", "\n", "\n", "", "def", "eval", "(", "self", ",", "eval_batch_data", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._get_initializer": [[169, 213], ["tensorflow.compat.v1.truncated_normal_initializer", "tensorflow.compat.v1.random_uniform_initializer", "tensorflow.compat.v1.random_normal_initializer", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.truncated_normal_initializer"], "methods", ["None"], ["\n", "eval_input", ",", "eval_label", "=", "self", ".", "_get_input_label_from_iter", "(", "eval_batch_data", ")", "\n", "imp_index", "=", "eval_batch_data", "[", "\"impression_index_batch\"", "]", "\n", "\n", "pred_rslt", "=", "self", ".", "scorer", ".", "predict_on_batch", "(", "eval_input", ")", "\n", "\n", "return", "pred_rslt", ",", "eval_label", ",", "imp_index", "\n", "\n", "", "def", "fit", "(", "\n", "self", ",", "\n", "train_news_file", ",", "\n", "train_behaviors_file", ",", "\n", "valid_news_file", ",", "\n", "valid_behaviors_file", ",", "\n", "test_news_file", "=", "None", ",", "\n", "test_behaviors_file", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Fit the model with train_file. Evaluate the model on valid_file per epoch to observe the training status.\n        If test_news_file is not None, evaluate it too.\n\n        Args:\n            train_file (str): training data set.\n            valid_file (str): validation set.\n            test_news_file (str): test set.\n\n        Returns:\n            object: An instance of self.\n        \"\"\"", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "hparams", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "step", "=", "0", "\n", "self", ".", "hparams", ".", "current_epoch", "=", "epoch", "\n", "epoch_loss", "=", "0", "\n", "train_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "tqdm_util", "=", "tqdm", "(", "\n", "self", ".", "train_iterator", ".", "load_data_from_file", "(", "\n", "train_news_file", ",", "train_behaviors_file", "\n", ")", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._compute_data_loss": [[215, 263], ["tensorflow.reduce_mean", "tensorflow.sqrt", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.nn.softmax", "tensorflow.equal", "tensorflow.ones_like", "tensorflow.compat.v1.where", "ValueError", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.math.squared_difference", "tensorflow.compat.v1.losses.log_loss", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.ones_like", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.math.log", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["\n", "                ", "step_result", "=", "self", ".", "train", "(", "batch_data_input", ")", "\n", "step_data_loss", "=", "step_result", "\n", "\n", "epoch_loss", "+=", "step_data_loss", "\n", "step", "+=", "1", "\n", "if", "step", "%", "self", ".", "hparams", ".", "show_step", "==", "0", ":", "\n", "                    ", "tqdm_util", ".", "set_description", "(", "\n", "\"step {0:d} , total_loss: {1:.4f}, data_loss: {2:.4f}\"", ".", "format", "(", "\n", "step", ",", "epoch_loss", "/", "step", ",", "step_data_loss", "\n", ")", "\n", ")", "\n", "\n", "", "", "train_end", "=", "time", ".", "time", "(", ")", "\n", "train_time", "=", "train_end", "-", "train_start", "\n", "\n", "eval_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_info", "=", "\",\"", ".", "join", "(", "\n", "[", "\n", "str", "(", "item", "[", "0", "]", ")", "+", "\":\"", "+", "str", "(", "item", "[", "1", "]", ")", "\n", "for", "item", "in", "[", "(", "\"logloss loss\"", ",", "epoch_loss", "/", "step", ")", "]", "\n", "]", "\n", ")", "\n", "\n", "eval_res", "=", "self", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "\n", "eval_info", "=", "\", \"", ".", "join", "(", "\n", "[", "\n", "str", "(", "item", "[", "0", "]", ")", "+", "\":\"", "+", "str", "(", "item", "[", "1", "]", ")", "\n", "for", "item", "in", "sorted", "(", "eval_res", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "]", "\n", ")", "\n", "if", "test_news_file", "is", "not", "None", ":", "\n", "                ", "test_res", "=", "self", ".", "run_eval", "(", "test_news_file", ",", "test_behaviors_file", ")", "\n", "test_info", "=", "\", \"", ".", "join", "(", "\n", "[", "\n", "str", "(", "item", "[", "0", "]", ")", "+", "\":\"", "+", "str", "(", "item", "[", "1", "]", ")", "\n", "for", "item", "in", "sorted", "(", "test_res", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "]", "\n", ")", "\n", "", "eval_end", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end", "-", "eval_start", "\n", "\n", "if", "test_news_file", "is", "not", "None", ":", "\n", "                ", "print", "(", "\n", "\"at epoch {0:d}\"", ".", "format", "(", "epoch", ")", "\n", "+", "\"\\ntrain info: \"", "\n", "+", "train_info", "\n", "+", "\"\\neval info: \"", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._compute_regular_loss": [[264, 273], ["tensorflow.reduce_sum", "base_model.BaseModel._cross_l_loss", "base_model.BaseModel._l2_loss", "base_model.BaseModel._l1_loss"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._cross_l_loss", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._l2_loss", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._l1_loss"], ["+", "eval_info", "\n", "+", "\"\\ntest info: \"", "\n", "+", "test_info", "\n", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\n", "\"at epoch {0:d}\"", ".", "format", "(", "epoch", ")", "\n", "+", "\"\\ntrain info: \"", "\n", "+", "train_info", "\n", "+", "\"\\neval info: \"", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._train_opt": [[274, 304], ["tensorflow.compat.v1.train.AdadeltaOptimizer", "tensorflow.compat.v1.train.AdagradOptimizer", "tensorflow.compat.v1.train.GradientDescentOptimizer", "tensorflow.compat.v1.train.AdamOptimizer", "tensorflow.compat.v1.train.FtrlOptimizer", "tensorflow.compat.v1.train.GradientDescentOptimizer", "tensorflow.compat.v1.train.ProximalAdagradOptimizer", "tensorflow.compat.v1.train.ProximalGradientDescentOptimizer", "tensorflow.compat.v1.train.RMSPropOptimizer", "tensorflow.compat.v1.train.GradientDescentOptimizer"], "methods", ["None"], ["+", "eval_info", "\n", ")", "\n", "", "print", "(", "\n", "\"at epoch {0:d} , train time: {1:.1f} eval time: {2:.1f}\"", ".", "format", "(", "\n", "epoch", ",", "train_time", ",", "eval_time", "\n", ")", "\n", ")", "\n", "\n", "", "return", "self", "\n", "\n", "", "def", "group_labels", "(", "self", ",", "labels", ",", "preds", ",", "group_keys", ")", ":", "\n", "        ", "\"\"\"Devide labels and preds into several group according to values in group keys.\n\n        Args:\n            labels (list): ground truth label list.\n            preds (list): prediction score list.\n            group_keys (list): group key list.\n\n        Returns:\n            list, list, list:\n            - Keys after group.\n            - Labels after group.\n            - Preds after group.\n\n        \"\"\"", "\n", "\n", "all_keys", "=", "list", "(", "set", "(", "group_keys", ")", ")", "\n", "all_keys", ".", "sort", "(", ")", "\n", "group_labels", "=", "{", "k", ":", "[", "]", "for", "k", "in", "all_keys", "}", "\n", "group_preds", "=", "{", "k", ":", "[", "]", "for", "k", "in", "all_keys", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._build_train_opt": [[305, 323], ["base_model.BaseModel._train_opt", "zip", "base_model.BaseModel.apply_gradients", "zip", "base_model.BaseModel.compute_gradients", "tensorflow.clip_by_norm"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._train_opt"], ["for", "label", ",", "p", ",", "k", "in", "zip", "(", "labels", ",", "preds", ",", "group_keys", ")", ":", "\n", "            ", "group_labels", "[", "k", "]", ".", "append", "(", "label", ")", "\n", "group_preds", "[", "k", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "all_labels", "=", "[", "]", "\n", "all_preds", "=", "[", "]", "\n", "for", "k", "in", "all_keys", ":", "\n", "            ", "all_labels", ".", "append", "(", "group_labels", "[", "k", "]", ")", "\n", "all_preds", ".", "append", "(", "group_preds", "[", "k", "]", ")", "\n", "\n", "", "return", "all_keys", ",", "all_labels", ",", "all_preds", "\n", "\n", "", "def", "run_eval", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._active_layer": [[324, 338], ["base_model.BaseModel._activate", "base_model.BaseModel._dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._activate", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._dropout"], ["\n", "\n", "if", "self", ".", "support_quick_scoring", ":", "\n", "            ", "_", ",", "group_labels", ",", "group_preds", "=", "self", ".", "run_fast_eval", "(", "\n", "news_filename", ",", "behaviors_file", "\n", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "group_labels", ",", "group_preds", "=", "self", ".", "run_slow_eval", "(", "\n", "news_filename", ",", "behaviors_file", "\n", ")", "\n", "", "res", "=", "cal_metric", "(", "group_labels", ",", "group_preds", ",", "self", ".", "hparams", ".", "metrics", ")", "\n", "return", "res", "\n", "\n", "", "def", "user", "(", "self", ",", "batch_user_input", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._activate": [[339, 354], ["tensorflow.nn.sigmoid", "tensorflow.nn.softmax", "tensorflow.nn.relu", "tensorflow.nn.tanh", "tensorflow.nn.elu", "tensorflow.identity", "ValueError"], "methods", ["None"], ["        ", "user_input", "=", "self", ".", "_get_user_feature_from_iter", "(", "batch_user_input", ")", "\n", "user_vec", "=", "self", ".", "userencoder", ".", "predict_on_batch", "(", "user_input", ")", "\n", "user_index", "=", "batch_user_input", "[", "\"impr_index_batch\"", "]", "\n", "\n", "return", "user_index", ",", "user_vec", "\n", "\n", "", "def", "news", "(", "self", ",", "batch_news_input", ")", ":", "\n", "        ", "news_input", "=", "self", ".", "_get_news_feature_from_iter", "(", "batch_news_input", ")", "\n", "news_vec", "=", "self", ".", "newsencoder", ".", "predict_on_batch", "(", "news_input", ")", "\n", "news_index", "=", "batch_news_input", "[", "\"news_index_batch\"", "]", "\n", "\n", "return", "news_index", ",", "news_vec", "\n", "\n", "", "def", "run_user", "(", "self", ",", "news_filename", ",", "behaviors_file", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"userencoder\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"model must have attribute userencoder\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._dropout": [[355, 366], ["tensorflow.nn.dropout"], "methods", ["None"], ["\n", "", "user_indexes", "=", "[", "]", "\n", "user_vecs", "=", "[", "]", "\n", "for", "batch_data_input", "in", "tqdm", "(", "\n", "self", ".", "test_iterator", ".", "load_user_from_file", "(", "news_filename", ",", "behaviors_file", ")", "\n", ")", ":", "\n", "            ", "user_index", ",", "user_vec", "=", "self", ".", "user", "(", "batch_data_input", ")", "\n", "user_indexes", ".", "extend", "(", "np", ".", "reshape", "(", "user_index", ",", "-", "1", ")", ")", "\n", "user_vecs", ".", "extend", "(", "user_vec", ")", "\n", "\n", "", "return", "dict", "(", "zip", "(", "user_indexes", ",", "user_vecs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.infer": [[404, 417], ["sess.run"], "methods", ["None"], ["self", ".", "news_vecs", "=", "news_vecs", "\n", "self", ".", "user_vecs", "=", "user_vecs", "\n", "\n", "group_impr_indexes", "=", "[", "]", "\n", "group_labels", "=", "[", "]", "\n", "group_preds", "=", "[", "]", "\n", "\n", "for", "(", "\n", "impr_index", ",", "\n", "news_index", ",", "\n", "user_index", ",", "\n", "label", ",", "\n", ")", "in", "tqdm", "(", "self", ".", "test_iterator", ".", "load_impression_from_file", "(", "behaviors_file", ")", ")", ":", "\n", "            ", "pred", "=", "np", ".", "dot", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.load_model": [[418, 435], ["base_model.BaseModel.saver.restore", "IOError"], "methods", ["None"], ["np", ".", "stack", "(", "[", "news_vecs", "[", "i", "]", "for", "i", "in", "news_index", "]", ",", "axis", "=", "0", ")", ",", "\n", "user_vecs", "[", "impr_index", "]", ",", "\n", ")", "\n", "group_impr_indexes", ".", "append", "(", "impr_index", ")", "\n", "group_labels", ".", "append", "(", "label", ")", "\n", "group_preds", ".", "append", "(", "pred", ")", "\n", "\n", "", "return", "group_impr_indexes", ",", "group_labels", ",", "group_preds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel.predict": [[597, 619], ["tensorflow.io.gfile.GFile", "base_model.BaseModel.iterator.load_data_from_file", "base_model.BaseModel.infer", "numpy.reshape", "wt.write", "wt.write", "map"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._attention": [[620, 651], ["tensorflow.compat.v1.get_variable", "tensorflow.tensordot", "tensorflow.compat.v1.get_variable", "tensorflow.tensordot", "tensorflow.nn.softmax", "tensorflow.expand_dims"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._fcn_net": [[652, 736], ["tensorflow.compat.v1.variable_scope", "hidden_nn_layers.append", "tensorflow.compat.v1.variable_scope", "enumerate", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "base_model.BaseModel._active_layer", "hidden_nn_layers.append", "tensorflow.tensordot", "tensorflow.tensordot", "str", "tensorflow.compat.v1.layers.batch_normalization", "tensorflow.compat.v1.zeros_initializer", "str", "str", "tensorflow.compat.v1.zeros_initializer", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._active_layer"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_wide_deep_utils.pd_df": [[27, 47], ["pytest.fixture", "pandas.DataFrame", "pd.DataFrame.drop_duplicates", "pd.DataFrame.drop_duplicates"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "pd_df", "(", ")", ":", "\n", "    ", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "4", ",", "5", "]", ",", "\n", "ITEM_FEAT_COL", ":", "[", "\n", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "2", ",", "2", ",", "2", "]", ",", "\n", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "4", ",", "4", ",", "4", "]", ",", "\n", "[", "5", ",", "5", ",", "5", "]", ",", "\n", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", "]", ",", "\n", "}", "\n", ")", "\n", "users", "=", "df", ".", "drop_duplicates", "(", "DEFAULT_USER_COL", ")", "[", "DEFAULT_USER_COL", "]", ".", "values", "\n", "items", "=", "df", ".", "drop_duplicates", "(", "DEFAULT_ITEM_COL", ")", "[", "DEFAULT_ITEM_COL", "]", ".", "values", "\n", "return", "df", ",", "users", ",", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_wide_deep_utils.test_wide_model": [[49, 81], ["build_feature_columns", "build_model", "isinstance", "build_model.train", "tf.compat.v1.summary.FileWriterCache.get", "tf.compat.v1.summary.FileWriterCache.get.close", "len", "os.path.join", "pandas_input_fn"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_wide_model", "(", "pd_df", ",", "tmp", ")", ":", "\n", "    ", "data", ",", "users", ",", "items", "=", "pd_df", "\n", "\n", "# Test wide model", "\n", "# Test if wide column has two original features and one crossed feature", "\n", "wide_columns", ",", "_", "=", "build_feature_columns", "(", "\n", "users", ",", "items", ",", "model_type", "=", "\"wide\"", ",", "crossed_feat_dim", "=", "10", "\n", ")", "\n", "assert", "len", "(", "wide_columns", ")", "==", "3", "\n", "# Check crossed feature dimension", "\n", "assert", "wide_columns", "[", "2", "]", ".", "hash_bucket_size", "==", "10", "\n", "# Check model type", "\n", "model", "=", "build_model", "(", "\n", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"wide_\"", "+", "MODEL_DIR", ")", ",", "wide_columns", "=", "wide_columns", "\n", ")", "\n", "assert", "isinstance", "(", "model", ",", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "LinearRegressor", ")", "\n", "# Test if model train works", "\n", "model", ".", "train", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "data", ",", "\n", "y_col", "=", "DEFAULT_RATING_COL", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_epochs", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", ",", "\n", "steps", "=", "1", ",", "\n", ")", "\n", "\n", "# Close the event file so that the model folder can be cleaned up.", "\n", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "model", ".", "model_dir", ")", "\n", "summary_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_wide_deep_utils.test_deep_model": [[83, 105], ["build_feature_columns", "build_model", "isinstance", "build_model.train", "tf.compat.v1.summary.FileWriterCache.get", "tf.compat.v1.summary.FileWriterCache.get.close", "len", "os.path.join", "pandas_input_fn"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_deep_model", "(", "pd_df", ",", "tmp", ")", ":", "\n", "    ", "data", ",", "users", ",", "items", "=", "pd_df", "\n", "\n", "# Test if deep columns have user and item features", "\n", "_", ",", "deep_columns", "=", "build_feature_columns", "(", "users", ",", "items", ",", "model_type", "=", "\"deep\"", ")", "\n", "assert", "len", "(", "deep_columns", ")", "==", "2", "\n", "# Check model type", "\n", "model", "=", "build_model", "(", "\n", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"deep_\"", "+", "MODEL_DIR", ")", ",", "deep_columns", "=", "deep_columns", "\n", ")", "\n", "assert", "isinstance", "(", "model", ",", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "DNNRegressor", ")", "\n", "# Test if model train works", "\n", "model", ".", "train", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "data", ",", "y_col", "=", "DEFAULT_RATING_COL", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", "\n", ")", "\n", ")", "\n", "\n", "# Close the event file so that the model folder can be cleaned up.", "\n", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "model", ".", "model_dir", ")", "\n", "summary_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_wide_deep_utils.test_wide_deep_model": [[107, 139], ["build_feature_columns", "build_model", "isinstance", "build_model.train", "tf.compat.v1.summary.FileWriterCache.get", "tf.compat.v1.summary.FileWriterCache.get.close", "len", "len", "os.path.join", "pandas_input_fn"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.pandas_input_fn"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_wide_deep_model", "(", "pd_df", ",", "tmp", ")", ":", "\n", "    ", "data", ",", "users", ",", "items", "=", "pd_df", "\n", "\n", "# Test if wide and deep columns have correct features", "\n", "wide_columns", ",", "deep_columns", "=", "build_feature_columns", "(", "\n", "users", ",", "items", ",", "model_type", "=", "\"wide_deep\"", "\n", ")", "\n", "assert", "len", "(", "wide_columns", ")", "==", "3", "\n", "assert", "len", "(", "deep_columns", ")", "==", "2", "\n", "# Check model type", "\n", "model", "=", "build_model", "(", "\n", "os", ".", "path", ".", "join", "(", "tmp", ",", "\"wide_deep_\"", "+", "MODEL_DIR", ")", ",", "\n", "wide_columns", "=", "wide_columns", ",", "\n", "deep_columns", "=", "deep_columns", ",", "\n", ")", "\n", "assert", "isinstance", "(", "model", ",", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "DNNLinearCombinedRegressor", ")", "\n", "# Test if model train works", "\n", "model", ".", "train", "(", "\n", "input_fn", "=", "pandas_input_fn", "(", "\n", "df", "=", "data", ",", "\n", "y_col", "=", "DEFAULT_RATING_COL", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_epochs", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", ",", "\n", "steps", "=", "1", ",", "\n", ")", "\n", "\n", "# Close the event file so that the model folder can be cleaned up.", "\n", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriterCache", ".", "get", "(", "model", ".", "model_dir", ")", "\n", "summary_writer", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_rbm.init_rbm": [[13, 26], ["pytest.fixture"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "init_rbm", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"possible_ratings\"", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", "\"n_visible\"", ":", "500", ",", "\n", "\"n_hidden\"", ":", "100", ",", "\n", "\"epochs\"", ":", "10", ",", "\n", "\"minibatch\"", ":", "50", ",", "\n", "\"keep_prob\"", ":", "0.8", ",", "\n", "\"learning_rate\"", ":", "0.002", ",", "\n", "\"init_stdv\"", ":", "0.01", ",", "\n", "\"sampling_protocol\"", ":", "[", "30", ",", "50", ",", "80", ",", "90", ",", "100", "]", ",", "\n", "\"display_epoch\"", ":", "20", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_rbm.test_class_init": [[29, 64], ["RBM", "numpy.array_equal"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_class_init", "(", "init_rbm", ")", ":", "\n", "    ", "model", "=", "RBM", "(", "\n", "possible_ratings", "=", "init_rbm", "[", "\"possible_ratings\"", "]", ",", "\n", "visible_units", "=", "init_rbm", "[", "\"n_visible\"", "]", ",", "\n", "hidden_units", "=", "init_rbm", "[", "\"n_hidden\"", "]", ",", "\n", "training_epoch", "=", "init_rbm", "[", "\"epochs\"", "]", ",", "\n", "minibatch_size", "=", "init_rbm", "[", "\"minibatch\"", "]", ",", "\n", "keep_prob", "=", "init_rbm", "[", "\"keep_prob\"", "]", ",", "\n", "learning_rate", "=", "init_rbm", "[", "\"learning_rate\"", "]", ",", "\n", "init_stdv", "=", "init_rbm", "[", "\"init_stdv\"", "]", ",", "\n", "sampling_protocol", "=", "init_rbm", "[", "\"sampling_protocol\"", "]", ",", "\n", "display_epoch", "=", "init_rbm", "[", "\"display_epoch\"", "]", ",", "\n", ")", "\n", "\n", "# list of unique rating values", "\n", "assert", "np", ".", "array_equal", "(", "model", ".", "possible_ratings", ",", "init_rbm", "[", "\"possible_ratings\"", "]", ")", "\n", "# number of visible units", "\n", "assert", "model", ".", "n_visible", "==", "init_rbm", "[", "\"n_visible\"", "]", "\n", "# number of hidden units", "\n", "assert", "model", ".", "n_hidden", "==", "init_rbm", "[", "\"n_hidden\"", "]", "\n", "# number of training epochs", "\n", "assert", "model", ".", "epochs", "==", "init_rbm", "[", "\"epochs\"", "]", "+", "1", "\n", "# minibatch size", "\n", "assert", "model", ".", "minibatch", "==", "init_rbm", "[", "\"minibatch\"", "]", "\n", "# keep probability for dropout regulrization", "\n", "assert", "model", ".", "keep", "==", "init_rbm", "[", "\"keep_prob\"", "]", "\n", "# learning rate", "\n", "assert", "model", ".", "learning_rate", "==", "init_rbm", "[", "\"learning_rate\"", "]", "\n", "# standard deviation used to initialize the weight matrix from a normal distribution", "\n", "assert", "model", ".", "stdv", "==", "init_rbm", "[", "\"init_stdv\"", "]", "\n", "# sampling protocol used to increase the number of steps in Gibbs sampling", "\n", "assert", "model", ".", "sampling_protocol", "==", "init_rbm", "[", "\"sampling_protocol\"", "]", "\n", "# number of epochs after which the rmse is displayed", "\n", "assert", "model", ".", "display_epoch", "==", "init_rbm", "[", "\"display_epoch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_rbm.test_train_param_init": [[66, 90], ["RBM", "RBM.fit", "numpy.setdiff1d", "numpy.unique", "numpy.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_train_param_init", "(", "init_rbm", ",", "affinity_matrix", ")", ":", "\n", "# obtain the train/test set matrices", "\n", "    ", "Xtr", ",", "_", "=", "affinity_matrix", "\n", "\n", "# initialize the model", "\n", "model", "=", "RBM", "(", "\n", "possible_ratings", "=", "np", ".", "setdiff1d", "(", "np", ".", "unique", "(", "Xtr", ")", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "\n", "visible_units", "=", "Xtr", ".", "shape", "[", "1", "]", ",", "\n", "hidden_units", "=", "init_rbm", "[", "\"n_hidden\"", "]", ",", "\n", "training_epoch", "=", "init_rbm", "[", "\"epochs\"", "]", ",", "\n", "minibatch_size", "=", "init_rbm", "[", "\"minibatch\"", "]", ",", "\n", ")", "\n", "# fit the model to the data", "\n", "model", ".", "fit", "(", "Xtr", ")", "\n", "\n", "# visible units placeholder (tensor)", "\n", "model", ".", "vu", ".", "shape", "[", "1", "]", "==", "Xtr", ".", "shape", "[", "1", "]", "\n", "# weight matrix", "\n", "assert", "model", ".", "w", ".", "shape", "==", "[", "Xtr", ".", "shape", "[", "1", "]", ",", "init_rbm", "[", "\"n_hidden\"", "]", "]", "\n", "# bias, visible units", "\n", "assert", "model", ".", "bv", ".", "shape", "==", "[", "1", ",", "Xtr", ".", "shape", "[", "1", "]", "]", "\n", "# bias, hidden units", "\n", "assert", "model", ".", "bh", ".", "shape", "==", "[", "1", ",", "init_rbm", "[", "\"n_hidden\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_rbm.test_sampling_funct": [[92, 147], ["RBM", "Xtr.max", "RBM.fit", "RBM.sess.run", "check_sampled_values().all", "RBM.sess.run", "check_sampled_values().all", "range", "sum", "RBM.sample_hidden_units", "RBM.sample_visible_units", "numpy.sum", "pytest.approx", "numpy.setdiff1d", "a.append", "test_rbm.test_sampling_funct.check_sampled_values"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_hidden_units", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_visible_units"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_sampling_funct", "(", "init_rbm", ",", "affinity_matrix", ")", ":", "\n", "# obtain the train/test set matrices", "\n", "    ", "Xtr", ",", "_", "=", "affinity_matrix", "\n", "\n", "# initialize the model", "\n", "model", "=", "RBM", "(", "\n", "possible_ratings", "=", "np", ".", "setdiff1d", "(", "np", ".", "unique", "(", "Xtr", ")", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "\n", "visible_units", "=", "Xtr", ".", "shape", "[", "1", "]", ",", "\n", "hidden_units", "=", "init_rbm", "[", "\"n_hidden\"", "]", ",", "\n", "training_epoch", "=", "init_rbm", "[", "\"epochs\"", "]", ",", "\n", "minibatch_size", "=", "init_rbm", "[", "\"minibatch\"", "]", ",", "\n", ")", "\n", "\n", "def", "check_sampled_values", "(", "sampled", ",", "s", ")", ":", "\n", "        ", "\"\"\"\n        Check if the elements of the sampled units are in {0,s}\n        \"\"\"", "\n", "a", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "s", "+", "1", ")", ":", "\n", "            ", "l_bool", "=", "sampled", "==", "i", "\n", "a", ".", "append", "(", "l_bool", ")", "\n", "\n", "", "return", "sum", "(", "a", ")", "\n", "\n", "", "r", "=", "Xtr", ".", "max", "(", ")", "# obtain the rating scale", "\n", "\n", "# fit the model to the data", "\n", "model", ".", "fit", "(", "Xtr", ")", "\n", "\n", "# evaluate the activation probabilities of the hidden units and their sampled values", "\n", "phv", ",", "h", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "sample_hidden_units", "(", "model", ".", "v", ")", ")", "\n", "\n", "# check the dimensions of the two matrices", "\n", "assert", "phv", ".", "shape", "==", "(", "Xtr", ".", "shape", "[", "0", "]", ",", "100", ")", "\n", "assert", "h", ".", "shape", "==", "(", "Xtr", ".", "shape", "[", "0", "]", ",", "100", ")", "\n", "\n", "# check that the activation probabilities are in [0,1]", "\n", "assert", "(", "phv", "<=", "1", ")", ".", "all", "(", ")", "&", "(", "phv", ">=", "0", ")", ".", "all", "(", ")", "\n", "\n", "# check that the sampled value of the hidden units is either 1 or 0", "\n", "assert", "check_sampled_values", "(", "h", ",", "1", ")", ".", "all", "(", ")", "\n", "\n", "# evaluate the activation probabilities of the visible units and their sampled values", "\n", "pvh", ",", "v_sampled", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "sample_visible_units", "(", "h", ")", ")", "\n", "\n", "assert", "pvh", ".", "shape", "==", "(", "Xtr", ".", "shape", "[", "0", "]", ",", "Xtr", ".", "shape", "[", "1", "]", ",", "r", ")", "\n", "assert", "v_sampled", ".", "shape", "==", "Xtr", ".", "shape", "\n", "\n", "# check that the multinomial distribution is normalized over the r classes for all users/items", "\n", "assert", "np", ".", "sum", "(", "pvh", ",", "axis", "=", "2", ")", "==", "pytest", ".", "approx", "(", "np", ".", "ones", "(", "Xtr", ".", "shape", ")", ")", "\n", "\n", "# check that the sampled values of the visible units is in [0,r]", "\n", "assert", "check_sampled_values", "(", "v_sampled", ",", "r", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_rbm.test_save_load": [[148, 208], ["RBM", "RBM.save", "RBM", "RBM.load", "numpy.array_equal", "numpy.setdiff1d", "numpy.setdiff1d", "numpy.unique", "numpy.array", "numpy.unique", "numpy.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_save_load", "(", "init_rbm", ",", "affinity_matrix", ")", ":", "\n", "\n", "# obtain the train/test set matrices", "\n", "    ", "Xtr", ",", "_", "=", "affinity_matrix", "\n", "\n", "# initialize the model", "\n", "original_model", "=", "RBM", "(", "\n", "possible_ratings", "=", "np", ".", "setdiff1d", "(", "np", ".", "unique", "(", "Xtr", ")", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "\n", "visible_units", "=", "Xtr", ".", "shape", "[", "1", "]", ",", "\n", "hidden_units", "=", "init_rbm", "[", "\"n_hidden\"", "]", ",", "\n", "training_epoch", "=", "init_rbm", "[", "\"epochs\"", "]", ",", "\n", "minibatch_size", "=", "init_rbm", "[", "\"minibatch\"", "]", ",", "\n", "keep_prob", "=", "init_rbm", "[", "\"keep_prob\"", "]", ",", "\n", "learning_rate", "=", "init_rbm", "[", "\"learning_rate\"", "]", ",", "\n", "init_stdv", "=", "init_rbm", "[", "\"init_stdv\"", "]", ",", "\n", "sampling_protocol", "=", "init_rbm", "[", "\"sampling_protocol\"", "]", ",", "\n", "display_epoch", "=", "init_rbm", "[", "\"display_epoch\"", "]", ",", "\n", ")", "\n", "\n", "# save the model", "\n", "original_model", ".", "save", "(", ")", "\n", "\n", "# initialize another model", "\n", "saved_model", "=", "RBM", "(", "\n", "possible_ratings", "=", "np", ".", "setdiff1d", "(", "np", ".", "unique", "(", "Xtr", ")", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "\n", "visible_units", "=", "Xtr", ".", "shape", "[", "1", "]", ",", "\n", "hidden_units", "=", "init_rbm", "[", "\"n_hidden\"", "]", ",", "\n", "training_epoch", "=", "init_rbm", "[", "\"epochs\"", "]", ",", "\n", "minibatch_size", "=", "init_rbm", "[", "\"minibatch\"", "]", ",", "\n", "keep_prob", "=", "init_rbm", "[", "\"keep_prob\"", "]", ",", "\n", "learning_rate", "=", "init_rbm", "[", "\"learning_rate\"", "]", ",", "\n", "init_stdv", "=", "init_rbm", "[", "\"init_stdv\"", "]", ",", "\n", "sampling_protocol", "=", "init_rbm", "[", "\"sampling_protocol\"", "]", ",", "\n", "display_epoch", "=", "init_rbm", "[", "\"display_epoch\"", "]", ",", "\n", ")", "\n", "\n", "# load the pretrained model", "\n", "saved_model", ".", "load", "(", ")", "\n", "\n", "# list of unique rating values", "\n", "assert", "np", ".", "array_equal", "(", "saved_model", ".", "possible_ratings", ",", "original_model", ".", "possible_ratings", ")", "\n", "# number of visible units", "\n", "assert", "saved_model", ".", "n_visible", "==", "original_model", ".", "n_visible", "\n", "# number of hidden units", "\n", "assert", "saved_model", ".", "n_hidden", "==", "original_model", ".", "n_hidden", "\n", "# number of training epochs", "\n", "assert", "saved_model", ".", "epochs", "==", "original_model", ".", "epochs", "\n", "# minibatch size", "\n", "assert", "saved_model", ".", "minibatch", "==", "original_model", ".", "minibatch", "\n", "# keep probability for dropout regularization", "\n", "assert", "saved_model", ".", "keep", "==", "original_model", ".", "keep", "\n", "# learning rate", "\n", "assert", "saved_model", ".", "learning_rate", "==", "original_model", ".", "learning_rate", "\n", "# standard deviation used to initialize the weight matrix from a normal distribution", "\n", "assert", "saved_model", ".", "stdv", "==", "original_model", ".", "stdv", "\n", "# sampling protocol used to increase the number of steps in Gibbs sampling", "\n", "assert", "saved_model", ".", "sampling_protocol", "==", "original_model", ".", "sampling_protocol", "\n", "# number of epochs after which the rmse is displayed", "\n", "assert", "saved_model", ".", "display_epoch", "==", "original_model", ".", "display_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_utils.test_prepare_hparams": [[17, 32], ["pytest.mark.parametrize", "os.path.join", "os.path.join", "prepare_hparams", "hasattr", "os.path.exists", "download_deeprec_resources"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["from", "recommenders", ".", "models", ".", "deeprec", ".", "io", ".", "dkn_iterator", "import", "DKNTextIterator", "\n", "from", "recommenders", ".", "models", ".", "deeprec", ".", "io", ".", "dkn_item2item_iterator", "import", "(", "\n", "DKNItem2itemTextIterator", ",", "\n", ")", "\n", "from", "recommenders", ".", "models", ".", "deeprec", ".", "io", ".", "sequential_iterator", "import", "SequentialIterator", "\n", "", "except", "ImportError", ":", "\n", "    ", "pass", "# disable error while collecting tests for non-gpu environments", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_DKN_iterator", "(", "deeprec_resource_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_mind_demo.txt\"", ")", "\n", "news_feature_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"doc_feature.txt\"", ")", "\n", "user_history_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_history.txt\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_utils.test_load_yaml_file": [[34, 48], ["os.path.join", "os.path.join", "load_yaml", "os.path.exists", "download_deeprec_resources"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_yaml", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["entityEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"TransE_entity2vec_100.npy\"", ")", "\n", "contextEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"TransE_context2vec_100.npy\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"dkn.yaml\"", ")", "\n", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"mind-demo.zip\"", ",", "\n", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "news_feature_file", "=", "news_feature_file", ",", "\n", "user_history_file", "=", "user_history_file", ",", "\n", "wordEmb_file", "=", "\"\"", ",", "\n", "entityEmb_file", "=", "\"\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_surprise_utils.rating_true": [[25, 51], ["pd.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "rating_true", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "\n", "1", ",", "\n", "2", ",", "\n", "3", ",", "\n", "1", ",", "\n", "4", ",", "\n", "5", ",", "\n", "6", ",", "\n", "7", ",", "\n", "2", ",", "\n", "5", ",", "\n", "6", ",", "\n", "8", ",", "\n", "9", ",", "\n", "10", ",", "\n", "11", ",", "\n", "12", ",", "\n", "13", ",", "\n", "14", ",", "\n", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "1", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "1", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_surprise_utils.test_predict": [[55, 87], ["surprise.SVD", "surprise.Dataset.load_from_df().build_full_trainset", "surprise.SVD.fit", "predict", "predict", "set", "pytest.approx", "rating_true.rename", "set", "pytest.approx", "surprise.Dataset.load_from_df", "surprise.SVD.predict", "surprise.SVD.predict", "surprise.Reader"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "test_predict", "(", "rating_true", ")", ":", "\n", "    ", "svd", "=", "surprise", ".", "SVD", "(", ")", "\n", "train_set", "=", "surprise", ".", "Dataset", ".", "load_from_df", "(", "\n", "rating_true", ",", "reader", "=", "surprise", ".", "Reader", "(", ")", "\n", ")", ".", "build_full_trainset", "(", ")", "\n", "svd", ".", "fit", "(", "train_set", ")", "\n", "\n", "preds", "=", "predict", "(", "svd", ",", "rating_true", ")", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "}", "\n", "assert", "preds", "[", "\"userID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"itemID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "user", "=", "rating_true", ".", "iloc", "[", "0", "]", "[", "\"userID\"", "]", "\n", "item", "=", "rating_true", ".", "iloc", "[", "0", "]", "[", "\"itemID\"", "]", "\n", "assert", "preds", "[", "(", "preds", "[", "\"userID\"", "]", "==", "user", ")", "&", "(", "preds", "[", "\"itemID\"", "]", "==", "item", ")", "]", "[", "\n", "\"prediction\"", "\n", "]", ".", "values", "==", "pytest", ".", "approx", "(", "svd", ".", "predict", "(", "user", ",", "item", ")", ".", "est", ",", "rel", "=", "TOL", ")", "\n", "\n", "preds", "=", "predict", "(", "\n", "svd", ",", "\n", "rating_true", ".", "rename", "(", "columns", "=", "{", "\"userID\"", ":", "\"uid\"", ",", "\"itemID\"", ":", "\"iid\"", "}", ")", ",", "\n", "usercol", "=", "\"uid\"", ",", "\n", "itemcol", "=", "\"iid\"", ",", "\n", "predcol", "=", "\"pred\"", ",", "\n", ")", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"uid\"", ",", "\"iid\"", ",", "\"pred\"", "}", "\n", "assert", "preds", "[", "\"uid\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"iid\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "user", "=", "rating_true", ".", "iloc", "[", "1", "]", "[", "\"userID\"", "]", "\n", "item", "=", "rating_true", ".", "iloc", "[", "1", "]", "[", "\"itemID\"", "]", "\n", "assert", "preds", "[", "(", "preds", "[", "\"uid\"", "]", "==", "user", ")", "&", "(", "preds", "[", "\"iid\"", "]", "==", "item", ")", "]", "[", "\n", "\"pred\"", "\n", "]", ".", "values", "==", "pytest", ".", "approx", "(", "svd", ".", "predict", "(", "user", ",", "item", ")", ".", "est", ",", "rel", "=", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_surprise_utils.test_recommend_k_items": [[89, 136], ["len", "len", "surprise.SVD", "surprise.Dataset.load_from_df().build_full_trainset", "surprise.SVD.fit", "compute_ranking_predictions", "compute_ranking_predictions", "rating_true[].unique", "rating_true[].unique", "set", "pytest.approx", "rating_true.rename", "set", "pytest.approx", "surprise.Dataset.load_from_df", "surprise.SVD.predict", "pd.merge", "surprise.SVD.predict", "pd.merge", "surprise.Reader"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions", "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "test_recommend_k_items", "(", "rating_true", ")", ":", "\n", "    ", "n_users", "=", "len", "(", "rating_true", "[", "\"userID\"", "]", ".", "unique", "(", ")", ")", "\n", "n_items", "=", "len", "(", "rating_true", "[", "\"itemID\"", "]", ".", "unique", "(", ")", ")", "\n", "svd", "=", "surprise", ".", "SVD", "(", ")", "\n", "train_set", "=", "surprise", ".", "Dataset", ".", "load_from_df", "(", "\n", "rating_true", ",", "reader", "=", "surprise", ".", "Reader", "(", ")", "\n", ")", ".", "build_full_trainset", "(", ")", "\n", "svd", ".", "fit", "(", "train_set", ")", "\n", "\n", "preds", "=", "compute_ranking_predictions", "(", "svd", ",", "rating_true", ",", "remove_seen", "=", "True", ")", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "}", "\n", "assert", "preds", "[", "\"userID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"itemID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "user", "=", "preds", ".", "iloc", "[", "0", "]", "[", "\"userID\"", "]", "\n", "item", "=", "preds", ".", "iloc", "[", "0", "]", "[", "\"itemID\"", "]", "\n", "assert", "preds", "[", "(", "preds", "[", "\"userID\"", "]", "==", "user", ")", "&", "(", "preds", "[", "\"itemID\"", "]", "==", "item", ")", "]", "[", "\n", "\"prediction\"", "\n", "]", ".", "values", "==", "pytest", ".", "approx", "(", "svd", ".", "predict", "(", "user", ",", "item", ")", ".", "est", ",", "rel", "=", "TOL", ")", "\n", "# Test default remove_seen=True", "\n", "assert", "pd", ".", "merge", "(", "rating_true", ",", "preds", ",", "on", "=", "[", "\"userID\"", ",", "\"itemID\"", "]", ")", ".", "shape", "[", "0", "]", "==", "0", "\n", "assert", "preds", ".", "shape", "[", "0", "]", "==", "(", "n_users", "*", "n_items", "-", "rating_true", ".", "shape", "[", "0", "]", ")", "\n", "\n", "preds", "=", "compute_ranking_predictions", "(", "\n", "svd", ",", "\n", "rating_true", ".", "rename", "(", "columns", "=", "{", "\"userID\"", ":", "\"uid\"", ",", "\"itemID\"", ":", "\"iid\"", ",", "\"rating\"", ":", "\"r\"", "}", ")", ",", "\n", "usercol", "=", "\"uid\"", ",", "\n", "itemcol", "=", "\"iid\"", ",", "\n", "predcol", "=", "\"pred\"", ",", "\n", "remove_seen", "=", "False", ",", "\n", ")", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"uid\"", ",", "\"iid\"", ",", "\"pred\"", "}", "\n", "assert", "preds", "[", "\"uid\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"iid\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "user", "=", "preds", ".", "iloc", "[", "1", "]", "[", "\"uid\"", "]", "\n", "item", "=", "preds", ".", "iloc", "[", "1", "]", "[", "\"iid\"", "]", "\n", "assert", "preds", "[", "(", "preds", "[", "\"uid\"", "]", "==", "user", ")", "&", "(", "preds", "[", "\"iid\"", "]", "==", "item", ")", "]", "[", "\n", "\"pred\"", "\n", "]", ".", "values", "==", "pytest", ".", "approx", "(", "svd", ".", "predict", "(", "user", ",", "item", ")", ".", "est", ",", "rel", "=", "TOL", ")", "\n", "\n", "# Test remove_seen=False", "\n", "assert", "(", "\n", "pd", ".", "merge", "(", "\n", "rating_true", ",", "preds", ",", "left_on", "=", "[", "\"userID\"", ",", "\"itemID\"", "]", ",", "right_on", "=", "[", "\"uid\"", ",", "\"iid\"", "]", "\n", ")", ".", "shape", "[", "0", "]", "\n", "==", "rating_true", ".", "shape", "[", "0", "]", "\n", ")", "\n", "assert", "preds", ".", "shape", "[", "0", "]", "==", "n_users", "*", "n_items", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_cornac_utils.rating_true": [[20, 46], ["pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "rating_true", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "\n", "1", ",", "\n", "2", ",", "\n", "3", ",", "\n", "1", ",", "\n", "4", ",", "\n", "5", ",", "\n", "6", ",", "\n", "7", ",", "\n", "2", ",", "\n", "5", ",", "\n", "6", ",", "\n", "8", ",", "\n", "9", ",", "\n", "10", ",", "\n", "11", ",", "\n", "12", ",", "\n", "13", ",", "\n", "14", ",", "\n", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "1", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "1", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_cornac_utils.test_predict": [[50, 63], ["cornac.data.Dataset.from_uir", "cornac.models.MF().fit", "recommenders.models.cornac.cornac_utils.predict", "rating_true.itertuples", "set", "recommenders.evaluation.python_evaluation.mae", "recommenders.evaluation.python_evaluation.rmse", "cornac.models.MF"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse"], ["", "def", "test_predict", "(", "rating_true", ")", ":", "\n", "    ", "train_set", "=", "cornac", ".", "data", ".", "Dataset", ".", "from_uir", "(", "\n", "rating_true", ".", "itertuples", "(", "index", "=", "False", ")", ",", "seed", "=", "42", "\n", ")", "\n", "mf", "=", "cornac", ".", "models", ".", "MF", "(", "k", "=", "100", ",", "max_iter", "=", "10000", ",", "seed", "=", "42", ")", ".", "fit", "(", "train_set", ")", "\n", "\n", "preds", "=", "predict", "(", "mf", ",", "rating_true", ")", "\n", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "}", "\n", "assert", "preds", "[", "\"userID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"itemID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "assert", "0.02", ">", "mae", "(", "rating_true", ",", "preds", ")", "# ~0.018", "\n", "assert", "0.03", ">", "rmse", "(", "rating_true", ",", "preds", ")", "# ~0.021", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_cornac_utils.test_recommend_k_items": [[65, 83], ["cornac.data.Dataset.from_uir", "cornac.models.BPR().fit", "recommenders.models.cornac.cornac_utils.predict_ranking", "len", "len", "rating_true.itertuples", "rating_true[].unique", "rating_true[].unique", "set", "cornac.models.BPR", "recommenders.evaluation.python_evaluation.ndcg_at_k", "recommenders.evaluation.python_evaluation.recall_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.cornac.cornac_utils.predict_ranking", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "def", "test_recommend_k_items", "(", "rating_true", ")", ":", "\n", "    ", "train_set", "=", "cornac", ".", "data", ".", "Dataset", ".", "from_uir", "(", "\n", "rating_true", ".", "itertuples", "(", "index", "=", "False", ")", ",", "seed", "=", "42", "\n", ")", "\n", "bpr", "=", "cornac", ".", "models", ".", "BPR", "(", "k", "=", "100", ",", "max_iter", "=", "10000", ",", "seed", "=", "42", ")", ".", "fit", "(", "train_set", ")", "\n", "\n", "preds", "=", "predict_ranking", "(", "bpr", ",", "rating_true", ",", "remove_seen", "=", "False", ")", "\n", "\n", "n_users", "=", "len", "(", "rating_true", "[", "\"userID\"", "]", ".", "unique", "(", ")", ")", "\n", "n_items", "=", "len", "(", "rating_true", "[", "\"itemID\"", "]", ".", "unique", "(", ")", ")", "\n", "assert", "preds", ".", "shape", "[", "0", "]", "==", "n_users", "*", "n_items", "\n", "\n", "assert", "set", "(", "preds", ".", "columns", ")", "==", "{", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "}", "\n", "assert", "preds", "[", "\"userID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"userID\"", "]", ".", "dtypes", "\n", "assert", "preds", "[", "\"itemID\"", "]", ".", "dtypes", "==", "rating_true", "[", "\"itemID\"", "]", ".", "dtypes", "\n", "# perfect ranking achieved", "\n", "assert", "1e-10", ">", "1", "-", "ndcg_at_k", "(", "rating_true", ",", "preds", ")", "\n", "assert", "1e-10", ">", "1", "-", "recall_at_k", "(", "rating_true", ",", "preds", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_dataptr": [[41, 48], ["pytest.mark.parametrize", "DataPtr", "np.array_equal", "np.array_equal", "DataPtr.get_entity", "DataPtr.get_entity", "DataPtr.get_data"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data"], ["@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"data, entities\"", ",", "_IMC_TEST_DATA", ")", "\n", "def", "test_dataptr", "(", "data", ",", "entities", ")", ":", "\n", "    ", "ptr", "=", "DataPtr", "(", "data", ",", "entities", ")", "\n", "assert", "(", "ptr", ".", "get_data", "(", ")", "!=", "data", ")", ".", "nnz", "==", "0", "\n", "assert", "np", ".", "array_equal", "(", "ptr", ".", "get_entity", "(", "\"row\"", ")", ",", "entities", "[", "0", "]", ")", "\n", "assert", "np", ".", "array_equal", "(", "ptr", ".", "get_entity", "(", "\"col\"", ")", ",", "entities", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_length_normalize": [[51, 64], ["pytest.mark.parametrize", "np.allclose", "np.sqrt", "np.ones", "np.array", "np.array", "np.sum", "length_normalize"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.length_normalize"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"matrix\"", ",", "\n", "[", "\n", "(", "np", ".", "array", "(", "[", "[", "3", ",", "5", ",", "6", "]", ",", "[", "2", ",", "7", ",", "0", "]", ",", "[", "0", ",", "5", ",", "2", "]", "]", ")", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "7", ",", "9", ",", "9", "]", ",", "[", "4", ",", "3", ",", "8", "]", ",", "[", "6", ",", "0", ",", "3", "]", "]", ")", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_length_normalize", "(", "matrix", ")", ":", "\n", "    ", "assert", "np", ".", "allclose", "(", "\n", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "length_normalize", "(", "matrix", ")", "**", "2", ",", "axis", "=", "1", ")", ")", ",", "\n", "np", ".", "ones", "(", "matrix", ".", "shape", "[", "0", "]", ")", ",", "\n", "atol", "=", "1e-6", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_mean_center": [[67, 79], ["pytest.mark.parametrize", "mean_center", "np.allclose", "np.mean", "np.zeros", "np.array", "np.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.mean_center"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"matrix\"", ",", "\n", "[", "\n", "(", "np", ".", "array", "(", "[", "[", "3", ",", "5", ",", "6", "]", ",", "[", "2", ",", "7", ",", "0", "]", ",", "[", "0", ",", "5", ",", "2", "]", "]", ",", "dtype", "=", "\"float64\"", ")", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "7", ",", "9", ",", "9", "]", ",", "[", "4", ",", "3", ",", "8", "]", ",", "[", "6", ",", "0", ",", "3", "]", "]", ",", "dtype", "=", "\"float64\"", ")", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_mean_center", "(", "matrix", ")", ":", "\n", "    ", "mean_center", "(", "matrix", ")", "\n", "assert", "np", ".", "allclose", "(", "\n", "np", ".", "mean", "(", "matrix", ",", "axis", "=", "0", ")", ",", "np", ".", "zeros", "(", "matrix", ".", "shape", "[", "1", "]", ",", "dtype", "=", "\"float64\"", ")", ",", "atol", "=", "1e-10", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_reduce_dims": [[82, 86], ["np.random.rand", "reduce_dims"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.reduce_dims"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "def", "test_reduce_dims", "(", ")", ":", "\n", "    ", "matrix", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "100", ")", "\n", "assert", "reduce_dims", "(", "matrix", ",", "50", ")", ".", "shape", "[", "1", "]", "==", "50", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_imcproblem": [[89, 119], ["pytest.mark.parametrize", "IMCProblem", "np.array_equal", "np.array_equal", "IMCProblem.solve", "IMCProblem.reset", "dataPtr.get_entity", "dataPtr.get_entity", "len", "DataPtr", "DataPtr", "dataPtr.get_data"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem.reset", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dataPtr, rank\"", ",", "\n", "[", "\n", "(", "DataPtr", "(", "_IMC_TEST_DATA", "[", "0", "]", "[", "0", "]", ",", "_IMC_TEST_DATA", "[", "0", "]", "[", "1", "]", ")", ",", "3", ")", ",", "\n", "(", "DataPtr", "(", "_IMC_TEST_DATA", "[", "1", "]", "[", "0", "]", ",", "_IMC_TEST_DATA", "[", "1", "]", "[", "1", "]", ")", ",", "3", ")", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "experimental", "\n", "def", "test_imcproblem", "(", "dataPtr", ",", "rank", ")", ":", "\n", "\n", "# Test init", "\n", "    ", "prblm", "=", "IMCProblem", "(", "dataPtr", ",", "rank", "=", "rank", ")", "\n", "assert", "np", ".", "array_equal", "(", "prblm", ".", "X", ",", "dataPtr", ".", "get_entity", "(", "\"row\"", ")", ")", "\n", "assert", "np", ".", "array_equal", "(", "prblm", ".", "Z", ",", "dataPtr", ".", "get_entity", "(", "\"col\"", ")", ")", "\n", "assert", "(", "prblm", ".", "Y", "!=", "dataPtr", ".", "get_data", "(", ")", ")", ".", "nnz", "==", "0", "\n", "assert", "prblm", ".", "rank", "==", "rank", "\n", "assert", "prblm", ".", "lambda1", "==", "1e-2", "\n", "assert", "prblm", ".", "W", "is", "None", "\n", "assert", "not", "prblm", ".", "optima_reached", "\n", "\n", "# Test solve", "\n", "prblm", ".", "solve", "(", "10", ",", "10", ",", "0", ")", "\n", "assert", "len", "(", "prblm", ".", "W", ")", "==", "3", "\n", "assert", "prblm", ".", "optima_reached", "\n", "\n", "# Test reset", "\n", "prblm", ".", "reset", "(", ")", "\n", "assert", "prblm", ".", "W", "is", "None", "\n", "assert", "not", "prblm", ".", "optima_reached", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_inferer_init": [[122, 125], ["Inferer"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "def", "test_inferer_init", "(", ")", ":", "\n", "    ", "assert", "Inferer", "(", "method", "=", "\"dot\"", ")", ".", "method", ".", "__name__", "==", "\"PlainScalarProduct\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_geoimc.test_inferer_infer": [[127, 158], ["pytest.mark.parametrize", "Inferer().infer", "Inferer().infer", "collections.Counter", "Inferer().infer", "collections.Counter", "Stiefel().rand", "SymmetricPositiveDefinite().rand", "Stiefel().rand", "Inferer().infer.ravel", "Inferer().infer.ravel", "np.max", "DataPtr", "DataPtr", "test_data.get_entity", "test_data.get_entity", "Inferer", "Inferer", "Inferer", "np.count_nonzero", "Stiefel", "SymmetricPositiveDefinite", "Stiefel"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity"], ["", "@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dataPtr\"", ",", "\n", "[", "\n", "DataPtr", "(", "_IMC_TEST_DATA", "[", "0", "]", "[", "0", "]", ",", "_IMC_TEST_DATA", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "DataPtr", "(", "_IMC_TEST_DATA", "[", "1", "]", "[", "0", "]", ",", "_IMC_TEST_DATA", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_inferer_infer", "(", "dataPtr", ")", ":", "\n", "    ", "test_data", "=", "dataPtr", "\n", "\n", "rowFeatureDim", "=", "test_data", ".", "get_entity", "(", "\"row\"", ")", ".", "shape", "[", "1", "]", "\n", "colFeatureDim", "=", "test_data", ".", "get_entity", "(", "\"col\"", ")", ".", "shape", "[", "1", "]", "\n", "rank", "=", "2", "\n", "W", "=", "[", "\n", "Stiefel", "(", "rowFeatureDim", ",", "rank", ")", ".", "rand", "(", ")", ",", "\n", "SymmetricPositiveDefinite", "(", "rank", ")", ".", "rand", "(", ")", ",", "\n", "Stiefel", "(", "colFeatureDim", ",", "rank", ")", ".", "rand", "(", ")", ",", "\n", "]", "\n", "\n", "Inferer", "(", "method", "=", "\"dot\"", ")", ".", "infer", "(", "test_data", ",", "W", ")", "\n", "\n", "inference", "=", "Inferer", "(", "method", "=", "\"dot\"", ",", "transformation", "=", "\"mean\"", ")", ".", "infer", "(", "test_data", ",", "W", ")", "\n", "nOccurences", "=", "collections", ".", "Counter", "(", "inference", ".", "ravel", "(", ")", ")", "\n", "assert", "nOccurences", "[", "0", "]", "+", "nOccurences", "[", "1", "]", "==", "inference", ".", "size", "\n", "\n", "k", "=", "2", "\n", "inference", "=", "Inferer", "(", "method", "=", "\"dot\"", ",", "k", "=", "k", ",", "transformation", "=", "\"topk\"", ")", ".", "infer", "(", "test_data", ",", "W", ")", "\n", "nOccurences", "=", "collections", ".", "Counter", "(", "inference", ".", "ravel", "(", ")", ")", "\n", "assert", "nOccurences", "[", "0", "]", "+", "nOccurences", "[", "1", "]", "==", "inference", ".", "size", "\n", "assert", "np", ".", "max", "(", "np", ".", "count_nonzero", "(", "inference", "==", "1", ",", "axis", "=", "0", ")", ")", "<=", "k", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_model.test_nrms_component_definition": [[20, 48], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "NRMSModel", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_nrms", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"nrms.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_model.test_naml_component_definition": [[50, 82], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "NAMLModel", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "iterator", "=", "MINDIterator", "\n", "model", "=", "NRMSModel", "(", "hparams", ",", "iterator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_naml", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding_all.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict_all.pkl\"", ")", "\n", "vertDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"vert_dict.pkl\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_model.test_npa_component_definition": [[84, 112], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "NPAModel", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"naml.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "vertDict_file", "=", "vertDict_file", ",", "\n", "subvertDict_file", "=", "subvertDict_file", ",", "\n", "epochs", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_model.test_lstur_component_definition": [[114, 141], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "LSTURModel", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["\n", "iterator", "=", "MINDAllIterator", "\n", "model", "=", "NAMLModel", "(", "hparams", ",", "iterator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_lstur", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"lstur.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df": [[13, 47], ["pytest.fixture", "pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "df", "(", ")", ":", "\n", "    ", "mock_text", "=", "{", "\n", "\"cord_uid\"", ":", "[", "\"ej795nks\"", ",", "\"9mzs5dl4\"", ",", "\"u7lz3spe\"", "]", ",", "\n", "\"doi\"", ":", "[", "\"10.1289/ehp.7117\"", ",", "\"10.1289/ehp.7491\"", ",", "\"10.1371/journal.pmed.0030149\"", "]", ",", "\n", "\"title\"", ":", "[", "\n", "\"Understanding the Spatial Clustering of\"", ",", "\n", "\"The Application of the Haddon Matrix to\"", ",", "\n", "\"Cynomolgus Macaque as an Animal Model for\"", ",", "\n", "]", ",", "\n", "\"authors\"", ":", "[", "\n", "\"Lai, P.C.; Wong, C.M.; Hedley, A.J.; Lo,\"", ",", "\n", "\"Barnett, Daniel J.; Balicer, Ran D.;\"", ",", "\n", "\"Lawler, James V; Endy, Timothy P; Hensley,\"", ",", "\n", "]", ",", "\n", "\"journal\"", ":", "[", "\"Environ Health Perspect\"", ",", "\"Environ Health Perspect\"", ",", "\"PLoS Med\"", "]", ",", "\n", "\"abstract\"", ":", "[", "\n", "\"We applied cartographic and geostatistical met\"", ",", "\n", "\"State and local health departments continue to\"", ",", "\n", "\"BACKGROUND: The emergence of severe acute resp.\"", ",", "\n", "]", ",", "\n", "\"publish_time\"", ":", "[", "\"2004-07-27\"", ",", "\"2005-02-02\"", ",", "\"2006-04-18\"", "]", ",", "\n", "\"url\"", ":", "[", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11\"", ",", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12\"", ",", "\n", "\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC13\"", ",", "\n", "]", ",", "\n", "\"full_text\"", ":", "[", "\n", "\"Since the emergence and rapid spread of the e...\"", ",", "\n", "\"sudden fever and dry cough, along with chills\"", ",", "\n", "\"The emergence of severe acute respiratory syndrome (SARS)\"", ",", "\n", "]", ",", "\n", "}", "\n", "return", "pd", ".", "DataFrame", "(", "mock_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.model": [[49, 52], ["pytest.fixture", "recommenders.models.tfidf.tfidf_utils.TfidfRecommender", "test_tfidf_utils.df", "test_tfidf_utils.df", "test_tfidf_utils.df_clean", "test_tfidf_utils.df_clean"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df_clean", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df_clean"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "model", "(", ")", ":", "\n", "    ", "return", "TfidfRecommender", "(", "id_col", "=", "\"cord_uid\"", ",", "tokenization_method", "=", "\"scibert\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_init": [[54, 57], ["None"], "function", ["None"], ["", "def", "test_init", "(", "model", ")", ":", "\n", "    ", "assert", "model", ".", "id_col", "==", "\"cord_uid\"", "\n", "assert", "model", ".", "tokenization_method", "==", "\"scibert\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_clean_dataframe": [[59, 70], ["model.clean_dataframe", "list", "model.clean_dataframe.iterrows", "str", "list.append", "str.replace().isalnum", "str.replace"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.clean_dataframe"], ["", "def", "test_clean_dataframe", "(", "model", ",", "df", ")", ":", "\n", "    ", "df_clean", "=", "model", ".", "clean_dataframe", "(", "\n", "df", ",", "[", "\"abstract\"", ",", "\"full_text\"", "]", ",", "new_col_name", "=", "CLEAN_COL", "\n", ")", "\n", "\n", "isalphanumeric", "=", "list", "(", ")", "\n", "for", "idx", ",", "_", "in", "df_clean", ".", "iterrows", "(", ")", ":", "\n", "        ", "s1", "=", "str", "(", "df_clean", "[", "CLEAN_COL", "]", "[", "idx", "]", ")", "\n", "isalphanumeric", ".", "append", "(", "s1", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "isalnum", "(", ")", ")", "\n", "\n", "", "assert", "False", "not", "in", "isalphanumeric", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df_clean": [[72, 75], ["pytest.fixture", "model.clean_dataframe"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.clean_dataframe"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "df_clean", "(", "model", ",", "df", ")", ":", "\n", "    ", "return", "model", ".", "clean_dataframe", "(", "df", ",", "[", "\"abstract\"", ",", "\"full_text\"", "]", ",", "new_col_name", "=", "CLEAN_COL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_tokenize_text": [[77, 80], ["model.tokenize_text", "list"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.tokenize_text"], ["", "def", "test_tokenize_text", "(", "model", ",", "df_clean", ")", ":", "\n", "    ", "_", ",", "vectors_tokenized", "=", "model", ".", "tokenize_text", "(", "df_clean", ")", "\n", "assert", "True", "not", "in", "list", "(", "df_clean", "[", "CLEAN_COL", "]", "==", "vectors_tokenized", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_fit": [[82, 86], ["model.tokenize_text", "model.fit", "type"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.tokenize_text", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "test_fit", "(", "model", ",", "df_clean", ")", ":", "\n", "    ", "tf", ",", "vectors_tokenized", "=", "model", ".", "tokenize_text", "(", "df_clean", ")", "\n", "model", ".", "fit", "(", "tf", ",", "vectors_tokenized", ")", "\n", "assert", "type", "(", "model", ".", "tfidf_matrix", ")", "==", "scipy", ".", "sparse", ".", "csr", ".", "csr_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.model_fit": [[88, 95], ["pytest.fixture", "recommenders.models.tfidf.tfidf_utils.TfidfRecommender", "recommenders.models.tfidf.tfidf_utils.TfidfRecommender.tokenize_text", "recommenders.models.tfidf.tfidf_utils.TfidfRecommender.fit", "test_tfidf_utils.df_clean", "test_tfidf_utils.df_clean"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.tokenize_text", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df_clean", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.df_clean"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "model_fit", "(", "model", ",", "df_clean", ")", ":", "\n", "    ", "model_fit", "=", "TfidfRecommender", "(", "id_col", "=", "\"cord_uid\"", ",", "tokenization_method", "=", "\"scibert\"", ")", "\n", "tf", ",", "vectors_tokenized", "=", "model_fit", ".", "tokenize_text", "(", "df_clean", ")", "\n", "model_fit", ".", "fit", "(", "tf", ",", "vectors_tokenized", ")", "\n", "\n", "return", "model_fit", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_get_tokens": [[97, 101], ["model_fit.get_tokens", "type", "type", "list", "model_fit.get_tokens.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_tokens"], ["", "def", "test_get_tokens", "(", "model_fit", ")", ":", "\n", "    ", "tokens", "=", "model_fit", ".", "get_tokens", "(", ")", "\n", "assert", "type", "(", "tokens", ")", "==", "dict", "\n", "assert", "type", "(", "list", "(", "tokens", ".", "keys", "(", ")", ")", "[", "0", "]", ")", "==", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_get_stop_words": [[103, 106], ["model_fit.get_stop_words", "type", "list"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_stop_words"], ["", "def", "test_get_stop_words", "(", "model_fit", ")", ":", "\n", "    ", "stop_words", "=", "model_fit", ".", "get_stop_words", "(", ")", "\n", "assert", "type", "(", "list", "(", "stop_words", ")", "[", "0", "]", ")", "==", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_recommend_top_k_items": [[108, 111], ["model_fit.recommend_top_k_items", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.recommend_top_k_items"], ["", "def", "test_recommend_top_k_items", "(", "model_fit", ",", "df_clean", ")", ":", "\n", "    ", "top_k_recommendations", "=", "model_fit", ".", "recommend_top_k_items", "(", "df_clean", ",", "k", "=", "K", ")", "\n", "assert", "len", "(", "top_k_recommendations", ")", ">", "len", "(", "df_clean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_tfidf_utils.test_get_top_k_recommendations": [[113, 117], ["model_fit.get_top_k_recommendations", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_top_k_recommendations"], ["", "def", "test_get_top_k_recommendations", "(", "model_fit", ",", "df_clean", ")", ":", "\n", "    ", "query_id", "=", "\"ej795nks\"", "\n", "displayed_top_k", "=", "model_fit", ".", "get_top_k_recommendations", "(", "df_clean", ",", "query_id", "=", "query_id", ")", "\n", "assert", "len", "(", "displayed_top_k", ".", "data", ")", "==", "K", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.df": [[12, 16], ["pytest.fixture", "pandas.DataFrame", "dict"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "df", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "user", "=", "[", "1", ",", "3", ",", "2", "]", ",", "item", "=", "[", "8", ",", "7", ",", "7", "]", ",", "rating", "=", "[", "1", ",", "5", ",", "3", "]", ",", "timestamp", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.model": [[19, 24], ["pytest.fixture", "recommenders.models.vowpal_wabbit.vw.VW", "test_vowpal_wabbit.df", "test_vowpal_wabbit.df", "test_vowpal_wabbit.df"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"function\"", ")", "\n", "def", "model", "(", ")", ":", "\n", "    ", "model", "=", "VW", "(", "col_user", "=", "\"user\"", ",", "col_item", "=", "\"item\"", ",", "col_prediction", "=", "\"prediction\"", ",", "q", "=", "\"ui\"", ")", "\n", "yield", "model", "\n", "del", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_vw_init_del": [[26, 34], ["recommenders.models.vowpal_wabbit.vw.VW", "os.path.exists", "os.path.exists"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_vw_init_del", "(", ")", ":", "\n", "    ", "model", "=", "VW", "(", ")", "\n", "tempdir", "=", "model", ".", "tempdir", ".", "name", "\n", "assert", "os", ".", "path", ".", "exists", "(", "tempdir", ")", "\n", "\n", "del", "model", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "tempdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_to_vw_cmd": [[36, 61], ["dict", "recommenders.models.vowpal_wabbit.vw.VW.to_vw_cmd"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_cmd"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_to_vw_cmd", "(", ")", ":", "\n", "    ", "expected", "=", "[", "\n", "\"vw\"", ",", "\n", "\"-l\"", ",", "\n", "\"0.1\"", ",", "\n", "\"--l1\"", ",", "\n", "\"0.2\"", ",", "\n", "\"--loss_function\"", ",", "\n", "\"logistic\"", ",", "\n", "\"--holdout_off\"", ",", "\n", "\"--rank\"", ",", "\n", "\"3\"", ",", "\n", "\"-t\"", ",", "\n", "]", "\n", "params", "=", "dict", "(", "\n", "l", "=", "0.1", ",", "\n", "l1", "=", "0.2", ",", "\n", "loss_function", "=", "\"logistic\"", ",", "\n", "holdout_off", "=", "True", ",", "\n", "quiet", "=", "False", ",", "\n", "rank", "=", "3", ",", "\n", "t", "=", "True", ",", "\n", ")", "\n", "assert", "VW", ".", "to_vw_cmd", "(", "params", "=", "params", ")", "==", "expected", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_parse_train_cmd": [[63, 78], ["dict", "model.parse_train_params"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_train_params"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_parse_train_cmd", "(", "model", ")", ":", "\n", "    ", "expected", "=", "[", "\n", "\"vw\"", ",", "\n", "\"--loss_function\"", ",", "\n", "\"logistic\"", ",", "\n", "\"--oaa\"", ",", "\n", "\"5\"", ",", "\n", "\"-f\"", ",", "\n", "model", ".", "model_file", ",", "\n", "\"-d\"", ",", "\n", "model", ".", "train_file", ",", "\n", "]", "\n", "params", "=", "dict", "(", "loss_function", "=", "\"logistic\"", ",", "oaa", "=", "5", ",", "f", "=", "\"test\"", ",", "d", "=", "\"data\"", ",", "quiet", "=", "False", ")", "\n", "assert", "model", ".", "parse_train_params", "(", "params", "=", "params", ")", "==", "expected", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_parse_test_cmd": [[80, 99], ["dict", "model.parse_test_params"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_test_params"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_parse_test_cmd", "(", "model", ")", ":", "\n", "    ", "expected", "=", "[", "\n", "\"vw\"", ",", "\n", "\"--loss_function\"", ",", "\n", "\"logistic\"", ",", "\n", "\"-d\"", ",", "\n", "model", ".", "test_file", ",", "\n", "\"--quiet\"", ",", "\n", "\"-i\"", ",", "\n", "model", ".", "model_file", ",", "\n", "\"-p\"", ",", "\n", "model", ".", "prediction_file", ",", "\n", "\"-t\"", ",", "\n", "]", "\n", "params", "=", "dict", "(", "\n", "loss_function", "=", "\"logistic\"", ",", "i", "=", "\"test\"", ",", "oaa", "=", "5", ",", "d", "=", "\"data\"", ",", "test_only", "=", "True", ",", "quiet", "=", "True", "\n", ")", "\n", "assert", "model", ".", "parse_test_params", "(", "params", "=", "params", ")", "==", "expected", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_to_vw_file": [[101, 108], ["model.to_vw_file", "open", "f.read().splitlines", "f.read"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_file"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_to_vw_file", "(", "model", ",", "df", ")", ":", "\n", "    ", "expected", "=", "[", "\"1 0|user 1 |item 8\"", ",", "\"5 1|user 3 |item 7\"", ",", "\"3 2|user 2 |item 7\"", "]", "\n", "model", ".", "to_vw_file", "(", "df", ",", "train", "=", "True", ")", "\n", "with", "open", "(", "model", ".", "train_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "assert", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "==", "expected", "\n", "", "del", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_vowpal_wabbit.test_fit_and_predict": [[110, 132], ["dict", "open", "f.writelines", "unittest.mock.patch", "model.fit", "model.predict", "model.predict.to_dict", "dict", "dict", "dict", "dict", "dict", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "@", "pytest", ".", "mark", ".", "vw", "\n", "def", "test_fit_and_predict", "(", "model", ",", "df", ")", ":", "\n", "# generate fake predictions", "\n", "    ", "with", "open", "(", "model", ".", "prediction_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "[", "\"1 0\\n\"", ",", "\"3 1\\n\"", ",", "\"5 2\\n\"", "]", ")", "\n", "\n", "# patch subprocess call to vw", "\n", "", "with", "mock", ".", "patch", "(", "\n", "\"recommenders.models.vowpal_wabbit.vw.run\"", "\n", ")", "as", "mock_run", ":", "# noqa: F841", "\n", "        ", "model", ".", "fit", "(", "df", ")", "\n", "result", "=", "model", ".", "predict", "(", "df", ")", "\n", "\n", "", "expected", "=", "dict", "(", "\n", "user", "=", "dict", "(", "enumerate", "(", "[", "1", ",", "3", ",", "2", "]", ")", ")", ",", "\n", "item", "=", "dict", "(", "enumerate", "(", "[", "8", ",", "7", ",", "7", "]", ")", ")", ",", "\n", "rating", "=", "dict", "(", "enumerate", "(", "[", "1", ",", "5", ",", "3", "]", ")", ")", ",", "\n", "timestamp", "=", "dict", "(", "enumerate", "(", "[", "1", ",", "2", ",", "3", "]", ")", ")", ",", "\n", "prediction", "=", "dict", "(", "enumerate", "(", "[", "1", ",", "3", ",", "5", "]", ")", ")", ",", "\n", ")", "\n", "\n", "assert", "result", ".", "to_dict", "(", ")", "==", "expected", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.model_parameters": [[23, 37], ["pytest.fixture"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", ")", "\n", "def", "model_parameters", "(", ")", ":", "\n", "    ", "params", "=", "{", "\n", "\"itemnum\"", ":", "85930", ",", "\n", "\"usernum\"", ":", "63114", ",", "\n", "\"maxlen\"", ":", "50", ",", "\n", "\"num_blocks\"", ":", "2", ",", "\n", "\"hidden_units\"", ":", "100", ",", "\n", "\"num_heads\"", ":", "1", ",", "\n", "\"dropout_rate\"", ":", "0.1", ",", "\n", "\"l2_emb\"", ":", "0.0", ",", "\n", "\"num_neg_test\"", ":", "100", ",", "\n", "}", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.data_process_with_time": [[39, 120], ["collections.defaultdict", "set", "set", "collections.defaultdict", "collections.defaultdict", "print", "set", "set", "print", "print", "print", "open", "print", "print", "print", "open", "line.rstrip().split", "User[].append", "set.add", "set.add", "set.add", "set.add", "len", "len", "set.add", "len", "len", "len", "sorted", "zip", "line.rstrip", "fw.write", "str", "str", "out_txt.append", "str", "sep.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "data_process_with_time", "(", "fname", ",", "pname", ",", "K", "=", "10", ",", "sep", "=", "\" \"", ",", "item_set", "=", "None", ",", "add_time", "=", "False", ")", ":", "\n", "    ", "User", "=", "defaultdict", "(", "list", ")", "\n", "Users", "=", "set", "(", ")", "\n", "Items", "=", "set", "(", ")", "\n", "user_dict", ",", "item_dict", "=", "{", "}", ",", "{", "}", "\n", "\n", "item_counter", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "user_counter", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "with", "open", "(", "fname", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "u", ",", "i", ",", "t", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "sep", ")", "\n", "User", "[", "u", "]", ".", "append", "(", "(", "i", ",", "t", ")", ")", "\n", "Items", ".", "add", "(", "i", ")", "\n", "Users", ".", "add", "(", "u", ")", "\n", "item_counter", "[", "i", "]", "+=", "1", "\n", "user_counter", "[", "u", "]", "+=", "1", "\n", "\n", "# remove items with less than K interactions", "\n", "", "", "print", "(", "f\"Read {len(User)} users and {len(Items)} items\"", ")", "\n", "remove_items", "=", "set", "(", ")", "\n", "count_remove", ",", "count_missing", "=", "0", ",", "0", "\n", "for", "item", "in", "Items", ":", "\n", "        ", "if", "item_counter", "[", "item", "]", "<", "K", ":", "\n", "            ", "count_remove", "+=", "1", "\n", "remove_items", ".", "add", "(", "item", ")", "\n", "", "elif", "item_set", "and", "item", "not", "in", "item_set", ":", "\n", "            ", "count_missing", "+=", "1", "\n", "remove_items", ".", "add", "(", "item", ")", "\n", "\n", "", "", "if", "count_remove", ">", "0", ":", "\n", "        ", "print", "(", "f\"{count_remove} items have less than {K} interactions\"", ")", "\n", "\n", "", "if", "count_missing", ">", "0", ":", "\n", "        ", "print", "(", "f\"{count_missing} items are not in the meta data\"", ")", "\n", "\n", "", "Items", "=", "Items", "-", "remove_items", "\n", "\n", "# remove users with less than K interactions", "\n", "remove_users", "=", "set", "(", ")", "\n", "count_remove", "=", "0", "\n", "# Users = set(User.keys())", "\n", "for", "user", "in", "Users", ":", "\n", "        ", "if", "user_counter", "[", "user", "]", "<", "K", ":", "\n", "            ", "remove_users", ".", "add", "(", "user", ")", "\n", "count_remove", "+=", "1", "\n", "", "", "if", "count_remove", ">", "0", ":", "\n", "        ", "print", "(", "f\"{count_remove} users have less than {K} interactions\"", ")", "\n", "Users", "=", "Users", "-", "remove_users", "\n", "\n", "", "print", "(", "f\"Total {len(Users)} users and {len(Items)} items\"", ")", "\n", "item_count", "=", "1", "\n", "for", "item", "in", "Items", ":", "\n", "        ", "item_dict", "[", "item", "]", "=", "item_count", "\n", "item_count", "+=", "1", "\n", "\n", "", "count_del", "=", "0", "\n", "user_count", "=", "1", "\n", "with", "open", "(", "pname", ",", "\"w\"", ")", "as", "fw", ":", "\n", "        ", "for", "user", "in", "Users", ":", "\n", "            ", "items", "=", "User", "[", "user", "]", "\n", "items", "=", "[", "tup", "for", "tup", "in", "items", "if", "tup", "[", "0", "]", "in", "Items", "]", "\n", "if", "len", "(", "items", ")", "<", "K", ":", "\n", "                ", "count_del", "+=", "1", "\n", "", "else", ":", "\n", "                ", "user_dict", "[", "user", "]", "=", "user_count", "\n", "# sort by time", "\n", "items", "=", "sorted", "(", "items", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n", "# replace by the item-code", "\n", "timestamps", "=", "[", "x", "[", "1", "]", "for", "x", "in", "items", "]", "\n", "items", "=", "[", "item_dict", "[", "x", "[", "0", "]", "]", "for", "x", "in", "items", "]", "\n", "for", "i", ",", "t", "in", "zip", "(", "items", ",", "timestamps", ")", ":", "\n", "                    ", "out_txt", "=", "[", "str", "(", "user_count", ")", ",", "str", "(", "i", ")", "]", "\n", "if", "add_time", ":", "\n", "                        ", "out_txt", ".", "append", "(", "str", "(", "t", ")", ")", "\n", "", "fw", ".", "write", "(", "sep", ".", "join", "(", "out_txt", ")", "+", "\"\\n\"", ")", "\n", "", "user_count", "+=", "1", "\n", "\n", "", "", "", "print", "(", "f\"Total {user_count-1} users, {count_del} removed\"", ")", "\n", "print", "(", "f\"Processed model input data in {pname}\"", ")", "\n", "return", "user_dict", ",", "item_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.test_prepare_data": [[122, 143], ["os.path.join", "os.path.join", "os.path.join", "download_and_extract", "_reviews_preprocessing", "test_sasrec_model.data_process_with_time", "SASRecDataSet", "SASRecDataSet.split", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._reviews_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.data_process_with_time", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_prepare_data", "(", ")", ":", "\n", "    ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"resources\"", ",", "\"deeprec\"", ",", "\"sasrec\"", ")", "\n", "dataset", "=", "\"reviews_Electronics_5\"", "\n", "reviews_name", "=", "dataset", "+", "\".json\"", "\n", "outfile", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset", "+", "\".txt\"", ")", "\n", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "reviews_name", ")", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "reviews_output", "=", "_reviews_preprocessing", "(", "reviews_file", ")", "\n", "_", ",", "_", "=", "data_process_with_time", "(", "reviews_output", ",", "outfile", ",", "K", "=", "10", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "# initiate a dataset class", "\n", "data", "=", "SASRecDataSet", "(", "filename", "=", "outfile", ",", "col_sep", "=", "\"\\t\"", ")", "\n", "\n", "# create train, validation and test splits", "\n", "data", ".", "split", "(", ")", "\n", "\n", "assert", "len", "(", "data", ".", "user_train", ")", ">", "0", "\n", "assert", "len", "(", "data", ".", "user_valid", ")", ">", "0", "\n", "assert", "len", "(", "data", ".", "user_test", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.test_sampler": [[145, 179], ["os.path.join", "os.path.join", "os.path.join", "download_and_extract", "_reviews_preprocessing", "test_sasrec_model.data_process_with_time", "SASRecDataSet", "SASRecDataSet.split", "WarpSampler", "WarpSampler.next_batch", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews._reviews_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.data_process_with_time", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.next_batch"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_sampler", "(", ")", ":", "\n", "    ", "batch_size", "=", "8", "\n", "maxlen", "=", "50", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"resources\"", ",", "\"deeprec\"", ",", "\"sasrec\"", ")", "\n", "dataset", "=", "\"reviews_Electronics_5\"", "\n", "reviews_name", "=", "dataset", "+", "\".json\"", "\n", "outfile", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset", "+", "\".txt\"", ")", "\n", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "reviews_name", ")", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "reviews_output", "=", "_reviews_preprocessing", "(", "reviews_file", ")", "\n", "_", ",", "_", "=", "data_process_with_time", "(", "reviews_output", ",", "outfile", ",", "K", "=", "10", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "# initiate a dataset class", "\n", "data", "=", "SASRecDataSet", "(", "filename", "=", "outfile", ",", "col_sep", "=", "\"\\t\"", ")", "\n", "\n", "# create train, validation and test splits", "\n", "data", ".", "split", "(", ")", "\n", "\n", "sampler", "=", "WarpSampler", "(", "\n", "data", ".", "user_train", ",", "\n", "data", ".", "usernum", ",", "\n", "data", ".", "itemnum", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "maxlen", "=", "maxlen", ",", "\n", "n_workers", "=", "3", ",", "\n", ")", "\n", "u", ",", "seq", ",", "pos", ",", "neg", "=", "sampler", ".", "next_batch", "(", ")", "\n", "\n", "assert", "len", "(", "u", ")", "==", "batch_size", "\n", "assert", "len", "(", "seq", ")", "==", "batch_size", "\n", "assert", "len", "(", "pos", ")", "==", "batch_size", "\n", "assert", "len", "(", "neg", ")", "==", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.test_sasrec": [[181, 201], ["SASREC"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_sasrec", "(", "model_parameters", ")", ":", "\n", "\n", "    ", "params", "=", "model_parameters", "\n", "\n", "model", "=", "SASREC", "(", "\n", "item_num", "=", "params", "[", "\"itemnum\"", "]", ",", "\n", "seq_max_len", "=", "params", "[", "\"maxlen\"", "]", ",", "\n", "num_blocks", "=", "params", "[", "\"num_blocks\"", "]", ",", "\n", "embedding_dim", "=", "params", "[", "\"hidden_units\"", "]", ",", "\n", "attention_dim", "=", "params", "[", "\"hidden_units\"", "]", ",", "\n", "attention_num_heads", "=", "params", "[", "\"num_heads\"", "]", ",", "\n", "dropout_rate", "=", "params", "[", "\"dropout_rate\"", "]", ",", "\n", "conv_dims", "=", "[", "100", ",", "100", "]", ",", "\n", "l2_reg", "=", "params", "[", "\"l2_emb\"", "]", ",", "\n", "num_neg_test", "=", "params", "[", "\"num_neg_test\"", "]", ",", "\n", ")", "\n", "\n", "assert", "model", ".", "encoder", "is", "not", "None", "\n", "assert", "model", ".", "item_embedding_layer", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sasrec_model.test_ssept": [[203, 226], ["SSEPT"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_ssept", "(", "model_parameters", ")", ":", "\n", "\n", "    ", "params", "=", "model_parameters", "\n", "\n", "model", "=", "SSEPT", "(", "\n", "item_num", "=", "params", "[", "\"itemnum\"", "]", ",", "\n", "user_num", "=", "params", "[", "\"usernum\"", "]", ",", "\n", "seq_max_len", "=", "params", "[", "\"maxlen\"", "]", ",", "\n", "num_blocks", "=", "params", "[", "\"num_blocks\"", "]", ",", "\n", "user_embedding_dim", "=", "params", "[", "\"hidden_units\"", "]", ",", "\n", "item_embedding_dim", "=", "params", "[", "\"hidden_units\"", "]", ",", "\n", "attention_dim", "=", "params", "[", "\"hidden_units\"", "]", ",", "\n", "attention_num_heads", "=", "params", "[", "\"num_heads\"", "]", ",", "\n", "dropout_rate", "=", "params", "[", "\"dropout_rate\"", "]", ",", "\n", "conv_dims", "=", "[", "200", ",", "200", "]", ",", "\n", "l2_reg", "=", "params", "[", "\"l2_emb\"", "]", ",", "\n", "num_neg_test", "=", "params", "[", "\"num_neg_test\"", "]", ",", "\n", ")", "\n", "\n", "assert", "model", ".", "encoder", "is", "not", "None", "\n", "assert", "model", ".", "item_embedding_layer", "is", "not", "None", "\n", "assert", "model", ".", "user_embedding_layer", "is", "not", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_utils.test_prepare_hparams": [[14, 43], ["pytest.mark.parametrize", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "hasattr", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_news_iterator", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"nrms.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_newsrec_utils.test_load_yaml_file": [[45, 57], ["os.path.join", "load_yaml", "os.path.exists", "download_deeprec_resources", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_yaml", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], [")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "train_iterator", "=", "MINDIterator", "(", "hparams", ",", "hparams", ".", "npratio", ")", "\n", "test_iterator", "=", "MINDIterator", "(", "hparams", ",", "-", "1", ")", "\n", "\n", "assert", "train_iterator", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_xdeepfm_component_definition": [[39, 57], ["os.path.join", "os.path.join", "prepare_hparams", "XDeepFMModel", "os.path.exists", "download_deeprec_resources"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"sample_FFM_data.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"xdeepfmresources.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "yaml_file", ")", "\n", "iterator", "=", "FFMTextIterator", "(", "hparams", ",", "tf", ".", "Graph", "(", ")", ")", "\n", "assert", "iterator", "is", "not", "None", "\n", "for", "res", "in", "iterator", ".", "load_data_from_file", "(", "data_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "tuple", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.dkn_files": [[59, 83], ["pytest.fixture", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_deeprec_resources"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"xdeepfm\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"xDeepFM.yaml\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"sample_FFM_data.txt\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"xdeepfmresources.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "yaml_file", ",", "learning_rate", "=", "0.01", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "FFMTextIterator", "\n", "model", "=", "XDeepFMModel", "(", "hparams", ",", "input_creator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "data_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "model", ".", "fit", "(", "data_file", ",", "data_file", ")", ",", "BaseModel", ")", "\n", "assert", "model", ".", "predict", "(", "data_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_dkn_component_definition": [[86, 116], ["prepare_hparams", "DKN"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], ["    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"dkn.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_mind_demo.txt\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_mind_demo.txt\"", ")", "\n", "news_feature_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"doc_feature.txt\"", ")", "\n", "user_history_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_history.txt\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"word_embeddings_100.npy\"", ")", "\n", "entityEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"TransE_entity2vec_100.npy\"", ")", "\n", "contextEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"TransE_context2vec_100.npy\"", ")", "\n", "\n", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"mind-demo.zip\"", ",", "\n", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "news_feature_file", "=", "news_feature_file", ",", "\n", "user_history_file", "=", "user_history_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "entityEmb_file", "=", "entityEmb_file", ",", "\n", "contextEmb_file", "=", "contextEmb_file", ",", "\n", "epochs", "=", "1", ",", "\n", "learning_rate", "=", "0.0001", ",", "\n", ")", "\n", "input_creator", "=", "DKNTextIterator", "\n", "model", "=", "DKN", "(", "hparams", ",", "input_creator", ")", "\n", "\n", "assert", "isinstance", "(", "model", ".", "fit", "(", "train_file", ",", "valid_file", ")", ",", "BaseModel", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ")", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_dkn_item2item_component_definition": [[118, 153], ["prepare_hparams", "DKNItem2Item", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], ["\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "@", "pytest", ".", "mark", ".", "sequential", "\n", "def", "test_model_slirec", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"slirec\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"sli_rec.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_data\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_data\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"test_data\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "train_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for training", "\n", ")", "\n", "valid_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for validation", "\n", ")", "\n", "test_num_ngs", "=", "(", "\n", "9", "# number of negative instances with a positive instance for testing", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file", ")", ":", "\n", "        ", "user_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_vocab.pkl\"", ")", "\n", "item_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_vocab.pkl\"", ")", "\n", "cate_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"category_vocab.pkl\"", ")", "\n", "reviews_name", "=", "\"reviews_Movies_and_TV_5.json\"", "\n", "meta_name", "=", "\"meta_Movies_and_TV.json\"", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "reviews_name", ")", "\n", "meta_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "meta_name", ")", "\n", "sample_rate", "=", "(", "\n", "0.005", "# sample a small item set for training and testing here for example", "\n", ")", "\n", "\n", "input_files", "=", "[", "\n", "reviews_file", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.sequential_files": [[155, 204], ["pytest.fixture", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "recommenders.datasets.amazon_reviews.download_and_extract", "recommenders.datasets.amazon_reviews.download_and_extract", "recommenders.datasets.amazon_reviews.data_preprocessing"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.data_preprocessing"], ["train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "]", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "download_and_extract", "(", "meta_name", ",", "meta_file", ")", "\n", "data_preprocessing", "(", "\n", "*", "input_files", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "valid_num_ngs", "=", "valid_num_ngs", ",", "\n", "test_num_ngs", "=", "test_num_ngs", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "learning_rate", "=", "0.01", ",", "epochs", "=", "3", ",", "train_num_ngs", "=", "train_num_ngs", "\n", ")", "# confirm train_num_ngs before initializing a SLi_Rec model.", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "SequentialIterator", "\n", "model", "=", "SLI_RECModel", "(", "hparams", ",", "input_creator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ",", "num_ngs", "=", "valid_num_ngs", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "train_file", ",", "valid_file", ",", "valid_num_ngs", "=", "valid_num_ngs", ")", ",", "BaseModel", "\n", ")", "\n", "assert", "model", ".", "predict", "(", "test_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "@", "pytest", ".", "mark", ".", "sequential", "\n", "def", "test_model_sum", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"slirec\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"sum.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_data\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_data\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"test_data\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "train_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for training", "\n", ")", "\n", "valid_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for validation", "\n", ")", "\n", "test_num_ngs", "=", "(", "\n", "9", "# number of negative instances with a positive instance for testing", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_slirec_component_definition": [[207, 232], ["os.path.join", "prepare_hparams", "SLI_RECModel", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], ["        ", "user_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_vocab.pkl\"", ")", "\n", "item_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_vocab.pkl\"", ")", "\n", "cate_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"category_vocab.pkl\"", ")", "\n", "reviews_name", "=", "\"reviews_Movies_and_TV_5.json\"", "\n", "meta_name", "=", "\"meta_Movies_and_TV.json\"", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "reviews_name", ")", "\n", "meta_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "meta_name", ")", "\n", "sample_rate", "=", "(", "\n", "0.005", "# sample a small item set for training and testing here for example", "\n", ")", "\n", "\n", "input_files", "=", "[", "\n", "reviews_file", ",", "\n", "meta_file", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "]", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "download_and_extract", "(", "meta_name", ",", "meta_file", ")", "\n", "data_preprocessing", "(", "\n", "*", "input_files", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_nextitnet_component_definition": [[234, 260], ["os.path.join", "prepare_hparams", "NextItNetModel", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], ["test_num_ngs", "=", "test_num_ngs", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "learning_rate", "=", "0.01", ",", "epochs", "=", "1", ",", "train_num_ngs", "=", "train_num_ngs", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "SequentialIterator", "\n", "model", "=", "SUMModel", "(", "hparams", ",", "input_creator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ",", "num_ngs", "=", "valid_num_ngs", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "train_file", ",", "valid_file", ",", "valid_num_ngs", "=", "valid_num_ngs", ")", ",", "BaseModel", "\n", ")", "\n", "assert", "model", ".", "predict", "(", "valid_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "def", "test_model_lightgcn", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"lightgcn.yaml\"", ")", "\n", "user_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_embeddings.csv\"", ")", "\n", "item_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_embeddings.csv\"", ")", "\n", "\n", "df", "=", "movielens", ".", "load_pandas_df", "(", "size", "=", "\"100k\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_sum_component_definition": [[262, 288], ["os.path.join", "prepare_hparams", "SUMModel", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], ["\n", "data", "=", "ImplicitCF", "(", "train", "=", "train", ",", "test", "=", "test", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "yaml_file", ",", "epochs", "=", "1", ")", "\n", "model", "=", "LightGCN", "(", "hparams", ",", "data", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", ")", "is", "not", "None", "\n", "model", ".", "fit", "(", ")", "\n", "assert", "model", ".", "recommend_k_items", "(", "test", ")", "is", "not", "None", "\n", "model", ".", "infer_embedding", "(", "user_file", ",", "item_file", ")", "\n", "assert", "os", ".", "path", ".", "getsize", "(", "user_file", ")", "!=", "0", "\n", "assert", "os", ".", "path", ".", "getsize", "(", "item_file", ")", "!=", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_deeprec_model.test_lightgcn_component_definition": [[290, 312], ["os.path.join", "recommenders.datasets.movielens.load_pandas_df", "recommenders.datasets.python_splitters.python_stratified_split", "ImplicitCF", "prepare_hparams", "LightGCN"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_singlenode.test_init": [[26, 48], ["pytest.mark.parametrize", "NCF", "model_type.lower"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"model_type, n_users, n_items\"", ",", "[", "(", "\"NeuMF\"", ",", "1", ",", "1", ")", ",", "(", "\"GMF\"", ",", "10", ",", "10", ")", ",", "(", "\"MLP\"", ",", "4", ",", "8", ")", "]", "\n", ")", "\n", "def", "test_init", "(", "model_type", ",", "n_users", ",", "n_items", ")", ":", "\n", "    ", "model", "=", "NCF", "(", "\n", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ",", "seed", "=", "SEED", "\n", ")", "\n", "# model type", "\n", "assert", "model", ".", "model_type", "==", "model_type", ".", "lower", "(", ")", "\n", "# number of users in dataset", "\n", "assert", "model", ".", "n_users", "==", "n_users", "\n", "# number of items in dataset", "\n", "assert", "model", ".", "n_items", "==", "n_items", "\n", "# dimension of gmf user embedding", "\n", "assert", "model", ".", "embedding_gmf_P", ".", "shape", "==", "[", "n_users", ",", "model", ".", "n_factors", "]", "\n", "# dimension of gmf item embedding", "\n", "assert", "model", ".", "embedding_gmf_Q", ".", "shape", "==", "[", "n_items", ",", "model", ".", "n_factors", "]", "\n", "# dimension of mlp user embedding", "\n", "assert", "model", ".", "embedding_mlp_P", ".", "shape", "==", "[", "n_users", ",", "model", ".", "n_factors", "]", "\n", "# dimension of mlp item embedding", "\n", "assert", "model", ".", "embedding_mlp_Q", ".", "shape", "==", "[", "n_items", ",", "model", ".", "n_factors", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_singlenode.test_regular_save_load": [[52, 99], ["pytest.mark.parametrize", "os.path.exists", "NCF", "NCF.save", "NCF", "numpy.array_equal", "numpy.array_equal", "os.path.exists", "shutil.rmtree", "NCF.sess.run", "NCF.sess.run", "NCF.load", "NCF.sess.run", "NCF.sess.run", "shutil.rmtree", "NCF.sess.run", "NCF.sess.run", "NCF.load", "NCF.sess.run", "NCF.sess.run", "NCF.sess.run", "NCF.sess.run", "NCF.load", "NCF.sess.run", "NCF.sess.run"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"model_type, n_users, n_items\"", ",", "[", "(", "\"NeuMF\"", ",", "5", ",", "5", ")", ",", "(", "\"GMF\"", ",", "5", ",", "5", ")", ",", "(", "\"MLP\"", ",", "5", ",", "5", ")", "]", "\n", ")", "\n", "def", "test_regular_save_load", "(", "model_type", ",", "n_users", ",", "n_items", ")", ":", "\n", "    ", "ckpt", "=", "\".%s\"", "%", "model_type", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt", ")", "\n", "\n", "", "model", "=", "NCF", "(", "\n", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ",", "seed", "=", "SEED", "\n", ")", "\n", "model", ".", "save", "(", "ckpt", ")", "\n", "if", "model", ".", "model_type", "==", "\"neumf\"", ":", "\n", "        ", "P", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "", "elif", "model", ".", "model_type", "==", "\"gmf\"", ":", "\n", "        ", "P", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_Q", ")", "\n", "", "elif", "model", ".", "model_type", "==", "\"mlp\"", ":", "\n", "        ", "P", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_P", ")", "\n", "Q", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "\n", "", "del", "model", "\n", "model", "=", "NCF", "(", "\n", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ",", "seed", "=", "SEED", "\n", ")", "\n", "\n", "if", "model", ".", "model_type", "==", "\"neumf\"", ":", "\n", "        ", "model", ".", "load", "(", "neumf_dir", "=", "ckpt", ")", "\n", "P_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "", "elif", "model", ".", "model_type", "==", "\"gmf\"", ":", "\n", "        ", "model", ".", "load", "(", "gmf_dir", "=", "ckpt", ")", "\n", "P_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_Q", ")", "\n", "", "elif", "model", ".", "model_type", "==", "\"mlp\"", ":", "\n", "        ", "model", ".", "load", "(", "mlp_dir", "=", "ckpt", ")", "\n", "P_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_P", ")", "\n", "Q_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "\n", "# test load function", "\n", "", "assert", "np", ".", "array_equal", "(", "P", ",", "P_", ")", "\n", "assert", "np", ".", "array_equal", "(", "Q", ",", "Q_", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_singlenode.test_neumf_save_load": [[101, 143], ["pytest.mark.parametrize", "os.path.exists", "NCF", "NCF.save", "NCF.sess.run", "NCF.sess.run", "os.path.exists", "NCF", "NCF.save", "NCF.sess.run", "NCF.sess.run", "NCF", "NCF.load", "NCF.sess.run", "NCF.sess.run", "NCF.sess.run", "NCF.sess.run", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "os.path.exists", "os.path.exists", "shutil.rmtree", "shutil.rmtree", "shutil.rmtree", "shutil.rmtree"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_users, n_items\"", ",", "[", "(", "5", ",", "5", ")", ",", "(", "4", ",", "8", ")", "]", ")", "\n", "def", "test_neumf_save_load", "(", "n_users", ",", "n_items", ")", ":", "\n", "    ", "model_type", "=", "\"gmf\"", "\n", "ckpt_gmf", "=", "\".%s\"", "%", "model_type", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_gmf", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt_gmf", ")", "\n", "", "model", "=", "NCF", "(", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ")", "\n", "model", ".", "save", "(", "ckpt_gmf", ")", "\n", "P_gmf", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q_gmf", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_Q", ")", "\n", "del", "model", "\n", "\n", "model_type", "=", "\"mlp\"", "\n", "ckpt_mlp", "=", "\".%s\"", "%", "model_type", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_mlp", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt_mlp", ")", "\n", "", "model", "=", "NCF", "(", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ")", "\n", "model", ".", "save", "(", "\".%s\"", "%", "model_type", ")", "\n", "P_mlp", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_P", ")", "\n", "Q_mlp", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "del", "model", "\n", "\n", "model_type", "=", "\"neumf\"", "\n", "model", "=", "NCF", "(", "n_users", "=", "n_users", ",", "n_items", "=", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", ")", "\n", "model", ".", "load", "(", "gmf_dir", "=", "ckpt_gmf", ",", "mlp_dir", "=", "ckpt_mlp", ")", "\n", "\n", "P_gmf_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_P", ")", "\n", "Q_gmf_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_gmf_Q", ")", "\n", "\n", "P_mlp_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_P", ")", "\n", "Q_mlp_", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "embedding_mlp_Q", ")", "\n", "\n", "assert", "np", ".", "array_equal", "(", "P_gmf", ",", "P_gmf_", ")", "\n", "assert", "np", ".", "array_equal", "(", "Q_gmf", ",", "Q_gmf_", ")", "\n", "assert", "np", ".", "array_equal", "(", "P_mlp", ",", "P_mlp_", ")", "\n", "assert", "np", ".", "array_equal", "(", "Q_mlp", ",", "Q_mlp_", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_gmf", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt_gmf", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "ckpt_mlp", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "ckpt_mlp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_singlenode.test_fit": [[147, 156], ["pytest.mark.parametrize", "Dataset", "NCF", "NCF.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"model_type\"", ",", "[", "\"NeuMF\"", ",", "\"GMF\"", ",", "\"MLP\"", "]", ")", "\n", "def", "test_fit", "(", "dataset_ncf_files_sorted", ",", "model_type", ")", ":", "\n", "    ", "train_path", ",", "test_path", ",", "_", "=", "dataset_ncf_files_sorted", "\n", "data", "=", "Dataset", "(", "train_file", "=", "train_path", ",", "test_file", "=", "test_path", ",", "n_neg", "=", "N_NEG", ",", "n_neg_test", "=", "N_NEG_TEST", ")", "\n", "model", "=", "NCF", "(", "\n", "n_users", "=", "data", ".", "n_users", ",", "n_items", "=", "data", ".", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", "\n", ")", "\n", "model", ".", "fit", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_singlenode.test_predict": [[158, 178], ["pytest.mark.parametrize", "pandas.read_csv", "Dataset", "NCF", "NCF.fit", "NCF.predict", "list", "list", "type", "type", "len", "len", "NCF.predict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"model_type\"", ",", "[", "\"NeuMF\"", ",", "\"GMF\"", ",", "\"MLP\"", "]", ")", "\n", "def", "test_predict", "(", "dataset_ncf_files_sorted", ",", "model_type", ")", ":", "\n", "# test data format", "\n", "    ", "train_path", ",", "test_path", ",", "_", "=", "dataset_ncf_files_sorted", "\n", "test", "=", "pd", ".", "read_csv", "(", "test_path", ")", "\n", "data", "=", "Dataset", "(", "train_file", "=", "train_path", ",", "test_file", "=", "test_path", ",", "n_neg", "=", "N_NEG", ",", "n_neg_test", "=", "N_NEG_TEST", ")", "\n", "model", "=", "NCF", "(", "\n", "n_users", "=", "data", ".", "n_users", ",", "n_items", "=", "data", ".", "n_items", ",", "model_type", "=", "model_type", ",", "n_epochs", "=", "1", "\n", ")", "\n", "model", ".", "fit", "(", "data", ")", "\n", "\n", "test_users", ",", "test_items", "=", "list", "(", "test", "[", "DEFAULT_USER_COL", "]", ")", ",", "list", "(", "test", "[", "DEFAULT_ITEM_COL", "]", ")", "\n", "\n", "assert", "type", "(", "model", ".", "predict", "(", "test_users", "[", "0", "]", ",", "test_items", "[", "0", "]", ")", ")", "==", "float", "\n", "\n", "res", "=", "model", ".", "predict", "(", "test_users", ",", "test_items", ",", "is_list", "=", "True", ")", "\n", "\n", "assert", "type", "(", "res", ")", "==", "list", "\n", "assert", "len", "(", "res", ")", "==", "len", "(", "test", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_datafile_init": [[24, 67], ["pandas.read_csv", "train[].unique", "train[].unique", "recommenders.models.ncf.dataset.DataFile", "pandas.DataFrame.from_records", "datafile_df.sort_values.sort_values", "train.drop.sort_values", "train[].apply", "train.drop.drop", "train.drop.equals", "set", "set", "set", "set", "set", "set", "set", "set", "len", "len", "len", "len", "f.load_data", "recommenders.models.ncf.dataset.DataFile.user2id.keys", "recommenders.models.ncf.dataset.DataFile.item2id.keys", "set", "set", "datafile_records.append", "float", "pytest.raises", "recommenders.models.ncf.dataset.DataFile.user2id.values", "recommenders.models.ncf.dataset.DataFile.item2id.values", "f.load_data"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data"], ["@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_datafile_init", "(", "dataset_ncf_files_sorted", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "_", "=", "dataset_ncf_files_sorted", "\n", "train", "=", "pd", ".", "read_csv", "(", "train_path", ")", "\n", "users", "=", "train", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "items", "=", "train", "[", "DEFAULT_ITEM_COL", "]", ".", "unique", "(", ")", "\n", "datafile", "=", "DataFile", "(", "\n", "train_path", ",", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", ",", "DEFAULT_RATING_COL", ",", "col_test_batch", "=", "None", ",", "binary", "=", "True", "\n", ")", "\n", "assert", "set", "(", "datafile", ".", "users", ")", "==", "set", "(", "users", ")", "\n", "assert", "set", "(", "datafile", ".", "items", ")", "==", "set", "(", "items", ")", "\n", "assert", "set", "(", "datafile", ".", "user2id", ".", "keys", "(", ")", ")", "==", "set", "(", "users", ")", "\n", "assert", "set", "(", "datafile", ".", "item2id", ".", "keys", "(", ")", ")", "==", "set", "(", "items", ")", "\n", "assert", "len", "(", "set", "(", "datafile", ".", "user2id", ".", "values", "(", ")", ")", ")", "==", "len", "(", "users", ")", "\n", "assert", "len", "(", "set", "(", "datafile", ".", "item2id", ".", "values", "(", ")", ")", ")", "==", "len", "(", "items", ")", "\n", "assert", "datafile", ".", "data_len", "==", "train", ".", "shape", "[", "0", "]", "\n", "\n", "datafile_records", "=", "[", "]", "\n", "with", "datafile", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "datafile_records", ".", "append", "(", "{", "\n", "DEFAULT_USER_COL", ":", "line", "[", "DEFAULT_USER_COL", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "line", "[", "DEFAULT_ITEM_COL", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "line", "[", "DEFAULT_RATING_COL", "]", "\n", "}", ")", "\n", "", "", "datafile_df", "=", "pd", ".", "DataFrame", ".", "from_records", "(", "datafile_records", ")", "\n", "assert", "datafile_df", ".", "shape", "[", "0", "]", "==", "train", ".", "shape", "[", "0", "]", "\n", "\n", "# test the data loaded from the file is the same as original data", "\n", "datafile_df", "=", "datafile_df", ".", "sort_values", "(", "by", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", ")", "\n", "train", "=", "train", ".", "sort_values", "(", "by", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", ")", "\n", "train", "[", "DEFAULT_RATING_COL", "]", "=", "train", "[", "DEFAULT_RATING_COL", "]", ".", "apply", "(", "lambda", "x", ":", "float", "(", "x", ">", "0", ")", ")", "\n", "train", "=", "train", ".", "drop", "(", "DEFAULT_TIMESTAMP_COL", ",", "axis", "=", "1", ")", "\n", "assert", "train", ".", "equals", "(", "datafile_df", ")", "\n", "\n", "# test data can be loaded for a valid user and it throws exception for invalid user", "\n", "user", "=", "train", "[", "DEFAULT_USER_COL", "]", ".", "iloc", "[", "0", "]", "\n", "missing_user", "=", "train", "[", "DEFAULT_USER_COL", "]", ".", "iloc", "[", "-", "1", "]", "+", "1", "\n", "with", "datafile", "as", "f", ":", "\n", "        ", "user_data", "=", "f", ".", "load_data", "(", "user", ")", "\n", "assert", "user_data", "[", "DEFAULT_USER_COL", "]", ".", "iloc", "[", "0", "]", "==", "user", "\n", "with", "pytest", ".", "raises", "(", "MissingUserException", ")", ":", "\n", "            ", "user_data", "==", "f", ".", "load_data", "(", "missing_user", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_datafile_init_unsorted": [[69, 75], ["pytest.raises", "recommenders.models.ncf.dataset.DataFile"], "function", ["None"], ["", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_datafile_init_unsorted", "(", "dataset_ncf_files_unsorted", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "_", "=", "dataset_ncf_files_unsorted", "\n", "with", "pytest", ".", "raises", "(", "FileNotSortedException", ")", ":", "\n", "        ", "datafile", "=", "DataFile", "(", "\n", "train_path", ",", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", ",", "DEFAULT_RATING_COL", ",", "col_test_batch", "=", "None", ",", "binary", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_datafile_init_empty": [[78, 84], ["pytest.raises", "recommenders.models.ncf.dataset.DataFile"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_datafile_init_empty", "(", "dataset_ncf_files_empty", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "_", "=", "dataset_ncf_files_empty", "\n", "with", "pytest", ".", "raises", "(", "EmptyFileException", ")", ":", "\n", "        ", "datafile", "=", "DataFile", "(", "\n", "train_path", ",", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", ",", "DEFAULT_RATING_COL", ",", "col_test_batch", "=", "None", ",", "binary", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_datafile_missing_column": [[87, 93], ["pytest.raises", "recommenders.models.ncf.dataset.DataFile"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_datafile_missing_column", "(", "dataset_ncf_files_missing_column", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "_", "=", "dataset_ncf_files_missing_column", "\n", "with", "pytest", ".", "raises", "(", "MissingFieldsException", ")", ":", "\n", "        ", "datafile", "=", "DataFile", "(", "\n", "train_path", ",", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", ",", "DEFAULT_RATING_COL", ",", "col_test_batch", "=", "None", ",", "binary", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_negative_sampler": [[96, 118], ["recommenders.models.ncf.dataset.NegativeSampler", "recommenders.models.ncf.dataset.NegativeSampler.sample", "recommenders.models.ncf.dataset.NegativeSampler", "recommenders.models.ncf.dataset.NegativeSampler", "set", "item_pool.difference", "len", "recommenders.models.ncf.dataset.NegativeSampler.sample"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_negative_sampler", "(", "caplog", ")", ":", "\n", "    ", "user", "=", "1", "\n", "n_samples", "=", "3", "\n", "user_positive_item_pool", "=", "{", "1", ",", "2", "}", "\n", "item_pool", "=", "{", "1", ",", "2", ",", "3", ",", "4", ",", "5", "}", "\n", "sample_with_replacement", "=", "False", "\n", "sampler", "=", "NegativeSampler", "(", "user", ",", "n_samples", ",", "user_positive_item_pool", ",", "item_pool", ",", "sample_with_replacement", ")", "\n", "assert", "sampler", ".", "n_samples", "==", "3", "\n", "samples", "=", "sampler", ".", "sample", "(", ")", "\n", "assert", "set", "(", "samples", ")", "==", "item_pool", ".", "difference", "(", "user_positive_item_pool", ")", "\n", "\n", "# test sampler adjusts n_samples down if population is too small and that it raises a warning", "\n", "n_samples", "=", "4", "\n", "sampler", "=", "NegativeSampler", "(", "user", ",", "n_samples", ",", "user_positive_item_pool", ",", "item_pool", ",", "sample_with_replacement", ")", "\n", "assert", "sampler", ".", "n_samples", "==", "3", "\n", "assert", "\"The population of negative items to sample from is too small for user 1\"", "in", "caplog", ".", "text", "\n", "\n", "# test sampling with replacement returns requested number of samples despite small population", "\n", "sampler", "=", "NegativeSampler", "(", "user", ",", "n_samples", ",", "user_positive_item_pool", ",", "item_pool", ",", "sample_with_replacement", "=", "True", ")", "\n", "assert", "sampler", ".", "n_samples", "==", "4", "\n", "assert", "len", "(", "sampler", ".", "sample", "(", ")", ")", "==", "n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_train_loader": [[120, 163], ["pandas.read_csv", "train[].unique", "train[].unique", "recommenders.models.ncf.dataset.Dataset", "os.path.join", "recommenders.models.ncf.dataset.Dataset.train_loader", "pandas.concat().reset_index", "os.path.exists", "pandas.read_csv", "pd.read_csv.equals", "len", "len", "set", "set", "set", "set", "len", "len", "len", "len", "batch_records.append", "len", "set", "set", "set", "set", "recommenders.models.ncf.dataset.Dataset.user2id.keys", "recommenders.models.ncf.dataset.Dataset.item2id.keys", "set", "set", "type", "type", "type", "pandas.DataFrame", "pandas.concat", "recommenders.models.ncf.dataset.Dataset.user2id.values", "recommenders.models.ncf.dataset.Dataset.item2id.values"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.train_loader", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_train_loader", "(", "tmp_path", ",", "dataset_ncf_files_sorted", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "_", "=", "dataset_ncf_files_sorted", "\n", "train", "=", "pd", ".", "read_csv", "(", "train_path", ")", "\n", "users", "=", "train", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "items", "=", "train", "[", "DEFAULT_ITEM_COL", "]", ".", "unique", "(", ")", "\n", "\n", "n_neg", "=", "1", "\n", "dataset", "=", "Dataset", "(", "train_path", ",", "n_neg", "=", "n_neg", ")", "\n", "assert", "dataset", ".", "n_users", "==", "len", "(", "users", ")", "\n", "assert", "dataset", ".", "n_items", "==", "len", "(", "items", ")", "\n", "assert", "set", "(", "dataset", ".", "user2id", ".", "keys", "(", ")", ")", "==", "set", "(", "users", ")", "\n", "assert", "set", "(", "dataset", ".", "item2id", ".", "keys", "(", ")", ")", "==", "set", "(", "items", ")", "\n", "assert", "len", "(", "set", "(", "dataset", ".", "user2id", ".", "values", "(", ")", ")", ")", "==", "len", "(", "users", ")", "\n", "assert", "len", "(", "set", "(", "dataset", ".", "item2id", ".", "values", "(", ")", ")", ")", "==", "len", "(", "items", ")", "\n", "\n", "# test number of batches and data size is as expected after loading all training data", "\n", "full_data_len", "=", "train", ".", "shape", "[", "0", "]", "*", "2", "\n", "batch_size", "=", "full_data_len", "//", "10", "\n", "expected_batches", "=", "full_data_len", "//", "batch_size", "\n", "train_save_path", "=", "os", ".", "path", ".", "join", "(", "tmp_path", ",", "\"train_full.csv\"", ")", "\n", "batch_records", "=", "[", "]", "\n", "for", "batch", "in", "dataset", ".", "train_loader", "(", "batch_size", ",", "shuffle_size", "=", "batch_size", ",", "yield_id", "=", "True", ",", "write_to", "=", "train_save_path", ")", ":", "\n", "        ", "assert", "type", "(", "batch", "[", "0", "]", "[", "0", "]", ")", "==", "int", "\n", "assert", "type", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "==", "int", "\n", "assert", "type", "(", "batch", "[", "2", "]", "[", "0", "]", ")", "==", "float", "\n", "batch_data", "=", "{", "\n", "DEFAULT_USER_COL", ":", "[", "dataset", ".", "id2user", "[", "user", "]", "for", "user", "in", "batch", "[", "0", "]", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "dataset", ".", "id2item", "[", "item", "]", "for", "item", "in", "batch", "[", "1", "]", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "batch", "[", "2", "]", "\n", "}", "\n", "batch_records", ".", "append", "(", "pd", ".", "DataFrame", "(", "batch_data", ")", ")", "\n", "\n", "", "assert", "len", "(", "batch_records", ")", "==", "expected_batches", "\n", "train_loader_df", "=", "pd", ".", "concat", "(", "batch_records", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "assert", "train_loader_df", ".", "shape", "[", "0", "]", "==", "expected_batches", "*", "batch_size", "\n", "assert", "set", "(", "train_loader_df", "[", "DEFAULT_USER_COL", "]", ")", "==", "set", "(", "users", ")", "\n", "assert", "set", "(", "train_loader_df", "[", "DEFAULT_ITEM_COL", "]", ")", "==", "set", "(", "items", ")", "\n", "\n", "# test that data is successfully saved", "\n", "assert", "os", ".", "path", ".", "exists", "(", "train_save_path", ")", "\n", "train_file_data", "=", "pd", ".", "read_csv", "(", "train_save_path", ")", "\n", "assert", "train_file_data", ".", "equals", "(", "train_loader_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_ncf_dataset.test_test_loader": [[165, 195], ["pandas.read_csv", "leave_one_out_test[].unique", "recommenders.models.ncf.dataset.Dataset", "recommenders.models.ncf.dataset.Dataset.test_loader", "pandas.concat().reset_index", "set", "set", "batch_records.append", "len", "set", "set", "max", "type", "type", "type", "pandas.DataFrame", "pandas.concat"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset.test_loader"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_test_loader", "(", "dataset_ncf_files_sorted", ")", ":", "\n", "    ", "train_path", ",", "_", ",", "leave_one_out_test_path", "=", "dataset_ncf_files_sorted", "\n", "leave_one_out_test", "=", "pd", ".", "read_csv", "(", "leave_one_out_test_path", ")", "\n", "test_users", "=", "leave_one_out_test", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "\n", "n_neg", "=", "1", "\n", "n_neg_test", "=", "1", "\n", "dataset", "=", "Dataset", "(", "train_path", ",", "test_file", "=", "leave_one_out_test_path", ",", "n_neg", "=", "n_neg", ",", "n_neg_test", "=", "n_neg_test", ")", "\n", "assert", "set", "(", "dataset", ".", "test_full_datafile", ".", "users", ")", "==", "set", "(", "test_users", ")", "\n", "\n", "# test number of batches and data size is as expected after loading all test data", "\n", "expected_test_batches", "=", "leave_one_out_test", ".", "shape", "[", "0", "]", "\n", "assert", "max", "(", "dataset", ".", "test_full_datafile", ".", "batch_indices_range", ")", "+", "1", "==", "expected_test_batches", "\n", "batch_records", "=", "[", "]", "\n", "for", "batch", "in", "dataset", ".", "test_loader", "(", "yield_id", "=", "True", ")", ":", "\n", "        ", "assert", "type", "(", "batch", "[", "0", "]", "[", "0", "]", ")", "==", "int", "\n", "assert", "type", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "==", "int", "\n", "assert", "type", "(", "batch", "[", "2", "]", "[", "0", "]", ")", "==", "float", "\n", "batch_data", "=", "{", "\n", "DEFAULT_USER_COL", ":", "[", "dataset", ".", "id2user", "[", "user", "]", "for", "user", "in", "batch", "[", "0", "]", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "dataset", ".", "id2item", "[", "item", "]", "for", "item", "in", "batch", "[", "1", "]", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "batch", "[", "2", "]", "\n", "}", "\n", "batch_records", ".", "append", "(", "pd", ".", "DataFrame", "(", "batch_data", ")", ")", "\n", "\n", "", "assert", "len", "(", "batch_records", ")", "==", "expected_test_batches", "\n", "test_loader_df", "=", "pd", ".", "concat", "(", "batch_records", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "assert", "test_loader_df", ".", "shape", "[", "0", "]", "==", "expected_test_batches", "*", "n_neg_test", "*", "2", "\n", "assert", "set", "(", "test_loader_df", "[", "DEFAULT_USER_COL", "]", ")", "==", "set", "(", "test_users", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.df": [[23, 55], ["pytest.fixture", "pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "df", "(", ")", ":", "\n", "    ", "mock_data", "=", "{", "\n", "\"userID\"", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", ",", "\n", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", ",", "\n", "\"rating\"", ":", "[", "2.0", ",", "4.0", ",", "1.0", ",", "4.0", ",", "1.0", ",", "2.0", ",", "5.0", ",", "1.0", ",", "1.0", ",", "2.0", "]", ",", "\n", "\"genre\"", ":", "[", "\n", "\"Action|Comedy\"", ",", "\n", "\"Drama\"", ",", "\n", "\"Drama|Romance|War\"", ",", "\n", "\"Drama|Sci-Fi\"", ",", "\n", "\"Horror\"", ",", "\n", "\"Action|Horror|Sci-Fi|Thriller\"", ",", "\n", "\"Drama|Romance|War\"", ",", "\n", "\"Western\"", ",", "\n", "\"Comedy\"", ",", "\n", "\"Horror\"", ",", "\n", "]", ",", "\n", "\"occupation\"", ":", "[", "\n", "\"engineer\"", ",", "\n", "\"student\"", ",", "\n", "\"retired\"", ",", "\n", "\"administrator\"", ",", "\n", "\"writer\"", ",", "\n", "\"administrator\"", ",", "\n", "\"student\"", ",", "\n", "\"executive\"", ",", "\n", "\"student\"", ",", "\n", "\"other\"", ",", "\n", "]", ",", "\n", "}", "\n", "return", "pd", ".", "DataFrame", "(", "mock_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.interactions": [[57, 88], ["pytest.fixture", "sorted", "sorted", "lightfm.data.Dataset", "lightfm.data.Dataset.fit", "lightfm.data.Dataset.build_item_features", "lightfm.data.Dataset.build_user_features", "lightfm.data.Dataset.build_interactions", "lightfm.cross_validation.random_train_test_split", "x.split", "list", "list", "set", "set", "numpy.random.RandomState", "itertools.chain.from_iterable", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "interactions", "(", "df", ")", ":", "\n", "    ", "movie_genre", "=", "[", "x", ".", "split", "(", "\"|\"", ")", "for", "x", "in", "df", "[", "\"genre\"", "]", "]", "\n", "all_movie_genre", "=", "sorted", "(", "list", "(", "set", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "movie_genre", ")", ")", ")", ")", "\n", "\n", "all_occupations", "=", "sorted", "(", "list", "(", "set", "(", "df", "[", "\"occupation\"", "]", ")", ")", ")", "\n", "\n", "dataset", "=", "Dataset", "(", ")", "\n", "dataset", ".", "fit", "(", "\n", "df", "[", "\"userID\"", "]", ",", "\n", "df", "[", "\"itemID\"", "]", ",", "\n", "item_features", "=", "all_movie_genre", ",", "\n", "user_features", "=", "all_occupations", ",", "\n", ")", "\n", "\n", "item_features", "=", "dataset", ".", "build_item_features", "(", "\n", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "zip", "(", "df", ".", "itemID", ",", "movie_genre", ")", "\n", ")", "\n", "\n", "user_features", "=", "dataset", ".", "build_user_features", "(", "\n", "(", "x", ",", "[", "y", "]", ")", "for", "x", ",", "y", "in", "zip", "(", "df", ".", "userID", ",", "df", "[", "\"occupation\"", "]", ")", "\n", ")", "\n", "\n", "(", "interactions", ",", "_", ")", "=", "dataset", ".", "build_interactions", "(", "df", ".", "iloc", "[", ":", ",", "0", ":", "3", "]", ".", "values", ")", "\n", "\n", "train_interactions", ",", "test_interactions", "=", "cross_validation", ".", "random_train_test_split", "(", "\n", "interactions", ",", "\n", "test_percentage", "=", "TEST_PERCENTAGE", ",", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "SEEDNO", ")", ",", "\n", ")", "\n", "return", "train_interactions", ",", "test_interactions", ",", "item_features", ",", "user_features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.model": [[90, 93], ["pytest.fixture", "lightfm.LightFM", "numpy.random.RandomState"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "model", "(", ")", ":", "\n", "    ", "return", "LightFM", "(", "loss", "=", "\"warp\"", ",", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "SEEDNO", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.fitting": [[95, 108], ["pytest.fixture", "recommenders.models.lightfm.lightfm_utils.track_model_metrics"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.track_model_metrics"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "fitting", "(", "model", ",", "interactions", ",", "df", ")", ":", "\n", "    ", "train_interactions", ",", "test_interactions", ",", "item_features", ",", "user_features", "=", "interactions", "\n", "output", ",", "fitted_model", "=", "track_model_metrics", "(", "\n", "model", "=", "model", ",", "\n", "train_interactions", "=", "train_interactions", ",", "\n", "test_interactions", "=", "test_interactions", ",", "\n", "user_features", "=", "user_features", ",", "\n", "item_features", "=", "item_features", ",", "\n", "no_epochs", "=", "1", ",", "\n", "show_plot", "=", "False", ",", "\n", ")", "\n", "return", "output", ",", "fitted_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.sim_users": [[110, 116], ["pytest.fixture", "recommenders.models.lightfm.lightfm_utils.similar_users"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.similar_users"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "sim_users", "(", "interactions", ",", "fitting", ")", ":", "\n", "    ", "_", ",", "_", ",", "_", ",", "user_features", "=", "interactions", "\n", "_", ",", "fitted_model", "=", "fitting", "\n", "return", "similar_users", "(", "\n", "user_id", "=", "TEST_USER_ID", ",", "user_features", "=", "user_features", ",", "model", "=", "fitted_model", ",", "N", "=", "5", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.sim_items": [[119, 125], ["pytest.fixture", "recommenders.models.lightfm.lightfm_utils.similar_items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.similar_items"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "sim_items", "(", "interactions", ",", "fitting", ")", ":", "\n", "    ", "_", ",", "_", ",", "item_features", ",", "_", "=", "interactions", "\n", "_", ",", "fitted_model", "=", "fitting", "\n", "return", "similar_items", "(", "\n", "item_id", "=", "TEST_ITEM_ID", ",", "item_features", "=", "item_features", ",", "model", "=", "fitted_model", ",", "N", "=", "5", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.test_interactions": [[128, 134], ["None"], "function", ["None"], ["", "def", "test_interactions", "(", "interactions", ")", ":", "\n", "    ", "train_interactions", ",", "test_interactions", ",", "item_features", ",", "user_features", "=", "interactions", "\n", "assert", "train_interactions", ".", "shape", "==", "(", "10", ",", "10", ")", "\n", "assert", "test_interactions", ".", "shape", "==", "(", "10", ",", "10", ")", "\n", "assert", "item_features", ".", "shape", "==", "(", "10", ",", "19", ")", "\n", "assert", "user_features", ".", "shape", "==", "(", "10", ",", "17", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.test_fitting": [[136, 149], ["numpy.array", "numpy.testing.assert_array_equal"], "function", ["None"], ["", "def", "test_fitting", "(", "fitting", ")", ":", "\n", "    ", "output", ",", "_", "=", "fitting", "\n", "assert", "output", ".", "shape", "==", "(", "4", ",", "4", ")", "\n", "target", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "0", ",", "0.10000000894069672", ",", "\"train\"", ",", "\"Precision\"", "]", ",", "\n", "[", "0", ",", "0.10000000149011612", ",", "\"test\"", ",", "\"Precision\"", "]", ",", "\n", "[", "0", ",", "1.0", ",", "\"train\"", ",", "\"Recall\"", "]", ",", "\n", "[", "0", ",", "1.0", ",", "\"test\"", ",", "\"Recall\"", "]", ",", "\n", "]", ",", "\n", "dtype", "=", "\"object\"", ",", "\n", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "output", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.test_sim_users": [[151, 153], ["None"], "function", ["None"], ["", "def", "test_sim_users", "(", "sim_users", ")", ":", "\n", "    ", "assert", "sim_users", ".", "shape", "==", "(", "5", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_lightfm_utils.test_sim_items": [[155, 157], ["None"], "function", ["None"], ["", "def", "test_sim_items", "(", "sim_items", ")", ":", "\n", "    ", "assert", "sim_items", ".", "shape", "==", "(", "5", ",", "2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._csv_reader_url": [[18, 22], ["urllib.request.urlopen", "csv.reader", "codecs.iterdecode"], "function", ["None"], ["def", "_csv_reader_url", "(", "url", ",", "delimiter", "=", "\",\"", ",", "encoding", "=", "\"utf-8\"", ")", ":", "\n", "    ", "ftpstream", "=", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "\n", "csvfile", "=", "csv", ".", "reader", "(", "codecs", ".", "iterdecode", "(", "ftpstream", ",", "encoding", ")", ",", "delimiter", "=", "delimiter", ")", "\n", "return", "csvfile", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.load_affinity": [[24, 30], ["test_sar_singlenode._csv_reader_url", "numpy.array", "next", "next"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._csv_reader_url"], ["", "def", "load_affinity", "(", "file", ")", ":", "\n", "    ", "\"\"\"Loads user affinities from test dataset\"\"\"", "\n", "reader", "=", "_csv_reader_url", "(", "file", ")", "\n", "items", "=", "next", "(", "reader", ")", "[", "1", ":", "]", "\n", "affinities", "=", "np", ".", "array", "(", "next", "(", "reader", ")", "[", "1", ":", "]", ")", "\n", "return", "affinities", ",", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.load_userpred": [[32, 40], ["test_sar_singlenode._csv_reader_url", "next", "next", "numpy.array", "float"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._csv_reader_url"], ["", "def", "load_userpred", "(", "file", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"Loads test predicted items and their SAR scores\"\"\"", "\n", "reader", "=", "_csv_reader_url", "(", "file", ")", "\n", "next", "(", "reader", ")", "\n", "values", "=", "next", "(", "reader", ")", "\n", "items", "=", "values", "[", "1", ":", "(", "k", "+", "1", ")", "]", "\n", "scores", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "values", "[", "(", "k", "+", "1", ")", ":", "]", "]", ")", "\n", "return", "items", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.read_matrix": [[42, 62], ["test_sar_singlenode._csv_reader_url", "numpy.array", "next"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._csv_reader_url"], ["", "def", "read_matrix", "(", "file", ",", "row_map", "=", "None", ",", "col_map", "=", "None", ")", ":", "\n", "    ", "\"\"\"read in test matrix and hash it\"\"\"", "\n", "reader", "=", "_csv_reader_url", "(", "file", ")", "\n", "\n", "# skip the header", "\n", "col_ids", "=", "next", "(", "reader", ")", "[", "1", ":", "]", "\n", "row_ids", "=", "[", "]", "\n", "rows", "=", "[", "]", "\n", "for", "row", "in", "reader", ":", "\n", "        ", "rows", "+=", "[", "row", "[", "1", ":", "]", "]", "\n", "row_ids", "+=", "[", "row", "[", "0", "]", "]", "\n", "", "array", "=", "np", ".", "array", "(", "rows", ")", "\n", "\n", "# now map the rows and columns to the right values", "\n", "if", "row_map", "is", "not", "None", "and", "col_map", "is", "not", "None", ":", "\n", "        ", "row_index", "=", "[", "row_map", "[", "x", "]", "for", "x", "in", "row_ids", "]", "\n", "col_index", "=", "[", "col_map", "[", "x", "]", "for", "x", "in", "col_ids", "]", "\n", "array", "=", "array", "[", "row_index", ",", ":", "]", "\n", "array", "=", "array", "[", ":", ",", "col_index", "]", "\n", "", "return", "array", ",", "row_ids", ",", "col_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._rearrange_to_test": [[64, 73], ["None"], "function", ["None"], ["", "def", "_rearrange_to_test", "(", "array", ",", "row_ids", ",", "col_ids", ",", "row_map", ",", "col_map", ")", ":", "\n", "    ", "\"\"\"Rearranges SAR array into test array order\"\"\"", "\n", "if", "row_ids", "is", "not", "None", ":", "\n", "        ", "row_index", "=", "[", "row_map", "[", "x", "]", "for", "x", "in", "row_ids", "]", "\n", "array", "=", "array", "[", "row_index", ",", ":", "]", "\n", "", "if", "col_ids", "is", "not", "None", ":", "\n", "        ", "col_index", "=", "[", "col_map", "[", "x", "]", "for", "x", "in", "col_ids", "]", "\n", "array", "=", "array", "[", ":", ",", "col_index", "]", "\n", "", "return", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_init": [[75, 88], ["recommenders.models.sar.sar_singlenode.SARSingleNode"], "function", ["None"], ["", "def", "test_init", "(", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "similarity_type", "=", "\"jaccard\"", ",", "**", "header", ")", "\n", "\n", "assert", "model", ".", "col_user", "==", "\"UserId\"", "\n", "assert", "model", ".", "col_item", "==", "\"MovieId\"", "\n", "assert", "model", ".", "col_rating", "==", "\"Rating\"", "\n", "assert", "model", ".", "col_timestamp", "==", "\"Timestamp\"", "\n", "assert", "model", ".", "col_prediction", "==", "\"prediction\"", "\n", "assert", "model", ".", "similarity_type", "==", "\"jaccard\"", "\n", "assert", "model", ".", "time_decay_half_life", "==", "2592000", "\n", "assert", "not", "model", ".", "time_decay_flag", "\n", "assert", "model", ".", "time_now", "is", "None", "\n", "assert", "model", ".", "threshold", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_fit": [[90, 99], ["pytest.mark.parametrize", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"similarity_type, timedecay_formula\"", ",", "[", "(", "\"jaccard\"", ",", "False", ")", ",", "(", "\"lift\"", ",", "True", ")", "]", "\n", ")", "\n", "def", "test_fit", "(", "similarity_type", ",", "timedecay_formula", ",", "train_test_dummy_timestamp", ",", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "similarity_type", ",", "timedecay_formula", "=", "timedecay_formula", ",", "**", "header", "\n", ")", "\n", "trainset", ",", "testset", "=", "train_test_dummy_timestamp", "\n", "model", ".", "fit", "(", "trainset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_predict": [[101, 119], ["pytest.mark.parametrize", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "recommenders.models.sar.sar_singlenode.SARSingleNode.predict", "isinstance", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"similarity_type, timedecay_formula\"", ",", "[", "(", "\"jaccard\"", ",", "False", ")", ",", "(", "\"lift\"", ",", "True", ")", "]", "\n", ")", "\n", "def", "test_predict", "(", "\n", "similarity_type", ",", "timedecay_formula", ",", "train_test_dummy_timestamp", ",", "header", "\n", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "similarity_type", ",", "timedecay_formula", "=", "timedecay_formula", ",", "**", "header", "\n", ")", "\n", "trainset", ",", "testset", "=", "train_test_dummy_timestamp", "\n", "model", ".", "fit", "(", "trainset", ")", "\n", "preds", "=", "model", ".", "predict", "(", "testset", ")", "\n", "\n", "assert", "len", "(", "preds", ")", "==", "2", "\n", "assert", "isinstance", "(", "preds", ",", "pd", ".", "DataFrame", ")", "\n", "assert", "preds", "[", "header", "[", "\"col_user\"", "]", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_user\"", "]", "]", ".", "dtype", "\n", "assert", "preds", "[", "header", "[", "\"col_item\"", "]", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_item\"", "]", "]", ".", "dtype", "\n", "assert", "preds", "[", "DEFAULT_PREDICTION_COL", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_rating\"", "]", "]", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_predict_all_items": [[121, 137], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "itertools.product", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.predict", "isinstance", "trainset[].unique", "trainset[].unique", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "test_predict_all_items", "(", "train_test_dummy_timestamp", ",", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "trainset", ",", "_", "=", "train_test_dummy_timestamp", "\n", "model", ".", "fit", "(", "trainset", ")", "\n", "\n", "user_items", "=", "itertools", ".", "product", "(", "\n", "trainset", "[", "header", "[", "\"col_user\"", "]", "]", ".", "unique", "(", ")", ",", "trainset", "[", "header", "[", "\"col_item\"", "]", "]", ".", "unique", "(", ")", "\n", ")", "\n", "testset", "=", "pd", ".", "DataFrame", "(", "user_items", ",", "columns", "=", "[", "header", "[", "\"col_user\"", "]", ",", "header", "[", "\"col_item\"", "]", "]", ")", "\n", "preds", "=", "model", ".", "predict", "(", "testset", ")", "\n", "\n", "assert", "len", "(", "preds", ")", "==", "len", "(", "testset", ")", "\n", "assert", "isinstance", "(", "preds", ",", "pd", ".", "DataFrame", ")", "\n", "assert", "preds", "[", "header", "[", "\"col_user\"", "]", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_user\"", "]", "]", ".", "dtype", "\n", "assert", "preds", "[", "header", "[", "\"col_item\"", "]", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_item\"", "]", "]", ".", "dtype", "\n", "assert", "preds", "[", "DEFAULT_PREDICTION_COL", "]", ".", "dtype", "==", "trainset", "[", "header", "[", "\"col_rating\"", "]", "]", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_sar_item_similarity": [[139, 197], ["pytest.mark.parametrize", "recommenders.models.sar.sar_singlenode.SARSingleNode", "demo_usage_data.drop_duplicates.sort_values", "demo_usage_data.drop_duplicates.drop_duplicates", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "test_sar_singlenode.read_matrix", "test_sar_singlenode._rearrange_to_test", "numpy.array_equal", "test_sar_singlenode._rearrange_to_test", "numpy.allclose", "recommenders.models.sar.sar_singlenode.SARSingleNode.item_similarity.todense", "true_item_similarity.astype", "true_item_similarity.astype", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.read_matrix", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._rearrange_to_test", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._rearrange_to_test"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"threshold,similarity_type,file\"", ",", "\n", "[", "\n", "(", "1", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "\n", "(", "1", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "\n", "(", "1", ",", "\"lift\"", ",", "\"lift\"", ")", ",", "\n", "(", "3", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "\n", "(", "3", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "\n", "(", "3", ",", "\"lift\"", ",", "\"lift\"", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_sar_item_similarity", "(", "\n", "threshold", ",", "similarity_type", ",", "file", ",", "demo_usage_data", ",", "sar_settings", ",", "header", "\n", ")", ":", "\n", "\n", "    ", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "similarity_type", ",", "\n", "timedecay_formula", "=", "False", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "threshold", "=", "threshold", ",", "\n", "**", "header", "\n", ")", "\n", "\n", "# Remove duplicates", "\n", "demo_usage_data", "=", "demo_usage_data", ".", "sort_values", "(", "\n", "header", "[", "\"col_timestamp\"", "]", ",", "ascending", "=", "False", "\n", ")", "\n", "demo_usage_data", "=", "demo_usage_data", ".", "drop_duplicates", "(", "\n", "[", "header", "[", "\"col_user\"", "]", ",", "header", "[", "\"col_item\"", "]", "]", ",", "\n", "keep", "=", "\"first\"", "\n", ")", "\n", "\n", "model", ".", "fit", "(", "demo_usage_data", ")", "\n", "\n", "true_item_similarity", ",", "row_ids", ",", "col_ids", "=", "read_matrix", "(", "\n", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"sim_\"", "+", "file", "+", "str", "(", "threshold", ")", "+", "\".csv\"", "\n", ")", "\n", "\n", "if", "similarity_type", "==", "\"cooccurrence\"", ":", "\n", "        ", "test_item_similarity", "=", "_rearrange_to_test", "(", "\n", "model", ".", "item_similarity", ".", "todense", "(", ")", ",", "\n", "row_ids", ",", "\n", "col_ids", ",", "\n", "model", ".", "item2index", ",", "\n", "model", ".", "item2index", ",", "\n", ")", "\n", "assert", "np", ".", "array_equal", "(", "\n", "true_item_similarity", ".", "astype", "(", "test_item_similarity", ".", "dtype", ")", ",", "\n", "test_item_similarity", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "test_item_similarity", "=", "_rearrange_to_test", "(", "\n", "model", ".", "item_similarity", ",", "row_ids", ",", "col_ids", ",", "model", ".", "item2index", ",", "model", ".", "item2index", "\n", ")", "\n", "assert", "np", ".", "allclose", "(", "\n", "true_item_similarity", ".", "astype", "(", "test_item_similarity", ".", "dtype", ")", ",", "\n", "test_item_similarity", ",", "\n", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_user_affinity": [[200, 246], ["demo_usage_data[].max", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "test_sar_singlenode.load_affinity", "numpy.reshape", "numpy.allclose", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "true_user_affinity.astype.astype", "numpy.allclose", "numpy.array", "true_user_affinity.astype.astype", "pandas.Series", "recommenders.models.sar.sar_singlenode.SARSingleNode.user_affinity[].toarray().flatten", "[].todense", "pandas.read_csv", "demo_usage_data[].max", "recommenders.models.sar.sar_singlenode.SARSingleNode.user_affinity[].toarray", "test_sar_singlenode._rearrange_to_test"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.load_affinity", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode._rearrange_to_test"], ["", "", "def", "test_user_affinity", "(", "demo_usage_data", ",", "sar_settings", ",", "header", ")", ":", "\n", "    ", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "\n", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "\"cooccurrence\"", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "time_now", ",", "\n", "**", "header", "\n", ")", "\n", "model", ".", "fit", "(", "demo_usage_data", ")", "\n", "\n", "true_user_affinity", ",", "items", "=", "load_affinity", "(", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"user_aff.csv\"", ")", "\n", "user_index", "=", "model", ".", "user2index", "[", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "]", "\n", "sar_user_affinity", "=", "np", ".", "reshape", "(", "\n", "np", ".", "array", "(", "\n", "_rearrange_to_test", "(", "\n", "model", ".", "user_affinity", ",", "None", ",", "items", ",", "None", ",", "model", ".", "item2index", "\n", ")", "[", "\n", "user_index", ",", "\n", "]", ".", "todense", "(", ")", "\n", ")", ",", "\n", "-", "1", ",", "\n", ")", "\n", "assert", "np", ".", "allclose", "(", "\n", "true_user_affinity", ".", "astype", "(", "sar_user_affinity", ".", "dtype", ")", ",", "\n", "sar_user_affinity", ",", "\n", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ",", "\n", ")", "\n", "\n", "# Set time_now to 60 days later", "\n", "two_months", "=", "2", "*", "30", "*", "(", "24", "*", "60", "*", "60", ")", "\n", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "\"cooccurrence\"", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "+", "two_months", ",", "\n", "**", "header", "\n", ")", "\n", "model", ".", "fit", "(", "demo_usage_data", ")", "\n", "true_user_affinity_url", "=", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"user_aff_2_months_later.csv\"", "\n", "true_user_affinity", "=", "pd", ".", "read_csv", "(", "true_user_affinity_url", ")", ".", "iloc", "[", ":", ",", "1", ":", "]", "\n", "user_index", "=", "model", ".", "user2index", "[", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "]", "\n", "item_indexes", "=", "pd", ".", "Series", "(", "model", ".", "item2index", ")", "[", "true_user_affinity", ".", "columns", "]", "\n", "sar_user_affinity", "=", "model", ".", "user_affinity", "[", "user_index", "]", ".", "toarray", "(", ")", ".", "flatten", "(", ")", "[", "item_indexes", "]", "\n", "true_user_affinity", "=", "true_user_affinity", ".", "astype", "(", "sar_user_affinity", ".", "dtype", ")", "\n", "assert", "np", ".", "allclose", "(", "true_user_affinity", ",", "sar_user_affinity", ",", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_recommend_k_items": [[248, 285], ["pytest.mark.parametrize", "demo_usage_data[].max", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "test_sar_singlenode.load_userpred", "recommenders.models.sar.sar_singlenode.SARSingleNode.recommend_k_items", "list", "numpy.array", "numpy.allclose", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.load_userpred", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"threshold,similarity_type,file\"", ",", "\n", "[", "(", "3", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "(", "3", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "(", "3", ",", "\"lift\"", ",", "\"lift\"", ")", "]", ",", "\n", ")", "\n", "def", "test_recommend_k_items", "(", "\n", "threshold", ",", "similarity_type", ",", "file", ",", "header", ",", "sar_settings", ",", "demo_usage_data", "\n", ")", ":", "\n", "    ", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "\n", "model", "=", "SARSingleNode", "(", "\n", "similarity_type", "=", "similarity_type", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "time_now", ",", "\n", "threshold", "=", "threshold", ",", "\n", "**", "header", "\n", ")", "\n", "model", ".", "fit", "(", "demo_usage_data", ")", "\n", "\n", "true_items", ",", "true_scores", "=", "load_userpred", "(", "\n", "sar_settings", "[", "\"FILE_DIR\"", "]", "\n", "+", "\"userpred_\"", "\n", "+", "file", "\n", "+", "str", "(", "threshold", ")", "\n", "+", "\"_userid_only.csv\"", "\n", ")", "\n", "test_results", "=", "model", ".", "recommend_k_items", "(", "\n", "demo_usage_data", "[", "\n", "demo_usage_data", "[", "header", "[", "\"col_user\"", "]", "]", "==", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "\n", "]", ",", "\n", "top_k", "=", "10", ",", "\n", "sort_top_k", "=", "True", ",", "\n", "remove_seen", "=", "True", ",", "\n", ")", "\n", "test_items", "=", "list", "(", "test_results", "[", "header", "[", "\"col_item\"", "]", "]", ")", "\n", "test_scores", "=", "np", ".", "array", "(", "test_results", "[", "\"prediction\"", "]", ")", "\n", "assert", "true_items", "==", "test_items", "\n", "assert", "np", ".", "allclose", "(", "true_scores", ",", "test_scores", ",", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_get_item_based_topk": [[287, 334], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "pandas.DataFrame", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "pandas.testing.assert_frame_equal", "pandas.DataFrame", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "pandas.testing.assert_frame_equal", "pandas.DataFrame().set_index", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_item_based_topk().set_index", "pandas.testing.assert_frame_equal", "dict", "dict", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_item_based_topk"], ["", "def", "test_get_item_based_topk", "(", "header", ",", "pandas_dummy", ")", ":", "\n", "\n", "    ", "sar", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "sar", ".", "fit", "(", "pandas_dummy", ")", "\n", "\n", "# test with just items provided", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "0", ",", "0", ",", "0", "]", ",", "MovieId", "=", "[", "8", ",", "7", ",", "6", "]", ",", "prediction", "=", "[", "2.0", ",", "2.0", ",", "2.0", "]", ")", "\n", ")", "\n", "items", "=", "pd", ".", "DataFrame", "(", "{", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "5", ",", "10", "]", "}", ")", "\n", "actual", "=", "sar", ".", "get_item_based_topk", "(", "items", ",", "top_k", "=", "3", ")", "\n", "assert_frame_equal", "(", "expected", ",", "actual", ",", "check_dtype", "=", "False", ")", "\n", "\n", "# test with items and users", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "100", ",", "100", ",", "100", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "MovieId", "=", "[", "8", ",", "7", ",", "6", ",", "4", ",", "3", ",", "10", "]", ",", "\n", "prediction", "=", "[", "2.0", ",", "2.0", ",", "2.0", ",", "2.0", ",", "2.0", ",", "1.0", "]", ",", "\n", ")", "\n", ")", "\n", "items", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "100", ",", "100", ",", "1", ",", "100", ",", "1", ",", "1", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "5", ",", "1", ",", "10", ",", "2", ",", "6", "]", ",", "\n", "}", "\n", ")", "\n", "actual", "=", "sar", ".", "get_item_based_topk", "(", "items", ",", "top_k", "=", "3", ",", "sort_top_k", "=", "True", ")", "\n", "assert_frame_equal", "(", "expected", ",", "actual", ",", "check_dtype", "=", "False", ")", "\n", "\n", "# test with items, users, and ratings", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "100", ",", "100", ",", "100", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "MovieId", "=", "[", "2", ",", "4", ",", "3", ",", "4", ",", "3", ",", "10", "]", ",", "\n", "prediction", "=", "[", "5.0", ",", "5.0", ",", "5.0", ",", "8.0", ",", "8.0", ",", "4.0", "]", ",", "\n", ")", "\n", ")", ".", "set_index", "(", "[", "\"UserId\"", ",", "\"MovieId\"", "]", ")", "\n", "items", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "100", ",", "100", ",", "1", ",", "100", ",", "1", ",", "1", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "5", ",", "1", ",", "10", ",", "2", ",", "6", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "5", ",", "1", ",", "3", ",", "1", ",", "5", ",", "4", "]", ",", "\n", "}", "\n", ")", "\n", "actual", "=", "sar", ".", "get_item_based_topk", "(", "items", ",", "top_k", "=", "3", ")", ".", "set_index", "(", "[", "\"UserId\"", ",", "\"MovieId\"", "]", ")", "\n", "assert_frame_equal", "(", "expected", ",", "actual", ",", "check_like", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_get_popularity_based_topk": [[336, 357], ["pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk", "pandas.testing.assert_frame_equal", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk", "pandas.testing.assert_frame_equal", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk"], ["", "def", "test_get_popularity_based_topk", "(", "header", ")", ":", "\n", "\n", "    ", "train_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "4", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "4", ",", "2", ",", "1", ",", "5", ",", "4", ",", "1", ",", "4", ",", "6", ",", "3", ",", "2", ",", "4", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "2", ",", "3", ",", "1", ",", "2", ",", "3", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "sar", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "sar", ".", "fit", "(", "train_df", ")", "\n", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "dict", "(", "MovieId", "=", "[", "4", ",", "1", ",", "2", "]", ",", "prediction", "=", "[", "4", ",", "3", ",", "2", "]", ")", ")", "\n", "actual", "=", "sar", ".", "get_popularity_based_topk", "(", "top_k", "=", "3", ",", "sort_top_k", "=", "True", ")", "\n", "assert_frame_equal", "(", "expected", ",", "actual", ")", "\n", "\n", "# get most popular users", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "dict", "(", "UserId", "=", "[", "3", ",", "2", ",", "1", "]", ",", "prediction", "=", "[", "5", ",", "4", ",", "2", "]", ")", ")", "\n", "actual", "=", "sar", ".", "get_popularity_based_topk", "(", "top_k", "=", "3", ",", "sort_top_k", "=", "True", ",", "items", "=", "False", ")", "\n", "assert_frame_equal", "(", "expected", ",", "actual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_get_normalized_scores": [[359, 416], ["pandas.DataFrame", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "recommenders.models.sar.sar_singlenode.SARSingleNode.score", "numpy.array", "isinstance", "numpy.isclose().all", "recommenders.models.sar.sar_singlenode.SARSingleNode.score", "numpy.array", "isinstance", "numpy.isclose().all", "numpy.isclose", "numpy.isclose", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score"], ["", "def", "test_get_normalized_scores", "(", "header", ")", ":", "\n", "    ", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "1", ",", "5", ",", "6", ",", "7", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "5.0", ",", "4.0", ",", "3.0", ",", "2.0", ",", "1.0", ",", "5.0", "]", ",", "\n", "header", "[", "\"col_timestamp\"", "]", ":", "[", "1", ",", "20", ",", "30", ",", "400", ",", "50", ",", "60", ",", "70", ",", "800", "]", ",", "\n", "}", "\n", ")", "\n", "test", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "5", ",", "6", ",", "7", ",", "2", ",", "3", ",", "4", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "2.0", ",", "1.0", ",", "5.0", ",", "3.0", ",", "4.0", ",", "5.0", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "model", "=", "SARSingleNode", "(", "**", "header", ",", "timedecay_formula", "=", "True", ",", "normalize", "=", "True", ")", "\n", "model", ".", "fit", "(", "train", ")", "\n", "actual", "=", "model", ".", "score", "(", "test", ",", "remove_seen", "=", "True", ")", "\n", "expected", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "1.23512374", ",", "1.23512374", ",", "1.23512374", "]", ",", "\n", "[", "-", "np", ".", "inf", ",", "1.23512374", ",", "1.23512374", ",", "1.23512374", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", "]", ",", "\n", "]", "\n", ")", "\n", "assert", "actual", ".", "shape", "==", "(", "2", ",", "7", ")", "\n", "assert", "isinstance", "(", "actual", ",", "np", ".", "ndarray", ")", "\n", "assert", "np", ".", "isclose", "(", "expected", ",", "np", ".", "asarray", "(", "actual", ")", ")", ".", "all", "(", ")", "\n", "\n", "actual", "=", "model", ".", "score", "(", "test", ")", "\n", "expected", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "\n", "3.11754872", ",", "\n", "4.29408577", ",", "\n", "4.29408577", ",", "\n", "4.29408577", ",", "\n", "1.23512374", ",", "\n", "1.23512374", ",", "\n", "1.23512374", ",", "\n", "]", ",", "\n", "[", "\n", "2.5293308", ",", "\n", "1.23511758", ",", "\n", "1.23511758", ",", "\n", "1.23511758", ",", "\n", "3.11767458", ",", "\n", "3.11767458", ",", "\n", "3.11767458", ",", "\n", "]", ",", "\n", "]", "\n", ")", "\n", "\n", "assert", "actual", ".", "shape", "==", "(", "2", ",", "7", ")", "\n", "assert", "isinstance", "(", "actual", ",", "np", ".", "ndarray", ")", "\n", "assert", "np", ".", "isclose", "(", "expected", ",", "np", ".", "asarray", "(", "actual", ")", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_match_similarity_type_from_json_file": [[418, 439], ["json.dumps", "json.loads", "json.loads.update", "recommenders.models.sar.sar_singlenode.SARSingleNode", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "test_match_similarity_type_from_json_file", "(", "header", ")", ":", "\n", "# store parameters in json", "\n", "    ", "params_str", "=", "json", ".", "dumps", "(", "{", "'similarity_type'", ":", "'lift'", "}", ")", "\n", "# load parameters in json", "\n", "params", "=", "json", ".", "loads", "(", "params_str", ")", "\n", "\n", "params", ".", "update", "(", "header", ")", "\n", "\n", "model", "=", "SARSingleNode", "(", "**", "params", ")", "\n", "\n", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "1", ",", "5", ",", "6", ",", "7", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "5.0", ",", "4.0", ",", "3.0", ",", "2.0", ",", "1.0", ",", "5.0", "]", ",", "\n", "header", "[", "\"col_timestamp\"", "]", ":", "[", "1", ",", "20", ",", "30", ",", "400", ",", "50", ",", "60", ",", "70", ",", "800", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "# make sure fit still works when similarity type is loaded from a json file", "\n", "model", ".", "fit", "(", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_dataset_with_duplicates": [[441, 452], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "pandas.DataFrame", "pytest.raises", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "test_dataset_with_duplicates", "(", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "1", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "3.0", ",", "4.0", ",", "4.0", "]", "\n", "}", "\n", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "model", ".", "fit", "(", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_get_topk_most_similar_users": [[454, 477], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users", "pandas.DataFrame", "pandas.testing.assert_frame_equal", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users", "pandas.DataFrame", "pandas.testing.assert_frame_equal", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users", "pandas.DataFrame", "pandas.testing.assert_frame_equal", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users"], ["", "", "def", "test_get_topk_most_similar_users", "(", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "# 1, 2, and 4 used the same items, but 1 and 2 have the same ratings also", "\n", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "4", ",", "4", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "1", ",", "2", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "3.0", ",", "4.0", ",", "3.0", ",", "2.0", ",", "1.0", ",", "5.0", ",", "5.0", ",", "1.0", "]", "\n", "}", "\n", ")", "\n", "model", ".", "fit", "(", "train", ")", "\n", "\n", "similar_users", "=", "model", ".", "get_topk_most_similar_users", "(", "user", "=", "1", ",", "top_k", "=", "1", ")", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "dict", "(", "UserId", "=", "[", "2", "]", ",", "prediction", "=", "[", "25.0", "]", ")", ")", "\n", "assert_frame_equal", "(", "expected", ",", "similar_users", ")", "\n", "\n", "similar_users", "=", "model", ".", "get_topk_most_similar_users", "(", "user", "=", "2", ",", "top_k", "=", "1", ")", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "dict", "(", "UserId", "=", "[", "1", "]", ",", "prediction", "=", "[", "25.0", "]", ")", ")", "\n", "assert_frame_equal", "(", "expected", ",", "similar_users", ")", "\n", "\n", "similar_users", "=", "model", ".", "get_topk_most_similar_users", "(", "user", "=", "1", ",", "top_k", "=", "2", ")", "\n", "expected", "=", "pd", ".", "DataFrame", "(", "dict", "(", "UserId", "=", "[", "2", ",", "4", "]", ",", "prediction", "=", "[", "25.0", ",", "19.0", "]", ")", ")", "\n", "assert_frame_equal", "(", "expected", ",", "similar_users", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_item_frequencies": [[479, 490], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "test_item_frequencies", "(", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "4", ",", "4", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "1", ",", "3", ",", "3", ",", "4", ",", "5", ",", "6", ",", "1", ",", "2", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "5.0", ",", "4.0", ",", "3.0", ",", "2.0", ",", "1.0", ",", "5.0", ",", "1.0", ",", "1.0", "]", "\n", "}", "\n", ")", "\n", "model", ".", "fit", "(", "train", ")", "\n", "assert", "model", ".", "item_frequencies", "[", "0", "]", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.models.test_sar_singlenode.test_user_frequencies": [[492, 505], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "pandas.DataFrame", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit", "recommenders.models.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk"], ["", "def", "test_user_frequencies", "(", "header", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "header", ")", "\n", "train", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "4", ",", "4", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "1", ",", "3", ",", "3", ",", "4", ",", "5", ",", "6", ",", "1", ",", "2", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "3.0", ",", "4.0", ",", "5.0", ",", "4.0", ",", "3.0", ",", "2.0", ",", "1.0", ",", "5.0", ",", "1.0", ",", "1.0", "]", "\n", "}", "\n", ")", "\n", "model", ".", "fit", "(", "train", ")", "\n", "# run this method once so that user frequencies are calculated", "\n", "model", ".", "get_popularity_based_topk", "(", "items", "=", "False", ")", "\n", "assert", "model", ".", "user_frequencies", "[", "0", "]", "==", "2", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.__init__": [[34, 113], ["ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "col_user", "=", "constants", ".", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "constants", ".", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "constants", ".", "DEFAULT_RATING_COL", ",", "\n", "col_timestamp", "=", "constants", ".", "DEFAULT_TIMESTAMP_COL", ",", "\n", "col_prediction", "=", "constants", ".", "DEFAULT_PREDICTION_COL", ",", "\n", "similarity_type", "=", "JACCARD", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "None", ",", "\n", "timedecay_formula", "=", "False", ",", "\n", "threshold", "=", "1", ",", "\n", "normalize", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize model parameters\n\n        Args:\n            col_user (str): user column name\n            col_item (str): item column name\n            col_rating (str): rating column name\n            col_timestamp (str): timestamp column name\n            col_prediction (str): prediction column name\n            similarity_type (str): ['cooccurrence', 'jaccard', 'lift'] option for computing item-item similarity\n            time_decay_coefficient (float): number of days till ratings are decayed by 1/2\n            time_now (int | None): current time for time decay calculation\n            timedecay_formula (bool): flag to apply time decay\n            threshold (int): item-item co-occurrences below this threshold will be removed\n            normalize (bool): option for normalizing predictions to scale of original ratings\n        \"\"\"", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_timestamp", "=", "col_timestamp", "\n", "self", ".", "col_prediction", "=", "col_prediction", "\n", "\n", "if", "similarity_type", "not", "in", "[", "COOCCUR", ",", "JACCARD", ",", "LIFT", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Similarity type must be one of [\"cooccurrence\" | \"jaccard\" | \"lift\"]'", "\n", ")", "\n", "", "self", ".", "similarity_type", "=", "similarity_type", "\n", "self", ".", "time_decay_half_life", "=", "(", "\n", "time_decay_coefficient", "*", "24", "*", "60", "*", "60", "\n", ")", "# convert to seconds", "\n", "self", ".", "time_decay_flag", "=", "timedecay_formula", "\n", "self", ".", "time_now", "=", "time_now", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "user_affinity", "=", "None", "\n", "self", ".", "item_similarity", "=", "None", "\n", "self", ".", "item_frequencies", "=", "None", "\n", "self", ".", "user_frequencies", "=", "None", "\n", "\n", "# threshold - items below this number get set to zero in co-occurrence counts", "\n", "if", "self", ".", "threshold", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Threshold cannot be < 1\"", ")", "\n", "\n", "# set flag to capture unity-rating user-affinity matrix for scaling scores", "\n", "", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "col_unity_rating", "=", "\"_unity_rating\"", "\n", "self", ".", "unity_user_affinity", "=", "None", "\n", "\n", "# column for mapping user / item ids to internal indices", "\n", "self", ".", "col_item_id", "=", "\"_indexed_items\"", "\n", "self", ".", "col_user_id", "=", "\"_indexed_users\"", "\n", "\n", "# obtain all the users and items from both training and test data", "\n", "self", ".", "n_users", "=", "None", "\n", "self", ".", "n_items", "=", "None", "\n", "\n", "# The min and max of the rating scale, obtained from the training data.", "\n", "self", ".", "rating_min", "=", "None", "\n", "self", ".", "rating_max", "=", "None", "\n", "\n", "# mapping for item to matrix element", "\n", "self", ".", "user2index", "=", "None", "\n", "self", ".", "item2index", "=", "None", "\n", "\n", "# the opposite of the above maps - map array index to actual string ID", "\n", "self", ".", "index2item", "=", "None", "\n", "self", ".", "index2user", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_affinity_matrix": [[114, 133], ["scipy.sparse.coo_matrix().tocsr", "scipy.sparse.coo_matrix"], "methods", ["None"], ["", "def", "compute_affinity_matrix", "(", "self", ",", "df", ",", "rating_col", ")", ":", "\n", "        ", "\"\"\"Affinity matrix.\n\n        The user-affinity matrix can be constructed by treating the users and items as\n        indices in a sparse matrix, and the events as the data. Here, we're treating\n        the ratings as the event weights.  We convert between different sparse-matrix\n        formats to de-duplicate user-item pairs, otherwise they will get added up.\n\n        Args:\n            df (pandas.DataFrame): Indexed df of users and items\n            rating_col (str): Name of column to use for ratings\n\n        Returns:\n            sparse.csr: Affinity matrix in Compressed Sparse Row (CSR) format.\n        \"\"\"", "\n", "\n", "return", "sparse", ".", "coo_matrix", "(", "\n", "(", "df", "[", "rating_col", "]", ",", "(", "df", "[", "self", ".", "col_user_id", "]", ",", "df", "[", "self", ".", "col_item_id", "]", ")", ")", ",", "\n", "shape", "=", "(", "self", ".", "n_users", ",", "self", ".", "n_items", ")", ",", "\n", ")", ".", "tocsr", "(", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_time_decay": [[135, 159], ["recommenders.utils.python_utils.exponential_decay", "df.groupby().sum().reset_index", "df[].max", "df.groupby().sum", "df.groupby"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.exponential_decay"], ["", "def", "compute_time_decay", "(", "self", ",", "df", ",", "decay_column", ")", ":", "\n", "        ", "\"\"\"Compute time decay on provided column.\n\n        Args:\n            df (pandas.DataFrame): DataFrame of users and items\n            decay_column (str): column to decay\n\n        Returns:\n            pandas.DataFrame: with column decayed\n        \"\"\"", "\n", "\n", "# if time_now is None use the latest time", "\n", "if", "self", ".", "time_now", "is", "None", ":", "\n", "            ", "self", ".", "time_now", "=", "df", "[", "self", ".", "col_timestamp", "]", ".", "max", "(", ")", "\n", "\n", "# apply time decay to each rating", "\n", "", "df", "[", "decay_column", "]", "*=", "exponential_decay", "(", "\n", "value", "=", "df", "[", "self", ".", "col_timestamp", "]", ",", "\n", "max_val", "=", "self", ".", "time_now", ",", "\n", "half_life", "=", "self", ".", "time_decay_half_life", ",", "\n", ")", "\n", "\n", "# group time decayed ratings by user-item and take the sum as the user-item affinity", "\n", "return", "df", ".", "groupby", "(", "[", "self", ".", "col_user", ",", "self", ".", "col_item", "]", ")", ".", "sum", "(", ")", ".", "reset_index", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_cooccurrence_matrix": [[160, 184], ["scipy.sparse.coo_matrix().tocsr", "scipy.sparse.coo_matrix().tocsr.transpose().dot", "item_cooccurrence.multiply.multiply.multiply", "item_cooccurrence.multiply.multiply.astype", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix().tocsr.transpose", "numpy.repeat"], "methods", ["None"], ["", "def", "compute_cooccurrence_matrix", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Co-occurrence matrix.\n\n        The co-occurrence matrix is defined as :math:`C = U^T * U`\n\n        where U is the user_affinity matrix with 1's as values (instead of ratings).\n\n        Args:\n            df (pandas.DataFrame): DataFrame of users and items\n\n        Returns:\n            numpy.ndarray: Co-occurrence matrix\n        \"\"\"", "\n", "user_item_hits", "=", "sparse", ".", "coo_matrix", "(", "\n", "(", "np", ".", "repeat", "(", "1", ",", "df", ".", "shape", "[", "0", "]", ")", ",", "(", "df", "[", "self", ".", "col_user_id", "]", ",", "df", "[", "self", ".", "col_item_id", "]", ")", ")", ",", "\n", "shape", "=", "(", "self", ".", "n_users", ",", "self", ".", "n_items", ")", ",", "\n", ")", ".", "tocsr", "(", ")", "\n", "\n", "item_cooccurrence", "=", "user_item_hits", ".", "transpose", "(", ")", ".", "dot", "(", "user_item_hits", ")", "\n", "item_cooccurrence", "=", "item_cooccurrence", ".", "multiply", "(", "\n", "item_cooccurrence", ">=", "self", ".", "threshold", "\n", ")", "\n", "\n", "return", "item_cooccurrence", ".", "astype", "(", "df", "[", "self", ".", "col_rating", "]", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index": [[185, 203], ["dict", "dict", "len", "len", "enumerate", "enumerate", "df[].unique", "df[].unique", "sar_singlenode.SARSingleNode.index2item.items", "sar_singlenode.SARSingleNode.index2user.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "set_index", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Generate continuous indices for users and items to reduce memory usage.\n\n        Args:\n            df (pandas.DataFrame): dataframe with user and item ids\n        \"\"\"", "\n", "\n", "# generate a map of continuous index values to items", "\n", "self", ".", "index2item", "=", "dict", "(", "enumerate", "(", "df", "[", "self", ".", "col_item", "]", ".", "unique", "(", ")", ")", ")", "\n", "self", ".", "index2user", "=", "dict", "(", "enumerate", "(", "df", "[", "self", ".", "col_user", "]", ".", "unique", "(", ")", ")", ")", "\n", "\n", "# invert the mappings from above", "\n", "self", ".", "item2index", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "index2item", ".", "items", "(", ")", "}", "\n", "self", ".", "user2index", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "index2user", ".", "items", "(", ")", "}", "\n", "\n", "# set values for the total count of users and items", "\n", "self", ".", "n_users", "=", "len", "(", "self", ".", "user2index", ")", "\n", "self", ".", "n_items", "=", "len", "(", "self", ".", "index2item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.fit": [[204, 295], ["df[].duplicated().any", "logger.info", "df[].copy", "logger.info", "temp_df[].apply", "temp_df[].apply", "logger.info", "sar_singlenode.SARSingleNode.compute_affinity_matrix", "logger.info", "sar_singlenode.SARSingleNode.compute_cooccurrence_matrix", "sar_singlenode.SARSingleNode.diagonal", "logger.info", "logger.info", "ValueError", "sar_singlenode.SARSingleNode.set_index", "numpy.issubdtype", "TypeError", "logger.info", "sar_singlenode.SARSingleNode.compute_time_decay", "temp_df[].min", "temp_df[].max", "logger.info", "sar_singlenode.SARSingleNode.compute_affinity_matrix", "logger.info", "df[].duplicated", "sar_singlenode.SARSingleNode.item2index.get", "sar_singlenode.SARSingleNode.user2index.get", "sar_singlenode.SARSingleNode.compute_time_decay", "logger.info", "recommenders.utils.python_utils.jaccard().astype", "logger.info", "recommenders.utils.python_utils.lift().astype", "ValueError", "recommenders.utils.python_utils.jaccard", "recommenders.utils.python_utils.lift"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_affinity_matrix", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_cooccurrence_matrix", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_time_decay", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_affinity_matrix", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.compute_time_decay", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.jaccard", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.lift"], ["", "def", "fit", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Main fit method for SAR.\n\n        .. note::\n\n        Please make sure that `df` has no duplicates.\n\n        Args:\n            df (pandas.DataFrame): User item rating dataframe (without duplicates).\n        \"\"\"", "\n", "select_columns", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", "]", "\n", "if", "self", ".", "time_decay_flag", ":", "\n", "            ", "select_columns", "+=", "[", "self", ".", "col_timestamp", "]", "\n", "\n", "", "if", "df", "[", "select_columns", "]", ".", "duplicated", "(", ")", ".", "any", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"There should not be duplicates in the dataframe\"", ")", "\n", "\n", "# generate continuous indices if this hasn't been done", "\n", "", "if", "self", ".", "index2item", "is", "None", ":", "\n", "            ", "self", ".", "set_index", "(", "df", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Collecting user affinity matrix\"", ")", "\n", "if", "not", "np", ".", "issubdtype", "(", "df", "[", "self", ".", "col_rating", "]", ".", "dtype", ",", "np", ".", "number", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Rating column data type must be numeric\"", ")", "\n", "\n", "# copy the DataFrame to avoid modification of the input", "\n", "", "temp_df", "=", "df", "[", "select_columns", "]", ".", "copy", "(", ")", "\n", "\n", "if", "self", ".", "time_decay_flag", ":", "\n", "            ", "logger", ".", "info", "(", "\"Calculating time-decayed affinities\"", ")", "\n", "temp_df", "=", "self", ".", "compute_time_decay", "(", "df", "=", "temp_df", ",", "decay_column", "=", "self", ".", "col_rating", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Creating index columns\"", ")", "\n", "# add mapping of user and item ids to indices", "\n", "temp_df", ".", "loc", "[", ":", ",", "self", ".", "col_item_id", "]", "=", "temp_df", "[", "self", ".", "col_item", "]", ".", "apply", "(", "\n", "lambda", "item", ":", "self", ".", "item2index", ".", "get", "(", "item", ",", "np", ".", "NaN", ")", "\n", ")", "\n", "temp_df", ".", "loc", "[", ":", ",", "self", ".", "col_user_id", "]", "=", "temp_df", "[", "self", ".", "col_user", "]", ".", "apply", "(", "\n", "lambda", "user", ":", "self", ".", "user2index", ".", "get", "(", "user", ",", "np", ".", "NaN", ")", "\n", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "rating_min", "=", "temp_df", "[", "self", ".", "col_rating", "]", ".", "min", "(", ")", "\n", "self", ".", "rating_max", "=", "temp_df", "[", "self", ".", "col_rating", "]", ".", "max", "(", ")", "\n", "logger", ".", "info", "(", "\"Calculating normalization factors\"", ")", "\n", "temp_df", "[", "self", ".", "col_unity_rating", "]", "=", "1.0", "\n", "if", "self", ".", "time_decay_flag", ":", "\n", "                ", "temp_df", "=", "self", ".", "compute_time_decay", "(", "\n", "df", "=", "temp_df", ",", "decay_column", "=", "self", ".", "col_unity_rating", "\n", ")", "\n", "", "self", ".", "unity_user_affinity", "=", "self", ".", "compute_affinity_matrix", "(", "\n", "df", "=", "temp_df", ",", "rating_col", "=", "self", ".", "col_unity_rating", "\n", ")", "\n", "\n", "# affinity matrix", "\n", "", "logger", ".", "info", "(", "\"Building user affinity sparse matrix\"", ")", "\n", "self", ".", "user_affinity", "=", "self", ".", "compute_affinity_matrix", "(", "\n", "df", "=", "temp_df", ",", "rating_col", "=", "self", ".", "col_rating", "\n", ")", "\n", "\n", "# calculate item co-occurrence", "\n", "logger", ".", "info", "(", "\"Calculating item co-occurrence\"", ")", "\n", "item_cooccurrence", "=", "self", ".", "compute_cooccurrence_matrix", "(", "df", "=", "temp_df", ")", "\n", "\n", "# free up some space", "\n", "del", "temp_df", "\n", "\n", "# creates an array with the frequency of every unique item", "\n", "self", ".", "item_frequencies", "=", "item_cooccurrence", ".", "diagonal", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Calculating item similarity\"", ")", "\n", "if", "self", ".", "similarity_type", "==", "COOCCUR", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using co-occurrence based similarity\"", ")", "\n", "self", ".", "item_similarity", "=", "item_cooccurrence", "\n", "", "elif", "self", ".", "similarity_type", "==", "JACCARD", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using jaccard based similarity\"", ")", "\n", "self", ".", "item_similarity", "=", "jaccard", "(", "item_cooccurrence", ")", ".", "astype", "(", "\n", "df", "[", "self", ".", "col_rating", "]", ".", "dtype", "\n", ")", "\n", "", "elif", "self", ".", "similarity_type", "==", "LIFT", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using lift based similarity\"", ")", "\n", "self", ".", "item_similarity", "=", "lift", "(", "item_cooccurrence", ")", ".", "astype", "(", "\n", "df", "[", "self", ".", "col_rating", "]", ".", "dtype", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown similarity type: {}\"", ".", "format", "(", "self", ".", "similarity_type", ")", ")", "\n", "\n", "# free up some space", "\n", "", "del", "item_cooccurrence", "\n", "\n", "logger", ".", "info", "(", "\"Done training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.score": [[296, 349], ["list", "any", "logger.info", "sar_singlenode.SARSingleNode.user_affinity[].dot", "isinstance", "map", "numpy.isnan", "ValueError", "recommenders.utils.python_utils.rescale.toarray", "sar_singlenode.SARSingleNode.unity_user_affinity[].dot", "recommenders.utils.python_utils.rescale", "logger.info", "test[].unique", "numpy.tile", "numpy.tile", "sar_singlenode.SARSingleNode.user2index.get", "sar_singlenode.SARSingleNode.min", "sar_singlenode.SARSingleNode.max"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.rescale"], ["", "def", "score", "(", "self", ",", "test", ",", "remove_seen", "=", "False", ")", ":", "\n", "        ", "\"\"\"Score all items for test users.\n\n        Args:\n            test (pandas.DataFrame): user to test\n            remove_seen (bool): flag to remove items seen in training from recommendation\n\n        Returns:\n            numpy.ndarray: Value of interest of all items for the users.\n        \"\"\"", "\n", "\n", "# get user / item indices from test set", "\n", "user_ids", "=", "list", "(", "\n", "map", "(", "\n", "lambda", "user", ":", "self", ".", "user2index", ".", "get", "(", "user", ",", "np", ".", "NaN", ")", ",", "\n", "test", "[", "self", ".", "col_user", "]", ".", "unique", "(", ")", ",", "\n", ")", "\n", ")", "\n", "if", "any", "(", "np", ".", "isnan", "(", "user_ids", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"SAR cannot score users that are not in the training set\"", ")", "\n", "\n", "# calculate raw scores with a matrix multiplication", "\n", "", "logger", ".", "info", "(", "\"Calculating recommendation scores\"", ")", "\n", "test_scores", "=", "self", ".", "user_affinity", "[", "user_ids", ",", ":", "]", ".", "dot", "(", "self", ".", "item_similarity", ")", "\n", "\n", "# ensure we're working with a dense ndarray", "\n", "if", "isinstance", "(", "test_scores", ",", "sparse", ".", "spmatrix", ")", ":", "\n", "            ", "test_scores", "=", "test_scores", ".", "toarray", "(", ")", "\n", "\n", "", "if", "self", ".", "normalize", ":", "\n", "            ", "counts", "=", "self", ".", "unity_user_affinity", "[", "user_ids", ",", ":", "]", ".", "dot", "(", "self", ".", "item_similarity", ")", "\n", "user_min_scores", "=", "(", "\n", "np", ".", "tile", "(", "counts", ".", "min", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "test_scores", ".", "shape", "[", "1", "]", ")", "\n", "*", "self", ".", "rating_min", "\n", ")", "\n", "user_max_scores", "=", "(", "\n", "np", ".", "tile", "(", "counts", ".", "max", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "test_scores", ".", "shape", "[", "1", "]", ")", "\n", "*", "self", ".", "rating_max", "\n", ")", "\n", "test_scores", "=", "rescale", "(", "\n", "test_scores", ",", "\n", "self", ".", "rating_min", ",", "\n", "self", ".", "rating_max", ",", "\n", "user_min_scores", ",", "\n", "user_max_scores", ",", "\n", ")", "\n", "\n", "# remove items in the train set so recommended items are always novel", "\n", "", "if", "remove_seen", ":", "\n", "            ", "logger", ".", "info", "(", "\"Removing seen items\"", ")", "\n", "test_scores", "+=", "self", ".", "user_affinity", "[", "user_ids", ",", ":", "]", "*", "-", "np", ".", "inf", "\n", "\n", "", "return", "test_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk": [[350, 383], ["numpy.array", "logger.info", "recommenders.utils.python_utils.get_top_k_scored_items", "pandas.DataFrame", "sar_singlenode.SARSingleNode.user_affinity.getnnz().astype", "top_scores.flatten", "sar_singlenode.SARSingleNode.user_affinity.getnnz", "top_components.flatten"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "get_popularity_based_topk", "(", "self", ",", "top_k", "=", "10", ",", "sort_top_k", "=", "True", ",", "items", "=", "True", ")", ":", "\n", "        ", "\"\"\"Get top K most frequently occurring items across all users.\n\n        Args:\n            top_k (int): number of top items to recommend.\n            sort_top_k (bool): flag to sort top k results.\n            items (bool): if false, return most frequent users instead\n\n        Returns:\n            pandas.DataFrame: top k most popular items.\n        \"\"\"", "\n", "if", "items", ":", "\n", "            ", "frequencies", "=", "self", ".", "item_frequencies", "\n", "col", "=", "self", ".", "col_item", "\n", "idx", "=", "self", ".", "index2item", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "user_frequencies", "is", "None", ":", "\n", "                ", "self", ".", "user_frequencies", "=", "self", ".", "user_affinity", ".", "getnnz", "(", "axis", "=", "1", ")", ".", "astype", "(", "\"int64\"", ")", "\n", "", "frequencies", "=", "self", ".", "user_frequencies", "\n", "col", "=", "self", ".", "col_user", "\n", "idx", "=", "self", ".", "index2user", "\n", "\n", "", "test_scores", "=", "np", ".", "array", "(", "[", "frequencies", "]", ")", "\n", "\n", "logger", ".", "info", "(", "\"Getting top K\"", ")", "\n", "top_components", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "test_scores", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "\n", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "col", ":", "[", "idx", "[", "item", "]", "for", "item", "in", "top_components", ".", "flatten", "(", ")", "]", ",", "\n", "self", ".", "col_prediction", ":", "top_scores", ".", "flatten", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_item_based_topk": [[386, 461], ["numpy.asarray", "scipy.sparse.coo_matrix().tocsr", "scipy.sparse.coo_matrix().tocsr.dot", "recommenders.utils.python_utils.get_top_k_scored_items", "pandas.DataFrame", "pandas.DataFrame.replace().dropna", "list", "pandas.Series", "pandas.Series.map", "pandas.Series", "map", "numpy.ones_like", "numpy.zeros_like", "pd.Series.map.drop_duplicates", "scipy.sparse.coo_matrix", "numpy.repeat", "top_scores.flatten", "pandas.DataFrame.replace", "enumerate", "sar_singlenode.SARSingleNode.item2index.get", "items[].unique", "pandas.Series.drop_duplicates", "top_items.flatten"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "get_item_based_topk", "(", "self", ",", "items", ",", "top_k", "=", "10", ",", "sort_top_k", "=", "True", ")", ":", "\n", "        ", "\"\"\"Get top K similar items to provided seed items based on similarity metric defined.\n        This method will take a set of items and use them to recommend the most similar items to that set\n        based on the similarity matrix fit during training.\n        This allows recommendations for cold-users (unseen during training), note - the model is not updated.\n\n        The following options are possible based on information provided in the items input:\n        1. Single user or seed of items: only item column (ratings are assumed to be 1)\n        2. Single user or seed of items w/ ratings: item column and rating column\n        3. Separate users or seeds of items: item and user column (user ids are only used to separate item sets)\n        4. Separate users or seeds of items with ratings: item, user and rating columns provided\n\n        Args:\n            items (pandas.DataFrame): DataFrame with item, user (optional), and rating (optional) columns\n            top_k (int): number of top items to recommend\n            sort_top_k (bool): flag to sort top k results\n\n        Returns:\n            pandas.DataFrame: sorted top k recommendation items\n        \"\"\"", "\n", "\n", "# convert item ids to indices", "\n", "item_ids", "=", "np", ".", "asarray", "(", "\n", "list", "(", "\n", "map", "(", "\n", "lambda", "item", ":", "self", ".", "item2index", ".", "get", "(", "item", ",", "np", ".", "NaN", ")", ",", "\n", "items", "[", "self", ".", "col_item", "]", ".", "values", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "# if no ratings were provided assume they are all 1", "\n", "if", "self", ".", "col_rating", "in", "items", ".", "columns", ":", "\n", "            ", "ratings", "=", "items", "[", "self", ".", "col_rating", "]", "\n", "", "else", ":", "\n", "            ", "ratings", "=", "pd", ".", "Series", "(", "np", ".", "ones_like", "(", "item_ids", ")", ")", "\n", "\n", "# create local map of user ids", "\n", "", "if", "self", ".", "col_user", "in", "items", ".", "columns", ":", "\n", "            ", "test_users", "=", "items", "[", "self", ".", "col_user", "]", "\n", "user2index", "=", "{", "x", "[", "1", "]", ":", "x", "[", "0", "]", "for", "x", "in", "enumerate", "(", "items", "[", "self", ".", "col_user", "]", ".", "unique", "(", ")", ")", "}", "\n", "user_ids", "=", "test_users", ".", "map", "(", "user2index", ")", "\n", "", "else", ":", "\n", "# if no user column exists assume all entries are for a single user", "\n", "            ", "test_users", "=", "pd", ".", "Series", "(", "np", ".", "zeros_like", "(", "item_ids", ")", ")", "\n", "user_ids", "=", "test_users", "\n", "", "n_users", "=", "user_ids", ".", "drop_duplicates", "(", ")", ".", "shape", "[", "0", "]", "\n", "\n", "# generate pseudo user affinity using seed items", "\n", "pseudo_affinity", "=", "sparse", ".", "coo_matrix", "(", "\n", "(", "ratings", ",", "(", "user_ids", ",", "item_ids", ")", ")", ",", "shape", "=", "(", "n_users", ",", "self", ".", "n_items", ")", "\n", ")", ".", "tocsr", "(", ")", "\n", "\n", "# calculate raw scores with a matrix multiplication", "\n", "test_scores", "=", "pseudo_affinity", ".", "dot", "(", "self", ".", "item_similarity", ")", "\n", "\n", "# remove items in the seed set so recommended items are novel", "\n", "test_scores", "[", "user_ids", ",", "item_ids", "]", "=", "-", "np", ".", "inf", "\n", "\n", "top_items", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "test_scores", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "self", ".", "col_user", ":", "np", ".", "repeat", "(", "\n", "test_users", ".", "drop_duplicates", "(", ")", ".", "values", ",", "top_items", ".", "shape", "[", "1", "]", "\n", ")", ",", "\n", "self", ".", "col_item", ":", "[", "self", ".", "index2item", "[", "item", "]", "for", "item", "in", "top_items", ".", "flatten", "(", ")", "]", ",", "\n", "self", ".", "col_prediction", ":", "top_scores", ".", "flatten", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# drop invalid items", "\n", "return", "df", ".", "replace", "(", "-", "np", ".", "inf", ",", "np", ".", "nan", ")", ".", "dropna", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_topk_most_similar_users": [[462, 490], ["sar_singlenode.SARSingleNode.user_affinity[].dot().toarray", "recommenders.utils.python_utils.get_top_k_scored_items", "pandas.DataFrame", "pandas.DataFrame.replace().dropna", "sar_singlenode.SARSingleNode.user_affinity[].dot", "top_scores.flatten", "pandas.DataFrame.replace", "top_items.flatten"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "get_topk_most_similar_users", "(", "self", ",", "user", ",", "top_k", ",", "sort_top_k", "=", "True", ")", ":", "\n", "        ", "\"\"\"Based on user affinity towards items, calculate the most similar users to the given user.\n\n        Args:\n            user (int): user to retrieve most similar users for\n            top_k (int): number of top items to recommend\n            sort_top_k (bool): flag to sort top k results\n\n        Returns:\n            pandas.DataFrame: top k most similar users and their scores\n        \"\"\"", "\n", "user_idx", "=", "self", ".", "user2index", "[", "user", "]", "\n", "similarities", "=", "self", ".", "user_affinity", "[", "user_idx", "]", ".", "dot", "(", "self", ".", "user_affinity", ".", "T", ")", ".", "toarray", "(", ")", "\n", "similarities", "[", "0", ",", "user_idx", "]", "=", "-", "np", ".", "inf", "\n", "\n", "top_items", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "similarities", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "self", ".", "col_user", ":", "[", "self", ".", "index2user", "[", "user", "]", "for", "user", "in", "top_items", ".", "flatten", "(", ")", "]", ",", "\n", "self", ".", "col_prediction", ":", "top_scores", ".", "flatten", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# drop invalid items", "\n", "return", "df", ".", "replace", "(", "-", "np", ".", "inf", ",", "np", ".", "nan", ")", ".", "dropna", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.recommend_k_items": [[491, 522], ["sar_singlenode.SARSingleNode.score", "recommenders.utils.python_utils.get_top_k_scored_items", "pandas.DataFrame", "pandas.DataFrame.replace().dropna", "numpy.repeat", "top_scores.flatten", "pandas.DataFrame.replace", "test[].drop_duplicates", "top_items.flatten"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "recommend_k_items", "(", "self", ",", "test", ",", "top_k", "=", "10", ",", "sort_top_k", "=", "True", ",", "remove_seen", "=", "False", ")", ":", "\n", "        ", "\"\"\"Recommend top K items for all users which are in the test set\n\n        Args:\n            test (pandas.DataFrame): users to test\n            top_k (int): number of top items to recommend\n            sort_top_k (bool): flag to sort top k results\n            remove_seen (bool): flag to remove items seen in training from recommendation\n\n        Returns:\n            pandas.DataFrame: top k recommendation items for each user\n        \"\"\"", "\n", "\n", "test_scores", "=", "self", ".", "score", "(", "test", ",", "remove_seen", "=", "remove_seen", ")", "\n", "\n", "top_items", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "test_scores", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "self", ".", "col_user", ":", "np", ".", "repeat", "(", "\n", "test", "[", "self", ".", "col_user", "]", ".", "drop_duplicates", "(", ")", ".", "values", ",", "top_items", ".", "shape", "[", "1", "]", "\n", ")", ",", "\n", "self", ".", "col_item", ":", "[", "self", ".", "index2item", "[", "item", "]", "for", "item", "in", "top_items", ".", "flatten", "(", ")", "]", ",", "\n", "self", ".", "col_prediction", ":", "top_scores", ".", "flatten", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# drop invalid items", "\n", "return", "df", ".", "replace", "(", "-", "np", ".", "inf", ",", "np", ".", "nan", ")", ".", "dropna", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.predict": [[523, 569], ["sar_singlenode.SARSingleNode.score", "numpy.asarray", "numpy.asarray", "numpy.isnan", "any", "pandas.DataFrame", "list", "list", "logger.warning", "numpy.append", "item_ids.astype.astype.astype", "map", "map", "numpy.zeros", "sar_singlenode.SARSingleNode.user2index.get", "sar_singlenode.SARSingleNode.item2index.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score"], ["", "def", "predict", "(", "self", ",", "test", ")", ":", "\n", "        ", "\"\"\"Output SAR scores for only the users-items pairs which are in the test set\n\n        Args:\n            test (pandas.DataFrame): DataFrame that contains users and items to test\n\n        Returns:\n            pandas.DataFrame: DataFrame contains the prediction results\n        \"\"\"", "\n", "\n", "test_scores", "=", "self", ".", "score", "(", "test", ")", "\n", "user_ids", "=", "np", ".", "asarray", "(", "\n", "list", "(", "\n", "map", "(", "\n", "lambda", "user", ":", "self", ".", "user2index", ".", "get", "(", "user", ",", "np", ".", "NaN", ")", ",", "\n", "test", "[", "self", ".", "col_user", "]", ".", "values", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "# create mapping of new items to zeros", "\n", "item_ids", "=", "np", ".", "asarray", "(", "\n", "list", "(", "\n", "map", "(", "\n", "lambda", "item", ":", "self", ".", "item2index", ".", "get", "(", "item", ",", "np", ".", "NaN", ")", ",", "\n", "test", "[", "self", ".", "col_item", "]", ".", "values", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "nans", "=", "np", ".", "isnan", "(", "item_ids", ")", "\n", "if", "any", "(", "nans", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Items found in test not seen during training, new items will have score of 0\"", "\n", ")", "\n", "test_scores", "=", "np", ".", "append", "(", "test_scores", ",", "np", ".", "zeros", "(", "(", "self", ".", "n_users", ",", "1", ")", ")", ",", "axis", "=", "1", ")", "\n", "item_ids", "[", "nans", "]", "=", "self", ".", "n_items", "\n", "item_ids", "=", "item_ids", ".", "astype", "(", "\"int64\"", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "self", ".", "col_user", ":", "test", "[", "self", ".", "col_user", "]", ".", "values", ",", "\n", "self", ".", "col_item", ":", "test", "[", "self", ".", "col_item", "]", ".", "values", ",", "\n", "self", ".", "col_prediction", ":", "test_scores", "[", "user_ids", ",", "item_ids", "]", ",", "\n", "}", "\n", ")", "\n", "return", "df", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.cornac.cornac_utils.predict": [[14, 48], ["pandas.DataFrame", "getattr", "getattr", "model.rate", "data.itertuples", "uid_map.get", "iid_map.get", "getattr", "len", "getattr", "len"], "function", ["None"], ["def", "predict", "(", "\n", "model", ",", "\n", "data", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Computes predictions of a recommender model from Cornac on the data.\n    Can be used for computing rating metrics like RMSE.\n\n    Args:\n        model (cornac.models.Recommender): A recommender model from Cornac\n        data (pandas.DataFrame): The data on which to predict\n        usercol (str): Name of the user column\n        itemcol (str): Name of the item column\n\n    Returns:\n        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n    \"\"\"", "\n", "uid_map", "=", "model", ".", "train_set", ".", "uid_map", "\n", "iid_map", "=", "model", ".", "train_set", ".", "iid_map", "\n", "predictions", "=", "[", "\n", "[", "\n", "getattr", "(", "row", ",", "usercol", ")", ",", "\n", "getattr", "(", "row", ",", "itemcol", ")", ",", "\n", "model", ".", "rate", "(", "\n", "user_idx", "=", "uid_map", ".", "get", "(", "getattr", "(", "row", ",", "usercol", ")", ",", "len", "(", "uid_map", ")", ")", ",", "\n", "item_idx", "=", "iid_map", ".", "get", "(", "getattr", "(", "row", ",", "itemcol", ")", ",", "len", "(", "iid_map", ")", ")", ",", "\n", ")", ",", "\n", "]", "\n", "for", "row", "in", "data", ".", "itertuples", "(", ")", "\n", "]", "\n", "predictions", "=", "pd", ".", "DataFrame", "(", "data", "=", "predictions", ",", "columns", "=", "[", "usercol", ",", "itemcol", ",", "predcol", "]", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.cornac.cornac_utils.predict_ranking": [[50, 97], ["list", "model.train_set.uid_map.items", "pandas.DataFrame", "model.train_set.iid_map.keys", "users.extend", "items.extend", "preds.extend", "pandas.concat", "pandas.merge", "merged[].drop", "len", "model.score().tolist", "pandas.DataFrame", "model.score", "numpy.ones", "merged[].isnull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score"], ["", "def", "predict_ranking", "(", "\n", "model", ",", "\n", "data", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "remove_seen", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n    It can be used for computing ranking metrics like NDCG.\n\n    Args:\n        model (cornac.models.Recommender): A recommender model from Cornac\n        data (pandas.DataFrame): The data from which to get the users and items\n        usercol (str): Name of the user column\n        itemcol (str): Name of the item column\n        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n\n    Returns:\n        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n    \"\"\"", "\n", "users", ",", "items", ",", "preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "item", "=", "list", "(", "model", ".", "train_set", ".", "iid_map", ".", "keys", "(", ")", ")", "\n", "for", "uid", ",", "user_idx", "in", "model", ".", "train_set", ".", "uid_map", ".", "items", "(", ")", ":", "\n", "        ", "user", "=", "[", "uid", "]", "*", "len", "(", "item", ")", "\n", "users", ".", "extend", "(", "user", ")", "\n", "items", ".", "extend", "(", "item", ")", "\n", "preds", ".", "extend", "(", "model", ".", "score", "(", "user_idx", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "all_predictions", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "usercol", ":", "users", ",", "itemcol", ":", "items", ",", "predcol", ":", "preds", "}", "\n", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "        ", "tempdf", "=", "pd", ".", "concat", "(", "\n", "[", "\n", "data", "[", "[", "usercol", ",", "itemcol", "]", "]", ",", "\n", "pd", ".", "DataFrame", "(", "\n", "data", "=", "np", ".", "ones", "(", "data", ".", "shape", "[", "0", "]", ")", ",", "columns", "=", "[", "\"dummycol\"", "]", ",", "index", "=", "data", ".", "index", "\n", ")", ",", "\n", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "merged", "=", "pd", ".", "merge", "(", "tempdf", ",", "all_predictions", ",", "on", "=", "[", "usercol", ",", "itemcol", "]", ",", "how", "=", "\"outer\"", ")", "\n", "return", "merged", "[", "merged", "[", "\"dummycol\"", "]", ".", "isnull", "(", ")", "]", ".", "drop", "(", "\"dummycol\"", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "return", "all_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF.__init__": [[27, 92], ["tensorflow.compat.v1.set_random_seed", "numpy.random.seed", "model_type.lower", "ncf_singlenode.NCF._create_model", "tensorflow.compat.v1.GPUOptions", "tensorflow.compat.v1.Session", "ncf_singlenode.NCF.sess.run", "ValueError", "tensorflow.compat.v1.global_variables_initializer", "tensorflow.compat.v1.ConfigProto"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._create_model"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_users", ",", "\n", "n_items", ",", "\n", "model_type", "=", "\"NeuMF\"", ",", "\n", "n_factors", "=", "8", ",", "\n", "layer_sizes", "=", "[", "16", ",", "8", ",", "4", "]", ",", "\n", "n_epochs", "=", "50", ",", "\n", "batch_size", "=", "64", ",", "\n", "learning_rate", "=", "5e-3", ",", "\n", "verbose", "=", "1", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            n_users (int): Number of users in the dataset.\n            n_items (int): Number of items in the dataset.\n            model_type (str): Model type.\n            n_factors (int): Dimension of latent space.\n            layer_sizes (list): Number of layers for MLP.\n            n_epochs (int): Number of epochs for training.\n            batch_size (int): Batch size.\n            learning_rate (float): Learning rate.\n            verbose (int): Whether to show the training output or not.\n            seed (int): Seed.\n\n        \"\"\"", "\n", "\n", "# seed", "\n", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "\n", "self", ".", "n_users", "=", "n_users", "\n", "self", ".", "n_items", "=", "n_items", "\n", "self", ".", "model_type", "=", "model_type", ".", "lower", "(", ")", "\n", "self", ".", "n_factors", "=", "n_factors", "\n", "self", ".", "layer_sizes", "=", "layer_sizes", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "\n", "# check model type", "\n", "model_options", "=", "[", "\"gmf\"", ",", "\"mlp\"", ",", "\"neumf\"", "]", "\n", "if", "self", ".", "model_type", "not", "in", "model_options", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong model type, please select one of this list: {}\"", ".", "format", "(", "\n", "model_options", "\n", ")", "\n", ")", "\n", "\n", "# ncf layer input size", "\n", "", "self", ".", "ncf_layer_size", "=", "n_factors", "+", "layer_sizes", "[", "-", "1", "]", "\n", "# create ncf model", "\n", "self", ".", "_create_model", "(", ")", "\n", "# set GPU use with demand growth", "\n", "gpu_options", "=", "tf", ".", "compat", ".", "v1", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", "# set TF Session", "\n", "self", ".", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "\n", "config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", ")", "\n", "# parameters initialization", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._create_model": [[93, 272], ["tensorflow.compat.v1.reset_default_graph", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.variable_scope", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.compat.v1.variable_scope", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.compat.v1.variable_scope", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.losses.log_loss", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.train.AdamOptimizer().minimize", "tensorflow.random.truncated_normal", "tensorflow.random.truncated_normal", "tensorflow.random.truncated_normal", "tensorflow.random.truncated_normal", "tf_slim.layers.fully_connected", "tf_slim.layers.fully_connected", "tensorflow.sigmoid", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tf_slim.layers.fully_connected", "tensorflow.sigmoid", "tensorflow.compat.v1.train.AdamOptimizer", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.concat", "tf_slim.layers.fully_connected", "tensorflow.sigmoid", "int", "int", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.compat.v1.keras.initializers.VarianceScaling"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["", "def", "_create_model", "(", "\n", "self", ",", "\n", ")", ":", "\n", "# reset graph", "\n", "        ", "tf", ".", "compat", ".", "v1", ".", "reset_default_graph", "(", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"input_data\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# input: index of users, items and ground truth", "\n", "            ", "self", ".", "user_input", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "1", "]", ")", "\n", "self", ".", "item_input", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "1", "]", ")", "\n", "self", ".", "labels", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"embedding\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# set embedding table", "\n", "            ", "self", ".", "embedding_gmf_P", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "truncated_normal", "(", "\n", "shape", "=", "[", "self", ".", "n_users", ",", "self", ".", "n_factors", "]", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "0.01", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", "name", "=", "\"embedding_gmf_P\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "self", ".", "embedding_gmf_Q", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "truncated_normal", "(", "\n", "shape", "=", "[", "self", ".", "n_items", ",", "self", ".", "n_factors", "]", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "0.01", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", "name", "=", "\"embedding_gmf_Q\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "# set embedding table", "\n", "self", ".", "embedding_mlp_P", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "truncated_normal", "(", "\n", "shape", "=", "[", "self", ".", "n_users", ",", "int", "(", "self", ".", "layer_sizes", "[", "0", "]", "/", "2", ")", "]", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "0.01", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", "name", "=", "\"embedding_mlp_P\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "self", ".", "embedding_mlp_Q", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "random", ".", "truncated_normal", "(", "\n", "shape", "=", "[", "self", ".", "n_items", ",", "int", "(", "self", ".", "layer_sizes", "[", "0", "]", "/", "2", ")", "]", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "0.01", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", "name", "=", "\"embedding_mlp_Q\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"gmf\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# get user embedding p and item embedding q", "\n", "            ", "self", ".", "gmf_p", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "embedding_gmf_P", ",", "ids", "=", "self", ".", "user_input", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "self", ".", "gmf_q", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "embedding_gmf_Q", ",", "ids", "=", "self", ".", "item_input", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "# get gmf vector", "\n", "self", ".", "gmf_vector", "=", "self", ".", "gmf_p", "*", "self", ".", "gmf_q", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"mlp\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# get user embedding p and item embedding q", "\n", "            ", "self", ".", "mlp_p", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "embedding_mlp_P", ",", "ids", "=", "self", ".", "user_input", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "self", ".", "mlp_q", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "embedding_mlp_Q", ",", "ids", "=", "self", ".", "item_input", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "# concatenate user and item vector", "\n", "output", "=", "tf", ".", "concat", "(", "[", "self", ".", "mlp_p", ",", "self", ".", "mlp_q", "]", ",", "1", ")", "\n", "\n", "# MLP Layers", "\n", "for", "layer_size", "in", "self", ".", "layer_sizes", "[", "1", ":", "]", ":", "\n", "                ", "output", "=", "slim", ".", "layers", ".", "fully_connected", "(", "\n", "output", ",", "\n", "num_outputs", "=", "layer_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "", "self", ".", "mlp_vector", "=", "output", "\n", "\n", "# self.output = tf.sigmoid(tf.reduce_sum(self.mlp_vector, axis=1, keepdims=True))", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"ncf\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "            ", "if", "self", ".", "model_type", "==", "\"gmf\"", ":", "\n", "# GMF only", "\n", "                ", "output", "=", "slim", ".", "layers", ".", "fully_connected", "(", "\n", "self", ".", "gmf_vector", ",", "\n", "num_outputs", "=", "1", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "output", "=", "tf", ".", "sigmoid", "(", "output", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"mlp\"", ":", "\n", "# MLP only", "\n", "                ", "output", "=", "slim", ".", "layers", ".", "fully_connected", "(", "\n", "self", ".", "mlp_vector", ",", "\n", "num_outputs", "=", "1", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "output", "=", "tf", ".", "sigmoid", "(", "output", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"neumf\"", ":", "\n", "# concatenate GMF and MLP vector", "\n", "                ", "self", ".", "ncf_vector", "=", "tf", ".", "concat", "(", "[", "self", ".", "gmf_vector", ",", "self", ".", "mlp_vector", "]", ",", "1", ")", "\n", "# get predicted rating score", "\n", "output", "=", "slim", ".", "layers", ".", "fully_connected", "(", "\n", "self", ".", "ncf_vector", ",", "\n", "num_outputs", "=", "1", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "output", "=", "tf", ".", "sigmoid", "(", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"loss\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# set loss function", "\n", "            ", "self", ".", "loss", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "log_loss", "(", "self", ".", "labels", ",", "self", ".", "output", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"optimizer\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# set optimizer", "\n", "            ", "self", ".", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "self", ".", "learning_rate", "\n", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF.save": [[273, 285], ["tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.save", "os.path.exists", "os.makedirs", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "", "def", "save", "(", "self", ",", "dir_name", ")", ":", "\n", "        ", "\"\"\"Save model parameters in `dir_name`\n\n        Args:\n            dir_name (str): directory name, which should be a folder name instead of file name\n                we will create a new directory if not existing.\n        \"\"\"", "\n", "# save trained model", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dir_name", ")", "\n", "", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF.load": [[286, 324], ["tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "os.path.join", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "os.path.join", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "os.path.join", "ncf_singlenode.NCF._load_neumf"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._load_neumf"], ["", "def", "load", "(", "self", ",", "gmf_dir", "=", "None", ",", "mlp_dir", "=", "None", ",", "neumf_dir", "=", "None", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Load model parameters for further use.\n\n        GMF model --> load parameters in `gmf_dir`\n\n        MLP model --> load parameters in `mlp_dir`\n\n        NeuMF model --> load parameters in `neumf_dir` or in `gmf_dir` and `mlp_dir`\n\n        Args:\n            gmf_dir (str): Directory name for GMF model.\n            mlp_dir (str): Directory name for MLP model.\n            neumf_dir (str): Directory name for neumf model.\n            alpha (float): the concatenation hyper-parameter for gmf and mlp output layer.\n\n        Returns:\n            object: Load parameters in this model.\n        \"\"\"", "\n", "\n", "# load pre-trained model", "\n", "if", "self", ".", "model_type", "==", "\"gmf\"", "and", "gmf_dir", "is", "not", "None", ":", "\n", "            ", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "gmf_dir", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"mlp\"", "and", "mlp_dir", "is", "not", "None", ":", "\n", "            ", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "mlp_dir", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"neumf\"", "and", "neumf_dir", "is", "not", "None", ":", "\n", "            ", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "neumf_dir", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"neumf\"", "and", "gmf_dir", "is", "not", "None", "and", "mlp_dir", "is", "not", "None", ":", "\n", "# load neumf using gmf and mlp", "\n", "            ", "self", ".", "_load_neumf", "(", "gmf_dir", ",", "mlp_dir", ",", "alpha", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._load_neumf": [[325, 368], ["tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "tensorflow.compat.v1.get_collection", "tensorflow.train.load_variable", "tensorflow.train.load_variable", "tensorflow.compat.v1.assign", "ncf_singlenode.NCF.sess.run", "os.path.join", "os.path.join", "len", "tensorflow.concat"], "methods", ["None"], ["", "", "def", "_load_neumf", "(", "self", ",", "gmf_dir", ",", "mlp_dir", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Load gmf and mlp model parameters for further use in NeuMF.\n        NeuMF model --> load parameters in `gmf_dir` and `mlp_dir`\n        \"\"\"", "\n", "# load gmf part", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "# get variables with 'gmf'", "\n", "var_flow_restore", "=", "[", "\n", "val", "for", "val", "in", "variables", "if", "\"gmf\"", "in", "val", ".", "name", "and", "\"ncf\"", "not", "in", "val", ".", "name", "\n", "]", "\n", "# load 'gmf' variable", "\n", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "var_flow_restore", ")", "\n", "# restore", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "gmf_dir", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n", "# load mlp part", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "# get variables with 'gmf'", "\n", "var_flow_restore", "=", "[", "\n", "val", "for", "val", "in", "variables", "if", "\"mlp\"", "in", "val", ".", "name", "and", "\"ncf\"", "not", "in", "val", ".", "name", "\n", "]", "\n", "# load 'gmf' variable", "\n", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "var_flow_restore", ")", "\n", "# restore", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "mlp_dir", ",", "MODEL_CHECKPOINT", ")", ")", "\n", "\n", "# concat pretrain h_from_gmf and h_from_mlp", "\n", "vars_list", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "\"ncf\"", "\n", ")", "\n", "\n", "assert", "len", "(", "vars_list", ")", "==", "1", "\n", "ncf_fc", "=", "vars_list", "[", "0", "]", "\n", "\n", "# get weight from gmf and mlp", "\n", "gmf_fc", "=", "tf", ".", "train", ".", "load_variable", "(", "gmf_dir", ",", "ncf_fc", ".", "name", ")", "\n", "mlp_fc", "=", "tf", ".", "train", ".", "load_variable", "(", "mlp_dir", ",", "ncf_fc", ".", "name", ")", "\n", "\n", "# load fc layer by tf.concat", "\n", "assign_op", "=", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "\n", "ncf_fc", ",", "tf", ".", "concat", "(", "[", "alpha", "*", "gmf_fc", ",", "(", "1", "-", "alpha", ")", "*", "mlp_fc", "]", ",", "axis", "=", "0", ")", "\n", ")", "\n", "self", ".", "sess", ".", "run", "(", "assign_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF.fit": [[369, 414], ["range", "time.time.time", "data.train_loader", "numpy.array", "numpy.array", "numpy.array", "ncf_singlenode.NCF.sess.run", "train_loss.append", "time.time.time", "logger.info", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.train_loader"], ["", "def", "fit", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Fit model with training data\n\n        Args:\n            data (NCFDataset): initilized Dataset in ./dataset.py\n        \"\"\"", "\n", "\n", "# get user and item mapping dict", "\n", "self", ".", "user2id", "=", "data", ".", "user2id", "\n", "self", ".", "item2id", "=", "data", ".", "item2id", "\n", "self", ".", "id2user", "=", "data", ".", "id2user", "\n", "self", ".", "id2item", "=", "data", ".", "id2item", "\n", "\n", "# loop for n_epochs", "\n", "for", "epoch_count", "in", "range", "(", "1", ",", "self", ".", "n_epochs", "+", "1", ")", ":", "\n", "\n", "# negative sampling for training", "\n", "            ", "train_begin", "=", "time", "(", ")", "\n", "\n", "# initialize", "\n", "train_loss", "=", "[", "]", "\n", "\n", "# calculate loss and update NCF parameters", "\n", "for", "user_input", ",", "item_input", ",", "labels", "in", "data", ".", "train_loader", "(", "self", ".", "batch_size", ")", ":", "\n", "\n", "                ", "user_input", "=", "np", ".", "array", "(", "[", "self", ".", "user2id", "[", "x", "]", "for", "x", "in", "user_input", "]", ")", "\n", "item_input", "=", "np", ".", "array", "(", "[", "self", ".", "item2id", "[", "x", "]", "for", "x", "in", "item_input", "]", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "user_input", ":", "user_input", "[", "...", ",", "None", "]", ",", "\n", "self", ".", "item_input", ":", "item_input", "[", "...", ",", "None", "]", ",", "\n", "self", ".", "labels", ":", "labels", "[", "...", ",", "None", "]", ",", "\n", "}", "\n", "\n", "# get loss and execute optimization", "\n", "loss", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "optimizer", "]", ",", "feed_dict", ")", "\n", "train_loss", ".", "append", "(", "loss", ")", "\n", "", "train_time", "=", "time", "(", ")", "-", "train_begin", "\n", "\n", "# output every self.verbose", "\n", "if", "self", ".", "verbose", "and", "epoch_count", "%", "self", ".", "verbose", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Epoch %d [%.2fs]: train_loss = %.6f \"", "\n", "%", "(", "epoch_count", ",", "train_time", ",", "sum", "(", "train_loss", ")", "/", "len", "(", "train_loss", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF.predict": [[416, 436], ["ncf_singlenode.NCF._predict", "list", "ncf_singlenode.NCF._predict", "float", "ncf_singlenode.NCF.reshape", "numpy.array", "numpy.array", "ncf_singlenode.NCF.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._predict", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._predict"], ["", "", "", "def", "predict", "(", "self", ",", "user_input", ",", "item_input", ",", "is_list", "=", "False", ")", ":", "\n", "        ", "\"\"\"Predict function of this trained model\n\n        Args:\n            user_input (list or element of list): userID or userID list\n            item_input (list or element of list): itemID or itemID list\n            is_list (bool): if true, the input is list type\n                noting that list-wise type prediction is faster than element-wise's.\n\n        Returns:\n            list or float: A list of predicted rating or predicted rating score.\n        \"\"\"", "\n", "\n", "if", "is_list", ":", "\n", "            ", "output", "=", "self", ".", "_predict", "(", "user_input", ",", "item_input", ")", "\n", "return", "list", "(", "output", ".", "reshape", "(", "-", "1", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_predict", "(", "np", ".", "array", "(", "[", "user_input", "]", ")", ",", "np", ".", "array", "(", "[", "item_input", "]", ")", ")", "\n", "return", "float", "(", "output", ".", "reshape", "(", "-", "1", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.ncf_singlenode.NCF._predict": [[437, 451], ["numpy.array", "numpy.array", "ncf_singlenode.NCF.sess.run"], "methods", ["None"], ["", "", "def", "_predict", "(", "self", ",", "user_input", ",", "item_input", ")", ":", "\n", "\n", "# index converting", "\n", "        ", "user_input", "=", "np", ".", "array", "(", "[", "self", ".", "user2id", "[", "x", "]", "for", "x", "in", "user_input", "]", ")", "\n", "item_input", "=", "np", ".", "array", "(", "[", "self", ".", "item2id", "[", "x", "]", "for", "x", "in", "item_input", "]", ")", "\n", "\n", "# get feed dict", "\n", "feed_dict", "=", "{", "\n", "self", ".", "user_input", ":", "user_input", "[", "...", ",", "None", "]", ",", "\n", "self", ".", "item_input", ":", "item_input", "[", "...", ",", "None", "]", ",", "\n", "}", "\n", "\n", "# calculate predicted score", "\n", "return", "self", ".", "sess", ".", "run", "(", "self", ".", "output", ",", "feed_dict", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.__init__": [[43, 68], ["dataset.DataFile._init_data", "dataset.DataFile.expected_fields.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._init_data"], ["def", "__init__", "(", "\n", "self", ",", "filename", ",", "col_user", ",", "col_item", ",", "col_rating", ",", "col_test_batch", "=", "None", ",", "binary", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            filename (str): Path to file to be processed.\n            col_user (str): User column name.\n            col_item (str): Item column name.\n            col_rating (str): Rating column name.\n            col_test_batch (str): Test batch column name.\n            binary (bool): If true, set rating > 0 to rating = 1.\n        \"\"\"", "\n", "self", ".", "filename", "=", "filename", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_test_batch", "=", "col_test_batch", "\n", "self", ".", "expected_fields", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", "]", "\n", "if", "self", ".", "col_test_batch", "is", "not", "None", ":", "\n", "            ", "self", ".", "expected_fields", ".", "append", "(", "self", ".", "col_test_batch", ")", "\n", "", "self", ".", "binary", "=", "binary", "\n", "self", ".", "_init_data", "(", ")", "\n", "self", ".", "id2user", "=", "{", "self", ".", "user2id", "[", "k", "]", ":", "k", "for", "k", "in", "self", ".", "user2id", "}", "\n", "self", ".", "id2item", "=", "{", "self", ".", "item2id", "[", "k", "]", ":", "k", "for", "k", "in", "self", ".", "item2id", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.users": [[69, 72], ["dataset.DataFile.user2id.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "users", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "user2id", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items": [[73, 76], ["dataset.DataFile.item2id.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "item2id", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.end_of_file": [[77, 80], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "end_of_file", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "line_num", ">", "0", ")", "and", "self", ".", "next_row", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.__iter__": [[81, 83], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.__enter__": [[84, 91], ["open", "csv.DictReader", "dataset.DataFile._check_for_missing_fields"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._check_for_missing_fields"], ["", "def", "__enter__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "file", "=", "open", "(", "self", ".", "filename", ",", "\"r\"", ",", "encoding", "=", "\"UTF8\"", ")", "\n", "self", ".", "reader", "=", "csv", ".", "DictReader", "(", "self", ".", "file", ")", "\n", "self", ".", "_check_for_missing_fields", "(", "self", ".", "expected_fields", ")", "\n", "self", ".", "line_num", "=", "0", "\n", "self", ".", "row", ",", "self", ".", "next_row", "=", "None", ",", "None", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.__exit__": [[92, 97], ["dataset.DataFile.file.close"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "file", ".", "close", "(", ")", "\n", "self", ".", "reader", "=", "None", "\n", "self", ".", "line_num", "=", "0", "\n", "self", ".", "row", ",", "self", ".", "next_row", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.__next__": [[98, 111], ["dataset.DataFile._extract_row_data", "next", "dataset.DataFile._extract_row_data", "next", "dataset.EmptyFileException"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._extract_row_data", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._extract_row_data"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "next_row", ":", "\n", "            ", "self", ".", "row", "=", "self", ".", "next_row", "\n", "", "elif", "self", ".", "line_num", "==", "0", ":", "\n", "            ", "self", ".", "row", "=", "self", ".", "_extract_row_data", "(", "next", "(", "self", ".", "reader", ",", "None", ")", ")", "\n", "if", "self", ".", "row", "is", "None", ":", "\n", "                ", "raise", "EmptyFileException", "(", "\"{} is empty.\"", ".", "format", "(", "self", ".", "filename", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "StopIteration", "# end of file", "\n", "", "self", ".", "next_row", "=", "self", ".", "_extract_row_data", "(", "next", "(", "self", ".", "reader", ",", "None", ")", ")", "\n", "self", ".", "line_num", "+=", "1", "\n", "\n", "return", "self", ".", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._check_for_missing_fields": [[112, 118], ["set().difference", "len", "set", "dataset.MissingFieldsException", "set"], "methods", ["None"], ["", "def", "_check_for_missing_fields", "(", "self", ",", "fields_to_check", ")", ":", "\n", "        ", "missing_fields", "=", "set", "(", "fields_to_check", ")", ".", "difference", "(", "set", "(", "self", ".", "reader", ".", "fieldnames", ")", ")", "\n", "if", "len", "(", "missing_fields", ")", ":", "\n", "            ", "raise", "MissingFieldsException", "(", "\n", "\"Columns {} not in header of file {}\"", ".", "format", "(", "\n", "missing_fields", ",", "self", ".", "filename", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._extract_row_data": [[121, 137], ["int", "int", "float", "float", "int"], "methods", ["None"], ["", "", "def", "_extract_row_data", "(", "self", ",", "row", ")", ":", "\n", "        ", "if", "row", "is", "None", ":", "\n", "            ", "return", "row", "\n", "", "user", "=", "int", "(", "row", "[", "self", ".", "col_user", "]", ")", "\n", "item", "=", "int", "(", "row", "[", "self", ".", "col_item", "]", ")", "\n", "rating", "=", "float", "(", "row", "[", "self", ".", "col_rating", "]", ")", "\n", "if", "self", ".", "binary", ":", "\n", "            ", "rating", "=", "float", "(", "rating", ">", "0", ")", "\n", "", "test_batch", "=", "None", "\n", "if", "self", ".", "col_test_batch", ":", "\n", "            ", "test_batch", "=", "int", "(", "row", "[", "self", ".", "col_test_batch", "]", ")", "\n", "", "return", "{", "\n", "self", ".", "col_user", ":", "user", ",", "\n", "self", ".", "col_item", ":", "item", ",", "\n", "self", ".", "col_rating", ":", "rating", ",", "\n", "self", ".", "col_test_batch", ":", "test_batch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile._init_data": [[139, 177], ["logger.info", "range", "collections.OrderedDict", "collections.OrderedDict", "user_items.append", "len", "len", "dataset.FileNotSortedException", "dataset.FileNotSortedException"], "methods", ["None"], ["", "def", "_init_data", "(", "self", ")", ":", "\n", "# Compile lists of unique users and items, assign IDs to users and items,", "\n", "# and ensure file is sorted by user (and batch index if test set)", "\n", "        ", "logger", ".", "info", "(", "\"Indexing {} ...\"", ".", "format", "(", "self", ".", "filename", ")", ")", "\n", "with", "self", ":", "\n", "            ", "user_items", "=", "[", "]", "\n", "self", ".", "item2id", ",", "self", ".", "user2id", "=", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", "\n", "batch_index", "=", "0", "\n", "for", "_", "in", "self", ":", "\n", "                ", "item", "=", "self", ".", "row", "[", "self", ".", "col_item", "]", "\n", "user", "=", "self", ".", "row", "[", "self", ".", "col_user", "]", "\n", "test_batch", "=", "self", ".", "row", "[", "self", ".", "col_test_batch", "]", "\n", "if", "not", "self", ".", "end_of_file", ":", "\n", "                    ", "next_user", "=", "self", ".", "next_row", "[", "self", ".", "col_user", "]", "\n", "next_test_batch", "=", "self", ".", "next_row", "[", "self", ".", "col_test_batch", "]", "\n", "", "if", "item", "not", "in", "self", ".", "items", ":", "\n", "                    ", "self", ".", "item2id", "[", "item", "]", "=", "len", "(", "self", ".", "item2id", ")", "\n", "", "user_items", ".", "append", "(", "item", ")", "\n", "\n", "if", "(", "next_user", "!=", "user", ")", "or", "self", ".", "next_row", "is", "None", ":", "\n", "                    ", "if", "not", "self", ".", "end_of_file", ":", "\n", "                        ", "if", "next_user", "in", "self", ".", "users", ":", "\n", "                            ", "raise", "FileNotSortedException", "(", "\n", "\"File {} is not sorted by user\"", ".", "format", "(", "self", ".", "filename", ")", "\n", ")", "\n", "", "", "self", ".", "user2id", "[", "user", "]", "=", "len", "(", "self", ".", "user2id", ")", "\n", "", "if", "self", ".", "col_test_batch", ":", "\n", "                    ", "if", "(", "next_test_batch", "!=", "test_batch", ")", "or", "self", ".", "next_row", "is", "None", ":", "\n", "                        ", "if", "not", "self", ".", "end_of_file", ":", "\n", "                            ", "if", "next_test_batch", "<", "batch_index", ":", "\n", "                                ", "raise", "FileNotSortedException", "(", "\n", "\"File {} is not sorted by {}\"", ".", "format", "(", "\n", "self", ".", "filename", ",", "self", ".", "col_test_batch", "\n", ")", "\n", ")", "\n", "", "", "batch_index", "+=", "1", "\n", "", "", "", "self", ".", "batch_indices_range", "=", "range", "(", "0", ",", "batch_index", ")", "\n", "self", ".", "data_len", "=", "self", ".", "line_num", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.load_data": [[178, 207], ["pandas.DataFrame.from_records", "next", "records.append", "dataset.MissingUserException", "next"], "methods", ["None"], ["", "", "def", "load_data", "(", "self", ",", "key", ",", "by_user", "=", "True", ")", ":", "\n", "        ", "\"\"\"Load data for a specified user or test batch\n\n        Args:\n            key (int): user or test batch index\n            by_user (bool): load data by usr if True, else by test batch\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"", "\n", "records", "=", "[", "]", "\n", "key_col", "=", "self", ".", "col_user", "if", "by_user", "else", "self", ".", "col_test_batch", "\n", "\n", "# fast forward in file to user/test batch", "\n", "while", "(", "self", ".", "line_num", "==", "0", ")", "or", "(", "self", ".", "row", "[", "key_col", "]", "!=", "key", ")", ":", "\n", "            ", "if", "self", ".", "end_of_file", ":", "\n", "                ", "raise", "MissingUserException", "(", "\"User {} not in file {}\"", ".", "format", "(", "key", ",", "self", ".", "filename", ")", ")", "\n", "", "next", "(", "self", ")", "\n", "# collect user/test batch data", "\n", "", "while", "self", ".", "row", "[", "key_col", "]", "==", "key", ":", "\n", "            ", "row", "=", "self", ".", "row", "\n", "if", "self", ".", "col_test_batch", "in", "row", ":", "\n", "                ", "del", "row", "[", "self", ".", "col_test_batch", "]", "\n", "", "records", ".", "append", "(", "row", ")", "\n", "if", "not", "self", ".", "end_of_file", ":", "\n", "                ", "next", "(", "self", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "return", "pd", ".", "DataFrame", ".", "from_records", "(", "records", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.__init__": [[212, 252], ["dataset.NegativeSampler._get_user_negatives_pool", "len", "dataset.NegativeSampler._check_sample_size"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._get_user_negatives_pool", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._check_sample_size"], ["def", "__init__", "(", "\n", "self", ",", "\n", "user", ",", "\n", "n_samples", ",", "\n", "user_positive_item_pool", ",", "\n", "item_pool", ",", "\n", "sample_with_replacement", ",", "\n", "print_warnings", "=", "True", ",", "\n", "training", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            user (str or int): User to be sampled for.\n            n_samples (int): Number of required samples.\n            user_positive_item_pool (set): Set of items with which user has previously interacted.\n            item_pool (set): Set of all items in population.\n            sample_with_replacement (bool): If true, sample negative examples with replacement,\n                otherwise without replacement.\n            print_warnings (bool): If true, prints warnings if sampling without replacement and\n                there are not enough items to sample from to satisfy n_neg or n_neg_test.\n            training (bool): Set to true if sampling for the training set or false if for the test set.\n        \"\"\"", "\n", "self", ".", "user", "=", "user", "\n", "self", ".", "n_samples", "=", "n_samples", "\n", "self", ".", "user_positive_item_pool", "=", "user_positive_item_pool", "\n", "self", ".", "item_pool", "=", "item_pool", "\n", "self", ".", "sample_with_replacement", "=", "sample_with_replacement", "\n", "self", ".", "print_warnings", "=", "print_warnings", "\n", "self", ".", "training", "=", "training", "\n", "\n", "self", ".", "user_negative_item_pool", "=", "self", ".", "_get_user_negatives_pool", "(", ")", "\n", "self", ".", "population_size", "=", "len", "(", "self", ".", "user_negative_item_pool", ")", "\n", "self", ".", "_sample", "=", "(", "\n", "self", ".", "_sample_negatives_with_replacement", "\n", "if", "self", ".", "sample_with_replacement", "\n", "else", "self", ".", "_sample_negatives_without_replacement", "\n", ")", "\n", "if", "not", "self", ".", "sample_with_replacement", ":", "\n", "            ", "self", ".", "_check_sample_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample": [[253, 259], ["dataset.NegativeSampler._sample"], "methods", ["None"], ["", "", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"Method for sampling uniformly from a population of negative items\n\n        Returns: list\n        \"\"\"", "\n", "return", "self", ".", "_sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._get_user_negatives_pool": [[260, 263], ["list", "set"], "methods", ["None"], ["", "def", "_get_user_negatives_pool", "(", "self", ")", ":", "\n", "# get list of items user has not interacted with", "\n", "        ", "return", "list", "(", "set", "(", "self", ".", "item_pool", ")", "-", "self", ".", "user_positive_item_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._sample_negatives_with_replacement": [[264, 266], ["random.choices"], "methods", ["None"], ["", "def", "_sample_negatives_with_replacement", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "choices", "(", "self", ".", "user_negative_item_pool", ",", "k", "=", "self", ".", "n_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._sample_negatives_without_replacement": [[267, 269], ["random.sample"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "def", "_sample_negatives_without_replacement", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "sample", "(", "self", ".", "user_negative_item_pool", ",", "k", "=", "self", ".", "n_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler._check_sample_size": [[270, 294], ["min", "logging.warning"], "methods", ["None"], ["", "def", "_check_sample_size", "(", "self", ")", ":", "\n", "# if sampling without replacement, check sample population is sufficient and reduce", "\n", "# n_samples if not.", "\n", "        ", "n_neg_var", "=", "\"n_neg\"", "if", "self", ".", "training", "else", "\"n_neg_test\"", "\n", "dataset_name", "=", "\"training\"", "if", "self", ".", "training", "else", "\"test\"", "\n", "\n", "k", "=", "min", "(", "self", ".", "n_samples", ",", "self", ".", "population_size", ")", "\n", "if", "k", "<", "self", ".", "n_samples", "and", "self", ".", "print_warnings", ":", "\n", "            ", "warning_string", "=", "(", "\n", "\"The population of negative items to sample from is too small for user {}. \"", "\n", "\"Samples needed = {}, negative items = {}. \"", "\n", "\"Reducing samples to {} for this user.\"", "\n", "\"If an equal number of negative samples for each user is required in the {} set, sample with replacement or reduce {}. \"", "\n", "\"This warning can be turned off by setting print_warnings=False\"", ".", "format", "(", "\n", "self", ".", "user", ",", "\n", "self", ".", "n_samples", ",", "\n", "self", ".", "population_size", ",", "\n", "self", ".", "population_size", ",", "\n", "dataset_name", ",", "\n", "n_neg_var", ",", "\n", ")", "\n", ")", "\n", "logging", ".", "warning", "(", "warning_string", ")", "\n", "", "self", ".", "n_samples", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset.__init__": [[299, 387], ["dataset.DataFile", "len", "len", "random.seed", "dataset.DataFile", "dataset.DataFile", "dataset.Dataset._create_test_file", "os.path.isfile", "os.path.splitext"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._create_test_file"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train_file", ",", "\n", "test_file", "=", "None", ",", "\n", "test_file_full", "=", "None", ",", "\n", "overwrite_test_file_full", "=", "False", ",", "\n", "n_neg", "=", "4", ",", "\n", "n_neg_test", "=", "100", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "binary", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "sample_with_replacement", "=", "False", ",", "\n", "print_warnings", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            train_file (str): Path to training dataset file.\n            test_file (str): Path to test dataset file for leave-one-out evaluation.\n            test_file_full (str): Path to full test dataset file including negative samples.\n            overwrite_test_file_full (bool): If true, recreate and overwrite test_file_full.\n            n_neg (int): Number of negative samples per positive example for training set.\n            n_neg_test (int): Number of negative samples per positive example for test set.\n            col_user (str): User column name.\n            col_item (str): Item column name.\n            col_rating (str): Rating column name.\n            binary (bool): If true, set rating > 0 to rating = 1.\n            seed (int): Seed.\n            sample_with_replacement (bool): If true, sample negative examples with replacement,\n                otherwise without replacement.\n            print_warnings (bool): If true, prints warnings if sampling without replacement and\n                there are not enough items to sample from to satisfy n_neg or n_neg_test.\n        \"\"\"", "\n", "self", ".", "train_file", "=", "train_file", "\n", "self", ".", "test_file", "=", "test_file", "\n", "self", ".", "test_file_full", "=", "test_file_full", "\n", "self", ".", "overwrite_test_file_full", "=", "overwrite_test_file_full", "\n", "self", ".", "n_neg", "=", "n_neg", "\n", "self", ".", "n_neg_test", "=", "n_neg_test", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "binary", "=", "binary", "\n", "self", ".", "sample_with_replacement", "=", "sample_with_replacement", "\n", "self", ".", "print_warnings", "=", "print_warnings", "\n", "\n", "self", ".", "col_test_batch", "=", "\"test_batch\"", "\n", "\n", "self", ".", "train_datafile", "=", "DataFile", "(", "\n", "filename", "=", "self", ".", "train_file", ",", "\n", "col_user", "=", "self", ".", "col_user", ",", "\n", "col_item", "=", "self", ".", "col_item", ",", "\n", "col_rating", "=", "self", ".", "col_rating", ",", "\n", "binary", "=", "self", ".", "binary", ",", "\n", ")", "\n", "\n", "self", ".", "n_users", "=", "len", "(", "self", ".", "train_datafile", ".", "users", ")", "\n", "self", ".", "n_items", "=", "len", "(", "self", ".", "train_datafile", ".", "items", ")", "\n", "self", ".", "user2id", "=", "self", ".", "train_datafile", ".", "user2id", "\n", "self", ".", "item2id", "=", "self", ".", "train_datafile", ".", "item2id", "\n", "self", ".", "id2user", "=", "self", ".", "train_datafile", ".", "id2user", "\n", "self", ".", "id2item", "=", "self", ".", "train_datafile", ".", "id2item", "\n", "self", ".", "train_len", "=", "self", ".", "train_datafile", ".", "data_len", "\n", "\n", "if", "self", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "test_datafile", "=", "DataFile", "(", "\n", "filename", "=", "self", ".", "test_file", ",", "\n", "col_user", "=", "self", ".", "col_user", ",", "\n", "col_item", "=", "self", ".", "col_item", ",", "\n", "col_rating", "=", "self", ".", "col_rating", ",", "\n", "binary", "=", "self", ".", "binary", ",", "\n", ")", "\n", "if", "self", ".", "test_file_full", "is", "None", ":", "\n", "                ", "self", ".", "test_file_full", "=", "os", ".", "path", ".", "splitext", "(", "self", ".", "test_file", ")", "[", "0", "]", "+", "\"_full.csv\"", "\n", "", "if", "self", ".", "overwrite_test_file_full", "or", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "test_file_full", ")", ":", "\n", "                ", "self", ".", "_create_test_file", "(", ")", "\n", "", "self", ".", "test_full_datafile", "=", "DataFile", "(", "\n", "filename", "=", "self", ".", "test_file_full", ",", "\n", "col_user", "=", "self", ".", "col_user", ",", "\n", "col_item", "=", "self", ".", "col_item", ",", "\n", "col_rating", "=", "self", ".", "col_rating", ",", "\n", "col_test_batch", "=", "self", ".", "col_test_batch", ",", "\n", "binary", "=", "self", ".", "binary", ",", "\n", ")", "\n", "# set random seed", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._create_negative_examples_df": [[388, 396], ["len", "pandas.DataFrame"], "methods", ["None"], ["", "def", "_create_negative_examples_df", "(", "self", ",", "user", ",", "user_negative_samples", ")", ":", "\n", "# create dataframe containing negative examples for user assigned zero rating", "\n", "        ", "n_samples", "=", "len", "(", "user_negative_samples", ")", "\n", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "self", ".", "col_user", ":", "[", "user", "]", "*", "n_samples", ",", "\n", "self", ".", "col_item", ":", "user_negative_samples", ",", "\n", "self", ".", "col_rating", ":", "[", "0.0", "]", "*", "n_samples", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._create_test_file": [[399, 449], ["logger.info", "pandas.DataFrame().to_csv", "pandas.DataFrame", "tqdm.tqdm.tqdm", "test_datafile.load_data", "train_datafile.load_data", "set().union", "dataset.NegativeSampler", "numpy.array_split", "pandas.concat", "pandas.concat.to_csv", "user_train_data[].unique", "dataset.Dataset._create_negative_examples_df", "pandas.concat", "user_examples_dfs.append", "set", "dataset.NegativeSampler.sample", "user_test_data[].unique"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._create_negative_examples_df", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "def", "_create_test_file", "(", "self", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Creating full leave-one-out test file {} ...\"", ".", "format", "(", "self", ".", "test_file_full", ")", "\n", ")", "\n", "\n", "# create empty csv", "\n", "pd", ".", "DataFrame", "(", "\n", "columns", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", ",", "self", ".", "col_test_batch", "]", "\n", ")", ".", "to_csv", "(", "self", ".", "test_file_full", ",", "index", "=", "False", ")", "\n", "\n", "batch_idx", "=", "0", "\n", "\n", "with", "self", ".", "train_datafile", "as", "train_datafile", ":", "\n", "            ", "with", "self", ".", "test_datafile", "as", "test_datafile", ":", "\n", "                ", "for", "user", "in", "tqdm", "(", "test_datafile", ".", "users", ")", ":", "\n", "                    ", "if", "user", "in", "train_datafile", ".", "users", ":", "\n", "                        ", "user_test_data", "=", "test_datafile", ".", "load_data", "(", "user", ")", "\n", "user_train_data", "=", "train_datafile", ".", "load_data", "(", "user", ")", "\n", "# for leave-one-out evaluation, exclude items seen in both training and test sets", "\n", "# when sampling negatives", "\n", "user_positive_item_pool", "=", "set", "(", "\n", "user_test_data", "[", "self", ".", "col_item", "]", ".", "unique", "(", ")", "\n", ")", ".", "union", "(", "user_train_data", "[", "self", ".", "col_item", "]", ".", "unique", "(", ")", ")", "\n", "sampler", "=", "NegativeSampler", "(", "\n", "user", ",", "\n", "self", ".", "n_neg_test", ",", "\n", "user_positive_item_pool", ",", "\n", "self", ".", "train_datafile", ".", "items", ",", "\n", "self", ".", "sample_with_replacement", ",", "\n", "self", ".", "print_warnings", ",", "\n", "training", "=", "False", ",", "\n", ")", "\n", "\n", "user_examples_dfs", "=", "[", "]", "\n", "# sample n_neg_test negatives for each positive example and assign a batch index", "\n", "for", "positive_example", "in", "np", ".", "array_split", "(", "\n", "user_test_data", ",", "user_test_data", ".", "shape", "[", "0", "]", "\n", ")", ":", "\n", "                            ", "negative_examples", "=", "self", ".", "_create_negative_examples_df", "(", "\n", "user", ",", "sampler", ".", "sample", "(", ")", "\n", ")", "\n", "examples", "=", "pd", ".", "concat", "(", "[", "positive_example", ",", "negative_examples", "]", ")", "\n", "examples", "[", "self", ".", "col_test_batch", "]", "=", "batch_idx", "\n", "user_examples_dfs", ".", "append", "(", "examples", ")", "\n", "batch_idx", "+=", "1", "\n", "# append user test data to file", "\n", "", "user_examples", "=", "pd", ".", "concat", "(", "user_examples_dfs", ")", "\n", "user_examples", ".", "to_csv", "(", "\n", "self", ".", "test_file_full", ",", "mode", "=", "\"a\"", ",", "index", "=", "False", ",", "header", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._split_into_batches": [[451, 454], ["range", "len"], "methods", ["None"], ["", "", "", "", "", "def", "_split_into_batches", "(", "self", ",", "shuffle_buffer", ",", "batch_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "shuffle_buffer", ")", ",", "batch_size", ")", ":", "\n", "            ", "yield", "shuffle_buffer", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._prepare_batch_with_id": [[455, 460], ["batch[].values.tolist"], "methods", ["None"], ["", "", "def", "_prepare_batch_with_id", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "[", "\n", "[", "self", ".", "user2id", "[", "user", "]", "for", "user", "in", "batch", "[", "self", ".", "col_user", "]", ".", "values", "]", ",", "\n", "[", "self", ".", "item2id", "[", "item", "]", "for", "item", "in", "batch", "[", "self", ".", "col_item", "]", ".", "values", "]", ",", "\n", "batch", "[", "self", ".", "col_rating", "]", ".", "values", ".", "tolist", "(", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._prepare_batch_without_id": [[462, 467], ["batch[].values.tolist", "batch[].values.tolist", "batch[].values.tolist"], "methods", ["None"], ["", "def", "_prepare_batch_without_id", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "[", "\n", "batch", "[", "self", ".", "col_user", "]", ".", "values", ".", "tolist", "(", ")", ",", "\n", "batch", "[", "self", ".", "col_item", "]", ".", "values", ".", "tolist", "(", ")", ",", "\n", "batch", "[", "self", ".", "col_rating", "]", ".", "values", ".", "tolist", "(", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._release_shuffle_buffer": [[469, 486], ["pandas.concat", "shuffle_buffer_df.sample.sample.sample", "dataset.Dataset._split_into_batches", "batch.to_csv", "prepare_batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._split_into_batches"], ["", "def", "_release_shuffle_buffer", "(", "\n", "self", ",", "shuffle_buffer", ",", "batch_size", ",", "yield_id", ",", "write_to", "=", "None", "\n", ")", ":", "\n", "        ", "prepare_batch", "=", "(", "\n", "self", ".", "_prepare_batch_with_id", "if", "yield_id", "else", "self", ".", "_prepare_batch_without_id", "\n", ")", "\n", "shuffle_buffer_df", "=", "pd", ".", "concat", "(", "shuffle_buffer", ")", "\n", "shuffle_buffer_df", "=", "shuffle_buffer_df", ".", "sample", "(", "\n", "shuffle_buffer_df", ".", "shape", "[", "0", "]", "\n", ")", "# shuffle the buffer", "\n", "for", "batch", "in", "self", ".", "_split_into_batches", "(", "shuffle_buffer_df", ",", "batch_size", ")", ":", "\n", "            ", "if", "batch", ".", "shape", "[", "0", "]", "==", "batch_size", ":", "\n", "                ", "if", "write_to", ":", "\n", "                    ", "batch", ".", "to_csv", "(", "write_to", ",", "mode", "=", "\"a\"", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "", "yield", "prepare_batch", "(", "batch", ")", "\n", "", "else", ":", "\n", "                ", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset.train_loader": [[487, 548], ["pandas.DataFrame().to_csv", "train_datafile.load_data", "set", "dataset.NegativeSampler", "dataset.Dataset._create_negative_examples_df", "pandas.concat", "shuffle_buffer.append", "sum", "dataset.Dataset._release_shuffle_buffer", "pandas.DataFrame", "user_positive_examples[].unique", "dataset.NegativeSampler.sample", "dataset.Dataset._release_shuffle_buffer"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._create_negative_examples_df", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._release_shuffle_buffer", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset._release_shuffle_buffer"], ["", "", "", "def", "train_loader", "(", "\n", "self", ",", "batch_size", ",", "shuffle_size", "=", "None", ",", "yield_id", "=", "False", ",", "write_to", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Generator for serving batches of training data. Positive examples are loaded from the\n        original training file, to which negative samples are added. Data is loaded in memory into a\n        shuffle buffer up to a maximum of shuffle_size rows, before the data is shuffled and released.\n        If out-of-memory errors are encountered, try reducing shuffle_size.\n\n        Args:\n            batch_size (int): Number of examples in each batch.\n            shuffle_size (int): Maximum number of examples in shuffle buffer.\n            yield_id (bool): If true, return assigned user and item IDs, else return original values.\n            write_to (str): Path of file to write full dataset (including negative examples).\n\n        Returns:\n            list\n        \"\"\"", "\n", "\n", "# if shuffle_size not supplied, use (estimated) full data size i.e. complete in-memory shuffle", "\n", "if", "shuffle_size", "is", "None", ":", "\n", "            ", "shuffle_size", "=", "self", ".", "train_len", "*", "(", "self", ".", "n_neg", "+", "1", ")", "\n", "", "if", "write_to", ":", "\n", "            ", "pd", ".", "DataFrame", "(", "\n", "columns", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", "]", "\n", ")", ".", "to_csv", "(", "write_to", ",", "header", "=", "True", ",", "index", "=", "False", ")", "\n", "", "shuffle_buffer", "=", "[", "]", "\n", "\n", "with", "self", ".", "train_datafile", "as", "train_datafile", ":", "\n", "            ", "for", "user", "in", "train_datafile", ".", "users", ":", "\n", "                ", "user_positive_examples", "=", "train_datafile", ".", "load_data", "(", "user", ")", "\n", "user_positive_item_pool", "=", "set", "(", "\n", "user_positive_examples", "[", "self", ".", "col_item", "]", ".", "unique", "(", ")", "\n", ")", "\n", "n_samples", "=", "self", ".", "n_neg", "*", "user_positive_examples", ".", "shape", "[", "0", "]", "\n", "sampler", "=", "NegativeSampler", "(", "\n", "user", ",", "\n", "n_samples", ",", "\n", "user_positive_item_pool", ",", "\n", "self", ".", "train_datafile", ".", "items", ",", "\n", "self", ".", "sample_with_replacement", ",", "\n", "self", ".", "print_warnings", ",", "\n", ")", "\n", "user_negative_examples", "=", "self", ".", "_create_negative_examples_df", "(", "\n", "user", ",", "sampler", ".", "sample", "(", ")", "\n", ")", "\n", "user_examples", "=", "pd", ".", "concat", "(", "\n", "[", "user_positive_examples", ",", "user_negative_examples", "]", "\n", ")", "\n", "shuffle_buffer", ".", "append", "(", "user_examples", ")", "\n", "shuffle_buffer_len", "=", "sum", "(", "[", "df", ".", "shape", "[", "0", "]", "for", "df", "in", "shuffle_buffer", "]", ")", "\n", "if", "shuffle_buffer_len", ">=", "shuffle_size", ":", "\n", "                    ", "buffer_remainder", "=", "yield", "from", "self", ".", "_release_shuffle_buffer", "(", "\n", "shuffle_buffer", ",", "batch_size", ",", "yield_id", ",", "write_to", "\n", ")", "\n", "shuffle_buffer", "=", "(", "\n", "[", "buffer_remainder", "]", "if", "buffer_remainder", "is", "not", "None", "else", "[", "]", "\n", ")", "\n", "# yield remaining buffer", "\n", "", "", "yield", "from", "self", ".", "_release_shuffle_buffer", "(", "\n", "shuffle_buffer", ",", "batch_size", ",", "yield_id", ",", "write_to", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.Dataset.test_loader": [[550, 569], ["test_full_datafile.load_data", "prepare_batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data"], ["", "", "def", "test_loader", "(", "self", ",", "yield_id", "=", "False", ")", ":", "\n", "        ", "\"\"\"Generator for serving batches of test data for leave-one-out evaluation. Data is loaded from test_file_full.\n\n        Args:\n            yield_id (bool): If true, return assigned user and item IDs, else return original values.\n\n        Returns:\n            list\n        \"\"\"", "\n", "prepare_batch", "=", "(", "\n", "self", ".", "_prepare_batch_with_id", "if", "yield_id", "else", "self", ".", "_prepare_batch_without_id", "\n", ")", "\n", "\n", "with", "self", ".", "test_full_datafile", "as", "test_full_datafile", ":", "\n", "            ", "for", "test_batch_idx", "in", "test_full_datafile", ".", "batch_indices_range", ":", "\n", "                ", "test_batch_data", "=", "test_full_datafile", ".", "load_data", "(", "\n", "test_batch_idx", ",", "by_user", "=", "False", "\n", ")", "\n", "yield", "prepare_batch", "(", "test_batch_data", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_feature_columns": [[10, 68], ["tensorflow.feature_column.categorical_column_with_vocabulary_list", "tensorflow.feature_column.categorical_column_with_vocabulary_list", "ValueError", "wide_deep_utils._build_wide_columns", "wide_deep_utils._build_deep_columns", "wide_deep_utils._build_wide_columns", "wide_deep_utils._build_deep_columns"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_wide_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_deep_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_wide_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_deep_columns"], ["def", "build_feature_columns", "(", "\n", "users", ",", "\n", "items", ",", "\n", "user_col", "=", "DEFAULT_USER_COL", ",", "\n", "item_col", "=", "DEFAULT_ITEM_COL", ",", "\n", "item_feat_col", "=", "None", ",", "\n", "crossed_feat_dim", "=", "1000", ",", "\n", "user_dim", "=", "8", ",", "\n", "item_dim", "=", "8", ",", "\n", "item_feat_shape", "=", "None", ",", "\n", "model_type", "=", "\"wide_deep\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Build wide and/or deep feature columns for TensorFlow high-level API Estimator.\n\n    Args:\n        users (iterable): Distinct user ids.\n        items (iterable): Distinct item ids.\n        user_col (str): User column name.\n        item_col (str): Item column name.\n        item_feat_col (str): Item feature column name for 'deep' or 'wide_deep' model.\n        crossed_feat_dim (int): Crossed feature dimension for 'wide' or 'wide_deep' model.\n        user_dim (int): User embedding dimension for 'deep' or 'wide_deep' model.\n        item_dim (int): Item embedding dimension for 'deep' or 'wide_deep' model.\n        item_feat_shape (int or an iterable of integers): Item feature array shape for 'deep' or 'wide_deep' model.\n        model_type (str): Model type, either\n            'wide' for a linear model,\n            'deep' for a deep neural networks, or\n            'wide_deep' for a combination of linear model and neural networks.\n\n    Returns:\n        list, list:\n        - The wide feature columns\n        - The deep feature columns. If only the wide model is selected, the deep column list is empty and viceversa.\n    \"\"\"", "\n", "if", "model_type", "not", "in", "[", "\"wide\"", ",", "\"deep\"", ",", "\"wide_deep\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"Model type should be either 'wide', 'deep', or 'wide_deep'\"", ")", "\n", "\n", "", "user_ids", "=", "tf", ".", "feature_column", ".", "categorical_column_with_vocabulary_list", "(", "\n", "user_col", ",", "users", "\n", ")", "\n", "item_ids", "=", "tf", ".", "feature_column", ".", "categorical_column_with_vocabulary_list", "(", "\n", "item_col", ",", "items", "\n", ")", "\n", "\n", "if", "model_type", "==", "\"wide\"", ":", "\n", "        ", "return", "_build_wide_columns", "(", "user_ids", ",", "item_ids", ",", "crossed_feat_dim", ")", ",", "[", "]", "\n", "", "elif", "model_type", "==", "\"deep\"", ":", "\n", "        ", "return", "(", "\n", "[", "]", ",", "\n", "_build_deep_columns", "(", "\n", "user_ids", ",", "item_ids", ",", "user_dim", ",", "item_dim", ",", "item_feat_col", ",", "item_feat_shape", "\n", ")", ",", "\n", ")", "\n", "", "elif", "model_type", "==", "\"wide_deep\"", ":", "\n", "        ", "return", "(", "\n", "_build_wide_columns", "(", "user_ids", ",", "item_ids", ",", "crossed_feat_dim", ")", ",", "\n", "_build_deep_columns", "(", "\n", "user_ids", ",", "item_ids", ",", "user_dim", ",", "item_dim", ",", "item_feat_col", ",", "item_feat_shape", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_wide_columns": [[72, 89], ["tensorflow.feature_column.crossed_column"], "function", ["None"], ["", "", "def", "_build_wide_columns", "(", "user_ids", ",", "item_ids", ",", "hash_bucket_size", "=", "1000", ")", ":", "\n", "    ", "\"\"\"Build wide feature (crossed) columns. `user_ids` * `item_ids` are hashed into `hash_bucket_size`\n\n    Args:\n        user_ids (tf.feature_column.categorical_column_with_vocabulary_list): User ids.\n        item_ids (tf.feature_column.categorical_column_with_vocabulary_list): Item ids.\n        hash_bucket_size (int): Hash bucket size.\n\n    Returns:\n        list: Wide feature columns.\n    \"\"\"", "\n", "# Including the original features in addition to the crossed one is recommended to address hash collision problem.", "\n", "return", "[", "\n", "user_ids", ",", "\n", "item_ids", ",", "\n", "tf", ".", "feature_column", ".", "crossed_column", "(", "\n", "[", "user_ids", ",", "item_ids", "]", ",", "hash_bucket_size", "=", "hash_bucket_size", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils._build_deep_columns": [[93, 127], ["tensorflow.feature_column.embedding_column", "tensorflow.feature_column.embedding_column", "deep_columns.append", "tensorflow.feature_column.numeric_column"], "function", ["None"], ["", "def", "_build_deep_columns", "(", "\n", "user_ids", ",", "item_ids", ",", "user_dim", ",", "item_dim", ",", "item_feat_col", "=", "None", ",", "item_feat_shape", "=", "1", "\n", ")", ":", "\n", "    ", "\"\"\"Build deep feature columns\n\n    Args:\n        user_ids (tf.feature_column.categorical_column_with_vocabulary_list): User ids.\n        item_ids (tf.feature_column.categorical_column_with_vocabulary_list): Item ids.\n        user_dim (int): User embedding dimension.\n        item_dim (int): Item embedding dimension.\n        item_feat_col (str): Item feature column name.\n        item_feat_shape (int or an iterable of integers): Item feature array shape.\n\n    Returns:\n        list: Deep feature columns.\n    \"\"\"", "\n", "deep_columns", "=", "[", "\n", "# User embedding", "\n", "tf", ".", "feature_column", ".", "embedding_column", "(", "\n", "categorical_column", "=", "user_ids", ",", "dimension", "=", "user_dim", ",", "max_norm", "=", "user_dim", "**", "0.5", "\n", ")", ",", "\n", "# Item embedding", "\n", "tf", ".", "feature_column", ".", "embedding_column", "(", "\n", "categorical_column", "=", "item_ids", ",", "dimension", "=", "item_dim", ",", "max_norm", "=", "item_dim", "**", "0.5", "\n", ")", ",", "\n", "]", "\n", "# Item feature", "\n", "if", "item_feat_col", "is", "not", "None", ":", "\n", "        ", "deep_columns", ".", "append", "(", "\n", "tf", ".", "feature_column", ".", "numeric_column", "(", "\n", "item_feat_col", ",", "shape", "=", "item_feat_shape", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", ")", "\n", "", "return", "deep_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.wide_deep.wide_deep_utils.build_model": [[129, 210], ["tensorflow.estimator.RunConfig", "tensorflow.compat.v1.estimator.LinearRegressor", "len", "len", "tensorflow.compat.v1.estimator.DNNRegressor", "len", "len", "tensorflow.compat.v1.estimator.DNNLinearCombinedRegressor", "ValueError", "len", "len"], "function", ["None"], ["", "def", "build_model", "(", "\n", "model_dir", "=", "MODEL_DIR", ",", "\n", "wide_columns", "=", "(", ")", ",", "\n", "deep_columns", "=", "(", ")", ",", "\n", "linear_optimizer", "=", "\"Ftrl\"", ",", "\n", "dnn_optimizer", "=", "\"Adagrad\"", ",", "\n", "dnn_hidden_units", "=", "(", "128", ",", "128", ")", ",", "\n", "dnn_dropout", "=", "0.0", ",", "\n", "dnn_batch_norm", "=", "True", ",", "\n", "log_every_n_iter", "=", "1000", ",", "\n", "save_checkpoints_steps", "=", "10000", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Build wide-deep model.\n\n    To generate wide model, pass wide_columns only.\n    To generate deep model, pass deep_columns only.\n    To generate wide_deep model, pass both wide_columns and deep_columns.\n\n    Args:\n        model_dir (str): Model checkpoint directory.\n        wide_columns (list of tf.feature_column): Wide model feature columns.\n        deep_columns (list of tf.feature_column): Deep model feature columns.\n        linear_optimizer (str or tf.train.Optimizer): Wide model optimizer name or object.\n        dnn_optimizer (str or tf.train.Optimizer): Deep model optimizer name or object.\n        dnn_hidden_units (list of int): Deep model hidden units. E.g., [10, 10, 10] is three layers of 10 nodes each.\n        dnn_dropout (float): Deep model's dropout rate.\n        dnn_batch_norm (bool): Deep model's batch normalization flag.\n        log_every_n_iter (int): Log the training loss for every n steps.\n        save_checkpoints_steps (int): Model checkpoint frequency.\n        seed (int): Random seed.\n\n    Returns:\n        tf.estimator.Estimator: Model\n    \"\"\"", "\n", "# TensorFlow training log frequency setup", "\n", "config", "=", "tf", ".", "estimator", ".", "RunConfig", "(", "\n", "tf_random_seed", "=", "seed", ",", "\n", "log_step_count_steps", "=", "log_every_n_iter", ",", "\n", "save_checkpoints_steps", "=", "save_checkpoints_steps", ",", "\n", ")", "\n", "\n", "if", "len", "(", "wide_columns", ")", ">", "0", "and", "len", "(", "deep_columns", ")", "==", "0", ":", "\n", "        ", "model", "=", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "LinearRegressor", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "config", "=", "config", ",", "\n", "feature_columns", "=", "wide_columns", ",", "\n", "optimizer", "=", "linear_optimizer", ",", "\n", ")", "\n", "", "elif", "len", "(", "wide_columns", ")", "==", "0", "and", "len", "(", "deep_columns", ")", ">", "0", ":", "\n", "        ", "model", "=", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "DNNRegressor", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "config", "=", "config", ",", "\n", "feature_columns", "=", "deep_columns", ",", "\n", "hidden_units", "=", "dnn_hidden_units", ",", "\n", "optimizer", "=", "dnn_optimizer", ",", "\n", "dropout", "=", "dnn_dropout", ",", "\n", "batch_norm", "=", "dnn_batch_norm", ",", "\n", ")", "\n", "", "elif", "len", "(", "wide_columns", ")", ">", "0", "and", "len", "(", "deep_columns", ")", ">", "0", ":", "\n", "        ", "model", "=", "tf", ".", "compat", ".", "v1", ".", "estimator", ".", "DNNLinearCombinedRegressor", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "config", "=", "config", ",", "\n", "# wide settings", "\n", "linear_feature_columns", "=", "wide_columns", ",", "\n", "linear_optimizer", "=", "linear_optimizer", ",", "\n", "# deep settings", "\n", "dnn_feature_columns", "=", "deep_columns", ",", "\n", "dnn_hidden_units", "=", "dnn_hidden_units", ",", "\n", "dnn_optimizer", "=", "dnn_optimizer", ",", "\n", "dnn_dropout", "=", "dnn_dropout", ",", "\n", "batch_norm", "=", "dnn_batch_norm", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"To generate wide model, set wide_columns.\\n\"", "\n", "\"To generate deep model, set deep_columns.\\n\"", "\n", "\"To generate wide_deep model, set both wide_columns and deep_columns.\"", "\n", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.check_type": [[14, 80], ["TypeError", "TypeError", "TypeError", "TypeError", "TypeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance"], "function", ["None"], ["def", "check_type", "(", "config", ")", ":", "\n", "    ", "\"\"\"Check that the config parameters are the correct type\n\n    Args:\n        config (dict): Configuration dictionary.\n\n    Raises:\n        TypeError: If the parameters are not the correct type.\n    \"\"\"", "\n", "\n", "int_parameters", "=", "[", "\n", "\"word_size\"", ",", "\n", "\"his_size\"", ",", "\n", "\"title_size\"", ",", "\n", "\"body_size\"", ",", "\n", "\"npratio\"", ",", "\n", "\"word_emb_dim\"", ",", "\n", "\"attention_hidden_dim\"", ",", "\n", "\"epochs\"", ",", "\n", "\"batch_size\"", ",", "\n", "\"show_step\"", ",", "\n", "\"save_epoch\"", ",", "\n", "\"head_num\"", ",", "\n", "\"head_dim\"", ",", "\n", "\"user_num\"", ",", "\n", "\"filter_num\"", ",", "\n", "\"window_size\"", ",", "\n", "\"gru_unit\"", ",", "\n", "\"user_emb_dim\"", ",", "\n", "\"vert_emb_dim\"", ",", "\n", "\"subvert_emb_dim\"", ",", "\n", "]", "\n", "for", "param", "in", "int_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be int\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "float_parameters", "=", "[", "\"learning_rate\"", ",", "\"dropout\"", "]", "\n", "for", "param", "in", "float_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "float", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be float\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "str_parameters", "=", "[", "\n", "\"wordEmb_file\"", ",", "\n", "\"wordDict_file\"", ",", "\n", "\"userDict_file\"", ",", "\n", "\"vertDict_file\"", ",", "\n", "\"subvertDict_file\"", ",", "\n", "\"method\"", ",", "\n", "\"loss\"", ",", "\n", "\"optimizer\"", ",", "\n", "\"cnn_activation\"", ",", "\n", "\"dense_activation\"", "\"type\"", ",", "\n", "]", "\n", "for", "param", "in", "str_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be str\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "list_parameters", "=", "[", "\"layer_sizes\"", ",", "\"activation\"", "]", "\n", "for", "param", "in", "list_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be list\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "bool_parameters", "=", "[", "\"support_quick_scoring\"", "]", "\n", "for", "param", "in", "bool_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "bool", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be bool\"", ".", "format", "(", "param", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.check_nn_config": [[82, 205], ["newsrec_utils.check_type", "ValueError", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_type"], ["", "", "", "def", "check_nn_config", "(", "f_config", ")", ":", "\n", "    ", "\"\"\"Check neural networks configuration.\n\n    Args:\n        f_config (dict): Neural network configuration.\n\n    Raises:\n        ValueError: If the parameters are not correct.\n    \"\"\"", "\n", "\n", "if", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"nrms\"", ",", "\"NRMS\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"title_size\"", ",", "\n", "\"his_size\"", ",", "\n", "\"wordEmb_file\"", ",", "\n", "\"wordDict_file\"", ",", "\n", "\"userDict_file\"", ",", "\n", "\"npratio\"", ",", "\n", "\"data_format\"", ",", "\n", "\"word_emb_dim\"", ",", "\n", "# nrms", "\n", "\"head_num\"", ",", "\n", "\"head_dim\"", ",", "\n", "# attention", "\n", "\"attention_hidden_dim\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "]", "\n", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"naml\"", ",", "\"NAML\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"title_size\"", ",", "\n", "\"body_size\"", ",", "\n", "\"his_size\"", ",", "\n", "\"wordEmb_file\"", ",", "\n", "\"subvertDict_file\"", ",", "\n", "\"vertDict_file\"", ",", "\n", "\"wordDict_file\"", ",", "\n", "\"userDict_file\"", ",", "\n", "\"npratio\"", ",", "\n", "\"data_format\"", ",", "\n", "\"word_emb_dim\"", ",", "\n", "\"vert_emb_dim\"", ",", "\n", "\"subvert_emb_dim\"", ",", "\n", "# naml", "\n", "\"filter_num\"", ",", "\n", "\"cnn_activation\"", ",", "\n", "\"window_size\"", ",", "\n", "\"dense_activation\"", ",", "\n", "# attention", "\n", "\"attention_hidden_dim\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"lstur\"", ",", "\"LSTUR\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"title_size\"", ",", "\n", "\"his_size\"", ",", "\n", "\"wordEmb_file\"", ",", "\n", "\"wordDict_file\"", ",", "\n", "\"userDict_file\"", ",", "\n", "\"npratio\"", ",", "\n", "\"data_format\"", ",", "\n", "\"word_emb_dim\"", ",", "\n", "# lstur", "\n", "\"gru_unit\"", ",", "\n", "\"type\"", ",", "\n", "\"filter_num\"", ",", "\n", "\"cnn_activation\"", ",", "\n", "\"window_size\"", ",", "\n", "# attention", "\n", "\"attention_hidden_dim\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"npa\"", ",", "\"NPA\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"title_size\"", ",", "\n", "\"his_size\"", ",", "\n", "\"wordEmb_file\"", ",", "\n", "\"wordDict_file\"", ",", "\n", "\"userDict_file\"", ",", "\n", "\"npratio\"", ",", "\n", "\"data_format\"", ",", "\n", "\"word_emb_dim\"", ",", "\n", "# npa", "\n", "\"user_emb_dim\"", ",", "\n", "\"filter_num\"", ",", "\n", "\"cnn_activation\"", ",", "\n", "\"window_size\"", ",", "\n", "# attention", "\n", "\"attention_hidden_dim\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "required_parameters", "=", "[", "]", "\n", "\n", "# check required parameters", "\n", "", "for", "param", "in", "required_parameters", ":", "\n", "        ", "if", "param", "not", "in", "f_config", ":", "\n", "            ", "raise", "ValueError", "(", "\"Parameters {0} must be set\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "if", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"nrms\"", ",", "\"NRMS\"", ",", "\"lstur\"", ",", "\"LSTUR\"", "]", ":", "\n", "        ", "if", "f_config", "[", "\"data_format\"", "]", "!=", "\"news\"", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"For nrms and naml model, data format must be 'news', but your set is {0}\"", ".", "format", "(", "\n", "f_config", "[", "\"data_format\"", "]", "\n", ")", "\n", ")", "\n", "", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"naml\"", ",", "\"NAML\"", "]", ":", "\n", "        ", "if", "f_config", "[", "\"data_format\"", "]", "!=", "\"naml\"", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"For nrms and naml model, data format must be 'naml', but your set is {0}\"", ".", "format", "(", "\n", "f_config", "[", "\"data_format\"", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "check_type", "(", "f_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.create_hparams": [[207, 245], ["init_dict.update", "recommenders.models.deeprec.deeprec_utils.HParams"], "function", ["None"], ["", "def", "create_hparams", "(", "flags", ")", ":", "\n", "    ", "\"\"\"Create the model hyperparameters.\n\n    Args:\n        flags (dict): Dictionary with the model requirements.\n\n    Returns:\n        HParams: Hyperparameter object.\n    \"\"\"", "\n", "init_dict", "=", "{", "\n", "# data", "\n", "\"support_quick_scoring\"", ":", "False", ",", "\n", "# models", "\n", "\"dropout\"", ":", "0.0", ",", "\n", "\"attention_hidden_dim\"", ":", "200", ",", "\n", "# nrms", "\n", "\"head_num\"", ":", "4", ",", "\n", "\"head_dim\"", ":", "100", ",", "\n", "# naml", "\n", "\"filter_num\"", ":", "200", ",", "\n", "\"window_size\"", ":", "3", ",", "\n", "\"vert_emb_dim\"", ":", "100", ",", "\n", "\"subvert_emb_dim\"", ":", "100", ",", "\n", "# lstur", "\n", "\"gru_unit\"", ":", "400", ",", "\n", "\"type\"", ":", "\"ini\"", ",", "\n", "# npa", "\n", "\"user_emb_dim\"", ":", "50", ",", "\n", "# train", "\n", "\"learning_rate\"", ":", "0.001", ",", "\n", "\"optimizer\"", ":", "\"adam\"", ",", "\n", "\"epochs\"", ":", "10", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "# show info", "\n", "\"show_step\"", ":", "1", ",", "\n", "}", "\n", "init_dict", ".", "update", "(", "flags", ")", "\n", "return", "HParams", "(", "init_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.prepare_hparams": [[247, 266], ["recommenders.models.deeprec.deeprec_utils.flat_config.update", "newsrec_utils.check_nn_config", "newsrec_utils.create_hparams", "recommenders.models.deeprec.deeprec_utils.load_yaml", "recommenders.models.deeprec.deeprec_utils.flat_config"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_nn_config", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.create_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_yaml", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.flat_config"], ["", "def", "prepare_hparams", "(", "yaml_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Prepare the model hyperparameters and check that all have the correct value.\n\n    Args:\n        yaml_file (str): YAML file as configuration.\n\n    Returns:\n        HParams: Hyperparameter object.\n    \"\"\"", "\n", "if", "yaml_file", "is", "not", "None", ":", "\n", "        ", "config", "=", "load_yaml", "(", "yaml_file", ")", "\n", "config", "=", "flat_config", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "{", "}", "\n", "\n", "", "config", ".", "update", "(", "kwargs", ")", "\n", "\n", "check_nn_config", "(", "config", ")", "\n", "return", "create_hparams", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.word_tokenize": [[268, 281], ["re.compile", "isinstance", "re.compile.findall", "sent.lower"], "function", ["None"], ["", "def", "word_tokenize", "(", "sent", ")", ":", "\n", "    ", "\"\"\"Split sentence into word list using regex.\n    Args:\n        sent (str): Input sentence\n\n    Return:\n        list: word list\n    \"\"\"", "\n", "pat", "=", "re", ".", "compile", "(", "r\"[\\w]+|[.,!?;|]\"", ")", "\n", "if", "isinstance", "(", "sent", ",", "str", ")", ":", "\n", "        ", "return", "pat", ".", "findall", "(", "sent", ".", "lower", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.newsample": [[283, 298], ["len", "random.sample", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "", "def", "newsample", "(", "news", ",", "ratio", ")", ":", "\n", "    ", "\"\"\"Sample ratio samples from news list.\n    If length of news is less than ratio, pad zeros.\n\n    Args:\n        news (list): input news list\n        ratio (int): sample number\n\n    Returns:\n        list: output of sample list.\n    \"\"\"", "\n", "if", "ratio", ">", "len", "(", "news", ")", ":", "\n", "        ", "return", "news", "+", "[", "0", "]", "*", "(", "ratio", "-", "len", "(", "news", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "random", ".", "sample", "(", "news", ",", "ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.get_mind_data_set": [[300, 333], ["None"], "function", ["None"], ["", "", "def", "get_mind_data_set", "(", "type", ")", ":", "\n", "    ", "\"\"\"Get MIND dataset address\n\n    Args:\n        type (str): type of mind dataset, must be in ['large', 'small', 'demo']\n\n    Returns:\n        list: data url and train valid dataset name\n    \"\"\"", "\n", "assert", "type", "in", "[", "\"large\"", ",", "\"small\"", ",", "\"demo\"", "]", "\n", "\n", "if", "type", "==", "\"large\"", ":", "\n", "        ", "return", "(", "\n", "\"https://mind201910small.blob.core.windows.net/release/\"", ",", "\n", "\"MINDlarge_train.zip\"", ",", "\n", "\"MINDlarge_dev.zip\"", ",", "\n", "\"MINDlarge_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "elif", "type", "==", "\"small\"", ":", "\n", "        ", "return", "(", "\n", "\"https://mind201910small.blob.core.windows.net/release/\"", ",", "\n", "\"MINDsmall_train.zip\"", ",", "\n", "\"MINDsmall_dev.zip\"", ",", "\n", "\"MINDsmall_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "elif", "type", "==", "\"demo\"", ":", "\n", "        ", "return", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.__init__": [[33, 60], ["mind_all_iterator.MINDAllIterator.load_dict", "mind_all_iterator.MINDAllIterator.load_dict", "mind_all_iterator.MINDAllIterator.load_dict", "mind_all_iterator.MINDAllIterator.load_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "npratio", "=", "-", "1", ",", "\n", "col_spliter", "=", "\"\\t\"", ",", "\n", "ID_spliter", "=", "\"%\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create necessary placeholders for the model.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\n            graph (object): the running graph. All created placeholder will be added to this graph.\n            col_spliter (str): column spliter in one line.\n            ID_spliter (str): ID spliter in one line.\n        \"\"\"", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "self", ".", "ID_spliter", "=", "ID_spliter", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "title_size", "=", "hparams", ".", "title_size", "\n", "self", ".", "body_size", "=", "hparams", ".", "body_size", "\n", "self", ".", "his_size", "=", "hparams", ".", "his_size", "\n", "self", ".", "npratio", "=", "npratio", "\n", "\n", "self", ".", "word_dict", "=", "self", ".", "load_dict", "(", "hparams", ".", "wordDict_file", ")", "\n", "self", ".", "vert_dict", "=", "self", ".", "load_dict", "(", "hparams", ".", "vertDict_file", ")", "\n", "self", ".", "subvert_dict", "=", "self", ".", "load_dict", "(", "hparams", ".", "subvertDict_file", ")", "\n", "self", ".", "uid2index", "=", "self", ".", "load_dict", "(", "hparams", ".", "userDict_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.load_dict": [[61, 72], ["open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "load_dict", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"Load pickled file\n\n        Args:\n            file path (str): File path\n\n        Returns:\n            object: pickle load obj\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.init_news": [[73, 129], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "tensorflow.io.gfile.GFile", "len", "range", "range", "line.strip().split", "recommenders.models.newsrec.newsrec_utils.word_tokenize", "recommenders.models.newsrec.newsrec_utils.word_tokenize", "news_title.append", "news_ab.append", "news_vert.append", "news_subvert.append", "len", "len", "len", "len", "min", "min", "len", "len", "len", "line.strip", "title[].lower", "ab[].lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.word_tokenize", "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.word_tokenize"], ["", "", "def", "init_news", "(", "self", ",", "news_file", ")", ":", "\n", "        ", "\"\"\"Init news information given news file, such as `news_title_index`, `news_abstract_index`.\n\n        Args:\n            news_file: path of news file\n        \"\"\"", "\n", "self", ".", "nid2index", "=", "{", "}", "\n", "news_title", "=", "[", "\"\"", "]", "\n", "news_ab", "=", "[", "\"\"", "]", "\n", "news_vert", "=", "[", "\"\"", "]", "\n", "news_subvert", "=", "[", "\"\"", "]", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "news_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "nid", ",", "vert", ",", "subvert", ",", "title", ",", "ab", ",", "url", ",", "_", ",", "_", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\n", "self", ".", "col_spliter", "\n", ")", "\n", "\n", "if", "nid", "in", "self", ".", "nid2index", ":", "\n", "                    ", "continue", "\n", "\n", "", "self", ".", "nid2index", "[", "nid", "]", "=", "len", "(", "self", ".", "nid2index", ")", "+", "1", "\n", "title", "=", "word_tokenize", "(", "title", ")", "\n", "ab", "=", "word_tokenize", "(", "ab", ")", "\n", "news_title", ".", "append", "(", "title", ")", "\n", "news_ab", ".", "append", "(", "ab", ")", "\n", "news_vert", ".", "append", "(", "vert", ")", "\n", "news_subvert", ".", "append", "(", "subvert", ")", "\n", "\n", "", "", "self", ".", "news_title_index", "=", "np", ".", "zeros", "(", "\n", "(", "len", "(", "news_title", ")", ",", "self", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "\n", "self", ".", "news_ab_index", "=", "np", ".", "zeros", "(", "(", "len", "(", "news_ab", ")", ",", "self", ".", "body_size", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "self", ".", "news_vert_index", "=", "np", ".", "zeros", "(", "(", "len", "(", "news_vert", ")", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "self", ".", "news_subvert_index", "=", "np", ".", "zeros", "(", "(", "len", "(", "news_subvert", ")", ",", "1", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "for", "news_index", "in", "range", "(", "len", "(", "news_title", ")", ")", ":", "\n", "            ", "title", "=", "news_title", "[", "news_index", "]", "\n", "ab", "=", "news_ab", "[", "news_index", "]", "\n", "vert", "=", "news_vert", "[", "news_index", "]", "\n", "subvert", "=", "news_subvert", "[", "news_index", "]", "\n", "for", "word_index", "in", "range", "(", "min", "(", "self", ".", "title_size", ",", "len", "(", "title", ")", ")", ")", ":", "\n", "                ", "if", "title", "[", "word_index", "]", "in", "self", ".", "word_dict", ":", "\n", "                    ", "self", ".", "news_title_index", "[", "news_index", ",", "word_index", "]", "=", "self", ".", "word_dict", "[", "\n", "title", "[", "word_index", "]", ".", "lower", "(", ")", "\n", "]", "\n", "", "", "for", "word_index_ab", "in", "range", "(", "min", "(", "self", ".", "body_size", ",", "len", "(", "ab", ")", ")", ")", ":", "\n", "                ", "if", "ab", "[", "word_index_ab", "]", "in", "self", ".", "word_dict", ":", "\n", "                    ", "self", ".", "news_ab_index", "[", "news_index", ",", "word_index_ab", "]", "=", "self", ".", "word_dict", "[", "\n", "ab", "[", "word_index_ab", "]", ".", "lower", "(", ")", "\n", "]", "\n", "", "", "if", "vert", "in", "self", ".", "vert_dict", ":", "\n", "                ", "self", ".", "news_vert_index", "[", "news_index", ",", "0", "]", "=", "self", ".", "vert_dict", "[", "vert", "]", "\n", "", "if", "subvert", "in", "self", ".", "subvert_dict", ":", "\n", "                ", "self", ".", "news_subvert_index", "[", "news_index", ",", "0", "]", "=", "self", ".", "subvert_dict", "[", "subvert", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.init_behaviors": [[130, 162], ["tensorflow.io.gfile.GFile", "mind_all_iterator.MINDAllIterator.histories.append", "mind_all_iterator.MINDAllIterator.imprs.append", "mind_all_iterator.MINDAllIterator.labels.append", "mind_all_iterator.MINDAllIterator.impr_indexes.append", "mind_all_iterator.MINDAllIterator.uindexes.append", "line.strip().split", "int", "history.split", "impr.split", "impr.split", "line.strip", "len", "i.split", "i.split"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "init_behaviors", "(", "self", ",", "behaviors_file", ")", ":", "\n", "        ", "\"\"\"Init behavior logs given behaviors file.\n\n        Args:\n            behaviors_file (str): path of behaviors file\n        \"\"\"", "\n", "self", ".", "histories", "=", "[", "]", "\n", "self", ".", "imprs", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "self", ".", "impr_indexes", "=", "[", "]", "\n", "self", ".", "uindexes", "=", "[", "]", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "behaviors_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "impr_index", "=", "0", "\n", "for", "line", "in", "rd", ":", "\n", "                ", "uid", ",", "time", ",", "history", ",", "impr", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "self", ".", "col_spliter", ")", "[", "-", "4", ":", "]", "\n", "\n", "history", "=", "[", "self", ".", "nid2index", "[", "i", "]", "for", "i", "in", "history", ".", "split", "(", ")", "]", "\n", "history", "=", "[", "0", "]", "*", "(", "self", ".", "his_size", "-", "len", "(", "history", ")", ")", "+", "history", "[", "\n", ":", "self", ".", "his_size", "\n", "]", "\n", "\n", "impr_news", "=", "[", "self", ".", "nid2index", "[", "i", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "]", "for", "i", "in", "impr", ".", "split", "(", ")", "]", "\n", "label", "=", "[", "int", "(", "i", ".", "split", "(", "\"-\"", ")", "[", "1", "]", ")", "for", "i", "in", "impr", ".", "split", "(", ")", "]", "\n", "uindex", "=", "self", ".", "uid2index", "[", "uid", "]", "if", "uid", "in", "self", ".", "uid2index", "else", "0", "\n", "\n", "self", ".", "histories", ".", "append", "(", "history", ")", "\n", "self", ".", "imprs", ".", "append", "(", "impr_news", ")", "\n", "self", ".", "labels", ".", "append", "(", "label", ")", "\n", "self", ".", "impr_indexes", ".", "append", "(", "impr_index", ")", "\n", "self", ".", "uindexes", ".", "append", "(", "uindex", ")", "\n", "impr_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.parser_one_line": [[163, 257], ["zip", "zip", "recommenders.models.newsrec.newsrec_utils.newsample", "impr_index.append", "user_index.append", "candidate_title_index.append", "impr_index.append", "user_index.append", "poss.append", "negs.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.newsample"], ["", "", "", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Parse one string line into feature values.\n\n        Args:\n            line (str): a string indicating one instance.\n\n        Yields:\n            list: Parsed results including label, impression id , user id,\n            candidate_title_index, clicked_title_index,\n            candidate_ab_index, clicked_ab_index,\n            candidate_vert_index, clicked_vert_index,\n            candidate_subvert_index, clicked_subvert_index,\n        \"\"\"", "\n", "if", "self", ".", "npratio", ">", "0", ":", "\n", "            ", "impr_label", "=", "self", ".", "labels", "[", "line", "]", "\n", "impr", "=", "self", ".", "imprs", "[", "line", "]", "\n", "\n", "poss", "=", "[", "]", "\n", "negs", "=", "[", "]", "\n", "\n", "for", "news", ",", "click", "in", "zip", "(", "impr", ",", "impr_label", ")", ":", "\n", "                ", "if", "click", "==", "1", ":", "\n", "                    ", "poss", ".", "append", "(", "news", ")", "\n", "", "else", ":", "\n", "                    ", "negs", ".", "append", "(", "news", ")", "\n", "\n", "", "", "for", "p", "in", "poss", ":", "\n", "                ", "candidate_title_index", "=", "[", "]", "\n", "impr_index", "=", "[", "]", "\n", "user_index", "=", "[", "]", "\n", "label", "=", "[", "1", "]", "+", "[", "0", "]", "*", "self", ".", "npratio", "\n", "\n", "n", "=", "newsample", "(", "negs", ",", "self", ".", "npratio", ")", "\n", "candidate_title_index", "=", "self", ".", "news_title_index", "[", "[", "p", "]", "+", "n", "]", "\n", "candidate_ab_index", "=", "self", ".", "news_ab_index", "[", "[", "p", "]", "+", "n", "]", "\n", "candidate_vert_index", "=", "self", ".", "news_vert_index", "[", "[", "p", "]", "+", "n", "]", "\n", "candidate_subvert_index", "=", "self", ".", "news_subvert_index", "[", "[", "p", "]", "+", "n", "]", "\n", "click_title_index", "=", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_ab_index", "=", "self", ".", "news_ab_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_vert_index", "=", "self", ".", "news_vert_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_subvert_index", "=", "self", ".", "news_subvert_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "impr_index", ".", "append", "(", "self", ".", "impr_indexes", "[", "line", "]", ")", "\n", "user_index", ".", "append", "(", "self", ".", "uindexes", "[", "line", "]", ")", "\n", "\n", "yield", "(", "\n", "label", ",", "\n", "impr_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "candidate_ab_index", ",", "\n", "candidate_vert_index", ",", "\n", "candidate_subvert_index", ",", "\n", "click_title_index", ",", "\n", "click_ab_index", ",", "\n", "click_vert_index", ",", "\n", "click_subvert_index", ",", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "impr_label", "=", "self", ".", "labels", "[", "line", "]", "\n", "impr", "=", "self", ".", "imprs", "[", "line", "]", "\n", "\n", "for", "news", ",", "label", "in", "zip", "(", "impr", ",", "impr_label", ")", ":", "\n", "                ", "candidate_title_index", "=", "[", "]", "\n", "impr_index", "=", "[", "]", "\n", "user_index", "=", "[", "]", "\n", "label", "=", "[", "label", "]", "\n", "\n", "candidate_title_index", ".", "append", "(", "self", ".", "news_title_index", "[", "news", "]", ")", "\n", "click_title_index", "=", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "\n", "candidate_title_index", "=", "self", ".", "news_title_index", "[", "news", "]", "\n", "candidate_ab_index", "=", "self", ".", "news_ab_index", "[", "news", "]", "\n", "candidate_vert_index", "=", "self", ".", "news_vert_index", "[", "news", "]", "\n", "candidate_subvert_index", "=", "self", ".", "news_subvert_index", "[", "news", "]", "\n", "click_title_index", "=", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_ab_index", "=", "self", ".", "news_ab_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_vert_index", "=", "self", ".", "news_vert_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "click_subvert_index", "=", "self", ".", "news_subvert_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "impr_index", ".", "append", "(", "self", ".", "impr_indexes", "[", "line", "]", ")", "\n", "user_index", ".", "append", "(", "self", ".", "uindexes", "[", "line", "]", ")", "\n", "\n", "yield", "(", "\n", "label", ",", "\n", "impr_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "candidate_ab_index", ",", "\n", "candidate_vert_index", ",", "\n", "candidate_subvert_index", ",", "\n", "click_title_index", ",", "\n", "click_ab_index", ",", "\n", "click_vert_index", ",", "\n", "click_subvert_index", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.load_data_from_file": [[259, 347], ["numpy.arange", "hasattr", "mind_all_iterator.MINDAllIterator.init_news", "hasattr", "mind_all_iterator.MINDAllIterator.init_behaviors", "len", "numpy.random.shuffle", "mind_all_iterator.MINDAllIterator.parser_one_line", "candidate_title_indexes.append", "candidate_ab_indexes.append", "candidate_vert_indexes.append", "candidate_subvert_indexes.append", "click_title_indexes.append", "click_ab_indexes.append", "click_vert_indexes.append", "click_subvert_indexes.append", "imp_indexes.append", "user_indexes.append", "label_list.append", "mind_all_iterator.MINDAllIterator._convert_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data"], ["", "", "", "def", "load_data_from_file", "(", "self", ",", "news_file", ",", "behavior_file", ")", ":", "\n", "        ", "\"\"\"Read and parse data from a file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n            beahaviros_file (str): A file contains information of user impressions.\n\n        Yields:\n            object: An iterator that yields parsed results, in the format of graph feed_dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"impr_indexes\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behavior_file", ")", "\n", "\n", "", "label_list", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "user_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "candidate_ab_indexes", "=", "[", "]", "\n", "candidate_vert_indexes", "=", "[", "]", "\n", "candidate_subvert_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "click_ab_indexes", "=", "[", "]", "\n", "click_vert_indexes", "=", "[", "]", "\n", "click_subvert_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "indexes", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "\n", "if", "self", ".", "npratio", ">", "0", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "indexes", ")", "\n", "\n", "", "for", "index", "in", "indexes", ":", "\n", "            ", "for", "(", "\n", "label", ",", "\n", "impr_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "candidate_ab_index", ",", "\n", "candidate_vert_index", ",", "\n", "candidate_subvert_index", ",", "\n", "click_title_index", ",", "\n", "click_ab_index", ",", "\n", "click_vert_index", ",", "\n", "click_subvert_index", ",", "\n", ")", "in", "self", ".", "parser_one_line", "(", "index", ")", ":", "\n", "                ", "candidate_title_indexes", ".", "append", "(", "candidate_title_index", ")", "\n", "candidate_ab_indexes", ".", "append", "(", "candidate_ab_index", ")", "\n", "candidate_vert_indexes", ".", "append", "(", "candidate_vert_index", ")", "\n", "candidate_subvert_indexes", ".", "append", "(", "candidate_subvert_index", ")", "\n", "click_title_indexes", ".", "append", "(", "click_title_index", ")", "\n", "click_ab_indexes", ".", "append", "(", "click_ab_index", ")", "\n", "click_vert_indexes", ".", "append", "(", "click_vert_index", ")", "\n", "click_subvert_indexes", ".", "append", "(", "click_subvert_index", ")", "\n", "imp_indexes", ".", "append", "(", "impr_index", ")", "\n", "user_indexes", ".", "append", "(", "user_index", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "yield", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "imp_indexes", ",", "\n", "user_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "candidate_ab_indexes", ",", "\n", "candidate_vert_indexes", ",", "\n", "candidate_subvert_indexes", ",", "\n", "click_title_indexes", ",", "\n", "click_ab_indexes", ",", "\n", "click_vert_indexes", ",", "\n", "click_subvert_indexes", ",", "\n", ")", "\n", "label_list", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "user_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "candidate_ab_indexes", "=", "[", "]", "\n", "candidate_vert_indexes", "=", "[", "]", "\n", "candidate_subvert_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "click_ab_indexes", "=", "[", "]", "\n", "click_vert_indexes", "=", "[", "]", "\n", "click_subvert_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator._convert_data": [[348, 408], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "", "", "def", "_convert_data", "(", "\n", "self", ",", "\n", "label_list", ",", "\n", "imp_indexes", ",", "\n", "user_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "candidate_ab_indexes", ",", "\n", "candidate_vert_indexes", ",", "\n", "candidate_subvert_indexes", ",", "\n", "click_title_indexes", ",", "\n", "click_ab_indexes", ",", "\n", "click_vert_indexes", ",", "\n", "click_subvert_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            label_list (list): a list of ground-truth labels.\n            imp_indexes (list): a list of impression indexes.\n            user_indexes (list): a list of user indexes.\n            candidate_title_indexes (list): the candidate news titles' words indices.\n            candidate_ab_indexes (list): the candidate news abstarcts' words indices.\n            candidate_vert_indexes (list): the candidate news verts' words indices.\n            candidate_subvert_indexes (list): the candidate news subverts' indices.\n            click_title_indexes (list): words indices for user's clicked news titles.\n            click_ab_indexes (list): words indices for user's clicked news abstarcts.\n            click_vert_indexes (list): indices for user's clicked news verts.\n            click_subvert_indexes (list):indices for user's clicked news subverts.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "labels", "=", "np", ".", "asarray", "(", "label_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "imp_indexes", "=", "np", ".", "asarray", "(", "imp_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "user_indexes", "=", "np", ".", "asarray", "(", "user_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_title_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_title_indexes", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "candidate_ab_index_batch", "=", "np", ".", "asarray", "(", "candidate_ab_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "candidate_vert_index_batch", "=", "np", ".", "asarray", "(", "candidate_vert_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "candidate_subvert_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_subvert_indexes", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "click_title_index_batch", "=", "np", ".", "asarray", "(", "click_title_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_ab_index_batch", "=", "np", ".", "asarray", "(", "click_ab_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_vert_index_batch", "=", "np", ".", "asarray", "(", "click_vert_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_subvert_index_batch", "=", "np", ".", "asarray", "(", "click_subvert_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "{", "\n", "\"impression_index_batch\"", ":", "imp_indexes", ",", "\n", "\"user_index_batch\"", ":", "user_indexes", ",", "\n", "\"clicked_title_batch\"", ":", "click_title_index_batch", ",", "\n", "\"clicked_ab_batch\"", ":", "click_ab_index_batch", ",", "\n", "\"clicked_vert_batch\"", ":", "click_vert_index_batch", ",", "\n", "\"clicked_subvert_batch\"", ":", "click_subvert_index_batch", ",", "\n", "\"candidate_title_batch\"", ":", "candidate_title_index_batch", ",", "\n", "\"candidate_ab_batch\"", ":", "candidate_ab_index_batch", ",", "\n", "\"candidate_vert_batch\"", ":", "candidate_vert_index_batch", ",", "\n", "\"candidate_subvert_batch\"", ":", "candidate_subvert_index_batch", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.load_user_from_file": [[410, 459], ["range", "hasattr", "mind_all_iterator.MINDAllIterator.init_news", "hasattr", "mind_all_iterator.MINDAllIterator.init_behaviors", "len", "click_title_indexes.append", "click_ab_indexes.append", "click_vert_indexes.append", "click_subvert_indexes.append", "user_indexes.append", "impr_indexes.append", "mind_all_iterator.MINDAllIterator._convert_user_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_user_data"], ["", "def", "load_user_from_file", "(", "self", ",", "news_file", ",", "behavior_file", ")", ":", "\n", "        ", "\"\"\"Read and parse user data from news file and behavior file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n            beahaviros_file (str): A file contains information of user impressions.\n\n        Yields:\n            object: An iterator that yields parsed user feature, in the format of dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"impr_indexes\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behavior_file", ")", "\n", "\n", "", "user_indexes", "=", "[", "]", "\n", "impr_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "click_ab_indexes", "=", "[", "]", "\n", "click_vert_indexes", "=", "[", "]", "\n", "click_subvert_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "impr_indexes", ")", ")", ":", "\n", "            ", "click_title_indexes", ".", "append", "(", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "index", "]", "]", ")", "\n", "click_ab_indexes", ".", "append", "(", "self", ".", "news_ab_index", "[", "self", ".", "histories", "[", "index", "]", "]", ")", "\n", "click_vert_indexes", ".", "append", "(", "self", ".", "news_vert_index", "[", "self", ".", "histories", "[", "index", "]", "]", ")", "\n", "click_subvert_indexes", ".", "append", "(", "self", ".", "news_subvert_index", "[", "self", ".", "histories", "[", "index", "]", "]", ")", "\n", "user_indexes", ".", "append", "(", "self", ".", "uindexes", "[", "index", "]", ")", "\n", "impr_indexes", ".", "append", "(", "self", ".", "impr_indexes", "[", "index", "]", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                ", "yield", "self", ".", "_convert_user_data", "(", "\n", "user_indexes", ",", "\n", "impr_indexes", ",", "\n", "click_title_indexes", ",", "\n", "click_ab_indexes", ",", "\n", "click_vert_indexes", ",", "\n", "click_subvert_indexes", ",", "\n", ")", "\n", "user_indexes", "=", "[", "]", "\n", "impr_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "click_ab_indexes", "=", "[", "]", "\n", "click_vert_indexes", "=", "[", "]", "\n", "click_subvert_indexes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator._convert_user_data": [[460, 496], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "", "def", "_convert_user_data", "(", "\n", "self", ",", "\n", "user_indexes", ",", "\n", "impr_indexes", ",", "\n", "click_title_indexes", ",", "\n", "click_ab_indexes", ",", "\n", "click_vert_indexes", ",", "\n", "click_subvert_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            user_indexes (list): a list of user indexes.\n            click_title_indexes (list): words indices for user's clicked news titles.\n            click_ab_indexes (list): words indices for user's clicked news abs.\n            click_vert_indexes (list): words indices for user's clicked news verts.\n            click_subvert_indexes (list): words indices for user's clicked news subverts.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "user_indexes", "=", "np", ".", "asarray", "(", "user_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "impr_indexes", "=", "np", ".", "asarray", "(", "impr_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "click_title_index_batch", "=", "np", ".", "asarray", "(", "click_title_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_ab_index_batch", "=", "np", ".", "asarray", "(", "click_ab_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_vert_index_batch", "=", "np", ".", "asarray", "(", "click_vert_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "click_subvert_index_batch", "=", "np", ".", "asarray", "(", "click_subvert_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "return", "{", "\n", "\"user_index_batch\"", ":", "user_indexes", ",", "\n", "\"impr_index_batch\"", ":", "impr_indexes", ",", "\n", "\"clicked_title_batch\"", ":", "click_title_index_batch", ",", "\n", "\"clicked_ab_batch\"", ":", "click_ab_index_batch", ",", "\n", "\"clicked_vert_batch\"", ":", "click_vert_index_batch", ",", "\n", "\"clicked_subvert_batch\"", ":", "click_subvert_index_batch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.load_news_from_file": [[498, 538], ["range", "hasattr", "mind_all_iterator.MINDAllIterator.init_news", "len", "news_indexes.append", "candidate_title_indexes.append", "candidate_ab_indexes.append", "candidate_vert_indexes.append", "candidate_subvert_indexes.append", "mind_all_iterator.MINDAllIterator._convert_news_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_news_data"], ["", "def", "load_news_from_file", "(", "self", ",", "news_file", ")", ":", "\n", "        ", "\"\"\"Read and parse user data from news file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n\n        Yields:\n            object: An iterator that yields parsed news feature, in the format of dict.\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "news_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "candidate_ab_indexes", "=", "[", "]", "\n", "candidate_vert_indexes", "=", "[", "]", "\n", "candidate_subvert_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "news_title_index", ")", ")", ":", "\n", "            ", "news_indexes", ".", "append", "(", "index", ")", "\n", "candidate_title_indexes", ".", "append", "(", "self", ".", "news_title_index", "[", "index", "]", ")", "\n", "candidate_ab_indexes", ".", "append", "(", "self", ".", "news_ab_index", "[", "index", "]", ")", "\n", "candidate_vert_indexes", ".", "append", "(", "self", ".", "news_vert_index", "[", "index", "]", ")", "\n", "candidate_subvert_indexes", ".", "append", "(", "self", ".", "news_subvert_index", "[", "index", "]", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                ", "yield", "self", ".", "_convert_news_data", "(", "\n", "news_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "candidate_ab_indexes", ",", "\n", "candidate_vert_indexes", ",", "\n", "candidate_subvert_indexes", ",", "\n", ")", "\n", "news_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "candidate_ab_indexes", "=", "[", "]", "\n", "candidate_vert_indexes", "=", "[", "]", "\n", "candidate_subvert_indexes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator._convert_news_data": [[539, 576], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "", "def", "_convert_news_data", "(", "\n", "self", ",", "\n", "news_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "candidate_ab_indexes", ",", "\n", "candidate_vert_indexes", ",", "\n", "candidate_subvert_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            news_indexes (list): a list of news indexes.\n            candidate_title_indexes (list): the candidate news titles' words indices.\n            candidate_ab_indexes (list): the candidate news abstarcts' words indices.\n            candidate_vert_indexes (list): the candidate news verts' words indices.\n            candidate_subvert_indexes (list): the candidate news subverts' words indices.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "news_indexes_batch", "=", "np", ".", "asarray", "(", "news_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_title_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_title_indexes", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "candidate_ab_index_batch", "=", "np", ".", "asarray", "(", "candidate_ab_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_vert_index_batch", "=", "np", ".", "asarray", "(", "candidate_vert_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_subvert_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_subvert_indexes", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "\n", "return", "{", "\n", "\"news_index_batch\"", ":", "news_indexes_batch", ",", "\n", "\"candidate_title_batch\"", ":", "candidate_title_index_batch", ",", "\n", "\"candidate_ab_batch\"", ":", "candidate_ab_index_batch", ",", "\n", "\"candidate_vert_batch\"", ":", "candidate_vert_index_batch", ",", "\n", "\"candidate_subvert_batch\"", ":", "candidate_subvert_index_batch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_all_iterator.MINDAllIterator.load_impression_from_file": [[578, 602], ["numpy.arange", "hasattr", "mind_all_iterator.MINDAllIterator.init_behaviors", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors"], ["", "def", "load_impression_from_file", "(", "self", ",", "behaivors_file", ")", ":", "\n", "        ", "\"\"\"Read and parse impression data from behaivors file.\n\n        Args:\n            behaivors_file (str): A file contains several informations of behaviros.\n\n        Yields:\n            object: An iterator that yields parsed impression data, in the format of dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"histories\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behaivors_file", ")", "\n", "\n", "", "indexes", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "\n", "for", "index", "in", "indexes", ":", "\n", "            ", "impr_label", "=", "np", ".", "array", "(", "self", ".", "labels", "[", "index", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "impr_news", "=", "np", ".", "array", "(", "self", ".", "imprs", "[", "index", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "yield", "(", "\n", "self", ".", "impr_indexes", "[", "index", "]", ",", "\n", "impr_news", ",", "\n", "self", ".", "uindexes", "[", "index", "]", ",", "\n", "impr_label", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.__init__": [[32, 56], ["mind_iterator.MINDIterator.load_dict", "mind_iterator.MINDIterator.load_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "npratio", "=", "-", "1", ",", "\n", "col_spliter", "=", "\"\\t\"", ",", "\n", "ID_spliter", "=", "\"%\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create necessary placeholders for the model.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\n            npratio (int): negaive and positive ratio used in negative sampling. -1 means no need of negtive sampling.\n            col_spliter (str): column spliter in one line.\n            ID_spliter (str): ID spliter in one line.\n        \"\"\"", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "self", ".", "ID_spliter", "=", "ID_spliter", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "title_size", "=", "hparams", ".", "title_size", "\n", "self", ".", "his_size", "=", "hparams", ".", "his_size", "\n", "self", ".", "npratio", "=", "npratio", "\n", "\n", "self", ".", "word_dict", "=", "self", ".", "load_dict", "(", "hparams", ".", "wordDict_file", ")", "\n", "self", ".", "uid2index", "=", "self", ".", "load_dict", "(", "hparams", ".", "userDict_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_dict": [[57, 68], ["open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "load_dict", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"load pickle file\n\n        Args:\n            file path (str): file path\n\n        Returns:\n            object: pickle loaded object\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news": [[69, 101], ["numpy.zeros", "range", "tensorflow.io.gfile.GFile", "len", "range", "line.strip().split", "recommenders.models.newsrec.newsrec_utils.word_tokenize", "news_title.append", "len", "min", "len", "len", "line.strip", "title[].lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.word_tokenize"], ["", "", "def", "init_news", "(", "self", ",", "news_file", ")", ":", "\n", "        ", "\"\"\"init news information given news file, such as news_title_index and nid2index.\n        Args:\n            news_file: path of news file\n        \"\"\"", "\n", "\n", "self", ".", "nid2index", "=", "{", "}", "\n", "news_title", "=", "[", "\"\"", "]", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "news_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "nid", ",", "vert", ",", "subvert", ",", "title", ",", "ab", ",", "url", ",", "_", ",", "_", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\n", "self", ".", "col_spliter", "\n", ")", "\n", "\n", "if", "nid", "in", "self", ".", "nid2index", ":", "\n", "                    ", "continue", "\n", "\n", "", "self", ".", "nid2index", "[", "nid", "]", "=", "len", "(", "self", ".", "nid2index", ")", "+", "1", "\n", "title", "=", "word_tokenize", "(", "title", ")", "\n", "news_title", ".", "append", "(", "title", ")", "\n", "\n", "", "", "self", ".", "news_title_index", "=", "np", ".", "zeros", "(", "\n", "(", "len", "(", "news_title", ")", ",", "self", ".", "title_size", ")", ",", "dtype", "=", "\"int32\"", "\n", ")", "\n", "\n", "for", "news_index", "in", "range", "(", "len", "(", "news_title", ")", ")", ":", "\n", "            ", "title", "=", "news_title", "[", "news_index", "]", "\n", "for", "word_index", "in", "range", "(", "min", "(", "self", ".", "title_size", ",", "len", "(", "title", ")", ")", ")", ":", "\n", "                ", "if", "title", "[", "word_index", "]", "in", "self", ".", "word_dict", ":", "\n", "                    ", "self", ".", "news_title_index", "[", "news_index", ",", "word_index", "]", "=", "self", ".", "word_dict", "[", "\n", "title", "[", "word_index", "]", ".", "lower", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors": [[103, 135], ["tensorflow.io.gfile.GFile", "mind_iterator.MINDIterator.histories.append", "mind_iterator.MINDIterator.imprs.append", "mind_iterator.MINDIterator.labels.append", "mind_iterator.MINDIterator.impr_indexes.append", "mind_iterator.MINDIterator.uindexes.append", "line.strip().split", "int", "history.split", "impr.split", "impr.split", "line.strip", "len", "i.split", "i.split"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "", "def", "init_behaviors", "(", "self", ",", "behaviors_file", ")", ":", "\n", "        ", "\"\"\"init behavior logs given behaviors file.\n\n        Args:\n        behaviors_file: path of behaviors file\n        \"\"\"", "\n", "self", ".", "histories", "=", "[", "]", "\n", "self", ".", "imprs", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "self", ".", "impr_indexes", "=", "[", "]", "\n", "self", ".", "uindexes", "=", "[", "]", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "behaviors_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "impr_index", "=", "0", "\n", "for", "line", "in", "rd", ":", "\n", "                ", "uid", ",", "time", ",", "history", ",", "impr", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "self", ".", "col_spliter", ")", "[", "-", "4", ":", "]", "\n", "\n", "history", "=", "[", "self", ".", "nid2index", "[", "i", "]", "for", "i", "in", "history", ".", "split", "(", ")", "]", "\n", "history", "=", "[", "0", "]", "*", "(", "self", ".", "his_size", "-", "len", "(", "history", ")", ")", "+", "history", "[", "\n", ":", "self", ".", "his_size", "\n", "]", "\n", "\n", "impr_news", "=", "[", "self", ".", "nid2index", "[", "i", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "]", "for", "i", "in", "impr", ".", "split", "(", ")", "]", "\n", "label", "=", "[", "int", "(", "i", ".", "split", "(", "\"-\"", ")", "[", "1", "]", ")", "for", "i", "in", "impr", ".", "split", "(", ")", "]", "\n", "uindex", "=", "self", ".", "uid2index", "[", "uid", "]", "if", "uid", "in", "self", ".", "uid2index", "else", "0", "\n", "\n", "self", ".", "histories", ".", "append", "(", "history", ")", "\n", "self", ".", "imprs", ".", "append", "(", "impr_news", ")", "\n", "self", ".", "labels", ".", "append", "(", "label", ")", "\n", "self", ".", "impr_indexes", ".", "append", "(", "impr_index", ")", "\n", "self", ".", "uindexes", ".", "append", "(", "uindex", ")", "\n", "impr_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.parser_one_line": [[136, 201], ["zip", "zip", "recommenders.models.newsrec.newsrec_utils.newsample", "impr_index.append", "user_index.append", "candidate_title_index.append", "impr_index.append", "user_index.append", "poss.append", "negs.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.newsample"], ["", "", "", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Parse one behavior sample into feature values.\n        if npratio is larger than 0, return negtive sampled result.\n\n        Args:\n            line (int): sample index.\n\n        Yields:\n            list: Parsed results including label, impression id , user id,\n            candidate_title_index, clicked_title_index.\n        \"\"\"", "\n", "if", "self", ".", "npratio", ">", "0", ":", "\n", "            ", "impr_label", "=", "self", ".", "labels", "[", "line", "]", "\n", "impr", "=", "self", ".", "imprs", "[", "line", "]", "\n", "\n", "poss", "=", "[", "]", "\n", "negs", "=", "[", "]", "\n", "\n", "for", "news", ",", "click", "in", "zip", "(", "impr", ",", "impr_label", ")", ":", "\n", "                ", "if", "click", "==", "1", ":", "\n", "                    ", "poss", ".", "append", "(", "news", ")", "\n", "", "else", ":", "\n", "                    ", "negs", ".", "append", "(", "news", ")", "\n", "\n", "", "", "for", "p", "in", "poss", ":", "\n", "                ", "candidate_title_index", "=", "[", "]", "\n", "impr_index", "=", "[", "]", "\n", "user_index", "=", "[", "]", "\n", "label", "=", "[", "1", "]", "+", "[", "0", "]", "*", "self", ".", "npratio", "\n", "\n", "n", "=", "newsample", "(", "negs", ",", "self", ".", "npratio", ")", "\n", "candidate_title_index", "=", "self", ".", "news_title_index", "[", "[", "p", "]", "+", "n", "]", "\n", "click_title_index", "=", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "impr_index", ".", "append", "(", "self", ".", "impr_indexes", "[", "line", "]", ")", "\n", "user_index", ".", "append", "(", "self", ".", "uindexes", "[", "line", "]", ")", "\n", "\n", "yield", "(", "\n", "label", ",", "\n", "impr_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "click_title_index", ",", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "impr_label", "=", "self", ".", "labels", "[", "line", "]", "\n", "impr", "=", "self", ".", "imprs", "[", "line", "]", "\n", "\n", "for", "news", ",", "label", "in", "zip", "(", "impr", ",", "impr_label", ")", ":", "\n", "                ", "candidate_title_index", "=", "[", "]", "\n", "impr_index", "=", "[", "]", "\n", "user_index", "=", "[", "]", "\n", "label", "=", "[", "label", "]", "\n", "\n", "candidate_title_index", ".", "append", "(", "self", ".", "news_title_index", "[", "news", "]", ")", "\n", "click_title_index", "=", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "line", "]", "]", "\n", "impr_index", ".", "append", "(", "self", ".", "impr_indexes", "[", "line", "]", ")", "\n", "user_index", ".", "append", "(", "self", ".", "uindexes", "[", "line", "]", ")", "\n", "\n", "yield", "(", "\n", "label", ",", "\n", "impr_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "click_title_index", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_data_from_file": [[203, 269], ["numpy.arange", "hasattr", "mind_iterator.MINDIterator.init_news", "hasattr", "mind_iterator.MINDIterator.init_behaviors", "len", "numpy.random.shuffle", "mind_iterator.MINDIterator.parser_one_line", "candidate_title_indexes.append", "click_title_indexes.append", "imp_indexes.append", "user_indexes.append", "label_list.append", "mind_iterator.MINDIterator._convert_data", "mind_iterator.MINDIterator._convert_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data"], ["", "", "", "def", "load_data_from_file", "(", "self", ",", "news_file", ",", "behavior_file", ")", ":", "\n", "        ", "\"\"\"Read and parse data from news file and behavior file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n            beahaviros_file (str): A file contains information of user impressions.\n\n        Yields:\n            object: An iterator that yields parsed results, in the format of dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"impr_indexes\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behavior_file", ")", "\n", "\n", "", "label_list", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "user_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "indexes", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "\n", "if", "self", ".", "npratio", ">", "0", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "indexes", ")", "\n", "\n", "", "for", "index", "in", "indexes", ":", "\n", "            ", "for", "(", "\n", "label", ",", "\n", "imp_index", ",", "\n", "user_index", ",", "\n", "candidate_title_index", ",", "\n", "click_title_index", ",", "\n", ")", "in", "self", ".", "parser_one_line", "(", "index", ")", ":", "\n", "                ", "candidate_title_indexes", ".", "append", "(", "candidate_title_index", ")", "\n", "click_title_indexes", ".", "append", "(", "click_title_index", ")", "\n", "imp_indexes", ".", "append", "(", "imp_index", ")", "\n", "user_indexes", ".", "append", "(", "user_index", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "yield", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "imp_indexes", ",", "\n", "user_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", "\n", "label_list", "=", "[", "]", "\n", "imp_indexes", "=", "[", "]", "\n", "user_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "", "", "", "if", "cnt", ">", "0", ":", "\n", "            ", "yield", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "imp_indexes", ",", "\n", "user_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_data": [[271, 305], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "def", "_convert_data", "(", "\n", "self", ",", "\n", "label_list", ",", "\n", "imp_indexes", ",", "\n", "user_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            label_list (list): a list of ground-truth labels.\n            imp_indexes (list): a list of impression indexes.\n            user_indexes (list): a list of user indexes.\n            candidate_title_indexes (list): the candidate news titles' words indices.\n            click_title_indexes (list): words indices for user's clicked news titles.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "labels", "=", "np", ".", "asarray", "(", "label_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "imp_indexes", "=", "np", ".", "asarray", "(", "imp_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "user_indexes", "=", "np", ".", "asarray", "(", "user_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_title_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_title_indexes", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "click_title_index_batch", "=", "np", ".", "asarray", "(", "click_title_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "{", "\n", "\"impression_index_batch\"", ":", "imp_indexes", ",", "\n", "\"user_index_batch\"", ":", "user_indexes", ",", "\n", "\"clicked_title_batch\"", ":", "click_title_index_batch", ",", "\n", "\"candidate_title_batch\"", ":", "candidate_title_index_batch", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_user_from_file": [[307, 351], ["range", "hasattr", "mind_iterator.MINDIterator.init_news", "hasattr", "mind_iterator.MINDIterator.init_behaviors", "len", "click_title_indexes.append", "user_indexes.append", "impr_indexes.append", "mind_iterator.MINDIterator._convert_user_data", "mind_iterator.MINDIterator._convert_user_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_user_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_user_data"], ["", "def", "load_user_from_file", "(", "self", ",", "news_file", ",", "behavior_file", ")", ":", "\n", "        ", "\"\"\"Read and parse user data from news file and behavior file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n            beahaviros_file (str): A file contains information of user impressions.\n\n        Yields:\n            object: An iterator that yields parsed user feature, in the format of dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"impr_indexes\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behavior_file", ")", "\n", "\n", "", "user_indexes", "=", "[", "]", "\n", "impr_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "impr_indexes", ")", ")", ":", "\n", "            ", "click_title_indexes", ".", "append", "(", "self", ".", "news_title_index", "[", "self", ".", "histories", "[", "index", "]", "]", ")", "\n", "user_indexes", ".", "append", "(", "self", ".", "uindexes", "[", "index", "]", ")", "\n", "impr_indexes", ".", "append", "(", "self", ".", "impr_indexes", "[", "index", "]", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                ", "yield", "self", ".", "_convert_user_data", "(", "\n", "user_indexes", ",", "\n", "impr_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", "\n", "user_indexes", "=", "[", "]", "\n", "impr_indexes", "=", "[", "]", "\n", "click_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "            ", "yield", "self", ".", "_convert_user_data", "(", "\n", "user_indexes", ",", "\n", "impr_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_user_data": [[353, 377], ["numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "def", "_convert_user_data", "(", "\n", "self", ",", "\n", "user_indexes", ",", "\n", "impr_indexes", ",", "\n", "click_title_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            user_indexes (list): a list of user indexes.\n            click_title_indexes (list): words indices for user's clicked news titles.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "user_indexes", "=", "np", ".", "asarray", "(", "user_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "impr_indexes", "=", "np", ".", "asarray", "(", "impr_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "click_title_index_batch", "=", "np", ".", "asarray", "(", "click_title_indexes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "return", "{", "\n", "\"user_index_batch\"", ":", "user_indexes", ",", "\n", "\"impr_index_batch\"", ":", "impr_indexes", ",", "\n", "\"clicked_title_batch\"", ":", "click_title_index_batch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_news_from_file": [[379, 413], ["range", "hasattr", "mind_iterator.MINDIterator.init_news", "len", "news_indexes.append", "candidate_title_indexes.append", "mind_iterator.MINDIterator._convert_news_data", "mind_iterator.MINDIterator._convert_news_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_news", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_news_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_news_data"], ["", "def", "load_news_from_file", "(", "self", ",", "news_file", ")", ":", "\n", "        ", "\"\"\"Read and parse user data from news file.\n\n        Args:\n            news_file (str): A file contains several informations of news.\n\n        Yields:\n            object: An iterator that yields parsed news feature, in the format of dict.\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"news_title_index\"", ")", ":", "\n", "            ", "self", ".", "init_news", "(", "news_file", ")", "\n", "\n", "", "news_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "news_title_index", ")", ")", ":", "\n", "            ", "news_indexes", ".", "append", "(", "index", ")", "\n", "candidate_title_indexes", ".", "append", "(", "self", ".", "news_title_index", "[", "index", "]", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                ", "yield", "self", ".", "_convert_news_data", "(", "\n", "news_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", ")", "\n", "news_indexes", "=", "[", "]", "\n", "candidate_title_indexes", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "            ", "yield", "self", ".", "_convert_news_data", "(", "\n", "news_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator._convert_news_data": [[415, 438], ["numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "def", "_convert_news_data", "(", "\n", "self", ",", "\n", "news_indexes", ",", "\n", "candidate_title_indexes", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            news_indexes (list): a list of news indexes.\n            candidate_title_indexes (list): the candidate news titles' words indices.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "\n", "news_indexes_batch", "=", "np", ".", "asarray", "(", "news_indexes", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "candidate_title_index_batch", "=", "np", ".", "asarray", "(", "\n", "candidate_title_indexes", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "\n", "return", "{", "\n", "\"news_index_batch\"", ":", "news_indexes_batch", ",", "\n", "\"candidate_title_batch\"", ":", "candidate_title_index_batch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.load_impression_from_file": [[440, 464], ["numpy.arange", "hasattr", "mind_iterator.MINDIterator.init_behaviors", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.mind_iterator.MINDIterator.init_behaviors"], ["", "def", "load_impression_from_file", "(", "self", ",", "behaivors_file", ")", ":", "\n", "        ", "\"\"\"Read and parse impression data from behaivors file.\n\n        Args:\n            behaivors_file (str): A file contains several informations of behaviros.\n\n        Yields:\n            object: An iterator that yields parsed impression data, in the format of dict.\n        \"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"histories\"", ")", ":", "\n", "            ", "self", ".", "init_behaviors", "(", "behaivors_file", ")", "\n", "\n", "", "indexes", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "\n", "for", "index", "in", "indexes", ":", "\n", "            ", "impr_label", "=", "np", ".", "array", "(", "self", ".", "labels", "[", "index", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "impr_news", "=", "np", ".", "array", "(", "self", ".", "imprs", "[", "index", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "yield", "(", "\n", "self", ".", "impr_indexes", "[", "index", "]", ",", "\n", "impr_news", ",", "\n", "self", ".", "uindexes", "[", "index", "]", ",", "\n", "impr_label", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_item2item_iterator.DKNItem2itemTextIterator.__init__": [[10, 37], ["dkn_item2item_iterator.DKNItem2itemTextIterator._loading_nessary_files", "dkn_item2item_iterator.DKNItem2itemTextIterator.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_item2item_iterator.DKNItem2itemTextIterator._loading_nessary_files", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "graph", ")", ":", "\n", "        ", "\"\"\"This new iterator is for DKN's item-to-item recommendations version.\n        The tutorial can be found `on this notebook <https://github.com/microsoft/recommenders/blob/main/examples/07_tutorials/KDD2020-tutorial/step4_run_dkn_item2item.ipynb>`_.\n\n        Compared with user-to-item recommendations, we don't need the user behavior module.\n        So the placeholder can be simplified from the original DKNTextIterator.\n\n        Args:\n            hparams (object): Global hyper-parameters.\n            graph (object): The running graph.\n        \"\"\"", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "neg_num", "=", "hparams", ".", "neg_num", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "*", "(", "self", ".", "neg_num", "+", "2", ")", "\n", "self", ".", "doc_size", "=", "hparams", ".", "doc_size", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "candidate_news_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ",", "name", "=", "\"candidate_news_index\"", "\n", ")", "\n", "self", ".", "candidate_news_entity_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "\n", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ",", "\n", "name", "=", "\"candidate_news_entity_index\"", ",", "\n", ")", "\n", "\n", "", "self", ".", "_loading_nessary_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_item2item_iterator.DKNItem2itemTextIterator._loading_nessary_files": [[38, 56], ["open", "rd.readline", "rd.readline.strip().split", "int", "int", "rd.readline.strip", "word_index.split", "entity_index.split"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_loading_nessary_files", "(", "self", ")", ":", "\n", "        ", "\"\"\"Only one feature file is needed:  `news_feature_file`.\n        This function loads the news article's features into two dictionaries: `self.news_word_index` and `self.news_entity_index`.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "self", ".", "news_word_index", "=", "{", "}", "\n", "self", ".", "news_entity_index", "=", "{", "}", "\n", "with", "open", "(", "hparams", ".", "news_feature_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                    ", "break", "\n", "", "newsid", ",", "word_index", ",", "entity_index", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "self", ".", "news_word_index", "[", "newsid", "]", "=", "[", "\n", "int", "(", "item", ")", "for", "item", "in", "word_index", ".", "split", "(", "\",\"", ")", "\n", "]", "\n", "self", ".", "news_entity_index", "[", "newsid", "]", "=", "[", "\n", "int", "(", "item", ")", "for", "item", "in", "entity_index", ".", "split", "(", "\",\"", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_item2item_iterator.DKNItem2itemTextIterator.load_data_from_file": [[58, 118], ["open", "rd.readline", "rd.readline.strip", "newsid_list.append", "candidate_news_index_batch.append", "candidate_news_entity_index_batch.append", "dkn_item2item_iterator.DKNItem2itemTextIterator._convert_infer_data", "dkn_item2item_iterator.DKNItem2itemTextIterator._convert_infer_data", "candidate_news_index_batch.append", "candidate_news_entity_index_batch.append", "dkn_item2item_iterator.DKNItem2itemTextIterator.gen_infer_feed_dict", "dkn_item2item_iterator.DKNItem2itemTextIterator.gen_infer_feed_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_infer_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_infer_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_infer_feed_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_infer_feed_dict"], ["", "", "", "def", "load_data_from_file", "(", "self", ",", "infile", ")", ":", "\n", "        ", "\"\"\"This function will return a mini-batch of data with features,\n        by looking up `news_word_index` dictionary and `news_entity_index` dictionary according to the news article's ID.\n\n        Args:\n            infile (str): File path. Each line of `infile` is a news article's ID.\n\n        Yields:\n            dict, list, int:\n            - A dictionary that maps graph elements to numpy arrays.\n            - A list with news article's ID.\n            - Size of the data in a batch.\n        \"\"\"", "\n", "newsid_list", "=", "[", "]", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "with", "open", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "line", "=", "rd", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                    ", "break", "\n", "", "newsid", "=", "line", ".", "strip", "(", ")", "\n", "word_index", ",", "entity_index", "=", "(", "\n", "self", ".", "news_word_index", "[", "newsid", "]", ",", "\n", "self", ".", "news_entity_index", "[", "newsid", "]", ",", "\n", ")", "\n", "newsid_list", ".", "append", "(", "newsid", ")", "\n", "\n", "candidate_news_index_batch", ".", "append", "(", "word_index", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "entity_index", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "res", "=", "self", ".", "_convert_infer_data", "(", "\n", "candidate_news_index_batch", ",", "\n", "candidate_news_entity_index_batch", ",", "\n", ")", "\n", "data_size", "=", "self", ".", "batch_size", "\n", "yield", "self", ".", "gen_infer_feed_dict", "(", "res", ")", ",", "newsid_list", ",", "data_size", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "newsid_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "                ", "data_size", "=", "cnt", "\n", "while", "cnt", "<", "self", ".", "batch_size", ":", "\n", "                    ", "candidate_news_index_batch", ".", "append", "(", "\n", "candidate_news_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "\n", "candidate_news_entity_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "cnt", "+=", "1", "\n", "", "res", "=", "self", ".", "_convert_infer_data", "(", "\n", "candidate_news_index_batch", ",", "\n", "candidate_news_entity_index_batch", ",", "\n", ")", "\n", "yield", "self", ".", "gen_infer_feed_dict", "(", "res", ")", ",", "newsid_list", ",", "data_size", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.__init__": [[23, 90], ["dkn_iterator.DKNTextIterator.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.io.gfile.GFile", "tensorflow.io.gfile.GFile", "line.strip().split", "range", "int", "int", "len", "line.strip", "line.strip().split", "user_history_string.split", "len", "click_news_index.append", "click_news_entity_index.append", "click_news_index.append", "click_news_entity_index.append", "line.strip", "word_index.split", "entity_index.split", "line.strip().split", "len", "numpy.zeros", "numpy.zeros", "line.strip", "line.strip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["def", "__init__", "(", "self", ",", "hparams", ",", "graph", ",", "col_spliter", "=", "\" \"", ",", "ID_spliter", "=", "\"%\"", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create necessary placeholders for the model.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key setttings such as #_feature and #_field are there.\n            graph (object): the running graph. All created placeholder will be added to this graph.\n            col_spliter (str): column spliter in one line.\n            ID_spliter (str): ID spliter in one line.\n        \"\"\"", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "self", ".", "ID_spliter", "=", "ID_spliter", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "doc_size", "=", "hparams", ".", "doc_size", "\n", "self", ".", "history_size", "=", "hparams", ".", "history_size", "\n", "\n", "self", ".", "graph", "=", "graph", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "labels", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ",", "name", "=", "\"label\"", ")", "\n", "self", ".", "candidate_news_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ",", "name", "=", "\"candidate_news_index\"", "\n", ")", "\n", "self", ".", "click_news_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "\n", "[", "self", ".", "batch_size", ",", "self", ".", "history_size", ",", "self", ".", "doc_size", "]", ",", "\n", "name", "=", "\"click_news_index\"", ",", "\n", ")", "\n", "self", ".", "candidate_news_entity_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "\n", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ",", "\n", "name", "=", "\"candidate_news_entity_index\"", ",", "\n", ")", "\n", "self", ".", "click_news_entity_index_batch", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "\n", "[", "self", ".", "batch_size", ",", "self", ".", "history_size", ",", "self", ".", "doc_size", "]", ",", "\n", "name", "=", "\"click_news_entity_index\"", ",", "\n", ")", "\n", "", "self", ".", "news_word_index", "=", "{", "}", "\n", "self", ".", "news_entity_index", "=", "{", "}", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "hparams", ".", "news_feature_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "newsid", ",", "word_index", ",", "entity_index", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "col_spliter", ")", "\n", "self", ".", "news_word_index", "[", "newsid", "]", "=", "[", "\n", "int", "(", "item", ")", "for", "item", "in", "word_index", ".", "split", "(", "\",\"", ")", "\n", "]", "\n", "self", ".", "news_entity_index", "[", "newsid", "]", "=", "[", "\n", "int", "(", "item", ")", "for", "item", "in", "entity_index", ".", "split", "(", "\",\"", ")", "\n", "]", "\n", "", "", "self", ".", "user_history", "=", "{", "}", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "hparams", ".", "user_history_file", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "if", "len", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "col_spliter", ")", ")", "==", "1", ":", "\n", "                    ", "userid", "=", "line", ".", "strip", "(", ")", "\n", "user_history", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "userid", ",", "user_history_string", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "col_spliter", ")", "\n", "user_history", "=", "user_history_string", ".", "split", "(", "\",\"", ")", "\n", "", "click_news_index", "=", "[", "]", "\n", "click_news_entity_index", "=", "[", "]", "\n", "if", "len", "(", "user_history", ")", ">", "self", ".", "history_size", ":", "\n", "                    ", "user_history", "=", "user_history", "[", "-", "self", ".", "history_size", ":", "]", "\n", "", "for", "newsid", "in", "user_history", ":", "\n", "                    ", "click_news_index", ".", "append", "(", "self", ".", "news_word_index", "[", "newsid", "]", ")", "\n", "click_news_entity_index", ".", "append", "(", "self", ".", "news_entity_index", "[", "newsid", "]", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "history_size", "-", "len", "(", "user_history", ")", ")", ":", "\n", "                    ", "click_news_index", ".", "append", "(", "np", ".", "zeros", "(", "self", ".", "doc_size", ")", ")", "\n", "click_news_entity_index", ".", "append", "(", "np", ".", "zeros", "(", "self", ".", "doc_size", ")", ")", "\n", "", "self", ".", "user_history", "[", "userid", "]", "=", "(", "click_news_index", ",", "click_news_entity_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.parser_one_line": [[91, 125], ["line.strip().split", "words[].strip().split", "float", "len", "words[].strip", "line.strip", "words[].strip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Parse one string line into feature values.\n\n        Args:\n            line (str): a string indicating one instance\n\n        Returns:\n            list: Parsed results including `label`, `candidate_news_index`, `click_news_index`,\n            `candidate_news_entity_index`, `click_news_entity_index`, `impression_id`.\n\n        \"\"\"", "\n", "impression_id", "=", "0", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "ID_spliter", ")", "\n", "if", "len", "(", "words", ")", "==", "2", ":", "\n", "            ", "impression_id", "=", "words", "[", "1", "]", ".", "strip", "(", ")", "\n", "\n", "", "cols", "=", "words", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "col_spliter", ")", "\n", "label", "=", "float", "(", "cols", "[", "0", "]", ")", "\n", "\n", "userid", "=", "cols", "[", "1", "]", "\n", "candidate_news", "=", "cols", "[", "2", "]", "\n", "\n", "candidate_news_index", "=", "self", ".", "news_word_index", "[", "candidate_news", "]", "\n", "candidate_news_entity_index", "=", "self", ".", "news_entity_index", "[", "candidate_news", "]", "\n", "click_news_index", "=", "self", ".", "user_history", "[", "userid", "]", "[", "0", "]", "\n", "click_news_entity_index", "=", "self", ".", "user_history", "[", "userid", "]", "[", "1", "]", "\n", "\n", "return", "(", "\n", "label", ",", "\n", "candidate_news_index", ",", "\n", "click_news_index", ",", "\n", "candidate_news_entity_index", ",", "\n", "click_news_entity_index", ",", "\n", "impression_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.load_data_from_file": [[127, 211], ["tensorflow.io.gfile.GFile", "dkn_iterator.DKNTextIterator.parser_one_line", "candidate_news_index_batch.append", "click_news_index_batch.append", "candidate_news_entity_index_batch.append", "click_news_entity_index_batch.append", "label_list.append", "impression_id_list.append", "dkn_iterator.DKNTextIterator._convert_data", "dkn_iterator.DKNTextIterator._convert_data", "candidate_news_index_batch.append", "click_news_index_batch.append", "candidate_news_entity_index_batch.append", "click_news_entity_index_batch.append", "label_list.append", "impression_id_list.append", "dkn_iterator.DKNTextIterator.gen_feed_dict", "dkn_iterator.DKNTextIterator.gen_feed_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict"], ["", "def", "load_data_from_file", "(", "self", ",", "infile", ")", ":", "\n", "        ", "\"\"\"Read and parse data from a file.\n\n        Args:\n            infile (str): text input file. Each line in this file is an instance.\n\n        Yields:\n            obj, list, int:\n            - An iterator that yields parsed results, in the format of graph `feed_dict`.\n            - Impression id list.\n            - Size of the data in a batch.\n        \"\"\"", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "click_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "click_news_entity_index_batch", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "impression_id_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "(", "\n", "label", ",", "\n", "candidate_news_index", ",", "\n", "click_news_index", ",", "\n", "candidate_news_entity_index", ",", "\n", "click_news_entity_index", ",", "\n", "impression_id", ",", "\n", ")", "=", "self", ".", "parser_one_line", "(", "line", ")", "\n", "\n", "candidate_news_index_batch", ".", "append", "(", "candidate_news_index", ")", "\n", "click_news_index_batch", ".", "append", "(", "click_news_index", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "candidate_news_entity_index", ")", "\n", "click_news_entity_index_batch", ".", "append", "(", "click_news_entity_index", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "impression_id_list", ".", "append", "(", "impression_id", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "res", "=", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "candidate_news_index_batch", ",", "\n", "click_news_index_batch", ",", "\n", "candidate_news_entity_index_batch", ",", "\n", "click_news_entity_index_batch", ",", "\n", "impression_id_list", ",", "\n", ")", "\n", "data_size", "=", "self", ".", "batch_size", "\n", "yield", "self", ".", "gen_feed_dict", "(", "res", ")", ",", "impression_id_list", ",", "data_size", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "click_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "click_news_entity_index_batch", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "impression_id_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "                ", "data_size", "=", "cnt", "\n", "while", "cnt", "<", "self", ".", "batch_size", ":", "\n", "                    ", "candidate_news_index_batch", ".", "append", "(", "\n", "candidate_news_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "click_news_index_batch", ".", "append", "(", "\n", "click_news_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "\n", "candidate_news_entity_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "click_news_entity_index_batch", ".", "append", "(", "\n", "click_news_entity_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "label_list", ".", "append", "(", "label_list", "[", "cnt", "%", "data_size", "]", ")", "\n", "impression_id_list", ".", "append", "(", "impression_id_list", "[", "cnt", "%", "data_size", "]", ")", "\n", "cnt", "+=", "1", "\n", "", "res", "=", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "candidate_news_index_batch", ",", "\n", "click_news_index_batch", ",", "\n", "candidate_news_entity_index_batch", ",", "\n", "click_news_entity_index_batch", ",", "\n", "impression_id_list", ",", "\n", ")", "\n", "yield", "self", ".", "gen_feed_dict", "(", "res", ")", ",", "impression_id_list", ",", "data_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.load_infer_data_from_file": [[212, 268], ["tensorflow.io.gfile.GFile", "line.strip().split", "newsid_list.append", "word_index.split", "entity_index.split", "candidate_news_index_batch.append", "candidate_news_entity_index_batch.append", "dkn_iterator.DKNTextIterator._convert_infer_data", "candidate_news_index.append", "candidate_news_entity_index.append", "dkn_iterator.DKNTextIterator._convert_infer_data", "candidate_news_index_batch.append", "candidate_news_entity_index_batch.append", "line.strip", "int", "int", "dkn_iterator.DKNTextIterator.gen_infer_feed_dict", "dkn_iterator.DKNTextIterator.gen_infer_feed_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_infer_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_infer_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_infer_feed_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_infer_feed_dict"], ["", "", "", "def", "load_infer_data_from_file", "(", "self", ",", "infile", ")", ":", "\n", "        ", "\"\"\"Read and parse data from a file for infer document embedding.\n\n        Args:\n            infile (str): text input file. Each line in this file is an instance.\n\n        Yields:\n            obj, list, int:\n            - An iterator that yields parsed results, in the format of graph `feed_dict`.\n            - Impression id list.\n            - Size of the data in a batch.\n        \"\"\"", "\n", "newsid_list", "=", "[", "]", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "newsid", ",", "word_index", ",", "entity_index", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "newsid_list", ".", "append", "(", "newsid", ")", "\n", "candidate_news_index", "=", "[", "]", "\n", "candidate_news_entity_index", "=", "[", "]", "\n", "for", "item", "in", "word_index", ".", "split", "(", "\",\"", ")", ":", "\n", "                    ", "candidate_news_index", ".", "append", "(", "int", "(", "item", ")", ")", "\n", "", "for", "item", "in", "entity_index", ".", "split", "(", "\",\"", ")", ":", "\n", "                    ", "candidate_news_entity_index", ".", "append", "(", "int", "(", "item", ")", ")", "\n", "\n", "", "candidate_news_index_batch", ".", "append", "(", "candidate_news_index", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "candidate_news_entity_index", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "res", "=", "self", ".", "_convert_infer_data", "(", "\n", "candidate_news_index_batch", ",", "candidate_news_entity_index_batch", "\n", ")", "\n", "data_size", "=", "self", ".", "batch_size", "\n", "yield", "self", ".", "gen_infer_feed_dict", "(", "res", ")", ",", "newsid_list", ",", "data_size", "\n", "candidate_news_index_batch", "=", "[", "]", "\n", "candidate_news_entity_index_batch", "=", "[", "]", "\n", "newsid_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "                ", "data_size", "=", "cnt", "\n", "while", "cnt", "<", "self", ".", "batch_size", ":", "\n", "                    ", "candidate_news_index_batch", ".", "append", "(", "\n", "candidate_news_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "candidate_news_entity_index_batch", ".", "append", "(", "\n", "candidate_news_entity_index_batch", "[", "cnt", "%", "data_size", "]", "\n", ")", "\n", "cnt", "+=", "1", "\n", "", "res", "=", "self", ".", "_convert_infer_data", "(", "\n", "candidate_news_index_batch", ",", "candidate_news_entity_index_batch", "\n", ")", "\n", "yield", "self", ".", "gen_infer_feed_dict", "(", "res", ")", ",", "newsid_list", ",", "data_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_data": [[269, 307], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "", "", "def", "_convert_data", "(", "\n", "self", ",", "\n", "label_list", ",", "\n", "candidate_news_index_batch", ",", "\n", "click_news_index_batch", ",", "\n", "candidate_news_entity_index_batch", ",", "\n", "click_news_entity_index_batch", ",", "\n", "impression_id_list", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            label_list (list): a list of ground-truth labels.\n            candidate_news_index_batch (list): the candidate news article's words indices\n            click_news_index_batch (list): words indices for user's clicked news articles\n            candidate_news_entity_index_batch (list): the candidate news article's entities indices\n            click_news_entity_index_batch (list): the user's clicked news article's entities indices\n            impression_id_list (list) : the session's impression indices\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "[", "[", "label", "]", "for", "label", "in", "label_list", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"candidate_news_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "candidate_news_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "res", "[", "\"click_news_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "click_news_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "res", "[", "\"candidate_news_entity_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "candidate_news_entity_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "res", "[", "\"click_news_entity_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "click_news_entity_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "res", "[", "\"impression_id\"", "]", "=", "np", ".", "asarray", "(", "impression_id_list", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator._convert_infer_data": [[308, 327], ["numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "def", "_convert_infer_data", "(", "\n", "self", ",", "candidate_news_index_batch", ",", "candidate_news_entity_index_batch", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            candidate_news_index_batch (list): the candidate news article's words indices\n            candidate_news_entity_index_batch (list): the candidate news article's entities indices\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"candidate_news_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "candidate_news_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "res", "[", "\"candidate_news_entity_index_batch\"", "]", "=", "np", ".", "asarray", "(", "\n", "candidate_news_entity_index_batch", ",", "dtype", "=", "np", ".", "int64", "\n", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_feed_dict": [[328, 354], ["data_dict[].reshape", "data_dict[].reshape", "data_dict[].reshape", "data_dict[].reshape", "data_dict[].reshape"], "methods", ["None"], ["", "def", "gen_feed_dict", "(", "self", ",", "data_dict", ")", ":", "\n", "        ", "\"\"\"Construct a dictionary that maps graph elements to values.\n\n        Args:\n            data_dict (dict): a dictionary that maps string name to numpy arrays.\n\n        Returns:\n            dict: A dictionary that maps graph elements to numpy arrays.\n\n        \"\"\"", "\n", "feed_dict", "=", "{", "\n", "self", ".", "labels", ":", "data_dict", "[", "\"labels\"", "]", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", ",", "\n", "self", ".", "candidate_news_index_batch", ":", "data_dict", "[", "\n", "\"candidate_news_index_batch\"", "\n", "]", ".", "reshape", "(", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ")", ",", "\n", "self", ".", "click_news_index_batch", ":", "data_dict", "[", "\"click_news_index_batch\"", "]", ".", "reshape", "(", "\n", "[", "self", ".", "batch_size", ",", "self", ".", "history_size", ",", "self", ".", "doc_size", "]", "\n", ")", ",", "\n", "self", ".", "candidate_news_entity_index_batch", ":", "data_dict", "[", "\n", "\"candidate_news_entity_index_batch\"", "\n", "]", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "doc_size", "]", ")", ",", "\n", "self", ".", "click_news_entity_index_batch", ":", "data_dict", "[", "\n", "\"click_news_entity_index_batch\"", "\n", "]", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "history_size", ",", "self", ".", "doc_size", "]", ")", ",", "\n", "}", "\n", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.dkn_iterator.DKNTextIterator.gen_infer_feed_dict": [[355, 374], ["data_dict[].reshape", "data_dict[].reshape"], "methods", ["None"], ["", "def", "gen_infer_feed_dict", "(", "self", ",", "data_dict", ")", ":", "\n", "        ", "\"\"\"Construct a dictionary that maps graph elements to values.\n\n        Args:\n            data_dict (dict): a dictionary that maps string name to numpy arrays.\n\n        Returns:\n            dict: A dictionary that maps graph elements to numpy arrays.\n\n        \"\"\"", "\n", "feed_dict", "=", "{", "\n", "self", ".", "candidate_news_index_batch", ":", "data_dict", "[", "\n", "\"candidate_news_index_batch\"", "\n", "]", ".", "reshape", "(", "[", "self", ".", "batch_size", ",", "self", ".", "doc_size", "]", ")", ",", "\n", "self", ".", "candidate_news_entity_index_batch", ":", "data_dict", "[", "\n", "\"candidate_news_entity_index_batch\"", "\n", "]", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "doc_size", "]", ")", ",", "\n", "}", "\n", "return", "feed_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.nextitnet_iterator.NextItNetIterator.__init__": [[23, 70], ["dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "nextitnet_iterator.NextItNetIterator.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["def", "__init__", "(", "self", ",", "hparams", ",", "graph", ",", "col_spliter", "=", "\"\\t\"", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create necessary placeholders for the model.\n        Different from sequential iterator\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key settings such as #_feature and #_field are there.\n            graph (object): The running graph. All created placeholder will be added to this graph.\n            col_spliter (str): Column splitter in one line.\n        \"\"\"", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "\n", "self", ".", "userdict", ",", "self", ".", "itemdict", ",", "self", ".", "catedict", "=", "(", "\n", "load_dict", "(", "hparams", ".", "user_vocab", ")", ",", "\n", "load_dict", "(", "hparams", ".", "item_vocab", ")", ",", "\n", "load_dict", "(", "hparams", ".", "cate_vocab", ")", ",", "\n", ")", "\n", "\n", "self", ".", "max_seq_length", "=", "hparams", ".", "max_seq_length", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "iter_data", "=", "dict", "(", ")", "\n", "\n", "self", ".", "graph", "=", "graph", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "labels", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "None", "]", ",", "name", "=", "\"label\"", "\n", ")", "\n", "self", ".", "users", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"users\"", ")", "\n", "self", ".", "items", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "name", "=", "\"items\"", ")", "\n", "self", ".", "cates", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "name", "=", "\"cates\"", ")", "\n", "self", ".", "item_history", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"item_history\"", "\n", ")", "\n", "self", ".", "item_cate_history", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"item_cate_history\"", "\n", ")", "\n", "self", ".", "mask", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"mask\"", "\n", ")", "\n", "self", ".", "time", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"time\"", ")", "\n", "self", ".", "time_diff", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_diff\"", "\n", ")", "\n", "self", ".", "time_from_first_action", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_from_first_action\"", "\n", ")", "\n", "self", ".", "time_to_now", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_to_now\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.nextitnet_iterator.NextItNetIterator._convert_data": [[72, 269], ["len", "numpy.asarray().flatten", "numpy.asarray().flatten", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.asarray().reshape", "numpy.asarray", "numpy.asarray().reshape", "numpy.asarray().reshape", "numpy.asarray", "len", "min", "range", "label_list_all.append", "item_list_all.append", "item_cate_list_all.append", "len", "min", "numpy.asarray", "numpy.asarray", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "label_list_all.append", "item_list_all.append", "item_cate_list_all.append", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "random.randint", "negative_item_list.append", "negative_item_cate_list.append"], "methods", ["None"], ["", "", "def", "_convert_data", "(", "\n", "self", ",", "\n", "label_list", ",", "\n", "user_list", ",", "\n", "item_list", ",", "\n", "item_cate_list", ",", "\n", "item_history_batch", ",", "\n", "item_cate_history_batch", ",", "\n", "time_list", ",", "\n", "time_diff_list", ",", "\n", "time_from_first_action_list", ",", "\n", "time_to_now_list", ",", "\n", "batch_num_ngs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n        Note: This is different from `sequential_iterator`.\n\n        Args:\n            label_list (list): A list of ground-truth labels.\n            user_list (list): A list of user indexes.\n            item_list (list): A list of item indexes.\n            item_cate_list (list): A list of category indexes.\n            item_history_batch (list): A list of item history indexes.\n            item_cate_history_batch (list): A list of category history indexes.\n            time_list (list): A list of current timestamp.\n            time_diff_list (list): A list of timestamp between each sequential opertions.\n            time_from_first_action_list (list): A list of timestamp from the first opertion.\n            time_to_now_list (list): A list of timestamp to the current time.\n            batch_num_ngs (int): The number of negative sampling while training in mini-batch.\n\n        Returns:\n            dict: A dictionary, contains multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "if", "batch_num_ngs", ":", "\n", "            ", "instance_cnt", "=", "len", "(", "label_list", ")", "\n", "if", "instance_cnt", "<", "5", ":", "\n", "                ", "return", "\n", "\n", "", "label_list_all", "=", "[", "]", "\n", "item_list_all", "=", "[", "]", "\n", "item_cate_list_all", "=", "[", "]", "\n", "user_list_all", "=", "np", ".", "asarray", "(", "\n", "[", "[", "user", "]", "*", "(", "batch_num_ngs", "+", "1", ")", "for", "user", "in", "user_list", "]", ",", "dtype", "=", "np", ".", "int32", "\n", ")", ".", "flatten", "(", ")", "\n", "time_list_all", "=", "np", ".", "asarray", "(", "\n", "[", "[", "t", "]", "*", "(", "batch_num_ngs", "+", "1", ")", "for", "t", "in", "time_list", "]", ",", "dtype", "=", "np", ".", "float32", "\n", ")", ".", "flatten", "(", ")", "\n", "\n", "history_lengths", "=", "[", "len", "(", "item_history_batch", "[", "i", "]", ")", "for", "i", "in", "range", "(", "instance_cnt", ")", "]", "\n", "max_seq_length_batch", "=", "self", ".", "max_seq_length", "\n", "item_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "int32", ",", "\n", ")", "\n", "item_cate_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "int32", ",", "\n", ")", "\n", "time_diff_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", ")", "\n", "time_from_first_action_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", ")", "\n", "time_to_now_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "1", "+", "batch_num_ngs", ")", ",", "max_seq_length_batch", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "this_length", "=", "min", "(", "history_lengths", "[", "i", "]", ",", "max_seq_length_batch", ")", "\n", "for", "index", "in", "range", "(", "batch_num_ngs", "+", "1", ")", ":", "\n", "                    ", "item_history_batch_all", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "\n", "]", "=", "np", ".", "asarray", "(", "item_history_batch", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "item_cate_history_batch_all", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "\n", "]", "=", "np", ".", "asarray", "(", "\n", "item_cate_history_batch", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "mask", "[", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "]", "=", "1.0", "\n", "time_diff_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "\n", "]", "=", "np", ".", "asarray", "(", "time_diff_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "time_from_first_action_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "\n", "]", "=", "np", ".", "asarray", "(", "\n", "time_from_first_action_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "time_to_now_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", "-", "this_length", ":", "\n", "]", "=", "np", ".", "asarray", "(", "time_to_now_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "positive_item", "=", "[", "\n", "*", "item_history_batch_all", "[", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "]", "[", "1", ":", "]", ",", "\n", "item_list", "[", "i", "]", ",", "\n", "]", "\n", "positive_item_cate", "=", "[", "\n", "*", "item_cate_history_batch_all", "[", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "]", "[", "1", ":", "]", ",", "\n", "item_cate_list", "[", "i", "]", ",", "\n", "]", "\n", "label_list_all", ".", "append", "(", "[", "1", "]", "*", "max_seq_length_batch", ")", "\n", "item_list_all", ".", "append", "(", "positive_item", ")", "\n", "item_cate_list_all", ".", "append", "(", "positive_item_cate", ")", "\n", "\n", "count", "=", "0", "\n", "while", "count", "<", "batch_num_ngs", ":", "\n", "                    ", "negative_item_list", "=", "[", "]", "\n", "negative_item_cate_list", "=", "[", "]", "\n", "count_inner", "=", "1", "\n", "while", "count_inner", "<=", "max_seq_length_batch", ":", "\n", "                        ", "random_value", "=", "random", ".", "randint", "(", "0", ",", "instance_cnt", "-", "1", ")", "\n", "negative_item", "=", "item_list", "[", "random_value", "]", "\n", "if", "negative_item", "==", "positive_item", "[", "count_inner", "-", "1", "]", ":", "\n", "                            ", "continue", "\n", "", "negative_item_list", ".", "append", "(", "negative_item", ")", "\n", "negative_item_cate_list", ".", "append", "(", "item_cate_list", "[", "random_value", "]", ")", "\n", "count_inner", "+=", "1", "\n", "\n", "", "label_list_all", ".", "append", "(", "[", "0", "]", "*", "max_seq_length_batch", ")", "\n", "item_list_all", ".", "append", "(", "negative_item_list", ")", "\n", "item_cate_list_all", ".", "append", "(", "negative_item_cate_list", ")", "\n", "count", "+=", "1", "\n", "\n", "", "", "res", "=", "{", "}", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "\n", "label_list_all", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "# .reshape(-1,1)", "\n", "res", "[", "\"users\"", "]", "=", "user_list_all", "\n", "res", "[", "\"items\"", "]", "=", "np", ".", "asarray", "(", "item_list_all", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"cates\"", "]", "=", "np", ".", "asarray", "(", "item_cate_list_all", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"item_history\"", "]", "=", "item_history_batch_all", "\n", "res", "[", "\"item_cate_history\"", "]", "=", "item_cate_history_batch_all", "\n", "res", "[", "\"mask\"", "]", "=", "mask", "\n", "res", "[", "\"time\"", "]", "=", "time_list_all", "\n", "res", "[", "\"time_diff\"", "]", "=", "time_diff_batch", "\n", "res", "[", "\"time_from_first_action\"", "]", "=", "time_from_first_action_batch", "\n", "res", "[", "\"time_to_now\"", "]", "=", "time_to_now_batch", "\n", "\n", "return", "res", "\n", "\n", "", "else", ":", "\n", "            ", "instance_cnt", "=", "len", "(", "label_list", ")", "\n", "history_lengths", "=", "[", "len", "(", "item_history_batch", "[", "i", "]", ")", "for", "i", "in", "range", "(", "instance_cnt", ")", "]", "\n", "max_seq_length_batch", "=", "self", ".", "max_seq_length", "\n", "item_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "item_cate_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "time_diff_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "time_from_first_action_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "time_to_now_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "this_length", "=", "min", "(", "history_lengths", "[", "i", "]", ",", "max_seq_length_batch", ")", "\n", "item_history_batch_all", "[", "i", ",", "-", "this_length", ":", "]", "=", "item_history_batch", "[", "i", "]", "[", "\n", "-", "this_length", ":", "\n", "]", "\n", "item_cate_history_batch_all", "[", "i", ",", "-", "this_length", ":", "]", "=", "item_cate_history_batch", "[", "\n", "i", "\n", "]", "[", "-", "this_length", ":", "]", "\n", "mask", "[", "i", ",", "-", "this_length", ":", "]", "=", "1.0", "\n", "time_diff_batch", "[", "i", ",", "-", "this_length", ":", "]", "=", "time_diff_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "time_from_first_action_batch", "[", "\n", "i", ",", "-", "this_length", ":", "\n", "]", "=", "time_from_first_action_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "time_to_now_batch", "[", "i", ",", "-", "this_length", ":", "]", "=", "time_to_now_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "\n", "", "res", "=", "{", "}", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "label_list", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "res", "[", "\"users\"", "]", "=", "np", ".", "asarray", "(", "user_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"items\"", "]", "=", "np", ".", "asarray", "(", "item_list", ",", "dtype", "=", "np", ".", "int32", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "res", "[", "\"cates\"", "]", "=", "np", ".", "asarray", "(", "item_cate_list", ",", "dtype", "=", "np", ".", "int32", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "res", "[", "\"item_history\"", "]", "=", "item_history_batch_all", "\n", "res", "[", "\"item_cate_history\"", "]", "=", "item_cate_history_batch_all", "\n", "res", "[", "\"mask\"", "]", "=", "mask", "\n", "res", "[", "\"time\"", "]", "=", "np", ".", "asarray", "(", "time_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"time_diff\"", "]", "=", "time_diff_batch", "\n", "res", "[", "\"time_from_first_action\"", "]", "=", "time_from_first_action_batch", "\n", "res", "[", "\"time_to_now\"", "]", "=", "time_to_now_batch", "\n", "return", "res", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.BaseIterator.parser_one_line": [[12, 20], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Abstract method. Parse one string line into feature values.\n\n        Args:\n            line (str): A string indicating one instance.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.BaseIterator.load_data_from_file": [[21, 29], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "load_data_from_file", "(", "self", ",", "infile", ")", ":", "\n", "        ", "\"\"\"Abstract method. Read and parse data from a file.\n\n        Args:\n            infile (str): Text input file. Each line in this file is an instance.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.BaseIterator._convert_data": [[30, 33], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_convert_data", "(", "self", ",", "labels", ",", "features", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.BaseIterator.gen_feed_dict": [[34, 42], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "gen_feed_dict", "(", "self", ",", "data_dict", ")", ":", "\n", "        ", "\"\"\"Abstract method. Construct a dictionary that maps graph elements to values.\n\n        Args:\n            data_dict (dict): A dictionary that maps string name to numpy arrays.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.FFMTextIterator.__init__": [[50, 88], ["iterator.FFMTextIterator.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["def", "__init__", "(", "self", ",", "hparams", ",", "graph", ",", "col_spliter", "=", "\" \"", ",", "ID_spliter", "=", "\"%\"", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create the necessary placeholders for the model.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key settings such as #_feature and #_field are there.\n            graph (object): The running graph. All created placeholder will be added to this graph.\n            col_spliter (str): column splitter in one line.\n            ID_spliter (str): ID splitter in one line.\n        \"\"\"", "\n", "self", ".", "feature_cnt", "=", "hparams", ".", "FEATURE_COUNT", "\n", "self", ".", "field_cnt", "=", "hparams", ".", "FIELD_COUNT", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "self", ".", "ID_spliter", "=", "ID_spliter", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "\n", "self", ".", "graph", "=", "graph", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "labels", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ",", "name", "=", "\"label\"", ")", "\n", "self", ".", "fm_feat_indices", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "None", ",", "2", "]", ",", "name", "=", "\"fm_feat_indices\"", "\n", ")", "\n", "self", ".", "fm_feat_values", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"fm_feat_values\"", "\n", ")", "\n", "self", ".", "fm_feat_shape", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "None", "]", ",", "name", "=", "\"fm_feat_shape\"", "\n", ")", "\n", "self", ".", "dnn_feat_indices", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "None", ",", "2", "]", ",", "name", "=", "\"dnn_feat_indices\"", "\n", ")", "\n", "self", ".", "dnn_feat_values", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "None", "]", ",", "name", "=", "\"dnn_feat_values\"", "\n", ")", "\n", "self", ".", "dnn_feat_weights", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"dnn_feat_weights\"", "\n", ")", "\n", "self", ".", "dnn_feat_shape", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int64", ",", "[", "None", "]", ",", "name", "=", "\"dnn_feat_shape\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.FFMTextIterator.parser_one_line": [[90, 117], ["line.strip().split", "words[].strip().split", "float", "len", "words[].strip", "word.split", "features.append", "line.strip", "words[].strip", "word.strip", "float", "int", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Parse one string line into feature values.\n\n        Args:\n            line (str): A string indicating one instance.\n\n        Returns:\n            list: Parsed results, including `label`, `features` and `impression_id`.\n\n        \"\"\"", "\n", "impression_id", "=", "0", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "ID_spliter", ")", "\n", "if", "len", "(", "words", ")", "==", "2", ":", "\n", "            ", "impression_id", "=", "words", "[", "1", "]", ".", "strip", "(", ")", "\n", "\n", "", "cols", "=", "words", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "col_spliter", ")", "\n", "\n", "label", "=", "float", "(", "cols", "[", "0", "]", ")", "\n", "\n", "features", "=", "[", "]", "\n", "for", "word", "in", "cols", "[", "1", ":", "]", ":", "\n", "            ", "if", "not", "word", ".", "strip", "(", ")", ":", "\n", "                ", "continue", "\n", "", "tokens", "=", "word", ".", "split", "(", "\":\"", ")", "\n", "features", ".", "append", "(", "[", "int", "(", "tokens", "[", "0", "]", ")", "-", "1", ",", "int", "(", "tokens", "[", "1", "]", ")", "-", "1", ",", "float", "(", "tokens", "[", "2", "]", ")", "]", ")", "\n", "\n", "", "return", "label", ",", "features", ",", "impression_id", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.FFMTextIterator.load_data_from_file": [[118, 151], ["tensorflow.io.gfile.GFile", "iterator.FFMTextIterator.parser_one_line", "features_list.append", "label_list.append", "impression_id_list.append", "iterator.FFMTextIterator._convert_data", "iterator.FFMTextIterator._convert_data", "iterator.FFMTextIterator.gen_feed_dict", "iterator.FFMTextIterator.gen_feed_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict"], ["", "def", "load_data_from_file", "(", "self", ",", "infile", ")", ":", "\n", "        ", "\"\"\"Read and parse data from a file.\n\n        Args:\n            infile (str): Text input file. Each line in this file is an instance.\n\n        Returns:\n            object: An iterator that yields parsed results, in the format of graph `feed_dict`.\n        \"\"\"", "\n", "label_list", "=", "[", "]", "\n", "features_list", "=", "[", "]", "\n", "impression_id_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "infile", ",", "\"r\"", ")", "as", "rd", ":", "\n", "            ", "for", "line", "in", "rd", ":", "\n", "                ", "label", ",", "features", ",", "impression_id", "=", "self", ".", "parser_one_line", "(", "line", ")", "\n", "\n", "features_list", ".", "append", "(", "features", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "impression_id_list", ".", "append", "(", "impression_id", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", "==", "self", ".", "batch_size", ":", "\n", "                    ", "res", "=", "self", ".", "_convert_data", "(", "label_list", ",", "features_list", ")", "\n", "yield", "self", ".", "gen_feed_dict", "(", "res", ")", ",", "impression_id_list", ",", "self", ".", "batch_size", "\n", "label_list", "=", "[", "]", "\n", "features_list", "=", "[", "]", "\n", "impression_id_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "                ", "res", "=", "self", ".", "_convert_data", "(", "label_list", ",", "features_list", ")", "\n", "yield", "self", ".", "gen_feed_dict", "(", "res", ")", ",", "impression_id_list", ",", "cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.FFMTextIterator._convert_data": [[152, 220], ["len", "range", "sorted", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "range", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "fm_feat_indices.append", "fm_feat_values.append", "dnn_feat_indices.append", "dnn_feat_values.append", "dnn_feat_weights.append", "len"], "methods", ["None"], ["", "", "", "def", "_convert_data", "(", "self", ",", "labels", ",", "features", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further operation.\n\n        Args:\n            labels (list): a list of ground-truth labels.\n            features (list): a 3-dimensional list, carrying a list (batch_size) of feature array,\n                    where each feature array is a list of `[field_idx, feature_idx, feature_value]` tuple.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "dim", "=", "self", ".", "feature_cnt", "\n", "FIELD_COUNT", "=", "self", ".", "field_cnt", "\n", "instance_cnt", "=", "len", "(", "labels", ")", "\n", "\n", "fm_feat_indices", "=", "[", "]", "\n", "fm_feat_values", "=", "[", "]", "\n", "fm_feat_shape", "=", "[", "instance_cnt", ",", "dim", "]", "\n", "\n", "dnn_feat_indices", "=", "[", "]", "\n", "dnn_feat_values", "=", "[", "]", "\n", "dnn_feat_weights", "=", "[", "]", "\n", "dnn_feat_shape", "=", "[", "instance_cnt", "*", "FIELD_COUNT", ",", "-", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "            ", "m", "=", "len", "(", "features", "[", "i", "]", ")", "\n", "dnn_feat_dic", "=", "{", "}", "\n", "for", "j", "in", "range", "(", "m", ")", ":", "\n", "                ", "fm_feat_indices", ".", "append", "(", "[", "i", ",", "features", "[", "i", "]", "[", "j", "]", "[", "1", "]", "]", ")", "\n", "fm_feat_values", ".", "append", "(", "features", "[", "i", "]", "[", "j", "]", "[", "2", "]", ")", "\n", "if", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "not", "in", "dnn_feat_dic", ":", "\n", "                    ", "dnn_feat_dic", "[", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dnn_feat_dic", "[", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "]", "+=", "1", "\n", "", "dnn_feat_indices", ".", "append", "(", "\n", "[", "\n", "i", "*", "FIELD_COUNT", "+", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", ",", "\n", "dnn_feat_dic", "[", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "]", ",", "\n", "]", "\n", ")", "\n", "dnn_feat_values", ".", "append", "(", "features", "[", "i", "]", "[", "j", "]", "[", "1", "]", ")", "\n", "dnn_feat_weights", ".", "append", "(", "features", "[", "i", "]", "[", "j", "]", "[", "2", "]", ")", "\n", "if", "dnn_feat_shape", "[", "1", "]", "<", "dnn_feat_dic", "[", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "]", ":", "\n", "                    ", "dnn_feat_shape", "[", "1", "]", "=", "dnn_feat_dic", "[", "features", "[", "i", "]", "[", "j", "]", "[", "0", "]", "]", "\n", "", "", "", "dnn_feat_shape", "[", "1", "]", "+=", "1", "\n", "\n", "sorted_index", "=", "sorted", "(", "\n", "range", "(", "len", "(", "dnn_feat_indices", ")", ")", ",", "\n", "key", "=", "lambda", "k", ":", "(", "dnn_feat_indices", "[", "k", "]", "[", "0", "]", ",", "dnn_feat_indices", "[", "k", "]", "[", "1", "]", ")", ",", "\n", ")", "\n", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"fm_feat_indices\"", "]", "=", "np", ".", "asarray", "(", "fm_feat_indices", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "res", "[", "\"fm_feat_values\"", "]", "=", "np", ".", "asarray", "(", "fm_feat_values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"fm_feat_shape\"", "]", "=", "np", ".", "asarray", "(", "fm_feat_shape", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "[", "[", "label", "]", "for", "label", "in", "labels", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "res", "[", "\"dnn_feat_indices\"", "]", "=", "np", ".", "asarray", "(", "dnn_feat_indices", ",", "dtype", "=", "np", ".", "int64", ")", "[", "\n", "sorted_index", "\n", "]", "\n", "res", "[", "\"dnn_feat_values\"", "]", "=", "np", ".", "asarray", "(", "dnn_feat_values", ",", "dtype", "=", "np", ".", "int64", ")", "[", "\n", "sorted_index", "\n", "]", "\n", "res", "[", "\"dnn_feat_weights\"", "]", "=", "np", ".", "asarray", "(", "dnn_feat_weights", ",", "dtype", "=", "np", ".", "float32", ")", "[", "\n", "sorted_index", "\n", "]", "\n", "res", "[", "\"dnn_feat_shape\"", "]", "=", "np", ".", "asarray", "(", "dnn_feat_shape", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.iterator.FFMTextIterator.gen_feed_dict": [[221, 242], ["None"], "methods", ["None"], ["", "def", "gen_feed_dict", "(", "self", ",", "data_dict", ")", ":", "\n", "        ", "\"\"\"Construct a dictionary that maps graph elements to values.\n\n        Args:\n            data_dict (dict): A dictionary that maps string name to numpy arrays.\n\n        Returns:\n            dict: A dictionary that maps graph elements to numpy arrays.\n\n        \"\"\"", "\n", "feed_dict", "=", "{", "\n", "self", ".", "labels", ":", "data_dict", "[", "\"labels\"", "]", ",", "\n", "self", ".", "fm_feat_indices", ":", "data_dict", "[", "\"fm_feat_indices\"", "]", ",", "\n", "self", ".", "fm_feat_values", ":", "data_dict", "[", "\"fm_feat_values\"", "]", ",", "\n", "self", ".", "fm_feat_shape", ":", "data_dict", "[", "\"fm_feat_shape\"", "]", ",", "\n", "self", ".", "dnn_feat_indices", ":", "data_dict", "[", "\"dnn_feat_indices\"", "]", ",", "\n", "self", ".", "dnn_feat_values", ":", "data_dict", "[", "\"dnn_feat_values\"", "]", ",", "\n", "self", ".", "dnn_feat_weights", ":", "data_dict", "[", "\"dnn_feat_weights\"", "]", ",", "\n", "self", ".", "dnn_feat_shape", ":", "data_dict", "[", "\"dnn_feat_shape\"", "]", ",", "\n", "}", "\n", "return", "feed_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.__init__": [[16, 64], ["dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "sequential_iterator.SequentialIterator.graph.as_default", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "graph", ",", "col_spliter", "=", "\"\\t\"", ")", ":", "\n", "        ", "\"\"\"Initialize an iterator. Create necessary placeholders for the model.\n\n        Args:\n            hparams (object): Global hyper-parameters. Some key settings such as #_feature and #_field are there.\n            graph (object): The running graph. All created placeholder will be added to this graph.\n            col_spliter (str): Column splitter in one line.\n        \"\"\"", "\n", "self", ".", "col_spliter", "=", "col_spliter", "\n", "user_vocab", ",", "item_vocab", ",", "cate_vocab", "=", "(", "\n", "hparams", ".", "user_vocab", ",", "\n", "hparams", ".", "item_vocab", ",", "\n", "hparams", ".", "cate_vocab", ",", "\n", ")", "\n", "self", ".", "userdict", ",", "self", ".", "itemdict", ",", "self", ".", "catedict", "=", "(", "\n", "load_dict", "(", "user_vocab", ")", ",", "\n", "load_dict", "(", "item_vocab", ")", ",", "\n", "load_dict", "(", "cate_vocab", ")", ",", "\n", ")", "\n", "\n", "self", ".", "max_seq_length", "=", "hparams", ".", "max_seq_length", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "iter_data", "=", "dict", "(", ")", "\n", "\n", "self", ".", "graph", "=", "graph", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "labels", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ",", "name", "=", "\"label\"", ")", "\n", "self", ".", "users", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"users\"", ")", "\n", "self", ".", "items", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"items\"", ")", "\n", "self", ".", "cates", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"cates\"", ")", "\n", "self", ".", "item_history", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"item_history\"", "\n", ")", "\n", "self", ".", "item_cate_history", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"item_cate_history\"", "\n", ")", "\n", "self", ".", "mask", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"mask\"", "\n", ")", "\n", "self", ".", "time", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"time\"", ")", "\n", "self", ".", "time_diff", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_diff\"", "\n", ")", "\n", "self", ".", "time_from_first_action", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_from_first_action\"", "\n", ")", "\n", "self", ".", "time_to_now", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "max_seq_length", "]", ",", "name", "=", "\"time_to_now\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parse_file": [[66, 83], ["open", "f.readlines", "res.append", "sequential_iterator.SequentialIterator.parser_one_line"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line"], ["", "", "def", "parse_file", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"Parse the file to A list ready to be used for downstream tasks.\n\n        Args:\n            input_file: One of train, valid or test file which has never been parsed.\n\n        Returns:\n            list: A list with parsing result.\n        \"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "res", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "if", "not", "line", ":", "\n", "                ", "continue", "\n", "", "res", ".", "append", "(", "self", ".", "parser_one_line", "(", "line", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parser_one_line": [[84, 165], ["line.strip().split", "int", "float", "words[].strip().split", "words[].strip().split", "words[].strip().split", "range", "max", "numpy.log.append", "numpy.log", "max", "numpy.log.append", "numpy.log", "numpy.log", "item_history_sequence.append", "cate_history_sequence.append", "float", "max", "numpy.log.append", "max", "max", "line.strip", "words[].strip", "words[].strip", "words[].strip", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["", "def", "parser_one_line", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"Parse one string line into feature values.\n\n        Args:\n            line (str): a string indicating one instance.\n                This string contains tab-separated values including:\n                label, user_hash, item_hash, item_cate, operation_time, item_history_sequence,\n                item_cate_history_sequence, and time_history_sequence.\n\n        Returns:\n            list: Parsed results including `label`, `user_id`, `item_id`, `item_cate`, `item_history_sequence`, `cate_history_sequence`,\n            `current_time`, `time_diff`, `time_from_first_action`, `time_to_now`.\n\n        \"\"\"", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "col_spliter", ")", "\n", "label", "=", "int", "(", "words", "[", "0", "]", ")", "\n", "user_id", "=", "self", ".", "userdict", "[", "words", "[", "1", "]", "]", "if", "words", "[", "1", "]", "in", "self", ".", "userdict", "else", "0", "\n", "item_id", "=", "self", ".", "itemdict", "[", "words", "[", "2", "]", "]", "if", "words", "[", "2", "]", "in", "self", ".", "itemdict", "else", "0", "\n", "item_cate", "=", "self", ".", "catedict", "[", "words", "[", "3", "]", "]", "if", "words", "[", "3", "]", "in", "self", ".", "catedict", "else", "0", "\n", "current_time", "=", "float", "(", "words", "[", "4", "]", ")", "\n", "\n", "item_history_sequence", "=", "[", "]", "\n", "cate_history_sequence", "=", "[", "]", "\n", "time_history_sequence", "=", "[", "]", "\n", "\n", "item_history_words", "=", "words", "[", "5", "]", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "for", "item", "in", "item_history_words", ":", "\n", "            ", "item_history_sequence", ".", "append", "(", "\n", "self", ".", "itemdict", "[", "item", "]", "if", "item", "in", "self", ".", "itemdict", "else", "0", "\n", ")", "\n", "\n", "", "cate_history_words", "=", "words", "[", "6", "]", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "for", "cate", "in", "cate_history_words", ":", "\n", "            ", "cate_history_sequence", ".", "append", "(", "\n", "self", ".", "catedict", "[", "cate", "]", "if", "cate", "in", "self", ".", "catedict", "else", "0", "\n", ")", "\n", "\n", "", "time_history_words", "=", "words", "[", "7", "]", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "time_history_sequence", "=", "[", "float", "(", "i", ")", "for", "i", "in", "time_history_words", "]", "\n", "\n", "time_range", "=", "3600", "*", "24", "\n", "\n", "time_diff", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "time_history_sequence", ")", "-", "1", ")", ":", "\n", "            ", "diff", "=", "(", "\n", "time_history_sequence", "[", "i", "+", "1", "]", "-", "time_history_sequence", "[", "i", "]", "\n", ")", "/", "time_range", "\n", "diff", "=", "max", "(", "diff", ",", "0.5", ")", "\n", "time_diff", ".", "append", "(", "diff", ")", "\n", "", "last_diff", "=", "(", "current_time", "-", "time_history_sequence", "[", "-", "1", "]", ")", "/", "time_range", "\n", "last_diff", "=", "max", "(", "last_diff", ",", "0.5", ")", "\n", "time_diff", ".", "append", "(", "last_diff", ")", "\n", "time_diff", "=", "np", ".", "log", "(", "time_diff", ")", "\n", "\n", "time_from_first_action", "=", "[", "]", "\n", "first_time", "=", "time_history_sequence", "[", "0", "]", "\n", "time_from_first_action", "=", "[", "\n", "(", "t", "-", "first_time", ")", "/", "time_range", "for", "t", "in", "time_history_sequence", "[", "1", ":", "]", "\n", "]", "\n", "time_from_first_action", "=", "[", "max", "(", "t", ",", "0.5", ")", "for", "t", "in", "time_from_first_action", "]", "\n", "last_diff", "=", "(", "current_time", "-", "first_time", ")", "/", "time_range", "\n", "last_diff", "=", "max", "(", "last_diff", ",", "0.5", ")", "\n", "time_from_first_action", ".", "append", "(", "last_diff", ")", "\n", "time_from_first_action", "=", "np", ".", "log", "(", "time_from_first_action", ")", "\n", "\n", "time_to_now", "=", "[", "]", "\n", "time_to_now", "=", "[", "(", "current_time", "-", "t", ")", "/", "time_range", "for", "t", "in", "time_history_sequence", "]", "\n", "time_to_now", "=", "[", "max", "(", "t", ",", "0.5", ")", "for", "t", "in", "time_to_now", "]", "\n", "time_to_now", "=", "np", ".", "log", "(", "time_to_now", ")", "\n", "\n", "return", "(", "\n", "label", ",", "\n", "user_id", ",", "\n", "item_id", ",", "\n", "item_cate", ",", "\n", "item_history_sequence", ",", "\n", "cate_history_sequence", ",", "\n", "current_time", ",", "\n", "time_diff", ",", "\n", "time_from_first_action", ",", "\n", "time_to_now", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file": [[167, 276], ["sequential_iterator.SequentialIterator.parse_file", "random.shuffle", "label_list.append", "user_list.append", "item_list.append", "item_cate_list.append", "item_history_batch.append", "item_cate_history_batch.append", "time_list.append", "time_diff_list.append", "time_from_first_action_list.append", "time_to_now_list.append", "sequential_iterator.SequentialIterator._convert_data", "sequential_iterator.SequentialIterator.gen_feed_dict", "len", "sequential_iterator.SequentialIterator._convert_data", "sequential_iterator.SequentialIterator.gen_feed_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.parse_file", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict"], ["", "def", "load_data_from_file", "(", "self", ",", "infile", ",", "batch_num_ngs", "=", "0", ",", "min_seq_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"Read and parse data from a file.\n\n        Args:\n            infile (str): Text input file. Each line in this file is an instance.\n            batch_num_ngs (int): The number of negative sampling here in batch.\n                0 represents that there is no need to do negative sampling here.\n            min_seq_length (int): The minimum number of a sequence length.\n                Sequences with length lower than min_seq_length will be ignored.\n\n        Yields:\n            object: An iterator that yields parsed results, in the format of graph `feed_dict`.\n        \"\"\"", "\n", "label_list", "=", "[", "]", "\n", "user_list", "=", "[", "]", "\n", "item_list", "=", "[", "]", "\n", "item_cate_list", "=", "[", "]", "\n", "item_history_batch", "=", "[", "]", "\n", "item_cate_history_batch", "=", "[", "]", "\n", "time_list", "=", "[", "]", "\n", "time_diff_list", "=", "[", "]", "\n", "time_from_first_action_list", "=", "[", "]", "\n", "time_to_now_list", "=", "[", "]", "\n", "\n", "cnt", "=", "0", "\n", "\n", "if", "infile", "not", "in", "self", ".", "iter_data", ":", "\n", "            ", "lines", "=", "self", ".", "parse_file", "(", "infile", ")", "\n", "self", ".", "iter_data", "[", "infile", "]", "=", "lines", "\n", "", "else", ":", "\n", "            ", "lines", "=", "self", ".", "iter_data", "[", "infile", "]", "\n", "\n", "", "if", "batch_num_ngs", ">", "0", ":", "\n", "            ", "random", ".", "shuffle", "(", "lines", ")", "\n", "\n", "", "for", "line", "in", "lines", ":", "\n", "            ", "if", "not", "line", ":", "\n", "                ", "continue", "\n", "\n", "", "(", "\n", "label", ",", "\n", "user_id", ",", "\n", "item_id", ",", "\n", "item_cate", ",", "\n", "item_history_sequence", ",", "\n", "item_cate_history_sequence", ",", "\n", "current_time", ",", "\n", "time_diff", ",", "\n", "time_from_first_action", ",", "\n", "time_to_now", ",", "\n", ")", "=", "line", "\n", "if", "len", "(", "item_history_sequence", ")", "<", "min_seq_length", ":", "\n", "                ", "continue", "\n", "\n", "", "label_list", ".", "append", "(", "label", ")", "\n", "user_list", ".", "append", "(", "user_id", ")", "\n", "item_list", ".", "append", "(", "item_id", ")", "\n", "item_cate_list", ".", "append", "(", "item_cate", ")", "\n", "item_history_batch", ".", "append", "(", "item_history_sequence", ")", "\n", "item_cate_history_batch", ".", "append", "(", "item_cate_history_sequence", ")", "\n", "time_list", ".", "append", "(", "current_time", ")", "\n", "time_diff_list", ".", "append", "(", "time_diff", ")", "\n", "time_from_first_action_list", ".", "append", "(", "time_from_first_action", ")", "\n", "time_to_now_list", ".", "append", "(", "time_to_now", ")", "\n", "\n", "cnt", "+=", "1", "\n", "if", "cnt", "==", "self", ".", "batch_size", ":", "\n", "                ", "res", "=", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "user_list", ",", "\n", "item_list", ",", "\n", "item_cate_list", ",", "\n", "item_history_batch", ",", "\n", "item_cate_history_batch", ",", "\n", "time_list", ",", "\n", "time_diff_list", ",", "\n", "time_from_first_action_list", ",", "\n", "time_to_now_list", ",", "\n", "batch_num_ngs", ",", "\n", ")", "\n", "batch_input", "=", "self", ".", "gen_feed_dict", "(", "res", ")", "\n", "yield", "batch_input", "if", "batch_input", "else", "None", "\n", "label_list", "=", "[", "]", "\n", "user_list", "=", "[", "]", "\n", "item_list", "=", "[", "]", "\n", "item_cate_list", "=", "[", "]", "\n", "item_history_batch", "=", "[", "]", "\n", "item_cate_history_batch", "=", "[", "]", "\n", "time_list", "=", "[", "]", "\n", "time_diff_list", "=", "[", "]", "\n", "time_from_first_action_list", "=", "[", "]", "\n", "time_to_now_list", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "", "", "if", "cnt", ">", "0", ":", "\n", "            ", "res", "=", "self", ".", "_convert_data", "(", "\n", "label_list", ",", "\n", "user_list", ",", "\n", "item_list", ",", "\n", "item_cate_list", ",", "\n", "item_history_batch", ",", "\n", "item_cate_history_batch", ",", "\n", "time_list", ",", "\n", "time_diff_list", ",", "\n", "time_from_first_action_list", ",", "\n", "time_to_now_list", ",", "\n", "batch_num_ngs", ",", "\n", ")", "\n", "batch_input", "=", "self", ".", "gen_feed_dict", "(", "res", ")", "\n", "yield", "batch_input", "if", "batch_input", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator._convert_data": [[277, 450], ["len", "numpy.asarray().flatten", "numpy.asarray().flatten", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "range", "range", "numpy.asarray().reshape", "numpy.asarray", "numpy.asarray", "len", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "range", "numpy.asarray().reshape", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "min", "range", "label_list_all.append", "item_list_all.append", "item_cate_list_all.append", "len", "min", "numpy.asarray", "numpy.asarray", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "random.randint", "label_list_all.append", "item_list_all.append", "item_cate_list_all.append", "numpy.asarray", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.asarray"], "methods", ["None"], ["", "", "def", "_convert_data", "(", "\n", "self", ",", "\n", "label_list", ",", "\n", "user_list", ",", "\n", "item_list", ",", "\n", "item_cate_list", ",", "\n", "item_history_batch", ",", "\n", "item_cate_history_batch", ",", "\n", "time_list", ",", "\n", "time_diff_list", ",", "\n", "time_from_first_action_list", ",", "\n", "time_to_now_list", ",", "\n", "batch_num_ngs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Convert data into numpy arrays that are good for further model operation.\n\n        Args:\n            label_list (list): A list of ground-truth labels.\n            user_list (list): A list of user indexes.\n            item_list (list): A list of item indexes.\n            item_cate_list (list): A list of category indexes.\n            item_history_batch (list): A list of item history indexes.\n            item_cate_history_batch (list): A list of category history indexes.\n            time_list (list): A list of current timestamp.\n            time_diff_list (list): A list of timestamp between each sequential operations.\n            time_from_first_action_list (list): A list of timestamp from the first operation.\n            time_to_now_list (list): A list of timestamp to the current time.\n            batch_num_ngs (int): The number of negative sampling while training in mini-batch.\n\n        Returns:\n            dict: A dictionary, containing multiple numpy arrays that are convenient for further operation.\n        \"\"\"", "\n", "if", "batch_num_ngs", ":", "\n", "            ", "instance_cnt", "=", "len", "(", "label_list", ")", "\n", "if", "instance_cnt", "<", "5", ":", "\n", "                ", "return", "\n", "\n", "", "label_list_all", "=", "[", "]", "\n", "item_list_all", "=", "[", "]", "\n", "item_cate_list_all", "=", "[", "]", "\n", "user_list_all", "=", "np", ".", "asarray", "(", "\n", "[", "[", "user", "]", "*", "(", "batch_num_ngs", "+", "1", ")", "for", "user", "in", "user_list", "]", ",", "dtype", "=", "np", ".", "int32", "\n", ")", ".", "flatten", "(", ")", "\n", "time_list_all", "=", "np", ".", "asarray", "(", "\n", "[", "[", "t", "]", "*", "(", "batch_num_ngs", "+", "1", ")", "for", "t", "in", "time_list", "]", ",", "dtype", "=", "np", ".", "float32", "\n", ")", ".", "flatten", "(", ")", "\n", "\n", "history_lengths", "=", "[", "len", "(", "item_history_batch", "[", "i", "]", ")", "for", "i", "in", "range", "(", "instance_cnt", ")", "]", "\n", "max_seq_length_batch", "=", "self", ".", "max_seq_length", "\n", "item_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "item_cate_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "time_diff_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "time_from_first_action_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "time_to_now_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "batch_num_ngs", "+", "1", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", "*", "(", "1", "+", "batch_num_ngs", ")", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "this_length", "=", "min", "(", "history_lengths", "[", "i", "]", ",", "max_seq_length_batch", ")", "\n", "for", "index", "in", "range", "(", "batch_num_ngs", "+", "1", ")", ":", "\n", "                    ", "item_history_batch_all", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "\n", "]", "=", "np", ".", "asarray", "(", "item_history_batch", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "item_cate_history_batch_all", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "\n", "]", "=", "np", ".", "asarray", "(", "\n", "item_cate_history_batch", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "mask", "[", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "]", "=", "1.0", "\n", "time_diff_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "\n", "]", "=", "np", ".", "asarray", "(", "time_diff_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "time_from_first_action_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "\n", "]", "=", "np", ".", "asarray", "(", "\n", "time_from_first_action_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "time_to_now_batch", "[", "\n", "i", "*", "(", "batch_num_ngs", "+", "1", ")", "+", "index", ",", ":", "this_length", "\n", "]", "=", "np", ".", "asarray", "(", "time_to_now_list", "[", "i", "]", "[", "-", "this_length", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "positive_item", "=", "item_list", "[", "i", "]", "\n", "label_list_all", ".", "append", "(", "1", ")", "\n", "item_list_all", ".", "append", "(", "positive_item", ")", "\n", "item_cate_list_all", ".", "append", "(", "item_cate_list", "[", "i", "]", ")", "\n", "count", "=", "0", "\n", "while", "batch_num_ngs", ":", "\n", "                    ", "random_value", "=", "random", ".", "randint", "(", "0", ",", "instance_cnt", "-", "1", ")", "\n", "negative_item", "=", "item_list", "[", "random_value", "]", "\n", "if", "negative_item", "==", "positive_item", ":", "\n", "                        ", "continue", "\n", "", "label_list_all", ".", "append", "(", "0", ")", "\n", "item_list_all", ".", "append", "(", "negative_item", ")", "\n", "item_cate_list_all", ".", "append", "(", "item_cate_list", "[", "random_value", "]", ")", "\n", "count", "+=", "1", "\n", "if", "count", "==", "batch_num_ngs", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "res", "=", "{", "}", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "label_list_all", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "res", "[", "\"users\"", "]", "=", "user_list_all", "\n", "res", "[", "\"items\"", "]", "=", "np", ".", "asarray", "(", "item_list_all", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"cates\"", "]", "=", "np", ".", "asarray", "(", "item_cate_list_all", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"item_history\"", "]", "=", "item_history_batch_all", "\n", "res", "[", "\"item_cate_history\"", "]", "=", "item_cate_history_batch_all", "\n", "res", "[", "\"mask\"", "]", "=", "mask", "\n", "res", "[", "\"time\"", "]", "=", "time_list_all", "\n", "res", "[", "\"time_diff\"", "]", "=", "time_diff_batch", "\n", "res", "[", "\"time_from_first_action\"", "]", "=", "time_from_first_action_batch", "\n", "res", "[", "\"time_to_now\"", "]", "=", "time_to_now_batch", "\n", "return", "res", "\n", "\n", "", "else", ":", "\n", "            ", "instance_cnt", "=", "len", "(", "label_list", ")", "\n", "history_lengths", "=", "[", "len", "(", "item_history_batch", "[", "i", "]", ")", "for", "i", "in", "range", "(", "instance_cnt", ")", "]", "\n", "max_seq_length_batch", "=", "self", ".", "max_seq_length", "\n", "item_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "item_cate_history_batch_all", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "time_diff_batch", "=", "np", ".", "zeros", "(", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ")", ".", "astype", "(", "\n", "\"float32\"", "\n", ")", "\n", "time_from_first_action_batch", "=", "np", ".", "zeros", "(", "\n", "(", "instance_cnt", ",", "max_seq_length_batch", ")", "\n", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "time_to_now_batch", "=", "np", ".", "zeros", "(", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ")", ".", "astype", "(", "\n", "\"float32\"", "\n", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "instance_cnt", ",", "max_seq_length_batch", ")", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "instance_cnt", ")", ":", "\n", "                ", "this_length", "=", "min", "(", "history_lengths", "[", "i", "]", ",", "max_seq_length_batch", ")", "\n", "item_history_batch_all", "[", "i", ",", ":", "this_length", "]", "=", "item_history_batch", "[", "i", "]", "[", "\n", "-", "this_length", ":", "\n", "]", "\n", "item_cate_history_batch_all", "[", "i", ",", ":", "this_length", "]", "=", "item_cate_history_batch", "[", "\n", "i", "\n", "]", "[", "-", "this_length", ":", "]", "\n", "mask", "[", "i", ",", ":", "this_length", "]", "=", "1.0", "\n", "time_diff_batch", "[", "i", ",", ":", "this_length", "]", "=", "time_diff_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "time_from_first_action_batch", "[", "\n", "i", ",", ":", "this_length", "\n", "]", "=", "time_from_first_action_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "time_to_now_batch", "[", "i", ",", ":", "this_length", "]", "=", "time_to_now_list", "[", "i", "]", "[", "-", "this_length", ":", "]", "\n", "\n", "", "res", "=", "{", "}", "\n", "res", "[", "\"labels\"", "]", "=", "np", ".", "asarray", "(", "label_list", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "res", "[", "\"users\"", "]", "=", "np", ".", "asarray", "(", "user_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"items\"", "]", "=", "np", ".", "asarray", "(", "item_list", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"cates\"", "]", "=", "np", ".", "asarray", "(", "item_cate_list", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "res", "[", "\"item_history\"", "]", "=", "item_history_batch_all", "\n", "res", "[", "\"item_cate_history\"", "]", "=", "item_cate_history_batch_all", "\n", "res", "[", "\"mask\"", "]", "=", "mask", "\n", "res", "[", "\"time\"", "]", "=", "np", ".", "asarray", "(", "time_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "res", "[", "\"time_diff\"", "]", "=", "time_diff_batch", "\n", "res", "[", "\"time_from_first_action\"", "]", "=", "time_from_first_action_batch", "\n", "res", "[", "\"time_to_now\"", "]", "=", "time_to_now_batch", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.gen_feed_dict": [[451, 477], ["dict"], "methods", ["None"], ["", "", "def", "gen_feed_dict", "(", "self", ",", "data_dict", ")", ":", "\n", "        ", "\"\"\"Construct a dictionary that maps graph elements to values.\n\n        Args:\n            data_dict (dict): A dictionary that maps string name to numpy arrays.\n\n        Returns:\n            dict: A dictionary that maps graph elements to numpy arrays.\n\n        \"\"\"", "\n", "if", "not", "data_dict", ":", "\n", "            ", "return", "dict", "(", ")", "\n", "", "feed_dict", "=", "{", "\n", "self", ".", "labels", ":", "data_dict", "[", "\"labels\"", "]", ",", "\n", "self", ".", "users", ":", "data_dict", "[", "\"users\"", "]", ",", "\n", "self", ".", "items", ":", "data_dict", "[", "\"items\"", "]", ",", "\n", "self", ".", "cates", ":", "data_dict", "[", "\"cates\"", "]", ",", "\n", "self", ".", "item_history", ":", "data_dict", "[", "\"item_history\"", "]", ",", "\n", "self", ".", "item_cate_history", ":", "data_dict", "[", "\"item_cate_history\"", "]", ",", "\n", "self", ".", "mask", ":", "data_dict", "[", "\"mask\"", "]", ",", "\n", "self", ".", "time", ":", "data_dict", "[", "\"time\"", "]", ",", "\n", "self", ".", "time_diff", ":", "data_dict", "[", "\"time_diff\"", "]", ",", "\n", "self", ".", "time_from_first_action", ":", "data_dict", "[", "\"time_from_first_action\"", "]", ",", "\n", "self", ".", "time_to_now", ":", "data_dict", "[", "\"time_to_now\"", "]", ",", "\n", "}", "\n", "return", "feed_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.model_perf_plots": [[11, 22], ["seaborn.FacetGrid", "g.map().add_legend.map().add_legend", "g.map().add_legend.map"], "function", ["None"], ["def", "model_perf_plots", "(", "df", ")", ":", "\n", "    ", "\"\"\"Function to plot model performance metrics.\n\n    Args:\n        df (pandas.DataFrame): Dataframe in tidy format, with ['epoch','level','value'] columns\n\n    Returns:\n        object: matplotlib axes\n    \"\"\"", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "df", ",", "col", "=", "\"metric\"", ",", "hue", "=", "\"stage\"", ",", "col_wrap", "=", "2", ",", "sharey", "=", "False", ")", "\n", "g", "=", "g", ".", "map", "(", "sns", ".", "scatterplot", ",", "\"epoch\"", ",", "\"value\"", ")", ".", "add_legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.compare_metric": [[24, 46], ["pandas.DataFrame().stack().reset_index", "str", "list", "[].reset_index", "pandas.DataFrame().stack", "range", "pandas.DataFrame", "len", "zip"], "function", ["None"], ["", "def", "compare_metric", "(", "df_list", ",", "metric", "=", "\"prec\"", ",", "stage", "=", "\"test\"", ")", ":", "\n", "    ", "\"\"\"Function to combine and prepare list of dataframes into tidy format.\n\n    Args:\n        df_list (list): List of dataframes\n        metrics (str): name of metric to be extracted, optional\n        stage (str): name of model fitting stage to be extracted, optional\n\n    Returns:\n        pandas.DataFrame: Metrics\n    \"\"\"", "\n", "colnames", "=", "[", "\"model\"", "+", "str", "(", "x", ")", "for", "x", "in", "list", "(", "range", "(", "1", ",", "len", "(", "df_list", ")", "+", "1", ")", ")", "]", "\n", "models", "=", "[", "\n", "df", "[", "(", "df", "[", "\"stage\"", "]", "==", "stage", ")", "&", "(", "df", "[", "\"metric\"", "]", "==", "metric", ")", "]", "[", "\"value\"", "]", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ".", "values", "\n", "for", "df", "in", "df_list", "\n", "]", "\n", "\n", "output", "=", "pd", ".", "DataFrame", "(", "zip", "(", "*", "models", ")", ",", "columns", "=", "colnames", ")", ".", "stack", "(", ")", ".", "reset_index", "(", ")", "\n", "output", ".", "columns", "=", "[", "\"epoch\"", ",", "\"data\"", ",", "\"value\"", "]", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.track_model_metrics": [[48, 126], ["range", "pandas.DataFrame", "fitting_metrics.stack().reset_index.stack().reset_index", "fitting_metrics.stack().reset_index.drop", "fitting_metrics.stack().reset_index.metric.replace", "model.fit_partial", "lightfm.evaluation.precision_at_k().mean", "lightfm.evaluation.precision_at_k().mean", "lightfm.evaluation.recall_at_k().mean", "lightfm.evaluation.recall_at_k().mean", "zip", "lightfm_utils.model_perf_plots", "fitting_metrics.stack().reset_index.stack", "fitting_metrics.stack().reset_index.level.str.split", "fitting_metrics.stack().reset_index.level.str.split", "lightfm.evaluation.precision_at_k", "lightfm.evaluation.precision_at_k", "lightfm.evaluation.recall_at_k", "lightfm.evaluation.recall_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.model_perf_plots", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "def", "track_model_metrics", "(", "\n", "model", ",", "\n", "train_interactions", ",", "\n", "test_interactions", ",", "\n", "k", "=", "10", ",", "\n", "no_epochs", "=", "100", ",", "\n", "no_threads", "=", "8", ",", "\n", "show_plot", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "    ", "\"\"\"Function to record model's performance at each epoch, formats the performance into tidy format,\n    plots the performance and outputs the performance data.\n\n    Args:\n        model (LightFM instance): fitted LightFM model\n        train_interactions (scipy sparse COO matrix): train interactions set\n        test_interactions (scipy sparse COO matrix): test interaction set\n        k (int): number of recommendations, optional\n        no_epochs (int): Number of epochs to run, optional\n        no_threads (int): Number of parallel threads to use, optional\n        **kwargs: other keyword arguments to be passed down\n\n    Returns:\n        pandas.DataFrame, LightFM model, matplotlib axes:\n        - Performance traces of the fitted model\n        - Fitted model\n        - Side effect of the method\n    \"\"\"", "\n", "# initialising temp data storage", "\n", "model_prec_train", "=", "[", "0", "]", "*", "no_epochs", "\n", "model_prec_test", "=", "[", "0", "]", "*", "no_epochs", "\n", "\n", "model_rec_train", "=", "[", "0", "]", "*", "no_epochs", "\n", "model_rec_test", "=", "[", "0", "]", "*", "no_epochs", "\n", "\n", "# fit model and store train/test metrics at each epoch", "\n", "for", "epoch", "in", "range", "(", "no_epochs", ")", ":", "\n", "        ", "model", ".", "fit_partial", "(", "\n", "interactions", "=", "train_interactions", ",", "epochs", "=", "1", ",", "num_threads", "=", "no_threads", ",", "**", "kwargs", "\n", ")", "\n", "model_prec_train", "[", "epoch", "]", "=", "precision_at_k", "(", "\n", "model", ",", "train_interactions", ",", "k", "=", "k", ",", "**", "kwargs", "\n", ")", ".", "mean", "(", ")", "\n", "model_prec_test", "[", "epoch", "]", "=", "precision_at_k", "(", "\n", "model", ",", "test_interactions", ",", "k", "=", "k", ",", "**", "kwargs", "\n", ")", ".", "mean", "(", ")", "\n", "\n", "model_rec_train", "[", "epoch", "]", "=", "recall_at_k", "(", "\n", "model", ",", "train_interactions", ",", "k", "=", "k", ",", "**", "kwargs", "\n", ")", ".", "mean", "(", ")", "\n", "model_rec_test", "[", "epoch", "]", "=", "recall_at_k", "(", "\n", "model", ",", "test_interactions", ",", "k", "=", "k", ",", "**", "kwargs", "\n", ")", ".", "mean", "(", ")", "\n", "\n", "# collect the performance metrics into a dataframe", "\n", "", "fitting_metrics", "=", "pd", ".", "DataFrame", "(", "\n", "zip", "(", "model_prec_train", ",", "model_prec_test", ",", "model_rec_train", ",", "model_rec_test", ")", ",", "\n", "columns", "=", "[", "\n", "\"model_prec_train\"", ",", "\n", "\"model_prec_test\"", ",", "\n", "\"model_rec_train\"", ",", "\n", "\"model_rec_test\"", ",", "\n", "]", ",", "\n", ")", "\n", "# convert into tidy format", "\n", "fitting_metrics", "=", "fitting_metrics", ".", "stack", "(", ")", ".", "reset_index", "(", ")", "\n", "fitting_metrics", ".", "columns", "=", "[", "\"epoch\"", ",", "\"level\"", ",", "\"value\"", "]", "\n", "# exact the labels for each observation", "\n", "fitting_metrics", "[", "\"stage\"", "]", "=", "fitting_metrics", ".", "level", ".", "str", ".", "split", "(", "\"_\"", ")", ".", "str", "[", "-", "1", "]", "\n", "fitting_metrics", "[", "\"metric\"", "]", "=", "fitting_metrics", ".", "level", ".", "str", ".", "split", "(", "\"_\"", ")", ".", "str", "[", "1", "]", "\n", "fitting_metrics", ".", "drop", "(", "[", "\"level\"", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "# replace the metric keys to improve visualisation", "\n", "metric_keys", "=", "{", "\"prec\"", ":", "\"Precision\"", ",", "\"rec\"", ":", "\"Recall\"", "}", "\n", "fitting_metrics", ".", "metric", ".", "replace", "(", "metric_keys", ",", "inplace", "=", "True", ")", "\n", "# plots the performance data", "\n", "if", "show_plot", ":", "\n", "        ", "model_perf_plots", "(", "fitting_metrics", ")", "\n", "", "return", "fitting_metrics", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.similar_users": [[128, 152], ["model.get_user_representations", "user_representations.dot", "numpy.linalg.norm", "pandas.DataFrame", "numpy.argpartition", "sorted", "zip"], "function", ["None"], ["", "def", "similar_users", "(", "user_id", ",", "user_features", ",", "model", ",", "N", "=", "10", ")", ":", "\n", "    ", "\"\"\"Function to return top N similar users based on https://github.com/lyst/lightfm/issues/244#issuecomment-355305681\n\n     Args:\n        user_id (int): id of user to be used as reference\n        user_features (scipy sparse CSR matrix): user feature matric\n        model (LightFM instance): fitted LightFM model\n        N (int): Number of top similar users to return\n\n    Returns:\n        pandas.DataFrame: top N most similar users with score\n    \"\"\"", "\n", "_", ",", "user_representations", "=", "model", ".", "get_user_representations", "(", "features", "=", "user_features", ")", "\n", "\n", "# Cosine similarity", "\n", "scores", "=", "user_representations", ".", "dot", "(", "user_representations", "[", "user_id", ",", ":", "]", ")", "\n", "user_norms", "=", "np", ".", "linalg", ".", "norm", "(", "user_representations", ",", "axis", "=", "1", ")", "\n", "user_norms", "[", "user_norms", "==", "0", "]", "=", "1e-10", "\n", "scores", "/=", "user_norms", "\n", "\n", "best", "=", "np", ".", "argpartition", "(", "scores", ",", "-", "(", "N", "+", "1", ")", ")", "[", "-", "(", "N", "+", "1", ")", ":", "]", "\n", "return", "pd", ".", "DataFrame", "(", "\n", "sorted", "(", "zip", "(", "best", ",", "scores", "[", "best", "]", "/", "user_norms", "[", "user_id", "]", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "[", "1", ":", "]", ",", "\n", "columns", "=", "[", "\"userID\"", ",", "\"score\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.similar_items": [[155, 180], ["model.get_item_representations", "item_representations.dot", "numpy.linalg.norm", "pandas.DataFrame", "numpy.argpartition", "sorted", "zip"], "function", ["None"], ["", "def", "similar_items", "(", "item_id", ",", "item_features", ",", "model", ",", "N", "=", "10", ")", ":", "\n", "    ", "\"\"\"Function to return top N similar items\n    based on https://github.com/lyst/lightfm/issues/244#issuecomment-355305681\n\n    Args:\n        item_id (int): id of item to be used as reference\n        item_features (scipy sparse CSR matrix): item feature matric\n        model (LightFM instance): fitted LightFM model\n        N (int): Number of top similar items to return\n\n    Returns:\n        pandas.DataFrame: top N most similar items with score\n    \"\"\"", "\n", "_", ",", "item_representations", "=", "model", ".", "get_item_representations", "(", "features", "=", "item_features", ")", "\n", "\n", "# Cosine similarity", "\n", "scores", "=", "item_representations", ".", "dot", "(", "item_representations", "[", "item_id", ",", ":", "]", ")", "\n", "item_norms", "=", "np", ".", "linalg", ".", "norm", "(", "item_representations", ",", "axis", "=", "1", ")", "\n", "item_norms", "[", "item_norms", "==", "0", "]", "=", "1e-10", "\n", "scores", "/=", "item_norms", "\n", "\n", "best", "=", "np", ".", "argpartition", "(", "scores", ",", "-", "(", "N", "+", "1", ")", ")", "[", "-", "(", "N", "+", "1", ")", ":", "]", "\n", "return", "pd", ".", "DataFrame", "(", "\n", "sorted", "(", "zip", "(", "best", ",", "scores", "[", "best", "]", "/", "item_norms", "[", "item_id", "]", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "[", "1", ":", "]", ",", "\n", "columns", "=", "[", "\"itemID\"", ",", "\"score\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.prepare_test_df": [[183, 211], ["pandas.DataFrame", "weights.todok", "pd.DataFrame.apply", "zip", "list", "list", "uid_map.keys", "iid_map.keys"], "function", ["None"], ["", "def", "prepare_test_df", "(", "test_idx", ",", "uids", ",", "iids", ",", "uid_map", ",", "iid_map", ",", "weights", ")", ":", "\n", "    ", "\"\"\"Function to prepare test df for evaluation\n\n    Args:\n        test_idx (slice): slice of test indices\n        uids (numpy.ndarray): Array of internal user indices\n        iids (numpy.ndarray): Array of internal item indices\n        uid_map (dict): Keys to map internal user indices to external ids.\n        iid_map (dict): Keys to map internal item indices to external ids.\n        weights (numpy.float32 coo_matrix): user-item interaction\n\n    Returns:\n        pandas.DataFrame: user-item selected for testing\n    \"\"\"", "\n", "test_df", "=", "pd", ".", "DataFrame", "(", "\n", "zip", "(", "\n", "uids", "[", "test_idx", "]", ",", "\n", "iids", "[", "test_idx", "]", ",", "\n", "[", "list", "(", "uid_map", ".", "keys", "(", ")", ")", "[", "x", "]", "for", "x", "in", "uids", "[", "test_idx", "]", "]", ",", "\n", "[", "list", "(", "iid_map", ".", "keys", "(", ")", ")", "[", "x", "]", "for", "x", "in", "iids", "[", "test_idx", "]", "]", ",", "\n", ")", ",", "\n", "columns", "=", "[", "\"uid\"", ",", "\"iid\"", ",", "\"userID\"", ",", "\"itemID\"", "]", ",", "\n", ")", "\n", "\n", "dok_weights", "=", "weights", ".", "todok", "(", ")", "\n", "test_df", "[", "\"rating\"", "]", "=", "test_df", ".", "apply", "(", "lambda", "x", ":", "dok_weights", "[", "x", ".", "uid", ",", "x", ".", "iid", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "test_df", "[", "[", "\"userID\"", ",", "\"itemID\"", ",", "\"rating\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightfm.lightfm_utils.prepare_all_predictions": [[213, 266], ["list", "data.userID.unique", "pandas.DataFrame", "all_predictions.drop.userID.map", "all_predictions.drop.itemID.map", "interactions.todok", "all_predictions.drop.apply", "all_predictions[].reset_index", "all_predictions.drop.drop", "all_predictions.drop.apply", "data.itemID.unique", "users.extend", "items.extend", "len", "model.predict", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "prepare_all_predictions", "(", "\n", "data", ",", "\n", "uid_map", ",", "\n", "iid_map", ",", "\n", "interactions", ",", "\n", "model", ",", "\n", "num_threads", ",", "\n", "user_features", "=", "None", ",", "\n", "item_features", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Function to prepare all predictions for evaluation.\n    Args:\n        data (pandas df): dataframe of all users, items and ratings as loaded\n        uid_map (dict): Keys to map internal user indices to external ids.\n        iid_map (dict): Keys to map internal item indices to external ids.\n        interactions (np.float32 coo_matrix): user-item interaction\n        model (LightFM instance): fitted LightFM model\n        num_threads (int): number of parallel computation threads\n        user_features (np.float32 csr_matrix): User weights over features\n        item_features (np.float32 csr_matrix):  Item weights over features\n    Returns:\n        pandas.DataFrame: all predictions\n    \"\"\"", "\n", "users", ",", "items", ",", "preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# noqa: F841", "\n", "item", "=", "list", "(", "data", ".", "itemID", ".", "unique", "(", ")", ")", "\n", "for", "user", "in", "data", ".", "userID", ".", "unique", "(", ")", ":", "\n", "        ", "user", "=", "[", "user", "]", "*", "len", "(", "item", ")", "\n", "users", ".", "extend", "(", "user", ")", "\n", "items", ".", "extend", "(", "item", ")", "\n", "", "all_predictions", "=", "pd", ".", "DataFrame", "(", "data", "=", "{", "\"userID\"", ":", "users", ",", "\"itemID\"", ":", "items", "}", ")", "\n", "all_predictions", "[", "\"uid\"", "]", "=", "all_predictions", ".", "userID", ".", "map", "(", "uid_map", ")", "\n", "all_predictions", "[", "\"iid\"", "]", "=", "all_predictions", ".", "itemID", ".", "map", "(", "iid_map", ")", "\n", "\n", "dok_weights", "=", "interactions", ".", "todok", "(", ")", "\n", "all_predictions", "[", "\"rating\"", "]", "=", "all_predictions", ".", "apply", "(", "\n", "lambda", "x", ":", "dok_weights", "[", "x", ".", "uid", ",", "x", ".", "iid", "]", ",", "axis", "=", "1", "\n", ")", "\n", "\n", "all_predictions", "=", "all_predictions", "[", "all_predictions", ".", "rating", "<", "1", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "all_predictions", "=", "all_predictions", ".", "drop", "(", "\"rating\"", ",", "axis", "=", "1", ")", "\n", "\n", "all_predictions", "[", "\"prediction\"", "]", "=", "all_predictions", ".", "apply", "(", "\n", "lambda", "x", ":", "model", ".", "predict", "(", "\n", "user_ids", "=", "np", ".", "array", "(", "[", "x", "[", "\"uid\"", "]", "]", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "item_ids", "=", "np", ".", "array", "(", "[", "x", "[", "\"iid\"", "]", "]", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", "user_features", "=", "user_features", ",", "\n", "item_features", "=", "item_features", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", ")", "[", "0", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "return", "all_predictions", "[", "[", "\"userID\"", ",", "\"itemID\"", ",", "\"prediction\"", "]", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.__init__": [[24, 38], ["scipy.sparse.isspmatrix_csr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "entities", ")", ":", "\n", "        ", "\"\"\"Initialize a data pointer\n\n        Args:\n            data (csr_matrix): The target data matrix.\n            entities (Iterator): An iterator (of 2 elements (ndarray)) containing\n            the features of row, col entities.\n        \"\"\"", "\n", "assert", "isspmatrix_csr", "(", "data", ")", "\n", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "entities", "=", "entities", "\n", "self", ".", "data_indices", "=", "None", "\n", "self", ".", "entity_indices", "=", "[", "None", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_data": [[39, 47], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            csr_matrix: Target matrix (based on the data_indices filter)\n        \"\"\"", "\n", "if", "self", ".", "data_indices", "is", "None", ":", "\n", "            ", "return", "self", ".", "data", "\n", "", "return", "self", ".", "data", "[", "self", ".", "data_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity": [[48, 60], ["None"], "methods", ["None"], ["", "def", "get_entity", "(", "self", ",", "of", "=", "\"row\"", ")", ":", "\n", "        ", "\"\"\"Get entity\n\n        Args:\n            of (str): The entity, either 'row' or 'col'\n        Returns:\n            numpy.ndarray: Entity matrix (based on the entity_indices filter)\n        \"\"\"", "\n", "idx", "=", "0", "if", "of", "==", "\"row\"", "else", "1", "\n", "if", "self", ".", "entity_indices", "[", "idx", "]", "is", "None", ":", "\n", "            ", "return", "self", ".", "entities", "[", "idx", "]", "\n", "", "return", "self", ".", "entities", "[", "idx", "]", "[", "self", ".", "entity_indices", "[", "idx", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.__init__": [[67, 88], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "features_dim", "=", "0", ",", "normalize", "=", "False", ",", "target_transform", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Initialize parameters\n\n        Args:\n            name (str): Name of the dataset\n            features_dim (uint): Dimension of the features. If not 0, PCA is performed\n                on the features as the dimensionality reduction technique\n            normalize (bool): Normalize the features\n            target_transform (str): Transform the target values. Current options are\n                'normalize' (Normalize the values), '' (Do nothing), 'binarize' (convert\n                the values using a threshold defined per dataset)\n\n        \"\"\"", "\n", "self", ".", "name", "=", "None", "\n", "self", ".", "training_data", "=", "None", "\n", "self", ".", "test_data", "=", "None", "\n", "self", ".", "entities", "=", "None", "\n", "\n", "self", ".", "features_dim", "=", "features_dim", "\n", "self", ".", "feat_normalize", "=", "normalize", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.normalize": [[89, 98], ["range", "len", "scipy.sparse.isspmatrix_csr", "logger.info", "sklearn.preprocessing.normalize", "geoimc_utils.length_normalize"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.normalize", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.length_normalize"], ["", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Normalizes the entity features\"\"\"", "\n", "if", "self", ".", "feat_normalize", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "entities", ")", ")", ":", "\n", "                ", "if", "isspmatrix_csr", "(", "self", ".", "entities", "[", "i", "]", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Normalizing CSR matrix\"", ")", "\n", "self", ".", "entities", "[", "i", "]", "=", "normalize", "(", "self", ".", "entities", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "entities", "[", "i", "]", "=", "length_normalize", "(", "self", ".", "entities", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.generate_train_test_data": [[99, 119], ["geoimc_data.DataPtr", "geoimc_data.DataPtr", "sklearn.model_selection.train_test_split", "numpy.array", "range"], "methods", ["None"], ["", "", "", "", "def", "generate_train_test_data", "(", "self", ",", "data", ",", "test_ratio", "=", "0.3", ")", ":", "\n", "        ", "\"\"\"Generate train, test split. The split is performed on the row\n        entities. So, this essentially becomes a cold start row entity test.\n\n        Args:\n            data (csr_matrix): The entire target matrix.\n            test_ratio (float): Ratio of test split.\n\n        \"\"\"", "\n", "self", ".", "training_data", "=", "DataPtr", "(", "data", ",", "self", ".", "entities", ")", "\n", "self", ".", "test_data", "=", "DataPtr", "(", "data", ",", "self", ".", "entities", ")", "\n", "\n", "self", ".", "training_data", ".", "data_indices", ",", "self", ".", "test_data", ".", "data_indices", "=", "train_test_split", "(", "\n", "np", ".", "array", "(", "range", "(", "0", ",", "data", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "test_size", "=", "test_ratio", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_state", "=", "0", ",", "\n", ")", "\n", "self", ".", "training_data", ".", "entity_indices", "[", "0", "]", "=", "self", ".", "training_data", ".", "data_indices", "\n", "self", ".", "test_data", ".", "entity_indices", "[", "0", "]", "=", "self", ".", "test_data", ".", "data_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.reduce_dims": [[120, 126], ["geoimc_utils.reduce_dims", "geoimc_utils.reduce_dims", "logger.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.reduce_dims", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.reduce_dims"], ["", "def", "reduce_dims", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reduces the dimensionality of entity features.\"\"\"", "\n", "if", "self", ".", "features_dim", "!=", "0", ":", "\n", "            ", "self", ".", "entities", "[", "0", "]", "=", "reduce_dims", "(", "self", ".", "entities", "[", "0", "]", ",", "self", ".", "features_dim", ")", "\n", "self", ".", "entities", "[", "1", "]", "=", "reduce_dims", "(", "self", ".", "entities", "[", "1", "]", ",", "self", ".", "features_dim", ")", "\n", "logger", ".", "info", "(", "\"Dimensionality reduced ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.__init__": [[133, 137], ["geoimc_data.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "self", ".", "__class__", ".", "__name__", ",", "**", "kwargs", ")", "\n", "self", ".", "min_rating", "=", "1", "\n", "self", ".", "max_rating", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.df2coo": [[138, 160], ["list", "list", "range", "scipy.sparse.coo_matrix", "len", "numpy.sqrt", "recommenders.utils.python_utils.binarize", "numpy.sum", "numpy.array", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.binarize"], ["", "def", "df2coo", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Convert the input dataframe into a coo matrix\n\n        Args:\n            df (pandas.DataFrame): DataFrame containing the target matrix information.\n        \"\"\"", "\n", "data", "=", "[", "]", "\n", "row", "=", "list", "(", "df", "[", "\"user id\"", "]", "-", "1", ")", "\n", "col", "=", "list", "(", "df", "[", "\"item id\"", "]", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "len", "(", "df", ")", ")", ":", "\n", "            ", "val", "=", "df", "[", "\"rating\"", "]", ".", "iloc", "[", "idx", "]", "\n", "data", "+=", "[", "val", "]", "\n", "\n", "", "if", "self", ".", "target_transform", "==", "\"normalize\"", ":", "\n", "            ", "data", "=", "data", "/", "np", ".", "sqrt", "(", "\n", "np", ".", "sum", "(", "np", ".", "arange", "(", "self", ".", "min_rating", ",", "self", ".", "max_rating", "+", "1", ")", "**", "2", ")", "\n", ")", "\n", "", "elif", "self", ".", "target_transform", "==", "\"binarize\"", ":", "\n", "            ", "data", "=", "binarize", "(", "np", ".", "array", "(", "data", ")", ",", "3", ")", "\n", "\n", "# TODO: Get this from `u.info`", "\n", "", "return", "coo_matrix", "(", "(", "data", ",", "(", "row", ",", "col", ")", ")", ",", "shape", "=", "(", "943", ",", "1682", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._read_from_file": [[161, 175], ["pandas.read_csv", "pandas.read_csv.drop", "geoimc_data.ML_100K.df2coo"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.df2coo"], ["", "def", "_read_from_file", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Read the traget matrix from file at path.\n\n        Args:\n            path (str): Path to the target matrix\n        \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "\n", "path", ",", "\n", "delimiter", "=", "\"\\t\"", ",", "\n", "names", "=", "[", "\"user id\"", ",", "\"item id\"", ",", "\"rating\"", ",", "\"timestamp\"", "]", ",", "\n", "encoding", "=", "\"ISO-8859-1\"", ",", "\n", ")", "\n", "df", ".", "drop", "(", "[", "\"timestamp\"", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "return", "self", ".", "df2coo", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K.load_data": [[176, 195], ["geoimc_data.ML_100K.normalize", "geoimc_data.ML_100K.reduce_dims", "geoimc_data.DataPtr", "geoimc_data.DataPtr", "geoimc_data.ML_100K._load_user_features", "geoimc_data.ML_100K._load_item_features", "geoimc_data.ML_100K._read_from_file().tocsr", "geoimc_data.ML_100K._read_from_file().tocsr", "geoimc_data.ML_100K._read_from_file", "geoimc_data.ML_100K._read_from_file"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.normalize", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.reduce_dims", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._load_user_features", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._load_item_features", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._read_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._read_from_file"], ["", "def", "load_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Load dataset\n\n        Args:\n            path (str): Path to the directory containing ML100K dataset\n            e1_path (str): Path to the file containing row (user) features of ML100K dataset\n            e2_path (str): Path to the file containing col (movie) features of ML100K dataset\n        \"\"\"", "\n", "self", ".", "entities", "=", "[", "\n", "self", ".", "_load_user_features", "(", "f\"{path}/u.user\"", ")", ",", "\n", "self", ".", "_load_item_features", "(", "f\"{path}/u.item\"", ")", ",", "\n", "]", "\n", "self", ".", "normalize", "(", ")", "\n", "self", ".", "reduce_dims", "(", ")", "\n", "self", ".", "training_data", "=", "DataPtr", "(", "\n", "self", ".", "_read_from_file", "(", "f\"{path}/u1.base\"", ")", ".", "tocsr", "(", ")", ",", "self", ".", "entities", "\n", ")", "\n", "self", ".", "test_data", "=", "DataPtr", "(", "\n", "self", ".", "_read_from_file", "(", "f\"{path}/u1.test\"", ")", ".", "tocsr", "(", ")", ",", "self", ".", "entities", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._load_user_features": [[197, 223], ["pandas.read_csv", "pandas.concat", "pandas.concat.drop", "numpy.nan_to_num", "pandas.concat.to_numpy", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies"], "methods", ["None"], ["", "def", "_load_user_features", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Load user features\n\n        Args:\n            path (str): Path to the file containing user features information\n\n        \"\"\"", "\n", "data", "=", "pd", ".", "read_csv", "(", "\n", "path", ",", "\n", "delimiter", "=", "\"|\"", ",", "\n", "names", "=", "[", "\"user_id\"", ",", "\"age\"", ",", "\"gender\"", ",", "\"occupation\"", ",", "\"zip_code\"", "]", ",", "\n", ")", "\n", "features_df", "=", "pd", ".", "concat", "(", "\n", "[", "\n", "data", "[", "\"user_id\"", "]", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"user_id\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"age\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"gender\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"occupation\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"zip_code\"", "]", ")", ",", "\n", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "features_df", ".", "drop", "(", "[", "\"user_id\"", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "user_features", "=", "np", ".", "nan_to_num", "(", "features_df", ".", "to_numpy", "(", ")", ")", "\n", "return", "user_features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.ML_100K._load_item_features": [[224, 271], ["pandas.read_csv", "pandas.concat", "numpy.nan_to_num", "pandas.concat.to_numpy", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies"], "methods", ["None"], ["", "def", "_load_item_features", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Load item features\n\n        Args:\n            path (str): Path to the file containing item features information\n\n        \"\"\"", "\n", "header", "=", "[", "\n", "\"movie_id\"", ",", "\n", "\"movie_title\"", ",", "\n", "\"release_date\"", ",", "\n", "\"video_release_date\"", ",", "\n", "\"IMDb_URL\"", ",", "\n", "\"unknown\"", ",", "\n", "\"Action\"", ",", "\n", "\"Adventure\"", ",", "\n", "\"Animation\"", ",", "\n", "\"Childrens\"", ",", "\n", "\"Comedy\"", ",", "\n", "\"Crime\"", ",", "\n", "\"Documentary\"", ",", "\n", "\"Drama\"", ",", "\n", "\"Fantasy\"", ",", "\n", "\"Film-Noir\"", ",", "\n", "\"Horror\"", ",", "\n", "\"Musical\"", ",", "\n", "\"Mystery\"", ",", "\n", "\"Romance\"", ",", "\n", "\"Sci-Fi\"", ",", "\n", "\"Thriller\"", ",", "\n", "\"War\"", ",", "\n", "\"Western\"", ",", "\n", "]", "\n", "data", "=", "pd", ".", "read_csv", "(", "path", ",", "delimiter", "=", "\"|\"", ",", "names", "=", "header", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "features_df", "=", "pd", ".", "concat", "(", "\n", "[", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"movie_title\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "data", "[", "\"release_date\"", "]", ")", ",", "\n", "pd", ".", "get_dummies", "(", "\"video_release_date\"", ")", ",", "\n", "pd", ".", "get_dummies", "(", "\"IMDb_URL\"", ")", ",", "\n", "data", "[", "header", "[", "5", ":", "]", "]", ",", "\n", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "item_features", "=", "np", ".", "nan_to_num", "(", "features_df", ".", "to_numpy", "(", ")", ")", "\n", "return", "item_features", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.PlainScalarProduct.__init__": [[16, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "X", ",", "Y", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            X: numpy matrix of shape (users, features)\n            Y: numpy matrix of shape (items, features)\n        \"\"\"", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "Y", "=", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.PlainScalarProduct.sim": [[25, 29], ["geoimc_predict.PlainScalarProduct.X.dot"], "methods", ["None"], ["", "def", "sim", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the similarity score\"\"\"", "\n", "sim", "=", "self", ".", "X", ".", "dot", "(", "self", ".", "Y", ".", "T", ")", "\n", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.__init__": [[36, 53], ["geoimc_predict.Inferer._get_method"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer._get_method"], ["def", "__init__", "(", "self", ",", "method", "=", "\"dot\"", ",", "k", "=", "10", ",", "transformation", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Initialize parameters\n\n        Args:\n            method (str): The inference method. Currently 'dot'\n                (Dot product) is supported.\n            k (uint): `k` for 'topk' transformation.\n            transformation (str): Transform the inferred values into a\n                different scale. Currently 'mean' (Binarize the values\n                using mean of inferred matrix as the threshold), 'topk'\n                (Pick Top-K inferred values per row and assign them 1,\n                setting rest of them to 0), '' (No transformation) are\n                supported.\n        \"\"\"", "\n", "self", ".", "method", "=", "self", ".", "_get_method", "(", "method", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "transformation", "=", "transformation", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer._get_method": [[54, 68], ["ValueError"], "methods", ["None"], ["", "def", "_get_method", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"Get the inferer method\n\n        Args:\n            k (str): The inferer name\n\n        Returns:\n            class: A class object implementing the inferer 'k'\n        \"\"\"", "\n", "if", "k", "==", "\"dot\"", ":", "\n", "            ", "method", "=", "PlainScalarProduct", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{k} is unknown.\"", ")", "\n", "", "return", "method", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer": [[69, 103], ["isinstance", "geoimc_predict.Inferer.method().sim", "dataPtr.get_entity().dot().dot", "dataPtr.get_entity().dot().dot", "recommenders.utils.python_utils.binarize", "scipy.linalg.sqrtm", "scipy.linalg.sqrtm", "geoimc_predict.Inferer.method", "geoimc_predict.Inferer.mean", "geoimc_predict.Inferer.copy", "range", "dataPtr.get_entity().dot", "dataPtr.get_entity().dot", "numpy.ones", "numpy.argpartition", "dataPtr.get_entity", "dataPtr.get_entity"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.PlainScalarProduct.sim", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.binarize", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity"], ["", "def", "infer", "(", "self", ",", "dataPtr", ",", "W", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Main inference method\n\n        Args:\n            dataPtr (DataPtr): An object containing the X, Z features needed for inference\n            W (iterable): An iterable containing the U, B, V parametrized matrices.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "dataPtr", ",", "list", ")", ":", "\n", "            ", "a", "=", "dataPtr", "[", "0", "]", "\n", "b", "=", "dataPtr", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "a", "=", "dataPtr", ".", "get_entity", "(", "\"row\"", ")", ".", "dot", "(", "W", "[", "0", "]", ")", ".", "dot", "(", "sqrtm", "(", "W", "[", "1", "]", ")", ")", "\n", "b", "=", "dataPtr", ".", "get_entity", "(", "\"col\"", ")", ".", "dot", "(", "W", "[", "2", "]", ")", ".", "dot", "(", "sqrtm", "(", "W", "[", "1", "]", ")", ")", "\n", "\n", "", "sim_score", "=", "self", ".", "method", "(", "a", ",", "b", ")", ".", "sim", "(", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "transformation", "==", "\"mean\"", ":", "\n", "            ", "prediction", "=", "conv_binary", "(", "sim_score", ",", "sim_score", ".", "mean", "(", ")", ")", "\n", "", "elif", "self", ".", "transformation", "==", "\"topk\"", ":", "\n", "            ", "masked_sim_score", "=", "sim_score", ".", "copy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "sim_score", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "topKidx", "=", "np", ".", "argpartition", "(", "masked_sim_score", "[", "i", "]", ",", "-", "self", ".", "k", ")", "[", "-", "self", ".", "k", ":", "]", "\n", "mask", "=", "np", ".", "ones", "(", "sim_score", "[", "i", "]", ".", "size", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "topKidx", "]", "=", "False", "\n", "\n", "masked_sim_score", "[", "i", "]", "[", "topKidx", "]", "=", "1", "\n", "masked_sim_score", "[", "i", "]", "[", "mask", "]", "=", "0", "\n", "", "prediction", "=", "masked_sim_score", "\n", "", "else", ":", "\n", "            ", "prediction", "=", "sim_score", "\n", "\n", "", "return", "prediction", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem.__init__": [[23, 48], ["geoimc_algorithm.IMCProblem.dataset.get_entity", "geoimc_algorithm.IMCProblem.dataset.get_entity", "geoimc_algorithm.IMCProblem._loadTarget", "pymanopt.manifolds.Product", "pymanopt.manifolds.Stiefel", "pymanopt.manifolds.SymmetricPositiveDefinite", "pymanopt.manifolds.Stiefel"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.DataPtr.get_entity", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._loadTarget"], ["def", "__init__", "(", "self", ",", "dataPtr", ",", "lambda1", "=", "1e-2", ",", "rank", "=", "10", ")", ":", "\n", "        ", "\"\"\"Initialize parameters\n\n        Args:\n            dataPtr (DataPtr): An object of which contains X, Z side features and target matrix Y.\n            lambda1 (uint): Regularizer.\n            rank (uint): rank of the U, B, V parametrization.\n        \"\"\"", "\n", "\n", "self", ".", "dataset", "=", "dataPtr", "\n", "self", ".", "X", "=", "self", ".", "dataset", ".", "get_entity", "(", "\"row\"", ")", "\n", "self", ".", "Z", "=", "self", ".", "dataset", ".", "get_entity", "(", "\"col\"", ")", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "_loadTarget", "(", ")", "\n", "self", ".", "shape", "=", "(", "self", ".", "X", ".", "shape", "[", "0", "]", ",", "self", ".", "Z", ".", "shape", "[", "0", "]", ")", "\n", "self", ".", "lambda1", "=", "lambda1", "\n", "self", ".", "nSamples", "=", "self", ".", "Y", ".", "data", ".", "shape", "[", "0", "]", "\n", "\n", "self", ".", "W", "=", "None", "\n", "self", ".", "optima_reached", "=", "False", "\n", "self", ".", "manifold", "=", "Product", "(", "\n", "[", "\n", "Stiefel", "(", "self", ".", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "rank", ")", ",", "\n", "SymmetricPositiveDefinite", "(", "self", ".", "rank", ")", ",", "\n", "Stiefel", "(", "self", ".", "Z", ".", "shape", "[", "1", "]", ",", "self", ".", "rank", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._loadTarget": [[51, 56], ["geoimc_algorithm.IMCProblem.dataset.get_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data"], ["", "def", "_loadTarget", "(", "\n", "self", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Loads target matrix from the dataset pointer.\"\"\"", "\n", "self", ".", "Y", "=", "self", ".", "dataset", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._computeLoss_csrmatrix": [[57, 70], ["numba.njit", "numba.prange", "numba.prange", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "njit", "(", "nogil", "=", "True", ",", "parallel", "=", "True", ")", "\n", "def", "_computeLoss_csrmatrix", "(", "a", ",", "b", ",", "cd", ",", "indices", ",", "indptr", ",", "residual_global", ")", ":", "\n", "        ", "\"\"\"computes residual_global = a*b - cd at given indices in csr_matrix format\"\"\"", "\n", "N", "=", "a", ".", "shape", "[", "0", "]", "\n", "M", "=", "a", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "prange", "(", "N", ")", ":", "\n", "            ", "for", "j", "in", "prange", "(", "indptr", "[", "i", "]", ",", "indptr", "[", "i", "+", "1", "]", ")", ":", "\n", "                ", "num", "=", "0.0", "\n", "for", "k", "in", "range", "(", "M", ")", ":", "\n", "                    ", "num", "+=", "a", "[", "i", ",", "k", "]", "*", "b", "[", "k", ",", "indices", "[", "j", "]", "]", "\n", "", "residual_global", "[", "j", "]", "=", "num", "-", "cd", "[", "j", "]", "\n", "", "", "return", "residual_global", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._cost": [[71, 96], ["geoimc_algorithm.IMCProblem._computeLoss_csrmatrix", "numpy.sum", "geoimc_algorithm.IMCProblem.X.dot", "V.T.dot", "U.dot", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._computeLoss_csrmatrix"], ["", "def", "_cost", "(", "self", ",", "params", ",", "residual_global", ")", ":", "\n", "        ", "\"\"\"Compute the cost of GeoIMC optimization problem\n\n        Args:\n            params (Iterator): An iterator containing the manifold point at which\n            the cost needs to be evaluated.\n            residual_global (csr_matrix): Residual matrix.\n        \"\"\"", "\n", "U", "=", "params", "[", "0", "]", "\n", "B", "=", "params", "[", "1", "]", "\n", "V", "=", "params", "[", "2", "]", "\n", "\n", "regularizer", "=", "0.5", "*", "self", ".", "lambda1", "*", "np", ".", "sum", "(", "B", "**", "2", ")", "\n", "\n", "IMCProblem", ".", "_computeLoss_csrmatrix", "(", "\n", "self", ".", "X", ".", "dot", "(", "U", ".", "dot", "(", "B", ")", ")", ",", "\n", "V", ".", "T", ".", "dot", "(", "self", ".", "Z", ".", "T", ")", ",", "\n", "self", ".", "Y", ".", "data", ",", "\n", "self", ".", "Y", ".", "indices", ",", "\n", "self", ".", "Y", ".", "indptr", ",", "\n", "residual_global", ",", "\n", ")", "\n", "cost", "=", "0.5", "*", "np", ".", "sum", "(", "(", "residual_global", ")", "**", "2", ")", "/", "self", ".", "nSamples", "+", "regularizer", "\n", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._egrad": [[97, 132], ["scipy.sparse.csr_matrix", "numpy.dot", "scipy.sparse.csr_matrix.dot", "numpy.dot", "numpy.dot", "geoimc_algorithm.IMCProblem.Z.dot", "scipy.sparse.csr_matrix.dot", "scipy.sparse.csr_matrix.dot", "V.dot", "geoimc_algorithm.IMCProblem.X.dot", "geoimc_algorithm.IMCProblem.Z.dot", "geoimc_algorithm.IMCProblem.X.dot", "U.dot"], "methods", ["None"], ["", "def", "_egrad", "(", "self", ",", "params", ",", "residual_global", ")", ":", "\n", "        ", "\"\"\"Computes the euclidean gradient\n\n        Args:\n            params (Iterator): An iterator containing the manifold point at which\n            the cost needs to be evaluated.\n            residual_global (csr_matrix): Residual matrix.\n        \"\"\"", "\n", "U", "=", "params", "[", "0", "]", "\n", "B", "=", "params", "[", "1", "]", "\n", "V", "=", "params", "[", "2", "]", "\n", "\n", "residual_global_csr", "=", "csr_matrix", "(", "\n", "(", "residual_global", ",", "self", ".", "Y", ".", "indices", ",", "self", ".", "Y", ".", "indptr", ")", ",", "\n", "shape", "=", "self", ".", "shape", ",", "\n", ")", "\n", "\n", "gradU", "=", "(", "\n", "np", ".", "dot", "(", "self", ".", "X", ".", "T", ",", "residual_global_csr", ".", "dot", "(", "self", ".", "Z", ".", "dot", "(", "V", ".", "dot", "(", "B", ".", "T", ")", ")", ")", ")", "\n", "/", "self", ".", "nSamples", "\n", ")", "\n", "\n", "gradB", "=", "(", "\n", "np", ".", "dot", "(", "(", "self", ".", "X", ".", "dot", "(", "U", ")", ")", ".", "T", ",", "residual_global_csr", ".", "dot", "(", "self", ".", "Z", ".", "dot", "(", "V", ")", ")", ")", "\n", "/", "self", ".", "nSamples", "\n", "+", "self", ".", "lambda1", "*", "B", "\n", ")", "\n", "gradB_sym", "=", "(", "gradB", "+", "gradB", ".", "T", ")", "/", "2", "\n", "\n", "gradV", "=", "(", "\n", "np", ".", "dot", "(", "(", "self", ".", "X", ".", "dot", "(", "U", ".", "dot", "(", "B", ")", ")", ")", ".", "T", ",", "residual_global_csr", ".", "dot", "(", "self", ".", "Z", ")", ")", ".", "T", "\n", "/", "self", ".", "nSamples", "\n", ")", "\n", "\n", "return", "[", "gradU", ",", "gradB_sym", ",", "gradV", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem.solve": [[133, 148], ["geoimc_algorithm.IMCProblem._optimize"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._optimize"], ["", "def", "solve", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"Main solver of the IMC model\n\n        Args:\n            max_opt_time (uint): Maximum time (in secs) for optimization\n            max_opt_iter (uint): Maximum iterations for optimization\n            verbosity (uint): The level of verbosity for Pymanopt logs\n        \"\"\"", "\n", "if", "self", ".", "optima_reached", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "_optimize", "(", "*", "args", ")", "\n", "\n", "self", ".", "optima_reached", "=", "True", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem._optimize": [[149, 171], ["numpy.zeros", "pymanopt.solvers.ConjugateGradient", "pymanopt.Problem", "pymanopt.solvers.ConjugateGradient.solve", "geoimc_algorithm.IMCProblem._cost", "pymanopt.solvers.linesearch.LineSearchBackTracking", "geoimc_algorithm.IMCProblem._cost", "geoimc_algorithm.IMCProblem._egrad"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._cost", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._cost", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._egrad"], ["", "def", "_optimize", "(", "self", ",", "max_opt_time", ",", "max_opt_iter", ",", "verbosity", ")", ":", "\n", "        ", "\"\"\"Optimize the GeoIMC optimization problem\n\n        Args: The args of `solve`\n        \"\"\"", "\n", "residual_global", "=", "np", ".", "zeros", "(", "self", ".", "Y", ".", "data", ".", "shape", ")", "\n", "\n", "solver", "=", "ConjugateGradient", "(", "\n", "maxtime", "=", "max_opt_time", ",", "\n", "maxiter", "=", "max_opt_iter", ",", "\n", "linesearch", "=", "LineSearchBackTracking", "(", ")", ",", "\n", ")", "\n", "prb", "=", "Problem", "(", "\n", "manifold", "=", "self", ".", "manifold", ",", "\n", "cost", "=", "lambda", "x", ":", "self", ".", "_cost", "(", "x", ",", "residual_global", ")", ",", "\n", "egrad", "=", "lambda", "z", ":", "self", ".", "_egrad", "(", "z", ",", "residual_global", ")", ",", "\n", "verbosity", "=", "verbosity", ",", "\n", ")", "\n", "solution", "=", "solver", ".", "solve", "(", "prb", ",", "x", "=", "self", ".", "W", ")", "\n", "self", ".", "W", "=", "[", "solution", "[", "0", "]", ",", "solution", "[", "1", "]", ",", "solution", "[", "2", "]", "]", "\n", "\n", "return", "self", ".", "_cost", "(", "self", ".", "W", ",", "residual_global", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_algorithm.IMCProblem.reset": [[172, 177], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the model.\"\"\"", "\n", "self", ".", "optima_reached", "=", "False", "\n", "self", ".", "W", "=", "None", "\n", "return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.length_normalize": [[8, 20], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["def", "length_normalize", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Length normalize the matrix\n\n    Args:\n        matrix (np.ndarray): Input matrix that needs to be normalized\n\n    Returns:\n        Normalized matrix\n    \"\"\"", "\n", "norms", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "matrix", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "norms", "[", "norms", "==", "0", "]", "=", "1", "\n", "return", "matrix", "/", "norms", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.mean_center": [[22, 30], ["numpy.mean"], "function", ["None"], ["", "def", "mean_center", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Performs mean centering across axis 0\n\n    Args:\n        matrix (np.ndarray): Input matrix that needs to be mean centered\n    \"\"\"", "\n", "avg", "=", "np", ".", "mean", "(", "matrix", ",", "axis", "=", "0", ")", "\n", "matrix", "-=", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_utils.reduce_dims": [[32, 43], ["sklearn.decomposition.PCA", "sklearn.decomposition.PCA.fit", "sklearn.decomposition.PCA.transform"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform"], ["", "def", "reduce_dims", "(", "matrix", ",", "target_dim", ")", ":", "\n", "    ", "\"\"\"Reduce dimensionality of the data using PCA.\n\n    Args:\n        matrix (np.ndarray): Matrix of the form (n_sampes, n_features)\n        target_dim (uint): Dimension to which n_features should be reduced to.\n\n    \"\"\"", "\n", "model", "=", "PCA", "(", "n_components", "=", "target_dim", ")", "\n", "model", ".", "fit", "(", "matrix", ")", "\n", "return", "model", ".", "transform", "(", "matrix", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.__init__": [[27, 63], ["tempfile.TemporaryDirectory", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "vw.VW.parse_train_params", "vw.VW.parse_test_params", "kwargs.values"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_train_params", "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_test_params", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["def", "__init__", "(", "\n", "self", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize model parameters\n\n        Args:\n            col_user (str): user column name\n            col_item (str): item column name\n            col_rating (str): rating column name\n            col_timestamp (str): timestamp column name\n            col_prediction (str): prediction column name\n        \"\"\"", "\n", "\n", "# create temporary files", "\n", "self", ".", "tempdir", "=", "TemporaryDirectory", "(", ")", "\n", "self", ".", "train_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tempdir", ".", "name", ",", "\"train.dat\"", ")", "\n", "self", ".", "test_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tempdir", ".", "name", ",", "\"test.dat\"", ")", "\n", "self", ".", "model_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tempdir", ".", "name", ",", "\"vw.model\"", ")", "\n", "self", ".", "prediction_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tempdir", ".", "name", ",", "\"prediction.dat\"", ")", "\n", "\n", "# set DataFrame columns", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_timestamp", "=", "col_timestamp", "\n", "self", ".", "col_prediction", "=", "col_prediction", "\n", "\n", "self", ".", "logistic", "=", "\"logistic\"", "in", "kwargs", ".", "values", "(", ")", "\n", "self", ".", "train_cmd", "=", "self", ".", "parse_train_params", "(", "params", "=", "kwargs", ")", "\n", "self", ".", "test_cmd", "=", "self", ".", "parse_test_params", "(", "params", "=", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_cmd": [[64, 88], ["params.items", "cmd.append", "cmd.append", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "@", "staticmethod", "\n", "def", "to_vw_cmd", "(", "params", ")", ":", "\n", "        ", "\"\"\"Convert dictionary of parameters to vw command line.\n\n        Args:\n            params (dict): key = parameter, value = value (use True if parameter is just a flag)\n\n        Returns:\n            list[str]: vw command line parameters as list of strings\n        \"\"\"", "\n", "\n", "cmd", "=", "[", "\"vw\"", "]", "\n", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "False", ":", "\n", "# don't add parameters with a value == False", "\n", "                ", "continue", "\n", "\n", "# add the correct hyphen to the parameter", "\n", "", "cmd", ".", "append", "(", "f\"-{k}\"", "if", "len", "(", "k", ")", "==", "1", "else", "f\"--{k}\"", ")", "\n", "if", "v", "is", "not", "True", ":", "\n", "# don't add an argument for parameters with value == True", "\n", "                ", "cmd", ".", "append", "(", "\"{}\"", ".", "format", "(", "v", ")", ")", "\n", "\n", "", "", "return", "cmd", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_train_params": [[89, 127], ["params.copy", "params.copy.update", "vw.VW.to_vw_cmd", "params.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_cmd"], ["", "def", "parse_train_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"Parse input hyper-parameters to build vw train commands\n\n        Args:\n            params (dict): key = parameter, value = value (use True if parameter is just a flag)\n\n        Returns:\n            list[str]: vw command line parameters as list of strings\n        \"\"\"", "\n", "\n", "# make a copy of the original hyper parameters", "\n", "train_params", "=", "params", ".", "copy", "(", ")", "\n", "\n", "# remove options that are handled internally, not supported, or test only parameters", "\n", "invalid", "=", "[", "\n", "\"data\"", ",", "\n", "\"final_regressor\"", ",", "\n", "\"invert_hash\"", ",", "\n", "\"readable_model\"", ",", "\n", "\"t\"", ",", "\n", "\"testonly\"", ",", "\n", "\"i\"", ",", "\n", "\"initial_regressor\"", ",", "\n", "\"link\"", ",", "\n", "]", "\n", "\n", "for", "option", "in", "invalid", ":", "\n", "            ", "if", "option", "in", "train_params", ":", "\n", "                ", "del", "train_params", "[", "option", "]", "\n", "\n", "", "", "train_params", ".", "update", "(", "\n", "{", "\n", "\"d\"", ":", "self", ".", "train_file", ",", "\n", "\"f\"", ":", "self", ".", "model_file", ",", "\n", "\"quiet\"", ":", "params", ".", "get", "(", "\"quiet\"", ",", "True", ")", ",", "\n", "}", "\n", ")", "\n", "return", "self", ".", "to_vw_cmd", "(", "params", "=", "train_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.parse_test_params": [[128, 188], ["params.copy", "params.copy.update", "vw.VW.to_vw_cmd", "params.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_cmd"], ["", "def", "parse_test_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"Parse input hyper-parameters to build vw test commands\n\n        Args:\n            params (dict): key = parameter, value = value (use True if parameter is just a flag)\n\n        Returns:\n            list[str]: vw command line parameters as list of strings\n        \"\"\"", "\n", "\n", "# make a copy of the original hyper parameters", "\n", "test_params", "=", "params", ".", "copy", "(", ")", "\n", "\n", "# remove options that are handled internally, ot supported or train only parameters", "\n", "invalid", "=", "[", "\n", "\"data\"", ",", "\n", "\"f\"", ",", "\n", "\"final_regressor\"", ",", "\n", "\"initial_regressor\"", ",", "\n", "\"test_only\"", ",", "\n", "\"invert_hash\"", ",", "\n", "\"readable_model\"", ",", "\n", "\"b\"", ",", "\n", "\"bit_precision\"", ",", "\n", "\"holdout_off\"", ",", "\n", "\"c\"", ",", "\n", "\"cache\"", ",", "\n", "\"k\"", ",", "\n", "\"kill_cache\"", ",", "\n", "\"l\"", ",", "\n", "\"learning_rate\"", ",", "\n", "\"l1\"", ",", "\n", "\"l2\"", ",", "\n", "\"initial_t\"", ",", "\n", "\"power_t\"", ",", "\n", "\"decay_learning_rate\"", ",", "\n", "\"q\"", ",", "\n", "\"quadratic\"", ",", "\n", "\"cubic\"", ",", "\n", "\"i\"", ",", "\n", "\"interactions\"", ",", "\n", "\"rank\"", ",", "\n", "\"lrq\"", ",", "\n", "\"lrqdropout\"", ",", "\n", "\"oaa\"", ",", "\n", "]", "\n", "for", "option", "in", "invalid", ":", "\n", "            ", "if", "option", "in", "test_params", ":", "\n", "                ", "del", "test_params", "[", "option", "]", "\n", "\n", "", "", "test_params", ".", "update", "(", "\n", "{", "\n", "\"d\"", ":", "self", ".", "test_file", ",", "\n", "\"i\"", ":", "self", ".", "model_file", ",", "\n", "\"quiet\"", ":", "params", ".", "get", "(", "\"quiet\"", ",", "True", ")", ",", "\n", "\"p\"", ":", "self", ".", "prediction_file", ",", "\n", "\"t\"", ":", "True", ",", "\n", "}", "\n", ")", "\n", "return", "self", ".", "to_vw_cmd", "(", "params", "=", "test_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_file": [[189, 226], ["open", "df[].reset_index", "df[].reset_index.iterrows", "tmp[].astype", "f.write", "tmp[].max", "tmp[].apply", "round"], "methods", ["None"], ["", "def", "to_vw_file", "(", "self", ",", "df", ",", "train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Convert Pandas DataFrame to vw input format file\n\n        Args:\n            df (pandas.DataFrame): input DataFrame\n            train (bool): flag for train mode (or test mode if False)\n        \"\"\"", "\n", "\n", "output", "=", "self", ".", "train_file", "if", "train", "else", "self", ".", "test_file", "\n", "with", "open", "(", "output", ",", "\"w\"", ")", "as", "f", ":", "\n", "# extract columns and create a new dataframe", "\n", "            ", "tmp", "=", "df", "[", "[", "self", ".", "col_rating", ",", "self", ".", "col_user", ",", "self", ".", "col_item", "]", "]", ".", "reset_index", "(", ")", "\n", "\n", "if", "train", ":", "\n", "# we need to reset the rating type to an integer to simplify the vw formatting", "\n", "                ", "tmp", "[", "self", ".", "col_rating", "]", "=", "tmp", "[", "self", ".", "col_rating", "]", ".", "astype", "(", "\"int64\"", ")", "\n", "\n", "# convert rating to binary value", "\n", "if", "self", ".", "logistic", ":", "\n", "                    ", "max_value", "=", "tmp", "[", "self", ".", "col_rating", "]", ".", "max", "(", ")", "\n", "tmp", "[", "self", ".", "col_rating", "]", "=", "tmp", "[", "self", ".", "col_rating", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "2", "*", "round", "(", "x", "/", "max_value", ")", "-", "1", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "tmp", "[", "self", ".", "col_rating", "]", "=", "\"\"", "\n", "\n", "# convert each row to VW input format (https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format)", "\n", "# [label] [tag]|[user namespace] [user id feature] |[item namespace] [movie id feature]", "\n", "# label is the true rating, tag is a unique id for the example just used to link predictions to truth", "\n", "# user and item namespaces separate features to support interaction features through command line options", "\n", "", "for", "_", ",", "row", "in", "tmp", ".", "iterrows", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "\n", "\"{rating} {index}|user {userID} |item {itemID}\\n\"", ".", "format", "(", "\n", "rating", "=", "row", "[", "self", ".", "col_rating", "]", ",", "\n", "index", "=", "row", "[", "\"index\"", "]", ",", "\n", "userID", "=", "row", "[", "self", ".", "col_user", "]", ",", "\n", "itemID", "=", "row", "[", "self", ".", "col_item", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.fit": [[229, 241], ["vw.VW.to_vw_file", "subprocess.run"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_file"], ["", "", "", "def", "fit", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Train model\n\n        Args:\n            df (pandas.DataFrame): input training data\n        \"\"\"", "\n", "\n", "# write dataframe to disk in vw format", "\n", "self", ".", "to_vw_file", "(", "df", "=", "df", ")", "\n", "\n", "# train model", "\n", "run", "(", "self", ".", "train_cmd", ",", "check", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.predict": [[242, 262], ["vw.VW.to_vw_file", "subprocess.run", "df.join", "pandas.read_csv"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.to_vw_file"], ["", "def", "predict", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Predict results\n\n        Args:\n            df (pandas.DataFrame): input test data\n        \"\"\"", "\n", "\n", "# write dataframe to disk in vw format", "\n", "self", ".", "to_vw_file", "(", "df", "=", "df", ",", "train", "=", "False", ")", "\n", "\n", "# generate predictions", "\n", "run", "(", "self", ".", "test_cmd", ",", "check", "=", "True", ")", "\n", "\n", "# read predictions", "\n", "return", "df", ".", "join", "(", "\n", "pd", ".", "read_csv", "(", "\n", "self", ".", "prediction_file", ",", "\n", "delim_whitespace", "=", "True", ",", "\n", "names", "=", "[", "self", ".", "col_prediction", "]", ",", "\n", "index_col", "=", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vowpal_wabbit.vw.VW.__del__": [[265, 267], ["vw.VW.tempdir.cleanup"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "tempdir", ".", "cleanup", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.__init__": [[78, 98], ["multiprocessing.Queue", "range", "sampler.WarpSampler.processors.append", "sampler.WarpSampler.processors[].start", "multiprocessing.Process", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start"], ["def", "__init__", "(", "self", ",", "User", ",", "usernum", ",", "itemnum", ",", "batch_size", "=", "64", ",", "maxlen", "=", "10", ",", "n_workers", "=", "1", ")", ":", "\n", "        ", "self", ".", "result_queue", "=", "Queue", "(", "maxsize", "=", "n_workers", "*", "10", ")", "\n", "self", ".", "processors", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_workers", ")", ":", "\n", "            ", "self", ".", "processors", ".", "append", "(", "\n", "Process", "(", "\n", "target", "=", "sample_function", ",", "\n", "args", "=", "(", "\n", "User", ",", "\n", "usernum", ",", "\n", "itemnum", ",", "\n", "batch_size", ",", "\n", "maxlen", ",", "\n", "self", ".", "result_queue", ",", "\n", "np", ".", "random", ".", "randint", "(", "2e9", ")", ",", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "self", ".", "processors", "[", "-", "1", "]", ".", "daemon", "=", "True", "\n", "self", ".", "processors", "[", "-", "1", "]", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.next_batch": [[99, 101], ["sampler.WarpSampler.result_queue.get"], "methods", ["None"], ["", "", "def", "next_batch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "result_queue", ".", "get", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close": [[102, 106], ["p.terminate", "p.join"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "processors", ":", "\n", "            ", "p", ".", "terminate", "(", ")", "\n", "p", ".", "join", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.random_neq": [[9, 14], ["numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["def", "random_neq", "(", "left", ",", "right", ",", "s", ")", ":", "\n", "    ", "t", "=", "np", ".", "random", ".", "randint", "(", "left", ",", "right", ")", "\n", "while", "t", "in", "s", ":", "\n", "        ", "t", "=", "np", ".", "random", ".", "randint", "(", "left", ",", "right", ")", "\n", "", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.sample_function": [[16, 64], ["numpy.random.seed", "numpy.random.randint", "numpy.zeros", "numpy.zeros", "numpy.zeros", "set", "reversed", "range", "result_queue.put", "len", "numpy.random.randint", "one_batch.append", "zip", "sampler.random_neq", "sampler.sample_function.sample"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.random_neq", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "def", "sample_function", "(", "\n", "user_train", ",", "usernum", ",", "itemnum", ",", "batch_size", ",", "maxlen", ",", "result_queue", ",", "seed", "\n", ")", ":", "\n", "    ", "\"\"\"Batch sampler that creates a sequence of negative items based on the\n    original sequence of items (positive) that the user has interacted with.\n\n    Args:\n        user_train (dict): dictionary of training exampled for each user\n        usernum (int): number of users\n        itemnum (int): number of items\n        batch_size (int): batch size\n        maxlen (int): maximum input sequence length\n        result_queue (multiprocessing.Queue): queue for storing sample results\n        seed (int): seed for random generator\n    \"\"\"", "\n", "\n", "def", "sample", "(", ")", ":", "\n", "\n", "        ", "user", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "usernum", "+", "1", ")", "\n", "while", "len", "(", "user_train", "[", "user", "]", ")", "<=", "1", ":", "\n", "            ", "user", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "usernum", "+", "1", ")", "\n", "\n", "", "seq", "=", "np", ".", "zeros", "(", "[", "maxlen", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "pos", "=", "np", ".", "zeros", "(", "[", "maxlen", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "neg", "=", "np", ".", "zeros", "(", "[", "maxlen", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "nxt", "=", "user_train", "[", "user", "]", "[", "-", "1", "]", "\n", "idx", "=", "maxlen", "-", "1", "\n", "\n", "ts", "=", "set", "(", "user_train", "[", "user", "]", ")", "\n", "for", "i", "in", "reversed", "(", "user_train", "[", "user", "]", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "seq", "[", "idx", "]", "=", "i", "\n", "pos", "[", "idx", "]", "=", "nxt", "\n", "if", "nxt", "!=", "0", ":", "\n", "                ", "neg", "[", "idx", "]", "=", "random_neq", "(", "1", ",", "itemnum", "+", "1", ",", "ts", ")", "\n", "", "nxt", "=", "i", "\n", "idx", "-=", "1", "\n", "if", "idx", "==", "-", "1", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "(", "user", ",", "seq", ",", "pos", ",", "neg", ")", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "while", "True", ":", "\n", "        ", "one_batch", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "one_batch", ".", "append", "(", "sample", "(", ")", ")", "\n", "\n", "", "result_queue", ".", "put", "(", "zip", "(", "*", "one_batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.ssept.SSEPT.__init__": [[19, 75], ["recommenders.models.sasrec.model.SASREC.__init__", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "recommenders.models.sasrec.model.Encoder", "tensorflow.keras.layers.Masking", "recommenders.models.sasrec.model.LayerNormalization", "tensorflow.keras.regularizers.L2", "tensorflow.keras.regularizers.L2"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Model initialization.\n\n        Args:\n            item_num (int): Number of items in the dataset.\n            seq_max_len (int): Maximum number of items in user history.\n            num_blocks (int): Number of Transformer blocks to be used.\n            embedding_dim (int): Item embedding dimension.\n            attention_dim (int): Transformer attention dimension.\n            conv_dims (list): List of the dimensions of the Feedforward layer.\n            dropout_rate (float): Dropout rate.\n            l2_reg (float): Coefficient of the L2 regularization.\n            num_neg_test (int): Number of negative examples used in testing.\n            user_num (int): Number of users in the dataset.\n            user_embedding_dim (int): User embedding dimension.\n            item_embedding_dim (int): Item embedding dimension.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "user_num", "=", "kwargs", ".", "get", "(", "\"user_num\"", ",", "None", ")", "# New", "\n", "self", ".", "conv_dims", "=", "kwargs", ".", "get", "(", "\"conv_dims\"", ",", "[", "200", ",", "200", "]", ")", "# modified", "\n", "self", ".", "user_embedding_dim", "=", "kwargs", ".", "get", "(", "\n", "\"user_embedding_dim\"", ",", "self", ".", "embedding_dim", "\n", ")", "# extra", "\n", "self", ".", "item_embedding_dim", "=", "kwargs", ".", "get", "(", "\"item_embedding_dim\"", ",", "self", ".", "embedding_dim", ")", "\n", "self", ".", "hidden_units", "=", "self", ".", "item_embedding_dim", "+", "self", ".", "user_embedding_dim", "\n", "\n", "# New, user embedding", "\n", "self", ".", "user_embedding_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "input_dim", "=", "self", ".", "user_num", "+", "1", ",", "\n", "output_dim", "=", "self", ".", "user_embedding_dim", ",", "\n", "name", "=", "\"user_embeddings\"", ",", "\n", "mask_zero", "=", "True", ",", "\n", "input_length", "=", "1", ",", "\n", "embeddings_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "L2", "(", "self", ".", "l2_reg", ")", ",", "\n", ")", "\n", "self", ".", "positional_embedding_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "self", ".", "seq_max_len", ",", "\n", "self", ".", "user_embedding_dim", "+", "self", ".", "item_embedding_dim", ",", "# difference", "\n", "name", "=", "\"positional_embeddings\"", ",", "\n", "mask_zero", "=", "False", ",", "\n", "embeddings_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "L2", "(", "self", ".", "l2_reg", ")", ",", "\n", ")", "\n", "self", ".", "dropout_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "self", ".", "num_blocks", ",", "\n", "self", ".", "seq_max_len", ",", "\n", "self", ".", "hidden_units", ",", "\n", "self", ".", "hidden_units", ",", "\n", "self", ".", "attention_num_heads", ",", "\n", "self", ".", "conv_dims", ",", "\n", "self", ".", "dropout_rate", ",", "\n", ")", "\n", "self", ".", "mask_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Masking", "(", "mask_value", "=", "0", ")", "\n", "self", ".", "layer_normalization", "=", "LayerNormalization", "(", "\n", "self", ".", "seq_max_len", ",", "self", ".", "hidden_units", ",", "1e-08", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.ssept.SSEPT.call": [[77, 168], ["tensorflow.expand_dims", "ssept.SSEPT.embedding", "ssept.SSEPT.user_embedding_layer", "tensorflow.tile", "tensorflow.reshape", "ssept.SSEPT.dropout_layer", "ssept.SSEPT.encoder", "ssept.SSEPT.layer_normalization", "ssept.SSEPT.mask_layer", "ssept.SSEPT.mask_layer", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "ssept.SSEPT.item_embedding_layer", "ssept.SSEPT.item_embedding_layer", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.cast", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.not_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.embedding"], ["", "def", "call", "(", "self", ",", "x", ",", "training", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n            training (tf.Tensor): Training tensor.\n\n        Returns:\n            tf.Tensor, tf.Tensor, tf.Tensor:\n            - Logits of the positive examples.\n            - Logits of the negative examples.\n            - Mask for nonzero targets\n        \"\"\"", "\n", "\n", "users", "=", "x", "[", "\"users\"", "]", "\n", "input_seq", "=", "x", "[", "\"input_seq\"", "]", "\n", "pos", "=", "x", "[", "\"positive\"", "]", "\n", "neg", "=", "x", "[", "\"negative\"", "]", "\n", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_seq", ",", "0", ")", ",", "tf", ".", "float32", ")", ",", "-", "1", ")", "\n", "seq_embeddings", ",", "positional_embeddings", "=", "self", ".", "embedding", "(", "input_seq", ")", "\n", "\n", "# User Encoding", "\n", "# u0_latent = self.user_embedding_layer(users[0])", "\n", "# u0_latent = u0_latent * (self.embedding_dim ** 0.5)", "\n", "u_latent", "=", "self", ".", "user_embedding_layer", "(", "users", ")", "\n", "u_latent", "=", "u_latent", "*", "(", "self", ".", "user_embedding_dim", "**", "0.5", ")", "# (b, 1, h)", "\n", "# return users", "\n", "\n", "# replicate the user embedding for all the items", "\n", "u_latent", "=", "tf", ".", "tile", "(", "u_latent", ",", "[", "1", ",", "tf", ".", "shape", "(", "input_seq", ")", "[", "1", "]", ",", "1", "]", ")", "# (b, s, h)", "\n", "\n", "seq_embeddings", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "concat", "(", "[", "seq_embeddings", ",", "u_latent", "]", ",", "2", ")", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", ",", "-", "1", ",", "self", ".", "hidden_units", "]", ",", "\n", ")", "\n", "seq_embeddings", "+=", "positional_embeddings", "\n", "\n", "# dropout", "\n", "seq_embeddings", "=", "self", ".", "dropout_layer", "(", "seq_embeddings", ",", "training", "=", "training", ")", "\n", "\n", "# masking", "\n", "seq_embeddings", "*=", "mask", "\n", "\n", "# --- ATTENTION BLOCKS ---", "\n", "seq_attention", "=", "seq_embeddings", "# (b, s, h1 + h2)", "\n", "\n", "seq_attention", "=", "self", ".", "encoder", "(", "seq_attention", ",", "training", ",", "mask", ")", "\n", "seq_attention", "=", "self", ".", "layer_normalization", "(", "seq_attention", ")", "# (b, s, h1+h2)", "\n", "\n", "# --- PREDICTION LAYER ---", "\n", "# user's sequence embedding", "\n", "pos", "=", "self", ".", "mask_layer", "(", "pos", ")", "\n", "neg", "=", "self", ".", "mask_layer", "(", "neg", ")", "\n", "\n", "user_emb", "=", "tf", ".", "reshape", "(", "\n", "u_latent", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", ",", "self", ".", "user_embedding_dim", "]", ",", "\n", ")", "\n", "pos", "=", "tf", ".", "reshape", "(", "pos", ",", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ")", "\n", "neg", "=", "tf", ".", "reshape", "(", "neg", ",", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ")", "\n", "pos_emb", "=", "self", ".", "item_embedding_layer", "(", "pos", ")", "\n", "neg_emb", "=", "self", ".", "item_embedding_layer", "(", "neg", ")", "\n", "\n", "# Add user embeddings", "\n", "pos_emb", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "[", "pos_emb", ",", "user_emb", "]", ",", "1", ")", ",", "[", "-", "1", ",", "self", ".", "hidden_units", "]", ")", "\n", "neg_emb", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "[", "neg_emb", ",", "user_emb", "]", ",", "1", ")", ",", "[", "-", "1", ",", "self", ".", "hidden_units", "]", ")", "\n", "\n", "seq_emb", "=", "tf", ".", "reshape", "(", "\n", "seq_attention", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", ",", "self", ".", "hidden_units", "]", ",", "\n", ")", "# (b*s, d)", "\n", "\n", "pos_logits", "=", "tf", ".", "reduce_sum", "(", "pos_emb", "*", "seq_emb", ",", "-", "1", ")", "\n", "neg_logits", "=", "tf", ".", "reduce_sum", "(", "neg_emb", "*", "seq_emb", ",", "-", "1", ")", "\n", "\n", "pos_logits", "=", "tf", ".", "expand_dims", "(", "pos_logits", ",", "axis", "=", "-", "1", ")", "# (bs, 1)", "\n", "# pos_prob = tf.keras.layers.Dense(1, activation='sigmoid')(pos_logits)  # (bs, 1)", "\n", "\n", "neg_logits", "=", "tf", ".", "expand_dims", "(", "neg_logits", ",", "axis", "=", "-", "1", ")", "# (bs, 1)", "\n", "# neg_prob = tf.keras.layers.Dense(1, activation='sigmoid')(neg_logits)  # (bs, 1)", "\n", "\n", "# output = tf.concat([pos_logits, neg_logits], axis=0)", "\n", "\n", "# masking for loss calculation", "\n", "istarget", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "pos", ",", "0", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ",", "\n", ")", "\n", "\n", "return", "pos_logits", ",", "neg_logits", ",", "istarget", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.ssept.SSEPT.predict": [[169, 221], ["tensorflow.expand_dims", "ssept.SSEPT.embedding", "ssept.SSEPT.user_embedding_layer", "tensorflow.squeeze", "tensorflow.tile", "ssept.SSEPT.user_embedding_layer", "tensorflow.tile", "tensorflow.reshape", "ssept.SSEPT.encoder", "ssept.SSEPT.layer_normalization", "tensorflow.reshape", "ssept.SSEPT.item_embedding_layer", "tensorflow.squeeze", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.cast", "tensorflow.concat", "tensorflow.concat", "tensorflow.not_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.embedding"], ["", "def", "predict", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Model prediction for candidate (negative) items\n\n        \"\"\"", "\n", "training", "=", "False", "\n", "user", "=", "inputs", "[", "\"user\"", "]", "\n", "input_seq", "=", "inputs", "[", "\"input_seq\"", "]", "\n", "candidate", "=", "inputs", "[", "\"candidate\"", "]", "\n", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_seq", ",", "0", ")", ",", "tf", ".", "float32", ")", ",", "-", "1", ")", "\n", "seq_embeddings", ",", "positional_embeddings", "=", "self", ".", "embedding", "(", "input_seq", ")", "# (1, s, h)", "\n", "\n", "u0_latent", "=", "self", ".", "user_embedding_layer", "(", "user", ")", "\n", "u0_latent", "=", "u0_latent", "*", "(", "self", ".", "user_embedding_dim", "**", "0.5", ")", "# (1, 1, h)", "\n", "u0_latent", "=", "tf", ".", "squeeze", "(", "u0_latent", ",", "axis", "=", "0", ")", "# (1, h)", "\n", "test_user_emb", "=", "tf", ".", "tile", "(", "u0_latent", ",", "[", "1", "+", "self", ".", "num_neg_test", ",", "1", "]", ")", "# (101, h)", "\n", "\n", "u_latent", "=", "self", ".", "user_embedding_layer", "(", "user", ")", "\n", "u_latent", "=", "u_latent", "*", "(", "self", ".", "user_embedding_dim", "**", "0.5", ")", "# (b, 1, h)", "\n", "u_latent", "=", "tf", ".", "tile", "(", "u_latent", ",", "[", "1", ",", "tf", ".", "shape", "(", "input_seq", ")", "[", "1", "]", ",", "1", "]", ")", "# (b, s, h)", "\n", "\n", "seq_embeddings", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "concat", "(", "[", "seq_embeddings", ",", "u_latent", "]", ",", "2", ")", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", ",", "-", "1", ",", "self", ".", "hidden_units", "]", ",", "\n", ")", "\n", "seq_embeddings", "+=", "positional_embeddings", "# (b, s, h1 + h2)", "\n", "\n", "seq_embeddings", "*=", "mask", "\n", "seq_attention", "=", "seq_embeddings", "\n", "seq_attention", "=", "self", ".", "encoder", "(", "seq_attention", ",", "training", ",", "mask", ")", "\n", "seq_attention", "=", "self", ".", "layer_normalization", "(", "seq_attention", ")", "# (b, s, h1+h2)", "\n", "seq_emb", "=", "tf", ".", "reshape", "(", "\n", "seq_attention", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", ",", "self", ".", "hidden_units", "]", ",", "\n", ")", "# (b*s1, h1+h2)", "\n", "\n", "candidate_emb", "=", "self", ".", "item_embedding_layer", "(", "candidate", ")", "# (b, s2, h2)", "\n", "candidate_emb", "=", "tf", ".", "squeeze", "(", "candidate_emb", ",", "axis", "=", "0", ")", "# (s2, h2)", "\n", "candidate_emb", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "concat", "(", "[", "candidate_emb", ",", "test_user_emb", "]", ",", "1", ")", ",", "[", "-", "1", ",", "self", ".", "hidden_units", "]", "\n", ")", "# (b*s2, h1+h2)", "\n", "\n", "candidate_emb", "=", "tf", ".", "transpose", "(", "candidate_emb", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "# (h1+h2, b*s2)", "\n", "test_logits", "=", "tf", ".", "matmul", "(", "seq_emb", ",", "candidate_emb", ")", "# (b*s1, b*s2)", "\n", "\n", "test_logits", "=", "tf", ".", "reshape", "(", "\n", "test_logits", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", ",", "self", ".", "seq_max_len", ",", "1", "+", "self", ".", "num_neg_test", "]", ",", "\n", ")", "# (1, s, 101)", "\n", "test_logits", "=", "test_logits", "[", ":", ",", "-", "1", ",", ":", "]", "# (1, 101)", "\n", "return", "test_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.ssept.SSEPT.loss_function": [[222, 261], ["tensorflow.compat.v1.losses.get_regularization_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.math.log", "tensorflow.math.log", "tensorflow.math.sigmoid", "tensorflow.math.sigmoid"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["", "def", "loss_function", "(", "self", ",", "pos_logits", ",", "neg_logits", ",", "istarget", ")", ":", "\n", "        ", "\"\"\"Losses are calculated separately for the positive and negative\n        items based on the corresponding logits. A mask is included to\n        take care of the zero items (added for padding).\n\n        Args:\n            pos_logits (tf.Tensor): Logits of the positive examples.\n            neg_logits (tf.Tensor): Logits of the negative examples.\n            istarget (tf.Tensor): Mask for nonzero targets.\n\n        Returns:\n            float: Loss.\n        \"\"\"", "\n", "\n", "pos_logits", "=", "pos_logits", "[", ":", ",", "0", "]", "\n", "neg_logits", "=", "neg_logits", "[", ":", ",", "0", "]", "\n", "\n", "# ignore padding items (0)", "\n", "# istarget = tf.reshape(", "\n", "#     tf.cast(tf.not_equal(self.pos, 0), dtype=tf.float32),", "\n", "#     [tf.shape(self.input_seq)[0] * self.seq_max_len],", "\n", "# )", "\n", "# for logits", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "\n", "-", "tf", ".", "math", ".", "log", "(", "tf", ".", "math", ".", "sigmoid", "(", "pos_logits", ")", "+", "1e-24", ")", "*", "istarget", "\n", "-", "tf", ".", "math", ".", "log", "(", "1", "-", "tf", ".", "math", ".", "sigmoid", "(", "neg_logits", ")", "+", "1e-24", ")", "*", "istarget", "\n", ")", "/", "tf", ".", "reduce_sum", "(", "istarget", ")", "\n", "\n", "# for probabilities", "\n", "# loss = tf.reduce_sum(", "\n", "#         - tf.math.log(pos_logits + 1e-24) * istarget -", "\n", "#         tf.math.log(1 - neg_logits + 1e-24) * istarget", "\n", "# ) / tf.reduce_sum(istarget)", "\n", "reg_loss", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "# reg_losses = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES)", "\n", "# loss += sum(reg_losses)", "\n", "loss", "+=", "reg_loss", "\n", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.MultiHeadAttention.__init__": [[18, 38], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "attention_dim", ",", "num_heads", ",", "dropout_rate", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            attention_dim (int): Dimension of the attention embeddings.\n            num_heads (int): Number of heads in the multi-head self-attention module.\n            dropout_rate (float): Dropout probability.\n        \"\"\"", "\n", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "assert", "attention_dim", "%", "self", ".", "num_heads", "==", "0", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "\n", "self", ".", "depth", "=", "attention_dim", "//", "self", ".", "num_heads", "\n", "\n", "self", ".", "Q", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "attention_dim", ",", "activation", "=", "None", ")", "\n", "self", ".", "K", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "attention_dim", ",", "activation", "=", "None", ")", "\n", "self", ".", "V", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "attention_dim", ",", "activation", "=", "None", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.MultiHeadAttention.call": [[39, 119], ["model.MultiHeadAttention.Q", "model.MultiHeadAttention.K", "model.MultiHeadAttention.V", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "tensorflow.sign", "tensorflow.tile", "tensorflow.tile", "tensorflow.where", "tensorflow.ones_like", "tensorflow.linalg.LinearOperatorLowerTriangular().to_dense", "tensorflow.tile", "tensorflow.where", "tensorflow.nn.softmax", "tensorflow.sign", "tensorflow.tile", "tensorflow.tile", "model.MultiHeadAttention.dropout", "tensorflow.matmul", "tensorflow.concat", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.transpose", "tensorflow.abs", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.equal", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.equal", "tensorflow.abs", "tensorflow.expand_dims", "tensorflow.split", "tensorflow.reduce_sum", "tensorflow.linalg.LinearOperatorLowerTriangular", "tensorflow.reduce_sum", "tensorflow.concat.get_shape().as_list", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.concat.get_shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "call", "(", "self", ",", "queries", ",", "keys", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            queries (tf.Tensor): Tensor of queries.\n            keys (tf.Tensor): Tensor of keys\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "\n", "# Linear projections", "\n", "Q", "=", "self", ".", "Q", "(", "queries", ")", "# (N, T_q, C)", "\n", "K", "=", "self", ".", "K", "(", "keys", ")", "# (N, T_k, C)", "\n", "V", "=", "self", ".", "V", "(", "keys", ")", "# (N, T_k, C)", "\n", "\n", "# --- MULTI HEAD ---", "\n", "# Split and concat, Q_, K_ and V_ are all (h*N, T_q, C/h)", "\n", "Q_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "Q", ",", "self", ".", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "\n", "K_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "K", ",", "self", ".", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "\n", "V_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "V", ",", "self", ".", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "\n", "\n", "# --- SCALED DOT PRODUCT ---", "\n", "# Multiplication", "\n", "outputs", "=", "tf", ".", "matmul", "(", "Q_", ",", "tf", ".", "transpose", "(", "K_", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# (h*N, T_q, T_k)", "\n", "\n", "# Scale", "\n", "outputs", "=", "outputs", "/", "(", "K_", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Key Masking", "\n", "key_masks", "=", "tf", ".", "sign", "(", "tf", ".", "abs", "(", "tf", ".", "reduce_sum", "(", "keys", ",", "axis", "=", "-", "1", ")", ")", ")", "# (N, T_k)", "\n", "key_masks", "=", "tf", ".", "tile", "(", "key_masks", ",", "[", "self", ".", "num_heads", ",", "1", "]", ")", "# (h*N, T_k)", "\n", "key_masks", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "key_masks", ",", "1", ")", ",", "[", "1", ",", "tf", ".", "shape", "(", "queries", ")", "[", "1", "]", ",", "1", "]", "\n", ")", "# (h*N, T_q, T_k)", "\n", "\n", "paddings", "=", "tf", ".", "ones_like", "(", "outputs", ")", "*", "(", "-", "(", "2", "**", "32", ")", "+", "1", ")", "\n", "# outputs, (h*N, T_q, T_k)", "\n", "outputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "key_masks", ",", "0", ")", ",", "paddings", ",", "outputs", ")", "\n", "\n", "# Future blinding (Causality)", "\n", "diag_vals", "=", "tf", ".", "ones_like", "(", "outputs", "[", "0", ",", ":", ",", ":", "]", ")", "# (T_q, T_k)", "\n", "tril", "=", "tf", ".", "linalg", ".", "LinearOperatorLowerTriangular", "(", "\n", "diag_vals", "\n", ")", ".", "to_dense", "(", ")", "# (T_q, T_k)", "\n", "masks", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tril", ",", "0", ")", ",", "[", "tf", ".", "shape", "(", "outputs", ")", "[", "0", "]", ",", "1", ",", "1", "]", "\n", ")", "# (h*N, T_q, T_k)", "\n", "\n", "paddings", "=", "tf", ".", "ones_like", "(", "masks", ")", "*", "(", "-", "(", "2", "**", "32", ")", "+", "1", ")", "\n", "# outputs, (h*N, T_q, T_k)", "\n", "outputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "masks", ",", "0", ")", ",", "paddings", ",", "outputs", ")", "\n", "\n", "# Activation", "\n", "outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ")", "# (h*N, T_q, T_k)", "\n", "\n", "# Query Masking, query_masks (N, T_q)", "\n", "query_masks", "=", "tf", ".", "sign", "(", "tf", ".", "abs", "(", "tf", ".", "reduce_sum", "(", "queries", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "query_masks", "=", "tf", ".", "tile", "(", "query_masks", ",", "[", "self", ".", "num_heads", ",", "1", "]", ")", "# (h*N, T_q)", "\n", "query_masks", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "query_masks", ",", "-", "1", ")", ",", "[", "1", ",", "1", ",", "tf", ".", "shape", "(", "keys", ")", "[", "1", "]", "]", "\n", ")", "# (h*N, T_q, T_k)", "\n", "outputs", "*=", "query_masks", "# broadcasting. (N, T_q, C)", "\n", "\n", "# Dropouts", "\n", "outputs", "=", "self", ".", "dropout", "(", "outputs", ")", "\n", "\n", "# Weighted sum", "\n", "outputs", "=", "tf", ".", "matmul", "(", "outputs", ",", "V_", ")", "# ( h*N, T_q, C/h)", "\n", "\n", "# --- MULTI HEAD ---", "\n", "# concat heads", "\n", "outputs", "=", "tf", ".", "concat", "(", "\n", "tf", ".", "split", "(", "outputs", ",", "self", ".", "num_heads", ",", "axis", "=", "0", ")", ",", "axis", "=", "2", "\n", ")", "# (N, T_q, C)", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "queries", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.PointWiseFeedForward.__init__": [[126, 143], ["super().__init__", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "conv_dims", ",", "dropout_rate", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            conv_dims (list): List of the dimensions of the Feedforward layer.\n            dropout_rate (float): Dropout probability.\n        \"\"\"", "\n", "super", "(", "PointWiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_dims", "=", "conv_dims", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "conv_layer1", "=", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "\n", "filters", "=", "self", ".", "conv_dims", "[", "0", "]", ",", "kernel_size", "=", "1", ",", "activation", "=", "\"relu\"", ",", "use_bias", "=", "True", "\n", ")", "\n", "self", ".", "conv_layer2", "=", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "\n", "filters", "=", "self", ".", "conv_dims", "[", "1", "]", ",", "kernel_size", "=", "1", ",", "activation", "=", "None", ",", "use_bias", "=", "True", "\n", ")", "\n", "self", ".", "dropout_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.PointWiseFeedForward.call": [[144, 164], ["model.PointWiseFeedForward.conv_layer1", "model.PointWiseFeedForward.dropout_layer", "model.PointWiseFeedForward.conv_layer2", "model.PointWiseFeedForward.dropout_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "\n", "output", "=", "self", ".", "conv_layer1", "(", "x", ")", "\n", "output", "=", "self", ".", "dropout_layer", "(", "output", ")", "\n", "\n", "output", "=", "self", ".", "conv_layer2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout_layer", "(", "output", ")", "\n", "\n", "# Residual connection", "\n", "output", "+=", "x", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.EncoderLayer.__init__": [[172, 207], ["super().__init__", "model.MultiHeadAttention", "model.PointWiseFeedForward", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "model.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "seq_max_len", ",", "\n", "embedding_dim", ",", "\n", "attention_dim", ",", "\n", "num_heads", ",", "\n", "conv_dims", ",", "\n", "dropout_rate", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            seq_max_len (int): Maximum sequence length.\n            embedding_dim (int): Embedding dimension.\n            attention_dim (int): Dimension of the attention embeddings.\n            num_heads (int): Number of heads in the multi-head self-attention module.\n            conv_dims (list): List of the dimensions of the Feedforward layer.\n            dropout_rate (float): Dropout probability.\n        \"\"\"", "\n", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n", "self", ".", "mha", "=", "MultiHeadAttention", "(", "attention_dim", ",", "num_heads", ",", "dropout_rate", ")", "\n", "self", ".", "ffn", "=", "PointWiseFeedForward", "(", "conv_dims", ",", "dropout_rate", ")", "\n", "\n", "self", ".", "layernorm1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-6", ")", "\n", "self", ".", "layernorm2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-6", ")", "\n", "\n", "self", ".", "dropout1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout_rate", ")", "\n", "self", ".", "dropout2", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout_rate", ")", "\n", "\n", "self", ".", "layer_normalization", "=", "LayerNormalization", "(", "\n", "self", ".", "seq_max_len", ",", "self", ".", "embedding_dim", ",", "1e-08", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.EncoderLayer.call_": [[209, 236], ["model.EncoderLayer.mha", "model.EncoderLayer.dropout1", "model.EncoderLayer.layernorm1", "model.EncoderLayer.ffn", "model.EncoderLayer.dropout2", "model.EncoderLayer.layernorm2", "model.EncoderLayer.layer_normalization"], "methods", ["None"], ["", "def", "call_", "(", "self", ",", "x", ",", "training", ",", "mask", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n            training (tf.Tensor): Training tensor.\n            mask (tf.Tensor): Mask tensor.\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "\n", "attn_output", "=", "self", ".", "mha", "(", "queries", "=", "self", ".", "layer_normalization", "(", "x", ")", ",", "keys", "=", "x", ")", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ",", "training", "=", "training", ")", "\n", "out1", "=", "self", ".", "layernorm1", "(", "x", "+", "attn_output", ")", "\n", "\n", "# feed forward network", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out1", ")", "# (batch_size, input_seq_len, d_model)", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ",", "training", "=", "training", ")", "\n", "out2", "=", "self", ".", "layernorm2", "(", "\n", "out1", "+", "ffn_output", "\n", ")", "# (batch_size, input_seq_len, d_model)", "\n", "\n", "# masking", "\n", "out2", "*=", "mask", "\n", "\n", "return", "out2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.EncoderLayer.call": [[237, 255], ["model.EncoderLayer.layer_normalization", "model.EncoderLayer.mha", "model.EncoderLayer.ffn"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", ",", "mask", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n            training (tf.Tensor): Training tensor.\n            mask (tf.Tensor): Mask tensor.\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "\n", "x_norm", "=", "self", ".", "layer_normalization", "(", "x", ")", "\n", "attn_output", "=", "self", ".", "mha", "(", "queries", "=", "x_norm", ",", "keys", "=", "x", ")", "\n", "attn_output", "=", "self", ".", "ffn", "(", "attn_output", ")", "\n", "out", "=", "attn_output", "*", "mask", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.Encoder.__init__": [[263, 301], ["super().__init__", "tensorflow.keras.layers.Dropout", "model.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_layers", ",", "\n", "seq_max_len", ",", "\n", "embedding_dim", ",", "\n", "attention_dim", ",", "\n", "num_heads", ",", "\n", "conv_dims", ",", "\n", "dropout_rate", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            num_layers (int): Number of layers.\n            seq_max_len (int): Maximum sequence length.\n            embedding_dim (int): Embedding dimension.\n            attention_dim (int): Dimension of the attention embeddings.\n            num_heads (int): Number of heads in the multi-head self-attention module.\n            conv_dims (list): List of the dimensions of the Feedforward layer.\n            dropout_rate (float): Dropout probability.\n        \"\"\"", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "self", ".", "enc_layers", "=", "[", "\n", "EncoderLayer", "(", "\n", "seq_max_len", ",", "\n", "embedding_dim", ",", "\n", "attention_dim", ",", "\n", "num_heads", ",", "\n", "conv_dims", ",", "\n", "dropout_rate", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "\n", "]", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.Encoder.call": [[302, 318], ["range"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", ",", "mask", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n            training (tf.Tensor): Training tensor.\n            mask (tf.Tensor): Mask tensor.\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "enc_layers", "[", "i", "]", "(", "x", ",", "training", ",", "mask", ")", "\n", "\n", "", "return", "x", "# (batch_size, input_seq_len, d_model)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.LayerNormalization.__init__": [[326, 348], ["super().__init__", "tensorflow.ones_initializer", "tensorflow.Variable", "tensorflow.zeros_initializer", "tensorflow.Variable", "tensorflow.ones_initializer.", "tensorflow.zeros_initializer."], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "seq_max_len", ",", "embedding_dim", ",", "epsilon", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            seq_max_len (int): Maximum sequence length.\n            embedding_dim (int): Embedding dimension.\n            epsilon (float): Epsilon value.\n        \"\"\"", "\n", "super", "(", "LayerNormalization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "params_shape", "=", "(", "self", ".", "seq_max_len", ",", "self", ".", "embedding_dim", ")", "\n", "g_init", "=", "tf", ".", "ones_initializer", "(", ")", "\n", "self", ".", "gamma", "=", "tf", ".", "Variable", "(", "\n", "initial_value", "=", "g_init", "(", "shape", "=", "self", ".", "params_shape", ",", "dtype", "=", "\"float32\"", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n", "b_init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "self", ".", "beta", "=", "tf", ".", "Variable", "(", "\n", "initial_value", "=", "b_init", "(", "shape", "=", "self", ".", "params_shape", ",", "dtype", "=", "\"float32\"", ")", ",", "\n", "trainable", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.LayerNormalization.call": [[350, 363], ["tensorflow.nn.moments"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n\n        Returns:\n            tf.Tensor: Output tensor.\n        \"\"\"", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "-", "1", "]", ",", "keepdims", "=", "True", ")", "\n", "normalized", "=", "(", "x", "-", "mean", ")", "/", "(", "(", "variance", "+", "self", ".", "epsilon", ")", "**", "0.5", ")", "\n", "output", "=", "self", ".", "gamma", "*", "normalized", "+", "self", ".", "beta", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.__init__": [[380, 435], ["super().__init__", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "model.Encoder", "tensorflow.keras.layers.Masking", "model.LayerNormalization", "tensorflow.keras.regularizers.L2", "tensorflow.keras.regularizers.L2"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Model initialization.\n\n        Args:\n            item_num (int): Number of items in the dataset.\n            seq_max_len (int): Maximum number of items in user history.\n            num_blocks (int): Number of Transformer blocks to be used.\n            embedding_dim (int): Item embedding dimension.\n            attention_dim (int): Transformer attention dimension.\n            conv_dims (list): List of the dimensions of the Feedforward layer.\n            dropout_rate (float): Dropout rate.\n            l2_reg (float): Coefficient of the L2 regularization.\n            num_neg_test (int): Number of negative examples used in testing.\n        \"\"\"", "\n", "super", "(", "SASREC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "item_num", "=", "kwargs", ".", "get", "(", "\"item_num\"", ",", "None", ")", "\n", "self", ".", "seq_max_len", "=", "kwargs", ".", "get", "(", "\"seq_max_len\"", ",", "100", ")", "\n", "self", ".", "num_blocks", "=", "kwargs", ".", "get", "(", "\"num_blocks\"", ",", "2", ")", "\n", "self", ".", "embedding_dim", "=", "kwargs", ".", "get", "(", "\"embedding_dim\"", ",", "100", ")", "\n", "self", ".", "attention_dim", "=", "kwargs", ".", "get", "(", "\"attention_dim\"", ",", "100", ")", "\n", "self", ".", "attention_num_heads", "=", "kwargs", ".", "get", "(", "\"attention_num_heads\"", ",", "1", ")", "\n", "self", ".", "conv_dims", "=", "kwargs", ".", "get", "(", "\"conv_dims\"", ",", "[", "100", ",", "100", "]", ")", "\n", "self", ".", "dropout_rate", "=", "kwargs", ".", "get", "(", "\"dropout_rate\"", ",", "0.5", ")", "\n", "self", ".", "l2_reg", "=", "kwargs", ".", "get", "(", "\"l2_reg\"", ",", "0.0", ")", "\n", "self", ".", "num_neg_test", "=", "kwargs", ".", "get", "(", "\"num_neg_test\"", ",", "100", ")", "\n", "\n", "self", ".", "item_embedding_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "self", ".", "item_num", "+", "1", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "name", "=", "\"item_embeddings\"", ",", "\n", "mask_zero", "=", "True", ",", "\n", "embeddings_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "L2", "(", "self", ".", "l2_reg", ")", ",", "\n", ")", "\n", "\n", "self", ".", "positional_embedding_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "self", ".", "seq_max_len", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "name", "=", "\"positional_embeddings\"", ",", "\n", "mask_zero", "=", "False", ",", "\n", "embeddings_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "L2", "(", "self", ".", "l2_reg", ")", ",", "\n", ")", "\n", "self", ".", "dropout_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "self", ".", "num_blocks", ",", "\n", "self", ".", "seq_max_len", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "attention_dim", ",", "\n", "self", ".", "attention_num_heads", ",", "\n", "self", ".", "conv_dims", ",", "\n", "self", ".", "dropout_rate", ",", "\n", ")", "\n", "self", ".", "mask_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Masking", "(", "mask_value", "=", "0", ")", "\n", "self", ".", "layer_normalization", "=", "LayerNormalization", "(", "\n", "self", ".", "seq_max_len", ",", "self", ".", "embedding_dim", ",", "1e-08", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.embedding": [[437, 458], ["model.SASREC.item_embedding_layer", "tensorflow.expand_dims", "tensorflow.tile", "model.SASREC.positional_embedding_layer", "tensorflow.range", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "embedding", "(", "self", ",", "input_seq", ")", ":", "\n", "        ", "\"\"\"Compute the sequence and positional embeddings.\n\n        Args:\n            input_seq (tf.Tensor): Input sequence\n\n        Returns:\n            tf.Tensor, tf.Tensor:\n            - Sequence embeddings.\n            - Positional embeddings.\n        \"\"\"", "\n", "\n", "seq_embeddings", "=", "self", ".", "item_embedding_layer", "(", "input_seq", ")", "\n", "seq_embeddings", "=", "seq_embeddings", "*", "(", "self", ".", "embedding_dim", "**", "0.5", ")", "\n", "\n", "# FIXME", "\n", "positional_seq", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "tf", ".", "shape", "(", "input_seq", ")", "[", "1", "]", ")", ",", "0", ")", "\n", "positional_seq", "=", "tf", ".", "tile", "(", "positional_seq", ",", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", ",", "1", "]", ")", "\n", "positional_embeddings", "=", "self", ".", "positional_embedding_layer", "(", "positional_seq", ")", "\n", "\n", "return", "seq_embeddings", ",", "positional_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.call": [[459, 526], ["tensorflow.expand_dims", "model.SASREC.embedding", "model.SASREC.dropout_layer", "model.SASREC.encoder", "model.SASREC.layer_normalization", "model.SASREC.mask_layer", "model.SASREC.mask_layer", "tensorflow.reshape", "tensorflow.reshape", "model.SASREC.item_embedding_layer", "model.SASREC.item_embedding_layer", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.cast", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.not_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.embedding"], ["", "def", "call", "(", "self", ",", "x", ",", "training", ")", ":", "\n", "        ", "\"\"\"Model forward pass.\n\n        Args:\n            x (tf.Tensor): Input tensor.\n            training (tf.Tensor): Training tensor.\n\n        Returns:\n            tf.Tensor, tf.Tensor, tf.Tensor:\n            - Logits of the positive examples.\n            - Logits of the negative examples.\n            - Mask for nonzero targets\n        \"\"\"", "\n", "\n", "input_seq", "=", "x", "[", "\"input_seq\"", "]", "\n", "pos", "=", "x", "[", "\"positive\"", "]", "\n", "neg", "=", "x", "[", "\"negative\"", "]", "\n", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_seq", ",", "0", ")", ",", "tf", ".", "float32", ")", ",", "-", "1", ")", "\n", "seq_embeddings", ",", "positional_embeddings", "=", "self", ".", "embedding", "(", "input_seq", ")", "\n", "\n", "# add positional embeddings", "\n", "seq_embeddings", "+=", "positional_embeddings", "\n", "\n", "# dropout", "\n", "seq_embeddings", "=", "self", ".", "dropout_layer", "(", "seq_embeddings", ")", "\n", "\n", "# masking", "\n", "seq_embeddings", "*=", "mask", "\n", "\n", "# --- ATTENTION BLOCKS ---", "\n", "seq_attention", "=", "seq_embeddings", "\n", "seq_attention", "=", "self", ".", "encoder", "(", "seq_attention", ",", "training", ",", "mask", ")", "\n", "seq_attention", "=", "self", ".", "layer_normalization", "(", "seq_attention", ")", "# (b, s, d)", "\n", "\n", "# --- PREDICTION LAYER ---", "\n", "# user's sequence embedding", "\n", "pos", "=", "self", ".", "mask_layer", "(", "pos", ")", "\n", "neg", "=", "self", ".", "mask_layer", "(", "neg", ")", "\n", "\n", "pos", "=", "tf", ".", "reshape", "(", "pos", ",", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ")", "\n", "neg", "=", "tf", ".", "reshape", "(", "neg", ",", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ")", "\n", "pos_emb", "=", "self", ".", "item_embedding_layer", "(", "pos", ")", "\n", "neg_emb", "=", "self", ".", "item_embedding_layer", "(", "neg", ")", "\n", "seq_emb", "=", "tf", ".", "reshape", "(", "\n", "seq_attention", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", ",", "self", ".", "embedding_dim", "]", ",", "\n", ")", "# (b*s, d)", "\n", "\n", "pos_logits", "=", "tf", ".", "reduce_sum", "(", "pos_emb", "*", "seq_emb", ",", "-", "1", ")", "\n", "neg_logits", "=", "tf", ".", "reduce_sum", "(", "neg_emb", "*", "seq_emb", ",", "-", "1", ")", "\n", "\n", "pos_logits", "=", "tf", ".", "expand_dims", "(", "pos_logits", ",", "axis", "=", "-", "1", ")", "# (bs, 1)", "\n", "# pos_prob = tf.keras.layers.Dense(1, activation='sigmoid')(pos_logits)  # (bs, 1)", "\n", "\n", "neg_logits", "=", "tf", ".", "expand_dims", "(", "neg_logits", ",", "axis", "=", "-", "1", ")", "# (bs, 1)", "\n", "# neg_prob = tf.keras.layers.Dense(1, activation='sigmoid')(neg_logits)  # (bs, 1)", "\n", "\n", "# output = tf.concat([pos_logits, neg_logits], axis=0)", "\n", "\n", "# masking for loss calculation", "\n", "istarget", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "pos", ",", "0", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", "]", ",", "\n", ")", "\n", "\n", "return", "pos_logits", ",", "neg_logits", ",", "istarget", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.predict": [[527, 564], ["tensorflow.expand_dims", "model.SASREC.embedding", "model.SASREC.encoder", "model.SASREC.layer_normalization", "tensorflow.reshape", "model.SASREC.item_embedding_layer", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.embedding"], ["", "def", "predict", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Returns the logits for the test items.\n\n        Args:\n            inputs (tf.Tensor): Input tensor.\n\n        Returns:\n             tf.Tensor: Output tensor.\n        \"\"\"", "\n", "training", "=", "False", "\n", "input_seq", "=", "inputs", "[", "\"input_seq\"", "]", "\n", "candidate", "=", "inputs", "[", "\"candidate\"", "]", "\n", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_seq", ",", "0", ")", ",", "tf", ".", "float32", ")", ",", "-", "1", ")", "\n", "seq_embeddings", ",", "positional_embeddings", "=", "self", ".", "embedding", "(", "input_seq", ")", "\n", "seq_embeddings", "+=", "positional_embeddings", "\n", "# seq_embeddings = self.dropout_layer(seq_embeddings)", "\n", "seq_embeddings", "*=", "mask", "\n", "seq_attention", "=", "seq_embeddings", "\n", "seq_attention", "=", "self", ".", "encoder", "(", "seq_attention", ",", "training", ",", "mask", ")", "\n", "seq_attention", "=", "self", ".", "layer_normalization", "(", "seq_attention", ")", "# (b, s, d)", "\n", "seq_emb", "=", "tf", ".", "reshape", "(", "\n", "seq_attention", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", "*", "self", ".", "seq_max_len", ",", "self", ".", "embedding_dim", "]", ",", "\n", ")", "# (b*s, d)", "\n", "candidate_emb", "=", "self", ".", "item_embedding_layer", "(", "candidate", ")", "# (b, s, d)", "\n", "candidate_emb", "=", "tf", ".", "transpose", "(", "candidate_emb", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# (b, d, s)", "\n", "\n", "test_logits", "=", "tf", ".", "matmul", "(", "seq_emb", ",", "candidate_emb", ")", "\n", "# (200, 100) * (1, 101, 100)'", "\n", "\n", "test_logits", "=", "tf", ".", "reshape", "(", "\n", "test_logits", ",", "\n", "[", "tf", ".", "shape", "(", "input_seq", ")", "[", "0", "]", ",", "self", ".", "seq_max_len", ",", "1", "+", "self", ".", "num_neg_test", "]", ",", "\n", ")", "# (1, 200, 101)", "\n", "test_logits", "=", "test_logits", "[", ":", ",", "-", "1", ",", ":", "]", "# (1, 101)", "\n", "return", "test_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.loss_function": [[565, 604], ["tensorflow.compat.v1.losses.get_regularization_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.math.log", "tensorflow.math.log", "tensorflow.math.sigmoid", "tensorflow.math.sigmoid"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["", "def", "loss_function", "(", "self", ",", "pos_logits", ",", "neg_logits", ",", "istarget", ")", ":", "\n", "        ", "\"\"\"Losses are calculated separately for the positive and negative\n        items based on the corresponding logits. A mask is included to\n        take care of the zero items (added for padding).\n\n        Args:\n            pos_logits (tf.Tensor): Logits of the positive examples.\n            neg_logits (tf.Tensor): Logits of the negative examples.\n            istarget (tf.Tensor): Mask for nonzero targets.\n\n        Returns:\n            float: Loss.\n        \"\"\"", "\n", "\n", "pos_logits", "=", "pos_logits", "[", ":", ",", "0", "]", "\n", "neg_logits", "=", "neg_logits", "[", ":", ",", "0", "]", "\n", "\n", "# ignore padding items (0)", "\n", "# istarget = tf.reshape(", "\n", "#     tf.cast(tf.not_equal(self.pos, 0), dtype=tf.float32),", "\n", "#     [tf.shape(self.input_seq)[0] * self.seq_max_len],", "\n", "# )", "\n", "# for logits", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "\n", "-", "tf", ".", "math", ".", "log", "(", "tf", ".", "math", ".", "sigmoid", "(", "pos_logits", ")", "+", "1e-24", ")", "*", "istarget", "\n", "-", "tf", ".", "math", ".", "log", "(", "1", "-", "tf", ".", "math", ".", "sigmoid", "(", "neg_logits", ")", "+", "1e-24", ")", "*", "istarget", "\n", ")", "/", "tf", ".", "reduce_sum", "(", "istarget", ")", "\n", "\n", "# for probabilities", "\n", "# loss = tf.reduce_sum(", "\n", "#         - tf.math.log(pos_logits + 1e-24) * istarget -", "\n", "#         tf.math.log(1 - neg_logits + 1e-24) * istarget", "\n", "# ) / tf.reduce_sum(istarget)", "\n", "reg_loss", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "# reg_losses = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES)", "\n", "# loss += sum(reg_losses)", "\n", "loss", "+=", "reg_loss", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.create_combined_dataset": [[605, 635], ["tensorflow.keras.preprocessing.sequence.pad_sequences", "tensorflow.keras.preprocessing.sequence.pad_sequences", "tensorflow.keras.preprocessing.sequence.pad_sequences", "numpy.expand_dims", "numpy.concatenate", "numpy.expand_dims", "numpy.array", "numpy.repeat", "numpy.repeat"], "methods", ["None"], ["", "def", "create_combined_dataset", "(", "self", ",", "u", ",", "seq", ",", "pos", ",", "neg", ")", ":", "\n", "        ", "\"\"\"\n        function to create model inputs from sampled batch data.\n        This function is used only during training.\n        \"\"\"", "\n", "inputs", "=", "{", "}", "\n", "seq", "=", "tf", ".", "keras", ".", "preprocessing", ".", "sequence", ".", "pad_sequences", "(", "\n", "seq", ",", "padding", "=", "\"pre\"", ",", "truncating", "=", "\"pre\"", ",", "maxlen", "=", "self", ".", "seq_max_len", "\n", ")", "\n", "pos", "=", "tf", ".", "keras", ".", "preprocessing", ".", "sequence", ".", "pad_sequences", "(", "\n", "pos", ",", "padding", "=", "\"pre\"", ",", "truncating", "=", "\"pre\"", ",", "maxlen", "=", "self", ".", "seq_max_len", "\n", ")", "\n", "neg", "=", "tf", ".", "keras", ".", "preprocessing", ".", "sequence", ".", "pad_sequences", "(", "\n", "neg", ",", "padding", "=", "\"pre\"", ",", "truncating", "=", "\"pre\"", ",", "maxlen", "=", "self", ".", "seq_max_len", "\n", ")", "\n", "\n", "inputs", "[", "\"users\"", "]", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "u", ")", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "[", "\"input_seq\"", "]", "=", "seq", "\n", "inputs", "[", "\"positive\"", "]", "=", "pos", "\n", "inputs", "[", "\"negative\"", "]", "=", "neg", "\n", "\n", "target", "=", "np", ".", "concatenate", "(", "\n", "[", "\n", "np", ".", "repeat", "(", "1", ",", "seq", ".", "shape", "[", "0", "]", "*", "seq", ".", "shape", "[", "1", "]", ")", ",", "\n", "np", ".", "repeat", "(", "0", ",", "seq", ".", "shape", "[", "0", "]", "*", "seq", ".", "shape", "[", "1", "]", ")", ",", "\n", "]", ",", "\n", "axis", "=", "0", ",", "\n", ")", "\n", "target", "=", "np", ".", "expand_dims", "(", "target", ",", "axis", "=", "-", "1", ")", "\n", "return", "inputs", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train": [[636, 722], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "int", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.metrics.Mean", "tensorflow.function", "recommenders.utils.timer.Timer", "recommenders.utils.timer.Timer.start", "range", "model.SASREC.evaluate", "print", "tensorflow.TensorSpec", "tape.gradient", "tensorflow.keras.optimizers.Adam.apply_gradients", "tensorflow.keras.metrics.Mean.", "tensorflow.keras.metrics.Mean.reset_states", "tqdm.tqdm.tqdm", "len", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.GradientTape", "model.SASREC.", "model.SASREC.loss_function"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.start", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.evaluate", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.loss_function"], ["", "def", "train", "(", "self", ",", "dataset", ",", "sampler", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        High level function for model training as well as\n        evaluation on the validation and test dataset\n        \"\"\"", "\n", "num_epochs", "=", "kwargs", ".", "get", "(", "\"num_epochs\"", ",", "10", ")", "\n", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", "\n", "lr", "=", "kwargs", ".", "get", "(", "\"learning_rate\"", ",", "0.001", ")", "\n", "val_epoch", "=", "kwargs", ".", "get", "(", "\"val_epoch\"", ",", "5", ")", "\n", "\n", "num_steps", "=", "int", "(", "len", "(", "dataset", ".", "user_train", ")", "/", "batch_size", ")", "\n", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "lr", ",", "beta_1", "=", "0.9", ",", "beta_2", "=", "0.999", ",", "epsilon", "=", "1e-7", "\n", ")", "\n", "\n", "loss_function", "=", "self", ".", "loss_function", "\n", "\n", "train_loss", "=", "tf", ".", "keras", ".", "metrics", ".", "Mean", "(", "name", "=", "\"train_loss\"", ")", "\n", "\n", "train_step_signature", "=", "[", "\n", "{", "\n", "\"users\"", ":", "tf", ".", "TensorSpec", "(", "shape", "=", "(", "None", ",", "1", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "\"input_seq\"", ":", "tf", ".", "TensorSpec", "(", "\n", "shape", "=", "(", "None", ",", "self", ".", "seq_max_len", ")", ",", "dtype", "=", "tf", ".", "int64", "\n", ")", ",", "\n", "\"positive\"", ":", "tf", ".", "TensorSpec", "(", "\n", "shape", "=", "(", "None", ",", "self", ".", "seq_max_len", ")", ",", "dtype", "=", "tf", ".", "int64", "\n", ")", ",", "\n", "\"negative\"", ":", "tf", ".", "TensorSpec", "(", "\n", "shape", "=", "(", "None", ",", "self", ".", "seq_max_len", ")", ",", "dtype", "=", "tf", ".", "int64", "\n", ")", ",", "\n", "}", ",", "\n", "tf", ".", "TensorSpec", "(", "shape", "=", "(", "None", ",", "1", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "]", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "train_step_signature", ")", "\n", "def", "train_step", "(", "inp", ",", "tar", ")", ":", "\n", "            ", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "                ", "pos_logits", ",", "neg_logits", ",", "loss_mask", "=", "self", "(", "inp", ",", "training", "=", "True", ")", "\n", "loss", "=", "loss_function", "(", "pos_logits", ",", "neg_logits", ",", "loss_mask", ")", "\n", "\n", "", "gradients", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "trainable_variables", ")", "\n", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "self", ".", "trainable_variables", ")", ")", "\n", "\n", "train_loss", "(", "loss", ")", "\n", "return", "loss", "\n", "\n", "", "T", "=", "0.0", "\n", "t0", "=", "Timer", "(", ")", "\n", "t0", ".", "start", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "num_epochs", "+", "1", ")", ":", "\n", "\n", "            ", "step_loss", "=", "[", "]", "\n", "train_loss", ".", "reset_states", "(", ")", "\n", "for", "step", "in", "tqdm", "(", "\n", "range", "(", "num_steps", ")", ",", "total", "=", "num_steps", ",", "ncols", "=", "70", ",", "leave", "=", "False", ",", "unit", "=", "\"b\"", "\n", ")", ":", "\n", "\n", "                ", "u", ",", "seq", ",", "pos", ",", "neg", "=", "sampler", ".", "next_batch", "(", ")", "\n", "\n", "inputs", ",", "target", "=", "self", ".", "create_combined_dataset", "(", "u", ",", "seq", ",", "pos", ",", "neg", ")", "\n", "\n", "loss", "=", "train_step", "(", "inputs", ",", "target", ")", "\n", "step_loss", ".", "append", "(", "loss", ")", "\n", "\n", "", "if", "epoch", "%", "val_epoch", "==", "0", ":", "\n", "                ", "t0", ".", "stop", "(", ")", "\n", "t1", "=", "t0", ".", "interval", "\n", "T", "+=", "t1", "\n", "print", "(", "\"Evaluating...\"", ")", "\n", "t_test", "=", "self", ".", "evaluate", "(", "dataset", ")", "\n", "t_valid", "=", "self", ".", "evaluate_valid", "(", "dataset", ")", "\n", "print", "(", "\n", "f\"\\nepoch: {epoch}, time: {T}, valid (NDCG@10: {t_valid[0]}, HR@10: {t_valid[1]})\"", "\n", ")", "\n", "print", "(", "\n", "f\"epoch: {epoch}, time: {T},  test (NDCG@10: {t_test[0]}, HR@10: {t_test[1]})\"", "\n", ")", "\n", "t0", ".", "start", "(", ")", "\n", "\n", "", "", "t_test", "=", "self", ".", "evaluate", "(", "dataset", ")", "\n", "print", "(", "f\"\\nepoch: {epoch}, test (NDCG@10: {t_test[0]}, HR@10: {t_test[1]})\"", ")", "\n", "\n", "return", "t_test", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.evaluate": [[723, 784], ["tqdm.tqdm.tqdm", "random.sample", "range", "numpy.zeros", "reversed", "set", "set.add", "range", "numpy.expand_dims", "numpy.array", "numpy.array", "numpy.array", "range", "numpy.random.randint", "item_idx.append", "numpy.array", "model.SASREC.predict", "numpy.array.argsort().argsort", "len", "len", "numpy.random.randint", "numpy.log2", "numpy.array.argsort"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "evaluate", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        Evaluation on the test users (users with at least 3 items)\n        \"\"\"", "\n", "usernum", "=", "dataset", ".", "usernum", "\n", "itemnum", "=", "dataset", ".", "itemnum", "\n", "train", "=", "dataset", ".", "user_train", "# removing deepcopy", "\n", "valid", "=", "dataset", ".", "user_valid", "\n", "test", "=", "dataset", ".", "user_test", "\n", "\n", "NDCG", "=", "0.0", "\n", "HT", "=", "0.0", "\n", "valid_user", "=", "0.0", "\n", "\n", "if", "usernum", ">", "10000", ":", "\n", "            ", "users", "=", "random", ".", "sample", "(", "range", "(", "1", ",", "usernum", "+", "1", ")", ",", "10000", ")", "\n", "", "else", ":", "\n", "            ", "users", "=", "range", "(", "1", ",", "usernum", "+", "1", ")", "\n", "\n", "", "for", "u", "in", "tqdm", "(", "users", ",", "ncols", "=", "70", ",", "leave", "=", "False", ",", "unit", "=", "\"b\"", ")", ":", "\n", "\n", "            ", "if", "len", "(", "train", "[", "u", "]", ")", "<", "1", "or", "len", "(", "test", "[", "u", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "seq", "=", "np", ".", "zeros", "(", "[", "self", ".", "seq_max_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "idx", "=", "self", ".", "seq_max_len", "-", "1", "\n", "seq", "[", "idx", "]", "=", "valid", "[", "u", "]", "[", "0", "]", "\n", "idx", "-=", "1", "\n", "for", "i", "in", "reversed", "(", "train", "[", "u", "]", ")", ":", "\n", "                ", "seq", "[", "idx", "]", "=", "i", "\n", "idx", "-=", "1", "\n", "if", "idx", "==", "-", "1", ":", "\n", "                    ", "break", "\n", "", "", "rated", "=", "set", "(", "train", "[", "u", "]", ")", "\n", "rated", ".", "add", "(", "0", ")", "\n", "item_idx", "=", "[", "test", "[", "u", "]", "[", "0", "]", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_neg_test", ")", ":", "\n", "                ", "t", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "itemnum", "+", "1", ")", "\n", "while", "t", "in", "rated", ":", "\n", "                    ", "t", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "itemnum", "+", "1", ")", "\n", "", "item_idx", ".", "append", "(", "t", ")", "\n", "\n", "", "inputs", "=", "{", "}", "\n", "inputs", "[", "\"user\"", "]", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "u", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "[", "\"input_seq\"", "]", "=", "np", ".", "array", "(", "[", "seq", "]", ")", "\n", "inputs", "[", "\"candidate\"", "]", "=", "np", ".", "array", "(", "[", "item_idx", "]", ")", "\n", "\n", "# inverse to get descending sort", "\n", "predictions", "=", "-", "1.0", "*", "self", ".", "predict", "(", "inputs", ")", "\n", "predictions", "=", "np", ".", "array", "(", "predictions", ")", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "rank", "=", "predictions", ".", "argsort", "(", ")", ".", "argsort", "(", ")", "[", "0", "]", "\n", "\n", "valid_user", "+=", "1", "\n", "\n", "if", "rank", "<", "10", ":", "\n", "                ", "NDCG", "+=", "1", "/", "np", ".", "log2", "(", "rank", "+", "2", ")", "\n", "HT", "+=", "1", "\n", "\n", "", "", "return", "NDCG", "/", "valid_user", ",", "HT", "/", "valid_user", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.evaluate_valid": [[785, 842], ["tqdm.tqdm.tqdm", "random.sample", "range", "numpy.zeros", "reversed", "set", "set.add", "range", "numpy.expand_dims", "numpy.array", "numpy.array", "numpy.array", "range", "numpy.random.randint", "item_idx.append", "numpy.array", "model.SASREC.predict", "numpy.array.argsort().argsort", "len", "len", "numpy.random.randint", "numpy.log2", "numpy.array.argsort"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "evaluate_valid", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        Evaluation on the validation users\n        \"\"\"", "\n", "usernum", "=", "dataset", ".", "usernum", "\n", "itemnum", "=", "dataset", ".", "itemnum", "\n", "train", "=", "dataset", ".", "user_train", "# removing deepcopy", "\n", "valid", "=", "dataset", ".", "user_valid", "\n", "\n", "NDCG", "=", "0.0", "\n", "valid_user", "=", "0.0", "\n", "HT", "=", "0.0", "\n", "if", "usernum", ">", "10000", ":", "\n", "            ", "users", "=", "random", ".", "sample", "(", "range", "(", "1", ",", "usernum", "+", "1", ")", ",", "10000", ")", "\n", "", "else", ":", "\n", "            ", "users", "=", "range", "(", "1", ",", "usernum", "+", "1", ")", "\n", "\n", "", "for", "u", "in", "tqdm", "(", "users", ",", "ncols", "=", "70", ",", "leave", "=", "False", ",", "unit", "=", "\"b\"", ")", ":", "\n", "            ", "if", "len", "(", "train", "[", "u", "]", ")", "<", "1", "or", "len", "(", "valid", "[", "u", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "seq", "=", "np", ".", "zeros", "(", "[", "self", ".", "seq_max_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "idx", "=", "self", ".", "seq_max_len", "-", "1", "\n", "for", "i", "in", "reversed", "(", "train", "[", "u", "]", ")", ":", "\n", "                ", "seq", "[", "idx", "]", "=", "i", "\n", "idx", "-=", "1", "\n", "if", "idx", "==", "-", "1", ":", "\n", "                    ", "break", "\n", "\n", "", "", "rated", "=", "set", "(", "train", "[", "u", "]", ")", "\n", "rated", ".", "add", "(", "0", ")", "\n", "item_idx", "=", "[", "valid", "[", "u", "]", "[", "0", "]", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_neg_test", ")", ":", "\n", "                ", "t", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "itemnum", "+", "1", ")", "\n", "while", "t", "in", "rated", ":", "\n", "                    ", "t", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "itemnum", "+", "1", ")", "\n", "", "item_idx", ".", "append", "(", "t", ")", "\n", "\n", "", "inputs", "=", "{", "}", "\n", "inputs", "[", "\"user\"", "]", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "u", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "[", "\"input_seq\"", "]", "=", "np", ".", "array", "(", "[", "seq", "]", ")", "\n", "inputs", "[", "\"candidate\"", "]", "=", "np", ".", "array", "(", "[", "item_idx", "]", ")", "\n", "\n", "# predictions = -model.predict(sess, [u], [seq], item_idx)", "\n", "predictions", "=", "-", "1.0", "*", "self", ".", "predict", "(", "inputs", ")", "\n", "predictions", "=", "np", ".", "array", "(", "predictions", ")", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "rank", "=", "predictions", ".", "argsort", "(", ")", ".", "argsort", "(", ")", "[", "0", "]", "\n", "\n", "valid_user", "+=", "1", "\n", "\n", "if", "rank", "<", "10", ":", "\n", "                ", "NDCG", "+=", "1", "/", "np", ".", "log2", "(", "rank", "+", "2", ")", "\n", "HT", "+=", "1", "\n", "\n", "", "", "return", "NDCG", "/", "valid_user", ",", "HT", "/", "valid_user", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.__init__": [[23, 42], ["collections.defaultdict", "set", "kwargs.get", "kwargs.get", "fr.readline.strip().split", "open", "fr.readline", "fr.readline.strip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "usernum", "=", "0", "\n", "self", ".", "itemnum", "=", "0", "\n", "self", ".", "User", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "Items", "=", "set", "(", ")", "\n", "self", ".", "user_train", "=", "{", "}", "\n", "self", ".", "user_valid", "=", "{", "}", "\n", "self", ".", "user_test", "=", "{", "}", "\n", "self", ".", "col_sep", "=", "kwargs", ".", "get", "(", "\"col_sep\"", ",", "\" \"", ")", "\n", "self", ".", "filename", "=", "kwargs", ".", "get", "(", "\"filename\"", ",", "None", ")", "\n", "\n", "if", "self", ".", "filename", ":", "\n", "            ", "with", "open", "(", "self", ".", "filename", ",", "\"r\"", ")", "as", "fr", ":", "\n", "                ", "sample", "=", "fr", ".", "readline", "(", ")", "\n", "", "ncols", "=", "sample", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "col_sep", ")", "\n", "if", "ncols", "==", "3", ":", "\n", "                ", "self", ".", "with_time", "=", "True", "\n", "", "else", ":", "\n", "                ", "self", ".", "with_time", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split": [[43, 52], ["kwargs.get", "ValueError", "util.SASRecDataSet.data_partition_with_time", "util.SASRecDataSet.data_partition"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.data_partition_with_time", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.data_partition"], ["", "", "", "def", "split", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "filename", "=", "kwargs", ".", "get", "(", "\"filename\"", ",", "self", ".", "filename", ")", "\n", "if", "not", "self", ".", "filename", ":", "\n", "            ", "raise", "ValueError", "(", "\"Filename is required\"", ")", "\n", "\n", "", "if", "self", ".", "with_time", ":", "\n", "            ", "self", ".", "data_partition_with_time", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "data_partition", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.data_partition": [[53, 76], ["open", "line.rstrip().split", "int", "int", "max", "max", "util.SASRecDataSet.User[].append", "len", "util.SASRecDataSet.user_valid[].append", "util.SASRecDataSet.user_test[].append", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "def", "data_partition", "(", "self", ")", ":", "\n", "# assume user/item index starting from 1", "\n", "        ", "f", "=", "open", "(", "self", ".", "filename", ",", "\"r\"", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "u", ",", "i", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "self", ".", "col_sep", ")", "\n", "u", "=", "int", "(", "u", ")", "\n", "i", "=", "int", "(", "i", ")", "\n", "self", ".", "usernum", "=", "max", "(", "u", ",", "self", ".", "usernum", ")", "\n", "self", ".", "itemnum", "=", "max", "(", "i", ",", "self", ".", "itemnum", ")", "\n", "self", ".", "User", "[", "u", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "for", "user", "in", "self", ".", "User", ":", "\n", "            ", "nfeedback", "=", "len", "(", "self", ".", "User", "[", "user", "]", ")", "\n", "if", "nfeedback", "<", "3", ":", "\n", "                ", "self", ".", "user_train", "[", "user", "]", "=", "self", ".", "User", "[", "user", "]", "\n", "self", ".", "user_valid", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_test", "[", "user", "]", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "user_train", "[", "user", "]", "=", "self", ".", "User", "[", "user", "]", "[", ":", "-", "2", "]", "\n", "self", ".", "user_valid", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_valid", "[", "user", "]", ".", "append", "(", "self", ".", "User", "[", "user", "]", "[", "-", "2", "]", ")", "\n", "self", ".", "user_test", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_test", "[", "user", "]", ".", "append", "(", "self", ".", "User", "[", "user", "]", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.data_partition_with_time": [[77, 107], ["open", "util.SASRecDataSet.User.keys", "line.rstrip().split", "int", "int", "float", "max", "max", "util.SASRecDataSet.User[].append", "util.SASRecDataSet.Items.add", "sorted", "len", "util.SASRecDataSet.user_valid[].append", "util.SASRecDataSet.user_test[].append", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "", "", "def", "data_partition_with_time", "(", "self", ")", ":", "\n", "# assume user/item index starting from 1", "\n", "        ", "f", "=", "open", "(", "self", ".", "filename", ",", "\"r\"", ")", "\n", "for", "line", "in", "f", ":", "\n", "            ", "u", ",", "i", ",", "t", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "self", ".", "col_sep", ")", "\n", "u", "=", "int", "(", "u", ")", "\n", "i", "=", "int", "(", "i", ")", "\n", "t", "=", "float", "(", "t", ")", "\n", "self", ".", "usernum", "=", "max", "(", "u", ",", "self", ".", "usernum", ")", "\n", "self", ".", "itemnum", "=", "max", "(", "i", ",", "self", ".", "itemnum", ")", "\n", "self", ".", "User", "[", "u", "]", ".", "append", "(", "(", "i", ",", "t", ")", ")", "\n", "self", ".", "Items", ".", "add", "(", "i", ")", "\n", "\n", "", "for", "user", "in", "self", ".", "User", ".", "keys", "(", ")", ":", "\n", "# sort by time", "\n", "            ", "items", "=", "sorted", "(", "self", ".", "User", "[", "user", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "# keep only the items", "\n", "items", "=", "[", "x", "[", "0", "]", "for", "x", "in", "items", "]", "\n", "self", ".", "User", "[", "user", "]", "=", "items", "\n", "nfeedback", "=", "len", "(", "self", ".", "User", "[", "user", "]", ")", "\n", "if", "nfeedback", "<", "3", ":", "\n", "                ", "self", ".", "user_train", "[", "user", "]", "=", "self", ".", "User", "[", "user", "]", "\n", "self", ".", "user_valid", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_test", "[", "user", "]", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "user_train", "[", "user", "]", "=", "self", ".", "User", "[", "user", "]", "[", ":", "-", "2", "]", "\n", "self", ".", "user_valid", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_valid", "[", "user", "]", ".", "append", "(", "self", ".", "User", "[", "user", "]", "[", "-", "2", "]", ")", "\n", "self", ".", "user_test", "[", "user", "]", "=", "[", "]", "\n", "self", ".", "user_test", "[", "user", "]", ".", "append", "(", "self", ".", "User", "[", "user", "]", "[", "-", "1", "]", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.surprise_trainset_to_df": [[15, 45], ["pandas.DataFrame", "df[].map", "df[].map", "trainset.all_ratings", "recommenders.utils.general_utils.invert_dictionary", "recommenders.utils.general_utils.invert_dictionary"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.invert_dictionary", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.general_utils.invert_dictionary"], ["def", "surprise_trainset_to_df", "(", "\n", "trainset", ",", "col_user", "=", "\"uid\"", ",", "col_item", "=", "\"iid\"", ",", "col_rating", "=", "\"rating\"", "\n", ")", ":", "\n", "    ", "\"\"\"Converts a `surprise.Trainset` object to `pandas.DataFrame`\n\n    More info: https://surprise.readthedocs.io/en/stable/trainset.html\n\n    Args:\n        trainset (object): A surprise.Trainset object.\n        col_user (str): User column name.\n        col_item (str): Item column name.\n        col_rating (str): Rating column name.\n\n    Returns:\n        pandas.DataFrame: A dataframe with user column (str), item column (str), and rating column (float).\n    \"\"\"", "\n", "df", "=", "pd", ".", "DataFrame", "(", "trainset", ".", "all_ratings", "(", ")", ",", "columns", "=", "[", "col_user", ",", "col_item", ",", "col_rating", "]", ")", "\n", "map_user", "=", "(", "\n", "trainset", ".", "_inner2raw_id_users", "\n", "if", "trainset", ".", "_inner2raw_id_users", "is", "not", "None", "\n", "else", "invert_dictionary", "(", "trainset", ".", "_raw2inner_id_users", ")", "\n", ")", "\n", "map_item", "=", "(", "\n", "trainset", ".", "_inner2raw_id_items", "\n", "if", "trainset", ".", "_inner2raw_id_items", "is", "not", "None", "\n", "else", "invert_dictionary", "(", "trainset", ".", "_raw2inner_id_items", ")", "\n", ")", "\n", "df", "[", "col_user", "]", "=", "df", "[", "col_user", "]", ".", "map", "(", "map_user", ")", "\n", "df", "[", "col_item", "]", "=", "df", "[", "col_item", "]", ".", "map", "(", "map_item", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.predict": [[47, 74], ["pandas.DataFrame", "predictions.rename.rename", "predictions.rename.drop", "algo.predict", "getattr", "getattr", "data.itertuples"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "predict", "(", "\n", "algo", ",", "\n", "data", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Computes predictions of an algorithm from Surprise on the data. Can be used for computing rating metrics like RMSE.\n\n    Args:\n        algo (surprise.prediction_algorithms.algo_base.AlgoBase): an algorithm from Surprise\n        data (pandas.DataFrame): the data on which to predict\n        usercol (str): name of the user column\n        itemcol (str): name of the item column\n\n    Returns:\n        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n    \"\"\"", "\n", "predictions", "=", "[", "\n", "algo", ".", "predict", "(", "getattr", "(", "row", ",", "usercol", ")", ",", "getattr", "(", "row", ",", "itemcol", ")", ")", "\n", "for", "row", "in", "data", ".", "itertuples", "(", ")", "\n", "]", "\n", "predictions", "=", "pd", ".", "DataFrame", "(", "predictions", ")", "\n", "predictions", "=", "predictions", ".", "rename", "(", "\n", "index", "=", "str", ",", "columns", "=", "{", "\"uid\"", ":", "usercol", ",", "\"iid\"", ":", "itemcol", ",", "\"est\"", ":", "predcol", "}", "\n", ")", "\n", "return", "predictions", ".", "drop", "(", "[", "\"details\"", ",", "\"r_ui\"", "]", ",", "axis", "=", "\"columns\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions": [[76, 121], ["data[].unique", "data[].unique", "pandas.DataFrame", "pandas.concat", "pandas.merge", "merged[].drop", "preds_lst.append", "pandas.DataFrame", "algo.predict", "numpy.ones", "merged[].isnull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "compute_ranking_predictions", "(", "\n", "algo", ",", "\n", "data", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "remove_seen", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Computes predictions of an algorithm from Surprise on all users and items in data. It can be used for computing\n    ranking metrics like NDCG.\n\n    Args:\n        algo (surprise.prediction_algorithms.algo_base.AlgoBase): an algorithm from Surprise\n        data (pandas.DataFrame): the data from which to get the users and items\n        usercol (str): name of the user column\n        itemcol (str): name of the item column\n        remove_seen (bool): flag to remove (user, item) pairs seen in the training data\n\n    Returns:\n        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n    \"\"\"", "\n", "preds_lst", "=", "[", "]", "\n", "users", "=", "data", "[", "usercol", "]", ".", "unique", "(", ")", "\n", "items", "=", "data", "[", "itemcol", "]", ".", "unique", "(", ")", "\n", "\n", "for", "user", "in", "users", ":", "\n", "        ", "for", "item", "in", "items", ":", "\n", "            ", "preds_lst", ".", "append", "(", "[", "user", ",", "item", ",", "algo", ".", "predict", "(", "user", ",", "item", ")", ".", "est", "]", ")", "\n", "\n", "", "", "all_predictions", "=", "pd", ".", "DataFrame", "(", "data", "=", "preds_lst", ",", "columns", "=", "[", "usercol", ",", "itemcol", ",", "predcol", "]", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "        ", "tempdf", "=", "pd", ".", "concat", "(", "\n", "[", "\n", "data", "[", "[", "usercol", ",", "itemcol", "]", "]", ",", "\n", "pd", ".", "DataFrame", "(", "\n", "data", "=", "np", ".", "ones", "(", "data", ".", "shape", "[", "0", "]", ")", ",", "columns", "=", "[", "\"dummycol\"", "]", ",", "index", "=", "data", ".", "index", "\n", ")", ",", "\n", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "merged", "=", "pd", ".", "merge", "(", "tempdf", ",", "all_predictions", ",", "on", "=", "[", "usercol", ",", "itemcol", "]", ",", "how", "=", "\"outer\"", ")", "\n", "return", "merged", "[", "merged", "[", "\"dummycol\"", "]", ".", "isnull", "(", ")", "]", ".", "drop", "(", "\"dummycol\"", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "return", "all_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.fastai.fastai_utils.cartesian_product": [[14, 30], ["len", "numpy.result_type", "numpy.empty", "enumerate", "np.empty.reshape", "numpy.ix_", "len"], "function", ["None"], ["def", "cartesian_product", "(", "*", "arrays", ")", ":", "\n", "    ", "\"\"\"Compute the Cartesian product in fastai algo. This is a helper function.\n\n    Args:\n        arrays (tuple of numpy.ndarray): Input arrays\n\n    Returns:\n        numpy.ndarray: product\n\n    \"\"\"", "\n", "la", "=", "len", "(", "arrays", ")", "\n", "dtype", "=", "np", ".", "result_type", "(", "*", "arrays", ")", "\n", "arr", "=", "np", ".", "empty", "(", "[", "len", "(", "a", ")", "for", "a", "in", "arrays", "]", "+", "[", "la", "]", ",", "dtype", "=", "dtype", ")", "\n", "for", "i", ",", "a", "in", "enumerate", "(", "np", ".", "ix_", "(", "*", "arrays", ")", ")", ":", "\n", "        ", "arr", "[", "...", ",", "i", "]", "=", "a", "\n", "", "return", "arr", ".", "reshape", "(", "-", "1", ",", "la", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.fastai.fastai_utils.score": [[32, 73], ["learner.data.train_ds.x.classes.values", "learner.get_idx", "learner.get_idx", "learner.model.forward", "pandas.DataFrame", "scores.sort_values.sort_values", "scores.sort_values.groupby().head().reset_index", "scores.sort_values.groupby().head", "test_df[].isin", "test_df[].isin", "scores.sort_values.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["", "def", "score", "(", "\n", "learner", ",", "\n", "test_df", ",", "\n", "user_col", "=", "cc", ".", "DEFAULT_USER_COL", ",", "\n", "item_col", "=", "cc", ".", "DEFAULT_ITEM_COL", ",", "\n", "prediction_col", "=", "cc", ".", "DEFAULT_PREDICTION_COL", ",", "\n", "top_k", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Score all users+items provided and reduce to top_k items per user if top_k>0\n\n    Args:\n        learner (object): Model.\n        test_df (pandas.DataFrame): Test dataframe.\n        user_col (str): User column name.\n        item_col (str): Item column name.\n        prediction_col (str): Prediction column name.\n        top_k (int): Number of top items to recommend.\n\n    Returns:\n        pandas.DataFrame: Result of recommendation\n    \"\"\"", "\n", "# replace values not known to the model with NaN", "\n", "total_users", ",", "total_items", "=", "learner", ".", "data", ".", "train_ds", ".", "x", ".", "classes", ".", "values", "(", ")", "\n", "test_df", ".", "loc", "[", "~", "test_df", "[", "user_col", "]", ".", "isin", "(", "total_users", ")", ",", "user_col", "]", "=", "np", ".", "nan", "\n", "test_df", ".", "loc", "[", "~", "test_df", "[", "item_col", "]", ".", "isin", "(", "total_items", ")", ",", "item_col", "]", "=", "np", ".", "nan", "\n", "\n", "# map ids to embedding ids", "\n", "u", "=", "learner", ".", "get_idx", "(", "test_df", "[", "user_col", "]", ",", "is_item", "=", "False", ")", "\n", "m", "=", "learner", ".", "get_idx", "(", "test_df", "[", "item_col", "]", ",", "is_item", "=", "True", ")", "\n", "\n", "# score the pytorch model", "\n", "pred", "=", "learner", ".", "model", ".", "forward", "(", "u", ",", "m", ")", "\n", "scores", "=", "pd", ".", "DataFrame", "(", "\n", "{", "user_col", ":", "test_df", "[", "user_col", "]", ",", "item_col", ":", "test_df", "[", "item_col", "]", ",", "prediction_col", ":", "pred", "}", "\n", ")", "\n", "scores", "=", "scores", ".", "sort_values", "(", "[", "user_col", ",", "prediction_col", "]", ",", "ascending", "=", "[", "True", ",", "False", "]", ")", "\n", "if", "top_k", "is", "not", "None", ":", "\n", "        ", "top_scores", "=", "scores", ".", "groupby", "(", "user_col", ")", ".", "head", "(", "top_k", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "top_scores", "=", "scores", "\n", "", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.fastai.fastai_utils.hide_fastai_progress_bar": [[75, 83], ["fastprogress.fastprogress.force_console_behavior"], "function", ["None"], ["", "def", "hide_fastai_progress_bar", "(", ")", ":", "\n", "    ", "\"\"\"Hide fastai progress bar\"\"\"", "\n", "fastprogress", ".", "fastprogress", ".", "NO_BAR", "=", "True", "\n", "fastprogress", ".", "fastprogress", ".", "WRITER_FN", "=", "str", "\n", "master_bar", ",", "progress_bar", "=", "force_console_behavior", "(", ")", "\n", "fastai", ".", "basic_train", ".", "master_bar", ",", "fastai", ".", "basic_train", ".", "progress_bar", "=", "(", "\n", "master_bar", ",", "\n", "progress_bar", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.__init__": [[308, 329], ["hparams_dict.values", "setattr", "ValueError", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["def", "__init__", "(", "self", ",", "hparams_dict", ")", ":", "\n", "        ", "\"\"\"Create an HParams object from a dictionary of hyperparameter values.\n\n        Args:\n            hparams_dict (dict): Dictionary with the model hyperparameters.\n        \"\"\"", "\n", "for", "val", "in", "hparams_dict", ".", "values", "(", ")", ":", "\n", "            ", "if", "not", "(", "\n", "isinstance", "(", "val", ",", "int", ")", "\n", "or", "isinstance", "(", "val", ",", "float", ")", "\n", "or", "isinstance", "(", "val", ",", "str", ")", "\n", "or", "isinstance", "(", "val", ",", "list", ")", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Hyperparameter value {} should be integer, float, string or list.\"", ".", "format", "(", "\n", "val", "\n", ")", "\n", ")", "\n", "", "", "self", ".", "_values", "=", "hparams_dict", "\n", "for", "hparam", "in", "hparams_dict", ":", "\n", "            ", "setattr", "(", "self", ",", "hparam", ",", "hparams_dict", "[", "hparam", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.__repr__": [[330, 332], ["deeprec_utils.HParams._values.__repr__"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.__repr__"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"HParams object with values {}\"", ".", "format", "(", "self", ".", "_values", ".", "__repr__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values": [[333, 340], ["None"], "methods", ["None"], ["", "def", "values", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the hyperparameter values as a dictionary.\n\n        Returns:\n            dict: Dictionary with the hyperparameter values.\n        \"\"\"", "\n", "return", "self", ".", "_values", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.flat_config": [[21, 36], ["config.keys", "config[].items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["def", "flat_config", "(", "config", ")", ":", "\n", "    ", "\"\"\"Flat config loaded from a yaml file to a flat dict.\n\n    Args:\n        config (dict): Configuration loaded from a yaml file.\n\n    Returns:\n        dict: Configuration dictionary.\n    \"\"\"", "\n", "f_config", "=", "{", "}", "\n", "category", "=", "config", ".", "keys", "(", ")", "\n", "for", "cate", "in", "category", ":", "\n", "        ", "for", "key", ",", "val", "in", "config", "[", "cate", "]", ".", "items", "(", ")", ":", "\n", "            ", "f_config", "[", "key", "]", "=", "val", "\n", "", "", "return", "f_config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_type": [[38, 132], ["TypeError", "TypeError", "TypeError", "TypeError", "isinstance", "isinstance", "isinstance", "isinstance"], "function", ["None"], ["", "def", "check_type", "(", "config", ")", ":", "\n", "    ", "\"\"\"Check that the config parameters are the correct type\n\n    Args:\n        config (dict): Configuration dictionary.\n\n    Raises:\n        TypeError: If the parameters are not the correct type.\n    \"\"\"", "\n", "\n", "int_parameters", "=", "[", "\n", "\"word_size\"", ",", "\n", "\"entity_size\"", ",", "\n", "\"doc_size\"", ",", "\n", "\"history_size\"", ",", "\n", "\"FEATURE_COUNT\"", ",", "\n", "\"FIELD_COUNT\"", ",", "\n", "\"dim\"", ",", "\n", "\"epochs\"", ",", "\n", "\"batch_size\"", ",", "\n", "\"show_step\"", ",", "\n", "\"save_epoch\"", ",", "\n", "\"PAIR_NUM\"", ",", "\n", "\"DNN_FIELD_NUM\"", ",", "\n", "\"attention_layer_sizes\"", ",", "\n", "\"n_user\"", ",", "\n", "\"n_item\"", ",", "\n", "\"n_user_attr\"", ",", "\n", "\"n_item_attr\"", ",", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"user_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"hidden_size\"", ",", "\n", "\"T\"", ",", "\n", "\"L\"", ",", "\n", "\"n_v\"", ",", "\n", "\"n_h\"", ",", "\n", "\"kernel_size\"", ",", "\n", "\"min_seq_length\"", ",", "\n", "\"attention_size\"", ",", "\n", "\"epochs\"", ",", "\n", "\"batch_size\"", ",", "\n", "\"show_step\"", ",", "\n", "\"save_epoch\"", ",", "\n", "\"train_num_ngs\"", ",", "\n", "]", "\n", "for", "param", "in", "int_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be int\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "float_parameters", "=", "[", "\n", "\"init_value\"", ",", "\n", "\"learning_rate\"", ",", "\n", "\"embed_l2\"", ",", "\n", "\"embed_l1\"", ",", "\n", "\"layer_l2\"", ",", "\n", "\"layer_l1\"", ",", "\n", "\"mu\"", ",", "\n", "]", "\n", "for", "param", "in", "float_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "float", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be float\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "str_parameters", "=", "[", "\n", "\"train_file\"", ",", "\n", "\"eval_file\"", ",", "\n", "\"test_file\"", ",", "\n", "\"infer_file\"", ",", "\n", "\"method\"", ",", "\n", "\"load_model_name\"", ",", "\n", "\"infer_model_name\"", ",", "\n", "\"loss\"", ",", "\n", "\"optimizer\"", ",", "\n", "\"init_method\"", ",", "\n", "\"attention_activation\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "]", "\n", "for", "param", "in", "str_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be str\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "list_parameters", "=", "[", "\n", "\"layer_sizes\"", ",", "\n", "\"activation\"", ",", "\n", "\"dropout\"", ",", "\n", "\"att_fcn_layer_sizes\"", ",", "\n", "\"dilations\"", ",", "\n", "]", "\n", "for", "param", "in", "list_parameters", ":", "\n", "        ", "if", "param", "in", "config", "and", "not", "isinstance", "(", "config", "[", "param", "]", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Parameters {0} must be list\"", ".", "format", "(", "param", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_nn_config": [[134, 284], ["deeprec_utils.check_type", "ValueError", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_type"], ["", "", "", "def", "check_nn_config", "(", "f_config", ")", ":", "\n", "    ", "\"\"\"Check neural networks configuration.\n\n    Args:\n        f_config (dict): Neural network configuration.\n\n    Raises:\n        ValueError: If the parameters are not correct.\n    \"\"\"", "\n", "if", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"fm\"", ",", "\"FM\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\"FEATURE_COUNT\"", ",", "\"dim\"", ",", "\"loss\"", ",", "\"data_format\"", ",", "\"method\"", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"lr\"", ",", "\"LR\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\"FEATURE_COUNT\"", ",", "\"loss\"", ",", "\"data_format\"", ",", "\"method\"", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"dkn\"", ",", "\"DKN\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"doc_size\"", ",", "\n", "\"history_size\"", ",", "\n", "\"wordEmb_file\"", ",", "\n", "\"entityEmb_file\"", ",", "\n", "\"contextEmb_file\"", ",", "\n", "\"news_feature_file\"", ",", "\n", "\"user_history_file\"", ",", "\n", "\"word_size\"", ",", "\n", "\"entity_size\"", ",", "\n", "\"use_entity\"", ",", "\n", "\"use_context\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dim\"", ",", "\n", "\"layer_sizes\"", ",", "\n", "\"activation\"", ",", "\n", "\"attention_activation\"", ",", "\n", "\"attention_activation\"", ",", "\n", "\"attention_dropout\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "\"method\"", ",", "\n", "\"num_filters\"", ",", "\n", "\"filter_sizes\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"exDeepFM\"", ",", "\"xDeepFM\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"FIELD_COUNT\"", ",", "\n", "\"FEATURE_COUNT\"", ",", "\n", "\"method\"", ",", "\n", "\"dim\"", ",", "\n", "\"layer_sizes\"", ",", "\n", "\"cross_layer_sizes\"", ",", "\n", "\"activation\"", ",", "\n", "\"loss\"", ",", "\n", "\"data_format\"", ",", "\n", "\"dropout\"", ",", "\n", "]", "\n", "", "if", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"gru4rec\"", ",", "\"GRU4REC\"", ",", "\"GRU4Rec\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"loss\"", ",", "\n", "\"method\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "\"hidden_size\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"caser\"", ",", "\"CASER\"", ",", "\"Caser\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"user_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"loss\"", ",", "\n", "\"method\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "\"T\"", ",", "\n", "\"L\"", ",", "\n", "\"n_v\"", ",", "\n", "\"n_h\"", ",", "\n", "\"min_seq_length\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"asvd\"", ",", "\"ASVD\"", ",", "\"a2svd\"", ",", "\"A2SVD\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"loss\"", ",", "\n", "\"method\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"slirec\"", ",", "\"sli_rec\"", ",", "\"SLI_REC\"", ",", "\"Sli_rec\"", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"loss\"", ",", "\n", "\"method\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "\"attention_size\"", ",", "\n", "\"hidden_size\"", ",", "\n", "\"att_fcn_layer_sizes\"", ",", "\n", "]", "\n", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\n", "\"nextitnet\"", ",", "\n", "\"next_it_net\"", ",", "\n", "\"NextItNet\"", ",", "\n", "\"NEXT_IT_NET\"", ",", "\n", "]", ":", "\n", "        ", "required_parameters", "=", "[", "\n", "\"item_embedding_dim\"", ",", "\n", "\"cate_embedding_dim\"", ",", "\n", "\"user_embedding_dim\"", ",", "\n", "\"max_seq_length\"", ",", "\n", "\"loss\"", ",", "\n", "\"method\"", ",", "\n", "\"user_vocab\"", ",", "\n", "\"item_vocab\"", ",", "\n", "\"cate_vocab\"", ",", "\n", "\"dilations\"", ",", "\n", "\"kernel_size\"", ",", "\n", "\"min_seq_length\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "required_parameters", "=", "[", "]", "\n", "\n", "# check required parameters", "\n", "", "for", "param", "in", "required_parameters", ":", "\n", "        ", "if", "param", "not", "in", "f_config", ":", "\n", "            ", "raise", "ValueError", "(", "\"Parameters {0} must be set\"", ".", "format", "(", "param", ")", ")", "\n", "\n", "", "", "if", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"exDeepFM\"", ",", "\"xDeepFM\"", "]", ":", "\n", "        ", "if", "f_config", "[", "\"data_format\"", "]", "!=", "\"ffm\"", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"For xDeepFM model, data format must be 'ffm', but your set is {0}\"", ".", "format", "(", "\n", "f_config", "[", "\"data_format\"", "]", "\n", ")", "\n", ")", "\n", "", "", "elif", "f_config", "[", "\"model_type\"", "]", "in", "[", "\"dkn\"", ",", "\"DKN\"", "]", ":", "\n", "        ", "if", "f_config", "[", "\"data_format\"", "]", "!=", "\"dkn\"", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"For dkn model, data format must be 'dkn', but your set is {0}\"", ".", "format", "(", "\n", "f_config", "[", "\"data_format\"", "]", "\n", ")", "\n", ")", "\n", "", "", "check_type", "(", "f_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_yaml": [[286, 303], ["open", "yaml.load", "IOError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "load_yaml", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Load a yaml file.\n\n    Args:\n        filename (str): Filename.\n\n    Returns:\n        dict: Dictionary.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ",", "yaml", ".", "SafeLoader", ")", "\n", "", "return", "config", "\n", "", "except", "FileNotFoundError", ":", "# for file not found", "\n", "        ", "raise", "\n", "", "except", "Exception", ":", "# for other exceptions", "\n", "        ", "raise", "IOError", "(", "\"load {0} error!\"", ".", "format", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.create_hparams": [[342, 405], ["init_dict.update", "deeprec_utils.HParams"], "function", ["None"], ["", "", "def", "create_hparams", "(", "flags", ")", ":", "\n", "    ", "\"\"\"Create the model hyperparameters.\n\n    Args:\n        flags (dict): Dictionary with the model requirements.\n\n    Returns:\n        HParams: Hyperparameter object.\n    \"\"\"", "\n", "init_dict", "=", "{", "\n", "# dkn", "\n", "\"use_entity\"", ":", "True", ",", "\n", "\"use_context\"", ":", "True", ",", "\n", "# model", "\n", "\"cross_activation\"", ":", "\"identity\"", ",", "\n", "\"user_dropout\"", ":", "False", ",", "\n", "\"dropout\"", ":", "[", "0.0", "]", ",", "\n", "\"attention_dropout\"", ":", "0.0", ",", "\n", "\"load_saved_model\"", ":", "False", ",", "\n", "\"fast_CIN_d\"", ":", "0", ",", "\n", "\"use_Linear_part\"", ":", "False", ",", "\n", "\"use_FM_part\"", ":", "False", ",", "\n", "\"use_CIN_part\"", ":", "False", ",", "\n", "\"use_DNN_part\"", ":", "False", ",", "\n", "# train", "\n", "\"init_method\"", ":", "\"tnormal\"", ",", "\n", "\"init_value\"", ":", "0.01", ",", "\n", "\"embed_l2\"", ":", "0.0", ",", "\n", "\"embed_l1\"", ":", "0.0", ",", "\n", "\"layer_l2\"", ":", "0.0", ",", "\n", "\"layer_l1\"", ":", "0.0", ",", "\n", "\"cross_l2\"", ":", "0.0", ",", "\n", "\"cross_l1\"", ":", "0.0", ",", "\n", "\"reg_kg\"", ":", "0.0", ",", "\n", "\"learning_rate\"", ":", "0.001", ",", "\n", "\"lr_rs\"", ":", "1", ",", "\n", "\"lr_kg\"", ":", "0.5", ",", "\n", "\"kg_training_interval\"", ":", "5", ",", "\n", "\"max_grad_norm\"", ":", "2", ",", "\n", "\"is_clip_norm\"", ":", "0", ",", "\n", "\"dtype\"", ":", "32", ",", "\n", "\"optimizer\"", ":", "\"adam\"", ",", "\n", "\"epochs\"", ":", "10", ",", "\n", "\"batch_size\"", ":", "1", ",", "\n", "\"enable_BN\"", ":", "False", ",", "\n", "# show info", "\n", "\"show_step\"", ":", "1", ",", "\n", "\"save_model\"", ":", "True", ",", "\n", "\"save_epoch\"", ":", "5", ",", "\n", "\"write_tfevents\"", ":", "False", ",", "\n", "# sequential", "\n", "\"train_num_ngs\"", ":", "4", ",", "\n", "\"need_sample\"", ":", "True", ",", "\n", "\"embedding_dropout\"", ":", "0.0", ",", "\n", "\"EARLY_STOP\"", ":", "100", ",", "\n", "# caser,", "\n", "\"min_seq_length\"", ":", "1", ",", "\n", "# sum", "\n", "\"slots\"", ":", "5", ",", "\n", "\"cell\"", ":", "\"SUM\"", ",", "\n", "}", "\n", "init_dict", ".", "update", "(", "flags", ")", "\n", "return", "HParams", "(", "init_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams": [[407, 428], ["deeprec_utils.check_nn_config", "deeprec_utils.create_hparams", "deeprec_utils.load_yaml", "deeprec_utils.flat_config", "kwargs.items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.check_nn_config", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.create_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_yaml", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.flat_config", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "prepare_hparams", "(", "yaml_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Prepare the model hyperparameters and check that all have the correct value.\n\n    Args:\n        yaml_file (str): YAML file as configuration.\n\n    Returns:\n        HParams: Hyperparameter object.\n    \"\"\"", "\n", "if", "yaml_file", "is", "not", "None", ":", "\n", "        ", "config", "=", "load_yaml", "(", "yaml_file", ")", "\n", "config", "=", "flat_config", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "{", "}", "\n", "\n", "", "if", "kwargs", ":", "\n", "        ", "for", "name", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "config", "[", "name", "]", "=", "value", "\n", "\n", "", "", "check_nn_config", "(", "config", ")", "\n", "return", "create_hparams", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources": [[430, 445], ["os.makedirs", "recommenders.datasets.download_utils.maybe_download", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.remove", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.download_utils.maybe_download", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close"], ["", "def", "download_deeprec_resources", "(", "azure_container_url", ",", "data_path", ",", "remote_resource_name", ")", ":", "\n", "    ", "\"\"\"Download resources.\n\n    Args:\n        azure_container_url (str): URL of Azure container.\n        data_path (str): Path to download the resources.\n        remote_resource_name (str): Name of the resource.\n    \"\"\"", "\n", "os", ".", "makedirs", "(", "data_path", ",", "exist_ok", "=", "True", ")", "\n", "remote_path", "=", "azure_container_url", "+", "remote_resource_name", "\n", "maybe_download", "(", "remote_path", ",", "remote_resource_name", ",", "data_path", ")", "\n", "zip_ref", "=", "zipfile", ".", "ZipFile", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "remote_resource_name", ")", ",", "\"r\"", ")", "\n", "zip_ref", ".", "extractall", "(", "data_path", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "remote_resource_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.mrr_score": [[447, 461], ["numpy.take", "numpy.argsort", "numpy.sum", "numpy.sum", "numpy.arange", "len"], "function", ["None"], ["", "def", "mrr_score", "(", "y_true", ",", "y_score", ")", ":", "\n", "    ", "\"\"\"Computing mrr score metric.\n\n    Args:\n        y_true (np.ndarray): Ground-truth labels.\n        y_score (np.ndarray): Predicted labels.\n\n    Returns:\n        numpy.ndarray: mrr scores.\n    \"\"\"", "\n", "order", "=", "np", ".", "argsort", "(", "y_score", ")", "[", ":", ":", "-", "1", "]", "\n", "y_true", "=", "np", ".", "take", "(", "y_true", ",", "order", ")", "\n", "rr_score", "=", "y_true", "/", "(", "np", ".", "arange", "(", "len", "(", "y_true", ")", ")", "+", "1", ")", "\n", "return", "np", ".", "sum", "(", "rr_score", ")", "/", "np", ".", "sum", "(", "y_true", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.ndcg_score": [[463, 476], ["deeprec_utils.dcg_score", "deeprec_utils.dcg_score"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.dcg_score", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.dcg_score"], ["", "def", "ndcg_score", "(", "y_true", ",", "y_score", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"Computing ndcg score metric at k.\n\n    Args:\n        y_true (np.ndarray): Ground-truth labels.\n        y_score (np.ndarray): Predicted labels.\n\n    Returns:\n        numpy.ndarray: ndcg scores.\n    \"\"\"", "\n", "best", "=", "dcg_score", "(", "y_true", ",", "y_true", ",", "k", ")", "\n", "actual", "=", "dcg_score", "(", "y_true", ",", "y_score", ",", "k", ")", "\n", "return", "actual", "/", "best", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.hit_score": [[478, 494], ["numpy.where", "numpy.argsort"], "function", ["None"], ["", "def", "hit_score", "(", "y_true", ",", "y_score", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"Computing hit score metric at k.\n\n    Args:\n        y_true (np.ndarray): ground-truth labels.\n        y_score (np.ndarray): predicted labels.\n\n    Returns:\n        np.ndarray: hit score.\n    \"\"\"", "\n", "ground_truth", "=", "np", ".", "where", "(", "y_true", "==", "1", ")", "[", "0", "]", "\n", "argsort", "=", "np", ".", "argsort", "(", "y_score", ")", "[", ":", ":", "-", "1", "]", "[", ":", "k", "]", "\n", "for", "idx", "in", "argsort", ":", "\n", "        ", "if", "idx", "in", "ground_truth", ":", "\n", "            ", "return", "1", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.dcg_score": [[496, 512], ["min", "numpy.take", "numpy.log2", "numpy.sum", "numpy.argsort", "numpy.shape", "numpy.arange", "len"], "function", ["None"], ["", "def", "dcg_score", "(", "y_true", ",", "y_score", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"Computing dcg score metric at k.\n\n    Args:\n        y_true (np.ndarray): Ground-truth labels.\n        y_score (np.ndarray): Predicted labels.\n\n    Returns:\n        np.ndarray: dcg scores.\n    \"\"\"", "\n", "k", "=", "min", "(", "np", ".", "shape", "(", "y_true", ")", "[", "-", "1", "]", ",", "k", ")", "\n", "order", "=", "np", ".", "argsort", "(", "y_score", ")", "[", ":", ":", "-", "1", "]", "\n", "y_true", "=", "np", ".", "take", "(", "y_true", ",", "order", "[", ":", "k", "]", ")", "\n", "gains", "=", "2", "**", "y_true", "-", "1", "\n", "discounts", "=", "np", ".", "log2", "(", "np", ".", "arange", "(", "len", "(", "y_true", ")", ")", "+", "2", ")", "\n", "return", "np", ".", "sum", "(", "gains", "/", "discounts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric": [[514, 603], ["sklearn.metrics.roc_auc_score", "round", "numpy.asarray", "numpy.asarray", "sklearn.metrics.mean_squared_error", "numpy.sqrt", "numpy.asarray", "numpy.asarray", "round", "sklearn.metrics.log_loss", "round", "max", "numpy.asarray", "numpy.asarray", "numpy.asarray", "sklearn.metrics.accuracy_score", "round", "min", "numpy.asarray", "numpy.asarray", "sklearn.metrics.f1_score", "round", "numpy.asarray", "numpy.mean", "round", "metric.startswith", "metric.split", "metric.startswith", "deeprec_utils.mrr_score", "len", "numpy.mean", "round", "metric.split", "zip", "int", "len", "numpy.mean", "round", "numpy.mean", "round", "ValueError", "ks[].split", "deeprec_utils.ndcg_score", "int", "zip", "ks[].split", "deeprec_utils.hit_score", "sklearn.metrics.roc_auc_score", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.mrr_score", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.ndcg_score", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.hit_score"], ["", "def", "cal_metric", "(", "labels", ",", "preds", ",", "metrics", ")", ":", "\n", "    ", "\"\"\"Calculate metrics.\n\n    Available options are: `auc`, `rmse`, `logloss`, `acc` (accurary), `f1`, `mean_mrr`,\n    `ndcg` (format like: ndcg@2;4;6;8), `hit` (format like: hit@2;4;6;8), `group_auc`.\n\n    Args:\n        labels (array-like): Labels.\n        preds (array-like): Predictions.\n        metrics (list): List of metric names.\n\n    Return:\n        dict: Metrics.\n\n    Examples:\n        >>> cal_metric(labels, preds, [\"ndcg@2;4;6\", \"group_auc\"])\n        {'ndcg@2': 0.4026, 'ndcg@4': 0.4953, 'ndcg@6': 0.5346, 'group_auc': 0.8096}\n\n    \"\"\"", "\n", "res", "=", "{", "}", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "if", "metric", "==", "\"auc\"", ":", "\n", "            ", "auc", "=", "roc_auc_score", "(", "np", ".", "asarray", "(", "labels", ")", ",", "np", ".", "asarray", "(", "preds", ")", ")", "\n", "res", "[", "\"auc\"", "]", "=", "round", "(", "auc", ",", "4", ")", "\n", "", "elif", "metric", "==", "\"rmse\"", ":", "\n", "            ", "rmse", "=", "mean_squared_error", "(", "np", ".", "asarray", "(", "labels", ")", ",", "np", ".", "asarray", "(", "preds", ")", ")", "\n", "res", "[", "\"rmse\"", "]", "=", "np", ".", "sqrt", "(", "round", "(", "rmse", ",", "4", ")", ")", "\n", "", "elif", "metric", "==", "\"logloss\"", ":", "\n", "# avoid logloss nan", "\n", "            ", "preds", "=", "[", "max", "(", "min", "(", "p", ",", "1.0", "-", "10e-12", ")", ",", "10e-12", ")", "for", "p", "in", "preds", "]", "\n", "logloss", "=", "log_loss", "(", "np", ".", "asarray", "(", "labels", ")", ",", "np", ".", "asarray", "(", "preds", ")", ")", "\n", "res", "[", "\"logloss\"", "]", "=", "round", "(", "logloss", ",", "4", ")", "\n", "", "elif", "metric", "==", "\"acc\"", ":", "\n", "            ", "pred", "=", "np", ".", "asarray", "(", "preds", ")", "\n", "pred", "[", "pred", ">=", "0.5", "]", "=", "1", "\n", "pred", "[", "pred", "<", "0.5", "]", "=", "0", "\n", "acc", "=", "accuracy_score", "(", "np", ".", "asarray", "(", "labels", ")", ",", "pred", ")", "\n", "res", "[", "\"acc\"", "]", "=", "round", "(", "acc", ",", "4", ")", "\n", "", "elif", "metric", "==", "\"f1\"", ":", "\n", "            ", "pred", "=", "np", ".", "asarray", "(", "preds", ")", "\n", "pred", "[", "pred", ">=", "0.5", "]", "=", "1", "\n", "pred", "[", "pred", "<", "0.5", "]", "=", "0", "\n", "f1", "=", "f1_score", "(", "np", ".", "asarray", "(", "labels", ")", ",", "pred", ")", "\n", "res", "[", "\"f1\"", "]", "=", "round", "(", "f1", ",", "4", ")", "\n", "", "elif", "metric", "==", "\"mean_mrr\"", ":", "\n", "            ", "mean_mrr", "=", "np", ".", "mean", "(", "\n", "[", "\n", "mrr_score", "(", "each_labels", ",", "each_preds", ")", "\n", "for", "each_labels", ",", "each_preds", "in", "zip", "(", "labels", ",", "preds", ")", "\n", "]", "\n", ")", "\n", "res", "[", "\"mean_mrr\"", "]", "=", "round", "(", "mean_mrr", ",", "4", ")", "\n", "", "elif", "metric", ".", "startswith", "(", "\"ndcg\"", ")", ":", "# format like:  ndcg@2;4;6;8", "\n", "            ", "ndcg_list", "=", "[", "1", ",", "2", "]", "\n", "ks", "=", "metric", ".", "split", "(", "\"@\"", ")", "\n", "if", "len", "(", "ks", ")", ">", "1", ":", "\n", "                ", "ndcg_list", "=", "[", "int", "(", "token", ")", "for", "token", "in", "ks", "[", "1", "]", ".", "split", "(", "\";\"", ")", "]", "\n", "", "for", "k", "in", "ndcg_list", ":", "\n", "                ", "ndcg_temp", "=", "np", ".", "mean", "(", "\n", "[", "\n", "ndcg_score", "(", "each_labels", ",", "each_preds", ",", "k", ")", "\n", "for", "each_labels", ",", "each_preds", "in", "zip", "(", "labels", ",", "preds", ")", "\n", "]", "\n", ")", "\n", "res", "[", "\"ndcg@{0}\"", ".", "format", "(", "k", ")", "]", "=", "round", "(", "ndcg_temp", ",", "4", ")", "\n", "", "", "elif", "metric", ".", "startswith", "(", "\"hit\"", ")", ":", "# format like:  hit@2;4;6;8", "\n", "            ", "hit_list", "=", "[", "1", ",", "2", "]", "\n", "ks", "=", "metric", ".", "split", "(", "\"@\"", ")", "\n", "if", "len", "(", "ks", ")", ">", "1", ":", "\n", "                ", "hit_list", "=", "[", "int", "(", "token", ")", "for", "token", "in", "ks", "[", "1", "]", ".", "split", "(", "\";\"", ")", "]", "\n", "", "for", "k", "in", "hit_list", ":", "\n", "                ", "hit_temp", "=", "np", ".", "mean", "(", "\n", "[", "\n", "hit_score", "(", "each_labels", ",", "each_preds", ",", "k", ")", "\n", "for", "each_labels", ",", "each_preds", "in", "zip", "(", "labels", ",", "preds", ")", "\n", "]", "\n", ")", "\n", "res", "[", "\"hit@{0}\"", ".", "format", "(", "k", ")", "]", "=", "round", "(", "hit_temp", ",", "4", ")", "\n", "", "", "elif", "metric", "==", "\"group_auc\"", ":", "\n", "            ", "group_auc", "=", "np", ".", "mean", "(", "\n", "[", "\n", "roc_auc_score", "(", "each_labels", ",", "each_preds", ")", "\n", "for", "each_labels", ",", "each_preds", "in", "zip", "(", "labels", ",", "preds", ")", "\n", "]", "\n", ")", "\n", "res", "[", "\"group_auc\"", "]", "=", "round", "(", "group_auc", ",", "4", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Metric {0} not defined\"", ".", "format", "(", "metric", ")", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict": [[605, 617], ["open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "load_dict", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Load the vocabularies.\n\n    Args:\n        filename (str): Filename of user, item or category vocabulary.\n\n    Returns:\n        dict: A saved vocabulary.\n    \"\"\"", "\n", "with", "open", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "f_pkl", "=", "pkl", ".", "load", "(", "f", ")", "\n", "return", "f_pkl", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.__init__": [[31, 120], ["tensorflow.compat.v1.set_random_seed", "numpy.random.seed", "data.get_norm_adj_mat", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "lightgcn.LightGCN._init_weights", "lightgcn.LightGCN._create_lightgcn_embed", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.matmul", "lightgcn.LightGCN._create_bpr_loss", "tensorflow.compat.v1.train.AdamOptimizer().minimize", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.GPUOptions", "tensorflow.compat.v1.Session", "lightgcn.LightGCN.sess.run", "tensorflow.compat.v1.global_variables_initializer", "ValueError", "tensorflow.compat.v1.train.AdamOptimizer", "tensorflow.compat.v1.ConfigProto"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.get_norm_adj_mat", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._init_weights", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._create_lightgcn_embed", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._create_bpr_loss"], ["def", "__init__", "(", "self", ",", "hparams", ",", "data", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializing the model. Create parameters, placeholders, embeddings and loss function.\n\n        Args:\n            hparams (HParams): A HParams object, hold the entire set of hyperparameters.\n            data (object): A recommenders.models.deeprec.DataModel.ImplicitCF object, load and process data.\n            seed (int): Seed.\n\n        \"\"\"", "\n", "\n", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "epochs", "=", "hparams", ".", "epochs", "\n", "self", ".", "lr", "=", "hparams", ".", "learning_rate", "\n", "self", ".", "emb_dim", "=", "hparams", ".", "embed_size", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "self", ".", "n_layers", "=", "hparams", ".", "n_layers", "\n", "self", ".", "decay", "=", "hparams", ".", "decay", "\n", "self", ".", "eval_epoch", "=", "hparams", ".", "eval_epoch", "\n", "self", ".", "top_k", "=", "hparams", ".", "top_k", "\n", "self", ".", "save_model", "=", "hparams", ".", "save_model", "\n", "self", ".", "save_epoch", "=", "hparams", ".", "save_epoch", "\n", "self", ".", "metrics", "=", "hparams", ".", "metrics", "\n", "self", ".", "model_dir", "=", "hparams", ".", "MODEL_DIR", "\n", "\n", "metric_options", "=", "[", "\"map\"", ",", "\"ndcg\"", ",", "\"precision\"", ",", "\"recall\"", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "metric_options", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong metric(s), please select one of this list: {}\"", ".", "format", "(", "\n", "metric_options", "\n", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "norm_adj", "=", "data", ".", "get_norm_adj_mat", "(", ")", "\n", "\n", "self", ".", "n_users", "=", "data", ".", "n_users", "\n", "self", ".", "n_items", "=", "data", ".", "n_items", "\n", "\n", "self", ".", "users", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "self", ".", "pos_items", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "self", ".", "neg_items", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "self", ".", "weights", "=", "self", ".", "_init_weights", "(", ")", "\n", "self", ".", "ua_embeddings", ",", "self", ".", "ia_embeddings", "=", "self", ".", "_create_lightgcn_embed", "(", ")", "\n", "\n", "self", ".", "u_g_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "ua_embeddings", ",", "ids", "=", "self", ".", "users", "\n", ")", "\n", "self", ".", "pos_i_g_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "ia_embeddings", ",", "ids", "=", "self", ".", "pos_items", "\n", ")", "\n", "self", ".", "neg_i_g_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "ia_embeddings", ",", "ids", "=", "self", ".", "neg_items", "\n", ")", "\n", "self", ".", "u_g_embeddings_pre", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "weights", "[", "\"user_embedding\"", "]", ",", "ids", "=", "self", ".", "users", "\n", ")", "\n", "self", ".", "pos_i_g_embeddings_pre", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "weights", "[", "\"item_embedding\"", "]", ",", "ids", "=", "self", ".", "pos_items", "\n", ")", "\n", "self", ".", "neg_i_g_embeddings_pre", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "weights", "[", "\"item_embedding\"", "]", ",", "ids", "=", "self", ".", "neg_items", "\n", ")", "\n", "\n", "self", ".", "batch_ratings", "=", "tf", ".", "matmul", "(", "\n", "self", ".", "u_g_embeddings", ",", "\n", "self", ".", "pos_i_g_embeddings", ",", "\n", "transpose_a", "=", "False", ",", "\n", "transpose_b", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "mf_loss", ",", "self", ".", "emb_loss", "=", "self", ".", "_create_bpr_loss", "(", "\n", "self", ".", "u_g_embeddings", ",", "self", ".", "pos_i_g_embeddings", ",", "self", ".", "neg_i_g_embeddings", "\n", ")", "\n", "self", ".", "loss", "=", "self", ".", "mf_loss", "+", "self", ".", "emb_loss", "\n", "\n", "self", ".", "opt", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr", ")", ".", "minimize", "(", "\n", "self", ".", "loss", "\n", ")", "\n", "self", ".", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "gpu_options", "=", "tf", ".", "compat", ".", "v1", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", "self", ".", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "\n", "config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._init_weights": [[121, 142], ["dict", "tensorflow.compat.v1.keras.initializers.VarianceScaling", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.compat.v1.keras.initializers.VarianceScaling.", "tensorflow.compat.v1.keras.initializers.VarianceScaling."], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize user and item embeddings.\n\n        Returns:\n            dict: With keys `user_embedding` and `item_embedding`, embeddings of all users and items.\n\n        \"\"\"", "\n", "all_weights", "=", "dict", "(", ")", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", "\n", "scale", "=", "1.0", ",", "mode", "=", "\"fan_avg\"", ",", "distribution", "=", "\"uniform\"", "\n", ")", "\n", "\n", "all_weights", "[", "\"user_embedding\"", "]", "=", "tf", ".", "Variable", "(", "\n", "initializer", "(", "[", "self", ".", "n_users", ",", "self", ".", "emb_dim", "]", ")", ",", "name", "=", "\"user_embedding\"", "\n", ")", "\n", "all_weights", "[", "\"item_embedding\"", "]", "=", "tf", ".", "Variable", "(", "\n", "initializer", "(", "[", "self", ".", "n_items", ",", "self", ".", "emb_dim", "]", ")", ",", "name", "=", "\"item_embedding\"", "\n", ")", "\n", "print", "(", "\"Using xavier initialization.\"", ")", "\n", "\n", "return", "all_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._create_lightgcn_embed": [[143, 169], ["lightgcn.LightGCN._convert_sp_mat_to_sp_tensor", "tensorflow.concat", "range", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.split", "tensorflow.sparse.sparse_dense_matmul"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._convert_sp_mat_to_sp_tensor", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "_create_lightgcn_embed", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the average embeddings of users and items after every layer of the model.\n\n        Returns:\n            tf.Tensor, tf.Tensor: Average user embeddings. Average item embeddings.\n\n        \"\"\"", "\n", "A_hat", "=", "self", ".", "_convert_sp_mat_to_sp_tensor", "(", "self", ".", "norm_adj", ")", "\n", "\n", "ego_embeddings", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "weights", "[", "\"user_embedding\"", "]", ",", "self", ".", "weights", "[", "\"item_embedding\"", "]", "]", ",", "axis", "=", "0", "\n", ")", "\n", "all_embeddings", "=", "[", "ego_embeddings", "]", "\n", "\n", "for", "k", "in", "range", "(", "0", ",", "self", ".", "n_layers", ")", ":", "\n", "            ", "ego_embeddings", "=", "tf", ".", "sparse", ".", "sparse_dense_matmul", "(", "A_hat", ",", "ego_embeddings", ")", "\n", "all_embeddings", "+=", "[", "ego_embeddings", "]", "\n", "\n", "", "all_embeddings", "=", "tf", ".", "stack", "(", "all_embeddings", ",", "1", ")", "\n", "all_embeddings", "=", "tf", ".", "reduce_mean", "(", "\n", "input_tensor", "=", "all_embeddings", ",", "axis", "=", "1", ",", "keepdims", "=", "False", "\n", ")", "\n", "u_g_embeddings", ",", "i_g_embeddings", "=", "tf", ".", "split", "(", "\n", "all_embeddings", ",", "[", "self", ".", "n_users", ",", "self", ".", "n_items", "]", ",", "0", "\n", ")", "\n", "return", "u_g_embeddings", ",", "i_g_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._create_bpr_loss": [[170, 196], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.nn.l2_loss", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.nn.softplus"], "methods", ["None"], ["", "def", "_create_bpr_loss", "(", "self", ",", "users", ",", "pos_items", ",", "neg_items", ")", ":", "\n", "        ", "\"\"\"Calculate BPR loss.\n\n        Args:\n            users (tf.Tensor): User embeddings to calculate loss.\n            pos_items (tf.Tensor): Positive item embeddings to calculate loss.\n            neg_items (tf.Tensor): Negative item embeddings to calculate loss.\n\n        Returns:\n            tf.Tensor, tf.Tensor: Matrix factorization loss. Embedding regularization loss.\n\n        \"\"\"", "\n", "pos_scores", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "multiply", "(", "users", ",", "pos_items", ")", ",", "axis", "=", "1", ")", "\n", "neg_scores", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "multiply", "(", "users", ",", "neg_items", ")", ",", "axis", "=", "1", ")", "\n", "\n", "regularizer", "=", "(", "\n", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "u_g_embeddings_pre", ")", "\n", "+", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "pos_i_g_embeddings_pre", ")", "\n", "+", "tf", ".", "nn", ".", "l2_loss", "(", "self", ".", "neg_i_g_embeddings_pre", ")", "\n", ")", "\n", "regularizer", "=", "regularizer", "/", "self", ".", "batch_size", "\n", "mf_loss", "=", "tf", ".", "reduce_mean", "(", "\n", "input_tensor", "=", "tf", ".", "nn", ".", "softplus", "(", "-", "(", "pos_scores", "-", "neg_scores", ")", ")", "\n", ")", "\n", "emb_loss", "=", "self", ".", "decay", "*", "regularizer", "\n", "return", "mf_loss", ",", "emb_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN._convert_sp_mat_to_sp_tensor": [[197, 207], ["X.tocoo().astype", "numpy.mat().transpose", "tensorflow.SparseTensor", "X.tocoo", "numpy.mat"], "methods", ["None"], ["", "def", "_convert_sp_mat_to_sp_tensor", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"Convert a scipy sparse matrix to tf.SparseTensor.\n\n        Returns:\n            tf.SparseTensor: SparseTensor after conversion.\n\n        \"\"\"", "\n", "coo", "=", "X", ".", "tocoo", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "indices", "=", "np", ".", "mat", "(", "[", "coo", ".", "row", ",", "coo", ".", "col", "]", ")", ".", "transpose", "(", ")", "\n", "return", "tf", ".", "SparseTensor", "(", "indices", ",", "coo", ".", "data", ",", "coo", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.fit": [[208, 269], ["range", "time.time", "range", "numpy.isnan", "time.time", "lightgcn.LightGCN.data.train_loader", "lightgcn.LightGCN.sess.run", "print", "sys.exit", "os.path.join", "lightgcn.LightGCN.saver.save", "print", "print", "time.time", "lightgcn.LightGCN.run_eval", "time.time", "print", "os.path.exists", "os.makedirs", "str", "os.path.abspath", "zip"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.train_loader", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval"], ["", "def", "fit", "(", "self", ")", ":", "\n", "        ", "\"\"\"Fit the model on self.data.train. If eval_epoch is not -1, evaluate the model on `self.data.test`\n        every `eval_epoch` epoch to observe the training status.\n\n        \"\"\"", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "train_start", "=", "time", ".", "time", "(", ")", "\n", "loss", ",", "mf_loss", ",", "emb_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "n_batch", "=", "self", ".", "data", ".", "train", ".", "shape", "[", "0", "]", "//", "self", ".", "batch_size", "+", "1", "\n", "for", "idx", "in", "range", "(", "n_batch", ")", ":", "\n", "                ", "users", ",", "pos_items", ",", "neg_items", "=", "self", ".", "data", ".", "train_loader", "(", "self", ".", "batch_size", ")", "\n", "_", ",", "batch_loss", ",", "batch_mf_loss", ",", "batch_emb_loss", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "opt", ",", "self", ".", "loss", ",", "self", ".", "mf_loss", ",", "self", ".", "emb_loss", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "users", ":", "users", ",", "\n", "self", ".", "pos_items", ":", "pos_items", ",", "\n", "self", ".", "neg_items", ":", "neg_items", ",", "\n", "}", ",", "\n", ")", "\n", "loss", "+=", "batch_loss", "/", "n_batch", "\n", "mf_loss", "+=", "batch_mf_loss", "/", "n_batch", "\n", "emb_loss", "+=", "batch_emb_loss", "/", "n_batch", "\n", "\n", "", "if", "np", ".", "isnan", "(", "loss", ")", ":", "\n", "                ", "print", "(", "\"ERROR: loss is nan.\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "train_end", "=", "time", ".", "time", "(", ")", "\n", "train_time", "=", "train_end", "-", "train_start", "\n", "\n", "if", "self", ".", "save_model", "and", "epoch", "%", "self", ".", "save_epoch", "==", "0", ":", "\n", "                ", "save_path_str", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "\"epoch_\"", "+", "str", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path_str", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "save_path_str", ")", "\n", "", "checkpoint_path", "=", "self", ".", "saver", ".", "save", "(", "# noqa: F841", "\n", "sess", "=", "self", ".", "sess", ",", "save_path", "=", "save_path_str", "\n", ")", "\n", "print", "(", "\"Save model to path {0}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "save_path_str", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "eval_epoch", "==", "-", "1", "or", "epoch", "%", "self", ".", "eval_epoch", "!=", "0", ":", "\n", "                ", "print", "(", "\n", "\"Epoch %d (train)%.1fs: train loss = %.5f = (mf)%.5f + (embed)%.5f\"", "\n", "%", "(", "epoch", ",", "train_time", ",", "loss", ",", "mf_loss", ",", "emb_loss", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "eval_start", "=", "time", ".", "time", "(", ")", "\n", "ret", "=", "self", ".", "run_eval", "(", ")", "\n", "eval_end", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end", "-", "eval_start", "\n", "\n", "print", "(", "\n", "\"Epoch %d (train)%.1fs + (eval)%.1fs: train loss = %.5f = (mf)%.5f + (embed)%.5f, %s\"", "\n", "%", "(", "\n", "epoch", ",", "\n", "train_time", ",", "\n", "eval_time", ",", "\n", "loss", ",", "\n", "mf_loss", ",", "\n", "emb_loss", ",", "\n", "\", \"", ".", "join", "(", "\n", "metric", "+", "\" = %.5f\"", "%", "(", "r", ")", "\n", "for", "metric", ",", "r", "in", "zip", "(", "self", ".", "metrics", ",", "ret", ")", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.load": [[273, 288], ["lightgcn.LightGCN.saver.restore", "IOError"], "methods", ["None"], ["", "", "", "def", "load", "(", "self", ",", "model_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an existing model.\n\n        Args:\n            model_path: Model path.\n\n        Raises:\n            IOError: if the restore operation failed.\n\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "model_path", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "raise", "IOError", "(", "\n", "\"Failed to find any matching files for {0}\"", ".", "format", "(", "model_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.run_eval": [[290, 326], ["lightgcn.LightGCN.recommend_k_items", "ret.append", "recommenders.evaluation.python_evaluation.map_at_k", "ret.append", "recommenders.evaluation.python_evaluation.ndcg_at_k", "ret.append", "recommenders.evaluation.python_evaluation.precision_at_k", "ret.append", "recommenders.evaluation.python_evaluation.recall_at_k"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "", "def", "run_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run evaluation on self.data.test.\n\n        Returns:\n            dict: Results of all metrics in `self.metrics`.\n        \"\"\"", "\n", "topk_scores", "=", "self", ".", "recommend_k_items", "(", "\n", "self", ".", "data", ".", "test", ",", "top_k", "=", "self", ".", "top_k", ",", "use_id", "=", "True", "\n", ")", "\n", "ret", "=", "[", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "if", "metric", "==", "\"map\"", ":", "\n", "                ", "ret", ".", "append", "(", "\n", "map_at_k", "(", "\n", "self", ".", "data", ".", "test", ",", "topk_scores", ",", "relevancy_method", "=", "None", ",", "k", "=", "self", ".", "top_k", "\n", ")", "\n", ")", "\n", "", "elif", "metric", "==", "\"ndcg\"", ":", "\n", "                ", "ret", ".", "append", "(", "\n", "ndcg_at_k", "(", "\n", "self", ".", "data", ".", "test", ",", "topk_scores", ",", "relevancy_method", "=", "None", ",", "k", "=", "self", ".", "top_k", "\n", ")", "\n", ")", "\n", "", "elif", "metric", "==", "\"precision\"", ":", "\n", "                ", "ret", ".", "append", "(", "\n", "precision_at_k", "(", "\n", "self", ".", "data", ".", "test", ",", "topk_scores", ",", "relevancy_method", "=", "None", ",", "k", "=", "self", ".", "top_k", "\n", ")", "\n", ")", "\n", "", "elif", "metric", "==", "\"recall\"", ":", "\n", "                ", "ret", ".", "append", "(", "\n", "recall_at_k", "(", "\n", "self", ".", "data", ".", "test", ",", "topk_scores", ",", "relevancy_method", "=", "None", ",", "k", "=", "self", ".", "top_k", "\n", ")", "\n", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score": [[327, 358], ["any", "range", "numpy.concatenate", "numpy.isnan", "ValueError", "range", "lightgcn.LightGCN.sess.run", "numpy.concatenate.append", "len", "numpy.array", "lightgcn.LightGCN.data.R.tocsr"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "user_ids", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Score all items for test users.\n\n        Args:\n            user_ids (np.array): Users to test.\n            remove_seen (bool): Flag to remove items seen in training from recommendation.\n\n        Returns:\n            numpy.ndarray: Value of interest of all items for the users.\n\n        \"\"\"", "\n", "if", "any", "(", "np", ".", "isnan", "(", "user_ids", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"LightGCN cannot score users that are not in the training set\"", "\n", ")", "\n", "", "u_batch_size", "=", "self", ".", "batch_size", "\n", "n_user_batchs", "=", "len", "(", "user_ids", ")", "//", "u_batch_size", "+", "1", "\n", "test_scores", "=", "[", "]", "\n", "for", "u_batch_id", "in", "range", "(", "n_user_batchs", ")", ":", "\n", "            ", "start", "=", "u_batch_id", "*", "u_batch_size", "\n", "end", "=", "(", "u_batch_id", "+", "1", ")", "*", "u_batch_size", "\n", "user_batch", "=", "user_ids", "[", "start", ":", "end", "]", "\n", "item_batch", "=", "range", "(", "self", ".", "data", ".", "n_items", ")", "\n", "rate_batch", "=", "self", ".", "sess", ".", "run", "(", "\n", "self", ".", "batch_ratings", ",", "{", "self", ".", "users", ":", "user_batch", ",", "self", ".", "pos_items", ":", "item_batch", "}", "\n", ")", "\n", "test_scores", ".", "append", "(", "np", ".", "array", "(", "rate_batch", ")", ")", "\n", "", "test_scores", "=", "np", ".", "concatenate", "(", "test_scores", ",", "axis", "=", "0", ")", "\n", "if", "remove_seen", ":", "\n", "            ", "test_scores", "+=", "self", ".", "data", ".", "R", ".", "tocsr", "(", ")", "[", "user_ids", ",", ":", "]", "*", "-", "np", ".", "inf", "\n", "", "return", "test_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.recommend_k_items": [[359, 399], ["lightgcn.LightGCN.score", "recommenders.utils.python_utils.get_top_k_scored_items", "pandas.DataFrame", "pandas.DataFrame.replace().dropna", "numpy.array", "numpy.array", "test[].unique", "numpy.repeat", "top_scores.flatten", "pandas.DataFrame.replace", "top_items.flatten", "test[].unique", "test[].drop_duplicates", "top_items.flatten"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.python_utils.get_top_k_scored_items"], ["", "def", "recommend_k_items", "(", "\n", "self", ",", "test", ",", "top_k", "=", "10", ",", "sort_top_k", "=", "True", ",", "remove_seen", "=", "True", ",", "use_id", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Recommend top K items for all users in the test set.\n\n        Args:\n            test (pandas.DataFrame): Test data.\n            top_k (int): Number of top items to recommend.\n            sort_top_k (bool): Flag to sort top k results.\n            remove_seen (bool): Flag to remove items seen in training from recommendation.\n\n        Returns:\n            pandas.DataFrame: Top k recommendation items for each user.\n\n        \"\"\"", "\n", "data", "=", "self", ".", "data", "\n", "if", "not", "use_id", ":", "\n", "            ", "user_ids", "=", "np", ".", "array", "(", "[", "data", ".", "user2id", "[", "x", "]", "for", "x", "in", "test", "[", "data", ".", "col_user", "]", ".", "unique", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "user_ids", "=", "np", ".", "array", "(", "test", "[", "data", ".", "col_user", "]", ".", "unique", "(", ")", ")", "\n", "\n", "", "test_scores", "=", "self", ".", "score", "(", "user_ids", ",", "remove_seen", "=", "remove_seen", ")", "\n", "\n", "top_items", ",", "top_scores", "=", "get_top_k_scored_items", "(", "\n", "scores", "=", "test_scores", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "data", ".", "col_user", ":", "np", ".", "repeat", "(", "\n", "test", "[", "data", ".", "col_user", "]", ".", "drop_duplicates", "(", ")", ".", "values", ",", "top_items", ".", "shape", "[", "1", "]", "\n", ")", ",", "\n", "data", ".", "col_item", ":", "top_items", ".", "flatten", "(", ")", "\n", "if", "use_id", "\n", "else", "[", "data", ".", "id2item", "[", "item", "]", "for", "item", "in", "top_items", ".", "flatten", "(", ")", "]", ",", "\n", "data", ".", "col_prediction", ":", "top_scores", ".", "flatten", "(", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "df", ".", "replace", "(", "-", "np", ".", "inf", ",", "np", ".", "nan", ")", ".", "dropna", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.output_embeddings": [[400, 407], ["list", "target.eval", "open", "range", "wt.write", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "output_embeddings", "(", "self", ",", "idmapper", ",", "n", ",", "target", ",", "user_file", ")", ":", "\n", "        ", "embeddings", "=", "list", "(", "target", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", ")", "\n", "with", "open", "(", "user_file", ",", "\"w\"", ")", "as", "wt", ":", "\n", "            ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "wt", ".", "write", "(", "\n", "\"{0}\\t{1}\\n\"", ".", "format", "(", "\n", "idmapper", "[", "i", "]", ",", "\" \"", ".", "join", "(", "[", "str", "(", "a", ")", "for", "a", "in", "embeddings", "[", "i", "]", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.infer_embedding": [[410, 433], ["os.path.split", "os.path.split", "lightgcn.LightGCN.output_embeddings", "lightgcn.LightGCN.output_embeddings", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.output_embeddings", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.output_embeddings"], ["", "", "", "def", "infer_embedding", "(", "self", ",", "user_file", ",", "item_file", ")", ":", "\n", "        ", "\"\"\"Export user and item embeddings to csv files.\n\n        Args:\n            user_file (str): Path of file to save user embeddings.\n            item_file (str): Path of file to save item embeddings.\n\n        \"\"\"", "\n", "# create output directories if they do not exist", "\n", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "user_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirs", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirs", ")", "\n", "", "dirs", ",", "_", "=", "os", ".", "path", ".", "split", "(", "item_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirs", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirs", ")", "\n", "\n", "", "data", "=", "self", ".", "data", "\n", "\n", "self", ".", "output_embeddings", "(", "\n", "data", ".", "id2user", ",", "self", ".", "n_users", ",", "self", ".", "ua_embeddings", ",", "user_file", "\n", ")", "\n", "self", ".", "output_embeddings", "(", "\n", "data", ".", "id2item", ",", "self", ".", "n_items", ",", "self", ".", "ia_embeddings", ",", "item_file", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._build_seq_graph": [[24, 53], ["tensorflow.compat.v1.variable_scope", "tensorflow.concat", "sum.SUMModel._create_sumcell", "sum.SUMModel._build_sum", "sum.SUMModel._attention_query_by_state", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.summary.histogram", "hasattr", "hasattr", "tensorflow.compat.v1.summary.histogram", "hasattr", "hasattr", "tensorflow.compat.v1.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._create_sumcell", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._build_sum", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._attention_query_by_state"], ["def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create SUM model.\n\n        Returns:\n            object: The output of SUM section, which is a concatenation of user vector and target item vector.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "# noqa: F841", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"sum\"", ")", ":", "\n", "            ", "self", ".", "history_embedding", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_history_embedding", ",", "self", ".", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "cell", "=", "self", ".", "_create_sumcell", "(", ")", "\n", "self", ".", "cell", "=", "cell", "\n", "cell", ".", "model", "=", "self", "\n", "final_state", "=", "self", ".", "_build_sum", "(", "cell", ")", "\n", "\n", "for", "_p", "in", "cell", ".", "parameter_set", ":", "\n", "                ", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "_p", ".", "name", ",", "_p", ")", "\n", "", "if", "hasattr", "(", "cell", ",", "\"_alpha\"", ")", "and", "hasattr", "(", "cell", ".", "_alpha", ",", "\"name\"", ")", ":", "\n", "                ", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "cell", ".", "_alpha", ".", "name", ",", "cell", ".", "_alpha", ")", "\n", "", "if", "hasattr", "(", "cell", ",", "\"_beta\"", ")", "and", "hasattr", "(", "cell", ".", "_beta", ",", "\"name\"", ")", ":", "\n", "                ", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "cell", ".", "_beta", ".", "name", ",", "cell", ".", "_beta", ")", "\n", "\n", "", "final_state", ",", "att_weights", "=", "self", ".", "_attention_query_by_state", "(", "\n", "final_state", ",", "self", ".", "target_item_embedding", "\n", ")", "\n", "model_output", "=", "tf", ".", "concat", "(", "[", "final_state", ",", "self", ".", "target_item_embedding", "]", ",", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"model_output\"", ",", "model_output", ")", "\n", "", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._attention_query_by_state": [[54, 98], ["tensorflow.constant", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.reshape", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.squeeze", "tensorflow.matmul", "tensorflow.tensordot", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["None"], ["", "def", "_attention_query_by_state", "(", "self", ",", "seq_output", ",", "query", ")", ":", "\n", "        ", "\"\"\"Merge a user's memory states conditioned by a query item.\n\n        Params:\n            seq_output: A flatten representation of SUM memory states for (a batch of) users\n            query: (a batch of) target item candidates\n\n        Returns:\n            tf.Tensor, tf.Tensor: Merged user representation. Attention weights of each memory channel.\n        \"\"\"", "\n", "dim_q", "=", "query", ".", "shape", "[", "-", "1", "]", "\n", "att_weights", "=", "tf", ".", "constant", "(", "1.0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"query_att\"", ")", ":", "\n", "            ", "if", "self", ".", "hparams", ".", "slots", ">", "1", ":", "\n", "                ", "query_att_W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"query_att_W\"", ",", "\n", "shape", "=", "[", "self", ".", "hidden_size", ",", "dim_q", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ",", "\n", ")", "\n", "\n", "# reshape the memory states to (BatchSize, Slots, HiddenSize)", "\n", "memory_state", "=", "tf", ".", "reshape", "(", "\n", "seq_output", ",", "[", "-", "1", ",", "self", ".", "hparams", ".", "slots", ",", "self", ".", "hidden_size", "]", "\n", ")", "\n", "\n", "att_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "\n", "tf", ".", "squeeze", "(", "\n", "tf", ".", "matmul", "(", "\n", "tf", ".", "tensordot", "(", "memory_state", ",", "query_att_W", ",", "axes", "=", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "query", ",", "-", "1", ")", ",", "\n", ")", ",", "\n", "-", "1", ",", "\n", ")", ",", "\n", "-", "1", ",", "\n", ")", "\n", "# merge the memory states, the final shape is (BatchSize, HiddenSize)", "\n", "att_res", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "memory_state", "*", "tf", ".", "expand_dims", "(", "att_weights", ",", "-", "1", ")", ",", "axis", "=", "1", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "att_res", "=", "seq_output", "\n", "\n", "", "", "return", "att_res", ",", "att_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._create_sumcell": [[99, 121], ["sumCell", "ValueError"], "methods", ["None"], ["", "def", "_create_sumcell", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create a SUM cell\n\n        Returns:\n            object: An initialized SUM cell\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "input_embedding_dim", "=", "self", ".", "history_embedding", ".", "shape", "[", "-", "1", "]", "\n", "input_params", "=", "[", "\n", "hparams", ".", "hidden_size", "*", "hparams", ".", "slots", "+", "input_embedding_dim", ",", "\n", "hparams", ".", "slots", ",", "\n", "hparams", ".", "attention_size", ",", "\n", "input_embedding_dim", ",", "\n", "]", "\n", "sumcells", "=", "{", "\"SUM\"", ":", "SUMCell", ",", "\"SUMV2\"", ":", "SUMV2Cell", "}", "\n", "sumCell", "=", "sumcells", "[", "hparams", ".", "cell", "]", "\n", "res", "=", "None", "\n", "if", "hparams", ".", "cell", "in", "[", "\"SUM\"", ",", "\"SUMV2\"", "]", ":", "\n", "            ", "res", "=", "sumCell", "(", "*", "input_params", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"ERROR! Cell type not support: {0}\"", ".", "format", "(", "hparams", ".", "cell", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum.SUMModel._build_sum": [[122, 155], ["tensorflow.compat.v1.variable_scope", "tensorflow.reduce_sum", "tensorflow.compat.v1.nn.dynamic_rnn", "tensorflow.compat.v1.summary.histogram", "cell.zero_state", "tensorflow.shape"], "methods", ["None"], ["", "def", "_build_sum", "(", "self", ",", "cell", ")", ":", "\n", "        ", "\"\"\"Generate  user memory states from behavior sequence\n\n        Args:\n            object: An initialied SUM cell.\n\n        Returns:\n            object: A flatten representation of user memory states, in the shape of (BatchSize, SlotsNum x HiddenSize)\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"sum\"", ")", ":", "\n", "            ", "self", ".", "mask", "=", "self", ".", "iterator", ".", "mask", "\n", "self", ".", "sequence_length", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "mask", ",", "axis", "=", "1", ")", "\n", "\n", "rum_outputs", ",", "final_state", "=", "dynamic_rnn", "(", "\n", "cell", ",", "\n", "inputs", "=", "self", ".", "history_embedding", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "sequence_length", "=", "self", ".", "sequence_length", ",", "\n", "scope", "=", "\"sum\"", ",", "\n", "initial_state", "=", "cell", ".", "zero_state", "(", "\n", "tf", ".", "shape", "(", "input", "=", "self", ".", "history_embedding", ")", "[", "0", "]", ",", "tf", ".", "float32", "\n", ")", ",", "\n", ")", "\n", "\n", "final_state", "=", "final_state", "[", ":", ",", ":", "hparams", ".", "slots", "*", "hparams", ".", "hidden_size", "]", "\n", "\n", "self", ".", "heads", "=", "cell", ".", "heads", "\n", "self", ".", "alpha", "=", "cell", ".", "_alpha", "\n", "self", ".", "beta", "=", "cell", ".", "_beta", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"SUM_outputs\"", ",", "rum_outputs", ")", "\n", "\n", "", "return", "final_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.asvd.A2SVDModel._build_seq_graph": [[29, 48], ["tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.variable_scope", "asvd.A2SVDModel._attention", "tensorflow.reduce_sum", "tensorflow.compat.v1.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._attention"], ["def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create A2SVD model.\n\n        Returns:\n            object: The output of A2SVD section.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"a2svd\"", ")", ":", "\n", "            ", "hist_input", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_history_embedding", ",", "self", ".", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"Attention_layer\"", ")", ":", "\n", "                ", "att_outputs1", "=", "self", ".", "_attention", "(", "hist_input", ",", "hparams", ".", "attention_size", ")", "\n", "asvd_output", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "att_outputs1", ",", "axis", "=", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"a2svd_output\"", ",", "asvd_output", ")", "\n", "", "model_output", "=", "tf", ".", "concat", "(", "[", "asvd_output", ",", "self", ".", "target_item_embedding", "]", ",", "1", ")", "\n", "self", ".", "model_output", "=", "model_output", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"model_output\"", ",", "model_output", ")", "\n", "return", "model_output", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.__init__": [[20, 52], ["recommenders.models.deeprec.models.base_model.BaseModel.__init__", "ValueError", "tensorflow.Graph", "sequential_base_model.SequentialBaseModel.graph.as_default", "tensorflow.compat.v1.placeholder", "hparams.values", "hparams.values"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ",", "graph", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializing the model. Create common logics which are needed by all sequential models, such as loss function,\n        parameter set.\n\n        Args:\n            hparams (HParams): A `HParams` object, hold the entire set of hyperparameters.\n            iterator_creator (object): An iterator to load the data.\n            graph (object): An optional graph.\n            seed (int): Random seed.\n        \"\"\"", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "self", ".", "need_sample", "=", "hparams", ".", "need_sample", "\n", "self", ".", "train_num_ngs", "=", "hparams", ".", "train_num_ngs", "\n", "if", "self", ".", "train_num_ngs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Please confirm the number of negative samples for each positive instance.\"", "\n", ")", "\n", "", "self", ".", "min_seq_length", "=", "(", "\n", "hparams", ".", "min_seq_length", "if", "\"min_seq_length\"", "in", "hparams", ".", "values", "(", ")", "else", "1", "\n", ")", "\n", "self", ".", "hidden_size", "=", "(", "\n", "hparams", ".", "hidden_size", "if", "\"hidden_size\"", "in", "hparams", ".", "values", "(", ")", "else", "None", "\n", ")", "\n", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "if", "not", "graph", "else", "graph", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "sequence_length", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"sequence_length\"", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "graph", "=", "self", ".", "graph", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_seq_graph": [[53, 57], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Subclass will implement this.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_graph": [[58, 75], ["numpy.ones_like", "numpy.array", "tensorflow.compat.v1.variable_scope", "sequential_base_model.SequentialBaseModel._build_embedding", "sequential_base_model.SequentialBaseModel._lookup_from_embedding", "sequential_base_model.SequentialBaseModel._build_seq_graph", "sequential_base_model.SequentialBaseModel._fcn_net", "sequential_base_model.SequentialBaseModel._add_norm"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._lookup_from_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._build_seq_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._fcn_net", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._add_norm"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create sequential models.\n\n        Returns:\n            object: the prediction score make by the model.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "self", ".", "keep_prob_train", "=", "1", "-", "np", ".", "array", "(", "hparams", ".", "dropout", ")", "\n", "self", ".", "keep_prob_test", "=", "np", ".", "ones_like", "(", "hparams", ".", "dropout", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"sequential\"", ")", "as", "self", ".", "sequential_scope", ":", "\n", "            ", "self", ".", "_build_embedding", "(", ")", "\n", "self", ".", "_lookup_from_embedding", "(", ")", "\n", "model_output", "=", "self", ".", "_build_seq_graph", "(", ")", "\n", "logit", "=", "self", ".", "_fcn_net", "(", "model_output", ",", "hparams", ".", "layer_sizes", ",", "scope", "=", "\"logit_fcn\"", ")", "\n", "self", ".", "_add_norm", "(", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.fit": [[76, 191], ["list", "range", "print", "print", "ValueError", "ValueError", "tensorflow.compat.v1.summary.FileWriter", "sequential_base_model.SequentialBaseModel.iterator.load_data_from_file", "sequential_base_model.SequentialBaseModel.run_eval", "print", "list.append", "sequential_base_model.SequentialBaseModel.writer.close", "os.path.exists", "os.makedirs", "sequential_base_model.SequentialBaseModel.train", "print", "os.path.exists", "os.makedirs", "sequential_base_model.SequentialBaseModel.saver.save", "sequential_base_model.SequentialBaseModel.saver.save", "sequential_base_model.SequentialBaseModel.writer.add_summary", "print", "os.path.join", "str", "sequential_base_model.SequentialBaseModel.items", "str", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.sampler.WarpSampler.close", "home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.model.SASREC.train", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "", "def", "fit", "(", "\n", "self", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "valid_num_ngs", ",", "\n", "eval_metric", "=", "\"group_auc\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Fit the model with `train_file`. Evaluate the model on `valid_file` per epoch to observe the training status.\n        If `test_file` is not None, evaluate it too.\n\n        Args:\n            train_file (str): training data set.\n            valid_file (str): validation set.\n            valid_num_ngs (int): the number of negative instances with one positive instance in validation data.\n            eval_metric (str): the metric that control early stopping. e.g. \"auc\", \"group_auc\", etc.\n\n        Returns:\n            object: An instance of self.\n        \"\"\"", "\n", "\n", "# check bad input.", "\n", "if", "not", "self", ".", "need_sample", "and", "self", ".", "train_num_ngs", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Please specify a positive integer of negative numbers for training without sampling needed.\"", "\n", ")", "\n", "", "if", "valid_num_ngs", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Please specify a positive integer of negative numbers for validation.\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "need_sample", "and", "self", ".", "train_num_ngs", "<", "1", ":", "\n", "            ", "self", ".", "train_num_ngs", "=", "1", "\n", "\n", "", "if", "self", ".", "hparams", ".", "write_tfevents", "and", "self", ".", "hparams", ".", "SUMMARIES_DIR", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "hparams", ".", "SUMMARIES_DIR", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "hparams", ".", "SUMMARIES_DIR", ")", "\n", "\n", "", "self", ".", "writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "\n", "self", ".", "hparams", ".", "SUMMARIES_DIR", ",", "self", ".", "sess", ".", "graph", "\n", ")", "\n", "\n", "", "train_sess", "=", "self", ".", "sess", "\n", "eval_info", "=", "list", "(", ")", "\n", "\n", "best_metric", ",", "self", ".", "best_epoch", "=", "0", ",", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "hparams", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "step", "=", "0", "\n", "self", ".", "hparams", ".", "current_epoch", "=", "epoch", "\n", "epoch_loss", "=", "0", "\n", "file_iterator", "=", "self", ".", "iterator", ".", "load_data_from_file", "(", "\n", "train_file", ",", "\n", "min_seq_length", "=", "self", ".", "min_seq_length", ",", "\n", "batch_num_ngs", "=", "self", ".", "train_num_ngs", ",", "\n", ")", "\n", "\n", "for", "batch_data_input", "in", "file_iterator", ":", "\n", "                ", "if", "batch_data_input", ":", "\n", "                    ", "step_result", "=", "self", ".", "train", "(", "train_sess", ",", "batch_data_input", ")", "\n", "(", "_", ",", "_", ",", "step_loss", ",", "step_data_loss", ",", "summary", ")", "=", "step_result", "\n", "if", "self", ".", "hparams", ".", "write_tfevents", "and", "self", ".", "hparams", ".", "SUMMARIES_DIR", ":", "\n", "                        ", "self", ".", "writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "", "epoch_loss", "+=", "step_loss", "\n", "step", "+=", "1", "\n", "if", "step", "%", "self", ".", "hparams", ".", "show_step", "==", "0", ":", "\n", "                        ", "print", "(", "\n", "\"step {0:d} , total_loss: {1:.4f}, data_loss: {2:.4f}\"", ".", "format", "(", "\n", "step", ",", "step_loss", ",", "step_data_loss", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "valid_res", "=", "self", ".", "run_eval", "(", "valid_file", ",", "valid_num_ngs", ")", "\n", "print", "(", "\n", "\"eval valid at epoch {0}: {1}\"", ".", "format", "(", "\n", "epoch", ",", "\n", "\",\"", ".", "join", "(", "\n", "[", "\n", "\"\"", "+", "str", "(", "key", ")", "+", "\":\"", "+", "str", "(", "value", ")", "\n", "for", "key", ",", "value", "in", "valid_res", ".", "items", "(", ")", "\n", "]", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "eval_info", ".", "append", "(", "(", "epoch", ",", "valid_res", ")", ")", "\n", "\n", "progress", "=", "False", "\n", "early_stop", "=", "self", ".", "hparams", ".", "EARLY_STOP", "\n", "if", "valid_res", "[", "eval_metric", "]", ">", "best_metric", ":", "\n", "                ", "best_metric", "=", "valid_res", "[", "eval_metric", "]", "\n", "self", ".", "best_epoch", "=", "epoch", "\n", "progress", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "early_stop", ">", "0", "and", "epoch", "-", "self", ".", "best_epoch", ">=", "early_stop", ":", "\n", "                    ", "print", "(", "\"early stop at epoch {0}!\"", ".", "format", "(", "epoch", ")", ")", "\n", "break", "\n", "\n", "", "", "if", "self", ".", "hparams", ".", "save_model", "and", "self", ".", "hparams", ".", "MODEL_DIR", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "hparams", ".", "MODEL_DIR", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "self", ".", "hparams", ".", "MODEL_DIR", ")", "\n", "", "if", "progress", ":", "\n", "                    ", "checkpoint_path", "=", "self", ".", "saver", ".", "save", "(", "\n", "sess", "=", "train_sess", ",", "\n", "save_path", "=", "self", ".", "hparams", ".", "MODEL_DIR", "+", "\"epoch_\"", "+", "str", "(", "epoch", ")", ",", "\n", ")", "\n", "checkpoint_path", "=", "self", ".", "saver", ".", "save", "(", "# noqa: F841", "\n", "sess", "=", "train_sess", ",", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "hparams", ".", "MODEL_DIR", ",", "\"best_model\"", ")", ",", "\n", ")", "\n", "\n", "", "", "", "if", "self", ".", "hparams", ".", "write_tfevents", ":", "\n", "            ", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n", "", "print", "(", "eval_info", ")", "\n", "print", "(", "\"best epoch: {0}\"", ".", "format", "(", "self", ".", "best_epoch", ")", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval": [[192, 226], ["sequential_base_model.SequentialBaseModel.iterator.load_data_from_file", "recommenders.models.deeprec.deeprec_utils.cal_metric", "recommenders.models.deeprec.deeprec_utils.cal_metric", "recommenders.models.deeprec.deeprec_utils.cal_metric.update", "sequential_base_model.SequentialBaseModel.eval", "preds.extend", "labels.extend", "group_preds.extend", "group_labels.extend", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.cal_metric", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "run_eval", "(", "self", ",", "filename", ",", "num_ngs", ")", ":", "\n", "        ", "\"\"\"Evaluate the given file and returns some evaluation metrics.\n\n        Args:\n            filename (str): A file name that will be evaluated.\n            num_ngs (int): The number of negative sampling for a positive instance.\n\n        Returns:\n            dict: A dictionary that contains evaluation metrics.\n        \"\"\"", "\n", "\n", "load_sess", "=", "self", ".", "sess", "\n", "preds", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "group_preds", "=", "[", "]", "\n", "group_labels", "=", "[", "]", "\n", "group", "=", "num_ngs", "+", "1", "\n", "\n", "for", "batch_data_input", "in", "self", ".", "iterator", ".", "load_data_from_file", "(", "\n", "filename", ",", "min_seq_length", "=", "self", ".", "min_seq_length", ",", "batch_num_ngs", "=", "0", "\n", ")", ":", "\n", "            ", "if", "batch_data_input", ":", "\n", "                ", "step_pred", ",", "step_labels", "=", "self", ".", "eval", "(", "load_sess", ",", "batch_data_input", ")", "\n", "preds", ".", "extend", "(", "np", ".", "reshape", "(", "step_pred", ",", "-", "1", ")", ")", "\n", "labels", ".", "extend", "(", "np", ".", "reshape", "(", "step_labels", ",", "-", "1", ")", ")", "\n", "group_preds", ".", "extend", "(", "np", ".", "reshape", "(", "step_pred", ",", "(", "-", "1", ",", "group", ")", ")", ")", "\n", "group_labels", ".", "extend", "(", "np", ".", "reshape", "(", "step_labels", ",", "(", "-", "1", ",", "group", ")", ")", ")", "\n", "\n", "", "", "res", "=", "cal_metric", "(", "labels", ",", "preds", ",", "self", ".", "hparams", ".", "metrics", ")", "\n", "res_pairwise", "=", "cal_metric", "(", "\n", "group_labels", ",", "group_preds", ",", "self", ".", "hparams", ".", "pairwise_metrics", "\n", ")", "\n", "res", ".", "update", "(", "res_pairwise", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.predict": [[227, 249], ["tensorflow.io.gfile.GFile", "sequential_base_model.SequentialBaseModel.iterator.load_data_from_file", "sequential_base_model.SequentialBaseModel.infer", "numpy.reshape", "wt.write", "wt.write", "map"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_predict.Inferer.infer"], ["", "def", "predict", "(", "self", ",", "infile_name", ",", "outfile_name", ")", ":", "\n", "        ", "\"\"\"Make predictions on the given data, and output predicted scores to a file.\n\n        Args:\n            infile_name (str): Input file name.\n            outfile_name (str): Output file name.\n\n        Returns:\n            object: An instance of self.\n        \"\"\"", "\n", "\n", "load_sess", "=", "self", ".", "sess", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "outfile_name", ",", "\"w\"", ")", "as", "wt", ":", "\n", "            ", "for", "batch_data_input", "in", "self", ".", "iterator", ".", "load_data_from_file", "(", "\n", "infile_name", ",", "batch_num_ngs", "=", "0", "\n", ")", ":", "\n", "                ", "if", "batch_data_input", ":", "\n", "                    ", "step_pred", "=", "self", ".", "infer", "(", "load_sess", ",", "batch_data_input", ")", "\n", "step_pred", "=", "np", ".", "reshape", "(", "step_pred", ",", "-", "1", ")", "\n", "wt", ".", "write", "(", "\"\\n\"", ".", "join", "(", "map", "(", "str", ",", "step_pred", ")", ")", ")", "\n", "wt", ".", "write", "(", "\"\\n\"", ")", "\n", "", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._build_embedding": [[250, 275], ["len", "len", "len", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "recommenders.models.deeprec.deeprec_utils.load_dict", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.load_dict"], ["", "def", "_build_embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"The field embedding layer. Initialization of embedding variables.\"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "self", ".", "user_vocab_length", "=", "len", "(", "load_dict", "(", "hparams", ".", "user_vocab", ")", ")", "\n", "self", ".", "item_vocab_length", "=", "len", "(", "load_dict", "(", "hparams", ".", "item_vocab", ")", ")", "\n", "self", ".", "cate_vocab_length", "=", "len", "(", "load_dict", "(", "hparams", ".", "cate_vocab", ")", ")", "\n", "self", ".", "user_embedding_dim", "=", "hparams", ".", "user_embedding_dim", "\n", "self", ".", "item_embedding_dim", "=", "hparams", ".", "item_embedding_dim", "\n", "self", ".", "cate_embedding_dim", "=", "hparams", ".", "cate_embedding_dim", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"embedding\"", ",", "initializer", "=", "self", ".", "initializer", ")", ":", "\n", "            ", "self", ".", "user_lookup", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"user_embedding\"", ",", "\n", "shape", "=", "[", "self", ".", "user_vocab_length", ",", "self", ".", "user_embedding_dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "self", ".", "item_lookup", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"item_embedding\"", ",", "\n", "shape", "=", "[", "self", ".", "item_vocab_length", ",", "self", ".", "item_embedding_dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n", "self", ".", "cate_lookup", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"cate_embedding\"", ",", "\n", "shape", "=", "[", "self", ".", "cate_vocab_length", ",", "self", ".", "cate_embedding_dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._lookup_from_embedding": [[277, 335], ["tensorflow.nn.embedding_lookup", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.nn.embedding_lookup", "tensorflow.compat.v1.nn.embedding_lookup", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.nn.embedding_lookup", "tensorflow.compat.v1.nn.embedding_lookup", "tensorflow.compat.v1.summary.histogram", "tensorflow.concat", "tensorflow.unique", "tensorflow.nn.embedding_lookup", "sequential_base_model.SequentialBaseModel.embed_params.append", "tensorflow.concat", "tensorflow.unique", "tensorflow.nn.embedding_lookup", "sequential_base_model.SequentialBaseModel.embed_params.append", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["None"], ["", "", "def", "_lookup_from_embedding", "(", "self", ")", ":", "\n", "        ", "\"\"\"Lookup from embedding variables. A dropout layer follows lookup operations.\"\"\"", "\n", "self", ".", "user_embedding", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "user_lookup", ",", "ids", "=", "self", ".", "iterator", ".", "users", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"user_embedding_output\"", ",", "self", ".", "user_embedding", ")", "\n", "\n", "self", ".", "item_embedding", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "item_lookup", ",", "ids", "=", "self", ".", "iterator", ".", "items", "\n", ")", "\n", "self", ".", "item_history_embedding", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "item_lookup", ",", "ids", "=", "self", ".", "iterator", ".", "item_history", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"item_history_embedding_output\"", ",", "self", ".", "item_history_embedding", "\n", ")", "\n", "\n", "self", ".", "cate_embedding", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "cate_lookup", ",", "ids", "=", "self", ".", "iterator", ".", "cates", "\n", ")", "\n", "self", ".", "cate_history_embedding", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "cate_lookup", ",", "ids", "=", "self", ".", "iterator", ".", "item_cate_history", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"cate_history_embedding_output\"", ",", "self", ".", "cate_history_embedding", "\n", ")", "\n", "\n", "involved_items", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "tf", ".", "reshape", "(", "self", ".", "iterator", ".", "item_history", ",", "[", "-", "1", "]", ")", ",", "\n", "tf", ".", "reshape", "(", "self", ".", "iterator", ".", "items", ",", "[", "-", "1", "]", ")", ",", "\n", "]", ",", "\n", "-", "1", ",", "\n", ")", "\n", "self", ".", "involved_items", ",", "_", "=", "tf", ".", "unique", "(", "involved_items", ")", "\n", "involved_item_embedding", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "item_lookup", ",", "ids", "=", "self", ".", "involved_items", "\n", ")", "\n", "self", ".", "embed_params", ".", "append", "(", "involved_item_embedding", ")", "\n", "\n", "involved_cates", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "tf", ".", "reshape", "(", "self", ".", "iterator", ".", "item_cate_history", ",", "[", "-", "1", "]", ")", ",", "\n", "tf", ".", "reshape", "(", "self", ".", "iterator", ".", "cates", ",", "[", "-", "1", "]", ")", ",", "\n", "]", ",", "\n", "-", "1", ",", "\n", ")", "\n", "self", ".", "involved_cates", ",", "_", "=", "tf", ".", "unique", "(", "involved_cates", ")", "\n", "involved_cate_embedding", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "\n", "params", "=", "self", ".", "cate_lookup", ",", "ids", "=", "self", ".", "involved_cates", "\n", ")", "\n", "self", ".", "embed_params", ".", "append", "(", "involved_cate_embedding", ")", "\n", "\n", "self", ".", "target_item_embedding", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_embedding", ",", "self", ".", "cate_embedding", "]", ",", "-", "1", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\n", "\"target_item_embedding_output\"", ",", "self", ".", "target_item_embedding", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel._add_norm": [[337, 348], ["list", "sequential_base_model.SequentialBaseModel.layer_params.extend", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.trainable_variables", "set", "set"], "methods", ["None"], ["", "def", "_add_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Regularization for embedding variables and other variables.\"\"\"", "\n", "all_variables", ",", "embed_variables", "=", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ",", "\n", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", "\n", "self", ".", "sequential_scope", ".", "_name", "+", "\"/embedding\"", "\n", ")", ",", "\n", ")", "\n", "layer_params", "=", "list", "(", "set", "(", "all_variables", ")", "-", "set", "(", "embed_variables", ")", ")", "\n", "layer_params", "=", "[", "a", "for", "a", "in", "layer_params", "if", "\"_no_reg\"", "not", "in", "a", ".", "name", "]", "\n", "self", ".", "layer_params", ".", "extend", "(", "layer_params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sli_rec.SLI_RECModel._build_seq_graph": [[27, 97], ["tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.variable_scope", "sli_rec.SLI_RECModel._attention", "tensorflow.reduce_sum", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.nn.dynamic_rnn", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.variable_scope", "sli_rec.SLI_RECModel._attention_fcn", "tensorflow.reduce_sum", "tensorflow.compat.v1.summary.histogram", "tensorflow.compat.v1.name_scope", "tensorflow.concat", "sli_rec.SLI_RECModel._fcn_net", "tensorflow.sigmoid", "tensorflow.expand_dims", "tensorflow.expand_dims", "recommenders.models.deeprec.models.sequential.rnn_cell_implement.Time4LSTMCell", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._attention", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sli_rec.SLI_RECModel._attention_fcn", "home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._fcn_net"], ["def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create sli_rec model.\n\n        Returns:\n            object: the output of sli_rec section.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"sli_rec\"", ")", ":", "\n", "            ", "hist_input", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_history_embedding", ",", "self", ".", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "self", ".", "mask", "=", "self", ".", "iterator", ".", "mask", "\n", "self", ".", "sequence_length", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "mask", ",", "axis", "=", "1", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"long_term_asvd\"", ")", ":", "\n", "                ", "att_outputs1", "=", "self", ".", "_attention", "(", "hist_input", ",", "hparams", ".", "attention_size", ")", "\n", "att_fea1", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "att_outputs1", ",", "axis", "=", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"att_fea1\"", ",", "att_fea1", ")", "\n", "\n", "", "item_history_embedding_new", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "self", ".", "item_history_embedding", ",", "\n", "tf", ".", "expand_dims", "(", "self", ".", "iterator", ".", "time_from_first_action", ",", "-", "1", ")", ",", "\n", "]", ",", "\n", "-", "1", ",", "\n", ")", "\n", "item_history_embedding_new", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "item_history_embedding_new", ",", "\n", "tf", ".", "expand_dims", "(", "self", ".", "iterator", ".", "time_to_now", ",", "-", "1", ")", ",", "\n", "]", ",", "\n", "-", "1", ",", "\n", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"rnn\"", ")", ":", "\n", "                ", "rnn_outputs", ",", "_", "=", "dynamic_rnn", "(", "\n", "Time4LSTMCell", "(", "hparams", ".", "hidden_size", ")", ",", "\n", "inputs", "=", "item_history_embedding_new", ",", "\n", "sequence_length", "=", "self", ".", "sequence_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "scope", "=", "\"time4lstm\"", ",", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"LSTM_outputs\"", ",", "rnn_outputs", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_fcn\"", ")", ":", "\n", "                ", "att_outputs2", "=", "self", ".", "_attention_fcn", "(", "\n", "self", ".", "target_item_embedding", ",", "rnn_outputs", "\n", ")", "\n", "att_fea2", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "att_outputs2", ",", "axis", "=", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"att_fea2\"", ",", "att_fea2", ")", "\n", "\n", "# ensemble", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"alpha\"", ")", ":", "\n", "                ", "concat_all", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "self", ".", "target_item_embedding", ",", "\n", "att_fea1", ",", "\n", "att_fea2", ",", "\n", "tf", ".", "expand_dims", "(", "self", ".", "iterator", ".", "time_to_now", "[", ":", ",", "-", "1", "]", ",", "-", "1", ")", ",", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "last_hidden_nn_layer", "=", "concat_all", "\n", "alpha_logit", "=", "self", ".", "_fcn_net", "(", "\n", "last_hidden_nn_layer", ",", "hparams", ".", "att_fcn_layer_sizes", ",", "scope", "=", "\"fcn_alpha\"", "\n", ")", "\n", "alpha_output", "=", "tf", ".", "sigmoid", "(", "alpha_logit", ")", "\n", "user_embed", "=", "att_fea1", "*", "alpha_output", "+", "att_fea2", "*", "(", "1.0", "-", "alpha_output", ")", "\n", "", "model_output", "=", "tf", ".", "concat", "(", "[", "user_embed", ",", "self", ".", "target_item_embedding", "]", ",", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"model_output\"", ",", "model_output", ")", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sli_rec.SLI_RECModel._attention_fcn": [[98, 137], ["tensorflow.compat.v1.variable_scope", "tensorflow.equal", "tensorflow.compat.v1.get_variable", "tensorflow.tensordot", "tensorflow.reshape", "tensorflow.concat", "sli_rec.SLI_RECModel._fcn_net", "tensorflow.squeeze", "tensorflow.nn.softmax", "tensorflow.ones_like", "tensorflow.tile", "tensorflow.shape", "tensorflow.ones_like", "tensorflow.compat.v1.where", "tensorflow.expand_dims", "user_embedding.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.base_model.BaseModel._fcn_net"], ["", "", "def", "_attention_fcn", "(", "self", ",", "query", ",", "user_embedding", ")", ":", "\n", "        ", "\"\"\"Apply attention by fully connected layers.\n\n        Args:\n            query (object): The embedding of target item which is regarded as a query in attention operations.\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\n\n        Returns:\n            object: Weighted sum of user modeling.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_fcn\"", ")", ":", "\n", "            ", "query_size", "=", "query", ".", "shape", "[", "1", "]", "\n", "boolean_mask", "=", "tf", ".", "equal", "(", "self", ".", "mask", ",", "tf", ".", "ones_like", "(", "self", ".", "mask", ")", ")", "\n", "\n", "attention_mat", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "\"attention_mat\"", ",", "\n", "shape", "=", "[", "user_embedding", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "query_size", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ",", "\n", ")", "\n", "att_inputs", "=", "tf", ".", "tensordot", "(", "user_embedding", ",", "attention_mat", ",", "[", "[", "2", "]", ",", "[", "0", "]", "]", ")", "\n", "\n", "queries", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "query", ",", "[", "1", ",", "att_inputs", ".", "shape", "[", "1", "]", "]", ")", ",", "tf", ".", "shape", "(", "input", "=", "att_inputs", ")", "\n", ")", "\n", "last_hidden_nn_layer", "=", "tf", ".", "concat", "(", "\n", "[", "att_inputs", ",", "queries", ",", "att_inputs", "-", "queries", ",", "att_inputs", "*", "queries", "]", ",", "-", "1", "\n", ")", "\n", "att_fnc_output", "=", "self", ".", "_fcn_net", "(", "\n", "last_hidden_nn_layer", ",", "hparams", ".", "att_fcn_layer_sizes", ",", "scope", "=", "\"att_fcn\"", "\n", ")", "\n", "att_fnc_output", "=", "tf", ".", "squeeze", "(", "att_fnc_output", ",", "-", "1", ")", "\n", "mask_paddings", "=", "tf", ".", "ones_like", "(", "att_fnc_output", ")", "*", "(", "-", "(", "2", "**", "32", ")", "+", "1", ")", "\n", "att_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "where", "(", "boolean_mask", ",", "att_fnc_output", ",", "mask_paddings", ")", ",", "\n", "name", "=", "\"att_weights\"", ",", "\n", ")", "\n", "output", "=", "user_embedding", "*", "tf", ".", "expand_dims", "(", "att_weights", ",", "-", "1", ")", "\n", "return", "output", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._build_seq_graph": [[24, 84], ["tensorflow.equal", "tensorflow.cond", "tensorflow.cond", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "enumerate", "tensorflow.cond", "tensorflow.cond", "nextitnet.NextItNetModel._nextitnet_residual_block_one", "nextitnet.NextItNetModel._nextitnet_residual_block_one", "tensorflow.cond.get_shape", "tensorflow.cond.get_shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._nextitnet_residual_block_one", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._nextitnet_residual_block_one"], ["def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create nextitnet model.\n\n        Returns:\n            object: The output of nextitnet section.\n        \"\"\"", "\n", "hparams", "=", "self", ".", "hparams", "\n", "is_training", "=", "tf", ".", "equal", "(", "self", ".", "is_train_stage", ",", "True", ")", "\n", "item_history_embedding", "=", "tf", ".", "cond", "(", "\n", "pred", "=", "is_training", ",", "\n", "true_fn", "=", "lambda", ":", "self", ".", "item_history_embedding", "[", "\n", ":", ":", "self", ".", "hparams", ".", "train_num_ngs", "+", "1", "\n", "]", ",", "\n", "false_fn", "=", "lambda", ":", "self", ".", "item_history_embedding", ",", "\n", ")", "\n", "cate_history_embedding", "=", "tf", ".", "cond", "(", "\n", "pred", "=", "is_training", ",", "\n", "true_fn", "=", "lambda", ":", "self", ".", "cate_history_embedding", "[", "\n", ":", ":", "self", ".", "hparams", ".", "train_num_ngs", "+", "1", "\n", "]", ",", "\n", "false_fn", "=", "lambda", ":", "self", ".", "cate_history_embedding", ",", "\n", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"nextitnet\"", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "            ", "dilate_input", "=", "tf", ".", "concat", "(", "\n", "[", "item_history_embedding", ",", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "\n", "for", "layer_id", ",", "dilation", "in", "enumerate", "(", "hparams", ".", "dilations", ")", ":", "\n", "                ", "dilate_input", "=", "tf", ".", "cond", "(", "\n", "pred", "=", "is_training", ",", "\n", "true_fn", "=", "lambda", ":", "self", ".", "_nextitnet_residual_block_one", "(", "\n", "dilate_input", ",", "\n", "dilation", ",", "\n", "layer_id", ",", "\n", "dilate_input", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "\n", "hparams", ".", "kernel_size", ",", "\n", "causal", "=", "True", ",", "\n", "train", "=", "True", ",", "\n", ")", ",", "\n", "false_fn", "=", "lambda", ":", "self", ".", "_nextitnet_residual_block_one", "(", "\n", "dilate_input", ",", "\n", "dilation", ",", "\n", "layer_id", ",", "\n", "dilate_input", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "\n", "hparams", ".", "kernel_size", ",", "\n", "causal", "=", "True", ",", "\n", "train", "=", "False", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "self", ".", "dilate_input", "=", "dilate_input", "\n", "model_output", "=", "tf", ".", "cond", "(", "\n", "pred", "=", "is_training", ",", "\n", "true_fn", "=", "self", ".", "_training_output", ",", "\n", "false_fn", "=", "self", ".", "_normal_output", ",", "\n", ")", "\n", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._training_output": [[85, 102], ["tensorflow.repeat", "tensorflow.concat", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape.get_shape", "tensorflow.reshape.get_shape"], "methods", ["None"], ["", "", "def", "_training_output", "(", "self", ")", ":", "\n", "        ", "model_output", "=", "tf", ".", "repeat", "(", "\n", "self", ".", "dilate_input", ",", "self", ".", "hparams", ".", "train_num_ngs", "+", "1", ",", "axis", "=", "0", "\n", ")", "\n", "model_output", "=", "tf", ".", "concat", "(", "[", "model_output", ",", "self", ".", "target_item_embedding", "]", ",", "-", "1", ")", "\n", "model_output", "=", "tf", ".", "reshape", "(", "\n", "model_output", ",", "\n", "(", "\n", "-", "1", ",", "\n", "self", ".", "hparams", ".", "train_num_ngs", "+", "1", ",", "\n", "self", ".", "hparams", ".", "max_seq_length", ",", "\n", "model_output", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "\n", ")", ",", "\n", ")", "\n", "model_output", "=", "tf", ".", "transpose", "(", "a", "=", "model_output", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "model_output", "=", "tf", ".", "reshape", "(", "model_output", ",", "(", "-", "1", ",", "model_output", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", ")", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._normal_output": [[103, 109], ["tensorflow.concat"], "methods", ["None"], ["", "def", "_normal_output", "(", "self", ")", ":", "\n", "        ", "model_output", "=", "self", ".", "dilate_input", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "model_output", "=", "tf", ".", "concat", "(", "\n", "[", "model_output", ",", "self", ".", "target_item_embedding", "[", ":", ",", "-", "1", ",", ":", "]", "]", ",", "-", "1", "\n", ")", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._nextitnet_residual_block_one": [[110, 162], ["tensorflow.compat.v1.variable_scope", "nextitnet.NextItNetModel._layer_norm", "tensorflow.nn.relu", "nextitnet.NextItNetModel._conv1d", "nextitnet.NextItNetModel._layer_norm", "tensorflow.nn.relu", "nextitnet.NextItNetModel._conv1d", "nextitnet.NextItNetModel._layer_norm", "tensorflow.nn.relu", "nextitnet.NextItNetModel._conv1d", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._layer_norm", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._conv1d", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._layer_norm", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._conv1d", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._layer_norm", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._conv1d"], ["", "def", "_nextitnet_residual_block_one", "(", "\n", "self", ",", "\n", "input_", ",", "\n", "dilation", ",", "\n", "layer_id", ",", "\n", "residual_channels", ",", "\n", "kernel_size", ",", "\n", "causal", "=", "True", ",", "\n", "train", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"The main function to use dilated CNN and residual network at sequence data\n\n        Args:\n            input_ (object): The output of history sequential embeddings\n            dilation (int): The dilation number of CNN layer\n            layer_id (str): String value of layer ID, 0, 1, 2...\n            residual_channels (int): Embedding size of input sequence\n            kernel_size (int): Kernel size of CNN mask\n            causal (bool): Whether to pad in front of the sequence or to pad surroundingly\n            train (bool): is in training stage\n\n        Returns:\n            object: The output of residual layers.\n        \"\"\"", "\n", "resblock_type", "=", "\"decoder\"", "\n", "resblock_name", "=", "\"nextitnet_residual_block_one_{}_layer_{}_{}\"", ".", "format", "(", "\n", "resblock_type", ",", "layer_id", ",", "dilation", "\n", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "resblock_name", ")", ":", "\n", "            ", "input_ln", "=", "self", ".", "_layer_norm", "(", "input_", ",", "name", "=", "\"layer_norm1\"", ",", "trainable", "=", "train", ")", "\n", "relu1", "=", "tf", ".", "nn", ".", "relu", "(", "input_ln", ")", "\n", "conv1", "=", "self", ".", "_conv1d", "(", "\n", "relu1", ",", "int", "(", "0.5", "*", "int", "(", "residual_channels", ")", ")", ",", "name", "=", "\"conv1d_1\"", "\n", ")", "\n", "conv1", "=", "self", ".", "_layer_norm", "(", "conv1", ",", "name", "=", "\"layer_norm2\"", ",", "trainable", "=", "train", ")", "\n", "relu2", "=", "tf", ".", "nn", ".", "relu", "(", "conv1", ")", "\n", "\n", "dilated_conv", "=", "self", ".", "_conv1d", "(", "\n", "relu2", ",", "\n", "int", "(", "0.5", "*", "int", "(", "residual_channels", ")", ")", ",", "\n", "dilation", ",", "\n", "kernel_size", ",", "\n", "causal", "=", "causal", ",", "\n", "name", "=", "\"dilated_conv\"", ",", "\n", ")", "\n", "\n", "dilated_conv", "=", "self", ".", "_layer_norm", "(", "\n", "dilated_conv", ",", "name", "=", "\"layer_norm3\"", ",", "trainable", "=", "train", "\n", ")", "\n", "relu3", "=", "tf", ".", "nn", ".", "relu", "(", "dilated_conv", ")", "\n", "conv2", "=", "self", ".", "_conv1d", "(", "relu3", ",", "residual_channels", ",", "name", "=", "\"conv1d_2\"", ")", "\n", "return", "input_", "+", "conv2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._conv1d": [[163, 214], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.squeeze", "tensorflow.pad", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.compat.v1.truncated_normal_initializer", "tensorflow.compat.v1.constant_initializer", "tensorflow.nn.atrous_conv2d", "tensorflow.nn.conv2d", "input_.get_shape"], "methods", ["None"], ["", "", "def", "_conv1d", "(", "\n", "self", ",", "\n", "input_", ",", "\n", "output_channels", ",", "\n", "dilation", "=", "1", ",", "\n", "kernel_size", "=", "1", ",", "\n", "causal", "=", "False", ",", "\n", "name", "=", "\"dilated_conv\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Call a dilated CNN layer\n\n        Returns:\n            object: The output of dilated CNN layers.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "weight", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"weight\"", ",", "\n", "[", "1", ",", "kernel_size", ",", "input_", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "output_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "truncated_normal_initializer", "(", "\n", "stddev", "=", "0.02", ",", "seed", "=", "1", "\n", ")", ",", "\n", ")", "\n", "bias", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"bias\"", ",", "\n", "[", "output_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", ")", "\n", "\n", "if", "causal", ":", "\n", "                ", "padding", "=", "[", "[", "0", ",", "0", "]", ",", "[", "(", "kernel_size", "-", "1", ")", "*", "dilation", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", "\n", "padded", "=", "tf", ".", "pad", "(", "tensor", "=", "input_", ",", "paddings", "=", "padding", ")", "\n", "input_expanded", "=", "tf", ".", "expand_dims", "(", "padded", ",", "axis", "=", "1", ")", "\n", "out", "=", "(", "\n", "tf", ".", "nn", ".", "atrous_conv2d", "(", "\n", "input_expanded", ",", "weight", ",", "rate", "=", "dilation", ",", "padding", "=", "\"VALID\"", "\n", ")", "\n", "+", "bias", "\n", ")", "\n", "", "else", ":", "\n", "                ", "input_expanded", "=", "tf", ".", "expand_dims", "(", "input_", ",", "axis", "=", "1", ")", "\n", "out", "=", "(", "\n", "tf", ".", "nn", ".", "conv2d", "(", "\n", "input", "=", "input_expanded", ",", "\n", "filters", "=", "weight", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", ")", "\n", "+", "bias", "\n", ")", "\n", "\n", "", "return", "tf", ".", "squeeze", "(", "out", ",", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.nextitnet.NextItNetModel._layer_norm": [[215, 241], ["tensorflow.compat.v1.variable_scope", "x.get_shape", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.moments", "tensorflow.sqrt", "int", "tensorflow.compat.v1.constant_initializer", "int", "tensorflow.compat.v1.constant_initializer", "len"], "methods", ["None"], ["", "", "def", "_layer_norm", "(", "self", ",", "x", ",", "name", ",", "epsilon", "=", "1e-8", ",", "trainable", "=", "True", ")", ":", "\n", "        ", "\"\"\"Call a layer normalization\n\n        Returns:\n            object: Normalized data\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "shape", "=", "x", ".", "get_shape", "(", ")", "\n", "beta", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"beta\"", ",", "\n", "[", "int", "(", "shape", "[", "-", "1", "]", ")", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "0", ")", ",", "\n", "trainable", "=", "trainable", ",", "\n", ")", "\n", "gamma", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"gamma\"", ",", "\n", "[", "int", "(", "shape", "[", "-", "1", "]", ")", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "1", ")", ",", "\n", "trainable", "=", "trainable", ",", "\n", ")", "\n", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", "=", "x", ",", "axes", "=", "[", "len", "(", "shape", ")", "-", "1", "]", ",", "keepdims", "=", "True", ")", "\n", "\n", "x", "=", "(", "x", "-", "mean", ")", "/", "tf", ".", "sqrt", "(", "variance", "+", "epsilon", ")", "\n", "\n", "return", "gamma", "*", "x", "+", "beta", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4LSTMCell.__init__": [[47, 120], ["tensorflow.python.ops.rnn_cell_impl.RNNCell.__init__", "tensorflow.python.platform.tf_logging.warn", "tensorflow.python.platform.tf_logging.warn", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_units", ",", "\n", "use_peepholes", "=", "False", ",", "\n", "cell_clip", "=", "None", ",", "\n", "initializer", "=", "None", ",", "\n", "num_proj", "=", "None", ",", "\n", "proj_clip", "=", "None", ",", "\n", "num_unit_shards", "=", "None", ",", "\n", "num_proj_shards", "=", "None", ",", "\n", "forget_bias", "=", "1.0", ",", "\n", "state_is_tuple", "=", "True", ",", "\n", "activation", "=", "None", ",", "\n", "reuse", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "Time4LSTMCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "if", "not", "state_is_tuple", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"%s: Using a concatenated state is slower and will soon be \"", "\n", "\"deprecated.  Use state_is_tuple=True.\"", ",", "\n", "self", ",", "\n", ")", "\n", "", "if", "num_unit_shards", "is", "not", "None", "or", "num_proj_shards", "is", "not", "None", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"%s: The num_unit_shards and proj_unit_shards parameters are \"", "\n", "\"deprecated and will be removed in Jan 2017.  \"", "\n", "\"Use a variable scope with a partitioner instead.\"", ",", "\n", "self", ",", "\n", ")", "\n", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_use_peepholes", "=", "use_peepholes", "\n", "self", ".", "_cell_clip", "=", "cell_clip", "\n", "self", ".", "_initializer", "=", "initializer", "\n", "self", ".", "_num_proj", "=", "num_proj", "\n", "self", ".", "_proj_clip", "=", "proj_clip", "\n", "self", ".", "_num_unit_shards", "=", "num_unit_shards", "\n", "self", ".", "_num_proj_shards", "=", "num_proj_shards", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "self", ".", "_activation", "=", "activation", "or", "math_ops", ".", "tanh", "\n", "\n", "if", "num_proj", ":", "\n", "            ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_proj", ")", "\n", "if", "state_is_tuple", "\n", "else", "num_units", "+", "num_proj", "\n", ")", "\n", "self", ".", "_output_size", "=", "num_proj", "\n", "", "else", ":", "\n", "            ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_units", ")", "\n", "if", "state_is_tuple", "\n", "else", "2", "*", "num_units", "\n", ")", "\n", "self", ".", "_output_size", "=", "num_units", "\n", "", "self", ".", "_linear1", "=", "None", "\n", "self", ".", "_linear2", "=", "None", "\n", "self", ".", "_time_input_w1", "=", "None", "\n", "self", ".", "_time_input_w2", "=", "None", "\n", "self", ".", "_time_kernel_w1", "=", "None", "\n", "self", ".", "_time_kernel_t1", "=", "None", "\n", "self", ".", "_time_bias1", "=", "None", "\n", "self", ".", "_time_kernel_w2", "=", "None", "\n", "self", ".", "_time_kernel_t2", "=", "None", "\n", "self", ".", "_time_bias2", "=", "None", "\n", "self", ".", "_o_kernel_t1", "=", "None", "\n", "self", ".", "_o_kernel_t2", "=", "None", "\n", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "self", ".", "_w_f_diag", "=", "None", "\n", "self", ".", "_w_i_diag", "=", "None", "\n", "self", ".", "_w_o_diag", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4LSTMCell.state_size": [[121, 124], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4LSTMCell.output_size": [[125, 128], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4LSTMCell.call": [[129, 299], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.tanh", "tensorflow.nn.tanh", "rnn_cell_implement.Time4LSTMCell._linear1", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.array_ops.slice", "tensorflow.python.ops.array_ops.slice", "inputs.get_shape().with_rank", "ValueError", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.clip_ops.clip_by_value", "rnn_cell_implement.Time4LSTMCell._linear2", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_implement._Linear", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.variable_scope", "sigmoid", "rnn_cell_implement.Time4LSTMCell._activation", "sigmoid", "rnn_cell_implement.Time4LSTMCell._activation", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.clip_ops.clip_by_value", "inputs.get_shape", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "unit_scope.set_partitioner", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "rnn_cell_implement.Time4LSTMCell._activation", "rnn_cell_implement.Time4LSTMCell._activation", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.partitioned_variables.fixed_size_partitioner", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_implement._Linear", "proj_scope.set_partitioner", "tensorflow.python.ops.partitioned_variables.fixed_size_partitioner"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "time_now_score", "=", "tf", ".", "expand_dims", "(", "inputs", "[", ":", ",", "-", "1", "]", ",", "-", "1", ")", "\n", "time_last_score", "=", "tf", ".", "expand_dims", "(", "inputs", "[", ":", ",", "-", "2", "]", ",", "-", "1", ")", "\n", "inputs", "=", "inputs", "[", ":", ",", ":", "-", "2", "]", "\n", "num_proj", "=", "self", ".", "_num_units", "if", "self", ".", "_num_proj", "is", "None", "else", "self", ".", "_num_proj", "\n", "sigmoid", "=", "math_ops", ".", "sigmoid", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "            ", "(", "c_prev", ",", "m_prev", ")", "=", "state", "\n", "", "else", ":", "\n", "            ", "c_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "self", ".", "_num_units", "]", ")", "\n", "m_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "self", ".", "_num_units", "]", ",", "[", "-", "1", ",", "num_proj", "]", ")", "\n", "\n", "", "dtype", "=", "inputs", ".", "dtype", "\n", "input_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "2", ")", "[", "1", "]", "\n", "if", "input_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Could not infer input size from inputs.get_shape()[-1]\"", ")", "\n", "\n", "", "if", "self", ".", "_time_kernel_w1", "is", "None", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "with", "vs", ".", "variable_scope", "(", "unit_scope", ")", ":", "\n", "                    ", "self", ".", "_time_input_w1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_w1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_bias1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_bias1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_w2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_w2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_bias2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_bias2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_kernel_w1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_w1\"", ",", "\n", "shape", "=", "[", "input_size", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_kernel_t1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_t1\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_bias1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_bias1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_kernel_w2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_w2\"", ",", "\n", "shape", "=", "[", "input_size", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_kernel_t2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_t2\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_bias2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_bias2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_o_kernel_t1", "=", "vs", ".", "get_variable", "(", "\n", "\"_o_kernel_t1\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_o_kernel_t2", "=", "vs", ".", "get_variable", "(", "\n", "\"_o_kernel_t2\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "\n", "", "", "", "time_now_input", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "time_now_score", "*", "self", ".", "_time_input_w1", "+", "self", ".", "_time_input_bias1", "\n", ")", "\n", "time_last_input", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "time_last_score", "*", "self", ".", "_time_input_w2", "+", "self", ".", "_time_input_bias2", "\n", ")", "\n", "\n", "time_now_state", "=", "(", "\n", "math_ops", ".", "matmul", "(", "inputs", ",", "self", ".", "_time_kernel_w1", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_now_input", ",", "self", ".", "_time_kernel_t1", ")", "\n", "+", "self", ".", "_time_bias1", "\n", ")", "\n", "time_last_state", "=", "(", "\n", "math_ops", ".", "matmul", "(", "inputs", ",", "self", ".", "_time_kernel_w2", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_last_input", ",", "self", ".", "_time_kernel_t2", ")", "\n", "+", "self", ".", "_time_bias2", "\n", ")", "\n", "\n", "if", "self", ".", "_linear1", "is", "None", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "if", "self", ".", "_num_unit_shards", "is", "not", "None", ":", "\n", "                    ", "unit_scope", ".", "set_partitioner", "(", "\n", "partitioned_variables", ".", "fixed_size_partitioner", "(", "\n", "self", ".", "_num_unit_shards", "\n", ")", "\n", ")", "\n", "", "self", ".", "_linear1", "=", "_Linear", "(", "[", "inputs", ",", "m_prev", "]", ",", "4", "*", "self", ".", "_num_units", ",", "True", ")", "\n", "\n", "# i = input_gate, j = new_input, f = forget_gate, o = output_gate", "\n", "", "", "lstm_matrix", "=", "self", ".", "_linear1", "(", "[", "inputs", ",", "m_prev", "]", ")", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "array_ops", ".", "split", "(", "value", "=", "lstm_matrix", ",", "num_or_size_splits", "=", "4", ",", "axis", "=", "1", ")", "\n", "o", "=", "(", "\n", "o", "\n", "+", "math_ops", ".", "matmul", "(", "time_now_input", ",", "self", ".", "_o_kernel_t1", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_last_input", ",", "self", ".", "_o_kernel_t2", ")", "\n", ")", "\n", "# Diagonal connections", "\n", "if", "self", ".", "_use_peepholes", "and", "not", "self", ".", "_w_f_diag", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "with", "vs", ".", "variable_scope", "(", "unit_scope", ")", ":", "\n", "                    ", "self", ".", "_w_f_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_f_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_w_i_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_i_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_w_o_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_o_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "\n", "", "", "", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "c", "=", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", "+", "self", ".", "_w_f_diag", "*", "c_prev", ")", "*", "sigmoid", "(", "\n", "time_last_state", "\n", ")", "*", "c_prev", "+", "sigmoid", "(", "i", "+", "self", ".", "_w_i_diag", "*", "c_prev", ")", "*", "sigmoid", "(", "\n", "time_now_state", "\n", ")", "*", "self", ".", "_activation", "(", "\n", "j", "\n", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", ")", "*", "sigmoid", "(", "\n", "time_last_state", "\n", ")", "*", "c_prev", "+", "sigmoid", "(", "i", ")", "*", "sigmoid", "(", "time_now_state", ")", "*", "self", ".", "_activation", "(", "j", ")", "\n", "\n", "", "if", "self", ".", "_cell_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "            ", "c", "=", "clip_ops", ".", "clip_by_value", "(", "c", ",", "-", "self", ".", "_cell_clip", ",", "self", ".", "_cell_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "m", "=", "sigmoid", "(", "o", "+", "self", ".", "_w_o_diag", "*", "c", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "", "else", ":", "\n", "            ", "m", "=", "sigmoid", "(", "o", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "_num_proj", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "_linear2", "is", "None", ":", "\n", "                ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", ":", "\n", "                    ", "with", "vs", ".", "variable_scope", "(", "\"projection\"", ")", "as", "proj_scope", ":", "\n", "                        ", "if", "self", ".", "_num_proj_shards", "is", "not", "None", ":", "\n", "                            ", "proj_scope", ".", "set_partitioner", "(", "\n", "partitioned_variables", ".", "fixed_size_partitioner", "(", "\n", "self", ".", "_num_proj_shards", "\n", ")", "\n", ")", "\n", "", "self", ".", "_linear2", "=", "_Linear", "(", "m", ",", "self", ".", "_num_proj", ",", "False", ")", "\n", "", "", "", "m", "=", "self", ".", "_linear2", "(", "m", ")", "\n", "\n", "if", "self", ".", "_proj_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "                ", "m", "=", "clip_ops", ".", "clip_by_value", "(", "m", ",", "-", "self", ".", "_proj_clip", ",", "self", ".", "_proj_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "\n", "", "", "new_state", "=", "(", "\n", "LSTMStateTuple", "(", "c", ",", "m", ")", "\n", "if", "self", ".", "_state_is_tuple", "\n", "else", "array_ops", ".", "concat", "(", "[", "c", ",", "m", "]", ",", "1", ")", "\n", ")", "\n", "return", "m", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4ALSTMCell.__init__": [[302, 375], ["tensorflow.python.ops.rnn_cell_impl.RNNCell.__init__", "tensorflow.python.platform.tf_logging.warn", "tensorflow.python.platform.tf_logging.warn", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_units", ",", "\n", "use_peepholes", "=", "False", ",", "\n", "cell_clip", "=", "None", ",", "\n", "initializer", "=", "None", ",", "\n", "num_proj", "=", "None", ",", "\n", "proj_clip", "=", "None", ",", "\n", "num_unit_shards", "=", "None", ",", "\n", "num_proj_shards", "=", "None", ",", "\n", "forget_bias", "=", "1.0", ",", "\n", "state_is_tuple", "=", "True", ",", "\n", "activation", "=", "None", ",", "\n", "reuse", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "Time4ALSTMCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "if", "not", "state_is_tuple", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"%s: Using a concatenated state is slower and will soon be \"", "\n", "\"deprecated.  Use state_is_tuple=True.\"", ",", "\n", "self", ",", "\n", ")", "\n", "", "if", "num_unit_shards", "is", "not", "None", "or", "num_proj_shards", "is", "not", "None", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"%s: The num_unit_shards and proj_unit_shards parameters are \"", "\n", "\"deprecated and will be removed in Jan 2017.  \"", "\n", "\"Use a variable scope with a partitioner instead.\"", ",", "\n", "self", ",", "\n", ")", "\n", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_use_peepholes", "=", "use_peepholes", "\n", "self", ".", "_cell_clip", "=", "cell_clip", "\n", "self", ".", "_initializer", "=", "initializer", "\n", "self", ".", "_num_proj", "=", "num_proj", "\n", "self", ".", "_proj_clip", "=", "proj_clip", "\n", "self", ".", "_num_unit_shards", "=", "num_unit_shards", "\n", "self", ".", "_num_proj_shards", "=", "num_proj_shards", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "self", ".", "_activation", "=", "activation", "or", "math_ops", ".", "tanh", "\n", "\n", "if", "num_proj", ":", "\n", "            ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_proj", ")", "\n", "if", "state_is_tuple", "\n", "else", "num_units", "+", "num_proj", "\n", ")", "\n", "self", ".", "_output_size", "=", "num_proj", "\n", "", "else", ":", "\n", "            ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_units", ")", "\n", "if", "state_is_tuple", "\n", "else", "2", "*", "num_units", "\n", ")", "\n", "self", ".", "_output_size", "=", "num_units", "\n", "", "self", ".", "_linear1", "=", "None", "\n", "self", ".", "_linear2", "=", "None", "\n", "self", ".", "_time_input_w1", "=", "None", "\n", "self", ".", "_time_input_w2", "=", "None", "\n", "self", ".", "_time_kernel_w1", "=", "None", "\n", "self", ".", "_time_kernel_t1", "=", "None", "\n", "self", ".", "_time_bias1", "=", "None", "\n", "self", ".", "_time_kernel_w2", "=", "None", "\n", "self", ".", "_time_kernel_t2", "=", "None", "\n", "self", ".", "_time_bias2", "=", "None", "\n", "self", ".", "_o_kernel_t1", "=", "None", "\n", "self", ".", "_o_kernel_t2", "=", "None", "\n", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "self", ".", "_w_f_diag", "=", "None", "\n", "self", ".", "_w_i_diag", "=", "None", "\n", "self", ".", "_w_o_diag", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4ALSTMCell.state_size": [[376, 379], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4ALSTMCell.output_size": [[380, 383], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement.Time4ALSTMCell.call": [[384, 556], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.tanh", "tensorflow.nn.tanh", "rnn_cell_implement.Time4ALSTMCell._linear1", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.array_ops.slice", "tensorflow.python.ops.array_ops.slice", "inputs.get_shape().with_rank", "ValueError", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.clip_ops.clip_by_value", "rnn_cell_implement.Time4ALSTMCell._linear2", "tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_implement._Linear", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.variable_scope", "sigmoid", "rnn_cell_implement.Time4ALSTMCell._activation", "sigmoid", "rnn_cell_implement.Time4ALSTMCell._activation", "tensorflow.python.ops.variable_scope.get_variable_scope", "tensorflow.python.ops.clip_ops.clip_by_value", "inputs.get_shape", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "unit_scope.set_partitioner", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "rnn_cell_implement.Time4ALSTMCell._activation", "rnn_cell_implement.Time4ALSTMCell._activation", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.partitioned_variables.fixed_size_partitioner", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_implement._Linear", "proj_scope.set_partitioner", "tensorflow.python.ops.partitioned_variables.fixed_size_partitioner"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sasrec.util.SASRecDataSet.split"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "att_score", "=", "tf", ".", "expand_dims", "(", "inputs", "[", ":", ",", "-", "1", "]", ",", "-", "1", ")", "\n", "time_now_score", "=", "tf", ".", "expand_dims", "(", "inputs", "[", ":", ",", "-", "2", "]", ",", "-", "1", ")", "\n", "time_last_score", "=", "tf", ".", "expand_dims", "(", "inputs", "[", ":", ",", "-", "3", "]", ",", "-", "1", ")", "\n", "inputs", "=", "inputs", "[", ":", ",", ":", "-", "3", "]", "\n", "num_proj", "=", "self", ".", "_num_units", "if", "self", ".", "_num_proj", "is", "None", "else", "self", ".", "_num_proj", "\n", "sigmoid", "=", "math_ops", ".", "sigmoid", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "            ", "(", "c_prev", ",", "m_prev", ")", "=", "state", "\n", "", "else", ":", "\n", "            ", "c_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "self", ".", "_num_units", "]", ")", "\n", "m_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "self", ".", "_num_units", "]", ",", "[", "-", "1", ",", "num_proj", "]", ")", "\n", "\n", "", "dtype", "=", "inputs", ".", "dtype", "\n", "input_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "2", ")", "[", "1", "]", "\n", "if", "input_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Could not infer input size from inputs.get_shape()[-1]\"", ")", "\n", "\n", "", "if", "self", ".", "_time_kernel_w1", "is", "None", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "with", "vs", ".", "variable_scope", "(", "unit_scope", ")", ":", "\n", "                    ", "self", ".", "_time_input_w1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_w1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_bias1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_bias1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_w2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_w2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_input_bias2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_input_bias2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_kernel_w1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_w1\"", ",", "\n", "shape", "=", "[", "input_size", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_kernel_t1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_t1\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_bias1", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_bias1\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_time_kernel_w2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_w2\"", ",", "\n", "shape", "=", "[", "input_size", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_kernel_t2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_kernel_t2\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_time_bias2", "=", "vs", ".", "get_variable", "(", "\n", "\"_time_bias2\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_o_kernel_t1", "=", "vs", ".", "get_variable", "(", "\n", "\"_o_kernel_t1\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "self", ".", "_o_kernel_t2", "=", "vs", ".", "get_variable", "(", "\n", "\"_o_kernel_t2\"", ",", "\n", "shape", "=", "[", "self", ".", "_num_units", ",", "self", ".", "_num_units", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", ")", "\n", "\n", "", "", "", "time_now_input", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "time_now_score", "*", "self", ".", "_time_input_w1", "+", "self", ".", "_time_input_bias1", "\n", ")", "\n", "time_last_input", "=", "tf", ".", "nn", ".", "tanh", "(", "\n", "time_last_score", "*", "self", ".", "_time_input_w2", "+", "self", ".", "_time_input_bias2", "\n", ")", "\n", "\n", "time_now_state", "=", "(", "\n", "math_ops", ".", "matmul", "(", "inputs", ",", "self", ".", "_time_kernel_w1", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_now_input", ",", "self", ".", "_time_kernel_t1", ")", "\n", "+", "self", ".", "_time_bias1", "\n", ")", "\n", "time_last_state", "=", "(", "\n", "math_ops", ".", "matmul", "(", "inputs", ",", "self", ".", "_time_kernel_w2", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_last_input", ",", "self", ".", "_time_kernel_t2", ")", "\n", "+", "self", ".", "_time_bias2", "\n", ")", "\n", "\n", "if", "self", ".", "_linear1", "is", "None", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "if", "self", ".", "_num_unit_shards", "is", "not", "None", ":", "\n", "                    ", "unit_scope", ".", "set_partitioner", "(", "\n", "partitioned_variables", ".", "fixed_size_partitioner", "(", "\n", "self", ".", "_num_unit_shards", "\n", ")", "\n", ")", "\n", "", "self", ".", "_linear1", "=", "_Linear", "(", "[", "inputs", ",", "m_prev", "]", ",", "4", "*", "self", ".", "_num_units", ",", "True", ")", "\n", "\n", "# i = input_gate, j = new_input, f = forget_gate, o = output_gate", "\n", "", "", "lstm_matrix", "=", "self", ".", "_linear1", "(", "[", "inputs", ",", "m_prev", "]", ")", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "array_ops", ".", "split", "(", "value", "=", "lstm_matrix", ",", "num_or_size_splits", "=", "4", ",", "axis", "=", "1", ")", "\n", "o", "=", "(", "\n", "o", "\n", "+", "math_ops", ".", "matmul", "(", "time_now_input", ",", "self", ".", "_o_kernel_t1", ")", "\n", "+", "math_ops", ".", "matmul", "(", "time_last_input", ",", "self", ".", "_o_kernel_t2", ")", "\n", ")", "\n", "# Diagonal connections", "\n", "if", "self", ".", "_use_peepholes", "and", "not", "self", ".", "_w_f_diag", ":", "\n", "            ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", "as", "unit_scope", ":", "\n", "                ", "with", "vs", ".", "variable_scope", "(", "unit_scope", ")", ":", "\n", "                    ", "self", ".", "_w_f_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_f_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_w_i_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_i_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "self", ".", "_w_o_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"w_o_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", "\n", ")", "\n", "\n", "", "", "", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "c", "=", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", "+", "self", ".", "_w_f_diag", "*", "c_prev", ")", "*", "sigmoid", "(", "\n", "time_last_state", "\n", ")", "*", "c_prev", "+", "sigmoid", "(", "i", "+", "self", ".", "_w_i_diag", "*", "c_prev", ")", "*", "sigmoid", "(", "\n", "time_now_state", "\n", ")", "*", "self", ".", "_activation", "(", "\n", "j", "\n", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", ")", "*", "sigmoid", "(", "\n", "time_last_state", "\n", ")", "*", "c_prev", "+", "sigmoid", "(", "i", ")", "*", "sigmoid", "(", "time_now_state", ")", "*", "self", ".", "_activation", "(", "j", ")", "\n", "\n", "", "if", "self", ".", "_cell_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "            ", "c", "=", "clip_ops", ".", "clip_by_value", "(", "c", ",", "-", "self", ".", "_cell_clip", ",", "self", ".", "_cell_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "", "if", "self", ".", "_use_peepholes", ":", "\n", "            ", "m", "=", "sigmoid", "(", "o", "+", "self", ".", "_w_o_diag", "*", "c", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "", "else", ":", "\n", "            ", "m", "=", "sigmoid", "(", "o", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "_num_proj", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "_linear2", "is", "None", ":", "\n", "                ", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ",", "initializer", "=", "self", ".", "_initializer", ")", ":", "\n", "                    ", "with", "vs", ".", "variable_scope", "(", "\"projection\"", ")", "as", "proj_scope", ":", "\n", "                        ", "if", "self", ".", "_num_proj_shards", "is", "not", "None", ":", "\n", "                            ", "proj_scope", ".", "set_partitioner", "(", "\n", "partitioned_variables", ".", "fixed_size_partitioner", "(", "\n", "self", ".", "_num_proj_shards", "\n", ")", "\n", ")", "\n", "", "self", ".", "_linear2", "=", "_Linear", "(", "m", ",", "self", ".", "_num_proj", ",", "False", ")", "\n", "", "", "", "m", "=", "self", ".", "_linear2", "(", "m", ")", "\n", "\n", "if", "self", ".", "_proj_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "                ", "m", "=", "clip_ops", ".", "clip_by_value", "(", "m", ",", "-", "self", ".", "_proj_clip", ",", "self", ".", "_proj_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "", "", "c", "=", "att_score", "*", "c", "+", "(", "1.0", "-", "att_score", ")", "*", "c", "\n", "m", "=", "att_score", "*", "m", "+", "(", "1.0", "-", "att_score", ")", "*", "m", "\n", "new_state", "=", "(", "\n", "LSTMStateTuple", "(", "c", ",", "m", ")", "\n", "if", "self", ".", "_state_is_tuple", "\n", "else", "array_ops", ".", "concat", "(", "[", "c", ",", "m", "]", ",", "1", ")", "\n", ")", "\n", "return", "m", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement._Linear.__init__": [[574, 628], ["tensorflow.python.ops.variable_scope.get_variable_scope", "ValueError", "tensorflow.python.util.nest.is_sequence", "a.get_shape", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.util.nest.is_sequence", "ValueError", "ValueError", "tensorflow.python.ops.variable_scope.variable_scope", "inner_scope.set_partitioner", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.init_ops.constant_initializer"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "args", ",", "\n", "output_size", ",", "\n", "build_bias", ",", "\n", "bias_initializer", "=", "None", ",", "\n", "kernel_initializer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_build_bias", "=", "build_bias", "\n", "\n", "if", "args", "is", "None", "or", "(", "nest", ".", "is_sequence", "(", "args", ")", "and", "not", "args", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"`args` must be specified\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "args", ")", ":", "\n", "            ", "args", "=", "[", "args", "]", "\n", "self", ".", "_is_sequence", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "_is_sequence", "=", "True", "\n", "\n", "# Calculate the total size of arguments on dimension 1.", "\n", "", "total_arg_size", "=", "0", "\n", "shapes", "=", "[", "a", ".", "get_shape", "(", ")", "for", "a", "in", "args", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "            ", "if", "shape", ".", "ndims", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"linear is expecting 2D arguments: %s\"", "%", "shapes", ")", "\n", "", "if", "shape", "[", "1", "]", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"linear expects shape[1] to be provided for shape %s, \"", "\n", "\"but saw %s\"", "%", "(", "shape", ",", "shape", "[", "1", "]", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "total_arg_size", "+=", "shape", "[", "1", "]", "\n", "\n", "", "", "dtype", "=", "[", "a", ".", "dtype", "for", "a", "in", "args", "]", "[", "0", "]", "\n", "\n", "scope", "=", "vs", ".", "get_variable_scope", "(", ")", "\n", "with", "vs", ".", "variable_scope", "(", "scope", ")", "as", "outer_scope", ":", "\n", "            ", "self", ".", "_weights", "=", "vs", ".", "get_variable", "(", "\n", "_WEIGHTS_VARIABLE_NAME", ",", "\n", "[", "total_arg_size", ",", "output_size", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "kernel_initializer", ",", "\n", ")", "\n", "if", "build_bias", ":", "\n", "                ", "with", "vs", ".", "variable_scope", "(", "outer_scope", ")", "as", "inner_scope", ":", "\n", "                    ", "inner_scope", ".", "set_partitioner", "(", "None", ")", "\n", "if", "bias_initializer", "is", "None", ":", "\n", "                        ", "bias_initializer", "=", "init_ops", ".", "constant_initializer", "(", "\n", "0.0", ",", "dtype", "=", "dtype", "\n", ")", "\n", "", "self", ".", "_biases", "=", "vs", ".", "get_variable", "(", "\n", "_BIAS_VARIABLE_NAME", ",", "\n", "[", "output_size", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "bias_initializer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.rnn_cell_implement._Linear.__call__": [[630, 641], ["len", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.nn_ops.bias_add", "tensorflow.python.ops.array_ops.concat"], "methods", ["None"], ["", "", "", "", "def", "__call__", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "not", "self", ".", "_is_sequence", ":", "\n", "            ", "args", "=", "[", "args", "]", "\n", "\n", "", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "            ", "res", "=", "math_ops", ".", "matmul", "(", "args", "[", "0", "]", ",", "self", ".", "_weights", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "math_ops", ".", "matmul", "(", "array_ops", ".", "concat", "(", "args", ",", "1", ")", ",", "self", ".", "_weights", ")", "\n", "", "if", "self", ".", "_build_bias", ":", "\n", "            ", "res", "=", "nn_ops", ".", "bias_add", "(", "res", ",", "self", ".", "_biases", ")", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.gru4rec.GRU4RecModel._build_seq_graph": [[23, 35], ["tensorflow.compat.v1.variable_scope", "gru4rec.GRU4RecModel._build_gru", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.gru4rec.GRU4RecModel._build_gru"], ["def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create GRU4Rec model.\n\n        Returns:\n            object:the output of GRU4Rec section.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"gru4rec\"", ")", ":", "\n", "# final_state = self._build_lstm()", "\n", "            ", "final_state", "=", "self", ".", "_build_gru", "(", ")", "\n", "model_output", "=", "tf", ".", "concat", "(", "[", "final_state", ",", "self", ".", "target_item_embedding", "]", ",", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"model_output\"", ",", "model_output", ")", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.gru4rec.GRU4RecModel._build_lstm": [[36, 57], ["tensorflow.compat.v1.name_scope", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.compat.v1.nn.dynamic_rnn", "tensorflow.compat.v1.summary.histogram", "keras.layers.legacy_rnn.rnn_cell_impl.LSTMCell"], "methods", ["None"], ["", "", "def", "_build_lstm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Apply an LSTM for modeling.\n\n        Returns:\n            object: The output of LSTM section.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"lstm\"", ")", ":", "\n", "            ", "self", ".", "mask", "=", "self", ".", "iterator", ".", "mask", "\n", "self", ".", "sequence_length", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "mask", ",", "axis", "=", "1", ")", "\n", "self", ".", "history_embedding", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_history_embedding", ",", "self", ".", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "rnn_outputs", ",", "final_state", "=", "dynamic_rnn", "(", "\n", "LSTMCell", "(", "self", ".", "hidden_size", ")", ",", "\n", "inputs", "=", "self", ".", "history_embedding", ",", "\n", "sequence_length", "=", "self", ".", "sequence_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "scope", "=", "\"lstm\"", ",", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"LSTM_outputs\"", ",", "rnn_outputs", ")", "\n", "return", "final_state", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.gru4rec.GRU4RecModel._build_gru": [[58, 79], ["tensorflow.compat.v1.name_scope", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.compat.v1.nn.dynamic_rnn", "tensorflow.compat.v1.summary.histogram", "keras.layers.legacy_rnn.rnn_cell_impl.GRUCell"], "methods", ["None"], ["", "", "def", "_build_gru", "(", "self", ")", ":", "\n", "        ", "\"\"\"Apply a GRU for modeling.\n\n        Returns:\n            object: The output of GRU section.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"gru\"", ")", ":", "\n", "            ", "self", ".", "mask", "=", "self", ".", "iterator", ".", "mask", "\n", "self", ".", "sequence_length", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "mask", ",", "axis", "=", "1", ")", "\n", "self", ".", "history_embedding", "=", "tf", ".", "concat", "(", "\n", "[", "self", ".", "item_history_embedding", ",", "self", ".", "cate_history_embedding", "]", ",", "2", "\n", ")", "\n", "rnn_outputs", ",", "final_state", "=", "dynamic_rnn", "(", "\n", "GRUCell", "(", "self", ".", "hidden_size", ")", ",", "\n", "inputs", "=", "self", ".", "history_embedding", ",", "\n", "sequence_length", "=", "self", ".", "sequence_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "scope", "=", "\"gru\"", ",", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"GRU_outputs\"", ",", "rnn_outputs", ")", "\n", "return", "final_state", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.__init__": [[25, 60], ["keras.layers.legacy_rnn.rnn_cell_impl.LayerRNNCell.__init__", "sum_cells._check_supported_dtypes", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "tensorflow.python.eager.context.executing_eagerly", "tensorflow.python.platform.tf_logging.warn", "tensorflow.python.keras.activations.get", "tensorflow.python.eager.context.num_gpus"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_supported_dtypes"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_units", ",", "\n", "slots", ",", "\n", "attention_size", ",", "\n", "input_size", ",", "\n", "activation", "=", "None", ",", "\n", "reuse", "=", "None", ",", "\n", "kernel_initializer", "=", "None", ",", "\n", "bias_initializer", "=", "None", ",", "\n", "name", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "SUMCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ",", "name", "=", "name", ",", "dtype", "=", "dtype", ",", "**", "kwargs", ")", "\n", "_check_supported_dtypes", "(", "self", ".", "dtype", ")", "\n", "\n", "if", "context", ".", "executing_eagerly", "(", ")", "and", "context", ".", "num_gpus", "(", ")", ">", "0", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"%s: Note that this cell is not optimized for performance. \"", "\n", "\"Please use keras.layers.cudnn_recurrent.CuDNNGRU for better \"", "\n", "\"performance on GPU.\"", ",", "\n", "self", ",", "\n", ")", "\n", "\n", "", "self", ".", "_input_size", "=", "input_size", "\n", "self", ".", "_slots", "=", "slots", "-", "1", "# the last channel is reserved for the highway slot", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_real_units", "=", "(", "self", ".", "_num_units", "-", "input_size", ")", "//", "slots", "\n", "if", "activation", ":", "\n", "            ", "self", ".", "_activation", "=", "activations", ".", "get", "(", "activation", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_activation", "=", "math_ops", ".", "tanh", "\n", "", "self", ".", "_kernel_initializer", "=", "initializers", ".", "get", "(", "kernel_initializer", ")", "\n", "self", ".", "_bias_initializer", "=", "initializers", ".", "get", "(", "bias_initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.state_size": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.output_size": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell._basic_build": [[69, 132], ["sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "sum_cells.SUMCell.add_variable", "tensorflow.compat.v1.constant_initializer", "tensorflow.compat.v1.constant_initializer", "tensorflow.python.ops.init_ops.constant_initializer", "tensorflow.python.ops.init_ops.constant_initializer", "tensorflow.python.ops.init_ops.constant_initializer", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_basic_build", "(", "self", ",", "inputs_shape", ")", ":", "\n", "        ", "\"\"\"Common initialization operations for SUM cell and its variants.\n        This function creates parameters for the cell.\n        \"\"\"", "\n", "\n", "d", "=", "inputs_shape", "[", "-", "1", "]", "\n", "h", "=", "self", ".", "_real_units", "\n", "s", "=", "self", ".", "_slots", "\n", "\n", "self", ".", "_erase_W", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_erase_W\"", ",", "shape", "=", "[", "d", "+", "h", ",", "h", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "self", ".", "_erase_b", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_erase_b\"", ",", "\n", "shape", "=", "[", "h", "]", ",", "\n", "initializer", "=", "(", "\n", "self", ".", "_bias_initializer", "\n", "if", "self", ".", "_bias_initializer", "is", "not", "None", "\n", "else", "init_ops", ".", "constant_initializer", "(", "1.0", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "self", ".", "_reset_W", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_reset_W\"", ",", "shape", "=", "[", "d", "+", "h", ",", "1", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "self", ".", "_reset_b", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_reset_b\"", ",", "\n", "shape", "=", "[", "1", "]", ",", "\n", "initializer", "=", "(", "\n", "self", ".", "_bias_initializer", "\n", "if", "self", ".", "_bias_initializer", "is", "not", "None", "\n", "else", "init_ops", ".", "constant_initializer", "(", "1.0", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "self", ".", "_add_W", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_add_W\"", ",", "shape", "=", "[", "d", "+", "h", ",", "h", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "self", ".", "_add_b", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_add_b\"", ",", "\n", "shape", "=", "[", "h", "]", ",", "\n", "initializer", "=", "(", "\n", "self", ".", "_bias_initializer", "\n", "if", "self", ".", "_bias_initializer", "is", "not", "None", "\n", "else", "init_ops", ".", "constant_initializer", "(", "1.0", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", ")", ",", "\n", ")", "\n", "self", ".", "heads", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_heads\"", ",", "shape", "=", "[", "s", ",", "d", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "\n", "self", ".", "_beta", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_beta_no_reg\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "\n", "np", ".", "array", "(", "[", "1.02", "]", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", ",", "\n", ")", "\n", "self", ".", "_alpha", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_alpha_no_reg\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "\n", "np", ".", "array", "(", "[", "0.98", "]", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.build": [[135, 163], ["sum_cells._check_supported_dtypes", "sum_cells.SUMCell._basic_build", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_supported_dtypes", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell._basic_build"], ["", "@", "tf_utils", ".", "shape_type_conversion", "\n", "def", "build", "(", "self", ",", "inputs_shape", ")", ":", "\n", "        ", "\"\"\"Initialization operations for SUM cell.\n        this function creates all the parameters for the cell.\n        \"\"\"", "\n", "if", "inputs_shape", "[", "-", "1", "]", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected inputs.shape[-1] to be known, saw shape: %s\"", "\n", "%", "str", "(", "inputs_shape", ")", "\n", ")", "\n", "", "_check_supported_dtypes", "(", "self", ".", "dtype", ")", "\n", "d", "=", "inputs_shape", "[", "-", "1", "]", "# noqa: F841", "\n", "h", "=", "self", ".", "_real_units", "# noqa: F841", "\n", "s", "=", "self", ".", "_slots", "# noqa: F841", "\n", "\n", "self", ".", "_basic_build", "(", "inputs_shape", ")", "\n", "\n", "self", ".", "parameter_set", "=", "[", "\n", "self", ".", "_erase_W", ",", "\n", "self", ".", "_erase_b", ",", "\n", "self", ".", "_reset_W", ",", "\n", "self", ".", "_reset_b", ",", "\n", "self", ".", "_add_W", ",", "\n", "self", ".", "_add_b", ",", "\n", "self", ".", "heads", ",", "\n", "]", "\n", "\n", "self", ".", "built", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.call": [[164, 229], ["sum_cells._check_rnn_cell_input_dtypes", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.math.pow", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "tensorflow.reshape", "tensorflow.concat", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_rnn_cell_input_dtypes"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "\"\"\"The real operations for SUM cell to process user behaviors.\n\n        params:\n            inputs: (a batch of) user behaviors at time T\n            state:  (a batch of) user states at time T-1\n\n        returns:\n            state, state:\n            - after process the user behavior at time T, returns (a batch of) new user states at time T\n            - after process the user behavior at time T, returns (a batch of) new user states at time T\n        \"\"\"", "\n", "_check_rnn_cell_input_dtypes", "(", "[", "inputs", ",", "state", "]", ")", "\n", "\n", "h", "=", "self", ".", "_real_units", "\n", "s", "=", "self", ".", "_slots", "+", "1", "\n", "state", ",", "last", "=", "state", "[", ":", ",", ":", "s", "*", "h", "]", ",", "state", "[", ":", ",", "s", "*", "h", ":", "]", "\n", "state", "=", "tf", ".", "reshape", "(", "state", ",", "[", "-", "1", ",", "s", ",", "h", "]", ")", "\n", "\n", "att_logit_mat", "=", "tf", ".", "matmul", "(", "inputs", ",", "self", ".", "heads", ",", "transpose_b", "=", "True", ")", "\n", "\n", "att_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "_beta", "*", "att_logit_mat", ",", "axis", "=", "-", "1", ")", "\n", "att_weights", "=", "tf", ".", "expand_dims", "(", "att_weights", ",", "2", ")", "\n", "\n", "h_hat", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "multiply", "(", "state", "[", ":", ",", ":", "self", ".", "_slots", ",", ":", "]", ",", "att_weights", ")", ",", "axis", "=", "1", "\n", ")", "\n", "h_hat", "=", "(", "h_hat", "+", "state", "[", ":", ",", "self", ".", "_slots", ",", ":", "]", ")", "/", "2", "\n", "\n", "n_a", ",", "n_b", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "last", ",", "1", ")", ",", "tf", ".", "nn", ".", "l2_normalize", "(", "inputs", ",", "1", ")", "\n", "dist", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "n_a", "*", "n_b", ",", "axis", "=", "1", ")", ",", "1", ")", "\n", "dist", "=", "tf", ".", "math", ".", "pow", "(", "self", ".", "_alpha", ",", "dist", ")", "\n", "\n", "att_weights", "=", "att_weights", "*", "tf", ".", "expand_dims", "(", "dist", ",", "1", ")", "\n", "\n", "reset", "=", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_reset_W", ",", "self", ".", "_reset_b", "\n", ")", "\n", ")", "\n", "erase", "=", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_erase_W", ",", "self", ".", "_erase_b", "\n", ")", "\n", ")", "\n", "add", "=", "tf", ".", "tanh", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "reset", "*", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_add_W", ",", "self", ".", "_add_b", "\n", ")", "\n", ")", "\n", "\n", "start_part01", "=", "state", "[", ":", ",", ":", "self", ".", "_slots", ",", ":", "]", "\n", "state01", "=", "start_part01", "*", "(", "\n", "tf", ".", "ones_like", "(", "start_part01", ")", "-", "att_weights", "*", "tf", ".", "expand_dims", "(", "erase", ",", "1", ")", "\n", ")", "\n", "state01", "=", "state01", "+", "att_weights", "*", "tf", ".", "expand_dims", "(", "erase", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "\n", "add", ",", "1", "\n", ")", "\n", "state01", "=", "tf", ".", "reshape", "(", "state01", ",", "[", "-", "1", ",", "self", ".", "_slots", "*", "self", ".", "_real_units", "]", ")", "\n", "\n", "start_part02", "=", "state", "[", ":", ",", "self", ".", "_slots", ",", ":", "]", "\n", "state02", "=", "start_part02", "*", "(", "tf", ".", "ones_like", "(", "start_part02", ")", "-", "dist", "*", "erase", ")", "\n", "state02", "=", "state02", "+", "dist", "*", "erase", "*", "add", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state01", ",", "state02", ",", "inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "return", "state", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.get_config": [[230, 240], ["super().get_config", "dict", "tensorflow.python.keras.initializers.serialize", "tensorflow.python.keras.initializers.serialize", "tensorflow.python.keras.activations.serialize", "list", "list", "super().get_config.items", "config.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell.get_config", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"num_units\"", ":", "self", ".", "_num_units", ",", "\n", "\"kernel_initializer\"", ":", "initializers", ".", "serialize", "(", "self", ".", "_kernel_initializer", ")", ",", "\n", "\"bias_initializer\"", ":", "initializers", ".", "serialize", "(", "self", ".", "_bias_initializer", ")", ",", "\n", "\"activation\"", ":", "activations", ".", "serialize", "(", "self", ".", "_activation", ")", ",", "\n", "\"reuse\"", ":", "self", ".", "_reuse", ",", "\n", "}", "\n", "base_config", "=", "super", "(", "SUMCell", ",", "self", ")", ".", "get_config", "(", ")", "\n", "return", "dict", "(", "list", "(", "base_config", ".", "items", "(", ")", ")", "+", "list", "(", "config", ".", "items", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMV2Cell.build": [[245, 292], ["sum_cells._check_supported_dtypes", "sum_cells.SUMV2Cell._basic_build", "sum_cells.SUMV2Cell.add_variable", "sum_cells.SUMV2Cell.add_variable", "sum_cells.SUMV2Cell.add_variable", "ValueError", "str", "tensorflow.python.ops.init_ops.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_supported_dtypes", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMCell._basic_build"], ["@", "tf_utils", ".", "shape_type_conversion", "\n", "def", "build", "(", "self", ",", "inputs_shape", ")", ":", "\n", "        ", "\"\"\"Initialization operations for SUMV2 cell.\n        this function creates all the parameters for the cell.\n        \"\"\"", "\n", "if", "inputs_shape", "[", "-", "1", "]", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected inputs.shape[-1] to be known, saw shape: %s\"", "\n", "%", "str", "(", "inputs_shape", ")", "\n", ")", "\n", "", "_check_supported_dtypes", "(", "self", ".", "dtype", ")", "\n", "d", "=", "inputs_shape", "[", "-", "1", "]", "\n", "h", "=", "self", ".", "_real_units", "\n", "s", "=", "self", ".", "_slots", "\n", "\n", "self", ".", "_basic_build", "(", "inputs_shape", ")", "\n", "\n", "self", ".", "_writing_W", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_writing_W\"", ",", "shape", "=", "[", "d", "+", "h", ",", "h", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "self", ".", "_writing_b", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_writing_b\"", ",", "\n", "shape", "=", "[", "h", "]", ",", "\n", "initializer", "=", "(", "\n", "self", ".", "_bias_initializer", "\n", "if", "self", ".", "_bias_initializer", "is", "not", "None", "\n", "else", "init_ops", ".", "constant_initializer", "(", "1.0", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", ")", ",", "\n", ")", "\n", "self", ".", "_writing_W02", "=", "self", ".", "add_variable", "(", "\n", "name", "=", "\"_writing_W02\"", ",", "shape", "=", "[", "h", ",", "s", "]", ",", "initializer", "=", "self", ".", "_kernel_initializer", "\n", ")", "\n", "\n", "self", ".", "parameter_set", "=", "[", "\n", "self", ".", "_erase_W", ",", "\n", "self", ".", "_erase_b", ",", "\n", "self", ".", "_reset_W", ",", "\n", "self", ".", "_reset_b", ",", "\n", "self", ".", "_add_W", ",", "\n", "self", ".", "_add_b", ",", "\n", "self", ".", "heads", ",", "\n", "self", ".", "_writing_W", ",", "\n", "self", ".", "_writing_W02", ",", "\n", "self", ".", "_writing_b", ",", "\n", "]", "\n", "\n", "self", ".", "built", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells.SUMV2Cell.call": [[293, 367], ["sum_cells._check_rnn_cell_input_dtypes", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.math.pow", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "tensorflow.reshape", "tensorflow.concat", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.compat.v1.nn.xw_plus_b", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_rnn_cell_input_dtypes"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "\"\"\"The real operations for SUMV2 cell to process user behaviors.\n\n        Args:\n            inputs: (a batch of) user behaviors at time T\n            state:  (a batch of) user states at time T-1\n\n        Returns:\n            state: after process the user behavior at time T, returns (a batch of) new user states at time T\n            state: after process the user behavior at time T, returns (a batch of) new user states at time T\n        \"\"\"", "\n", "_check_rnn_cell_input_dtypes", "(", "[", "inputs", ",", "state", "]", ")", "\n", "\n", "h", "=", "self", ".", "_real_units", "\n", "s", "=", "self", ".", "_slots", "+", "1", "\n", "state", ",", "last", "=", "state", "[", ":", ",", ":", "s", "*", "h", "]", ",", "state", "[", ":", ",", "s", "*", "h", ":", "]", "\n", "state", "=", "tf", ".", "reshape", "(", "state", ",", "[", "-", "1", ",", "s", ",", "h", "]", ")", "\n", "\n", "att_logit_mat", "=", "tf", ".", "matmul", "(", "inputs", ",", "self", ".", "heads", ",", "transpose_b", "=", "True", ")", "\n", "\n", "att_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "_beta", "*", "att_logit_mat", ",", "axis", "=", "-", "1", ")", "\n", "att_weights", "=", "tf", ".", "expand_dims", "(", "att_weights", ",", "2", ")", "\n", "\n", "h_hat", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "multiply", "(", "state", "[", ":", ",", ":", "self", ".", "_slots", ",", ":", "]", ",", "att_weights", ")", ",", "axis", "=", "1", "\n", ")", "\n", "h_hat", "=", "(", "h_hat", "+", "state", "[", ":", ",", "self", ".", "_slots", ",", ":", "]", ")", "/", "2", "\n", "\n", "# get the true writing attentions", "\n", "writing_input", "=", "tf", ".", "concat", "(", "[", "inputs", ",", "h_hat", "]", ",", "axis", "=", "1", ")", "\n", "att_weights", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "writing_input", ",", "self", ".", "_writing_W", ",", "self", ".", "_writing_b", "\n", ")", "\n", "att_weights", "=", "tf", ".", "nn", ".", "relu", "(", "att_weights", ")", "\n", "att_weights", "=", "tf", ".", "matmul", "(", "att_weights", ",", "self", ".", "_writing_W02", ")", "\n", "att_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "att_weights", ",", "axis", "=", "-", "1", ")", "\n", "att_weights", "=", "tf", ".", "expand_dims", "(", "att_weights", ",", "2", ")", "\n", "\n", "n_a", ",", "n_b", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "last", ",", "1", ")", ",", "tf", ".", "nn", ".", "l2_normalize", "(", "inputs", ",", "1", ")", "\n", "dist", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "n_a", "*", "n_b", ",", "axis", "=", "1", ")", ",", "1", ")", "\n", "dist", "=", "tf", ".", "math", ".", "pow", "(", "self", ".", "_alpha", ",", "dist", ")", "\n", "\n", "att_weights", "=", "att_weights", "*", "tf", ".", "expand_dims", "(", "dist", ",", "1", ")", "\n", "\n", "reset", "=", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_reset_W", ",", "self", ".", "_reset_b", "\n", ")", "\n", ")", "\n", "erase", "=", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_erase_W", ",", "self", ".", "_erase_b", "\n", ")", "\n", ")", "\n", "add", "=", "tf", ".", "tanh", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "xw_plus_b", "(", "\n", "tf", ".", "concat", "(", "[", "inputs", ",", "reset", "*", "h_hat", "]", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "_add_W", ",", "self", ".", "_add_b", "\n", ")", "\n", ")", "\n", "\n", "start_part01", "=", "state", "[", ":", ",", ":", "self", ".", "_slots", ",", ":", "]", "\n", "state01", "=", "start_part01", "*", "(", "\n", "tf", ".", "ones_like", "(", "start_part01", ")", "-", "att_weights", "*", "tf", ".", "expand_dims", "(", "erase", ",", "1", ")", "\n", ")", "\n", "state01", "=", "state01", "+", "att_weights", "*", "tf", ".", "expand_dims", "(", "erase", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "\n", "add", ",", "1", "\n", ")", "\n", "state01", "=", "tf", ".", "reshape", "(", "state01", ",", "[", "-", "1", ",", "self", ".", "_slots", "*", "self", ".", "_real_units", "]", ")", "\n", "\n", "start_part02", "=", "state", "[", ":", ",", "self", ".", "_slots", ",", ":", "]", "\n", "state02", "=", "start_part02", "*", "(", "tf", ".", "ones_like", "(", "start_part02", ")", "-", "dist", "*", "erase", ")", "\n", "state02", "=", "state02", "+", "dist", "*", "erase", "*", "add", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state01", ",", "state02", ",", "inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "return", "state", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_rnn_cell_input_dtypes": [[369, 372], ["tensorflow.python.util.nest.flatten", "sum_cells._check_supported_dtypes"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_supported_dtypes"], ["", "", "def", "_check_rnn_cell_input_dtypes", "(", "inputs", ")", ":", "\n", "    ", "for", "t", "in", "nest", ".", "flatten", "(", "inputs", ")", ":", "\n", "        ", "_check_supported_dtypes", "(", "t", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sum_cells._check_supported_dtypes": [[374, 381], ["tensorflow.python.framework.dtypes.as_dtype", "ValueError"], "function", ["None"], ["", "", "def", "_check_supported_dtypes", "(", "dtype", ")", ":", "\n", "    ", "if", "dtype", "is", "None", ":", "\n", "        ", "return", "\n", "", "dtype", "=", "dtypes", ".", "as_dtype", "(", "dtype", ")", "\n", "if", "not", "(", "dtype", ".", "is_floating", "or", "dtype", ".", "is_complex", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"RNN cell only supports floating point inputs, \"", "\"but saw dtype: %s\"", "%", "dtype", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel.__init__": [[22, 38], ["recommenders.models.deeprec.models.sequential.sequential_base_model.SequentialBaseModel.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "iterator_creator", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization of variables for caser\n\n        Args:\n            hparams (HParams): A HParams object, hold the entire set of hyperparameters.\n            iterator_creator (object): An iterator to load the data.\n        \"\"\"", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "L", "=", "hparams", ".", "L", "# history sequence that involved in convolution shape", "\n", "self", ".", "T", "=", "hparams", ".", "T", "# prediction shape", "\n", "self", ".", "n_v", "=", "hparams", ".", "n_v", "# number of vertical convolution layers", "\n", "self", ".", "n_h", "=", "hparams", ".", "n_h", "# number of horizonal convolution layers", "\n", "self", ".", "lengths", "=", "[", "\n", "i", "+", "1", "for", "i", "in", "range", "(", "self", ".", "L", ")", "\n", "]", "# horizonal convolution filter shape", "\n", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "iterator_creator", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._build_seq_graph": [[39, 50], ["tensorflow.compat.v1.variable_scope", "caser.CaserModel._caser_cnn", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._caser_cnn"], ["", "def", "_build_seq_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to create caser model.\n\n        Returns:\n            object: The output of caser section.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"caser\"", ")", ":", "\n", "            ", "cnn_output", "=", "self", ".", "_caser_cnn", "(", ")", "\n", "model_output", "=", "tf", ".", "concat", "(", "[", "cnn_output", ",", "self", ".", "target_item_embedding", "]", ",", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"model_output\"", ",", "model_output", ")", "\n", "return", "model_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._add_cnn": [[51, 77], ["tensorflow.concat", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.transpose", "caser.CaserModel._build_cnn", "tensorflow.compat.v1.layers.flatten", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "caser.CaserModel._build_cnn", "tensorflow.reduce_max", "out_hs.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._build_cnn", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._build_cnn"], ["", "", "def", "_add_cnn", "(", "self", ",", "hist_matrix", ",", "vertical_dim", ",", "scope", ")", ":", "\n", "        ", "\"\"\"The main function to use CNN at both vertical and horizonal aspects.\n\n        Args:\n            hist_matrix (object): The output of history sequential embeddings\n            vertical_dim (int): The shape of embeddings of input\n            scope (object): The scope of CNN input.\n\n        Returns:\n            object: The output of CNN layers.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"vertical\"", ")", ":", "\n", "                ", "embedding_T", "=", "tf", ".", "transpose", "(", "a", "=", "hist_matrix", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "out_v", "=", "self", ".", "_build_cnn", "(", "embedding_T", ",", "self", ".", "n_v", ",", "vertical_dim", ")", "\n", "out_v", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "flatten", "(", "out_v", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"horizonal\"", ")", ":", "\n", "                ", "out_hs", "=", "[", "]", "\n", "for", "h", "in", "self", ".", "lengths", ":", "\n", "                    ", "conv_out", "=", "self", ".", "_build_cnn", "(", "hist_matrix", ",", "self", ".", "n_h", ",", "h", ")", "\n", "max_pool_out", "=", "tf", ".", "reduce_max", "(", "\n", "input_tensor", "=", "conv_out", ",", "axis", "=", "[", "1", "]", ",", "name", "=", "\"max_pool_{0}\"", ".", "format", "(", "h", ")", "\n", ")", "\n", "out_hs", ".", "append", "(", "max_pool_out", ")", "\n", "", "out_h", "=", "tf", ".", "concat", "(", "out_hs", ",", "1", ")", "\n", "", "", "return", "tf", ".", "concat", "(", "[", "out_v", ",", "out_h", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._caser_cnn": [[78, 95], ["caser.CaserModel._add_cnn", "tensorflow.compat.v1.summary.histogram", "caser.CaserModel._add_cnn", "tensorflow.compat.v1.summary.histogram", "tensorflow.concat", "tensorflow.compat.v1.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._add_cnn", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._add_cnn"], ["", "def", "_caser_cnn", "(", "self", ")", ":", "\n", "        ", "\"\"\"The main function to use CNN at both item and category aspects.\n\n        Returns:\n            object: The concatenated output of two parts of item and category.\n        \"\"\"", "\n", "item_out", "=", "self", ".", "_add_cnn", "(", "\n", "self", ".", "item_history_embedding", ",", "self", ".", "item_embedding_dim", ",", "\"item\"", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"item_out\"", ",", "item_out", ")", "\n", "cate_out", "=", "self", ".", "_add_cnn", "(", "\n", "self", ".", "cate_history_embedding", ",", "self", ".", "cate_embedding_dim", ",", "\"cate\"", "\n", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"cate_out\"", ",", "cate_out", ")", "\n", "cnn_output", "=", "tf", ".", "concat", "(", "[", "item_out", ",", "cate_out", "]", ",", "1", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "histogram", "(", "\"cnn_output\"", ",", "cnn_output", ")", "\n", "return", "cnn_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.caser.CaserModel._build_cnn": [[96, 108], ["tensorflow.compat.v1.layers.conv1d", "str"], "methods", ["None"], ["", "def", "_build_cnn", "(", "self", ",", "history_matrix", ",", "nums", ",", "shape", ")", ":", "\n", "        ", "\"\"\"Call a CNN layer.\n\n        Returns:\n            object: The output of cnn section.\n        \"\"\"", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv1d", "(", "\n", "history_matrix", ",", "\n", "nums", ",", "\n", "shape", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"conv_\"", "+", "str", "(", "shape", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.__init__": [[24, 60], ["ImplicitCF.ImplicitCF._data_processing", "ImplicitCF.ImplicitCF._init_train_data", "random.seed"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._data_processing", "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF._init_train_data"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train", ",", "\n", "test", "=", "None", ",", "\n", "adj_dir", "=", "None", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "seed", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            adj_dir (str): Directory to save / load adjacency matrices. If it is None, adjacency\n                matrices will be created and will not be saved.\n            train (pandas.DataFrame): Training data with at least columns (col_user, col_item, col_rating).\n            test (pandas.DataFrame): Test data with at least columns (col_user, col_item, col_rating).\n                test can be None, if so, we only process the training data.\n            col_user (str): User column name.\n            col_item (str): Item column name.\n            col_rating (str): Rating column name.\n            seed (int): Seed.\n\n        \"\"\"", "\n", "self", ".", "user_idx", "=", "None", "\n", "self", ".", "item_idx", "=", "None", "\n", "self", ".", "adj_dir", "=", "adj_dir", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_prediction", "=", "col_prediction", "\n", "self", ".", "train", ",", "self", ".", "test", "=", "self", ".", "_data_processing", "(", "train", ",", "test", ")", "\n", "self", ".", "_init_train_data", "(", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF._data_processing": [[61, 102], ["train.append", "df[].drop_duplicates().reindex", "numpy.arange", "len", "dict", "dict", "df[].drop_duplicates", "numpy.arange", "len", "dict", "dict", "ImplicitCF.ImplicitCF._reindex", "ImplicitCF.ImplicitCF._reindex", "len", "zip", "zip", "len", "zip", "zip", "df[].drop_duplicates"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._reindex", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._reindex"], ["", "def", "_data_processing", "(", "self", ",", "train", ",", "test", ")", ":", "\n", "        ", "\"\"\"Process the dataset to reindex userID and itemID and only keep records with ratings greater than 0.\n\n        Args:\n            train (pandas.DataFrame): Training data with at least columns (col_user, col_item, col_rating).\n            test (pandas.DataFrame): Test data with at least columns (col_user, col_item, col_rating).\n                test can be None, if so, we only process the training data.\n\n        Returns:\n            list: train and test pandas.DataFrame Dataset, which have been reindexed and filtered.\n\n        \"\"\"", "\n", "df", "=", "train", "if", "test", "is", "None", "else", "train", ".", "append", "(", "test", ")", "\n", "\n", "if", "self", ".", "user_idx", "is", "None", ":", "\n", "            ", "user_idx", "=", "df", "[", "[", "self", ".", "col_user", "]", "]", ".", "drop_duplicates", "(", ")", ".", "reindex", "(", ")", "\n", "user_idx", "[", "self", ".", "col_user", "+", "\"_idx\"", "]", "=", "np", ".", "arange", "(", "len", "(", "user_idx", ")", ")", "\n", "self", ".", "n_users", "=", "len", "(", "user_idx", ")", "\n", "self", ".", "user_idx", "=", "user_idx", "\n", "\n", "self", ".", "user2id", "=", "dict", "(", "\n", "zip", "(", "user_idx", "[", "self", ".", "col_user", "]", ",", "user_idx", "[", "self", ".", "col_user", "+", "\"_idx\"", "]", ")", "\n", ")", "\n", "self", ".", "id2user", "=", "dict", "(", "\n", "zip", "(", "user_idx", "[", "self", ".", "col_user", "+", "\"_idx\"", "]", ",", "user_idx", "[", "self", ".", "col_user", "]", ")", "\n", ")", "\n", "\n", "", "if", "self", ".", "item_idx", "is", "None", ":", "\n", "            ", "item_idx", "=", "df", "[", "[", "self", ".", "col_item", "]", "]", ".", "drop_duplicates", "(", ")", "\n", "item_idx", "[", "self", ".", "col_item", "+", "\"_idx\"", "]", "=", "np", ".", "arange", "(", "len", "(", "item_idx", ")", ")", "\n", "self", ".", "n_items", "=", "len", "(", "item_idx", ")", "\n", "self", ".", "item_idx", "=", "item_idx", "\n", "\n", "self", ".", "item2id", "=", "dict", "(", "\n", "zip", "(", "item_idx", "[", "self", ".", "col_item", "]", ",", "item_idx", "[", "self", ".", "col_item", "+", "\"_idx\"", "]", ")", "\n", ")", "\n", "self", ".", "id2item", "=", "dict", "(", "\n", "zip", "(", "item_idx", "[", "self", ".", "col_item", "+", "\"_idx\"", "]", ",", "item_idx", "[", "self", ".", "col_item", "]", ")", "\n", ")", "\n", "\n", "", "return", "self", ".", "_reindex", "(", "train", ")", ",", "self", ".", "_reindex", "(", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF._reindex": [[103, 128], ["pandas.merge", "pandas.merge"], "methods", ["None"], ["", "def", "_reindex", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Process the dataset to reindex userID and itemID and only keep records with ratings greater than 0.\n\n        Args:\n            df (pandas.DataFrame): dataframe with at least columns (col_user, col_item, col_rating).\n\n        Returns:\n            list: train and test pandas.DataFrame Dataset, which have been reindexed and filtered.\n\n        \"\"\"", "\n", "\n", "if", "df", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "df", "=", "pd", ".", "merge", "(", "df", ",", "self", ".", "user_idx", ",", "on", "=", "self", ".", "col_user", ",", "how", "=", "\"left\"", ")", "\n", "df", "=", "pd", ".", "merge", "(", "df", ",", "self", ".", "item_idx", ",", "on", "=", "self", ".", "col_item", ",", "how", "=", "\"left\"", ")", "\n", "\n", "df", "=", "df", "[", "df", "[", "self", ".", "col_rating", "]", ">", "0", "]", "\n", "\n", "df_reindex", "=", "df", "[", "\n", "[", "self", ".", "col_user", "+", "\"_idx\"", ",", "self", ".", "col_item", "+", "\"_idx\"", ",", "self", ".", "col_rating", "]", "\n", "]", "\n", "df_reindex", ".", "columns", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", "]", "\n", "\n", "return", "df_reindex", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF._init_train_data": [[129, 142], ["[].apply().reset_index().rename", "scipy.dok_matrix", "[].apply().reset_index", "[].apply", "ImplicitCF.ImplicitCF.train.groupby"], "methods", ["None"], ["", "def", "_init_train_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Record items interated with each user in a dataframe self.interact_status, and create adjacency\n        matrix self.R.\n\n        \"\"\"", "\n", "self", ".", "interact_status", "=", "(", "\n", "self", ".", "train", ".", "groupby", "(", "self", ".", "col_user", ")", "[", "self", ".", "col_item", "]", "\n", ".", "apply", "(", "set", ")", "\n", ".", "reset_index", "(", ")", "\n", ".", "rename", "(", "columns", "=", "{", "self", ".", "col_item", ":", "self", ".", "col_item", "+", "\"_interacted\"", "}", ")", "\n", ")", "\n", "self", ".", "R", "=", "sp", ".", "dok_matrix", "(", "(", "self", ".", "n_users", ",", "self", ".", "n_items", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "R", "[", "self", ".", "train", "[", "self", ".", "col_user", "]", ",", "self", ".", "train", "[", "self", ".", "col_item", "]", "]", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.get_norm_adj_mat": [[143, 161], ["scipy.load_npz", "print", "ImplicitCF.ImplicitCF.create_norm_adj_mat", "scipy.save_npz"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.create_norm_adj_mat"], ["", "def", "get_norm_adj_mat", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load normalized adjacency matrix if it exists, otherwise create (and save) it.\n\n        Returns:\n            scipy.sparse.csr_matrix: Normalized adjacency matrix.\n\n        \"\"\"", "\n", "try", ":", "\n", "            ", "if", "self", ".", "adj_dir", "is", "None", ":", "\n", "                ", "raise", "FileNotFoundError", "\n", "", "norm_adj_mat", "=", "sp", ".", "load_npz", "(", "self", ".", "adj_dir", "+", "\"/norm_adj_mat.npz\"", ")", "\n", "print", "(", "\"Already load norm adj matrix.\"", ")", "\n", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "norm_adj_mat", "=", "self", ".", "create_norm_adj_mat", "(", ")", "\n", "if", "self", ".", "adj_dir", "is", "not", "None", ":", "\n", "                ", "sp", ".", "save_npz", "(", "self", ".", "adj_dir", "+", "\"/norm_adj_mat.npz\"", ",", "norm_adj_mat", ")", "\n", "", "", "return", "norm_adj_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.create_norm_adj_mat": [[162, 189], ["scipy.dok_matrix", "adj_mat.todok.todok.tolil", "ImplicitCF.ImplicitCF.R.tolil", "adj_mat.todok.todok.todok", "print", "numpy.array", "numpy.power().flatten", "scipy.diags", "scipy.diags.dot", "norm_adj_mat.dot.dot.dot", "print", "norm_adj_mat.dot.dot.tocsr", "adj_mat.todok.todok.sum", "numpy.power", "numpy.isinf"], "methods", ["None"], ["", "def", "create_norm_adj_mat", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create normalized adjacency matrix.\n\n        Returns:\n            scipy.sparse.csr_matrix: Normalized adjacency matrix.\n\n        \"\"\"", "\n", "adj_mat", "=", "sp", ".", "dok_matrix", "(", "\n", "(", "self", ".", "n_users", "+", "self", ".", "n_items", ",", "self", ".", "n_users", "+", "self", ".", "n_items", ")", ",", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "adj_mat", "=", "adj_mat", ".", "tolil", "(", ")", "\n", "R", "=", "self", ".", "R", ".", "tolil", "(", ")", "\n", "\n", "adj_mat", "[", ":", "self", ".", "n_users", ",", "self", ".", "n_users", ":", "]", "=", "R", "\n", "adj_mat", "[", "self", ".", "n_users", ":", ",", ":", "self", ".", "n_users", "]", "=", "R", ".", "T", "\n", "adj_mat", "=", "adj_mat", ".", "todok", "(", ")", "\n", "print", "(", "\"Already create adjacency matrix.\"", ")", "\n", "\n", "rowsum", "=", "np", ".", "array", "(", "adj_mat", ".", "sum", "(", "1", ")", ")", "\n", "d_inv", "=", "np", ".", "power", "(", "rowsum", "+", "1e-9", ",", "-", "0.5", ")", ".", "flatten", "(", ")", "\n", "d_inv", "[", "np", ".", "isinf", "(", "d_inv", ")", "]", "=", "0.0", "\n", "d_mat_inv", "=", "sp", ".", "diags", "(", "d_inv", ")", "\n", "norm_adj_mat", "=", "d_mat_inv", ".", "dot", "(", "adj_mat", ")", "\n", "norm_adj_mat", "=", "norm_adj_mat", ".", "dot", "(", "d_mat_inv", ")", "\n", "print", "(", "\"Already normalize adjacency matrix.\"", ")", "\n", "\n", "return", "norm_adj_mat", ".", "tocsr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.DataModel.ImplicitCF.ImplicitCF.train_loader": [[190, 224], ["range", "interact[].apply", "interact[].apply", "random.sample", "numpy.array", "numpy.array", "numpy.array", "random.randint", "random.choice", "random.choice", "ImplicitCF.ImplicitCF.train_loader.sample_neg"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.NegativeSampler.sample"], ["", "def", "train_loader", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Sample train data every batch. One positive item and one negative item sampled for each user.\n\n        Args:\n            batch_size (int): Batch size of users.\n\n        Returns:\n            numpy.ndarray, numpy.ndarray, numpy.ndarray:\n            - Sampled users.\n            - Sampled positive items.\n            - Sampled negative items.\n        \"\"\"", "\n", "\n", "def", "sample_neg", "(", "x", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "neg_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "n_items", "-", "1", ")", "\n", "if", "neg_id", "not", "in", "x", ":", "\n", "                    ", "return", "neg_id", "\n", "\n", "", "", "", "indices", "=", "range", "(", "self", ".", "n_users", ")", "\n", "if", "self", ".", "n_users", "<", "batch_size", ":", "\n", "            ", "users", "=", "[", "random", ".", "choice", "(", "indices", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "            ", "users", "=", "random", ".", "sample", "(", "indices", ",", "batch_size", ")", "\n", "\n", "", "interact", "=", "self", ".", "interact_status", ".", "iloc", "[", "users", "]", "\n", "pos_items", "=", "interact", "[", "self", ".", "col_item", "+", "\"_interacted\"", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "random", ".", "choice", "(", "list", "(", "x", ")", ")", "\n", ")", "\n", "neg_items", "=", "interact", "[", "self", ".", "col_item", "+", "\"_interacted\"", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "sample_neg", "(", "x", ")", "\n", ")", "\n", "\n", "return", "np", ".", "array", "(", "users", ")", ",", "np", ".", "array", "(", "pos_items", ")", ",", "np", ".", "array", "(", "neg_items", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.__init__": [[17, 133], ["numpy.random.seed", "tensorflow.compat.v1.set_random_seed", "tensorflow.compat.v1.reset_default_graph", "tensorflow.lookup.StaticHashTable", "rbm.RBM.generate_graph", "rbm.RBM.init_metrics", "rbm.RBM.init_gpu", "tensorflow.compat.v1.global_variables_initializer", "tensorflow.compat.v1.Session", "rbm.RBM.sess.run", "tensorflow.lookup.KeyValueTensorInitializer", "tensorflow.constant", "tensorflow.constant", "list", "list", "range", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.generate_graph", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_metrics", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_gpu"], ["def", "__init__", "(", "\n", "self", ",", "\n", "possible_ratings", ",", "\n", "visible_units", ",", "\n", "hidden_units", "=", "500", ",", "\n", "keep_prob", "=", "0.7", ",", "\n", "init_stdv", "=", "0.1", ",", "\n", "learning_rate", "=", "0.004", ",", "\n", "minibatch_size", "=", "100", ",", "\n", "training_epoch", "=", "20", ",", "\n", "display_epoch", "=", "10", ",", "\n", "sampling_protocol", "=", "[", "50", ",", "70", ",", "80", ",", "90", ",", "100", "]", ",", "\n", "debug", "=", "False", ",", "\n", "with_metrics", "=", "False", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implementation of a multinomial Restricted Boltzmann Machine for collaborative filtering\n        in numpy/pandas/tensorflow\n\n        Based on the article by Ruslan Salakhutdinov, Andriy Mnih and Geoffrey Hinton\n        https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf\n\n        In this implementation we use multinomial units instead of the one-hot-encoded used in\n        the paper. This means that the weights are rank 2 (matrices) instead of rank 3 tensors.\n\n        Basic mechanics:\n\n        1) A computational graph is created when the RBM class is instantiated.\n        For an item based recommender this consists of:\n        visible units: The number n_visible of visible units equals the number of items\n        hidden units : hyperparameter to fix during training\n\n        2) Gibbs Sampling:\n\n        2.1) for each training epoch, the visible units are first clamped on the data\n\n        2.2) The activation probability of the hidden units, given a linear combination of\n        the visibles, is evaluated P(h=1|phi_v). The latter is then used to sample the\n        value of the hidden units.\n\n        2.3) The probability P(v=l|phi_h) is evaluated, where l=1,..,r are the ratings (e.g.\n        r=5 for the movielens dataset). In general, this is a multinomial distribution,\n        from which we sample the value of v.\n\n        2.4) This step is repeated k times, where k increases as optimization converges. It is\n        essential to fix to zero the original unrated items during the all learning process.\n\n        3) Optimization:\n        The free energy of the visible units given the hidden is evaluated at the beginning (F_0)\n        and after k steps of Bernoulli sampling (F_k). The weights and biases are updated by\n        minimizing the differene F_0 - F_k.\n\n        4) Inference:\n        Once the joint probability distribution P(v,h) is learned, this is used to generate ratings\n        for unrated items for all users\n        \"\"\"", "\n", "\n", "# RBM parameters", "\n", "self", ".", "n_hidden", "=", "hidden_units", "# number of hidden units", "\n", "self", ".", "keep", "=", "keep_prob", "# keep probability for dropout regularization", "\n", "\n", "# standard deviation used to initialize the weights matrices", "\n", "self", ".", "stdv", "=", "init_stdv", "\n", "\n", "# learning rate used in the update method of the optimizer", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "\n", "# size of the minibatch used in the random minibatches training; setting to 1 corresponds to", "\n", "# stochastic gradient descent, and it is considerably slower. Good performance is achieved", "\n", "# for a size of ~100.", "\n", "self", ".", "minibatch", "=", "minibatch_size", "\n", "self", ".", "epochs", "=", "training_epoch", "+", "1", "# number of epochs used to train the model", "\n", "\n", "# number of epochs to show the mse error during training", "\n", "self", ".", "display_epoch", "=", "display_epoch", "\n", "\n", "# protocol to increase Gibbs sampling's step. Array containing the", "\n", "# percentage of the total training epoch when the step increases by 1", "\n", "self", ".", "sampling_protocol", "=", "sampling_protocol", "\n", "\n", "# if true, functions print their control paramters and/or outputs", "\n", "self", ".", "debug", "=", "debug", "\n", "\n", "# if true, compute msre and accuracy during training", "\n", "self", ".", "with_metrics", "=", "with_metrics", "\n", "\n", "# Seed", "\n", "self", ".", "seed", "=", "seed", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "self", ".", "seed", ")", "\n", "\n", "self", ".", "n_visible", "=", "visible_units", "# number of items", "\n", "\n", "tf", ".", "compat", ".", "v1", ".", "reset_default_graph", "(", ")", "\n", "\n", "# ----------------------Initializers-------------------------------------", "\n", "\n", "# create a sorted list of all the unique ratings (of float type)", "\n", "self", ".", "possible_ratings", "=", "possible_ratings", "\n", "\n", "# create a lookup table to map integer indices to float ratings", "\n", "self", ".", "ratings_lookup_table", "=", "tf", ".", "lookup", ".", "StaticHashTable", "(", "\n", "tf", ".", "lookup", ".", "KeyValueTensorInitializer", "(", "\n", "tf", ".", "constant", "(", "list", "(", "range", "(", "len", "(", "self", ".", "possible_ratings", ")", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "constant", "(", "list", "(", "self", ".", "possible_ratings", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", ")", ",", "default_value", "=", "0", "\n", ")", "\n", "\n", "self", ".", "generate_graph", "(", ")", "\n", "self", ".", "init_metrics", "(", ")", "\n", "self", ".", "init_gpu", "(", ")", "\n", "init_graph", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", "\n", "\n", "# Start TF training session on default graph", "\n", "self", ".", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "config", "=", "self", ".", "config_gpu", ")", "\n", "self", ".", "sess", ".", "run", "(", "init_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.binomial_sampling": [[134, 162], ["tensorflow.convert_to_tensor", "tensorflow.nn.relu", "tensorflow.sign", "numpy.random.uniform"], "methods", ["None"], ["", "def", "binomial_sampling", "(", "self", ",", "pr", ")", ":", "\n", "        ", "\"\"\"Binomial sampling of hidden units activations using a rejection method.\n\n        Basic mechanics:\n\n        1) Extract a random number from a uniform distribution (g) and compare it with\n        the unit's probability (pr)\n\n        2) Choose 0 if pr<g, 1 otherwise. It is convenient to implement this condtion using\n        the relu function.\n\n        Args:\n            pr (tf.Tensor, float32): Input conditional probability.\n            g  (numpy.ndarray, float32):  Uniform probability used for comparison.\n\n        Returns:\n            tf.Tensor: Float32 tensor of sampled units. The value is 1 if pr>g and 0 otherwise.\n        \"\"\"", "\n", "\n", "# sample from a Bernoulli distribution with same dimensions as input distribution", "\n", "g", "=", "tf", ".", "convert_to_tensor", "(", "\n", "value", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "pr", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# sample the value of the hidden units", "\n", "h_sampled", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "sign", "(", "pr", "-", "g", ")", ")", "\n", "\n", "return", "h_sampled", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_sampling": [[163, 204], ["numpy.random.uniform", "tensorflow.convert_to_tensor", "tensorflow.nn.relu", "tensorflow.cast", "tensorflow.cast", "tensorflow.sign", "tensorflow.argmax", "rbm.RBM.ratings_lookup_table.lookup", "numpy.random.uniform.sum"], "methods", ["None"], ["", "def", "multinomial_sampling", "(", "self", ",", "pr", ")", ":", "\n", "        ", "\"\"\"Multinomial Sampling of ratings\n\n        Basic mechanics:\n        For r classes, we sample r binomial distributions using the rejection method. This is possible\n        since each class is statistically independent from the other. Note that this is the same method\n        used in numpy's random.multinomial() function.\n\n        1) extract a size r array of random numbers from a uniform distribution (g). As pr is normalized,\n        we need to normalize g as well.\n\n        2) For each user and item, compare pr with the reference distribution. Note that the latter needs\n        to be the same for ALL the user/item pairs in the dataset, as by assumptions they are sampled\n        from a common distribution.\n\n        Args:\n            pr (tf.Tensor, float32): A distributions of shape (m, n, r), where m is the number of examples, n the number\n                 of features and r the number of classes. pr needs to be normalized, i.e. sum_k p(k) = 1 for all m, at fixed n.\n            f (tf.Tensor, float32): Normalized, uniform probability used for comparison.\n\n        Returns:\n            tf.Tensor: An (m,n) float32 tensor of sampled rankings from 1 to r.\n        \"\"\"", "\n", "g", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "pr", ".", "shape", "[", "2", "]", ")", "# sample from a uniform distribution", "\n", "f", "=", "tf", ".", "convert_to_tensor", "(", "\n", "value", "=", "g", "/", "g", ".", "sum", "(", ")", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "# normalize and convert to tensor", "\n", "\n", "samp", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "sign", "(", "pr", "-", "f", ")", ")", "# apply rejection method", "\n", "\n", "# get integer index of the rating to be sampled", "\n", "v_argmax", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "argmax", "(", "input", "=", "samp", ",", "axis", "=", "2", ")", ",", "\"int32\"", "\n", ")", "\n", "\n", "# lookup the rating using integer index", "\n", "v_samp", "=", "tf", ".", "cast", "(", "\n", "self", ".", "ratings_lookup_table", ".", "lookup", "(", "v_argmax", ")", ",", "\"float32\"", "\n", ")", "\n", "\n", "return", "v_samp", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_distribution": [[205, 228], ["tensorflow.reduce_sum", "tensorflow.compat.v1.div", "tensorflow.transpose", "tensorflow.exp", "tensorflow.multiply", "tensorflow.constant"], "methods", ["None"], ["", "def", "multinomial_distribution", "(", "self", ",", "phi", ")", ":", "\n", "        ", "\"\"\"Probability that unit v has value l given phi: P(v=l|phi)\n\n        Args:\n            phi (tf.Tensor): linear combination of values of the previous layer\n            r (float): rating scale, corresponding to the number of classes\n\n        Returns:\n            tf.Tensor:\n            - A tensor of shape (r, m, Nv): This needs to be reshaped as (m, Nv, r) in the last step to allow for faster sampling when used in the multinomial function.\n\n        \"\"\"", "\n", "\n", "numerator", "=", "[", "\n", "tf", ".", "exp", "(", "tf", ".", "multiply", "(", "tf", ".", "constant", "(", "k", ",", "dtype", "=", "\"float32\"", ")", ",", "phi", ")", ")", "\n", "for", "k", "in", "self", ".", "possible_ratings", "\n", "]", "\n", "\n", "denominator", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "numerator", ",", "axis", "=", "0", ")", "\n", "\n", "prob", "=", "tf", ".", "compat", ".", "v1", ".", "div", "(", "numerator", ",", "denominator", ")", "\n", "\n", "return", "tf", ".", "transpose", "(", "a", "=", "prob", ",", "perm", "=", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.free_energy": [[229, 248], ["tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.nn.softplus", "tensorflow.transpose"], "methods", ["None"], ["", "def", "free_energy", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Free energy of the visible units given the hidden units. Since the sum is over the hidden units'\n        states, the functional form of the visible units Free energy is the same as the one for the binary model.\n\n        Args:\n            x (tf.Tensor): This can be either the sampled value of the visible units (v_k) or the input data\n\n        Returns:\n            tf.Tensor: Free energy of the model.\n        \"\"\"", "\n", "\n", "bias", "=", "-", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "matmul", "(", "x", ",", "tf", ".", "transpose", "(", "a", "=", "self", ".", "bv", ")", ")", ")", "\n", "\n", "phi_x", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "w", ")", "+", "self", ".", "bh", "\n", "f", "=", "-", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "nn", ".", "softplus", "(", "phi_x", ")", ")", "\n", "\n", "F", "=", "bias", "+", "f", "# free energy density per training example", "\n", "\n", "return", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder": [[249, 252], ["tensorflow.compat.v1.placeholder"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["", "def", "placeholder", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize the placeholders for the visible units\"\"\"", "\n", "self", ".", "vu", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "shape", "=", "[", "None", ",", "self", ".", "n_visible", "]", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_parameters": [[253, 292], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.random_normal_initializer", "tensorflow.compat.v1.zeros_initializer", "tensorflow.compat.v1.zeros_initializer"], "methods", ["None"], ["", "def", "init_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize the parameters of the model.\n\n        This is a single layer model with two biases. So we have a rectangular matrix w_{ij} and\n        two bias vectors to initialize.\n\n        Args:\n            n_visible (int): number of visible units (input layer)\n            n_hidden (int): number of hidden units (latent variables of the model)\n\n        Returns:\n            tf.Tensor, tf.Tensor, tf.Tensor:\n            - `w` of size (n_visible, n_hidden): correlation matrix initialized by sampling from a normal distribution with zero mean and given variance init_stdv.\n            - `bv` of size (1, n_visible): visible units' bias, initialized to zero.\n            - `bh` of size (1, n_hidden): hidden units' bias, initiliazed to zero.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"Network_parameters\"", ")", ":", "\n", "\n", "            ", "self", ".", "w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"weight\"", ",", "\n", "[", "self", ".", "n_visible", ",", "self", ".", "n_hidden", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "self", ".", "stdv", ",", "seed", "=", "self", ".", "seed", "\n", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "\n", "self", ".", "bv", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"v_bias\"", ",", "\n", "[", "1", ",", "self", ".", "n_visible", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "\n", "self", ".", "bh", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "\"h_bias\"", ",", "\n", "[", "1", ",", "self", ".", "n_hidden", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "zeros_initializer", "(", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_hidden_units": [[294, 325], ["tensorflow.compat.v1.name_scope", "tensorflow.nn.sigmoid", "tensorflow.nn.dropout", "rbm.RBM.binomial_sampling", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.binomial_sampling"], ["", "", "def", "sample_hidden_units", "(", "self", ",", "vv", ")", ":", "\n", "        ", "\"\"\"Sampling: In RBM we use Contrastive divergence to sample the parameter space. In order to do that we need\n        to initialize the two conditional probabilities:\n\n        P(h|phi_v) --> returns the probability that the i-th hidden unit is active\n\n        P(v|phi_h) --> returns the probability that the  i-th visible unit is active\n\n        Sample hidden units given the visibles. This can be thought of as a Forward pass step in a FFN\n\n        Args:\n            vv (tf.Tensor, float32): visible units\n\n        Returns:\n            tf.Tensor, tf.Tensor:\n            - `phv`: The activation probability of the hidden unit.\n            - `h_`: The sampled value of the hidden unit from a Bernoulli distributions having success probability `phv`.\n        \"\"\"", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"sample_hidden_units\"", ")", ":", "\n", "\n", "            ", "phi_v", "=", "tf", ".", "matmul", "(", "vv", ",", "self", ".", "w", ")", "+", "self", ".", "bh", "# create a linear combination", "\n", "phv", "=", "tf", ".", "nn", ".", "sigmoid", "(", "phi_v", ")", "# conditional probability of h given v", "\n", "phv_reg", "=", "tf", ".", "nn", ".", "dropout", "(", "phv", ",", "1", "-", "(", "self", ".", "keep", ")", ")", "\n", "\n", "# Sampling", "\n", "h_", "=", "self", ".", "binomial_sampling", "(", "\n", "phv_reg", "\n", ")", "# obtain the value of the hidden units via Bernoulli sampling", "\n", "\n", "", "return", "phv", ",", "h_", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_visible_units": [[326, 370], ["tensorflow.compat.v1.name_scope", "rbm.RBM.multinomial_distribution", "rbm.RBM.multinomial_sampling", "tensorflow.equal", "tensorflow.compat.v1.where", "tensorflow.matmul", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_distribution", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_sampling"], ["", "def", "sample_visible_units", "(", "self", ",", "h", ")", ":", "\n", "        ", "\"\"\"Sample the visible units given the hiddens. This can be thought of as a Backward pass in a FFN\n        (negative phase). Each visible unit can take values in [1,rating], while the zero is reserved\n        for missing data; as such the value of the hidden unit is sampled from a multinomial distribution.\n\n        Basic mechanics:\n\n        1) For every training example we first sample Nv Multinomial distributions. The result is of the\n        form [0,1,0,0,0,...,0] where the index of the 1 element corresponds to the rth rating. The index\n        is extracted using the argmax function and we need to add 1 at the end since array indeces starts\n        from 0.\n\n        2) Selects only those units that have been sampled. During the training phase it is important to not\n        use the reconstructed inputs, so we beed to enforce a zero value in the reconstructed ratings in\n        the same position as the original input.\n\n        Args:\n            h (tf.Tensor, float32): visible units.\n\n        Returns:\n            tf.Tensor, tf.Tensor:\n            - `pvh`: The activation probability of the visible unit given the hidden.\n            - `v_`: The sampled value of the visible unit from a Multinomial distributions having success probability `pvh`.\n        \"\"\"", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"sample_visible_units\"", ")", ":", "\n", "\n", "            ", "phi_h", "=", "tf", ".", "matmul", "(", "h", ",", "tf", ".", "transpose", "(", "a", "=", "self", ".", "w", ")", ")", "+", "self", ".", "bv", "# linear combination", "\n", "pvh", "=", "self", ".", "multinomial_distribution", "(", "\n", "phi_h", "\n", ")", "# conditional probability of v given h", "\n", "\n", "# Sampling (modify here )", "\n", "v_tmp", "=", "self", ".", "multinomial_sampling", "(", "\n", "pvh", "\n", ")", "# sample the value of the visible units", "\n", "\n", "mask", "=", "tf", ".", "equal", "(", "self", ".", "v", ",", "0", ")", "# selects the inactive units in the input vector", "\n", "\n", "v_", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "\n", "mask", ",", "x", "=", "self", ".", "v", ",", "y", "=", "v_tmp", "\n", ")", "# enforce inactive units in the reconstructed vector", "\n", "\n", "", "return", "pvh", ",", "v_", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.gibbs_sampling": [[371, 398], ["tensorflow.compat.v1.name_scope", "range", "print", "rbm.RBM.sample_hidden_units", "rbm.RBM.sample_visible_units"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_hidden_units", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_visible_units"], ["", "def", "gibbs_sampling", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gibbs sampling: Determines an estimate of the model configuration via sampling. In the binary\n        RBM we need to impose that unseen movies stay as such, i.e. the sampling phase should not modify\n        the elements where v=0.\n\n        Args:\n            k (scalar, integer): iterator. Number of sampling steps.\n            v (tf.Tensor, float32): visible units.\n\n        Returns:\n            tf.Tensor, tf.Tensor:\n            - `h_k`: The sampled value of the hidden unit at step k, float32.\n            - `v_k`: The sampled value of the visible unit at step k, float32.\n        \"\"\"", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"gibbs_sampling\"", ")", ":", "\n", "\n", "            ", "self", ".", "v_k", "=", "(", "\n", "self", ".", "v", "\n", ")", "# initialize the value of the visible units at step k=0 on the data", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "print", "(", "\"CD step\"", ",", "self", ".", "k", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "k", ")", ":", "# k_sampling", "\n", "                ", "_", ",", "h_k", "=", "self", ".", "sample_hidden_units", "(", "self", ".", "v_k", ")", "\n", "_", ",", "self", ".", "v_k", "=", "self", ".", "sample_visible_units", "(", "h_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.losses": [[399, 414], ["tensorflow.compat.v1.variable_scope", "rbm.RBM.free_energy", "rbm.RBM.free_energy"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.free_energy", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.free_energy"], ["", "", "", "def", "losses", "(", "self", ",", "vv", ")", ":", "\n", "        ", "\"\"\"Calculate contrastive divergence, which is the difference between\n        the free energy clamped on the data (v) and the model Free energy (v_k).\n\n        Args:\n            vv (tf.Tensor, float32): empirical input\n\n        Returns:\n            obj: contrastive divergence\n        \"\"\"", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"losses\"", ")", ":", "\n", "            ", "obj", "=", "self", ".", "free_energy", "(", "vv", ")", "-", "self", ".", "free_energy", "(", "self", ".", "v_k", ")", "\n", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.gibbs_protocol": [[415, 445], ["tensorflow.compat.v1.name_scope", "log.info", "rbm.RBM.gibbs_sampling"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.gibbs_sampling"], ["", "def", "gibbs_protocol", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"Gibbs protocol.\n\n        Basic mechanics:\n\n        If the current epoch i is in the interval specified in the training protocol,\n        the number of steps in Gibbs sampling (k) is incremented by one and gibbs_sampling is updated\n        accordingly.\n\n        Args:\n            i (int): Current epoch in the loop\n        \"\"\"", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "\"gibbs_protocol\"", ")", ":", "\n", "\n", "            ", "epoch_percentage", "=", "(", "\n", "i", "/", "self", ".", "epochs", "\n", ")", "*", "100", "# current percentage of the total #epochs", "\n", "\n", "if", "epoch_percentage", "!=", "0", ":", "\n", "                ", "if", "(", "\n", "epoch_percentage", ">=", "self", ".", "sampling_protocol", "[", "self", ".", "l", "]", "\n", "and", "epoch_percentage", "<=", "self", ".", "sampling_protocol", "[", "self", ".", "l", "+", "1", "]", "\n", ")", ":", "\n", "                    ", "self", ".", "k", "+=", "1", "\n", "self", ".", "l", "+=", "1", "# noqa: E741 ambiguous variable name 'l'", "\n", "self", ".", "gibbs_sampling", "(", ")", "\n", "\n", "", "", "if", "self", ".", "debug", ":", "\n", "                ", "log", ".", "info", "(", "\"percentage of epochs covered so far %f2\"", "%", "(", "epoch_percentage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.data_pipeline": [[446, 464], ["tensorflow.compat.v1.placeholder", "tensorflow.data.Dataset.from_tensor_slices", "rbm.RBM.dataset.shuffle", "rbm.RBM.dataset.batch().repeat", "tensorflow.compat.v1.data.make_initializable_iterator", "rbm.RBM.iter.get_next", "rbm.RBM.dataset.batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder"], ["", "", "", "def", "data_pipeline", "(", "self", ")", ":", "\n", "        ", "\"\"\"Define the data pipeline\"\"\"", "\n", "\n", "# placeholder for the batch_size", "\n", "self", ".", "batch_size", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int64", ")", "\n", "\n", "# Create the data pipeline for faster training", "\n", "self", ".", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "self", ".", "vu", ")", "\n", "\n", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "shuffle", "(", "\n", "buffer_size", "=", "50", ",", "reshuffle_each_iteration", "=", "True", ",", "seed", "=", "self", ".", "seed", "\n", ")", "# randomize the batch", "\n", "\n", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "batch", "(", "batch_size", "=", "self", ".", "batch_size", ")", ".", "repeat", "(", ")", "\n", "\n", "# define iterator", "\n", "self", ".", "iter", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_initializable_iterator", "(", "self", ".", "dataset", ")", "\n", "self", ".", "v", "=", "self", ".", "iter", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_metrics": [[465, 471], ["tensorflow.sqrt", "tensorflow.compat.v1.losses.mean_squared_error", "tensorflow.where"], "methods", ["None"], ["", "def", "init_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize metrics\"\"\"", "\n", "\n", "if", "self", ".", "with_metrics", ":", "# if true (default) returns evaluation metrics", "\n", "            ", "self", ".", "rmse", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "mean_squared_error", "(", "self", ".", "v", ",", "self", ".", "v_k", ",", "weights", "=", "tf", ".", "where", "(", "self", ".", "v", ">", "0", ",", "1", ",", "0", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.generate_graph": [[473, 498], ["log.info", "rbm.RBM.placeholder", "rbm.RBM.data_pipeline", "rbm.RBM.init_parameters", "log.info", "rbm.RBM.gibbs_sampling", "rbm.RBM.losses", "tensorflow.compat.v1.train.AdamOptimizer().minimize", "tensorflow.compat.v1.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.placeholder", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.data_pipeline", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_parameters", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.gibbs_sampling", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.losses"], ["", "", "def", "generate_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Call the different RBM modules to generate the computational graph\"\"\"", "\n", "\n", "log", ".", "info", "(", "\"Creating the computational graph\"", ")", "\n", "\n", "self", ".", "placeholder", "(", ")", "# create the visible units placeholder", "\n", "self", ".", "data_pipeline", "(", ")", "# data_pipeline", "\n", "self", ".", "init_parameters", "(", ")", "# initialize Network parameters", "\n", "\n", "# --------------Initialize protocol for Gibbs sampling------------------", "\n", "log", ".", "info", "(", "\"Initialize Gibbs protocol\"", ")", "\n", "self", ".", "k", "=", "1", "# initialize the G_sampling step", "\n", "# initialize epoch_sample index", "\n", "self", ".", "l", "=", "0", "# noqa: E741 ambiguous variable name 'l'", "\n", "self", ".", "gibbs_sampling", "(", ")", "# returns the sampled value of the visible units", "\n", "\n", "# ---Instantiate loss function and optimizer----------------------------", "\n", "obj", "=", "self", ".", "losses", "(", "self", ".", "v", ")", "# objective function", "\n", "\n", "rate", "=", "(", "\n", "self", ".", "learning_rate", "/", "self", ".", "minibatch", "\n", ")", "# learning rate rescaled by the batch size", "\n", "\n", "self", ".", "opt", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "rate", ")", ".", "minimize", "(", "\n", "loss", "=", "obj", "\n", ")", "# Instantiate the optimizer", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_gpu": [[500, 507], ["tensorflow.compat.v1.ConfigProto"], "methods", ["None"], ["", "def", "init_gpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Config GPU memory\"\"\"", "\n", "\n", "self", ".", "config_gpu", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "\n", "log_device_placement", "=", "False", ",", "allow_soft_placement", "=", "True", "\n", ")", "\n", "self", ".", "config_gpu", ".", "gpu_options", ".", "allow_growth", "=", "True", "# dynamic memory allocation", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_training_session": [[508, 521], ["rbm.RBM.sess.run", "rbm.RBM.sess.run", "tensorflow.compat.v1.tables_initializer"], "methods", ["None"], ["", "def", "init_training_session", "(", "self", ",", "xtr", ")", ":", "\n", "        ", "\"\"\"Initialize the TF session on training data\n\n        Args:\n            xtr (numpy.ndarray, int32): The user/affinity matrix for the train set.\n        \"\"\"", "\n", "\n", "self", ".", "sess", ".", "run", "(", "\n", "self", ".", "iter", ".", "initializer", ",", "\n", "feed_dict", "=", "{", "self", ".", "vu", ":", "xtr", ",", "self", ".", "batch_size", ":", "self", ".", "minibatch", "}", ",", "\n", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "tables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.batch_training": [[522, 548], ["range", "rbm.RBM.sess.run", "rbm.RBM.sess.run"], "methods", ["None"], ["", "def", "batch_training", "(", "self", ",", "num_minibatches", ")", ":", "\n", "        ", "\"\"\"Perform training over input minibatches. If `self.with_metrics` is False,\n        no online metrics are evaluated.\n\n        Args:\n            num_minibatches (scalar, int32): Number of training minibatches.\n\n        Returns:\n            float: Training error per single epoch. If `self.with_metrics` is False, this is zero.\n        \"\"\"", "\n", "\n", "epoch_tr_err", "=", "0", "# initialize the training error for each epoch to zero", "\n", "\n", "# minibatch loop", "\n", "for", "_", "in", "range", "(", "num_minibatches", ")", ":", "\n", "\n", "            ", "if", "self", ".", "with_metrics", ":", "\n", "                ", "_", ",", "batch_err", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "opt", ",", "self", ".", "rmse", "]", ")", "\n", "\n", "# average msr error per minibatch", "\n", "epoch_tr_err", "+=", "batch_err", "/", "num_minibatches", "\n", "\n", "", "else", ":", "\n", "                ", "_", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "opt", ")", "\n", "\n", "", "", "return", "epoch_tr_err", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.fit": [[549, 591], ["numpy.not_equal", "int", "rbm.RBM.init_training_session", "range", "rbm.RBM.gibbs_protocol", "rbm.RBM.batch_training", "rmse_train.append", "log.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.init_training_session", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.gibbs_protocol", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.batch_training"], ["", "def", "fit", "(", "self", ",", "xtr", ")", ":", "\n", "        ", "\"\"\"Fit method\n\n        Training in generative models takes place in two steps:\n\n        1) Gibbs sampling\n        2) Gradient evaluation and parameters update\n\n        This estimate is later used in the weight update step by minimizing the distance between the\n        model and the empirical free energy. Note that while the unit's configuration space is sampled,\n        the weights are determined via maximum likelihood (saddle point).\n\n        Main component of the algo; once instantiated, it generates the computational graph and performs\n        model training\n\n        Args:\n            xtr (numpy.ndarray, integers): the user/affinity matrix for the train set\n            xtst (numpy.ndarray, integers): the user/affinity matrix for the test set\n        \"\"\"", "\n", "\n", "# keep the position of the items in the train set so that they can be optionally exluded from recommendation", "\n", "self", ".", "seen_mask", "=", "np", ".", "not_equal", "(", "xtr", ",", "0", ")", "\n", "\n", "n_users", "=", "xtr", ".", "shape", "[", "0", "]", "\n", "num_minibatches", "=", "int", "(", "n_users", "/", "self", ".", "minibatch", ")", "# number of minibatches", "\n", "\n", "self", ".", "init_training_session", "(", "xtr", ")", "\n", "\n", "rmse_train", "=", "[", "]", "# List to collect the metrics across epochs", "\n", "\n", "# start loop over training epochs", "\n", "for", "i", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "\n", "            ", "self", ".", "gibbs_protocol", "(", "i", ")", "# Gibbs sampling update", "\n", "epoch_tr_err", "=", "self", ".", "batch_training", "(", "num_minibatches", ")", "# model train", "\n", "\n", "if", "self", ".", "with_metrics", "and", "i", "%", "self", ".", "display_epoch", "==", "0", ":", "\n", "                ", "log", ".", "info", "(", "\"training epoch %i rmse %f\"", "%", "(", "i", ",", "epoch_tr_err", ")", ")", "\n", "\n", "", "rmse_train", ".", "append", "(", "epoch_tr_err", ")", "# mse training error per training epoch", "\n", "\n", "", "self", ".", "rmse_train", "=", "rmse_train", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.eval_out": [[592, 609], ["rbm.RBM.sample_hidden_units", "rbm.RBM.multinomial_distribution", "rbm.RBM.multinomial_sampling", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.sample_hidden_units", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_distribution", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.multinomial_sampling"], ["", "def", "eval_out", "(", "self", ")", ":", "\n", "        ", "\"\"\"Implement multinomial sampling from a trained model\"\"\"", "\n", "\n", "# Sampling", "\n", "_", ",", "h", "=", "self", ".", "sample_hidden_units", "(", "self", ".", "vu", ")", "# sample h", "\n", "\n", "# sample v", "\n", "phi_h", "=", "(", "\n", "tf", ".", "transpose", "(", "a", "=", "tf", ".", "matmul", "(", "self", ".", "w", ",", "tf", ".", "transpose", "(", "a", "=", "h", ")", ")", ")", "+", "self", ".", "bv", "\n", ")", "# linear combination", "\n", "pvh", "=", "self", ".", "multinomial_distribution", "(", "\n", "phi_h", "\n", ")", "# conditional probability of v given h", "\n", "\n", "v", "=", "self", ".", "multinomial_sampling", "(", "pvh", ")", "# sample the value of the visible units", "\n", "\n", "return", "v", ",", "pvh", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.recommend_k_items": [[610, 674], ["rbm.RBM.eval_out", "rbm.RBM.sess.run", "numpy.max", "numpy.multiply", "log.info", "numpy.multiply.copy", "numpy.argpartition", "range", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.eval_out"], ["", "def", "recommend_k_items", "(", "self", ",", "x", ",", "top_k", "=", "10", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the top-k items ordered by a relevancy score.\n\n        Basic mechanics:\n\n        The method samples new ratings from the learned joint distribution, together with their\n        probabilities. The input x must have the same number of columns as the one used for training\n        the model (i.e. the same number of items) but it can have an arbitrary number of rows (users).\n\n        A recommendation score is evaluated by taking the element-wise product between the ratings and\n        the associated probabilities. For example, we could have the following situation:\n\n        .. code-block:: python\n\n                    rating     probability     score\n            item1     5           0.5          2.5\n            item2     4           0.8          3.2\n\n        then item2 will be recommended.\n\n        Args:\n            x (numpy.ndarray, int32): input user/affinity matrix. Note that this can be a single vector, i.e. the ratings\n            of a single user.\n            top_k (scalar, int32): the number of items to recommend.\n\n        Returns:\n            numpy.ndarray, float:\n            - A sparse matrix containing the top_k elements ordered by their score.\n            - The time taken to recommend k items.\n        \"\"\"", "\n", "\n", "# evaluate the ratings and the associated probabilities", "\n", "v_", ",", "pvh_", "=", "self", ".", "eval_out", "(", ")", "\n", "\n", "# evaluate v_ and pvh_ on the input data", "\n", "vp", ",", "pvh", "=", "self", ".", "sess", ".", "run", "(", "[", "v_", ",", "pvh_", "]", ",", "feed_dict", "=", "{", "self", ".", "vu", ":", "x", "}", ")", "\n", "# returns only the probabilities for the predicted ratings in vp", "\n", "pv", "=", "np", ".", "max", "(", "pvh", ",", "axis", "=", "2", ")", "\n", "\n", "# evaluate the score", "\n", "score", "=", "np", ".", "multiply", "(", "vp", ",", "pv", ")", "\n", "# ----------------------Return the results as a P dataframe------------------------------------", "\n", "\n", "log", ".", "info", "(", "\"Extracting top %i elements\"", "%", "top_k", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "# if true, it removes items from the train set by setting them to zero", "\n", "            ", "vp", "[", "self", ".", "seen_mask", "]", "=", "0", "\n", "pv", "[", "self", ".", "seen_mask", "]", "=", "0", "\n", "score", "[", "self", ".", "seen_mask", "]", "=", "0", "\n", "\n", "", "top_items", "=", "np", ".", "argpartition", "(", "-", "score", ",", "range", "(", "top_k", ")", ",", "axis", "=", "1", ")", "[", "\n", ":", ",", ":", "top_k", "\n", "]", "# get the top k items", "\n", "\n", "score_c", "=", "score", ".", "copy", "(", ")", "# get a copy of the score matrix", "\n", "\n", "score_c", "[", "\n", "np", ".", "arange", "(", "score_c", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ",", "top_items", "\n", "]", "=", "0", "# set to zero the top_k elements", "\n", "\n", "top_scores", "=", "score", "-", "score_c", "# set to zeros all elements other then the top_k", "\n", "\n", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.predict": [[675, 700], ["rbm.RBM.eval_out", "rbm.RBM.sess.run"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.eval_out"], ["", "def", "predict", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Returns the inferred ratings. This method is similar to recommend_k_items() with the\n        exceptions that it returns all the inferred ratings\n\n        Basic mechanics:\n\n        The method samples new ratings from the learned joint distribution, together with\n        their probabilities. The input x must have the same number of columns as the one used\n        for training the model, i.e. the same number of items, but it can have an arbitrary number\n        of rows (users).\n\n        Args:\n            x (numpy.ndarray, int32): Input user/affinity matrix. Note that this can be a single vector, i.e.\n            the ratings of a single user.\n\n        Returns:\n            numpy.ndarray, float:\n            - A matrix with the inferred ratings.\n            - The elapsed time for predediction.\n        \"\"\"", "\n", "\n", "v_", ",", "_", "=", "self", ".", "eval_out", "(", ")", "# evaluate the ratings and the associated probabilities", "\n", "vp", "=", "self", ".", "sess", ".", "run", "(", "v_", ",", "feed_dict", "=", "{", "self", ".", "vu", ":", "x", "}", ")", "\n", "\n", "return", "vp", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save": [[701, 720], ["pathlib.Path", "os.makedirs", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.save", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "def", "save", "(", "self", ",", "file_path", "=", "'./rbm_model.ckpt'", ")", ":", "\n", "        ", "\"\"\"Save model parameters to `file_path`\n\n        This function saves the current tensorflow session to a specified path.\n\n        Args:\n            file_path (str): output file path for the RBM model checkpoint\n                we will create a new directory if not existing.\n        \"\"\"", "\n", "\n", "f_path", "=", "Path", "(", "file_path", ")", "\n", "dir_name", ",", "file_name", "=", "f_path", ".", "parent", ",", "f_path", ".", "name", "\n", "\n", "# create the directory if it does not exist", "\n", "os", ".", "makedirs", "(", "dir_name", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# save trained model", "\n", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "file_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load": [[721, 736], ["pathlib.Path", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "os.path.join"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "file_path", "=", "'./rbm_model.ckpt'", ")", ":", "\n", "        ", "\"\"\"Load model parameters for further use.\n\n        This function loads a saved tensorflow session.\n\n        Args:\n            file_path (str): file path for RBM model checkpoint\n        \"\"\"", "\n", "\n", "f_path", "=", "Path", "(", "file_path", ")", "\n", "dir_name", ",", "file_name", "=", "f_path", ".", "parent", ",", "f_path", ".", "name", "\n", "\n", "# load pre-trained model", "\n", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "file_name", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__init__": [[23, 44], ["tokenization_method.lower", "sklearn.feature_extraction.text.TfidfVectorizer", "dict", "dict", "frozenset", "dict", "pandas.DataFrame", "tokenization_method.lower", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "id_col", ",", "tokenization_method", "=", "\"scibert\"", ")", ":", "\n", "        ", "\"\"\"Initialize model parameters\n\n        Args:\n            id_col (str): Name of column containing item IDs.\n            tokenization_method (str): ['none','nltk','bert','scibert'] option for tokenization method.\n        \"\"\"", "\n", "self", ".", "id_col", "=", "id_col", "\n", "if", "tokenization_method", ".", "lower", "(", ")", "not", "in", "[", "\"none\"", ",", "\"nltk\"", ",", "\"bert\"", ",", "\"scibert\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Tokenization method must be one of [\"none\" | \"nltk\" | \"bert\" | \"scibert\"]'", "\n", ")", "\n", "", "self", ".", "tokenization_method", "=", "tokenization_method", ".", "lower", "(", ")", "\n", "\n", "# Initialize other variables used in this class", "\n", "self", ".", "tf", "=", "TfidfVectorizer", "(", ")", "\n", "self", ".", "tfidf_matrix", "=", "dict", "(", ")", "\n", "self", ".", "tokens", "=", "dict", "(", ")", "\n", "self", ".", "stop_words", "=", "frozenset", "(", ")", "\n", "self", ".", "recommendations", "=", "dict", "(", ")", "\n", "self", ".", "top_k_recommendations", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__clean_text": [[45, 88], ["unicodedata.normalize", "re.sub", "clean.lower.lower.replace", "clean.lower.lower.replace", "clean.lower.lower.replace", "clean.lower.lower.replace", "re.sub", "clean.lower.lower.lower", "print"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.geoimc.geoimc_data.Dataset.normalize"], ["", "def", "__clean_text", "(", "self", ",", "text", ",", "for_BERT", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"Clean text by removing HTML tags, symbols, and punctuation.\n\n        Args:\n            text (str): Text to clean.\n            for_BERT (boolean): True or False for if this text is being cleaned for a BERT word tokenization method.\n            verbose (boolean): True or False for whether to print.\n\n        Returns:\n            str: Cleaned version of text.\n        \"\"\"", "\n", "\n", "try", ":", "\n", "# Normalize unicode", "\n", "            ", "text_norm", "=", "unicodedata", ".", "normalize", "(", "\"NFC\"", ",", "text", ")", "\n", "\n", "# Remove HTML tags", "\n", "clean", "=", "re", ".", "sub", "(", "\"<.*?>\"", ",", "\"\"", ",", "text_norm", ")", "\n", "\n", "# Remove new line and tabs", "\n", "clean", "=", "clean", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "clean", "=", "clean", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "clean", "=", "clean", ".", "replace", "(", "\"\\r\"", ",", "\" \"", ")", "\n", "clean", "=", "clean", ".", "replace", "(", "\"\u00c2\\xa0\"", ",", "\"\"", ")", "# non-breaking space", "\n", "\n", "# Remove all punctuation and special characters", "\n", "clean", "=", "re", ".", "sub", "(", "\n", "r\"([^\\s\\w]|_)+\"", ",", "\"\"", ",", "clean", "\n", ")", "# noqa W695 invalid escape sequence '\\s'", "\n", "\n", "# If you want to keep some punctuation, see below commented out example", "\n", "# clean = re.sub(r'([^\\s\\w\\-\\_\\(\\)]|_)+','', clean)", "\n", "\n", "# Skip further processing if the text will be used in BERT tokenization", "\n", "if", "for_BERT", "is", "False", ":", "\n", "# Lower case", "\n", "                ", "clean", "=", "clean", ".", "lower", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "            ", "if", "verbose", "is", "True", ":", "\n", "                ", "print", "(", "\"Cannot clean non-existent text\"", ")", "\n", "", "clean", "=", "\"\"", "\n", "\n", "", "return", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.clean_dataframe": [[89, 116], ["df.replace.replace.replace", "df[].apply", "df[].map", "tfidf_utils.TfidfRecommender.__clean_text"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__clean_text"], ["", "def", "clean_dataframe", "(", "self", ",", "df", ",", "cols_to_clean", ",", "new_col_name", "=", "\"cleaned_text\"", ")", ":", "\n", "        ", "\"\"\"Clean the text within the columns of interest and return a dataframe with cleaned and combined text.\n\n        Args:\n            df (pandas.DataFrame): Dataframe containing the text content to clean.\n            cols_to_clean (list of str): List of columns to clean by name (e.g., ['abstract','full_text']).\n            new_col_name (str): Name of the new column that will contain the cleaned text.\n\n        Returns:\n            pandas.DataFrame: Dataframe with cleaned text in the new column.\n        \"\"\"", "\n", "# Collapse the table such that all descriptive text is just in a single column", "\n", "df", "=", "df", ".", "replace", "(", "np", ".", "nan", ",", "\"\"", ",", "regex", "=", "True", ")", "\n", "df", "[", "new_col_name", "]", "=", "df", "[", "cols_to_clean", "]", ".", "apply", "(", "lambda", "cols", ":", "\" \"", ".", "join", "(", "cols", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# Check if for BERT tokenization", "\n", "if", "self", ".", "tokenization_method", "in", "[", "\"bert\"", ",", "\"scibert\"", "]", ":", "\n", "            ", "for_BERT", "=", "True", "\n", "", "else", ":", "\n", "            ", "for_BERT", "=", "False", "\n", "\n", "# Clean the text in the dataframe", "\n", "", "df", "[", "new_col_name", "]", "=", "df", "[", "new_col_name", "]", ".", "map", "(", "\n", "lambda", "x", ":", "self", ".", "__clean_text", "(", "x", ",", "for_BERT", ")", "\n", ")", "\n", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.tokenize_text": [[117, 200], ["sklearn.feature_extraction.text.TfidfVectorizer", "transformers.BertTokenizer.from_pretrained", "vectors.copy", "range", "len", "nltk.stem.porter.PorterStemmer", "sklearn.feature_extraction.text.TfidfVectorizer", "transformers.BertTokenizer.from_pretrained.tokenize", "nltk.word_tokenize", "tfidf_utils.TfidfRecommender.tokenize_text.stem_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.newsrec.newsrec_utils.word_tokenize"], ["", "def", "tokenize_text", "(", "\n", "self", ",", "df_clean", ",", "text_col", "=", "\"cleaned_text\"", ",", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "min_df", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"Tokenize the input text.\n        For more details on the TfidfVectorizer, see https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n\n        Args:\n            df_clean (pandas.DataFrame): Dataframe with cleaned text in the new column.\n            text_col (str): Name of column containing the cleaned text.\n            ngram_range (tuple of int): The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n            min_df (int): When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n\n        Returns:\n            TfidfVectorizer, pandas.Series:\n            - Scikit-learn TfidfVectorizer object defined in `.tokenize_text()`.\n            - Each row contains tokens for respective documents separated by spaces.\n        \"\"\"", "\n", "vectors", "=", "df_clean", "[", "text_col", "]", "\n", "\n", "# If a HuggingFace BERT word tokenization method", "\n", "if", "self", ".", "tokenization_method", "in", "[", "\"bert\"", ",", "\"scibert\"", "]", ":", "\n", "# Set vectorizer", "\n", "            ", "tf", "=", "TfidfVectorizer", "(", "\n", "analyzer", "=", "\"word\"", ",", "\n", "ngram_range", "=", "ngram_range", ",", "\n", "min_df", "=", "min_df", ",", "\n", "stop_words", "=", "\"english\"", ",", "\n", ")", "\n", "\n", "# Get appropriate transformer name", "\n", "if", "self", ".", "tokenization_method", "==", "\"bert\"", ":", "\n", "                ", "bert_method", "=", "\"bert-base-cased\"", "\n", "", "elif", "self", ".", "tokenization_method", "==", "\"scibert\"", ":", "\n", "                ", "bert_method", "=", "\"allenai/scibert_scivocab_cased\"", "\n", "\n", "# Load pre-trained model tokenizer (vocabulary)", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_method", ")", "\n", "\n", "# Loop through each item", "\n", "vectors_tokenized", "=", "vectors", ".", "copy", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "vectors", ")", ")", ":", "\n", "                ", "vectors_tokenized", "[", "i", "]", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "vectors", "[", "i", "]", ")", ")", "\n", "\n", "", "", "elif", "self", ".", "tokenization_method", "==", "\"nltk\"", ":", "\n", "# NLTK Stemming", "\n", "            ", "token_dict", "=", "{", "}", "# noqa: F841", "\n", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "\n", "def", "stem_tokens", "(", "tokens", ",", "stemmer", ")", ":", "\n", "                ", "stemmed", "=", "[", "]", "\n", "for", "item", "in", "tokens", ":", "\n", "                    ", "stemmed", ".", "append", "(", "stemmer", ".", "stem", "(", "item", ")", ")", "\n", "", "return", "stemmed", "\n", "\n", "", "def", "tokenize", "(", "text", ")", ":", "\n", "                ", "tokens", "=", "nltk", ".", "word_tokenize", "(", "text", ")", "\n", "stems", "=", "stem_tokens", "(", "tokens", ",", "stemmer", ")", "\n", "return", "stems", "\n", "\n", "# When defining a custome tokenizer with TfidfVectorizer, the tokenization is applied in the fit function", "\n", "", "tf", "=", "TfidfVectorizer", "(", "\n", "tokenizer", "=", "tokenize", ",", "\n", "analyzer", "=", "\"word\"", ",", "\n", "ngram_range", "=", "ngram_range", ",", "\n", "min_df", "=", "min_df", ",", "\n", "stop_words", "=", "\"english\"", ",", "\n", ")", "\n", "vectors_tokenized", "=", "vectors", "\n", "\n", "", "elif", "self", ".", "tokenization_method", "==", "\"none\"", ":", "\n", "# No tokenization applied", "\n", "            ", "tf", "=", "TfidfVectorizer", "(", "\n", "analyzer", "=", "\"word\"", ",", "\n", "ngram_range", "=", "ngram_range", ",", "\n", "min_df", "=", "min_df", ",", "\n", "stop_words", "=", "\"english\"", ",", "\n", ")", "\n", "vectors_tokenized", "=", "vectors", "\n", "\n", "# Save to class variable", "\n", "", "self", ".", "tf", "=", "tf", "\n", "\n", "return", "tf", ",", "vectors_tokenized", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.fit": [[201, 209], ["tf.fit_transform"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.fit_transform"], ["", "def", "fit", "(", "self", ",", "tf", ",", "vectors_tokenized", ")", ":", "\n", "        ", "\"\"\"Fit TF-IDF vectorizer to the cleaned and tokenized text.\n\n        Args:\n            tf (TfidfVectorizer): sklearn.feature_extraction.text.TfidfVectorizer object defined in .tokenize_text().\n            vectors_tokenized (pandas.Series): Each row contains tokens for respective documents separated by spaces.\n        \"\"\"", "\n", "self", ".", "tfidf_matrix", "=", "tf", ".", "fit_transform", "(", "vectors_tokenized", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_tokens": [[210, 221], ["None"], "methods", ["None"], ["", "def", "get_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the tokens generated by the TF-IDF vectorizer.\n\n        Returns:\n            dict: Dictionary of tokens generated by the TF-IDF vectorizer.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "tokens", "=", "self", ".", "tf", ".", "vocabulary_", "\n", "", "except", "Exception", ":", "\n", "            ", "self", ".", "tokens", "=", "\"Run .tokenize_text() and .fit_tfidf() first\"", "\n", "", "return", "self", ".", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_stop_words": [[222, 233], ["tfidf_utils.TfidfRecommender.tf.get_stop_words"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_stop_words"], ["", "def", "get_stop_words", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the stop words excluded in the TF-IDF vectorizer.\n\n        Returns:\n            list: Frozenset of stop words used by the TF-IDF vectorizer (can be converted to list).\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "stop_words", "=", "self", ".", "tf", ".", "get_stop_words", "(", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "self", ".", "stop_words", "=", "\"Run .tokenize_text() and .fit_tfidf() first\"", "\n", "", "return", "self", ".", "stop_words", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__create_full_recommendation_dictionary": [[234, 258], ["sklearn.metrics.pairwise.linear_kernel", "numpy.argsort", "list", "len", "zip", "range"], "methods", ["None"], ["", "def", "__create_full_recommendation_dictionary", "(", "self", ",", "df_clean", ")", ":", "\n", "        ", "\"\"\"Create the full recommendation dictionary containing all recommendations for all items.\n\n        Args:\n            pandas.DataFrame: Dataframe with cleaned text.\n        \"\"\"", "\n", "\n", "# Similarity measure", "\n", "cosine_sim", "=", "linear_kernel", "(", "self", ".", "tfidf_matrix", ",", "self", ".", "tfidf_matrix", ")", "\n", "\n", "# sorted_idx has the indices that would sort the array.", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "cosine_sim", ",", "axis", "=", "1", ")", "\n", "\n", "data", "=", "list", "(", "df_clean", "[", "self", ".", "id_col", "]", ".", "values", ")", "\n", "len_df_clean", "=", "len", "(", "df_clean", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "idx", ",", "row", "in", "zip", "(", "range", "(", "0", ",", "len_df_clean", ")", ",", "data", ")", ":", "\n", "            ", "similar_indices", "=", "sorted_idx", "[", "idx", "]", "[", ":", "-", "(", "len_df_clean", "+", "1", ")", ":", "-", "1", "]", "\n", "similar_items", "=", "[", "(", "cosine_sim", "[", "idx", "]", "[", "i", "]", ",", "data", "[", "i", "]", ")", "for", "i", "in", "similar_indices", "]", "\n", "results", "[", "row", "]", "=", "similar_items", "[", "1", ":", "]", "\n", "\n", "# Save to class", "\n", "", "self", ".", "recommendations", "=", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__organize_results_as_tabular": [[259, 298], ["list", "list", "list", "list", "pandas.DataFrame", "tfidf_utils.TfidfRecommender.recommendations.get", "list", "list", "list.extend", "list.extend", "list.extend", "list.extend", "map", "map", "list", "range"], "methods", ["None"], ["", "def", "__organize_results_as_tabular", "(", "self", ",", "df_clean", ",", "k", ")", ":", "\n", "        ", "\"\"\"Restructures results dictionary into a table containing only the top k recommendations per item.\n\n        Args:\n            df_clean (pandas.DataFrame): Dataframe with cleaned text.\n            k (int): Number of recommendations to return.\n        \"\"\"", "\n", "# Initialize new dataframe to hold recommendation output", "\n", "item_id", "=", "list", "(", ")", "\n", "rec_rank", "=", "list", "(", ")", "\n", "rec_score", "=", "list", "(", ")", "\n", "rec_item_id", "=", "list", "(", ")", "\n", "\n", "# For each item", "\n", "for", "_item_id", "in", "self", ".", "recommendations", ":", "\n", "# Information about the item we are basing recommendations off of", "\n", "            ", "rec_based_on", "=", "tmp_item_id", "=", "_item_id", "\n", "\n", "# Get all scores and IDs for items recommended for this current item", "\n", "rec_array", "=", "self", ".", "recommendations", ".", "get", "(", "rec_based_on", ")", "\n", "tmp_rec_score", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "rec_array", ")", ")", "\n", "tmp_rec_id", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "1", "]", ",", "rec_array", ")", ")", "\n", "\n", "# Append multiple values at a time to list", "\n", "item_id", ".", "extend", "(", "[", "tmp_item_id", "]", "*", "k", ")", "\n", "rec_rank", ".", "extend", "(", "list", "(", "range", "(", "1", ",", "k", "+", "1", ")", ")", ")", "\n", "rec_score", ".", "extend", "(", "tmp_rec_score", "[", ":", "k", "]", ")", "\n", "rec_item_id", ".", "extend", "(", "tmp_rec_id", "[", ":", "k", "]", ")", "\n", "\n", "# Save the output", "\n", "", "output_dict", "=", "{", "\n", "self", ".", "id_col", ":", "item_id", ",", "\n", "\"rec_rank\"", ":", "rec_rank", ",", "\n", "\"rec_score\"", ":", "rec_score", ",", "\n", "\"rec_\"", "+", "self", ".", "id_col", ":", "rec_item_id", ",", "\n", "}", "\n", "\n", "# Convert to dataframe", "\n", "self", ".", "top_k_recommendations", "=", "pd", ".", "DataFrame", "(", "output_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.recommend_top_k_items": [[299, 317], ["tfidf_utils.TfidfRecommender.__create_full_recommendation_dictionary", "tfidf_utils.TfidfRecommender.__organize_results_as_tabular", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__create_full_recommendation_dictionary", "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__organize_results_as_tabular"], ["", "def", "recommend_top_k_items", "(", "self", ",", "df_clean", ",", "k", "=", "5", ")", ":", "\n", "        ", "\"\"\"Recommend k number of items similar to the item of interest.\n\n        Args:\n            df_clean (pandas.DataFrame): Dataframe with cleaned text.\n            k (int): Number of recommendations to return.\n\n        Returns:\n            pandas.DataFrame: Dataframe containing id of top k recommendations for all items.\n        \"\"\"", "\n", "if", "k", ">", "len", "(", "df_clean", ")", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot get more recommendations than there are items. Set k lower.\"", "\n", ")", "\n", "", "self", ".", "__create_full_recommendation_dictionary", "(", "df_clean", ")", "\n", "self", ".", "__organize_results_as_tabular", "(", "df_clean", ",", "k", ")", "\n", "\n", "return", "self", ".", "top_k_recommendations", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__get_single_item_info": [[318, 333], ["int", "numpy.where"], "methods", ["None"], ["", "def", "__get_single_item_info", "(", "self", ",", "metadata", ",", "rec_id", ")", ":", "\n", "        ", "\"\"\"Get full information for a single recommended item.\n\n        Args:\n            metadata (pandas.DataFrame): Dataframe containing item info.\n            rec_id (str): Identifier for recommended item.\n\n        Returns:\n            pandas.Series: Single row from dataframe containing recommended item info.\n        \"\"\"", "\n", "\n", "# Return row", "\n", "rec_info", "=", "metadata", ".", "iloc", "[", "int", "(", "np", ".", "where", "(", "metadata", "[", "self", ".", "id_col", "]", "==", "rec_id", ")", "[", "0", "]", ")", "]", "\n", "\n", "return", "rec_info", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__make_clickable": [[334, 341], ["None"], "methods", ["None"], ["", "def", "__make_clickable", "(", "self", ",", "address", ")", ":", "\n", "        ", "\"\"\"Make URL clickable.\n\n        Args:\n            address (str): URL address to make clickable.\n        \"\"\"", "\n", "return", "'<a href=\"{0}\">{0}</a>'", ".", "format", "(", "address", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.get_top_k_recommendations": [[342, 398], ["tfidf_utils.TfidfRecommender.top_k_recommendations.loc[].reset_index", "df.head().style.format.head().style.format.drop", "df.head().style.format.head().style.format.apply", "df.head().style.format.head().style.format.drop", "df.head().style.format.head().style.format.rename", "len", "cols_to_keep.insert", "cols_to_keep.insert", "list", "df.head().style.format.head().style.format.head().style.format", "tfidf_utils.TfidfRecommender.__get_single_item_info", "map", "x.lower", "df.head().style.format.head().style.format.head"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.tfidf.tfidf_utils.TfidfRecommender.__get_single_item_info"], ["", "def", "get_top_k_recommendations", "(", "\n", "self", ",", "metadata", ",", "query_id", ",", "cols_to_keep", "=", "[", "]", ",", "verbose", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"Return the top k recommendations with useful metadata for each recommendation.\n\n        Args:\n            metadata (pandas.DataFrame): Dataframe holding metadata for all public domain papers.\n            query_id (str): ID of item of interest.\n            cols_to_keep (list of str): List of columns from the metadata dataframe to include\n                (e.g., ['title','authors','journal','publish_time','url']).\n                By default, all columns are kept.\n            verbose (boolean): Set to True if you want to print the table.\n\n        Returns:\n            pandas.Styler: Stylized dataframe holding recommendations and associated metadata just for the item of interest (can access as normal dataframe by using df.data).\n        \"\"\"", "\n", "\n", "# Create subset of dataframe with just recommendations for the item of interest", "\n", "df", "=", "self", ".", "top_k_recommendations", ".", "loc", "[", "\n", "self", ".", "top_k_recommendations", "[", "self", ".", "id_col", "]", "==", "query_id", "\n", "]", ".", "reset_index", "(", ")", "\n", "\n", "# Remove id_col of query item", "\n", "df", ".", "drop", "(", "[", "self", ".", "id_col", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "# Add metadata for each recommended item (rec_<id_col>)", "\n", "metadata_cols", "=", "metadata", ".", "columns", ".", "values", "\n", "df", "[", "metadata_cols", "]", "=", "df", ".", "apply", "(", "\n", "lambda", "row", ":", "self", ".", "__get_single_item_info", "(", "\n", "metadata", ",", "row", "[", "\"rec_\"", "+", "self", ".", "id_col", "]", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "# Remove id col added from metadata (already present from self.top_k_recommendations)", "\n", "df", ".", "drop", "(", "[", "self", ".", "id_col", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "# Rename columns such that rec_ is no longer appended, for simplicity", "\n", "df", "=", "df", ".", "rename", "(", "columns", "=", "{", "\"rec_rank\"", ":", "\"rank\"", ",", "\"rec_score\"", ":", "\"similarity_score\"", "}", ")", "\n", "\n", "# Only keep columns of interest", "\n", "if", "len", "(", "cols_to_keep", ")", ">", "0", ":", "\n", "# Insert our recommendation scoring/ranking columns", "\n", "            ", "cols_to_keep", ".", "insert", "(", "0", ",", "\"similarity_score\"", ")", "\n", "cols_to_keep", ".", "insert", "(", "0", ",", "\"rank\"", ")", "\n", "df", "=", "df", "[", "cols_to_keep", "]", "\n", "\n", "# Make URLs clickable if they exist", "\n", "", "if", "\"url\"", "in", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "lower", "(", ")", ",", "metadata_cols", ")", ")", ":", "\n", "            ", "format_", "=", "{", "\"url\"", ":", "self", ".", "__make_clickable", "}", "\n", "df", "=", "df", ".", "head", "(", ")", ".", "style", ".", "format", "(", "format_", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "df", "\n", "\n", "", "return", "df", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.LossHistory.on_train_begin": [[20, 24], ["None"], "methods", ["None"], ["def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise the lists where the loss of training and validation will be saved.\"\"\"", "\n", "self", ".", "losses", "=", "[", "]", "\n", "self", ".", "val_losses", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.LossHistory.on_epoch_end": [[25, 29], ["standard_vae.LossHistory.losses.append", "standard_vae.LossHistory.val_losses.append", "logs.get", "logs.get"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Save the loss of training and validation set at the end of each epoch.\"\"\"", "\n", "self", ".", "losses", ".", "append", "(", "logs", ".", "get", "(", "\"loss\"", ")", ")", "\n", "self", ".", "val_losses", ".", "append", "(", "logs", ".", "get", "(", "\"val_loss\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.Metrics.__init__": [[35, 65], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "val_tr", ",", "val_te", ",", "mapper", ",", "k", ",", "save_path", "=", "None", ")", ":", "\n", "\n", "        ", "\"\"\"Initialize the class parameters.\n\n        Args:\n            model: trained model for validation.\n            val_tr (numpy.ndarray, float): the click matrix for the validation set training part.\n            val_te (numpy.ndarray, float): the click matrix for the validation set testing part.\n            mapper (AffinityMatrix): the mapper for converting click matrix to dataframe.\n            k (int): number of top k items per user (optional).\n            save_path (str): Default path to save weights.\n        \"\"\"", "\n", "# Model", "\n", "self", ".", "model", "=", "model", "\n", "\n", "# Initial value of NDCG", "\n", "self", ".", "best_ndcg", "=", "0.0", "\n", "\n", "# Validation data: training and testing parts", "\n", "self", ".", "val_tr", "=", "val_tr", "\n", "self", ".", "val_te", "=", "val_te", "\n", "\n", "# Mapper for converting from sparse matrix to dataframe", "\n", "self", ".", "mapper", "=", "mapper", "\n", "\n", "# Top k items to recommend", "\n", "self", ".", "k", "=", "k", "\n", "\n", "# Options to save the weights of the model for future use", "\n", "self", ".", "save_path", "=", "save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.Metrics.on_train_begin": [[66, 69], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise the list for validation NDCG@k.\"\"\"", "\n", "self", ".", "_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.Metrics.recommend_k_items": [[70, 103], ["standard_vae.Metrics.model.predict", "standard_vae.Metrics.copy", "numpy.not_equal", "numpy.argpartition", "range", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "recommend_k_items", "(", "self", ",", "x", ",", "k", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the top-k items ordered by a relevancy score.\n        Obtained probabilities are used as recommendation score.\n\n        Args:\n            x (numpy.ndarray, int32): input click matrix.\n            k (scalar, int32): the number of items to recommend.\n\n        Returns:\n            numpy.ndarray: A sparse matrix containing the top_k elements ordered by their score.\n\n        \"\"\"", "\n", "# obtain scores", "\n", "score", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "# if true, it removes items from the train set by setting them to zero", "\n", "            ", "seen_mask", "=", "np", ".", "not_equal", "(", "x", ",", "0", ")", "\n", "score", "[", "seen_mask", "]", "=", "0", "\n", "\n", "# get the top k items", "\n", "", "top_items", "=", "np", ".", "argpartition", "(", "-", "score", ",", "range", "(", "k", ")", ",", "axis", "=", "1", ")", "[", ":", ",", ":", "k", "]", "\n", "\n", "# get a copy of the score matrix", "\n", "score_c", "=", "score", ".", "copy", "(", ")", "\n", "\n", "# set to zero the k elements", "\n", "score_c", "[", "np", ".", "arange", "(", "score_c", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ",", "top_items", "]", "=", "0", "\n", "\n", "# set to zeros all elements other then the k", "\n", "top_scores", "=", "score", "-", "score_c", "\n", "\n", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.Metrics.on_epoch_end": [[104, 128], ["standard_vae.Metrics.recommend_k_items", "standard_vae.Metrics.mapper.map_back_sparse", "standard_vae.Metrics.mapper.map_back_sparse", "recommenders.evaluation.python_evaluation.ndcg_at_k", "standard_vae.Metrics._data.append", "standard_vae.Metrics.model.save"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "def", "on_epoch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each epoch calculate NDCG@k of the validation set.\n        If the model performance is improved, the model weights are saved.\n        Update the list of validation NDCG@k by adding obtained value.\n        \"\"\"", "\n", "# recommend top k items based on training part of validation set", "\n", "top_k", "=", "self", ".", "recommend_k_items", "(", "x", "=", "self", ".", "val_tr", ",", "k", "=", "self", ".", "k", ",", "remove_seen", "=", "True", ")", "\n", "\n", "# convert recommendations from sparse matrix to dataframe", "\n", "top_k_df", "=", "self", ".", "mapper", ".", "map_back_sparse", "(", "top_k", ",", "kind", "=", "\"prediction\"", ")", "\n", "test_df", "=", "self", ".", "mapper", ".", "map_back_sparse", "(", "self", ".", "val_te", ",", "kind", "=", "\"ratings\"", ")", "\n", "\n", "# calculate NDCG@k", "\n", "NDCG", "=", "ndcg_at_k", "(", "test_df", ",", "top_k_df", ",", "col_prediction", "=", "\"prediction\"", ",", "k", "=", "self", ".", "k", ")", "\n", "\n", "# check if there is an improvement in NDCG, if so, update the weights of the saved model", "\n", "if", "NDCG", ">", "self", ".", "best_ndcg", ":", "\n", "            ", "self", ".", "best_ndcg", "=", "NDCG", "\n", "\n", "# save the weights of the optimal model", "\n", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "model", ".", "save", "(", "self", ".", "save_path", ")", "\n", "\n", "", "", "self", ".", "_data", ".", "append", "(", "NDCG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.Metrics.get_data": [[129, 133], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of the NDCG@k of the validation set metrics calculated\n        at the end of each epoch.\"\"\"", "\n", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.AnnealingCallback.__init__": [[140, 160], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", ",", "anneal_cap", ",", "total_anneal_steps", ")", ":", "\n", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            beta (float): current value of beta.\n            anneal_cap (float): maximum value that beta can reach.\n            total_anneal_steps (int): total number of annealing steps.\n        \"\"\"", "\n", "# maximum value that beta can take", "\n", "self", ".", "anneal_cap", "=", "anneal_cap", "\n", "\n", "# initial value of beta", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "# update_count used for calculating the updated value of beta", "\n", "self", ".", "update_count", "=", "0", "\n", "\n", "# total annealing steps", "\n", "self", ".", "total_anneal_steps", "=", "total_anneal_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.AnnealingCallback.on_train_begin": [[161, 164], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise a list in which the beta value will be saved at the end of each epoch.\"\"\"", "\n", "self", ".", "_beta", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.AnnealingCallback.on_batch_end": [[165, 174], ["min", "tensorflow.keras.backend.set_value"], "methods", ["None"], ["", "def", "on_batch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each batch the beta should is updated until it reaches the values of anneal cap.\"\"\"", "\n", "self", ".", "update_count", "=", "self", ".", "update_count", "+", "1", "\n", "\n", "new_beta", "=", "min", "(", "\n", "1.0", "*", "self", ".", "update_count", "/", "self", ".", "total_anneal_steps", ",", "self", ".", "anneal_cap", "\n", ")", "\n", "\n", "K", ".", "set_value", "(", "self", ".", "beta", ",", "new_beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.AnnealingCallback.on_epoch_end": [[175, 179], ["tensorflow.keras.backend.eval", "standard_vae.AnnealingCallback._beta.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each epoch save the value of beta in _beta list.\"\"\"", "\n", "tmp", "=", "K", ".", "eval", "(", "self", ".", "beta", ")", "\n", "self", ".", "_beta", ".", "append", "(", "tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.AnnealingCallback.get_data": [[180, 183], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of the beta values per epoch.\"\"\"", "\n", "return", "self", ".", "_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.__init__": [[188, 268], ["numpy.random.seed", "standard_vae.StandardVAE._create_model", "tensorflow.keras.backend.variable", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._create_model"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_users", ",", "\n", "original_dim", ",", "\n", "intermediate_dim", "=", "200", ",", "\n", "latent_dim", "=", "70", ",", "\n", "n_epochs", "=", "400", ",", "\n", "batch_size", "=", "100", ",", "\n", "k", "=", "100", ",", "\n", "verbose", "=", "1", ",", "\n", "drop_encoder", "=", "0.5", ",", "\n", "drop_decoder", "=", "0.5", ",", "\n", "beta", "=", "1.0", ",", "\n", "annealing", "=", "False", ",", "\n", "anneal_cap", "=", "1.0", ",", "\n", "seed", "=", "None", ",", "\n", "save_path", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"Initialize class parameters.\n\n        Args:\n            n_users (int): Number of unique users in the train set.\n            original_dim (int): Number of unique items in the train set.\n            intermediate_dim (int): Dimension of intermediate space.\n            latent_dim (int): Dimension of latent space.\n            n_epochs (int): Number of epochs for training.\n            batch_size (int): Batch size.\n            k (int): number of top k items per user.\n            verbose (int): Whether to show the training output or not.\n            drop_encoder (float): Dropout percentage of the encoder.\n            drop_decoder (float): Dropout percentage of the decoder.\n            beta (float): a constant parameter \u03b2 in the ELBO function,\n                  when you are not using annealing (annealing=False)\n            annealing (bool): option of using annealing method for training the model (True)\n                  or not using annealing, keeping a constant beta (False)\n            anneal_cap (float): maximum value that beta can take during annealing process.\n            seed (int): Seed.\n            save_path (str): Default path to save weights.\n        \"\"\"", "\n", "# Seed", "\n", "self", ".", "seed", "=", "seed", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "\n", "# Parameters", "\n", "self", ".", "n_users", "=", "n_users", "\n", "self", ".", "original_dim", "=", "original_dim", "\n", "self", ".", "intermediate_dim", "=", "intermediate_dim", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "# Compute samples per epoch", "\n", "self", ".", "number_of_batches", "=", "self", ".", "n_users", "//", "self", ".", "batch_size", "\n", "\n", "# Annealing parameters", "\n", "self", ".", "anneal_cap", "=", "anneal_cap", "\n", "self", ".", "annealing", "=", "annealing", "\n", "\n", "if", "self", ".", "annealing", ":", "\n", "            ", "self", ".", "beta", "=", "K", ".", "variable", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "beta", "\n", "\n", "# Compute total annealing steps", "\n", "", "self", ".", "total_anneal_steps", "=", "(", "\n", "self", ".", "number_of_batches", "*", "(", "self", ".", "n_epochs", "-", "int", "(", "self", ".", "n_epochs", "*", "0.2", ")", ")", "\n", ")", "//", "self", ".", "anneal_cap", "\n", "\n", "# Dropout parameters", "\n", "self", ".", "drop_encoder", "=", "drop_encoder", "\n", "self", ".", "drop_decoder", "=", "drop_decoder", "\n", "\n", "# Path to save optimal model", "\n", "self", ".", "save_path", "=", "save_path", "\n", "\n", "# Create StandardVAE model", "\n", "self", ".", "_create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE._create_model": [[269, 296], ["Input", "Dense", "Dropout", "Dense", "standard_vae.StandardVAE.h_decoder", "standard_vae.StandardVAE.dropout_decoder", "standard_vae.StandardVAE.x_bar", "tensorflow.keras.models.Model", "standard_vae.StandardVAE.model.compile", "Dropout", "Dense", "Dense", "Dense", "Lambda", "tensorflow.keras.optimizers.Adam"], "methods", ["None"], ["", "def", "_create_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build and compile model.\"\"\"", "\n", "# Encoding", "\n", "self", ".", "x", "=", "Input", "(", "shape", "=", "(", "self", ".", "original_dim", ",", ")", ")", "\n", "self", ".", "dropout_encoder", "=", "Dropout", "(", "self", ".", "drop_encoder", ")", "(", "self", ".", "x", ")", "\n", "self", ".", "h", "=", "Dense", "(", "self", ".", "intermediate_dim", ",", "activation", "=", "\"tanh\"", ")", "(", "self", ".", "dropout_encoder", ")", "\n", "self", ".", "z_mean", "=", "Dense", "(", "self", ".", "latent_dim", ")", "(", "self", ".", "h", ")", "\n", "self", ".", "z_log_var", "=", "Dense", "(", "self", ".", "latent_dim", ")", "(", "self", ".", "h", ")", "\n", "\n", "# Sampling", "\n", "self", ".", "z", "=", "Lambda", "(", "self", ".", "_take_sample", ",", "output_shape", "=", "(", "self", ".", "latent_dim", ",", ")", ")", "(", "\n", "[", "self", ".", "z_mean", ",", "self", ".", "z_log_var", "]", "\n", ")", "\n", "\n", "# Decoding", "\n", "self", ".", "h_decoder", "=", "Dense", "(", "self", ".", "intermediate_dim", ",", "activation", "=", "\"tanh\"", ")", "\n", "self", ".", "dropout_decoder", "=", "Dropout", "(", "self", ".", "drop_decoder", ")", "\n", "self", ".", "x_bar", "=", "Dense", "(", "self", ".", "original_dim", ",", "activation", "=", "\"softmax\"", ")", "\n", "self", ".", "h_decoded", "=", "self", ".", "h_decoder", "(", "self", ".", "z", ")", "\n", "self", ".", "h_decoded_", "=", "self", ".", "dropout_decoder", "(", "self", ".", "h_decoded", ")", "\n", "self", ".", "x_decoded", "=", "self", ".", "x_bar", "(", "self", ".", "h_decoded_", ")", "\n", "\n", "# Training", "\n", "self", ".", "model", "=", "Model", "(", "self", ".", "x", ",", "self", ".", "x_decoded", ")", "\n", "self", ".", "model", ".", "compile", "(", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "0.001", ")", ",", "\n", "loss", "=", "self", ".", "_get_vae_loss", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE._get_vae_loss": [[298, 309], ["tensorflow.keras.losses.binary_crossentropy", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.square"], "methods", ["None"], ["", "def", "_get_vae_loss", "(", "self", ",", "x", ",", "x_bar", ")", ":", "\n", "        ", "\"\"\"Calculate negative ELBO (NELBO).\"\"\"", "\n", "# Reconstruction error: logistic log likelihood", "\n", "reconst_loss", "=", "self", ".", "original_dim", "*", "binary_crossentropy", "(", "x", ",", "x_bar", ")", "\n", "\n", "# Kullback\u2013Leibler divergence", "\n", "kl_loss", "=", "0.5", "*", "K", ".", "sum", "(", "\n", "-", "1", "-", "self", ".", "z_log_var", "+", "K", ".", "square", "(", "self", ".", "z_mean", ")", "+", "K", ".", "exp", "(", "self", ".", "z_log_var", ")", ",", "axis", "=", "-", "1", "\n", ")", "\n", "\n", "return", "reconst_loss", "+", "self", ".", "beta", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE._take_sample": [[310, 325], ["tensorflow.keras.backend.random_normal", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.shape"], "methods", ["None"], ["", "def", "_take_sample", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Sample epsilon \u223c N (0,I) and compute z via reparametrization trick.\"\"\"", "\n", "\"\"\"Calculate latent vector using the reparametrization trick.\n           The idea is that sampling from N (_mean, _var) is s the same as sampling from _mean+ epsilon * _var\n           where epsilon \u223c N(0,I).\"\"\"", "\n", "# sampling from latent dimension for decoder/generative part of network", "\n", "_mean", ",", "_log_var", "=", "args", "\n", "epsilon", "=", "K", ".", "random_normal", "(", "\n", "shape", "=", "(", "K", ".", "shape", "(", "_mean", ")", "[", "0", "]", ",", "self", ".", "latent_dim", ")", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "1.0", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n", "\n", "return", "_mean", "+", "K", ".", "exp", "(", "_log_var", "/", "2", ")", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.nn_batch_generator": [[326, 354], ["numpy.random.seed", "numpy.arange", "numpy.random.shuffle", "numpy.shape", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "nn_batch_generator", "(", "self", ",", "x_train", ")", ":", "\n", "        ", "\"\"\"Used for splitting dataset in batches.\n\n        Args:\n            x_train (numpy.ndarray): The click matrix for the train set with float values.\n        \"\"\"", "\n", "# Shuffle the batch", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "shuffle_index", "=", "np", ".", "arange", "(", "np", ".", "shape", "(", "x_train", ")", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "shuffle_index", ")", "\n", "x", "=", "x_train", "[", "shuffle_index", ",", ":", "]", "\n", "y", "=", "x_train", "[", "shuffle_index", ",", ":", "]", "\n", "\n", "# Iterate until making a full epoch", "\n", "counter", "=", "0", "\n", "while", "1", ":", "\n", "            ", "index_batch", "=", "shuffle_index", "[", "\n", "self", ".", "batch_size", "*", "counter", ":", "self", ".", "batch_size", "*", "(", "counter", "+", "1", ")", "\n", "]", "\n", "# Decompress batch", "\n", "x_batch", "=", "x", "[", "index_batch", ",", ":", "]", "\n", "y_batch", "=", "y", "[", "index_batch", ",", ":", "]", "\n", "counter", "+=", "1", "\n", "yield", "(", "np", ".", "array", "(", "x_batch", ")", ",", "np", ".", "array", "(", "y_batch", ")", ")", "\n", "\n", "# Stopping rule", "\n", "if", "counter", ">=", "self", ".", "number_of_batches", ":", "\n", "                ", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.fit": [[355, 415], ["standard_vae.LossHistory", "standard_vae.Metrics", "tensorflow.keras.callbacks.ReduceLROnPlateau", "standard_vae.Metrics.get_data", "standard_vae.AnnealingCallback", "standard_vae.StandardVAE.model.fit_generator", "standard_vae.AnnealingCallback.get_data", "standard_vae.StandardVAE.model.fit_generator", "standard_vae.StandardVAE.nn_batch_generator", "standard_vae.StandardVAE.nn_batch_generator"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.nn_batch_generator", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.nn_batch_generator"], ["", "", "", "def", "fit", "(", "self", ",", "x_train", ",", "x_valid", ",", "x_val_tr", ",", "x_val_te", ",", "mapper", ")", ":", "\n", "        ", "\"\"\"Fit model with the train sets and validate on the validation set.\n\n        Args:\n            x_train (numpy.ndarray): The click matrix for the train set.\n            x_valid (numpy.ndarray): The click matrix for the validation set.\n            x_val_tr (numpy.ndarray): The click matrix for the validation set training part.\n            x_val_te (numpy.ndarray): The click matrix for the validation set testing part.\n            mapper (object): The mapper for converting click matrix to dataframe. It can be AffinityMatrix.\n        \"\"\"", "\n", "# initialise LossHistory used for saving loss of validation and train set per epoch", "\n", "history", "=", "LossHistory", "(", ")", "\n", "\n", "# initialise Metrics  used for calculating NDCG@k per epoch", "\n", "# and saving the model weights with the highest NDCG@k value", "\n", "metrics", "=", "Metrics", "(", "\n", "model", "=", "self", ".", "model", ",", "\n", "val_tr", "=", "x_val_tr", ",", "\n", "val_te", "=", "x_val_te", ",", "\n", "mapper", "=", "mapper", ",", "\n", "k", "=", "self", ".", "k", ",", "\n", "save_path", "=", "self", ".", "save_path", ",", "\n", ")", "\n", "\n", "self", ".", "reduce_lr", "=", "ReduceLROnPlateau", "(", "\n", "monitor", "=", "\"val_loss\"", ",", "factor", "=", "0.2", ",", "patience", "=", "1", ",", "min_lr", "=", "0.0001", "\n", ")", "\n", "\n", "if", "self", ".", "annealing", ":", "\n", "# initialise AnnealingCallback for annealing process", "\n", "            ", "anneal", "=", "AnnealingCallback", "(", "\n", "self", ".", "beta", ",", "self", ".", "anneal_cap", ",", "self", ".", "total_anneal_steps", "\n", ")", "\n", "\n", "# fit model", "\n", "self", ".", "model", ".", "fit_generator", "(", "\n", "generator", "=", "self", ".", "nn_batch_generator", "(", "x_train", ")", ",", "\n", "steps_per_epoch", "=", "self", ".", "number_of_batches", ",", "\n", "epochs", "=", "self", ".", "n_epochs", ",", "\n", "verbose", "=", "self", ".", "verbose", ",", "\n", "callbacks", "=", "[", "metrics", ",", "history", ",", "self", ".", "reduce_lr", ",", "anneal", "]", ",", "\n", "validation_data", "=", "(", "x_valid", ",", "x_valid", ")", ",", "\n", ")", "\n", "\n", "self", ".", "ls_beta", "=", "anneal", ".", "get_data", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "fit_generator", "(", "\n", "generator", "=", "self", ".", "nn_batch_generator", "(", "x_train", ")", ",", "\n", "steps_per_epoch", "=", "self", ".", "number_of_batches", ",", "\n", "epochs", "=", "self", ".", "n_epochs", ",", "\n", "verbose", "=", "self", ".", "verbose", ",", "\n", "callbacks", "=", "[", "metrics", ",", "history", ",", "self", ".", "reduce_lr", "]", ",", "\n", "validation_data", "=", "(", "x_valid", ",", "x_valid", ")", ",", "\n", ")", "\n", "\n", "# save lists", "\n", "", "self", ".", "train_loss", "=", "history", ".", "losses", "\n", "self", ".", "val_loss", "=", "history", ".", "val_losses", "\n", "self", ".", "val_ndcg", "=", "metrics", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.get_optimal_beta": [[416, 425], ["numpy.argmax"], "methods", ["None"], ["", "def", "get_optimal_beta", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the value of the optimal beta.\"\"\"", "\n", "# find the epoch/index that had the highest NDCG@k value", "\n", "index_max_ndcg", "=", "np", ".", "argmax", "(", "self", ".", "val_ndcg", ")", "\n", "\n", "# using this index find the value that beta had at this epoch", "\n", "optimal_beta", "=", "self", ".", "ls_beta", "[", "index_max_ndcg", "]", "\n", "\n", "return", "optimal_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.display_metrics": [[426, 455], ["matplotlib.figure", "seaborn.set", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.subplot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.suptitle", "matplotlib.tight_layout"], "methods", ["None"], ["", "def", "display_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Plots:\n        1) Loss per epoch both for validation and train sets\n        2) NDCG@k per epoch of the validation set\n        \"\"\"", "\n", "# Plot setup", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "5", ")", ")", "\n", "sns", ".", "set", "(", "style", "=", "\"whitegrid\"", ")", "\n", "\n", "# Plot loss on the left graph", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "1", ")", "\n", "plt", ".", "plot", "(", "self", ".", "train_loss", ",", "color", "=", "\"b\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Train\"", ")", "\n", "plt", ".", "plot", "(", "self", ".", "val_loss", ",", "color", "=", "\"r\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Val\"", ")", "\n", "plt", ".", "title", "(", "\"\\n\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Epochs\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"Loss\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Plot NDCG on the right graph", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "2", ")", "\n", "plt", ".", "plot", "(", "self", ".", "val_ndcg", ",", "color", "=", "\"r\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Val\"", ")", "\n", "plt", ".", "title", "(", "\"\\n\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Epochs\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"NDCG@k\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Add title", "\n", "plt", ".", "suptitle", "(", "\"TRAINING AND VALIDATION METRICS HISTORY\"", ",", "size", "=", "16", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.recommend_k_items": [[456, 487], ["standard_vae.StandardVAE.model.load_weights", "standard_vae.StandardVAE.model.predict", "standard_vae.StandardVAE.copy", "numpy.not_equal", "numpy.argpartition", "range", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "recommend_k_items", "(", "self", ",", "x", ",", "k", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the top-k items ordered by a relevancy score.\n\n        Obtained probabilities are used as recommendation score.\n\n        Args:\n            x (numpy.ndarray): Input click matrix, with `int32` values.\n            k (scalar): The number of items to recommend.\n\n        Returns:\n            numpy.ndarray: A sparse matrix containing the top_k elements ordered by their score.\n\n        \"\"\"", "\n", "# return optimal model", "\n", "self", ".", "model", ".", "load_weights", "(", "self", ".", "save_path", ")", "\n", "\n", "# obtain scores", "\n", "score", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "if", "remove_seen", ":", "\n", "# if true, it removes items from the train set by setting them to zero", "\n", "            ", "seen_mask", "=", "np", ".", "not_equal", "(", "x", ",", "0", ")", "\n", "score", "[", "seen_mask", "]", "=", "0", "\n", "# get the top k items", "\n", "", "top_items", "=", "np", ".", "argpartition", "(", "-", "score", ",", "range", "(", "k", ")", ",", "axis", "=", "1", ")", "[", ":", ",", ":", "k", "]", "\n", "# get a copy of the score matrix", "\n", "score_c", "=", "score", ".", "copy", "(", ")", "\n", "# set to zero the k elements", "\n", "score_c", "[", "np", ".", "arange", "(", "score_c", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ",", "top_items", "]", "=", "0", "\n", "# set to zeros all elements other then the k", "\n", "top_scores", "=", "score", "-", "score_c", "\n", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.standard_vae.StandardVAE.ndcg_per_epoch": [[488, 492], ["None"], "methods", ["None"], ["", "def", "ndcg_per_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of NDCG@k at each epoch.\"\"\"", "\n", "\n", "return", "self", ".", "val_ndcg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.LossHistory.on_train_begin": [[19, 23], ["None"], "methods", ["None"], ["def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise the lists where the loss of training and validation will be saved.\"\"\"", "\n", "self", ".", "losses", "=", "[", "]", "\n", "self", ".", "val_losses", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.LossHistory.on_epoch_end": [[24, 28], ["multinomial_vae.LossHistory.losses.append", "multinomial_vae.LossHistory.val_losses.append", "logs.get", "logs.get"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Save the loss of training and validation set at the end of each epoch.\"\"\"", "\n", "self", ".", "losses", ".", "append", "(", "logs", ".", "get", "(", "\"loss\"", ")", ")", "\n", "self", ".", "val_losses", ".", "append", "(", "logs", ".", "get", "(", "\"val_loss\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Metrics.__init__": [[34, 64], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "val_tr", ",", "val_te", ",", "mapper", ",", "k", ",", "save_path", "=", "None", ")", ":", "\n", "\n", "        ", "\"\"\"Initialize the class parameters.\n\n        Args:\n            model: trained model for validation.\n            val_tr (numpy.ndarray, float): the click matrix for the validation set training part.\n            val_te (numpy.ndarray, float): the click matrix for the validation set testing part.\n            mapper (AffinityMatrix): the mapper for converting click matrix to dataframe.\n            k (int): number of top k items per user (optional).\n            save_path (str): Default path to save weights.\n        \"\"\"", "\n", "# Model", "\n", "self", ".", "model", "=", "model", "\n", "\n", "# Initial value of NDCG", "\n", "self", ".", "best_ndcg", "=", "0.0", "\n", "\n", "# Validation data: training and testing parts", "\n", "self", ".", "val_tr", "=", "val_tr", "\n", "self", ".", "val_te", "=", "val_te", "\n", "\n", "# Mapper for converting from sparse matrix to dataframe", "\n", "self", ".", "mapper", "=", "mapper", "\n", "\n", "# Top k items to recommend", "\n", "self", ".", "k", "=", "k", "\n", "\n", "# Options to save the weights of the model for future use", "\n", "self", ".", "save_path", "=", "save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Metrics.on_train_begin": [[65, 68], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise the list for validation NDCG@k.\"\"\"", "\n", "self", ".", "_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Metrics.recommend_k_items": [[69, 102], ["multinomial_vae.Metrics.model.predict", "multinomial_vae.Metrics.copy", "numpy.not_equal", "numpy.argpartition", "range", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "recommend_k_items", "(", "self", ",", "x", ",", "k", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the top-k items ordered by a relevancy score.\n        Obtained probabilities are used as recommendation score.\n\n        Args:\n            x (numpy.ndarray, int32): input click matrix.\n            k (scalar, int32): the number of items to recommend.\n\n        Returns:\n            numpy.ndarray: A sparse matrix containing the top_k elements ordered by their score.\n\n        \"\"\"", "\n", "# obtain scores", "\n", "score", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "# if true, it removes items from the train set by setting them to zero", "\n", "            ", "seen_mask", "=", "np", ".", "not_equal", "(", "x", ",", "0", ")", "\n", "score", "[", "seen_mask", "]", "=", "0", "\n", "\n", "# get the top k items", "\n", "", "top_items", "=", "np", ".", "argpartition", "(", "-", "score", ",", "range", "(", "k", ")", ",", "axis", "=", "1", ")", "[", ":", ",", ":", "k", "]", "\n", "\n", "# get a copy of the score matrix", "\n", "score_c", "=", "score", ".", "copy", "(", ")", "\n", "\n", "# set to zero the k elements", "\n", "score_c", "[", "np", ".", "arange", "(", "score_c", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ",", "top_items", "]", "=", "0", "\n", "\n", "# set to zeros all elements other then the k", "\n", "top_scores", "=", "score", "-", "score_c", "\n", "\n", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Metrics.on_epoch_end": [[103, 129], ["multinomial_vae.Metrics.recommend_k_items", "multinomial_vae.Metrics.mapper.map_back_sparse", "multinomial_vae.Metrics.mapper.map_back_sparse", "recommenders.evaluation.python_evaluation.ndcg_at_k", "multinomial_vae.Metrics._data.append", "multinomial_vae.Metrics.model.save"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.sparse.AffinityMatrix.map_back_sparse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "def", "on_epoch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each epoch calculate NDCG@k of the validation set.\n\n        If the model performance is improved, the model weights are saved.\n        Update the list of validation NDCG@k by adding obtained value\n\n        \"\"\"", "\n", "# recommend top k items based on training part of validation set", "\n", "top_k", "=", "self", ".", "recommend_k_items", "(", "x", "=", "self", ".", "val_tr", ",", "k", "=", "self", ".", "k", ",", "remove_seen", "=", "True", ")", "\n", "\n", "# convert recommendations from sparse matrix to dataframe", "\n", "top_k_df", "=", "self", ".", "mapper", ".", "map_back_sparse", "(", "top_k", ",", "kind", "=", "\"prediction\"", ")", "\n", "test_df", "=", "self", ".", "mapper", ".", "map_back_sparse", "(", "self", ".", "val_te", ",", "kind", "=", "\"ratings\"", ")", "\n", "\n", "# calculate NDCG@k", "\n", "NDCG", "=", "ndcg_at_k", "(", "test_df", ",", "top_k_df", ",", "col_prediction", "=", "\"prediction\"", ",", "k", "=", "self", ".", "k", ")", "\n", "\n", "# check if there is an improvement in NDCG, if so, update the weights of the saved model", "\n", "if", "NDCG", ">", "self", ".", "best_ndcg", ":", "\n", "            ", "self", ".", "best_ndcg", "=", "NDCG", "\n", "\n", "# save the weights of the optimal model", "\n", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "model", ".", "save", "(", "self", ".", "save_path", ")", "\n", "\n", "", "", "self", ".", "_data", ".", "append", "(", "NDCG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Metrics.get_data": [[130, 134], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of the NDCG@k of the validation set metrics calculated\n        at the end of each epoch.\"\"\"", "\n", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.__init__": [[140, 160], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", ",", "anneal_cap", ",", "total_anneal_steps", ")", ":", "\n", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            beta (float): current value of beta.\n            anneal_cap (float): maximum value that beta can reach.\n            total_anneal_steps (int): total number of annealing steps.\n        \"\"\"", "\n", "# maximum value that beta can take", "\n", "self", ".", "anneal_cap", "=", "anneal_cap", "\n", "\n", "# initial value of beta", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "# update_count used for calculating the updated value of beta", "\n", "self", ".", "update_count", "=", "0", "\n", "\n", "# total annealing steps", "\n", "self", ".", "total_anneal_steps", "=", "total_anneal_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.on_train_begin": [[161, 164], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialise a list in which the beta value will be saved at the end of each epoch.\"\"\"", "\n", "self", ".", "_beta", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.on_batch_end": [[165, 174], ["min", "tensorflow.keras.backend.set_value"], "methods", ["None"], ["", "def", "on_batch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each batch the beta should is updated until it reaches the values of anneal cap.\"\"\"", "\n", "self", ".", "update_count", "=", "self", ".", "update_count", "+", "1", "\n", "\n", "new_beta", "=", "min", "(", "\n", "1.0", "*", "self", ".", "update_count", "/", "self", ".", "total_anneal_steps", ",", "self", ".", "anneal_cap", "\n", ")", "\n", "\n", "K", ".", "set_value", "(", "self", ".", "beta", ",", "new_beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.on_epoch_end": [[175, 179], ["tensorflow.keras.backend.eval", "multinomial_vae.AnnealingCallback._beta.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"At the end of each epoch save the value of beta in _beta list.\"\"\"", "\n", "tmp", "=", "K", ".", "eval", "(", "self", ".", "beta", ")", "\n", "self", ".", "_beta", ".", "append", "(", "tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data": [[180, 183], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of the beta values per epoch.\"\"\"", "\n", "return", "self", ".", "_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.__init__": [[195, 277], ["numpy.random.seed", "multinomial_vae.Mult_VAE._create_model", "tensorflow.keras.backend.variable", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._create_model"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_users", ",", "\n", "original_dim", ",", "\n", "intermediate_dim", "=", "200", ",", "\n", "latent_dim", "=", "70", ",", "\n", "n_epochs", "=", "400", ",", "\n", "batch_size", "=", "100", ",", "\n", "k", "=", "100", ",", "\n", "verbose", "=", "1", ",", "\n", "drop_encoder", "=", "0.5", ",", "\n", "drop_decoder", "=", "0.5", ",", "\n", "beta", "=", "1.0", ",", "\n", "annealing", "=", "False", ",", "\n", "anneal_cap", "=", "1.0", ",", "\n", "seed", "=", "None", ",", "\n", "save_path", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"Constructor\n\n        Args:\n            n_users (int): Number of unique users in the train set.\n            original_dim (int): Number of unique items in the train set.\n            intermediate_dim (int): Dimension of intermediate space.\n            latent_dim (int): Dimension of latent space.\n            n_epochs (int): Number of epochs for training.\n            batch_size (int): Batch size.\n            k (int): number of top k items per user.\n            verbose (int): Whether to show the training output or not.\n            drop_encoder (float): Dropout percentage of the encoder.\n            drop_decoder (float): Dropout percentage of the decoder.\n            beta (float): a constant parameter \u03b2 in the ELBO function,\n                  when you are not using annealing (annealing=False)\n            annealing (bool): option of using annealing method for training the model (True)\n                  or not using annealing, keeping a constant beta (False)\n            anneal_cap (float): maximum value that beta can take during annealing process.\n            seed (int): Seed.\n            save_path (str): Default path to save weights.\n        \"\"\"", "\n", "# Seed", "\n", "self", ".", "seed", "=", "seed", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "\n", "# Parameters", "\n", "self", ".", "n_users", "=", "n_users", "\n", "self", ".", "original_dim", "=", "original_dim", "\n", "self", ".", "intermediate_dim", "=", "intermediate_dim", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "# Compute samples per epoch", "\n", "self", ".", "number_of_batches", "=", "self", ".", "n_users", "//", "self", ".", "batch_size", "\n", "\n", "# Annealing parameters", "\n", "self", ".", "anneal_cap", "=", "anneal_cap", "\n", "self", ".", "annealing", "=", "annealing", "\n", "\n", "if", "self", ".", "annealing", ":", "\n", "            ", "self", ".", "beta", "=", "K", ".", "variable", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "beta", "\n", "\n", "# Compute total annealing steps", "\n", "", "self", ".", "total_anneal_steps", "=", "(", "\n", "self", ".", "number_of_batches", "\n", "*", "(", "self", ".", "n_epochs", "-", "int", "(", "self", ".", "n_epochs", "*", "0.2", ")", ")", "\n", "//", "self", ".", "anneal_cap", "\n", ")", "\n", "\n", "# Dropout parameters", "\n", "self", ".", "drop_encoder", "=", "drop_encoder", "\n", "self", ".", "drop_decoder", "=", "drop_decoder", "\n", "\n", "# Path to save optimal model", "\n", "self", ".", "save_path", "=", "save_path", "\n", "\n", "# Create StandardVAE model", "\n", "self", ".", "_create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._create_model": [[278, 325], ["Input", "Dense", "Dropout", "Dense", "multinomial_vae.Mult_VAE.h_decoder", "multinomial_vae.Mult_VAE.dropout_decoder", "multinomial_vae.Mult_VAE.x_bar", "tensorflow.keras.models.Model", "multinomial_vae.Mult_VAE.model.compile", "Lambda", "Dropout", "Dense", "Dense", "Dense", "Lambda", "tensorflow.compat.v1.keras.initializers.glorot_uniform", "tensorflow.compat.v1.keras.initializers.truncated_normal", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.backend.l2_normalize", "tensorflow.compat.v1.keras.initializers.glorot_uniform", "tensorflow.compat.v1.keras.initializers.truncated_normal"], "methods", ["None"], ["", "def", "_create_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build and compile model.\"\"\"", "\n", "# Encoding", "\n", "self", ".", "x", "=", "Input", "(", "shape", "=", "(", "self", ".", "original_dim", ",", ")", ")", "\n", "self", ".", "x_", "=", "Lambda", "(", "lambda", "x", ":", "K", ".", "l2_normalize", "(", "x", ",", "axis", "=", "1", ")", ")", "(", "self", ".", "x", ")", "\n", "self", ".", "dropout_encoder", "=", "Dropout", "(", "self", ".", "drop_encoder", ")", "(", "self", ".", "x_", ")", "\n", "\n", "self", ".", "h", "=", "Dense", "(", "\n", "self", ".", "intermediate_dim", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "kernel_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "glorot_uniform", "(", "\n", "seed", "=", "self", ".", "seed", "\n", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "truncated_normal", "(", "\n", "stddev", "=", "0.001", ",", "seed", "=", "self", ".", "seed", "\n", ")", ",", "\n", ")", "(", "self", ".", "dropout_encoder", ")", "\n", "self", ".", "z_mean", "=", "Dense", "(", "self", ".", "latent_dim", ")", "(", "self", ".", "h", ")", "\n", "self", ".", "z_log_var", "=", "Dense", "(", "self", ".", "latent_dim", ")", "(", "self", ".", "h", ")", "\n", "\n", "# Sampling", "\n", "self", ".", "z", "=", "Lambda", "(", "self", ".", "_take_sample", ",", "output_shape", "=", "(", "self", ".", "latent_dim", ",", ")", ")", "(", "\n", "[", "self", ".", "z_mean", ",", "self", ".", "z_log_var", "]", "\n", ")", "\n", "\n", "# Decoding", "\n", "self", ".", "h_decoder", "=", "Dense", "(", "\n", "self", ".", "intermediate_dim", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "kernel_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "glorot_uniform", "(", "\n", "seed", "=", "self", ".", "seed", "\n", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "initializers", ".", "truncated_normal", "(", "\n", "stddev", "=", "0.001", ",", "seed", "=", "self", ".", "seed", "\n", ")", ",", "\n", ")", "\n", "self", ".", "dropout_decoder", "=", "Dropout", "(", "self", ".", "drop_decoder", ")", "\n", "self", ".", "x_bar", "=", "Dense", "(", "self", ".", "original_dim", ")", "\n", "self", ".", "h_decoded", "=", "self", ".", "h_decoder", "(", "self", ".", "z", ")", "\n", "self", ".", "h_decoded_", "=", "self", ".", "dropout_decoder", "(", "self", ".", "h_decoded", ")", "\n", "self", ".", "x_decoded", "=", "self", ".", "x_bar", "(", "self", ".", "h_decoded_", ")", "\n", "\n", "# Training", "\n", "self", ".", "model", "=", "Model", "(", "self", ".", "x", ",", "self", ".", "x_decoded", ")", "\n", "self", ".", "model", ".", "compile", "(", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "0.001", ")", ",", "\n", "loss", "=", "self", ".", "_get_vae_loss", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._get_vae_loss": [[327, 347], ["tensorflow.nn.log_softmax", "tensorflow.keras.backend.print_tensor", "tensorflow.keras.backend.mean", "tensorflow.reduce_mean", "tensorflow.keras.backend.sum", "tensorflow.reduce_sum", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.square"], "methods", ["None"], ["", "def", "_get_vae_loss", "(", "self", ",", "x", ",", "x_bar", ")", ":", "\n", "        ", "\"\"\"Calculate negative ELBO (NELBO).\"\"\"", "\n", "log_softmax_var", "=", "tf", ".", "nn", ".", "log_softmax", "(", "x_bar", ")", "\n", "self", ".", "neg_ll", "=", "-", "tf", ".", "reduce_mean", "(", "\n", "input_tensor", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "log_softmax_var", "*", "x", ",", "axis", "=", "-", "1", ")", "\n", ")", "\n", "a", "=", "tf", ".", "keras", ".", "backend", ".", "print_tensor", "(", "self", ".", "neg_ll", ")", "# noqa: F841", "\n", "# calculate positive Kullback\u2013Leibler divergence  divergence term", "\n", "kl_loss", "=", "K", ".", "mean", "(", "\n", "0.5", "\n", "*", "K", ".", "sum", "(", "\n", "-", "1", "-", "self", ".", "z_log_var", "+", "K", ".", "square", "(", "self", ".", "z_mean", ")", "+", "K", ".", "exp", "(", "self", ".", "z_log_var", ")", ",", "\n", "axis", "=", "-", "1", ",", "\n", ")", "\n", ")", "\n", "\n", "# obtain negative ELBO", "\n", "neg_ELBO", "=", "self", ".", "neg_ll", "+", "self", ".", "beta", "*", "kl_loss", "\n", "\n", "return", "neg_ELBO", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE._take_sample": [[348, 366], ["tensorflow.keras.backend.random_normal", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.shape"], "methods", ["None"], ["", "def", "_take_sample", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Sample epsilon \u223c N (0,I) and compute z via reparametrization trick.\"\"\"", "\n", "\n", "\"\"\"Calculate latent vector using the reparametrization trick.\n           The idea is that sampling from N (_mean, _var) is s the same as sampling from _mean+ epsilon * _var\n           where epsilon \u223c N(0,I).\"\"\"", "\n", "# _mean and _log_var calculated in encoder", "\n", "_mean", ",", "_log_var", "=", "args", "\n", "\n", "# epsilon", "\n", "epsilon", "=", "K", ".", "random_normal", "(", "\n", "shape", "=", "(", "K", ".", "shape", "(", "_mean", ")", "[", "0", "]", ",", "self", ".", "latent_dim", ")", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "1.0", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n", "\n", "return", "_mean", "+", "K", ".", "exp", "(", "_log_var", "/", "2", ")", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.nn_batch_generator": [[367, 395], ["numpy.random.seed", "numpy.arange", "numpy.random.shuffle", "numpy.shape", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "nn_batch_generator", "(", "self", ",", "x_train", ")", ":", "\n", "        ", "\"\"\"Used for splitting dataset in batches.\n\n        Args:\n            x_train (numpy.ndarray): The click matrix for the train set, with float values.\n        \"\"\"", "\n", "# Shuffle the batch", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "shuffle_index", "=", "np", ".", "arange", "(", "np", ".", "shape", "(", "x_train", ")", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "shuffle_index", ")", "\n", "x", "=", "x_train", "[", "shuffle_index", ",", ":", "]", "\n", "y", "=", "x_train", "[", "shuffle_index", ",", ":", "]", "\n", "\n", "# Iterate until making a full epoch", "\n", "counter", "=", "0", "\n", "while", "1", ":", "\n", "            ", "index_batch", "=", "shuffle_index", "[", "\n", "self", ".", "batch_size", "*", "counter", ":", "self", ".", "batch_size", "*", "(", "counter", "+", "1", ")", "\n", "]", "\n", "# Decompress batch", "\n", "x_batch", "=", "x", "[", "index_batch", ",", ":", "]", "\n", "y_batch", "=", "y", "[", "index_batch", ",", ":", "]", "\n", "counter", "+=", "1", "\n", "yield", "(", "np", ".", "array", "(", "x_batch", ")", ",", "np", ".", "array", "(", "y_batch", ")", ")", "\n", "\n", "# Stopping rule", "\n", "if", "counter", ">=", "self", ".", "number_of_batches", ":", "\n", "                ", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.fit": [[396, 456], ["multinomial_vae.LossHistory", "multinomial_vae.Metrics", "tensorflow.keras.callbacks.ReduceLROnPlateau", "multinomial_vae.Metrics.get_data", "multinomial_vae.AnnealingCallback", "multinomial_vae.Mult_VAE.model.fit_generator", "multinomial_vae.AnnealingCallback.get_data", "multinomial_vae.Mult_VAE.model.fit_generator", "multinomial_vae.Mult_VAE.nn_batch_generator", "multinomial_vae.Mult_VAE.nn_batch_generator"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.AnnealingCallback.get_data", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.nn_batch_generator", "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.nn_batch_generator"], ["", "", "", "def", "fit", "(", "self", ",", "x_train", ",", "x_valid", ",", "x_val_tr", ",", "x_val_te", ",", "mapper", ")", ":", "\n", "        ", "\"\"\"Fit model with the train sets and validate on the validation set.\n\n        Args:\n            x_train (numpy.ndarray): the click matrix for the train set.\n            x_valid (numpy.ndarray): the click matrix for the validation set.\n            x_val_tr (numpy.ndarray): the click matrix for the validation set training part.\n            x_val_te (numpy.ndarray): the click matrix for the validation set testing part.\n            mapper (object): the mapper for converting click matrix to dataframe. It can be AffinityMatrix.\n        \"\"\"", "\n", "# initialise LossHistory used for saving loss of validation and train set per epoch", "\n", "history", "=", "LossHistory", "(", ")", "\n", "\n", "# initialise Metrics  used for calculating NDCG@k per epoch", "\n", "# and saving the model weights with the highest NDCG@k value", "\n", "metrics", "=", "Metrics", "(", "\n", "model", "=", "self", ".", "model", ",", "\n", "val_tr", "=", "x_val_tr", ",", "\n", "val_te", "=", "x_val_te", ",", "\n", "mapper", "=", "mapper", ",", "\n", "k", "=", "self", ".", "k", ",", "\n", "save_path", "=", "self", ".", "save_path", ",", "\n", ")", "\n", "\n", "self", ".", "reduce_lr", "=", "ReduceLROnPlateau", "(", "\n", "monitor", "=", "\"val_loss\"", ",", "factor", "=", "0.2", ",", "patience", "=", "1", ",", "min_lr", "=", "0.0001", "\n", ")", "\n", "\n", "if", "self", ".", "annealing", ":", "\n", "# initialise AnnealingCallback for annealing process", "\n", "            ", "anneal", "=", "AnnealingCallback", "(", "\n", "self", ".", "beta", ",", "self", ".", "anneal_cap", ",", "self", ".", "total_anneal_steps", "\n", ")", "\n", "\n", "# fit model", "\n", "self", ".", "model", ".", "fit_generator", "(", "\n", "generator", "=", "self", ".", "nn_batch_generator", "(", "x_train", ")", ",", "\n", "steps_per_epoch", "=", "self", ".", "number_of_batches", ",", "\n", "epochs", "=", "self", ".", "n_epochs", ",", "\n", "verbose", "=", "self", ".", "verbose", ",", "\n", "callbacks", "=", "[", "metrics", ",", "history", ",", "self", ".", "reduce_lr", ",", "anneal", "]", ",", "\n", "validation_data", "=", "(", "x_valid", ",", "x_valid", ")", ",", "\n", ")", "\n", "\n", "self", ".", "ls_beta", "=", "anneal", ".", "get_data", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "fit_generator", "(", "\n", "generator", "=", "self", ".", "nn_batch_generator", "(", "x_train", ")", ",", "\n", "steps_per_epoch", "=", "self", ".", "number_of_batches", ",", "\n", "epochs", "=", "self", ".", "n_epochs", ",", "\n", "verbose", "=", "self", ".", "verbose", ",", "\n", "callbacks", "=", "[", "metrics", ",", "history", ",", "self", ".", "reduce_lr", "]", ",", "\n", "validation_data", "=", "(", "x_valid", ",", "x_valid", ")", ",", "\n", ")", "\n", "\n", "# save lists", "\n", "", "self", ".", "train_loss", "=", "history", ".", "losses", "\n", "self", ".", "val_loss", "=", "history", ".", "val_losses", "\n", "self", ".", "val_ndcg", "=", "metrics", ".", "get_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.get_optimal_beta": [[457, 467], ["numpy.argmax"], "methods", ["None"], ["", "def", "get_optimal_beta", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the value of the optimal beta.\"\"\"", "\n", "if", "self", ".", "annealing", ":", "\n", "# find the epoch/index that had the highest NDCG@k value", "\n", "            ", "index_max_ndcg", "=", "np", ".", "argmax", "(", "self", ".", "val_ndcg", ")", "\n", "\n", "# using this index find the value that beta had at this epoch", "\n", "return", "self", ".", "ls_beta", "[", "index_max_ndcg", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.display_metrics": [[468, 497], ["matplotlib.figure", "seaborn.set", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.subplot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.suptitle", "matplotlib.tight_layout"], "methods", ["None"], ["", "", "def", "display_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Plots:\n        1) Loss per epoch both for validation and train set\n        2) NDCG@k per epoch of the validation set\n        \"\"\"", "\n", "# Plot setup", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "5", ")", ")", "\n", "sns", ".", "set", "(", "style", "=", "\"whitegrid\"", ")", "\n", "\n", "# Plot loss on the left graph", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "1", ")", "\n", "plt", ".", "plot", "(", "self", ".", "train_loss", ",", "color", "=", "\"b\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Train\"", ")", "\n", "plt", ".", "plot", "(", "self", ".", "val_loss", ",", "color", "=", "\"r\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Val\"", ")", "\n", "plt", ".", "title", "(", "\"\\n\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Epochs\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"Loss\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Plot NDCG on the right graph", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "2", ")", "\n", "plt", ".", "plot", "(", "self", ".", "val_ndcg", ",", "color", "=", "\"r\"", ",", "linestyle", "=", "\"-\"", ",", "label", "=", "\"Val\"", ")", "\n", "plt", ".", "title", "(", "\"\\n\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Epochs\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"NDCG@k\"", ",", "size", "=", "14", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Add title", "\n", "plt", ".", "suptitle", "(", "\"TRAINING AND VALIDATION METRICS HISTORY\"", ",", "size", "=", "16", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.recommend_k_items": [[498, 527], ["multinomial_vae.Mult_VAE.model.load_weights", "multinomial_vae.Mult_VAE.model.predict", "multinomial_vae.Mult_VAE.copy", "numpy.not_equal", "numpy.argpartition", "range", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "recommend_k_items", "(", "self", ",", "x", ",", "k", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the top-k items ordered by a relevancy score.\n        Obtained probabilities are used as recommendation score.\n\n        Args:\n            x (numpy.ndarray, int32): input click matrix.\n            k (scalar, int32): the number of items to recommend.\n        Returns:\n            numpy.ndarray, float: A sparse matrix containing the top_k elements ordered by their score.\n        \"\"\"", "\n", "# return optimal model", "\n", "self", ".", "model", ".", "load_weights", "(", "self", ".", "save_path", ")", "\n", "\n", "# obtain scores", "\n", "score", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "\n", "if", "remove_seen", ":", "\n", "# if true, it removes items from the train set by setting them to zero", "\n", "            ", "seen_mask", "=", "np", ".", "not_equal", "(", "x", ",", "0", ")", "\n", "score", "[", "seen_mask", "]", "=", "0", "\n", "# get the top k items", "\n", "", "top_items", "=", "np", ".", "argpartition", "(", "-", "score", ",", "range", "(", "k", ")", ",", "axis", "=", "1", ")", "[", ":", ",", ":", "k", "]", "\n", "# get a copy of the score matrix", "\n", "score_c", "=", "score", ".", "copy", "(", ")", "\n", "# set to zero the k elements", "\n", "score_c", "[", "np", ".", "arange", "(", "score_c", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ",", "top_items", "]", "=", "0", "\n", "# set to zeros all elements other then the k", "\n", "top_scores", "=", "score", "-", "score_c", "\n", "return", "top_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.vae.multinomial_vae.Mult_VAE.ndcg_per_epoch": [[528, 531], ["None"], "methods", ["None"], ["", "def", "ndcg_per_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of NDCG@k at each epoch.\"\"\"", "\n", "return", "self", ".", "val_ndcg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.__init__": [[29, 55], ["pymanopt.solvers.solver.Solver.__init__", "pymanopt.solvers.linesearch.LineSearchAdaptive"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "beta_type", "=", "BetaTypes", ".", "HestenesStiefel", ",", "\n", "orth_value", "=", "np", ".", "inf", ",", "\n", "linesearch", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Instantiate gradient solver class.\n\n        Args:\n            beta_type (object): Conjugate gradient beta rule used to construct the new search direction.\n            orth_value (float): Parameter for Powell's restart strategy. An infinite value disables this strategy.\n                See in code formula for the specific criterion used.\n            - linesearch (object): The linesearch method to used.\n        \"\"\"", "\n", "super", "(", "ConjugateGradientMS", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_beta_type", "=", "beta_type", "\n", "self", ".", "_orth_value", "=", "orth_value", "\n", "\n", "if", "linesearch", "is", "None", ":", "\n", "            ", "self", ".", "_linesearch", "=", "LineSearchAdaptive", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_linesearch", "=", "linesearch", "# LineSearchBackTracking()", "\n", "", "self", ".", "linesearch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve": [[56, 256], ["time.time", "time.time", "objective", "gradient", "man.norm", "problem.precon", "man.inner", "conjugate_gradient_ms.ConjugateGradientMS._start_optlog", "copy.deepcopy", "print", "print", "man.rand", "time.time", "time.time", "conjugate_gradient_ms.ConjugateGradientMS._check_stopping_criterion", "man.inner", "linesearch.search", "objective", "gradient", "man.norm", "problem.precon", "man.inner", "man.transp", "conjugate_gradient_ms.ConjugateGradientMS._stop_optlog", "print", "compute_stats", "conjugate_gradient_ms.ConjugateGradientMS._append_optlog", "man.inner", "abs", "man.transp", "time.time", "time.time", "print", "print", "print", "man.inner", "max", "man.inner", "max", "man.transp", "man.inner", "man.inner", "man.norm", "max", "ValueError", "man.inner", "man.inner", "min", "man.inner"], "methods", ["None"], ["", "def", "solve", "(", "self", ",", "problem", ",", "x", "=", "None", ",", "reuselinesearch", "=", "False", ",", "compute_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"Perform optimization using nonlinear conjugate gradient method with\n        linesearch.\n\n        This method first computes the gradient of obj w.r.t. arg, and then\n        optimizes by moving in a direction that is conjugate to all previous\n        search directions.\n\n        Args:\n            problem (object): Pymanopt problem setup using the Problem class, this must\n                have a .manifold attribute specifying the manifold to optimize\n                over, as well as a cost and enough information to compute\n                the gradient of that cost.\n            x (numpy.ndarray): Optional parameter. Starting point on the manifold. If none\n                then a starting point will be randomly generated.\n            reuselinesearch (bool): Whether to reuse the previous linesearch object. Allows to\n                use information from a previous solve run.\n\n        Returns:\n            numpy.ndarray: Local minimum of obj, or if algorithm terminated before convergence x will be the point at which it terminated.\n        \"\"\"", "\n", "man", "=", "problem", ".", "manifold", "\n", "verbosity", "=", "problem", ".", "verbosity", "\n", "objective", "=", "problem", ".", "cost", "\n", "gradient", "=", "problem", ".", "grad", "\n", "\n", "if", "not", "reuselinesearch", "or", "self", ".", "linesearch", "is", "None", ":", "\n", "            ", "self", ".", "linesearch", "=", "deepcopy", "(", "self", ".", "_linesearch", ")", "\n", "", "linesearch", "=", "self", ".", "linesearch", "\n", "\n", "if", "verbosity", ">=", "1", ":", "\n", "            ", "print", "(", "\"Optimizing...\"", ")", "\n", "", "if", "verbosity", ">=", "2", ":", "\n", "            ", "print", "(", "\" iter\\t\\t   cost val\\t    grad. norm\"", ")", "\n", "\n", "# Initialize iteration counter and timer", "\n", "", "iter", "=", "0", "\n", "stats", "=", "{", "}", "\n", "# stats = {'iteration': [],'time': [],'objective': [],'trainRMSE': [],'testRMSE': []}", "\n", "stepsize", "=", "np", ".", "nan", "\n", "cumulative_time", "=", "0.0", "\n", "\n", "time0", "=", "time", ".", "time", "(", ")", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "\n", "# If no starting point is specified, generate one at random.", "\n", "if", "x", "is", "None", ":", "\n", "            ", "x", "=", "man", ".", "rand", "(", ")", "\n", "\n", "# Calculate initial cost-related quantities", "\n", "", "cost", "=", "objective", "(", "x", ")", "\n", "grad", "=", "gradient", "(", "x", ")", "\n", "gradnorm", "=", "man", ".", "norm", "(", "x", ",", "grad", ")", "\n", "Pgrad", "=", "problem", ".", "precon", "(", "x", ",", "grad", ")", "\n", "gradPgrad", "=", "man", ".", "inner", "(", "x", ",", "grad", ",", "Pgrad", ")", "\n", "\n", "# Initial descent direction is the negative gradient", "\n", "desc_dir", "=", "-", "Pgrad", "\n", "time_iter", "=", "time", ".", "time", "(", ")", "-", "t0", "\n", "cumulative_time", "+=", "time_iter", "\n", "\n", "self", ".", "_start_optlog", "(", "\n", "extraiterfields", "=", "[", "\"gradnorm\"", "]", ",", "\n", "solverparams", "=", "{", "\n", "\"beta_type\"", ":", "self", ".", "_beta_type", ",", "\n", "\"orth_value\"", ":", "self", ".", "_orth_value", ",", "\n", "\"linesearcher\"", ":", "linesearch", ",", "\n", "}", ",", "\n", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "if", "verbosity", ">=", "2", ":", "\n", "                ", "print", "(", "\"%5d\\t%+.16e\\t%.8e\"", "%", "(", "iter", ",", "cost", ",", "gradnorm", ")", ")", "\n", "", "if", "compute_stats", "is", "not", "None", ":", "\n", "                ", "compute_stats", "(", "x", ",", "[", "iter", ",", "cost", ",", "gradnorm", ",", "cumulative_time", "]", ",", "stats", ")", "\n", "\n", "", "if", "self", ".", "_logverbosity", ">=", "2", ":", "\n", "                ", "self", ".", "_append_optlog", "(", "iter", ",", "x", ",", "cost", ",", "gradnorm", "=", "gradnorm", ")", "\n", "\n", "", "t0", "=", "time", ".", "time", "(", ")", "\n", "# stop_reason = self._check_stopping_criterion(", "\n", "#    time0, gradnorm=gradnorm, iter=iter + 1, stepsize=stepsize)", "\n", "stop_reason", "=", "self", ".", "_check_stopping_criterion", "(", "\n", "time", ".", "time", "(", ")", "-", "cumulative_time", ",", "\n", "gradnorm", "=", "gradnorm", ",", "\n", "iter", "=", "iter", "+", "1", ",", "\n", "stepsize", "=", "stepsize", ",", "\n", ")", "\n", "\n", "if", "stop_reason", ":", "\n", "                ", "if", "verbosity", ">=", "1", ":", "\n", "                    ", "print", "(", "stop_reason", ")", "\n", "print", "(", "\"\"", ")", "\n", "", "break", "\n", "\n", "# The line search algorithms require the directional derivative of", "\n", "# the cost at the current point x along the search direction.", "\n", "", "df0", "=", "man", ".", "inner", "(", "x", ",", "grad", ",", "desc_dir", ")", "\n", "\n", "# If we didn't get a descent direction: restart, i.e., switch to", "\n", "# the negative gradient. Equivalent to resetting the CG direction", "\n", "# to a steepest descent step, which discards the past information.", "\n", "if", "df0", ">=", "0", ":", "\n", "# Or we switch to the negative gradient direction.", "\n", "                ", "if", "verbosity", ">=", "3", ":", "\n", "                    ", "print", "(", "\n", "\"Conjugate gradient info: got an ascent direction \"", "\n", "\"(df0 = %.2f), reset to the (preconditioned) \"", "\n", "\"steepest descent direction.\"", "%", "df0", "\n", ")", "\n", "# Reset to negative gradient: this discards the CG memory.", "\n", "", "desc_dir", "=", "-", "Pgrad", "\n", "df0", "=", "-", "gradPgrad", "\n", "\n", "# Execute line search", "\n", "", "stepsize", ",", "newx", "=", "linesearch", ".", "search", "(", "objective", ",", "man", ",", "x", ",", "desc_dir", ",", "cost", ",", "df0", ")", "\n", "\n", "# Compute the new cost-related quantities for newx", "\n", "newcost", "=", "objective", "(", "newx", ")", "\n", "newgrad", "=", "gradient", "(", "newx", ")", "\n", "newgradnorm", "=", "man", ".", "norm", "(", "newx", ",", "newgrad", ")", "\n", "Pnewgrad", "=", "problem", ".", "precon", "(", "newx", ",", "newgrad", ")", "\n", "newgradPnewgrad", "=", "man", ".", "inner", "(", "newx", ",", "newgrad", ",", "Pnewgrad", ")", "\n", "\n", "# Apply the CG scheme to compute the next search direction", "\n", "oldgrad", "=", "man", ".", "transp", "(", "x", ",", "newx", ",", "grad", ")", "\n", "orth_grads", "=", "man", ".", "inner", "(", "newx", ",", "oldgrad", ",", "Pnewgrad", ")", "/", "newgradPnewgrad", "\n", "\n", "# Powell's restart strategy (see page 12 of Hager and Zhang's", "\n", "# survey on conjugate gradient methods, for example)", "\n", "if", "abs", "(", "orth_grads", ")", ">=", "self", ".", "_orth_value", ":", "\n", "                ", "beta", "=", "0", "\n", "desc_dir", "=", "-", "Pnewgrad", "\n", "", "else", ":", "\n", "                ", "desc_dir", "=", "man", ".", "transp", "(", "x", ",", "newx", ",", "desc_dir", ")", "\n", "\n", "if", "self", ".", "_beta_type", "==", "BetaTypes", ".", "FletcherReeves", ":", "\n", "                    ", "beta", "=", "newgradPnewgrad", "/", "gradPgrad", "\n", "", "elif", "self", ".", "_beta_type", "==", "BetaTypes", ".", "PolakRibiere", ":", "\n", "                    ", "diff", "=", "newgrad", "-", "oldgrad", "\n", "ip_diff", "=", "man", ".", "inner", "(", "newx", ",", "Pnewgrad", ",", "diff", ")", "\n", "beta", "=", "max", "(", "0", ",", "ip_diff", "/", "gradPgrad", ")", "\n", "", "elif", "self", ".", "_beta_type", "==", "BetaTypes", ".", "HestenesStiefel", ":", "\n", "                    ", "diff", "=", "newgrad", "-", "oldgrad", "\n", "ip_diff", "=", "man", ".", "inner", "(", "newx", ",", "Pnewgrad", ",", "diff", ")", "\n", "try", ":", "\n", "                        ", "beta", "=", "max", "(", "0", ",", "ip_diff", "/", "man", ".", "inner", "(", "newx", ",", "diff", ",", "desc_dir", ")", ")", "\n", "# if ip_diff = man.inner(newx, diff, desc_dir) = 0", "\n", "", "except", "ZeroDivisionError", ":", "\n", "                        ", "beta", "=", "1", "\n", "", "", "elif", "self", ".", "_beta_type", "==", "BetaTypes", ".", "HagerZhang", ":", "\n", "                    ", "diff", "=", "newgrad", "-", "oldgrad", "\n", "Poldgrad", "=", "man", ".", "transp", "(", "x", ",", "newx", ",", "Pgrad", ")", "\n", "Pdiff", "=", "Pnewgrad", "-", "Poldgrad", "\n", "deno", "=", "man", ".", "inner", "(", "newx", ",", "diff", ",", "desc_dir", ")", "\n", "numo", "=", "man", ".", "inner", "(", "newx", ",", "diff", ",", "Pnewgrad", ")", "\n", "numo", "-=", "(", "\n", "2", "\n", "*", "man", ".", "inner", "(", "newx", ",", "diff", ",", "Pdiff", ")", "\n", "*", "man", ".", "inner", "(", "newx", ",", "desc_dir", ",", "newgrad", ")", "\n", "/", "deno", "\n", ")", "\n", "beta", "=", "numo", "/", "deno", "\n", "# Robustness (see Hager-Zhang paper mentioned above)", "\n", "desc_dir_norm", "=", "man", ".", "norm", "(", "newx", ",", "desc_dir", ")", "\n", "eta_HZ", "=", "-", "1", "/", "(", "desc_dir_norm", "*", "min", "(", "0.01", ",", "gradnorm", ")", ")", "\n", "beta", "=", "max", "(", "beta", ",", "eta_HZ", ")", "\n", "", "else", ":", "\n", "                    ", "types", "=", "\", \"", ".", "join", "(", "[", "\"BetaTypes.%s\"", "%", "t", "for", "t", "in", "BetaTypes", ".", "_fields", "]", ")", "\n", "raise", "ValueError", "(", "\n", "\"Unknown beta_type %s. Should be one of %s.\"", "\n", "%", "(", "self", ".", "_beta_type", ",", "types", ")", "\n", ")", "\n", "\n", "", "desc_dir", "=", "-", "Pnewgrad", "+", "beta", "*", "desc_dir", "\n", "\n", "# Update the necessary variables for the next iteration.", "\n", "", "x", "=", "newx", "\n", "cost", "=", "newcost", "\n", "grad", "=", "newgrad", "\n", "Pgrad", "=", "Pnewgrad", "\n", "gradnorm", "=", "newgradnorm", "\n", "gradPgrad", "=", "newgradPnewgrad", "\n", "iter", "+=", "1", "\n", "time_iter", "=", "time", ".", "time", "(", ")", "-", "t0", "\n", "cumulative_time", "+=", "time_iter", "\n", "\n", "", "if", "self", ".", "_logverbosity", "<=", "0", ":", "\n", "            ", "return", "x", ",", "stats", "\n", "", "else", ":", "\n", "            ", "self", ".", "_stop_optlog", "(", "\n", "x", ",", "\n", "cost", ",", "\n", "stop_reason", ",", "\n", "time0", ",", "\n", "stepsize", "=", "stepsize", ",", "\n", "gradnorm", "=", "gradnorm", ",", "\n", "iter", "=", "iter", ",", "\n", ")", "\n", "return", "x", ",", "stats", ",", "self", ".", "_optlog", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm.__init__": [[23, 52], ["model_param.get"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rank", ",", "\n", "C", ",", "\n", "model_param", ",", "\n", "initialize_flag", "=", "\"random\"", ",", "\n", "max_time", "=", "1000", ",", "\n", "maxiter", "=", "100", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            rank (int): rank of the final model. Should be a positive integer.\n            C (float): regularization parameter. Should be a positive real number.\n            model_param (dict): contains model parameters such as number of rows & columns of the matrix as well as\n                the mean rating in the training dataset.\n            initialize_flag (str): flag to set the initialization step of the algorithm. Current options are 'random'\n                (which is random initilization) and 'svd' (which is a singular value decomposition based initilization).\n            max_time (int): maximum time (in seconds), for which the algorithm is allowed to execute.\n            maxiter (int): maximum number of iterations, for which the algorithm is allowed to execute.\n        \"\"\"", "\n", "self", ".", "model_param", "=", "model_param", "\n", "self", ".", "train_mean", "=", "model_param", ".", "get", "(", "\"train_mean\"", ")", "\n", "self", ".", "initialize_flag", "=", "initialize_flag", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "C", "=", "C", "\n", "self", ".", "max_time", "=", "max_time", "\n", "self", ".", "maxiter", "=", "maxiter", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._init_train": [[53, 68], ["logger.info", "logger.info", "scipy.sparse.linalg.svds", "logger.warning", "numpy.diag"], "methods", ["None"], ["", "def", "_init_train", "(", "self", ",", "entries_train_csr", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Hyper-parameters of the algorithm\"", ")", "\n", "logger", ".", "info", "(", "\"Rank: %i, Regularization parameter: %e\"", "%", "(", "self", ".", "rank", ",", "self", ".", "C", ")", ")", "\n", "# Initialization # starting point on the manifold", "\n", "if", "self", ".", "initialize_flag", "==", "\"random\"", ":", "# rndom", "\n", "            ", "W0", "=", "None", "\n", "", "elif", "self", ".", "initialize_flag", "==", "\"svd\"", ":", "# svd", "\n", "            ", "U0", ",", "B0", ",", "V0", "=", "svds", "(", "entries_train_csr", ",", "k", "=", "self", ".", "rank", ")", "\n", "W0", "=", "[", "U0", ",", "V0", ".", "T", ",", "np", ".", "diag", "(", "B0", ")", "]", "\n", "", "else", ":", "# default option when given incorrect option", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Initialization flag not recognized. Setting it to random (default).\"", "\n", ")", "\n", "W0", "=", "None", "\n", "", "return", "W0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm.fit_and_evaluate": [[69, 79], ["RLRMCalgorithm.RLRMCalgorithm.fit"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "fit_and_evaluate", "(", "self", ",", "RLRMCdata", ",", "verbosity", "=", "0", ")", ":", "\n", "        ", "\"\"\"Main fit and evalute method for RLRMC. In addition to fitting the model, it also computes the per\n        iteration statistics in train (and validation) datasets.\n\n        Args:\n            RLRMCdata (RLRMCdataset): the RLRMCdataset object.\n            verbosity (int): verbosity of Pymanopt. Possible values are 0 (least verbose), 1, or 2 (most verbose).\n        \"\"\"", "\n", "# it calls fit method with appropriate arguments", "\n", "self", ".", "fit", "(", "RLRMCdata", ",", "verbosity", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm.fit": [[80, 152], ["RLRMCalgorithm.RLRMCalgorithm._init_train", "numpy.zeros", "recommenders.models.rlrmc.conjugate_gradient_ms.ConjugateGradientMS", "pymanopt.manifolds.Product", "pymanopt.Problem", "numpy.dot", "numpy.zeros", "recommenders.models.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "recommenders.models.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "pymanopt.solvers.linesearch.LineSearchBackTracking", "pymanopt.manifolds.Stiefel", "pymanopt.manifolds.Stiefel", "pymanopt.manifolds.SymmetricPositiveDefinite", "RLRMCalgorithm.RLRMCalgorithm.model_param.get", "RLRMCalgorithm.RLRMCalgorithm.model_param.get", "RLRMCalgorithm.RLRMCalgorithm._cost", "RLRMCalgorithm.RLRMCalgorithm._egrad", "RLRMCalgorithm.RLRMCalgorithm._my_stats"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._init_train", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.conjugate_gradient_ms.ConjugateGradientMS.solve", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._cost", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._egrad", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._my_stats"], ["", "def", "fit", "(", "self", ",", "RLRMCdata", ",", "verbosity", "=", "0", ",", "_evaluate", "=", "False", ")", ":", "\n", "        ", "\"\"\"The underlying fit method for RLRMC\n\n        Args:\n            RLRMCdata (RLRMCdataset): the RLRMCdataset object.\n            verbosity (int): verbosity of Pymanopt. Possible values are 0 (least verbose), 1, or 2 (most verbose).\n            _evaluate (bool): flag to compute the per iteration statistics in train (and validation) datasets.\n        \"\"\"", "\n", "# initialize the model", "\n", "W0", "=", "self", ".", "_init_train", "(", "RLRMCdata", ".", "train", ")", "\n", "self", ".", "user2id", "=", "RLRMCdata", ".", "user2id", "\n", "self", ".", "item2id", "=", "RLRMCdata", ".", "item2id", "\n", "self", ".", "id2user", "=", "RLRMCdata", ".", "id2user", "\n", "self", ".", "id2item", "=", "RLRMCdata", ".", "id2item", "\n", "\n", "# residual variable", "\n", "residual_global", "=", "np", ".", "zeros", "(", "RLRMCdata", ".", "train", ".", "data", ".", "shape", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "####################################", "\n", "# Riemannian first-order algorithm #", "\n", "####################################", "\n", "\n", "solver", "=", "ConjugateGradientMS", "(", "\n", "maxtime", "=", "self", ".", "max_time", ",", "\n", "maxiter", "=", "self", ".", "maxiter", ",", "\n", "linesearch", "=", "LineSearchBackTracking", "(", ")", ",", "\n", ")", "# , logverbosity=2)", "\n", "# construction of manifold", "\n", "manifold", "=", "Product", "(", "\n", "[", "\n", "Stiefel", "(", "self", ".", "model_param", ".", "get", "(", "\"num_row\"", ")", ",", "self", ".", "rank", ")", ",", "\n", "Stiefel", "(", "self", ".", "model_param", ".", "get", "(", "\"num_col\"", ")", ",", "self", ".", "rank", ")", ",", "\n", "SymmetricPositiveDefinite", "(", "self", ".", "rank", ")", ",", "\n", "]", "\n", ")", "\n", "problem", "=", "Problem", "(", "\n", "manifold", "=", "manifold", ",", "\n", "cost", "=", "lambda", "x", ":", "self", ".", "_cost", "(", "\n", "x", ",", "\n", "RLRMCdata", ".", "train", ".", "data", ",", "\n", "RLRMCdata", ".", "train", ".", "indices", ",", "\n", "RLRMCdata", ".", "train", ".", "indptr", ",", "\n", "residual_global", ",", "\n", ")", ",", "\n", "egrad", "=", "lambda", "z", ":", "self", ".", "_egrad", "(", "\n", "z", ",", "RLRMCdata", ".", "train", ".", "indices", ",", "RLRMCdata", ".", "train", ".", "indptr", ",", "residual_global", "\n", ")", ",", "\n", "verbosity", "=", "verbosity", ",", "\n", ")", "\n", "\n", "if", "_evaluate", ":", "\n", "            ", "residual_validation_global", "=", "np", ".", "zeros", "(", "\n", "RLRMCdata", ".", "validation", ".", "data", ".", "shape", ",", "dtype", "=", "np", ".", "float64", "\n", ")", "\n", "Wopt", ",", "self", ".", "stats", "=", "solver", ".", "solve", "(", "\n", "problem", ",", "\n", "x", "=", "W0", ",", "\n", "compute_stats", "=", "lambda", "x", ",", "y", ",", "z", ":", "self", ".", "_my_stats", "(", "\n", "x", ",", "\n", "y", ",", "\n", "z", ",", "\n", "residual_global", ",", "\n", "RLRMCdata", ".", "validation", ".", "data", ",", "\n", "RLRMCdata", ".", "validation", ".", "indices", ",", "\n", "RLRMCdata", ".", "validation", ".", "indptr", ",", "\n", "residual_validation_global", ",", "\n", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "Wopt", ",", "self", ".", "stats", "=", "solver", ".", "solve", "(", "problem", ",", "x", "=", "W0", ")", "\n", "", "self", ".", "L", "=", "np", ".", "dot", "(", "Wopt", "[", "0", "]", ",", "Wopt", "[", "2", "]", ")", "\n", "self", ".", "R", "=", "Wopt", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._computeLoss_csrmatrix": [[153, 166], ["numba.njit", "numba.prange", "numba.prange", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "njit", "(", "nogil", "=", "True", ",", "parallel", "=", "True", ")", "\n", "def", "_computeLoss_csrmatrix", "(", "a", ",", "b", ",", "cd", ",", "indices", ",", "indptr", ",", "residual_global", ")", ":", "\n", "        ", "\"\"\"computes residual_global = a*b - cd at given indices in csr_matrix format\"\"\"", "\n", "N", "=", "a", ".", "shape", "[", "0", "]", "\n", "M", "=", "a", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "prange", "(", "N", ")", ":", "\n", "            ", "for", "j", "in", "prange", "(", "indptr", "[", "i", "]", ",", "indptr", "[", "i", "+", "1", "]", ")", ":", "\n", "                ", "num", "=", "0.0", "\n", "for", "k", "in", "range", "(", "M", ")", ":", "\n", "                    ", "num", "+=", "a", "[", "i", ",", "k", "]", "*", "b", "[", "k", ",", "indices", "[", "j", "]", "]", "\n", "", "residual_global", "[", "j", "]", "=", "num", "-", "cd", "[", "j", "]", "\n", "", "", "return", "residual_global", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._my_stats": [[168, 214], ["stats.setdefault().append", "stats.setdefault().append", "stats.setdefault().append", "stats.setdefault().append", "numpy.dot", "numpy.mean", "math.sqrt", "stats.setdefault().append", "RLRMCalgorithm._computeLoss_csrmatrix", "numpy.mean", "math.sqrt", "stats.setdefault().append", "logger.info", "logger.info", "stats.setdefault", "stats.setdefault", "stats.setdefault", "stats.setdefault", "stats.setdefault", "stats.setdefault"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._computeLoss_csrmatrix"], ["", "def", "_my_stats", "(", "\n", "self", ",", "\n", "weights", ",", "\n", "given_stats", ",", "\n", "stats", ",", "\n", "residual_global", ",", "\n", "entries_validation_csr_data", "=", "None", ",", "\n", "entries_validation_csr_indices", "=", "None", ",", "\n", "entries_validation_csr_indptr", "=", "None", ",", "\n", "residual_validation_global", "=", "None", ",", "\n", ")", ":", "\n", "        ", "iteration", "=", "given_stats", "[", "0", "]", "\n", "cost", "=", "given_stats", "[", "1", "]", "\n", "gradnorm", "=", "given_stats", "[", "2", "]", "\n", "time_iter", "=", "given_stats", "[", "3", "]", "\n", "stats", ".", "setdefault", "(", "\"iteration\"", ",", "[", "]", ")", ".", "append", "(", "iteration", ")", "\n", "stats", ".", "setdefault", "(", "\"time\"", ",", "[", "]", ")", ".", "append", "(", "time_iter", ")", "\n", "stats", ".", "setdefault", "(", "\"objective\"", ",", "[", "]", ")", ".", "append", "(", "cost", ")", "\n", "stats", ".", "setdefault", "(", "\"gradnorm\"", ",", "[", "]", ")", ".", "append", "(", "gradnorm", ")", "\n", "U1", "=", "weights", "[", "0", "]", "\n", "U2", "=", "weights", "[", "1", "]", "\n", "B", "=", "weights", "[", "2", "]", "\n", "U1_dot_B", "=", "np", ".", "dot", "(", "U1", ",", "B", ")", "\n", "train_mse", "=", "np", ".", "mean", "(", "residual_global", "**", "2", ")", "\n", "train_rmse", "=", "sqrt", "(", "train_mse", ")", "\n", "stats", ".", "setdefault", "(", "\"trainRMSE\"", ",", "[", "]", ")", ".", "append", "(", "train_rmse", ")", "\n", "# Prediction", "\n", "if", "entries_validation_csr_data", "is", "not", "None", ":", "\n", "            ", "RLRMCalgorithm", ".", "_computeLoss_csrmatrix", "(", "\n", "U1_dot_B", ",", "\n", "U2", ".", "T", ",", "\n", "entries_validation_csr_data", ",", "\n", "entries_validation_csr_indices", ",", "\n", "entries_validation_csr_indptr", ",", "\n", "residual_validation_global", ",", "\n", ")", "\n", "validation_mse", "=", "np", ".", "mean", "(", "residual_validation_global", "**", "2", ")", "\n", "validation_rmse", "=", "sqrt", "(", "validation_mse", ")", "\n", "stats", ".", "setdefault", "(", "\"validationRMSE\"", ",", "[", "]", ")", ".", "append", "(", "validation_rmse", ")", "\n", "logger", ".", "info", "(", "\n", "\"Train RMSE: %.4f, Validation RMSE: %.4f, Total time: %.2f\"", "\n", "%", "(", "train_rmse", ",", "validation_rmse", ",", "time_iter", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Train RMSE: %.4f, Total time: %.2f\"", "%", "(", "train_rmse", ",", "time_iter", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._cost": [[216, 238], ["numpy.dot", "RLRMCalgorithm._computeLoss_csrmatrix", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._computeLoss_csrmatrix"], ["", "def", "_cost", "(", "\n", "self", ",", "\n", "weights", ",", "\n", "entries_train_csr_data", ",", "\n", "entries_train_csr_indices", ",", "\n", "entries_train_csr_indptr", ",", "\n", "residual_global", ",", "\n", ")", ":", "\n", "        ", "U1", "=", "weights", "[", "0", "]", "\n", "U2", "=", "weights", "[", "1", "]", "\n", "B", "=", "weights", "[", "2", "]", "\n", "U1_dot_B", "=", "np", ".", "dot", "(", "U1", ",", "B", ")", "\n", "RLRMCalgorithm", ".", "_computeLoss_csrmatrix", "(", "\n", "U1_dot_B", ",", "\n", "U2", ".", "T", ",", "\n", "entries_train_csr_data", ",", "\n", "entries_train_csr_indices", ",", "\n", "entries_train_csr_indptr", ",", "\n", "residual_global", ",", "\n", ")", "\n", "objective", "=", "0.5", "*", "np", ".", "sum", "(", "(", "residual_global", ")", "**", "2", ")", "+", "0.5", "*", "self", ".", "C", "*", "np", ".", "sum", "(", "B", "**", "2", ")", "\n", "return", "objective", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._egrad": [[240, 261], ["numpy.dot", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix.dot", "numpy.dot", "scipy.sparse.csr_matrix.T.dot", "numpy.dot"], "methods", ["None"], ["", "def", "_egrad", "(", "\n", "self", ",", "\n", "weights", ",", "\n", "entries_train_csr_indices", ",", "\n", "entries_train_csr_indptr", ",", "\n", "residual_global", ",", "\n", ")", ":", "\n", "        ", "U1", "=", "weights", "[", "0", "]", "\n", "U2", "=", "weights", "[", "1", "]", "\n", "B", "=", "weights", "[", "2", "]", "\n", "U1_dot_B", "=", "np", ".", "dot", "(", "U1", ",", "B", ")", "\n", "residual_global_csr", "=", "csr_matrix", "(", "\n", "(", "residual_global", ",", "entries_train_csr_indices", ",", "entries_train_csr_indptr", ")", ",", "\n", "shape", "=", "(", "U1", ".", "shape", "[", "0", "]", ",", "U2", ".", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "residual_global_csr_dot_U2", "=", "residual_global_csr", ".", "dot", "(", "U2", ")", "\n", "gradU1", "=", "np", ".", "dot", "(", "residual_global_csr_dot_U2", ",", "B", ")", "\n", "gradB_asymm", "=", "np", ".", "dot", "(", "U1", ".", "T", ",", "residual_global_csr_dot_U2", ")", "+", "self", ".", "C", "*", "B", "\n", "gradB", "=", "(", "gradB_asymm", "+", "gradB_asymm", ".", "T", ")", "/", "2.0", "\n", "gradU2", "=", "residual_global_csr", ".", "T", ".", "dot", "(", "U1_dot_B", ")", "\n", "return", "[", "gradU1", ",", "gradU2", ",", "gradB", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm.predict": [[262, 302], ["numpy.array", "numpy.array", "numpy.empty", "numpy.empty.fill", "print", "numpy.arange", "RLRMCalgorithm.RLRMCalgorithm.model_param.get", "RLRMCalgorithm.RLRMCalgorithm.model_param.get", "scipy.sparse.csr_matrix", "RLRMCalgorithm._computeLoss_csrmatrix", "numpy.ravel_multi_index", "numpy.argsort", "numpy.argsort", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCalgorithm.RLRMCalgorithm._computeLoss_csrmatrix"], ["", "def", "predict", "(", "self", ",", "user_input", ",", "item_input", ",", "low_memory", "=", "False", ")", ":", "\n", "        ", "\"\"\"Predict function of this trained model\n\n        Args:\n            user_input ( list or element of list ): userID or userID list\n            item_input ( list or element of list ): itemID or itemID list\n\n        Returns:\n            list or float: list of predicted rating or predicted rating score.\n        \"\"\"", "\n", "# index converting", "\n", "user_input", "=", "np", ".", "array", "(", "[", "self", ".", "user2id", "[", "x", "]", "for", "x", "in", "user_input", "]", ")", "# rows", "\n", "item_input", "=", "np", ".", "array", "(", "[", "self", ".", "item2id", "[", "x", "]", "for", "x", "in", "item_input", "]", ")", "# columns", "\n", "num_test", "=", "user_input", ".", "shape", "[", "0", "]", "\n", "if", "num_test", "!=", "item_input", ".", "shape", "[", "0", "]", ":", "\n", "            ", "print", "(", "\"ERROR! Dimension mismatch in test data.\"", ")", "\n", "return", "None", "\n", "", "output", "=", "np", ".", "empty", "(", "item_input", ".", "shape", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "output", ".", "fill", "(", "-", "self", ".", "train_mean", ")", "\n", "L", "=", "self", ".", "L", "\n", "R", "=", "self", ".", "R", "\n", "if", "low_memory", ":", "\n", "# for-loop", "\n", "            ", "for", "i", "in", "np", ".", "arange", "(", "num_test", ")", ":", "\n", "                ", "output", "[", "i", "]", "+=", "np", ".", "dot", "(", "L", "[", "user_input", "[", "i", "]", ",", ":", "]", ",", "R", "[", "item_input", "[", "i", "]", ",", ":", "]", ")", "\n", "", "", "else", ":", "\n", "# matrix multiplication", "\n", "            ", "d", "=", "self", ".", "model_param", ".", "get", "(", "\"num_row\"", ")", "\n", "T", "=", "self", ".", "model_param", ".", "get", "(", "\"num_col\"", ")", "\n", "test", "=", "csr_matrix", "(", "(", "output", ",", "(", "user_input", ",", "item_input", ")", ")", ",", "shape", "=", "(", "d", ",", "T", ")", ")", "\n", "RLRMCalgorithm", ".", "_computeLoss_csrmatrix", "(", "\n", "L", ",", "R", ".", "T", ",", "test", ".", "data", ",", "test", ".", "indices", ",", "test", ".", "indptr", ",", "output", "\n", ")", "\n", "lin_index_org", "=", "np", ".", "ravel_multi_index", "(", "\n", "(", "user_input", ",", "item_input", ")", ",", "dims", "=", "(", "d", ",", "T", ")", ",", "mode", "=", "\"raise\"", ",", "order", "=", "\"C\"", "\n", ")", "\n", "idx1", "=", "np", ".", "argsort", "(", "lin_index_org", ")", "\n", "idx2", "=", "np", ".", "argsort", "(", "idx1", ")", "\n", "output", "=", "output", "[", "idx2", "]", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset.__init__": [[19, 56], ["RLRMCdataset.RLRMCdataset._data_processing"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._data_processing"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train", ",", "\n", "validation", "=", "None", ",", "\n", "test", "=", "None", ",", "\n", "mean_center", "=", "True", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", "# seed=42,", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize parameters.\n\n        Args:\n            train (pandas.DataFrame: training data with at least columns (col_user, col_item, col_rating)\n            validation (pandas.DataFrame): validation data with at least columns (col_user, col_item, col_rating). validation can be None, if so, we only process the training data\n            mean_center (bool): flag to mean center the ratings in train (and validation) data\n            col_user (str): user column name\n            col_item (str): item column name\n            col_rating (str): rating column name\n            col_timestamp (str): timestamp column name\n        \"\"\"", "\n", "# initialize user and item index", "\n", "self", ".", "user_idx", "=", "None", "\n", "self", ".", "item_idx", "=", "None", "\n", "\n", "# get col name of user, item and rating", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_timestamp", "=", "col_timestamp", "\n", "# set random seed", "\n", "# random.seed(seed)", "\n", "\n", "# data preprocessing for training and validation data", "\n", "self", ".", "_data_processing", "(", "train", ",", "validation", ",", "test", ",", "mean_center", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._data_processing": [[57, 129], ["RLRMCdataset.RLRMCdataset._reindex", "len", "len", "scipy.sparse.csr_matrix", "train.append", "df.append", "df[].drop_duplicates().reindex", "numpy.arange", "len", "dict", "df[].drop_duplicates", "numpy.arange", "len", "dict", "numpy.mean", "RLRMCdataset.RLRMCdataset._reindex", "scipy.sparse.csr_matrix", "len", "zip", "len", "zip", "entries_train.T.ravel", "df[].drop_duplicates", "entries_validation.T.ravel"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._reindex", "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._reindex"], ["", "def", "_data_processing", "(", "self", ",", "train", ",", "validation", "=", "None", ",", "test", "=", "None", ",", "mean_center", "=", "True", ")", ":", "\n", "        ", "\"\"\"Process the dataset to reindex userID and itemID\n\n        Args:\n            train (pandas.DataFrame): training data with at least columns (col_user, col_item, col_rating)\n            validation (pandas.DataFrame): validation data with at least columns (col_user, col_item, col_rating). validation can be None, if so, we only process the training data\n            mean_center (bool): flag to mean center the ratings in train (and validation) data\n\n        Returns:\n            list: train and validation pandas.DataFrame Dataset, which have been reindexed.\n\n        \"\"\"", "\n", "# Data processing and reindexing code is adopted from https://github.com/Microsoft/Recommenders/blob/main/recommenders/models/ncf/dataset.py", "\n", "# If validation dataset is None", "\n", "df", "=", "train", "if", "validation", "is", "None", "else", "train", ".", "append", "(", "validation", ")", "\n", "df", "=", "df", "if", "test", "is", "None", "else", "df", ".", "append", "(", "test", ")", "\n", "\n", "# Reindex user and item index", "\n", "if", "self", ".", "user_idx", "is", "None", ":", "\n", "# Map user id", "\n", "            ", "user_idx", "=", "df", "[", "[", "self", ".", "col_user", "]", "]", ".", "drop_duplicates", "(", ")", ".", "reindex", "(", ")", "\n", "user_idx", "[", "self", ".", "col_user", "+", "\"_idx\"", "]", "=", "np", ".", "arange", "(", "len", "(", "user_idx", ")", ")", "\n", "self", ".", "n_users", "=", "len", "(", "user_idx", ")", "\n", "self", ".", "user_idx", "=", "user_idx", "\n", "\n", "self", ".", "user2id", "=", "dict", "(", "\n", "zip", "(", "user_idx", "[", "self", ".", "col_user", "]", ",", "user_idx", "[", "self", ".", "col_user", "+", "\"_idx\"", "]", ")", "\n", ")", "\n", "self", ".", "id2user", "=", "{", "self", ".", "user2id", "[", "k", "]", ":", "k", "for", "k", "in", "self", ".", "user2id", "}", "\n", "\n", "", "if", "self", ".", "item_idx", "is", "None", ":", "\n", "# Map item id", "\n", "            ", "item_idx", "=", "df", "[", "[", "self", ".", "col_item", "]", "]", ".", "drop_duplicates", "(", ")", "\n", "item_idx", "[", "self", ".", "col_item", "+", "\"_idx\"", "]", "=", "np", ".", "arange", "(", "len", "(", "item_idx", ")", ")", "\n", "self", ".", "n_items", "=", "len", "(", "item_idx", ")", "\n", "self", ".", "item_idx", "=", "item_idx", "\n", "\n", "self", ".", "item2id", "=", "dict", "(", "\n", "zip", "(", "item_idx", "[", "self", ".", "col_item", "]", ",", "item_idx", "[", "self", ".", "col_item", "+", "\"_idx\"", "]", ")", "\n", ")", "\n", "self", ".", "id2item", "=", "{", "self", ".", "item2id", "[", "k", "]", ":", "k", "for", "k", "in", "self", ".", "item2id", "}", "\n", "\n", "", "df_train", "=", "self", ".", "_reindex", "(", "train", ")", "\n", "\n", "d", "=", "len", "(", "user_idx", ")", "# number of rows", "\n", "T", "=", "len", "(", "item_idx", ")", "# number of columns", "\n", "\n", "rows_train", "=", "df_train", "[", "\"userID\"", "]", ".", "values", "\n", "cols_train", "=", "df_train", "[", "\"itemID\"", "]", ".", "values", "\n", "entries_omega", "=", "df_train", "[", "\"rating\"", "]", ".", "values", "\n", "if", "mean_center", ":", "\n", "            ", "train_mean", "=", "np", ".", "mean", "(", "entries_omega", ")", "\n", "", "else", ":", "\n", "            ", "train_mean", "=", "0.0", "\n", "", "entries_train", "=", "entries_omega", "-", "train_mean", "\n", "self", ".", "model_param", "=", "{", "\"num_row\"", ":", "d", ",", "\"num_col\"", ":", "T", ",", "\"train_mean\"", ":", "train_mean", "}", "\n", "\n", "self", ".", "train", "=", "csr_matrix", "(", "\n", "(", "entries_train", ".", "T", ".", "ravel", "(", ")", ",", "(", "rows_train", ",", "cols_train", ")", ")", ",", "shape", "=", "(", "d", ",", "T", ")", "\n", ")", "\n", "\n", "if", "validation", "is", "not", "None", ":", "\n", "            ", "df_validation", "=", "self", ".", "_reindex", "(", "validation", ")", "\n", "rows_validation", "=", "df_validation", "[", "\"userID\"", "]", ".", "values", "\n", "cols_validation", "=", "df_validation", "[", "\"itemID\"", "]", ".", "values", "\n", "entries_validation", "=", "df_validation", "[", "\"rating\"", "]", ".", "values", "-", "train_mean", "\n", "self", ".", "validation", "=", "csr_matrix", "(", "\n", "(", "entries_validation", ".", "T", ".", "ravel", "(", ")", ",", "(", "rows_validation", ",", "cols_validation", ")", ")", ",", "\n", "shape", "=", "(", "d", ",", "T", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "validation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.rlrmc.RLRMCdataset.RLRMCdataset._reindex": [[130, 156], ["pandas.merge", "pandas.merge"], "methods", ["None"], ["", "", "def", "_reindex", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Process dataset to reindex userID and itemID\n\n        Args:\n            df (pandas.DataFrame): dataframe with at least columns (col_user, col_item, col_rating)\n\n        Returns:\n            list: train and validation pandas.DataFrame Dataset, which have been reindexed.\n\n        \"\"\"", "\n", "\n", "# If validation dataset is None", "\n", "if", "df", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# Map user_idx and item_idx", "\n", "", "df", "=", "pd", ".", "merge", "(", "df", ",", "self", ".", "user_idx", ",", "on", "=", "self", ".", "col_user", ",", "how", "=", "\"left\"", ")", "\n", "df", "=", "pd", ".", "merge", "(", "df", ",", "self", ".", "item_idx", ",", "on", "=", "self", ".", "col_item", ",", "how", "=", "\"left\"", ")", "\n", "\n", "# Select relevant columns", "\n", "df_reindex", "=", "df", "[", "\n", "[", "self", ".", "col_user", "+", "\"_idx\"", ",", "self", ".", "col_item", "+", "\"_idx\"", ",", "self", ".", "col_rating", "]", "\n", "]", "\n", "df_reindex", ".", "columns", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "self", ".", "col_rating", "]", "\n", "\n", "return", "df_reindex", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.__init__": [[30, 60], ["logging.basicConfig", "category_encoders.ordinal.OrdinalEncoder"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cate_cols", ",", "nume_cols", ",", "label_col", ",", "threshold", "=", "10", ",", "thresrate", "=", "0.99", ")", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            cate_cols (list): The columns of categorical features.\n            nume_cols (list): The columns of numerical features.\n            label_col (object): The column of Label.\n            threshold (int): The categories whose frequency is lower than the threshold will be filtered (be treated\n                as \"<LESS>\").\n            thresrate (float): The (1.0 - thersrate, default 1%) lowest-frequency categories will also be filtered.\n        \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(asctime)s [INFO] %(message)s\"", ")", "\n", "self", ".", "label_name", "=", "label_col", "\n", "self", ".", "cate_cols", "=", "cate_cols", "\n", "self", ".", "dtype_dict", "=", "{", "}", "\n", "for", "item", "in", "cate_cols", ":", "\n", "            ", "self", ".", "dtype_dict", "[", "item", "]", "=", "\"str\"", "\n", "", "for", "item", "in", "nume_cols", ":", "\n", "            ", "self", ".", "dtype_dict", "[", "item", "]", "=", "\"float\"", "\n", "", "self", ".", "nume_cols", "=", "nume_cols", "\n", "self", ".", "tgt_nume_cols", "=", "[", "]", "\n", "self", ".", "encoder", "=", "ce", ".", "ordinal", ".", "OrdinalEncoder", "(", "cols", "=", "cate_cols", ")", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "thresrate", "=", "thresrate", "\n", "\n", "self", ".", "save_cate_avgs", "=", "{", "}", "\n", "self", ".", "save_value_filter", "=", "{", "}", "\n", "self", ".", "save_num_embs", "=", "{", "}", "\n", "self", ".", "Max_len", "=", "{", "}", "\n", "self", ".", "samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.fit_transform": [[61, 147], ["lightgbm_utils.NumEncoder.astype", "logging.info", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "logging.info", "lightgbm_utils.NumEncoder.encoder.fit_transform", "logging.info", "tqdm.tqdm.tqdm", "logging.info", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "numpy.array().reshape", "gc.collect", "numpy.array", "df[].value_counts", "list", "df[].map", "df[].fillna", "gc.collect", "df[].fillna", "collections.defaultdict", "range", "lightgbm_utils.NumEncoder.tgt_nume_cols.append", "lightgbm_utils.NumEncoder.tgt_nume_cols.append", "gc.collect", "df[].max", "unpackbits().reshape", "numpy.concatenate", "gc.collect", "set", "set", "df[].mean", "df[].sum", "feats.reshape", "numpy.concatenate", "len", "numpy.array", "feat_encoding[].append", "feat_encoding[].append", "feat_encoding[].append", "feat_encoding[].append", "bin", "lightgbm_utils.unpackbits", "feats.reshape", "int"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.fit_transform", "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.unpackbits"], ["", "def", "fit_transform", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Input a training set (pandas.DataFrame) and return the converted 2 numpy.ndarray (x,y).\n\n        Args:\n            df (pandas.DataFrame): Input dataframe\n\n        Returns:\n            numpy.ndarray, numpy.ndarray: New features and labels.\n        \"\"\"", "\n", "df", "=", "df", ".", "astype", "(", "dtype", "=", "self", ".", "dtype_dict", ")", "\n", "self", ".", "samples", "=", "df", ".", "shape", "[", "0", "]", "\n", "logging", ".", "info", "(", "\"Filtering and fillna features\"", ")", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "value_counts", "=", "df", "[", "item", "]", ".", "value_counts", "(", ")", "\n", "num", "=", "value_counts", ".", "shape", "[", "0", "]", "\n", "self", ".", "save_value_filter", "[", "item", "]", "=", "list", "(", "\n", "value_counts", "[", ":", "int", "(", "num", "*", "self", ".", "thresrate", ")", "]", "[", "\n", "value_counts", ">", "self", ".", "threshold", "\n", "]", ".", "index", "\n", ")", "\n", "rm_values", "=", "set", "(", "value_counts", ".", "index", ")", "-", "set", "(", "self", ".", "save_value_filter", "[", "item", "]", ")", "\n", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "map", "(", "lambda", "x", ":", "\"<LESS>\"", "if", "x", "in", "rm_values", "else", "x", ")", "\n", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "fillna", "(", "\"<UNK>\"", ")", "\n", "del", "value_counts", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "for", "item", "in", "tqdm", "(", "self", ".", "nume_cols", ")", ":", "\n", "            ", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "fillna", "(", "df", "[", "item", "]", ".", "mean", "(", ")", ")", "\n", "self", ".", "save_num_embs", "[", "item", "]", "=", "{", "\"sum\"", ":", "df", "[", "item", "]", ".", "sum", "(", ")", ",", "\"cnt\"", ":", "df", "[", "item", "]", ".", "shape", "[", "0", "]", "}", "\n", "\n", "", "logging", ".", "info", "(", "\"Ordinal encoding cate features\"", ")", "\n", "# ordinal_encoding", "\n", "df", "=", "self", ".", "encoder", ".", "fit_transform", "(", "df", ")", "\n", "\n", "logging", ".", "info", "(", "\"Target encoding cate features\"", ")", "\n", "# dynamic_targeting_encoding", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "feats", "=", "df", "[", "item", "]", ".", "values", "\n", "labels", "=", "df", "[", "self", ".", "label_name", "]", ".", "values", "\n", "feat_encoding", "=", "{", "\"mean\"", ":", "[", "]", ",", "\"count\"", ":", "[", "]", "}", "\n", "self", ".", "save_cate_avgs", "[", "item", "]", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "[", "0", ",", "0", "]", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "samples", ")", ":", "\n", "                ", "cur_feat", "=", "feats", "[", "idx", "]", "\n", "if", "cur_feat", "in", "self", ".", "save_cate_avgs", "[", "item", "]", ":", "\n", "                    ", "feat_encoding", "[", "\"mean\"", "]", ".", "append", "(", "\n", "self", ".", "save_cate_avgs", "[", "item", "]", "[", "cur_feat", "]", "[", "0", "]", "\n", "/", "self", ".", "save_cate_avgs", "[", "item", "]", "[", "cur_feat", "]", "[", "1", "]", "\n", ")", "\n", "feat_encoding", "[", "\"count\"", "]", ".", "append", "(", "\n", "self", ".", "save_cate_avgs", "[", "item", "]", "[", "cur_feat", "]", "[", "1", "]", "/", "idx", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "feat_encoding", "[", "\"mean\"", "]", ".", "append", "(", "0", ")", "\n", "feat_encoding", "[", "\"count\"", "]", ".", "append", "(", "0", ")", "\n", "", "self", ".", "save_cate_avgs", "[", "item", "]", "[", "cur_feat", "]", "[", "0", "]", "+=", "labels", "[", "idx", "]", "\n", "self", ".", "save_cate_avgs", "[", "item", "]", "[", "cur_feat", "]", "[", "1", "]", "+=", "1", "\n", "", "df", "[", "item", "+", "\"_t_mean\"", "]", "=", "feat_encoding", "[", "\"mean\"", "]", "\n", "df", "[", "item", "+", "\"_t_count\"", "]", "=", "feat_encoding", "[", "\"count\"", "]", "\n", "self", ".", "tgt_nume_cols", ".", "append", "(", "item", "+", "\"_t_mean\"", ")", "\n", "self", ".", "tgt_nume_cols", ".", "append", "(", "item", "+", "\"_t_count\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Start manual binary encoding\"", ")", "\n", "rows", "=", "None", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "nume_cols", "+", "self", ".", "tgt_nume_cols", ")", ":", "\n", "            ", "feats", "=", "df", "[", "item", "]", ".", "values", "\n", "if", "rows", "is", "None", ":", "\n", "                ", "rows", "=", "feats", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "rows", "=", "np", ".", "concatenate", "(", "[", "rows", ",", "feats", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "del", "feats", "\n", "gc", ".", "collect", "(", ")", "\n", "", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "feats", "=", "df", "[", "item", "]", ".", "values", "\n", "Max", "=", "df", "[", "item", "]", ".", "max", "(", ")", "\n", "bit_len", "=", "len", "(", "bin", "(", "Max", ")", ")", "-", "2", "\n", "samples", "=", "self", ".", "samples", "\n", "self", ".", "Max_len", "[", "item", "]", "=", "bit_len", "\n", "res", "=", "unpackbits", "(", "feats", ",", "bit_len", ")", ".", "reshape", "(", "(", "samples", ",", "-", "1", ")", ")", "\n", "rows", "=", "np", ".", "concatenate", "(", "[", "rows", ",", "res", "]", ",", "axis", "=", "1", ")", "\n", "del", "feats", "\n", "gc", ".", "collect", "(", ")", "\n", "", "trn_y", "=", "np", ".", "array", "(", "df", "[", "self", ".", "label_name", "]", ".", "values", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "del", "df", "\n", "gc", ".", "collect", "(", ")", "\n", "trn_x", "=", "np", ".", "array", "(", "rows", ")", "\n", "return", "trn_x", ",", "trn_y", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform": [[149, 208], ["lightgbm_utils.NumEncoder.astype", "logging.info", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "logging.info", "lightgbm_utils.NumEncoder.encoder.transform", "logging.info", "tqdm.tqdm.tqdm", "logging.info", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "numpy.array().reshape", "gc.collect", "numpy.array", "df[].value_counts", "df[].map", "df[].fillna", "df[].fillna", "df[].map", "df[].map", "gc.collect", "unpackbits().reshape", "numpy.concatenate", "gc.collect", "set", "set", "feats.reshape", "numpy.concatenate", "numpy.array", "lightgbm_utils.unpackbits", "feats.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform", "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.unpackbits"], ["", "def", "transform", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Input a testing / validation set (pandas.DataFrame) and return the converted 2 numpy.ndarray (x,y).\n\n        Args:\n            df (pandas.DataFrame): Input dataframe\n\n        Returns:\n            numpy.ndarray, numpy.ndarray: New features and labels.\n        \"\"\"", "\n", "df", "=", "df", ".", "astype", "(", "dtype", "=", "self", ".", "dtype_dict", ")", "\n", "samples", "=", "df", ".", "shape", "[", "0", "]", "\n", "logging", ".", "info", "(", "\"Filtering and fillna features\"", ")", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "value_counts", "=", "df", "[", "item", "]", ".", "value_counts", "(", ")", "\n", "rm_values", "=", "set", "(", "value_counts", ".", "index", ")", "-", "set", "(", "self", ".", "save_value_filter", "[", "item", "]", ")", "\n", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "map", "(", "lambda", "x", ":", "\"<LESS>\"", "if", "x", "in", "rm_values", "else", "x", ")", "\n", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "fillna", "(", "\"<UNK>\"", ")", "\n", "\n", "", "for", "item", "in", "tqdm", "(", "self", ".", "nume_cols", ")", ":", "\n", "            ", "mean", "=", "self", ".", "save_num_embs", "[", "item", "]", "[", "\"sum\"", "]", "/", "self", ".", "save_num_embs", "[", "item", "]", "[", "\"cnt\"", "]", "\n", "df", "[", "item", "]", "=", "df", "[", "item", "]", ".", "fillna", "(", "mean", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Ordinal encoding cate features\"", ")", "\n", "# ordinal_encoding", "\n", "df", "=", "self", ".", "encoder", ".", "transform", "(", "df", ")", "\n", "\n", "logging", ".", "info", "(", "\"Target encoding cate features\"", ")", "\n", "# dynamic_targeting_encoding", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "avgs", "=", "self", ".", "save_cate_avgs", "[", "item", "]", "\n", "df", "[", "item", "+", "\"_t_mean\"", "]", "=", "df", "[", "item", "]", ".", "map", "(", "\n", "lambda", "x", ":", "avgs", "[", "x", "]", "[", "0", "]", "/", "avgs", "[", "x", "]", "[", "1", "]", "if", "x", "in", "avgs", "else", "0", "\n", ")", "\n", "df", "[", "item", "+", "\"_t_count\"", "]", "=", "df", "[", "item", "]", ".", "map", "(", "\n", "lambda", "x", ":", "avgs", "[", "x", "]", "[", "1", "]", "/", "self", ".", "samples", "if", "x", "in", "avgs", "else", "0", "\n", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Start manual binary encoding\"", ")", "\n", "rows", "=", "None", "\n", "for", "item", "in", "tqdm", "(", "self", ".", "nume_cols", "+", "self", ".", "tgt_nume_cols", ")", ":", "\n", "            ", "feats", "=", "df", "[", "item", "]", ".", "values", "\n", "if", "rows", "is", "None", ":", "\n", "                ", "rows", "=", "feats", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "rows", "=", "np", ".", "concatenate", "(", "[", "rows", ",", "feats", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "del", "feats", "\n", "gc", ".", "collect", "(", ")", "\n", "", "for", "item", "in", "tqdm", "(", "self", ".", "cate_cols", ")", ":", "\n", "            ", "feats", "=", "df", "[", "item", "]", ".", "values", "\n", "bit_len", "=", "self", ".", "Max_len", "[", "item", "]", "\n", "res", "=", "unpackbits", "(", "feats", ",", "bit_len", ")", ".", "reshape", "(", "(", "samples", ",", "-", "1", ")", ")", "\n", "rows", "=", "np", ".", "concatenate", "(", "[", "rows", ",", "res", "]", ",", "axis", "=", "1", ")", "\n", "del", "feats", "\n", "gc", ".", "collect", "(", ")", "\n", "", "vld_y", "=", "np", ".", "array", "(", "df", "[", "self", ".", "label_name", "]", ".", "values", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "del", "df", "\n", "gc", ".", "collect", "(", ")", "\n", "vld_x", "=", "np", ".", "array", "(", "rows", ")", "\n", "return", "vld_x", ",", "vld_y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.unpackbits": [[12, 23], ["list", "x.reshape.reshape", "numpy.arange().reshape", "numpy.arange"], "function", ["None"], ["def", "unpackbits", "(", "x", ",", "num_bits", ")", ":", "\n", "    ", "\"\"\"Convert a decimal value numpy.ndarray into multi-binary value numpy.ndarray ([1,2]->[[0,1],[1,0]])\n\n    Args:\n        x (numpy.ndarray): Decimal array.\n        num_bits (int): The max length of the converted binary value.\n    \"\"\"", "\n", "xshape", "=", "list", "(", "x", ".", "shape", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "to_and", "=", "2", "**", "np", ".", "arange", "(", "num_bits", ")", ".", "reshape", "(", "[", "1", ",", "num_bits", "]", ")", "\n", "return", "(", "x", "&", "to_and", ")", ".", "astype", "(", "bool", ")", ".", "astype", "(", "int", ")", ".", "reshape", "(", "xshape", "+", "[", "num_bits", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._check_column_dtypes": [[35, 93], ["functools.wraps", "func", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype"], ["def", "_check_column_dtypes", "(", "func", ")", ":", "\n", "    ", "\"\"\"Checks columns of DataFrame inputs\n\n    This includes the checks on:\n\n    * whether the input columns exist in the input DataFrames\n    * whether the data types of col_user as well as col_item are matched in the two input DataFrames.\n\n    Args:\n        func (function): function that will be wrapped\n\n    Returns:\n        function: Wrapper function for checking dtypes.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "check_column_dtypes_wrapper", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Check columns of DataFrame inputs\n\n        Args:\n            rating_true (pandas.DataFrame): True data\n            rating_pred (pandas.DataFrame): Predicted data\n            col_user (str): column name for user\n            col_item (str): column name for item\n            col_rating (str): column name for rating\n            col_prediction (str): column name for prediction\n        \"\"\"", "\n", "\n", "if", "not", "has_columns", "(", "rating_true", ",", "[", "col_user", ",", "col_item", ",", "col_rating", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in true rating DataFrame\"", ")", "\n", "", "if", "not", "has_columns", "(", "rating_pred", ",", "[", "col_user", ",", "col_item", ",", "col_prediction", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in predicted rating DataFrame\"", ")", "\n", "", "if", "not", "has_same_base_dtype", "(", "\n", "rating_true", ",", "rating_pred", ",", "columns", "=", "[", "col_user", ",", "col_item", "]", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Columns in provided DataFrames are not the same datatype\"", ")", "\n", "\n", "", "return", "func", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "", "return", "check_column_dtypes_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred": [[95, 132], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "pandas.merge"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df"], ["", "@", "_check_column_dtypes", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "merge_rating_true_pred", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Join truth and prediction data frames on userID and itemID and return the true\n    and predicted rated with the correct index.\n\n    Args:\n        rating_true (pandas.DataFrame): True data\n        rating_pred (pandas.DataFrame): Predicted data\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        numpy.ndarray: Array with the true ratings\n        numpy.ndarray: Array with the predicted ratings\n\n    \"\"\"", "\n", "\n", "# pd.merge will apply suffixes to columns which have the same name across both dataframes", "\n", "suffixes", "=", "[", "\"_true\"", ",", "\"_pred\"", "]", "\n", "rating_true_pred", "=", "pd", ".", "merge", "(", "\n", "rating_true", ",", "rating_pred", ",", "on", "=", "[", "col_user", ",", "col_item", "]", ",", "suffixes", "=", "suffixes", "\n", ")", "\n", "if", "col_rating", "in", "rating_pred", ".", "columns", ":", "\n", "        ", "col_rating", "=", "col_rating", "+", "suffixes", "[", "0", "]", "\n", "", "if", "col_prediction", "in", "rating_true", ".", "columns", ":", "\n", "        ", "col_prediction", "=", "col_prediction", "+", "suffixes", "[", "1", "]", "\n", "", "return", "rating_true_pred", "[", "col_rating", "]", ",", "rating_true_pred", "[", "col_prediction", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.rmse": [[134, 165], ["python_evaluation.merge_rating_true_pred", "numpy.sqrt", "sklearn.metrics.mean_squared_error"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "rmse", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate Root Mean Squared Error\n\n    Args:\n        rating_true (pandas.DataFrame): True data. There should be no duplicate (userID, itemID) pairs\n        rating_pred (pandas.DataFrame): Predicted data. There should be no duplicate (userID, itemID) pairs\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: Root mean squared error\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "np", ".", "sqrt", "(", "mean_squared_error", "(", "y_true", ",", "y_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.mae": [[167, 198], ["python_evaluation.merge_rating_true_pred", "sklearn.metrics.mean_absolute_error"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "mae", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate Mean Absolute Error.\n\n    Args:\n        rating_true (pandas.DataFrame): True data. There should be no duplicate (userID, itemID) pairs\n        rating_pred (pandas.DataFrame): Predicted data. There should be no duplicate (userID, itemID) pairs\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: Mean Absolute Error.\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "mean_absolute_error", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.rsquared": [[200, 231], ["python_evaluation.merge_rating_true_pred", "sklearn.metrics.r2_score"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "rsquared", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate R squared\n\n    Args:\n        rating_true (pandas.DataFrame): True data. There should be no duplicate (userID, itemID) pairs\n        rating_pred (pandas.DataFrame): Predicted data. There should be no duplicate (userID, itemID) pairs\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: R squared (min=0, max=1).\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "r2_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.exp_var": [[233, 264], ["python_evaluation.merge_rating_true_pred", "sklearn.metrics.explained_variance_score"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "exp_var", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate explained variance.\n\n    Args:\n        rating_true (pandas.DataFrame): True data. There should be no duplicate (userID, itemID) pairs\n        rating_pred (pandas.DataFrame): Predicted data. There should be no duplicate (userID, itemID) pairs\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: Explained variance (min=0, max=1).\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "explained_variance_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.auc": [[266, 307], ["python_evaluation.merge_rating_true_pred", "sklearn.metrics.roc_auc_score"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "auc", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate the Area-Under-Curve metric for implicit feedback typed\n    recommender, where rating is binary and prediction is float number ranging\n    from 0 to 1.\n\n    https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\n\n    Note:\n        The evaluation does not require a leave-one-out scenario.\n        This metric does not calculate group-based AUC which considers the AUC scores\n        averaged across users. It is also not limited to k. Instead, it calculates the\n        scores on the entire prediction results regardless the users.\n\n    Args:\n        rating_true (pandas.DataFrame): True data\n        rating_pred (pandas.DataFrame): Predicted data\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: auc_score (min=0, max=1)\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "roc_auc_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.logloss": [[309, 344], ["python_evaluation.merge_rating_true_pred", "sklearn.metrics.log_loss"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "def", "logloss", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate the logloss metric for implicit feedback typed\n    recommender, where rating is binary and prediction is float number ranging\n    from 0 to 1.\n\n    https://en.wikipedia.org/wiki/Loss_functions_for_classification#Cross_entropy_loss_(Log_Loss)\n\n    Args:\n        rating_true (pandas.DataFrame): True data\n        rating_pred (pandas.DataFrame): Predicted data\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n\n    Returns:\n        float: log_loss_score (min=-inf, max=inf)\n    \"\"\"", "\n", "\n", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", ")", "\n", "return", "log_loss", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred": [[346, 416], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "set().intersection", "len", "python_evaluation.get_top_k_items", "pandas.merge", "set", "pandas.merge", "[].agg", "[].agg", "set", "rating_true[].isin", "rating_pred[].isin", "NotImplementedError", "get_top_k_items.groupby", "rating_true_common.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.get_top_k_items"], ["", "@", "_check_column_dtypes", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "merge_ranking_true_pred", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_rating", ",", "\n", "col_prediction", ",", "\n", "relevancy_method", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Filter truth and prediction data frames on common users\n\n    Args:\n        rating_true (pandas.DataFrame): True DataFrame\n        rating_pred (pandas.DataFrame): Predicted DataFrame\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n            top k items are directly provided, so there is no need to compute the relevancy operation.\n        k (int): number of top k items per user (optional)\n        threshold (float): threshold of top items per user (optional)\n\n    Returns:\n        pandas.DataFrame, pandas.DataFrame, int: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n        DataFrame of hit counts vs actual relevant items per user number of unique user ids\n    \"\"\"", "\n", "\n", "# Make sure the prediction and true data frames have the same set of users", "\n", "common_users", "=", "set", "(", "rating_true", "[", "col_user", "]", ")", ".", "intersection", "(", "set", "(", "rating_pred", "[", "col_user", "]", ")", ")", "\n", "rating_true_common", "=", "rating_true", "[", "rating_true", "[", "col_user", "]", ".", "isin", "(", "common_users", ")", "]", "\n", "rating_pred_common", "=", "rating_pred", "[", "rating_pred", "[", "col_user", "]", ".", "isin", "(", "common_users", ")", "]", "\n", "n_users", "=", "len", "(", "common_users", ")", "\n", "\n", "# Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.", "\n", "# Use first to generate unique ranking values for each item. This is to align with the implementation in", "\n", "# Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used", "\n", "# to calculate penalized precision of the ordered items.", "\n", "if", "relevancy_method", "==", "\"top_k\"", ":", "\n", "        ", "top_k", "=", "k", "\n", "", "elif", "relevancy_method", "==", "\"by_threshold\"", ":", "\n", "        ", "top_k", "=", "threshold", "\n", "", "elif", "relevancy_method", "is", "None", ":", "\n", "        ", "top_k", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Invalid relevancy_method\"", ")", "\n", "", "df_hit", "=", "get_top_k_items", "(", "\n", "dataframe", "=", "rating_pred_common", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_rating", "=", "col_prediction", ",", "\n", "k", "=", "top_k", ",", "\n", ")", "\n", "df_hit", "=", "pd", ".", "merge", "(", "df_hit", ",", "rating_true_common", ",", "on", "=", "[", "col_user", ",", "col_item", "]", ")", "[", "\n", "[", "col_user", ",", "col_item", ",", "\"rank\"", "]", "\n", "]", "\n", "\n", "# count the number of hits vs actual relevant items per user", "\n", "df_hit_count", "=", "pd", ".", "merge", "(", "\n", "df_hit", ".", "groupby", "(", "col_user", ",", "as_index", "=", "False", ")", "[", "col_user", "]", ".", "agg", "(", "{", "\"hit\"", ":", "\"count\"", "}", ")", ",", "\n", "rating_true_common", ".", "groupby", "(", "col_user", ",", "as_index", "=", "False", ")", "[", "col_user", "]", ".", "agg", "(", "\n", "{", "\"actual\"", ":", "\"count\"", "}", "\n", ")", ",", "\n", "on", "=", "col_user", ",", "\n", ")", "\n", "\n", "return", "df_hit", ",", "df_hit_count", ",", "n_users", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.precision_at_k": [[418, 470], ["python_evaluation.merge_ranking_true_pred"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred"], ["", "def", "precision_at_k", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Precision at K.\n\n    Note:\n        We use the same formula to calculate precision@k as that in Spark.\n        More details can be found at\n        http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.precisionAt\n        In particular, the maximum achievable precision may be < 1, if the number of items for a\n        user in rating_pred is less than k.\n\n    Args:\n        rating_true (pandas.DataFrame): True DataFrame\n        rating_pred (pandas.DataFrame): Predicted DataFrame\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n            top k items are directly provided, so there is no need to compute the relevancy operation.\n        k (int): number of top k items per user\n        threshold (float): threshold of top items per user (optional)\n\n    Returns:\n        float: precision at k (min=0, max=1)\n    \"\"\"", "\n", "\n", "df_hit", ",", "df_hit_count", ",", "n_users", "=", "merge_ranking_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", "relevancy_method", "=", "relevancy_method", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", ")", "\n", "\n", "if", "df_hit", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "        ", "return", "0.0", "\n", "\n", "", "return", "(", "df_hit_count", "[", "\"hit\"", "]", "/", "k", ")", ".", "sum", "(", ")", "/", "n_users", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.recall_at_k": [[472, 518], ["python_evaluation.merge_ranking_true_pred"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred"], ["", "def", "recall_at_k", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Recall at K.\n\n    Args:\n        rating_true (pandas.DataFrame): True DataFrame\n        rating_pred (pandas.DataFrame): Predicted DataFrame\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n            top k items are directly provided, so there is no need to compute the relevancy operation.\n        k (int): number of top k items per user\n        threshold (float): threshold of top items per user (optional)\n\n    Returns:\n        float: recall at k (min=0, max=1). The maximum value is 1 even when fewer than\n        k items exist for a user in rating_true.\n    \"\"\"", "\n", "\n", "df_hit", ",", "df_hit_count", ",", "n_users", "=", "merge_ranking_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", "relevancy_method", "=", "relevancy_method", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", ")", "\n", "\n", "if", "df_hit", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "        ", "return", "0.0", "\n", "\n", "", "return", "(", "df_hit_count", "[", "\"hit\"", "]", "/", "df_hit_count", "[", "\"actual\"", "]", ")", ".", "sum", "(", ")", "/", "n_users", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.ndcg_at_k": [[520, 580], ["python_evaluation.merge_ranking_true_pred", "df_hit.copy", "df_dcg.groupby().agg.groupby().agg", "pandas.merge", "df_ndcg[].apply", "numpy.log1p", "df_dcg.groupby().agg.groupby", "sum", "numpy.log1p", "range", "min"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred"], ["", "def", "ndcg_at_k", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Normalized Discounted Cumulative Gain (nDCG).\n\n    Info: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n\n    Args:\n        rating_true (pandas.DataFrame): True DataFrame\n        rating_pred (pandas.DataFrame): Predicted DataFrame\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n            top k items are directly provided, so there is no need to compute the relevancy operation.\n        k (int): number of top k items per user\n        threshold (float): threshold of top items per user (optional)\n\n    Returns:\n        float: nDCG at k (min=0, max=1).\n    \"\"\"", "\n", "\n", "df_hit", ",", "df_hit_count", ",", "n_users", "=", "merge_ranking_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", "relevancy_method", "=", "relevancy_method", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", ")", "\n", "\n", "if", "df_hit", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "        ", "return", "0.0", "\n", "\n", "# calculate discounted gain for hit items", "\n", "", "df_dcg", "=", "df_hit", ".", "copy", "(", ")", "\n", "# relevance in this case is always 1", "\n", "df_dcg", "[", "\"dcg\"", "]", "=", "1", "/", "np", ".", "log1p", "(", "df_dcg", "[", "\"rank\"", "]", ")", "\n", "# sum up discount gained to get discount cumulative gain", "\n", "df_dcg", "=", "df_dcg", ".", "groupby", "(", "col_user", ",", "as_index", "=", "False", ",", "sort", "=", "False", ")", ".", "agg", "(", "{", "\"dcg\"", ":", "\"sum\"", "}", ")", "\n", "# calculate ideal discounted cumulative gain", "\n", "df_ndcg", "=", "pd", ".", "merge", "(", "df_dcg", ",", "df_hit_count", ",", "on", "=", "[", "col_user", "]", ")", "\n", "df_ndcg", "[", "\"idcg\"", "]", "=", "df_ndcg", "[", "\"actual\"", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "sum", "(", "1", "/", "np", ".", "log1p", "(", "range", "(", "1", ",", "min", "(", "x", ",", "k", ")", "+", "1", ")", ")", ")", "\n", ")", "\n", "\n", "# DCG over IDCG is the normalized DCG", "\n", "return", "(", "df_ndcg", "[", "\"dcg\"", "]", "/", "df_ndcg", "[", "\"idcg\"", "]", ")", ".", "sum", "(", ")", "/", "n_users", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.map_at_k": [[582, 648], ["python_evaluation.merge_ranking_true_pred", "df_hit.copy", "df_hit_sorted.groupby().agg().reset_index.groupby().agg().reset_index", "pandas.merge", "df_hit_sorted.groupby().agg().reset_index.groupby().cumcount", "df_hit_sorted.groupby().agg().reset_index.groupby().agg", "df_hit_sorted.groupby().agg().reset_index.groupby", "df_hit_sorted.groupby().agg().reset_index.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred"], ["", "def", "map_at_k", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Mean Average Precision at k\n\n    The implementation of MAP is referenced from Spark MLlib evaluation metrics.\n    https://spark.apache.org/docs/2.3.0/mllib-evaluation-metrics.html#ranking-systems\n\n    A good reference can be found at:\n    http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n\n    Note:\n        1. The evaluation function is named as 'MAP is at k' because the evaluation class takes top k items for\n        the prediction items. The naming is different from Spark.\n\n        2. The MAP is meant to calculate Avg. Precision for the relevant items, so it is normalized by the number of\n        relevant items in the ground truth data, instead of k.\n\n    Args:\n        rating_true (pandas.DataFrame): True DataFrame\n        rating_pred (pandas.DataFrame): Predicted DataFrame\n        col_user (str): column name for user\n        col_item (str): column name for item\n        col_rating (str): column name for rating\n        col_prediction (str): column name for prediction\n        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n            top k items are directly provided, so there is no need to compute the relevancy operation.\n        k (int): number of top k items per user\n        threshold (float): threshold of top items per user (optional)\n\n    Returns:\n        float: MAP at k (min=0, max=1).\n    \"\"\"", "\n", "\n", "df_hit", ",", "df_hit_count", ",", "n_users", "=", "merge_ranking_true_pred", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_pred", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_rating", "=", "col_rating", ",", "\n", "col_prediction", "=", "col_prediction", ",", "\n", "relevancy_method", "=", "relevancy_method", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", ")", "\n", "\n", "if", "df_hit", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "        ", "return", "0.0", "\n", "\n", "# calculate reciprocal rank of items for each user and sum them up", "\n", "", "df_hit_sorted", "=", "df_hit", ".", "copy", "(", ")", "\n", "df_hit_sorted", "[", "\"rr\"", "]", "=", "(", "\n", "df_hit_sorted", ".", "groupby", "(", "col_user", ")", ".", "cumcount", "(", ")", "+", "1", "\n", ")", "/", "df_hit_sorted", "[", "\"rank\"", "]", "\n", "df_hit_sorted", "=", "df_hit_sorted", ".", "groupby", "(", "col_user", ")", ".", "agg", "(", "{", "\"rr\"", ":", "\"sum\"", "}", ")", ".", "reset_index", "(", ")", "\n", "\n", "df_merge", "=", "pd", ".", "merge", "(", "df_hit_sorted", ",", "df_hit_count", ",", "on", "=", "col_user", ")", "\n", "return", "(", "df_merge", "[", "\"rr\"", "]", "/", "df_merge", "[", "\"actual\"", "]", ")", ".", "sum", "(", ")", "/", "n_users", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.get_top_k_items": [[650, 684], ["dataframe.groupby().apply().reset_index", "dataframe.groupby().apply().reset_index.groupby().cumcount", "dataframe.groupby().apply", "dataframe.groupby().apply().reset_index.groupby", "dataframe.groupby", "x.nlargest"], "function", ["None"], ["", "def", "get_top_k_items", "(", "\n", "dataframe", ",", "col_user", "=", "DEFAULT_USER_COL", ",", "col_rating", "=", "DEFAULT_RATING_COL", ",", "k", "=", "DEFAULT_K", "\n", ")", ":", "\n", "    ", "\"\"\"Get the input customer-item-rating tuple in the format of Pandas\n    DataFrame, output a Pandas DataFrame in the dense format of top k items\n    for each user.\n\n    Note:\n        If it is implicit rating, just append a column of constants to be\n        ratings.\n\n    Args:\n        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n        customerID-itemID-rating)\n        col_user (str): column name for user\n        col_rating (str): column name for rating\n        k (int or None): number of items for each user; None means that the input has already been\n        filtered out top k items and sorted by ratings and there is no need to do that again.\n\n    Returns:\n        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n    \"\"\"", "\n", "# Sort dataframe by col_user and (top k) col_rating", "\n", "if", "k", "is", "None", ":", "\n", "        ", "top_k_items", "=", "dataframe", "\n", "", "else", ":", "\n", "        ", "top_k_items", "=", "(", "\n", "dataframe", ".", "groupby", "(", "col_user", ",", "as_index", "=", "False", ")", "\n", ".", "apply", "(", "lambda", "x", ":", "x", ".", "nlargest", "(", "k", ",", "col_rating", ")", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "# Add ranks", "\n", "", "top_k_items", "[", "\"rank\"", "]", "=", "top_k_items", ".", "groupby", "(", "col_user", ",", "sort", "=", "False", ")", ".", "cumcount", "(", ")", "+", "1", "\n", "return", "top_k_items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._check_column_dtypes_diversity_serendipity": [[702, 803], ["functools.wraps", "func", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "ValueError", "reco_df[].astype", "Exception", "Exception", "pandas.merge", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns"], ["def", "_check_column_dtypes_diversity_serendipity", "(", "func", ")", ":", "\n", "    ", "\"\"\"Checks columns of DataFrame inputs\n\n    This includes the checks on:\n\n    * whether the input columns exist in the input DataFrames\n    * whether the data types of col_user as well as col_item are matched in the two input DataFrames.\n    * whether reco_df contains any user_item pairs that are already shown in train_df\n    * check relevance column in reco_df\n    * check column names in item_feature_df\n\n    Args:\n        func (function): function that will be wrapped\n\n    Returns:\n        function: Wrapper function for checking dtypes.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "check_column_dtypes_diversity_serendipity_wrapper", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Check columns of DataFrame inputs\n\n        Args:\n            train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n            reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n            item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n                It contains two columns: col_item and features (a feature vector).\n            item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n                Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n            col_item_features (str): item feature column name.\n            col_user (str): User id column name.\n            col_item (str): Item id column name.\n            col_sim (str): This column indicates the column name for item similarity.\n            col_relevance (str): This column indicates whether the recommended item is actually\n                relevant to the user or not.\n        \"\"\"", "\n", "\n", "if", "not", "has_columns", "(", "train_df", ",", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in train_df DataFrame\"", ")", "\n", "", "if", "not", "has_columns", "(", "reco_df", ",", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in reco_df DataFrame\"", ")", "\n", "", "if", "not", "has_same_base_dtype", "(", "train_df", ",", "reco_df", ",", "columns", "=", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Columns in provided DataFrames are not the same datatype\"", ")", "\n", "", "if", "col_relevance", "is", "None", ":", "\n", "            ", "col_relevance", "=", "DEFAULT_RELEVANCE_COL", "\n", "# relevance term, default is 1 (relevant) for all", "\n", "reco_df", "=", "reco_df", "[", "[", "col_user", ",", "col_item", "]", "]", "\n", "reco_df", "[", "col_relevance", "]", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "col_relevance", "=", "col_relevance", "\n", "reco_df", "=", "reco_df", "[", "[", "col_user", ",", "col_item", ",", "col_relevance", "]", "]", ".", "astype", "(", "\n", "{", "col_relevance", ":", "np", ".", "float16", "}", "\n", ")", "\n", "", "if", "item_sim_measure", "==", "\"item_feature_vector\"", ":", "\n", "            ", "required_columns", "=", "[", "col_item", ",", "col_item_features", "]", "\n", "if", "item_feature_df", "is", "not", "None", ":", "\n", "                ", "if", "not", "has_columns", "(", "item_feature_df", ",", "required_columns", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Missing columns in item_feature_df DataFrame\"", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"item_feature_df not specified! item_feature_df must be provided \"", "\n", "\"if choosing to use item_feature_vector to calculate item similarity. \"", "\n", "\"item_feature_df should have columns: \"", "+", "str", "(", "required_columns", ")", "\n", ")", "\n", "# check if reco_df contains any user_item pairs that are already shown in train_df", "\n", "", "", "count_intersection", "=", "pd", ".", "merge", "(", "\n", "train_df", ",", "reco_df", ",", "how", "=", "\"inner\"", ",", "on", "=", "[", "col_user", ",", "col_item", "]", "\n", ")", ".", "shape", "[", "0", "]", "\n", "if", "count_intersection", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"reco_df should not contain any user_item pairs that are already shown in train_df\"", "\n", ")", "\n", "\n", "", "return", "func", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "item_sim_measure", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "col_sim", "=", "col_sim", ",", "\n", "col_relevance", "=", "col_relevance", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "", "return", "check_column_dtypes_diversity_serendipity_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._check_column_dtypes_novelty_coverage": [[805, 868], ["functools.wraps", "func", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_columns", "ValueError", "recommenders.datasets.pandas_df_utils.has_same_base_dtype", "ValueError", "Exception", "pandas.merge"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_columns", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.has_same_base_dtype"], ["", "def", "_check_column_dtypes_novelty_coverage", "(", "func", ")", ":", "\n", "    ", "\"\"\"Checks columns of DataFrame inputs\n\n    This includes the checks on:\n\n    * whether the input columns exist in the input DataFrames\n    * whether the data types of col_user as well as col_item are matched in the two input DataFrames.\n    * whether reco_df contains any user_item pairs that are already shown in train_df\n\n    Args:\n        func (function): function that will be wrapped\n\n    Returns:\n        function: Wrapper function for checking dtypes.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "check_column_dtypes_novelty_coverage_wrapper", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Check columns of DataFrame inputs\n\n        Args:\n            train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n            reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n            col_user (str): User id column name.\n            col_item (str): Item id column name.\n\n        \"\"\"", "\n", "\n", "if", "not", "has_columns", "(", "train_df", ",", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in train_df DataFrame\"", ")", "\n", "", "if", "not", "has_columns", "(", "reco_df", ",", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Missing columns in reco_df DataFrame\"", ")", "\n", "", "if", "not", "has_same_base_dtype", "(", "train_df", ",", "reco_df", ",", "columns", "=", "[", "col_user", ",", "col_item", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Columns in provided DataFrames are not the same datatype\"", ")", "\n", "\n", "", "count_intersection", "=", "pd", ".", "merge", "(", "\n", "train_df", ",", "reco_df", ",", "how", "=", "\"inner\"", ",", "on", "=", "[", "col_user", ",", "col_item", "]", "\n", ")", ".", "shape", "[", "0", "]", "\n", "if", "count_intersection", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"reco_df should not contain any user_item pairs that are already shown in train_df\"", "\n", ")", "\n", "\n", "", "return", "func", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "col_user", "=", "col_user", ",", "\n", "col_item", "=", "col_item", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "", "return", "check_column_dtypes_novelty_coverage_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._get_pairwise_items": [[870, 889], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "pandas.merge", "[].reset_index"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "_get_pairwise_items", "(", "\n", "df", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get pairwise combinations of items per user (ignoring duplicate pairs [1,2] == [2,1])\"\"\"", "\n", "df_user_i1", "=", "df", "[", "[", "col_user", ",", "col_item", "]", "]", "\n", "df_user_i1", ".", "columns", "=", "[", "col_user", ",", "\"i1\"", "]", "\n", "\n", "df_user_i2", "=", "df", "[", "[", "col_user", ",", "col_item", "]", "]", "\n", "df_user_i2", ".", "columns", "=", "[", "col_user", ",", "\"i2\"", "]", "\n", "\n", "df_user_i1_i2", "=", "pd", ".", "merge", "(", "df_user_i1", ",", "df_user_i2", ",", "how", "=", "\"inner\"", ",", "on", "=", "[", "col_user", "]", ")", "\n", "\n", "df_pairwise_items", "=", "df_user_i1_i2", "[", "(", "df_user_i1_i2", "[", "\"i1\"", "]", "<=", "df_user_i1_i2", "[", "\"i2\"", "]", ")", "]", "[", "\n", "[", "col_user", ",", "\"i1\"", ",", "\"i2\"", "]", "\n", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "return", "df_pairwise_items", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._get_cosine_similarity": [[891, 917], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation._get_cooccurrence_similarity", "python_evaluation._get_item_feature_similarity", "Exception"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cooccurrence_similarity", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_item_feature_similarity"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "_get_cosine_similarity", "(", "\n", "train_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", ")", ":", "\n", "\n", "    ", "if", "item_sim_measure", "==", "\"item_cooccurrence_count\"", ":", "\n", "# calculate item-item similarity based on item co-occurrence count", "\n", "        ", "df_cosine_similarity", "=", "_get_cooccurrence_similarity", "(", "\n", "train_df", ",", "col_user", ",", "col_item", ",", "col_sim", "\n", ")", "\n", "", "elif", "item_sim_measure", "==", "\"item_feature_vector\"", ":", "\n", "# calculdf_cosine_similarity = ate item-item similarity based on item feature vectors", "\n", "        ", "df_cosine_similarity", "=", "_get_item_feature_similarity", "(", "\n", "item_feature_df", ",", "col_item_features", ",", "col_user", ",", "col_item", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"item_sim_measure not recognized! The available options include 'item_cooccurrence_count' and 'item_feature_vector'.\"", "\n", ")", "\n", "", "return", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._get_cooccurrence_similarity": [[919, 974], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation._get_pairwise_items", "pandas.DataFrame().reset_index", "pandas.DataFrame().reset_index", "pd.DataFrame().reset_index.merge().drop", "item_co_occur.merge().drop.merge().drop", "item_co_occur[].sort_values().reset_index", "pandas.DataFrame", "pandas.DataFrame", "pd.DataFrame().reset_index.merge", "item_co_occur.merge().drop.merge", "item_co_occur[].sort_values", "_get_pairwise_items.groupby().size", "train_df.groupby().size", "_get_pairwise_items.groupby", "train_df.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_pairwise_items"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "_get_cooccurrence_similarity", "(", "\n", "train_df", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Cosine similarity metric from\n\n    :Citation:\n\n        Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n        introducing serendipity into music recommendation, WSDM 2012\n\n    The item indexes in the result are such that i1 <= i2.\n    \"\"\"", "\n", "pairs", "=", "_get_pairwise_items", "(", "train_df", ",", "col_user", ",", "col_item", ")", "\n", "pairs_count", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"count\"", ":", "pairs", ".", "groupby", "(", "[", "\"i1\"", ",", "\"i2\"", "]", ")", ".", "size", "(", ")", "}", "\n", ")", ".", "reset_index", "(", ")", "\n", "item_count", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"count\"", ":", "train_df", ".", "groupby", "(", "[", "col_item", "]", ")", ".", "size", "(", ")", "}", "\n", ")", ".", "reset_index", "(", ")", "\n", "item_count", "[", "\"item_sqrt_count\"", "]", "=", "item_count", "[", "\"count\"", "]", "**", "0.5", "\n", "item_co_occur", "=", "pairs_count", ".", "merge", "(", "\n", "item_count", "[", "[", "col_item", ",", "\"item_sqrt_count\"", "]", "]", ",", "\n", "left_on", "=", "[", "\"i1\"", "]", ",", "\n", "right_on", "=", "[", "col_item", "]", ",", "\n", ")", ".", "drop", "(", "columns", "=", "[", "col_item", "]", ")", "\n", "\n", "item_co_occur", ".", "columns", "=", "[", "\"i1\"", ",", "\"i2\"", ",", "\"count\"", ",", "\"i1_sqrt_count\"", "]", "\n", "\n", "item_co_occur", "=", "item_co_occur", ".", "merge", "(", "\n", "item_count", "[", "[", "col_item", ",", "\"item_sqrt_count\"", "]", "]", ",", "\n", "left_on", "=", "[", "\"i2\"", "]", ",", "\n", "right_on", "=", "[", "col_item", "]", ",", "\n", ")", ".", "drop", "(", "columns", "=", "[", "col_item", "]", ")", "\n", "item_co_occur", ".", "columns", "=", "[", "\n", "\"i1\"", ",", "\n", "\"i2\"", ",", "\n", "\"count\"", ",", "\n", "\"i1_sqrt_count\"", ",", "\n", "\"i2_sqrt_count\"", ",", "\n", "]", "\n", "\n", "item_co_occur", "[", "col_sim", "]", "=", "item_co_occur", "[", "\"count\"", "]", "/", "(", "\n", "item_co_occur", "[", "\"i1_sqrt_count\"", "]", "*", "item_co_occur", "[", "\"i2_sqrt_count\"", "]", "\n", ")", "\n", "df_cosine_similarity", "=", "(", "\n", "item_co_occur", "[", "[", "\"i1\"", ",", "\"i2\"", ",", "col_sim", "]", "]", "\n", ".", "sort_values", "(", "[", "\"i1\"", ",", "\"i2\"", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "return", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._get_item_feature_similarity": [[976, 1009], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "pandas.merge().drop", "df[].reset_index", "df[].reset_index.apply", "df_item_feature_pair[].sort_values", "pandas.merge", "float", "float", "x.f1.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "_get_item_feature_similarity", "(", "\n", "item_feature_df", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Cosine similarity metric based on item feature vectors\n\n    The item indexes in the result are such that i1 <= i2.\n    \"\"\"", "\n", "df1", "=", "item_feature_df", "[", "[", "col_item", ",", "col_item_features", "]", "]", "\n", "df1", ".", "columns", "=", "[", "\"i1\"", ",", "\"f1\"", "]", "\n", "df1", "[", "\"key\"", "]", "=", "0", "\n", "df2", "=", "item_feature_df", "[", "[", "col_item", ",", "col_item_features", "]", "]", "\n", "df2", ".", "columns", "=", "[", "\"i2\"", ",", "\"f2\"", "]", "\n", "df2", "[", "\"key\"", "]", "=", "0", "\n", "\n", "df", "=", "pd", ".", "merge", "(", "df1", ",", "df2", ",", "on", "=", "\"key\"", ",", "how", "=", "\"outer\"", ")", ".", "drop", "(", "\"key\"", ",", "axis", "=", "1", ")", "\n", "df_item_feature_pair", "=", "df", "[", "(", "df", "[", "\"i1\"", "]", "<=", "df", "[", "\"i2\"", "]", ")", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "df_item_feature_pair", "[", "col_sim", "]", "=", "df_item_feature_pair", ".", "apply", "(", "\n", "lambda", "x", ":", "float", "(", "x", ".", "f1", ".", "dot", "(", "x", ".", "f2", ")", ")", "\n", "/", "float", "(", "np", ".", "linalg", ".", "norm", "(", "x", ".", "f1", ",", "2", ")", "*", "np", ".", "linalg", ".", "norm", "(", "x", ".", "f2", ",", "2", ")", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "df_cosine_similarity", "=", "df_item_feature_pair", "[", "[", "\"i1\"", ",", "\"i2\"", ",", "col_sim", "]", "]", ".", "sort_values", "(", "\n", "[", "\"i1\"", ",", "\"i2\"", "]", "\n", ")", "\n", "\n", "return", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._get_intralist_similarity": [[1012, 1054], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation._get_pairwise_items", "python_evaluation._get_cosine_similarity", "_get_pairwise_items.merge", "item_pair_sim[].fillna", "item_pair_sim.loc[].reset_index.loc[].reset_index", "item_pair_sim.loc[].reset_index.groupby().agg().reset_index", "item_pair_sim.loc[].reset_index.groupby().agg", "item_pair_sim.loc[].reset_index.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_pairwise_items", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "_get_intralist_similarity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Intra-list similarity from\n\n    :Citation:\n\n        \"Improving Recommendation Lists Through Topic Diversification\",\n        Ziegler, McNee, Konstan and Lausen, 2005.\n    \"\"\"", "\n", "pairs", "=", "_get_pairwise_items", "(", "reco_df", ",", "col_user", ",", "col_item", ")", "\n", "similarity_df", "=", "_get_cosine_similarity", "(", "\n", "train_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", ")", "\n", "# Fillna(0) is needed in the cases where similarity_df does not have an entry for a pair of items.", "\n", "# e.g. i1 and i2 have never occurred together.", "\n", "\n", "item_pair_sim", "=", "pairs", ".", "merge", "(", "similarity_df", ",", "on", "=", "[", "\"i1\"", ",", "\"i2\"", "]", ",", "how", "=", "\"left\"", ")", "\n", "item_pair_sim", "[", "col_sim", "]", ".", "fillna", "(", "0", ",", "inplace", "=", "True", ")", "\n", "item_pair_sim", "=", "item_pair_sim", ".", "loc", "[", "\n", "item_pair_sim", "[", "\"i1\"", "]", "!=", "item_pair_sim", "[", "\"i2\"", "]", "\n", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "df_intralist_similarity", "=", "(", "\n", "item_pair_sim", ".", "groupby", "(", "[", "col_user", "]", ")", ".", "agg", "(", "{", "col_sim", ":", "\"mean\"", "}", ")", ".", "reset_index", "(", ")", "\n", ")", "\n", "df_intralist_similarity", ".", "columns", "=", "[", "col_user", ",", "\"avg_il_sim\"", "]", "\n", "\n", "return", "df_intralist_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.user_diversity": [[1056, 1115], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation._get_intralist_similarity", "df_user_diversity[].sort_values().reset_index", "df_user_diversity[].sort_values"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_intralist_similarity"], ["", "@", "_check_column_dtypes_diversity_serendipity", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "user_diversity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate average diversity of recommendations for each user.\n    The metric definition is based on formula (3) in the following reference:\n\n    :Citation:\n\n        Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n        introducing serendipity into music recommendation, WSDM 2012\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they have interacted with;\n            contains col_user, col_item. Assumed to not contain any duplicate rows.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item, col_relevance (optional).\n            Assumed to not contain any duplicate user-item pairs.\n        item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n            It contains two columns: col_item and features (a feature vector).\n        item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n            Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n        col_item_features (str): item feature column name.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n        col_sim (str): This column indicates the column name for item similarity.\n        col_relevance (str): This column indicates whether the recommended item is actually relevant to the user or not.\n\n    Returns:\n        pandas.DataFrame: A dataframe with the following columns: col_user, user_diversity.\n    \"\"\"", "\n", "\n", "df_intralist_similarity", "=", "_get_intralist_similarity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", ")", "\n", "df_user_diversity", "=", "df_intralist_similarity", "\n", "df_user_diversity", "[", "\"user_diversity\"", "]", "=", "1", "-", "df_user_diversity", "[", "\"avg_il_sim\"", "]", "\n", "df_user_diversity", "=", "(", "\n", "df_user_diversity", "[", "[", "col_user", ",", "\"user_diversity\"", "]", "]", "\n", ".", "sort_values", "(", "col_user", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "return", "df_user_diversity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.diversity": [[1117, 1161], ["python_evaluation.user_diversity", "user_diversity.agg"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "@", "_check_column_dtypes_diversity_serendipity", "\n", "def", "diversity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate average diversity of recommendations across all users.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they have interacted with;\n            contains col_user, col_item. Assumed to not contain any duplicate rows.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item, col_relevance (optional).\n            Assumed to not contain any duplicate user-item pairs.\n        item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n            It contains two columns: col_item and features (a feature vector).\n        item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n            Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n        col_item_features (str): item feature column name.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n        col_sim (str): This column indicates the column name for item similarity.\n        col_relevance (str): This column indicates whether the recommended item is actually relevant to the user or not.\n\n    Returns:\n        float: diversity.\n    \"\"\"", "\n", "df_user_diversity", "=", "user_diversity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", ")", "\n", "avg_diversity", "=", "df_user_diversity", ".", "agg", "(", "{", "\"user_diversity\"", ":", "\"mean\"", "}", ")", "[", "0", "]", "\n", "return", "avg_diversity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.historical_item_novelty": [[1164, 1212], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "pandas.DataFrame().reset_index", "item_count[].sort_values().reset_index", "numpy.log2", "pandas.DataFrame", "item_count[].sort_values", "train_df.groupby().size", "train_df.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df"], ["", "@", "_check_column_dtypes_novelty_coverage", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "historical_item_novelty", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate novelty for each item. Novelty is computed as the minus logarithm of\n    (number of interactions with item / total number of interactions). The definition of the metric\n    is based on the following reference using the choice model (eqs. 1 and 6):\n\n    :Citation:\n\n        P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems:\n        choice, discovery and relevance, ECIR 2011\n\n    The novelty of an item can be defined relative to a set of observed events on the set of all items.\n    These can be events of user choice (item \"is picked\" by a random user) or user discovery\n    (item \"is known\" to a random user). The above definition of novelty reflects a factor of item popularity.\n    High novelty values correspond to long-tail items in the density function, that few users have interacted\n    with and low novelty values correspond to popular head items.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n\n    Returns:\n        pandas.DataFrame: A dataframe with the following columns: col_item, item_novelty.\n    \"\"\"", "\n", "\n", "n_records", "=", "train_df", ".", "shape", "[", "0", "]", "\n", "item_count", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"count\"", ":", "train_df", ".", "groupby", "(", "[", "col_item", "]", ")", ".", "size", "(", ")", "}", "\n", ")", ".", "reset_index", "(", ")", "\n", "item_count", "[", "\"item_novelty\"", "]", "=", "-", "np", ".", "log2", "(", "item_count", "[", "\"count\"", "]", "/", "n_records", ")", "\n", "df_item_novelty", "=", "(", "\n", "item_count", "[", "[", "col_item", ",", "\"item_novelty\"", "]", "]", "\n", ".", "sort_values", "(", "col_item", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "return", "df_item_novelty", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.novelty": [[1214, 1249], ["python_evaluation.historical_item_novelty", "pandas.DataFrame().reset_index", "pd.DataFrame().reset_index.merge", "pandas.DataFrame", "reco_item_count.merge.agg", "reco_df.groupby().size", "reco_df.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty"], ["", "@", "_check_column_dtypes_novelty_coverage", "\n", "def", "novelty", "(", "train_df", ",", "reco_df", ",", "col_user", "=", "DEFAULT_USER_COL", ",", "col_item", "=", "DEFAULT_ITEM_COL", ")", ":", "\n", "    ", "\"\"\"Calculate the average novelty in a list of recommended items (this assumes that the recommendation list\n    is already computed). Follows section 5 from\n\n    :Citation:\n\n        P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems:\n        choice, discovery and relevance, ECIR 2011\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n\n    Returns:\n        float: novelty.\n    \"\"\"", "\n", "\n", "df_item_novelty", "=", "historical_item_novelty", "(", "train_df", ",", "reco_df", ",", "col_user", ",", "col_item", ")", "\n", "n_recommendations", "=", "reco_df", ".", "shape", "[", "0", "]", "\n", "reco_item_count", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"count\"", ":", "reco_df", ".", "groupby", "(", "[", "col_item", "]", ")", ".", "size", "(", ")", "}", "\n", ")", ".", "reset_index", "(", ")", "\n", "reco_item_novelty", "=", "reco_item_count", ".", "merge", "(", "df_item_novelty", ",", "on", "=", "col_item", ")", "\n", "reco_item_novelty", "[", "\"product\"", "]", "=", "(", "\n", "reco_item_novelty", "[", "\"count\"", "]", "*", "reco_item_novelty", "[", "\"item_novelty\"", "]", "\n", ")", "\n", "avg_novelty", "=", "reco_item_novelty", ".", "agg", "(", "{", "\"product\"", ":", "\"sum\"", "}", ")", "[", "0", "]", "/", "n_recommendations", "\n", "\n", "return", "avg_novelty", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.user_item_serendipity": [[1252, 1348], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation._get_cosine_similarity", "reco_user_item.merge", "reco_train_user_item[].min", "reco_train_user_item[].max", "reco_user_item.merge.merge", "reco_train_user_item_sim[].fillna", "reco_train_user_item.merge.groupby().agg().reset_index", "reco_train_user_item_sim.groupby().agg().reset_index.merge", "df_user_item_serendipity[].sort_values().reset_index", "reco_train_user_item.merge.groupby().agg", "df_user_item_serendipity[].sort_values", "reco_train_user_item.merge.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity"], ["", "@", "_check_column_dtypes_diversity_serendipity", "\n", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "def", "user_item_serendipity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate serendipity of each item in the recommendations for each user.\n    The metric definition is based on the following references:\n\n    :Citation:\n\n    Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n    introducing serendipity into music recommendation, WSDM 2012\n\n    Eugene Yan, Serendipity: Accuracy\u2019s unpopular best friend in Recommender Systems,\n    eugeneyan.com, April 2020\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n              have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n              col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n            It contains two columns: col_item and features (a feature vector).\n        item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n            Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n        col_item_features (str): item feature column name.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n        col_sim (str): This column indicates the column name for item similarity.\n        col_relevance (str): This column indicates whether the recommended item is actually\n              relevant to the user or not.\n    Returns:\n        pandas.DataFrame: A dataframe with columns: col_user, col_item, user_item_serendipity.\n    \"\"\"", "\n", "# for every col_user, col_item in reco_df, join all interacted items from train_df.", "\n", "# These interacted items are repeated for each item in reco_df for a specific user.", "\n", "df_cosine_similarity", "=", "_get_cosine_similarity", "(", "\n", "train_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", ")", "\n", "reco_user_item", "=", "reco_df", "[", "[", "col_user", ",", "col_item", "]", "]", "\n", "reco_user_item", "[", "\"reco_item_tmp\"", "]", "=", "reco_user_item", "[", "col_item", "]", "\n", "\n", "train_user_item", "=", "train_df", "[", "[", "col_user", ",", "col_item", "]", "]", "\n", "train_user_item", ".", "columns", "=", "[", "col_user", ",", "\"train_item_tmp\"", "]", "\n", "\n", "reco_train_user_item", "=", "reco_user_item", ".", "merge", "(", "train_user_item", ",", "on", "=", "[", "col_user", "]", ")", "\n", "reco_train_user_item", "[", "\"i1\"", "]", "=", "reco_train_user_item", "[", "\n", "[", "\"reco_item_tmp\"", ",", "\"train_item_tmp\"", "]", "\n", "]", ".", "min", "(", "axis", "=", "1", ")", "\n", "reco_train_user_item", "[", "\"i2\"", "]", "=", "reco_train_user_item", "[", "\n", "[", "\"reco_item_tmp\"", ",", "\"train_item_tmp\"", "]", "\n", "]", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "reco_train_user_item_sim", "=", "reco_train_user_item", ".", "merge", "(", "\n", "df_cosine_similarity", ",", "on", "=", "[", "\"i1\"", ",", "\"i2\"", "]", ",", "how", "=", "\"left\"", "\n", ")", "\n", "reco_train_user_item_sim", "[", "col_sim", "]", ".", "fillna", "(", "0", ",", "inplace", "=", "True", ")", "\n", "\n", "reco_user_item_avg_sim", "=", "(", "\n", "reco_train_user_item_sim", ".", "groupby", "(", "[", "col_user", ",", "col_item", "]", ")", "\n", ".", "agg", "(", "{", "col_sim", ":", "\"mean\"", "}", ")", "\n", ".", "reset_index", "(", ")", "\n", ")", "\n", "reco_user_item_avg_sim", ".", "columns", "=", "[", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "\"avg_item2interactedHistory_sim\"", ",", "\n", "]", "\n", "\n", "df_user_item_serendipity", "=", "reco_user_item_avg_sim", ".", "merge", "(", "\n", "reco_df", ",", "on", "=", "[", "col_user", ",", "col_item", "]", "\n", ")", "\n", "df_user_item_serendipity", "[", "\"user_item_serendipity\"", "]", "=", "(", "\n", "1", "-", "df_user_item_serendipity", "[", "\"avg_item2interactedHistory_sim\"", "]", "\n", ")", "*", "df_user_item_serendipity", "[", "col_relevance", "]", "\n", "df_user_item_serendipity", "=", "(", "\n", "df_user_item_serendipity", "[", "[", "col_user", ",", "col_item", ",", "\"user_item_serendipity\"", "]", "]", "\n", ".", "sort_values", "(", "[", "col_user", ",", "col_item", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "return", "df_user_item_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.user_serendipity": [[1350, 1405], ["recommenders.datasets.pandas_df_utils.lru_cache_df", "python_evaluation.user_item_serendipity", "user_item_serendipity.groupby().agg().reset_index", "df_user_serendipity.sort_values().reset_index.sort_values().reset_index", "user_item_serendipity.groupby().agg", "df_user_serendipity.sort_values().reset_index.sort_values", "user_item_serendipity.groupby"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.pandas_df_utils.lru_cache_df", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "@", "lru_cache_df", "(", "maxsize", "=", "1", ")", "\n", "@", "_check_column_dtypes_diversity_serendipity", "\n", "def", "user_serendipity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate average serendipity for each user's recommendations.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n              have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n              col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n            It contains two columns: col_item and features (a feature vector).\n        item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n            Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n        col_item_features (str): item feature column name.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n        col_sim (str): This column indicates the column name for item similarity.\n        col_relevance (str): This column indicates whether the recommended item is actually\n              relevant to the user or not.\n    Returns:\n        pandas.DataFrame: A dataframe with following columns: col_user, user_serendipity.\n    \"\"\"", "\n", "df_user_item_serendipity", "=", "user_item_serendipity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", "col_relevance", ",", "\n", ")", "\n", "df_user_serendipity", "=", "(", "\n", "df_user_item_serendipity", ".", "groupby", "(", "col_user", ")", "\n", ".", "agg", "(", "{", "\"user_item_serendipity\"", ":", "\"mean\"", "}", ")", "\n", ".", "reset_index", "(", ")", "\n", ")", "\n", "df_user_serendipity", ".", "columns", "=", "[", "col_user", ",", "\"user_serendipity\"", "]", "\n", "df_user_serendipity", "=", "df_user_serendipity", ".", "sort_values", "(", "col_user", ")", ".", "reset_index", "(", "\n", "drop", "=", "True", "\n", ")", "\n", "\n", "return", "df_user_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.serendipity": [[1407, 1452], ["python_evaluation.user_serendipity", "user_serendipity.agg"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "@", "_check_column_dtypes_diversity_serendipity", "\n", "def", "serendipity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_sim", "=", "DEFAULT_SIMILARITY_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate average serendipity for recommendations across all users.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n              have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n              col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        item_feature_df (pandas.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n            It contains two columns: col_item and features (a feature vector).\n        item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n            Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n        col_item_features (str): item feature column name.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n        col_sim (str): This column indicates the column name for item similarity.\n        col_relevance (str): This column indicates whether the recommended item is actually\n              relevant to the user or not.\n    Returns:\n        float: serendipity.\n    \"\"\"", "\n", "df_user_serendipity", "=", "user_serendipity", "(", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", ",", "\n", "item_sim_measure", ",", "\n", "col_item_features", ",", "\n", "col_user", ",", "\n", "col_item", ",", "\n", "col_sim", ",", "\n", "col_relevance", ",", "\n", ")", "\n", "avg_serendipity", "=", "df_user_serendipity", ".", "agg", "(", "{", "\"user_serendipity\"", ":", "\"mean\"", "}", ")", "[", "0", "]", "\n", "return", "avg_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.catalog_coverage": [[1455, 1487], ["reco_df[].nunique", "train_df[].nunique"], "function", ["None"], ["", "@", "_check_column_dtypes_novelty_coverage", "\n", "def", "catalog_coverage", "(", "\n", "train_df", ",", "reco_df", ",", "col_user", "=", "DEFAULT_USER_COL", ",", "col_item", "=", "DEFAULT_ITEM_COL", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate catalog coverage for recommendations across all users.\n    The metric definition is based on the \"catalog coverage\" definition in the following reference:\n\n    :Citation:\n\n        G. Shani and A. Gunawardana, Evaluating Recommendation Systems,\n        Recommender Systems Handbook pp. 257-297, 2010.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n\n    Returns:\n        float: catalog coverage\n    \"\"\"", "\n", "# distinct item count in reco_df", "\n", "count_distinct_item_reco", "=", "reco_df", "[", "col_item", "]", ".", "nunique", "(", ")", "\n", "# distinct item count in train_df", "\n", "count_distinct_item_train", "=", "train_df", "[", "col_item", "]", ".", "nunique", "(", ")", "\n", "\n", "# catalog coverage", "\n", "c_coverage", "=", "count_distinct_item_reco", "/", "count_distinct_item_train", "\n", "return", "c_coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.distributional_coverage": [[1489, 1528], ["pandas.DataFrame().reset_index", "numpy.log2", "pandas.DataFrame", "df_entropy.agg", "reco_df.groupby().size", "reco_df.groupby"], "function", ["None"], ["", "@", "_check_column_dtypes_novelty_coverage", "\n", "def", "distributional_coverage", "(", "\n", "train_df", ",", "reco_df", ",", "col_user", "=", "DEFAULT_USER_COL", ",", "col_item", "=", "DEFAULT_ITEM_COL", "\n", ")", ":", "\n", "    ", "\"\"\"Calculate distributional coverage for recommendations across all users.\n    The metric definition is based on formula (21) in the following reference:\n\n    :Citation:\n\n        G. Shani and A. Gunawardana, Evaluating Recommendation Systems,\n        Recommender Systems Handbook pp. 257-297, 2010.\n\n    Args:\n        train_df (pandas.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n        reco_df (pandas.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n        col_user (str): User id column name.\n        col_item (str): Item id column name.\n\n    Returns:\n        float: distributional coverage\n    \"\"\"", "\n", "# In reco_df, how  many times each col_item is being recommended", "\n", "df_itemcnt_reco", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"count\"", ":", "reco_df", ".", "groupby", "(", "[", "col_item", "]", ")", ".", "size", "(", ")", "}", "\n", ")", ".", "reset_index", "(", ")", "\n", "\n", "# the number of total recommendations", "\n", "count_row_reco", "=", "reco_df", ".", "shape", "[", "0", "]", "\n", "\n", "df_entropy", "=", "df_itemcnt_reco", "\n", "df_entropy", "[", "\"p(i)\"", "]", "=", "df_entropy", "[", "\"count\"", "]", "/", "count_row_reco", "\n", "df_entropy", "[", "\"entropy(i)\"", "]", "=", "df_entropy", "[", "\"p(i)\"", "]", "*", "np", ".", "log2", "(", "df_entropy", "[", "\"p(i)\"", "]", ")", "\n", "\n", "d_coverage", "=", "-", "df_entropy", ".", "agg", "(", "{", "\"entropy(i)\"", ":", "\"sum\"", "}", ")", "[", "0", "]", "\n", "\n", "return", "d_coverage", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.__init__": [[34, 123], ["spark_evaluation.SparkRatingEvaluation.rating_true.select", "spark_evaluation.SparkRatingEvaluation.rating_pred.select", "spark_evaluation.SparkRatingEvaluation.rating_true.join().drop().drop", "RegressionMetrics", "isinstance", "TypeError", "isinstance", "TypeError", "rating_true.count", "ValueError", "rating_pred.count", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "col", "col", "col().cast().alias", "col", "col", "col().cast().alias", "spark_evaluation.SparkRatingEvaluation.y_pred_true.rdd.map", "spark_evaluation.SparkRatingEvaluation.rating_true.join().drop", "col().cast", "col().cast", "spark_evaluation.SparkRatingEvaluation.rating_true.join", "col", "col"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializer.\n\n        This is the Spark version of rating metrics evaluator.\n        The methods of this class, calculate rating metrics such as root mean squared error, mean absolute error,\n        R squared, and explained variance.\n\n        Args:\n            rating_true (pyspark.sql.DataFrame): True labels.\n            rating_pred (pyspark.sql.DataFrame): Predicted labels.\n            col_user (str): column name for user.\n            col_item (str): column name for item.\n            col_rating (str): column name for rating.\n            col_prediction (str): column name for prediction.\n        \"\"\"", "\n", "self", ".", "rating_true", "=", "rating_true", "\n", "self", ".", "rating_pred", "=", "rating_pred", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_prediction", "=", "col_prediction", "\n", "\n", "# Check if inputs are Spark DataFrames.", "\n", "if", "not", "isinstance", "(", "self", ".", "rating_true", ",", "DataFrame", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"rating_true should be but is not a Spark DataFrame\"", "\n", ")", "# pragma : No Cover", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "rating_pred", ",", "DataFrame", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"rating_pred should be but is not a Spark DataFrame\"", "\n", ")", "# pragma : No Cover", "\n", "\n", "# Check if columns exist.", "\n", "", "true_columns", "=", "self", ".", "rating_true", ".", "columns", "\n", "pred_columns", "=", "self", ".", "rating_pred", ".", "columns", "\n", "\n", "if", "rating_true", ".", "count", "(", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Empty input dataframe\"", ")", "\n", "", "if", "rating_pred", ".", "count", "(", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Empty input dataframe\"", ")", "\n", "\n", "", "if", "self", ".", "col_user", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_true not valid. Missing User Col\"", ")", "\n", "", "if", "self", ".", "col_item", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_true not valid. Missing Item Col\"", ")", "\n", "", "if", "self", ".", "col_rating", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_true not valid. Missing Rating Col\"", ")", "\n", "\n", "", "if", "self", ".", "col_user", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Schema of rating_pred not valid. Missing User Col\"", "\n", ")", "# pragma : No Cover", "\n", "", "if", "self", ".", "col_item", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Schema of rating_pred not valid. Missing Item Col\"", "\n", ")", "# pragma : No Cover", "\n", "", "if", "self", ".", "col_prediction", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_pred not valid. Missing Prediction Col\"", ")", "\n", "\n", "", "self", ".", "rating_true", "=", "self", ".", "rating_true", ".", "select", "(", "\n", "col", "(", "self", ".", "col_user", ")", ",", "\n", "col", "(", "self", ".", "col_item", ")", ",", "\n", "col", "(", "self", ".", "col_rating", ")", ".", "cast", "(", "\"double\"", ")", ".", "alias", "(", "\"label\"", ")", ",", "\n", ")", "\n", "self", ".", "rating_pred", "=", "self", ".", "rating_pred", ".", "select", "(", "\n", "col", "(", "self", ".", "col_user", ")", ",", "\n", "col", "(", "self", ".", "col_item", ")", ",", "\n", "col", "(", "self", ".", "col_prediction", ")", ".", "cast", "(", "\"double\"", ")", ".", "alias", "(", "\"prediction\"", ")", ",", "\n", ")", "\n", "\n", "self", ".", "y_pred_true", "=", "(", "\n", "self", ".", "rating_true", ".", "join", "(", "\n", "self", ".", "rating_pred", ",", "[", "self", ".", "col_user", ",", "self", ".", "col_item", "]", ",", "\"inner\"", "\n", ")", "\n", ".", "drop", "(", "self", ".", "col_user", ")", "\n", ".", "drop", "(", "self", ".", "col_item", ")", "\n", ")", "\n", "\n", "self", ".", "metrics", "=", "RegressionMetrics", "(", "\n", "self", ".", "y_pred_true", ".", "rdd", ".", "map", "(", "lambda", "x", ":", "(", "x", ".", "prediction", ",", "x", ".", "label", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse": [[125, 132], ["None"], "methods", ["None"], ["", "def", "rmse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate Root Mean Squared Error.\n\n        Returns:\n            float: Root mean squared error.\n        \"\"\"", "\n", "return", "self", ".", "metrics", ".", "rootMeanSquaredError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae": [[133, 140], ["None"], "methods", ["None"], ["", "def", "mae", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate Mean Absolute Error.\n\n        Returns:\n            float: Mean Absolute Error.\n        \"\"\"", "\n", "return", "self", ".", "metrics", ".", "meanAbsoluteError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared": [[141, 148], ["None"], "methods", ["None"], ["", "def", "rsquared", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate R squared.\n\n        Returns:\n            float: R squared.\n        \"\"\"", "\n", "return", "self", ".", "metrics", ".", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var": [[149, 164], ["numpy.divide", "spark_evaluation.SparkRatingEvaluation.y_pred_true.selectExpr().collect", "spark_evaluation.SparkRatingEvaluation.y_pred_true.selectExpr().collect", "spark_evaluation.SparkRatingEvaluation.y_pred_true.selectExpr", "spark_evaluation.SparkRatingEvaluation.y_pred_true.selectExpr"], "methods", ["None"], ["", "def", "exp_var", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate explained variance.\n\n        .. note::\n           Spark MLLib's implementation is buggy (can lead to values > 1), hence we use var().\n\n        Returns:\n            float: Explained variance (min=0, max=1).\n        \"\"\"", "\n", "var1", "=", "self", ".", "y_pred_true", ".", "selectExpr", "(", "\"variance(label - prediction)\"", ")", ".", "collect", "(", ")", "[", "0", "]", "[", "\n", "0", "\n", "]", "\n", "var2", "=", "self", ".", "y_pred_true", ".", "selectExpr", "(", "\"variance(label)\"", ")", ".", "collect", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "# numpy divide is more tolerant to var2 being zero", "\n", "return", "1", "-", "np", ".", "divide", "(", "var1", ",", "var2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.__init__": [[169, 284], ["spark_evaluation.SparkRankingEvaluation._calculate_metrics", "isinstance", "TypeError", "isinstance", "TypeError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "str", "list", "relevant_func.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation._calculate_metrics"], ["def", "__init__", "(", "\n", "self", ",", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialization.\n        This is the Spark version of ranking metrics evaluator.\n        The methods of this class, calculate ranking metrics such as precision@k, recall@k, ndcg@k, and mean average\n        precision.\n\n        The implementations of precision@k, ndcg@k, and mean average precision are referenced from Spark MLlib, which\n        can be found at `here <https://spark.apache.org/docs/2.3.0/mllib-evaluation-metrics.html#ranking-systems>`_.\n\n        Args:\n            rating_true (pyspark.sql.DataFrame): DataFrame of true rating data (in the\n                format of customerID-itemID-rating tuple).\n            rating_pred (pyspark.sql.DataFrame): DataFrame of predicted rating data (in\n                the format of customerID-itemID-rating tuple).\n            col_user (str): column name for user.\n            col_item (str): column name for item.\n            col_rating (str): column name for rating.\n            col_prediction (str): column name for prediction.\n            k (int): number of items to recommend to each user.\n            relevancy_method (str): method for determining relevant items. Possible\n                values are \"top_k\", \"by_time_stamp\", and \"by_threshold\".\n            threshold (float): threshold for determining the relevant recommended items.\n                This is used for the case that predicted ratings follow a known\n                distribution. NOTE: this option is only activated if relevancy_method is\n                set to \"by_threshold\".\n        \"\"\"", "\n", "self", ".", "rating_true", "=", "rating_true", "\n", "self", ".", "rating_pred", "=", "rating_pred", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "col_rating", "=", "col_rating", "\n", "self", ".", "col_prediction", "=", "col_prediction", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n", "# Check if inputs are Spark DataFrames.", "\n", "if", "not", "isinstance", "(", "self", ".", "rating_true", ",", "DataFrame", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"rating_true should be but is not a Spark DataFrame\"", "\n", ")", "# pragma : No Cover", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "rating_pred", ",", "DataFrame", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"rating_pred should be but is not a Spark DataFrame\"", "\n", ")", "# pragma : No Cover", "\n", "\n", "# Check if columns exist.", "\n", "", "true_columns", "=", "self", ".", "rating_true", ".", "columns", "\n", "pred_columns", "=", "self", ".", "rating_pred", ".", "columns", "\n", "\n", "if", "self", ".", "col_user", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Schema of rating_true not valid. Missing User Col: \"", "\n", "+", "str", "(", "true_columns", ")", "\n", ")", "\n", "", "if", "self", ".", "col_item", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_true not valid. Missing Item Col\"", ")", "\n", "", "if", "self", ".", "col_rating", "not", "in", "true_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_true not valid. Missing Rating Col\"", ")", "\n", "\n", "", "if", "self", ".", "col_user", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Schema of rating_pred not valid. Missing User Col\"", "\n", ")", "# pragma : No Cover", "\n", "", "if", "self", ".", "col_item", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Schema of rating_pred not valid. Missing Item Col\"", "\n", ")", "# pragma : No Cover", "\n", "", "if", "self", ".", "col_prediction", "not", "in", "pred_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\"Schema of rating_pred not valid. Missing Prediction Col\"", ")", "\n", "\n", "", "self", ".", "k", "=", "k", "\n", "\n", "relevant_func", "=", "{", "\n", "\"top_k\"", ":", "_get_top_k_items", ",", "\n", "\"by_time_stamp\"", ":", "_get_relevant_items_by_timestamp", ",", "\n", "\"by_threshold\"", ":", "_get_relevant_items_by_threshold", ",", "\n", "}", "\n", "\n", "if", "relevancy_method", "not", "in", "relevant_func", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"relevancy_method should be one of {}\"", ".", "format", "(", "\n", "list", "(", "relevant_func", ".", "keys", "(", ")", ")", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "rating_pred", "=", "(", "\n", "relevant_func", "[", "relevancy_method", "]", "(", "\n", "dataframe", "=", "self", ".", "rating_pred", ",", "\n", "col_user", "=", "self", ".", "col_user", ",", "\n", "col_item", "=", "self", ".", "col_item", ",", "\n", "col_rating", "=", "self", ".", "col_prediction", ",", "\n", "threshold", "=", "self", ".", "threshold", ",", "\n", ")", "\n", "if", "relevancy_method", "==", "\"by_threshold\"", "\n", "else", "relevant_func", "[", "relevancy_method", "]", "(", "\n", "dataframe", "=", "self", ".", "rating_pred", ",", "\n", "col_user", "=", "self", ".", "col_user", ",", "\n", "col_item", "=", "self", ".", "col_item", ",", "\n", "col_rating", "=", "self", ".", "col_prediction", ",", "\n", "k", "=", "self", ".", "k", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "_metrics", "=", "self", ".", "_calculate_metrics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation._calculate_metrics": [[285, 300], ["spark_evaluation.SparkRankingEvaluation.rating_true.groupBy().agg().select", "spark_evaluation.SparkRankingEvaluation._items_for_user_pred.join().drop", "RankingMetrics", "spark_evaluation.SparkRankingEvaluation.rating_true.groupBy().agg", "spark_evaluation.SparkRankingEvaluation._items_for_user_pred.join", "expr", "spark_evaluation.SparkRankingEvaluation.rating_true.groupBy"], "methods", ["None"], ["", "def", "_calculate_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate ranking metrics.\"\"\"", "\n", "self", ".", "_items_for_user_pred", "=", "self", ".", "rating_pred", "\n", "\n", "self", ".", "_items_for_user_true", "=", "(", "\n", "self", ".", "rating_true", ".", "groupBy", "(", "self", ".", "col_user", ")", "\n", ".", "agg", "(", "expr", "(", "\"collect_list(\"", "+", "self", ".", "col_item", "+", "\") as ground_truth\"", ")", ")", "\n", ".", "select", "(", "self", ".", "col_user", ",", "\"ground_truth\"", ")", "\n", ")", "\n", "\n", "self", ".", "_items_for_user_all", "=", "self", ".", "_items_for_user_pred", ".", "join", "(", "\n", "self", ".", "_items_for_user_true", ",", "on", "=", "self", ".", "col_user", "\n", ")", ".", "drop", "(", "self", ".", "col_user", ")", "\n", "\n", "return", "RankingMetrics", "(", "self", ".", "_items_for_user_all", ".", "rdd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k": [[301, 314], ["spark_evaluation.SparkRankingEvaluation._metrics.precisionAt"], "methods", ["None"], ["", "def", "precision_at_k", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get precision@k.\n\n        .. note::\n            More details can be found\n            `here <http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.precisionAt>`_.\n\n        Return:\n            float: precision at k (min=0, max=1)\n        \"\"\"", "\n", "precision", "=", "self", ".", "_metrics", ".", "precisionAt", "(", "self", ".", "k", ")", "\n", "\n", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k": [[315, 330], ["spark_evaluation.SparkRankingEvaluation._items_for_user_all.rdd.map().mean", "spark_evaluation.SparkRankingEvaluation._items_for_user_all.rdd.map", "float", "float", "len", "len", "set().intersection", "set", "set"], "methods", ["None"], ["", "def", "recall_at_k", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get recall@K.\n\n        .. note::\n            More details can be found\n            `here <http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.meanAveragePrecision>`_.\n\n        Return:\n            float: recall at k (min=0, max=1).\n        \"\"\"", "\n", "recall", "=", "self", ".", "_items_for_user_all", ".", "rdd", ".", "map", "(", "\n", "lambda", "x", ":", "float", "(", "len", "(", "set", "(", "x", "[", "0", "]", ")", ".", "intersection", "(", "set", "(", "x", "[", "1", "]", ")", ")", ")", ")", "/", "float", "(", "len", "(", "x", "[", "1", "]", ")", ")", "\n", ")", ".", "mean", "(", ")", "\n", "\n", "return", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k": [[331, 344], ["spark_evaluation.SparkRankingEvaluation._metrics.ndcgAt"], "methods", ["None"], ["", "def", "ndcg_at_k", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get Normalized Discounted Cumulative Gain (NDCG)\n\n        .. note::\n            More details can be found\n            `here <http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.ndcgAt>`_.\n\n        Return:\n            float: nDCG at k (min=0, max=1).\n        \"\"\"", "\n", "ndcg", "=", "self", ".", "_metrics", ".", "ndcgAt", "(", "self", ".", "k", ")", "\n", "\n", "return", "ndcg", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k": [[345, 358], ["None"], "methods", ["None"], ["", "def", "map_at_k", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get mean average precision at k.\n\n        .. note::\n            More details can be found\n            `here <http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.meanAveragePrecision>`_.\n\n        Return:\n            float: MAP at k (min=0, max=1).\n        \"\"\"", "\n", "maprecision", "=", "self", ".", "_metrics", ".", "meanAveragePrecision", "\n", "\n", "return", "maprecision", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.__init__": [[491, 607], ["train_df.select", "spark_evaluation.SparkDiversityEvaluation.train_df.select().intersect().count", "reco_df.select", "reco_df.select", "StructType", "Exception", "F.lit().alias", "F.col().cast", "Exception", "spark_evaluation.SparkDiversityEvaluation.train_df.select().intersect", "DoubleType", "StructField", "StructField", "str", "str", "Exception", "spark_evaluation.SparkDiversityEvaluation.reco_df.select", "F.lit", "F.col", "IntegerType", "VectorUDT", "str", "spark_evaluation.SparkDiversityEvaluation.train_df.select", "str"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train_df", ",", "\n", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "DEFAULT_ITEM_SIM_MEASURE", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializer.\n\n        This is the Spark version of diversity metrics evaluator.\n        The methods of this class calculate the following diversity metrics:\n\n        * Coverage - it includes two metrics:\n            1. catalog_coverage, which measures the proportion of items that get recommended from the item catalog;\n            2. distributional_coverage, which measures how unequally different items are recommended in the\n               recommendations to all users.\n        * Novelty - A more novel item indicates it is less popular, i.e. it gets recommended less frequently.\n        * Diversity - The dissimilarity of items being recommended.\n        * Serendipity - The \"unusualness\" or \"surprise\" of recommendations to a user. When 'col_relevance' is used,\n            it indicates how \"pleasant surprise\" of recommendations is to a user.\n\n        The metric definitions/formulations are based on the following references with modification:\n\n        :Citation:\n\n            G. Shani and A. Gunawardana, Evaluating Recommendation Systems,\n            Recommender Systems Handbook pp. 257-297, 2010.\n\n            Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist: introducing\n            serendipity into music recommendation, WSDM 2012\n\n            P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems:\n            choice, discovery and relevance, ECIR 2011\n\n            Eugene Yan, Serendipity: Accuracy\u2019s unpopular best friend in Recommender Systems,\n            eugeneyan.com, April 2020\n\n        Args:\n            train_df (pyspark.sql.DataFrame): Data set with historical data for users and items they\n                have interacted with; contains col_user, col_item. Assumed to not contain any duplicate rows.\n                Interaction here follows the *item choice model* from Castells et al.\n            reco_df (pyspark.sql.DataFrame): Recommender's prediction output, containing col_user, col_item,\n                col_relevance (optional). Assumed to not contain any duplicate user-item pairs.\n            item_feature_df (pyspark.sql.DataFrame): (Optional) It is required only when item_sim_measure='item_feature_vector'.\n                It contains two columns: col_item and features (a feature vector).\n            item_sim_measure (str): (Optional) This column indicates which item similarity measure to be used.\n                Available measures include item_cooccurrence_count (default choice) and item_feature_vector.\n            col_user (str): User id column name.\n            col_item (str): Item id column name.\n            col_relevance (str): Optional. This column indicates whether the recommended item is actually\n                relevant to the user or not.\n        \"\"\"", "\n", "\n", "self", ".", "train_df", "=", "train_df", ".", "select", "(", "col_user", ",", "col_item", ")", "\n", "self", ".", "col_user", "=", "col_user", "\n", "self", ".", "col_item", "=", "col_item", "\n", "self", ".", "sim_col", "=", "DEFAULT_SIMILARITY_COL", "\n", "self", ".", "df_cosine_similarity", "=", "None", "\n", "self", ".", "df_user_item_serendipity", "=", "None", "\n", "self", ".", "df_user_serendipity", "=", "None", "\n", "self", ".", "avg_serendipity", "=", "None", "\n", "self", ".", "df_item_novelty", "=", "None", "\n", "self", ".", "avg_novelty", "=", "None", "\n", "self", ".", "df_intralist_similarity", "=", "None", "\n", "self", ".", "df_user_diversity", "=", "None", "\n", "self", ".", "avg_diversity", "=", "None", "\n", "self", ".", "item_feature_df", "=", "item_feature_df", "\n", "self", ".", "item_sim_measure", "=", "item_sim_measure", "\n", "\n", "if", "col_relevance", "is", "None", ":", "\n", "            ", "self", ".", "col_relevance", "=", "DEFAULT_RELEVANCE_COL", "\n", "# relevance term, default is 1 (relevant) for all", "\n", "self", ".", "reco_df", "=", "reco_df", ".", "select", "(", "\n", "col_user", ",", "col_item", ",", "F", ".", "lit", "(", "1.0", ")", ".", "alias", "(", "self", ".", "col_relevance", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "col_relevance", "=", "col_relevance", "\n", "self", ".", "reco_df", "=", "reco_df", ".", "select", "(", "\n", "col_user", ",", "col_item", ",", "F", ".", "col", "(", "self", ".", "col_relevance", ")", ".", "cast", "(", "DoubleType", "(", ")", ")", "\n", ")", "\n", "\n", "", "if", "self", ".", "item_sim_measure", "==", "\"item_feature_vector\"", ":", "\n", "            ", "self", ".", "col_item_features", "=", "DEFAULT_ITEM_FEATURES_COL", "\n", "required_schema", "=", "StructType", "(", "\n", "(", "\n", "StructField", "(", "self", ".", "col_item", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "self", ".", "col_item_features", ",", "VectorUDT", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "if", "self", ".", "item_feature_df", "is", "not", "None", ":", "\n", "\n", "                ", "if", "str", "(", "required_schema", ")", "!=", "str", "(", "item_feature_df", ".", "schema", ")", ":", "\n", "                    ", "raise", "Exception", "(", "\n", "\"Incorrect schema! item_feature_df should have schema:\"", "\n", "+", "str", "(", "required_schema", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"item_feature_df not specified! item_feature_df must be provided \"", "\n", "\"if choosing to use item_feature_vector to calculate item similarity. \"", "\n", "\"item_feature_df should have schema:\"", "+", "str", "(", "required_schema", ")", "\n", ")", "\n", "\n", "# check if reco_df contains any user_item pairs that are already shown in train_df", "\n", "", "", "count_intersection", "=", "(", "\n", "self", ".", "train_df", ".", "select", "(", "self", ".", "col_user", ",", "self", ".", "col_item", ")", "\n", ".", "intersect", "(", "self", ".", "reco_df", ".", "select", "(", "self", ".", "col_user", ",", "self", ".", "col_item", ")", ")", "\n", ".", "count", "(", ")", "\n", ")", "\n", "\n", "if", "count_intersection", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"reco_df should not contain any user_item pairs that are already shown in train_df\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_pairwise_items": [[609, 621], ["df.select().join().select", "df.select().join", "df.select", "df.select", "F.col().alias", "F.col().alias", "F.col().alias", "F.col", "F.col", "F.col", "F.col", "F.col", "F.col", "F.col"], "methods", ["None"], ["", "", "def", "_get_pairwise_items", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Get pairwise combinations of items per user (ignoring duplicate pairs [1,2] == [2,1])\"\"\"", "\n", "return", "(", "\n", "df", ".", "select", "(", "self", ".", "col_user", ",", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i1\"", ")", ")", "\n", ".", "join", "(", "\n", "df", ".", "select", "(", "\n", "F", ".", "col", "(", "self", ".", "col_user", ")", ".", "alias", "(", "\"_user\"", ")", ",", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i2\"", ")", ",", "\n", ")", ",", "\n", "(", "F", ".", "col", "(", "self", ".", "col_user", ")", "==", "F", ".", "col", "(", "\"_user\"", ")", ")", "&", "(", "F", ".", "col", "(", "\"i1\"", ")", "<=", "F", ".", "col", "(", "\"i2\"", ")", ")", ",", "\n", ")", "\n", ".", "select", "(", "self", ".", "col_user", ",", "\"i1\"", ",", "\"i2\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity": [[623, 636], ["spark_evaluation.SparkDiversityEvaluation._get_cooccurrence_similarity", "spark_evaluation.SparkDiversityEvaluation._get_item_feature_similarity", "Exception"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cooccurrence_similarity", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_item_feature_similarity"], ["", "def", "_get_cosine_similarity", "(", "self", ",", "n_partitions", "=", "200", ")", ":", "\n", "\n", "        ", "if", "self", ".", "item_sim_measure", "==", "\"item_cooccurrence_count\"", ":", "\n", "# calculate item-item similarity based on item co-occurrence count", "\n", "            ", "self", ".", "_get_cooccurrence_similarity", "(", "n_partitions", ")", "\n", "", "elif", "self", ".", "item_sim_measure", "==", "\"item_feature_vector\"", ":", "\n", "# calculate item-item similarity based on item feature vectors", "\n", "            ", "self", ".", "_get_item_feature_similarity", "(", "n_partitions", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"item_sim_measure not recognized! The available options include 'item_cooccurrence_count' and 'item_feature_vector'.\"", "\n", ")", "\n", "", "return", "self", ".", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cooccurrence_similarity": [[637, 679], ["spark_evaluation.SparkDiversityEvaluation._get_pairwise_items", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy().count", "spark_evaluation.SparkDiversityEvaluation.groupBy().count().join().join().select().repartition", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy", "spark_evaluation.SparkDiversityEvaluation.groupBy().count().join().join().select", "spark_evaluation.SparkDiversityEvaluation.groupBy().count().join().join", "spark_evaluation.SparkDiversityEvaluation.select", "spark_evaluation.SparkDiversityEvaluation.groupBy().count().join", "F.col().alias", "F.pow().alias", "F.col", "spark_evaluation.SparkDiversityEvaluation.select", "F.col", "F.col", "spark_evaluation.SparkDiversityEvaluation.groupBy().count", "F.col().alias", "F.pow().alias", "F.col", "F.pow", "F.col", "spark_evaluation.SparkDiversityEvaluation.groupBy", "F.col", "F.pow", "F.col"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_pairwise_items"], ["", "def", "_get_cooccurrence_similarity", "(", "self", ",", "n_partitions", ")", ":", "\n", "        ", "\"\"\"Cosine similarity metric from\n\n        :Citation:\n\n            Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n            introducing serendipity into music recommendation, WSDM 2012\n\n        The item indexes in the result are such that i1 <= i2.\n        \"\"\"", "\n", "if", "self", ".", "df_cosine_similarity", "is", "None", ":", "\n", "            ", "pairs", "=", "self", ".", "_get_pairwise_items", "(", "df", "=", "self", ".", "train_df", ")", "\n", "item_count", "=", "self", ".", "train_df", ".", "groupBy", "(", "self", ".", "col_item", ")", ".", "count", "(", ")", "\n", "\n", "self", ".", "df_cosine_similarity", "=", "(", "\n", "pairs", ".", "groupBy", "(", "\"i1\"", ",", "\"i2\"", ")", "\n", ".", "count", "(", ")", "\n", ".", "join", "(", "\n", "item_count", ".", "select", "(", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i1\"", ")", ",", "\n", "F", ".", "pow", "(", "F", ".", "col", "(", "\"count\"", ")", ",", "0.5", ")", ".", "alias", "(", "\"i1_sqrt_count\"", ")", ",", "\n", ")", ",", "\n", "on", "=", "\"i1\"", ",", "\n", ")", "\n", ".", "join", "(", "\n", "item_count", ".", "select", "(", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i2\"", ")", ",", "\n", "F", ".", "pow", "(", "F", ".", "col", "(", "\"count\"", ")", ",", "0.5", ")", ".", "alias", "(", "\"i2_sqrt_count\"", ")", ",", "\n", ")", ",", "\n", "on", "=", "\"i2\"", ",", "\n", ")", "\n", ".", "select", "(", "\n", "\"i1\"", ",", "\n", "\"i2\"", ",", "\n", "(", "\n", "F", ".", "col", "(", "\"count\"", ")", "\n", "/", "(", "F", ".", "col", "(", "\"i1_sqrt_count\"", ")", "*", "F", ".", "col", "(", "\"i2_sqrt_count\"", ")", ")", "\n", ")", ".", "alias", "(", "self", ".", "sim_col", ")", ",", "\n", ")", "\n", ".", "repartition", "(", "n_partitions", ",", "\"i1\"", ",", "\"i2\"", ")", "\n", ")", "\n", "", "return", "self", ".", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.sim_cos": [[680, 685], ["udf", "float", "float", "DoubleType", "v1.dot", "v1.norm", "v2.norm"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "udf", "(", "returnType", "=", "DoubleType", "(", ")", ")", "\n", "def", "sim_cos", "(", "v1", ",", "v2", ")", ":", "\n", "        ", "p", "=", "2", "\n", "return", "float", "(", "v1", ".", "dot", "(", "v2", ")", ")", "/", "float", "(", "v1", ".", "norm", "(", "p", ")", "*", "v2", ".", "norm", "(", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_item_feature_similarity": [[686, 709], ["spark_evaluation.SparkDiversityEvaluation.item_feature_df.select().join().select().sort().repartition", "spark_evaluation.SparkDiversityEvaluation.item_feature_df.select().join().select().sort", "spark_evaluation.SparkDiversityEvaluation.item_feature_df.select().join().select", "spark_evaluation.SparkDiversityEvaluation.sim_cos().alias", "spark_evaluation.SparkDiversityEvaluation.item_feature_df.select().join", "spark_evaluation.SparkDiversityEvaluation.item_feature_df.select", "spark_evaluation.SparkDiversityEvaluation.sim_cos", "spark_evaluation.SparkDiversityEvaluation.item_feature_df.select", "F.col().alias", "F.col().alias", "F.col", "F.col", "F.col().alias", "F.col().alias", "F.col", "F.col", "F.col", "F.col"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.sim_cos"], ["", "def", "_get_item_feature_similarity", "(", "self", ",", "n_partitions", ")", ":", "\n", "        ", "\"\"\"Cosine similarity metric based on item feature vectors\n\n        The item indexes in the result are such that i1 <= i2.\n        \"\"\"", "\n", "if", "self", ".", "df_cosine_similarity", "is", "None", ":", "\n", "            ", "self", ".", "df_cosine_similarity", "=", "(", "\n", "self", ".", "item_feature_df", ".", "select", "(", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i1\"", ")", ",", "\n", "F", ".", "col", "(", "self", ".", "col_item_features", ")", ".", "alias", "(", "\"f1\"", ")", ",", "\n", ")", "\n", ".", "join", "(", "\n", "self", ".", "item_feature_df", ".", "select", "(", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"i2\"", ")", ",", "\n", "F", ".", "col", "(", "self", ".", "col_item_features", ")", ".", "alias", "(", "\"f2\"", ")", ",", "\n", ")", ",", "\n", "(", "F", ".", "col", "(", "\"i1\"", ")", "<=", "F", ".", "col", "(", "\"i2\"", ")", ")", ",", "\n", ")", "\n", ".", "select", "(", "\"i1\"", ",", "\"i2\"", ",", "self", ".", "sim_cos", "(", "\"f1\"", ",", "\"f2\"", ")", ".", "alias", "(", "\"sim\"", ")", ")", "\n", ".", "sort", "(", "\"i1\"", ",", "\"i2\"", ")", "\n", ".", "repartition", "(", "n_partitions", ",", "\"i1\"", ",", "\"i2\"", ")", "\n", ")", "\n", "", "return", "self", ".", "df_cosine_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_intralist_similarity": [[711, 733], ["spark_evaluation.SparkDiversityEvaluation._get_pairwise_items", "spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity", "spark_evaluation.SparkDiversityEvaluation.join().fillna().filter().groupBy().agg().select", "spark_evaluation.SparkDiversityEvaluation.join().fillna().filter().groupBy().agg", "F.mean().alias", "spark_evaluation.SparkDiversityEvaluation.join().fillna().filter().groupBy", "F.mean", "spark_evaluation.SparkDiversityEvaluation.join().fillna().filter", "spark_evaluation.SparkDiversityEvaluation.join().fillna", "F.col", "F.col", "spark_evaluation.SparkDiversityEvaluation.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_pairwise_items", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity"], ["", "def", "_get_intralist_similarity", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Intra-list similarity from\n\n        :Citation:\n\n            \"Improving Recommendation Lists Through Topic Diversification\",\n            Ziegler, McNee, Konstan and Lausen, 2005.\n        \"\"\"", "\n", "if", "self", ".", "df_intralist_similarity", "is", "None", ":", "\n", "            ", "pairs", "=", "self", ".", "_get_pairwise_items", "(", "df", "=", "df", ")", "\n", "similarity_df", "=", "self", ".", "_get_cosine_similarity", "(", ")", "\n", "# Fillna(0) is needed in the cases where similarity_df does not have an entry for a pair of items.", "\n", "# e.g. i1 and i2 have never occurred together.", "\n", "self", ".", "df_intralist_similarity", "=", "(", "\n", "pairs", ".", "join", "(", "similarity_df", ",", "on", "=", "[", "\"i1\"", ",", "\"i2\"", "]", ",", "how", "=", "\"left\"", ")", "\n", ".", "fillna", "(", "0", ")", "\n", ".", "filter", "(", "F", ".", "col", "(", "\"i1\"", ")", "!=", "F", ".", "col", "(", "\"i2\"", ")", ")", "\n", ".", "groupBy", "(", "self", ".", "col_user", ")", "\n", ".", "agg", "(", "F", ".", "mean", "(", "self", ".", "sim_col", ")", ".", "alias", "(", "\"avg_il_sim\"", ")", ")", "\n", ".", "select", "(", "self", ".", "col_user", ",", "\"avg_il_sim\"", ")", "\n", ")", "\n", "", "return", "self", ".", "df_intralist_similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity": [[734, 756], ["spark_evaluation.SparkDiversityEvaluation._get_intralist_similarity", "spark_evaluation.SparkDiversityEvaluation.df_intralist_similarity.withColumn().select().orderBy", "spark_evaluation.SparkDiversityEvaluation.df_intralist_similarity.withColumn().select", "spark_evaluation.SparkDiversityEvaluation.df_intralist_similarity.withColumn", "F.col"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_intralist_similarity"], ["", "def", "user_diversity", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate average diversity of recommendations for each user.\n        The metric definition is based on formula (3) in the following reference:\n\n        :Citation:\n\n            Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n            introducing serendipity into music recommendation, WSDM 2012\n\n        Returns:\n            pyspark.sql.dataframe.DataFrame: A dataframe with the following columns: col_user, user_diversity.\n        \"\"\"", "\n", "if", "self", ".", "df_user_diversity", "is", "None", ":", "\n", "            ", "self", ".", "df_intralist_similarity", "=", "self", ".", "_get_intralist_similarity", "(", "self", ".", "reco_df", ")", "\n", "self", ".", "df_user_diversity", "=", "(", "\n", "self", ".", "df_intralist_similarity", ".", "withColumn", "(", "\n", "\"user_diversity\"", ",", "1", "-", "F", ".", "col", "(", "\"avg_il_sim\"", ")", "\n", ")", "\n", ".", "select", "(", "self", ".", "col_user", ",", "\"user_diversity\"", ")", "\n", ".", "orderBy", "(", "self", ".", "col_user", ")", "\n", ")", "\n", "", "return", "self", ".", "df_user_diversity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.diversity": [[757, 769], ["spark_evaluation.SparkDiversityEvaluation.user_diversity", "spark_evaluation.SparkDiversityEvaluation.df_user_diversity.agg().first", "spark_evaluation.SparkDiversityEvaluation.df_user_diversity.agg"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "def", "diversity", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate average diversity of recommendations across all users.\n\n        Returns:\n            float: diversity.\n        \"\"\"", "\n", "if", "self", ".", "avg_diversity", "is", "None", ":", "\n", "            ", "self", ".", "df_user_diversity", "=", "self", ".", "user_diversity", "(", ")", "\n", "self", ".", "avg_diversity", "=", "self", ".", "df_user_diversity", ".", "agg", "(", "\n", "{", "\"user_diversity\"", ":", "\"mean\"", "}", "\n", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "", "return", "self", ".", "avg_diversity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty": [[771, 800], ["spark_evaluation.SparkDiversityEvaluation.train_df.count", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy().count().withColumn().select().orderBy", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy().count().withColumn().select", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy().count().withColumn", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy().count", "F.log2", "spark_evaluation.SparkDiversityEvaluation.train_df.groupBy", "F.col"], "methods", ["None"], ["", "def", "historical_item_novelty", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate novelty for each item. Novelty is computed as the minus logarithm of\n        (number of interactions with item / total number of interactions). The definition of the metric\n        is based on the following reference using the choice model (eqs. 1 and 6):\n\n        :Citation:\n\n            P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems:\n            choice, discovery and relevance, ECIR 2011\n\n        The novelty of an item can be defined relative to a set of observed events on the set of all items.\n        These can be events of user choice (item \"is picked\" by a random user) or user discovery\n        (item \"is known\" to a random user). The above definition of novelty reflects a factor of item popularity.\n        High novelty values correspond to long-tail items in the density function, that few users have interacted\n        with and low novelty values correspond to popular head items.\n\n        Returns:\n            pyspark.sql.dataframe.DataFrame: A dataframe with the following columns: col_item, item_novelty.\n        \"\"\"", "\n", "if", "self", ".", "df_item_novelty", "is", "None", ":", "\n", "            ", "n_records", "=", "self", ".", "train_df", ".", "count", "(", ")", "\n", "self", ".", "df_item_novelty", "=", "(", "\n", "self", ".", "train_df", ".", "groupBy", "(", "self", ".", "col_item", ")", "\n", ".", "count", "(", ")", "\n", ".", "withColumn", "(", "\"item_novelty\"", ",", "-", "F", ".", "log2", "(", "F", ".", "col", "(", "\"count\"", ")", "/", "n_records", ")", ")", "\n", ".", "select", "(", "self", ".", "col_item", ",", "\"item_novelty\"", ")", "\n", ".", "orderBy", "(", "self", ".", "col_item", ")", "\n", ")", "\n", "", "return", "self", ".", "df_item_novelty", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.novelty": [[801, 825], ["spark_evaluation.SparkDiversityEvaluation.historical_item_novelty", "spark_evaluation.SparkDiversityEvaluation.reco_df.count", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy().count().join().selectExpr().first", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy().count().join().selectExpr", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy().count().join", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy().count", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty"], ["", "def", "novelty", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the average novelty in a list of recommended items (this assumes that the recommendation list\n        is already computed). Follows section 5 from\n\n        :Citation:\n\n            P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems:\n            choice, discovery and relevance, ECIR 2011\n\n        Returns:\n            pyspark.sql.dataframe.DataFrame: A dataframe with following columns: novelty.\n        \"\"\"", "\n", "if", "self", ".", "avg_novelty", "is", "None", ":", "\n", "            ", "self", ".", "df_item_novelty", "=", "self", ".", "historical_item_novelty", "(", ")", "\n", "n_recommendations", "=", "self", ".", "reco_df", ".", "count", "(", ")", "\n", "self", ".", "avg_novelty", "=", "(", "\n", "self", ".", "reco_df", ".", "groupBy", "(", "self", ".", "col_item", ")", "\n", ".", "count", "(", ")", "\n", ".", "join", "(", "self", ".", "df_item_novelty", ",", "self", ".", "col_item", ")", "\n", ".", "selectExpr", "(", "\"sum(count * item_novelty)\"", ")", "\n", ".", "first", "(", ")", "[", "0", "]", "\n", "/", "n_recommendations", "\n", ")", "\n", "", "return", "self", ".", "avg_novelty", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity": [[827, 884], ["spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy().agg().join().withColumn().select().orderBy", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy().agg().join().withColumn().select", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy().agg().join().withColumn", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy().agg().join", "F.col", "F.col", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy().agg", "F.mean().alias", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna().groupBy", "F.mean", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join().fillna", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select().join", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join().select", "F.least().alias", "F.greatest().alias", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().join", "spark_evaluation.SparkDiversityEvaluation.train_df.select", "F.least", "F.greatest", "spark_evaluation.SparkDiversityEvaluation.reco_df.select", "F.col().alias", "F.col", "F.col", "F.col", "F.col", "F.col().alias", "F.col", "F.col"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation._get_cosine_similarity"], ["", "def", "user_item_serendipity", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate serendipity of each item in the recommendations for each user.\n        The metric definition is based on the following references:\n\n        :Citation:\n\n            Y.C. Zhang, D.\u00d3. S\u00e9aghdha, D. Quercia and T. Jambor, Auralist:\n            introducing serendipity into music recommendation, WSDM 2012\n\n            Eugene Yan, Serendipity: Accuracy\u2019s unpopular best friend in Recommender Systems,\n            eugeneyan.com, April 2020\n\n        Returns:\n            pyspark.sql.dataframe.DataFrame: A dataframe with columns: col_user, col_item, user_item_serendipity.\n        \"\"\"", "\n", "# for every col_user, col_item in reco_df, join all interacted items from train_df.", "\n", "# These interacted items are repeated for each item in reco_df for a specific user.", "\n", "if", "self", ".", "df_user_item_serendipity", "is", "None", ":", "\n", "            ", "self", ".", "df_cosine_similarity", "=", "self", ".", "_get_cosine_similarity", "(", ")", "\n", "self", ".", "df_user_item_serendipity", "=", "(", "\n", "self", ".", "reco_df", ".", "select", "(", "\n", "self", ".", "col_user", ",", "\n", "self", ".", "col_item", ",", "\n", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\n", "\"reco_item_tmp\"", "\n", ")", ",", "# duplicate col_item to keep", "\n", ")", "\n", ".", "join", "(", "\n", "self", ".", "train_df", ".", "select", "(", "\n", "self", ".", "col_user", ",", "F", ".", "col", "(", "self", ".", "col_item", ")", ".", "alias", "(", "\"train_item_tmp\"", ")", "\n", ")", ",", "\n", "on", "=", "[", "self", ".", "col_user", "]", ",", "\n", ")", "\n", ".", "select", "(", "\n", "self", ".", "col_user", ",", "\n", "self", ".", "col_item", ",", "\n", "F", ".", "least", "(", "F", ".", "col", "(", "\"reco_item_tmp\"", ")", ",", "F", ".", "col", "(", "\"train_item_tmp\"", ")", ")", ".", "alias", "(", "\n", "\"i1\"", "\n", ")", ",", "\n", "F", ".", "greatest", "(", "F", ".", "col", "(", "\"reco_item_tmp\"", ")", ",", "F", ".", "col", "(", "\"train_item_tmp\"", ")", ")", ".", "alias", "(", "\n", "\"i2\"", "\n", ")", ",", "\n", ")", "\n", ".", "join", "(", "self", ".", "df_cosine_similarity", ",", "on", "=", "[", "\"i1\"", ",", "\"i2\"", "]", ",", "how", "=", "\"left\"", ")", "\n", ".", "fillna", "(", "0", ")", "\n", ".", "groupBy", "(", "self", ".", "col_user", ",", "self", ".", "col_item", ")", "\n", ".", "agg", "(", "F", ".", "mean", "(", "self", ".", "sim_col", ")", ".", "alias", "(", "\"avg_item2interactedHistory_sim\"", ")", ")", "\n", ".", "join", "(", "self", ".", "reco_df", ",", "on", "=", "[", "self", ".", "col_user", ",", "self", ".", "col_item", "]", ")", "\n", ".", "withColumn", "(", "\n", "\"user_item_serendipity\"", ",", "\n", "(", "1", "-", "F", ".", "col", "(", "\"avg_item2interactedHistory_sim\"", ")", ")", "\n", "*", "F", ".", "col", "(", "self", ".", "col_relevance", ")", ",", "\n", ")", "\n", ".", "select", "(", "self", ".", "col_user", ",", "self", ".", "col_item", ",", "\"user_item_serendipity\"", ")", "\n", ".", "orderBy", "(", "self", ".", "col_user", ",", "self", ".", "col_item", ")", "\n", ")", "\n", "", "return", "self", ".", "df_user_item_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity": [[885, 899], ["spark_evaluation.SparkDiversityEvaluation.user_item_serendipity", "spark_evaluation.SparkDiversityEvaluation.df_user_item_serendipity.groupBy().agg().orderBy", "spark_evaluation.SparkDiversityEvaluation.df_user_item_serendipity.groupBy().agg", "F.mean().alias", "spark_evaluation.SparkDiversityEvaluation.df_user_item_serendipity.groupBy", "F.mean"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "def", "user_serendipity", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate average serendipity for each user's recommendations.\n\n        Returns:\n            pyspark.sql.dataframe.DataFrame: A dataframe with following columns: col_user, user_serendipity.\n        \"\"\"", "\n", "if", "self", ".", "df_user_serendipity", "is", "None", ":", "\n", "            ", "self", ".", "df_user_item_serendipity", "=", "self", ".", "user_item_serendipity", "(", ")", "\n", "self", ".", "df_user_serendipity", "=", "(", "\n", "self", ".", "df_user_item_serendipity", ".", "groupBy", "(", "self", ".", "col_user", ")", "\n", ".", "agg", "(", "F", ".", "mean", "(", "\"user_item_serendipity\"", ")", ".", "alias", "(", "\"user_serendipity\"", ")", ")", "\n", ".", "orderBy", "(", "self", ".", "col_user", ")", "\n", ")", "\n", "", "return", "self", ".", "df_user_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.serendipity": [[900, 912], ["spark_evaluation.SparkDiversityEvaluation.user_serendipity", "spark_evaluation.SparkDiversityEvaluation.df_user_serendipity.agg().first", "spark_evaluation.SparkDiversityEvaluation.df_user_serendipity.agg"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "def", "serendipity", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate average serendipity for recommendations across all users.\n\n        Returns:\n            float: serendipity.\n        \"\"\"", "\n", "if", "self", ".", "avg_serendipity", "is", "None", ":", "\n", "            ", "self", ".", "df_user_serendipity", "=", "self", ".", "user_serendipity", "(", ")", "\n", "self", ".", "avg_serendipity", "=", "self", ".", "df_user_serendipity", ".", "agg", "(", "\n", "{", "\"user_serendipity\"", ":", "\"mean\"", "}", "\n", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "", "return", "self", ".", "avg_serendipity", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.catalog_coverage": [[914, 936], ["spark_evaluation.SparkDiversityEvaluation.reco_df.select().distinct().count", "spark_evaluation.SparkDiversityEvaluation.train_df.select().distinct().count", "spark_evaluation.SparkDiversityEvaluation.reco_df.select().distinct", "spark_evaluation.SparkDiversityEvaluation.train_df.select().distinct", "spark_evaluation.SparkDiversityEvaluation.reco_df.select", "spark_evaluation.SparkDiversityEvaluation.train_df.select"], "methods", ["None"], ["", "def", "catalog_coverage", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate catalog coverage for recommendations across all users.\n        The metric definition is based on the \"catalog coverage\" definition in the following reference:\n\n        :Citation:\n\n            G. Shani and A. Gunawardana, Evaluating Recommendation Systems,\n            Recommender Systems Handbook pp. 257-297, 2010.\n\n        Returns:\n            float: catalog coverage\n        \"\"\"", "\n", "# distinct item count in reco_df", "\n", "count_distinct_item_reco", "=", "self", ".", "reco_df", ".", "select", "(", "self", ".", "col_item", ")", ".", "distinct", "(", ")", ".", "count", "(", ")", "\n", "# distinct item count in train_df", "\n", "count_distinct_item_train", "=", "(", "\n", "self", ".", "train_df", ".", "select", "(", "self", ".", "col_item", ")", ".", "distinct", "(", ")", ".", "count", "(", ")", "\n", ")", "\n", "\n", "# catalog coverage", "\n", "c_coverage", "=", "count_distinct_item_reco", "/", "count_distinct_item_train", "\n", "return", "c_coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.distributional_coverage": [[937, 961], ["spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy().count", "spark_evaluation.SparkDiversityEvaluation.reco_df.count", "spark_evaluation.SparkDiversityEvaluation.withColumn().withColumn", "spark_evaluation.SparkDiversityEvaluation.reco_df.groupBy", "spark_evaluation.SparkDiversityEvaluation.withColumn", "F.col", "F.log2", "F.col", "spark_evaluation.SparkDiversityEvaluation.withColumn().withColumn.agg().collect", "F.col", "spark_evaluation.SparkDiversityEvaluation.withColumn().withColumn.agg", "F.sum"], "methods", ["None"], ["", "def", "distributional_coverage", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate distributional coverage for recommendations across all users.\n        The metric definition is based on formula (21) in the following reference:\n\n        :Citation:\n\n            G. Shani and A. Gunawardana, Evaluating Recommendation Systems,\n            Recommender Systems Handbook pp. 257-297, 2010.\n\n        Returns:\n            float: distributional coverage\n        \"\"\"", "\n", "# In reco_df, how  many times each col_item is being recommended", "\n", "df_itemcnt_reco", "=", "self", ".", "reco_df", ".", "groupBy", "(", "self", ".", "col_item", ")", ".", "count", "(", ")", "\n", "\n", "# the number of total recommendations", "\n", "count_row_reco", "=", "self", ".", "reco_df", ".", "count", "(", ")", "\n", "df_entropy", "=", "df_itemcnt_reco", ".", "withColumn", "(", "\n", "\"p(i)\"", ",", "F", ".", "col", "(", "\"count\"", ")", "/", "count_row_reco", "\n", ")", ".", "withColumn", "(", "\"entropy(i)\"", ",", "F", ".", "col", "(", "\"p(i)\"", ")", "*", "F", ".", "log2", "(", "F", ".", "col", "(", "\"p(i)\"", ")", ")", ")", "\n", "# distributional coverage", "\n", "d_coverage", "=", "-", "df_entropy", ".", "agg", "(", "F", ".", "sum", "(", "\"entropy(i)\"", ")", ")", ".", "collect", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "return", "d_coverage", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation._get_top_k_items": [[360, 400], ["Window.partitionBy().orderBy", "dataframe.select().where().groupby().agg", "col().desc", "F.collect_list().alias", "Window.partitionBy", "dataframe.select().where().groupby", "col", "F.collect_list", "dataframe.select().where", "dataframe.select", "col", "row_number().over().alias", "row_number().over", "row_number"], "function", ["None"], ["", "", "def", "_get_top_k_items", "(", "\n", "dataframe", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get the input customer-item-rating tuple in the format of Spark\n    DataFrame, output a Spark DataFrame in the dense format of top k items\n    for each user.\n\n    .. note::\n        if it is implicit rating, just append a column of constants to be ratings.\n\n    Args:\n        dataframe (pyspark.sql.DataFrame): DataFrame of rating data (in the format of\n        customerID-itemID-rating tuple).\n        col_user (str): column name for user.\n        col_item (str): column name for item.\n        col_rating (str): column name for rating.\n        col_prediction (str): column name for prediction.\n        k (int): number of items for each user.\n\n    Return:\n        pyspark.sql.DataFrame: DataFrame of top k items for each user.\n    \"\"\"", "\n", "window_spec", "=", "Window", ".", "partitionBy", "(", "col_user", ")", ".", "orderBy", "(", "col", "(", "col_rating", ")", ".", "desc", "(", ")", ")", "\n", "\n", "# this does not work for rating of the same value.", "\n", "items_for_user", "=", "(", "\n", "dataframe", ".", "select", "(", "\n", "col_user", ",", "col_item", ",", "col_rating", ",", "row_number", "(", ")", ".", "over", "(", "window_spec", ")", ".", "alias", "(", "\"rank\"", ")", "\n", ")", "\n", ".", "where", "(", "col", "(", "\"rank\"", ")", "<=", "k", ")", "\n", ".", "groupby", "(", "col_user", ")", "\n", ".", "agg", "(", "F", ".", "collect_list", "(", "col_item", ")", ".", "alias", "(", "col_prediction", ")", ")", "\n", ")", "\n", "\n", "return", "items_for_user", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation._get_relevant_items_by_threshold": [[402, 442], ["dataframe.orderBy().where().select().withColumn().select().dropDuplicates", "dataframe.orderBy().where().select().withColumn().select", "dataframe.orderBy().where().select().withColumn", "F.collect_list().over", "dataframe.orderBy().where().select", "Window.partitionBy", "F.collect_list", "dataframe.orderBy().where", "dataframe.orderBy", "str"], "function", ["None"], ["", "def", "_get_relevant_items_by_threshold", "(", "\n", "dataframe", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "threshold", "=", "DEFAULT_THRESHOLD", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get relevant items for each customer in the input rating data.\n\n    Relevant items are defined as those having ratings above certain threshold.\n    The threshold is defined as a statistical measure of the ratings for a\n    user, e.g., median.\n\n    Args:\n        dataframe: Spark DataFrame of customerID-itemID-rating tuples.\n        col_user (str): column name for user.\n        col_item (str): column name for item.\n        col_rating (str): column name for rating.\n        col_prediction (str): column name for prediction.\n        threshold (float): threshold for determining the relevant recommended items.\n            This is used for the case that predicted ratings follow a known\n            distribution.\n\n    Return:\n        pyspark.sql.DataFrame: DataFrame of customerID-itemID-rating tuples with only relevant\n        items.\n    \"\"\"", "\n", "items_for_user", "=", "(", "\n", "dataframe", ".", "orderBy", "(", "col_rating", ",", "ascending", "=", "False", ")", "\n", ".", "where", "(", "col_rating", "+", "\" >= \"", "+", "str", "(", "threshold", ")", ")", "\n", ".", "select", "(", "col_user", ",", "col_item", ",", "col_rating", ")", "\n", ".", "withColumn", "(", "\n", "col_prediction", ",", "F", ".", "collect_list", "(", "col_item", ")", ".", "over", "(", "Window", ".", "partitionBy", "(", "col_user", ")", ")", "\n", ")", "\n", ".", "select", "(", "col_user", ",", "col_prediction", ")", "\n", ".", "dropDuplicates", "(", ")", "\n", ")", "\n", "\n", "return", "items_for_user", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation._get_relevant_items_by_timestamp": [[444, 486], ["Window.partitionBy().orderBy", "dataframe.select().where().withColumn().select().dropDuplicates", "col().desc", "Window.partitionBy", "dataframe.select().where().withColumn().select", "col", "dataframe.select().where().withColumn", "F.collect_list().over", "dataframe.select().where", "Window.partitionBy", "F.collect_list", "dataframe.select", "col", "row_number().over().alias", "row_number().over", "row_number"], "function", ["None"], ["", "def", "_get_relevant_items_by_timestamp", "(", "\n", "dataframe", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "k", "=", "DEFAULT_K", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Get relevant items for each customer defined by timestamp.\n\n    Relevant items are defined as k items that appear mostly recently\n    according to timestamps.\n\n    Args:\n        dataframe (pyspark.sql.DataFrame): A Spark DataFrame of customerID-itemID-rating-timeStamp\n            tuples.\n        col_user (str): column name for user.\n        col_item (str): column name for item.\n        col_rating (str): column name for rating.\n        col_timestamp (str): column name for timestamp.\n        col_prediction (str): column name for prediction.\n        k: number of relevent items to be filtered by the function.\n\n    Return:\n        pyspark.sql.DataFrame: DataFrame of customerID-itemID-rating tuples with only relevant items.\n    \"\"\"", "\n", "window_spec", "=", "Window", ".", "partitionBy", "(", "col_user", ")", ".", "orderBy", "(", "col", "(", "col_timestamp", ")", ".", "desc", "(", ")", ")", "\n", "\n", "items_for_user", "=", "(", "\n", "dataframe", ".", "select", "(", "\n", "col_user", ",", "col_item", ",", "col_rating", ",", "row_number", "(", ")", ".", "over", "(", "window_spec", ")", ".", "alias", "(", "\"rank\"", ")", "\n", ")", "\n", ".", "where", "(", "col", "(", "\"rank\"", ")", "<=", "k", ")", "\n", ".", "withColumn", "(", "\n", "col_prediction", ",", "F", ".", "collect_list", "(", "col_item", ")", ".", "over", "(", "Window", ".", "partitionBy", "(", "col_user", ")", ")", "\n", ")", "\n", ".", "select", "(", "col_user", ",", "col_prediction", ")", "\n", ".", "dropDuplicates", "(", "[", "col_user", ",", "col_prediction", "]", ")", "\n", ")", "\n", "\n", "return", "items_for_user", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.target_metrics": [[32, 96], ["pytest.fixture", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pandas.DataFrame", "pytest.approx", "pytest.approx", "pandas.DataFrame", "pytest.approx", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pytest.approx", "pandas.DataFrame", "pandas.DataFrame", "pytest.approx", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "target_metrics", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"rmse\"", ":", "pytest", ".", "approx", "(", "7.254309", ",", "TOL", ")", ",", "\n", "\"mae\"", ":", "pytest", ".", "approx", "(", "6.375", ",", "TOL", ")", ",", "\n", "\"rsquared\"", ":", "pytest", ".", "approx", "(", "-", "31.699029", ",", "TOL", ")", ",", "\n", "\"exp_var\"", ":", "pytest", ".", "approx", "(", "-", "6.4466", ",", "0.01", ")", ",", "\n", "\"ndcg\"", ":", "pytest", ".", "approx", "(", "0.38172", ",", "TOL", ")", ",", "\n", "\"precision\"", ":", "pytest", ".", "approx", "(", "0.26666", ",", "TOL", ")", ",", "\n", "\"map\"", ":", "pytest", ".", "approx", "(", "0.23613", ",", "TOL", ")", ",", "\n", "\"recall\"", ":", "pytest", ".", "approx", "(", "0.37777", ",", "TOL", ")", ",", "\n", "\"c_coverage\"", ":", "pytest", ".", "approx", "(", "0.8", ",", "TOL", ")", ",", "\n", "\"d_coverage\"", ":", "pytest", ".", "approx", "(", "1.9183", ",", "TOL", ")", ",", "\n", "\"item_novelty\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "ItemId", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "item_novelty", "=", "[", "3.0", ",", "3.0", ",", "2.0", ",", "1.41504", ",", "3.0", "]", ")", "\n", ")", ",", "\n", "\"novelty\"", ":", "pytest", ".", "approx", "(", "2.83333", ",", "TOL", ")", ",", "\n", "# diversity when using item co-occurrence count to calculate item similarity", "\n", "\"diversity\"", ":", "pytest", ".", "approx", "(", "0.43096", ",", "TOL", ")", ",", "\n", "\"user_diversity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_diversity", "=", "[", "0.29289", ",", "1.0", ",", "0.0", "]", ")", "\n", ")", ",", "\n", "# diversity values when using item features to calculate item similarity", "\n", "\"diversity_item_feature_vector\"", ":", "pytest", ".", "approx", "(", "0.5000", ",", "TOL", ")", ",", "\n", "\"user_diversity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_diversity", "=", "[", "0.5000", ",", "0.5000", ",", "0.5000", "]", ")", "\n", ")", ",", "\n", "\"user_item_serendipity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "ItemId", "=", "[", "3", ",", "5", ",", "2", ",", "5", ",", "1", ",", "2", "]", ",", "\n", "user_item_serendipity", "=", "[", "\n", "0.72783", ",", "\n", "0.0", ",", "\n", "0.71132", ",", "\n", "0.35777", ",", "\n", "0.80755", ",", "\n", "0.0", ",", "\n", "]", ",", "\n", ")", "\n", ")", ",", "\n", "\"user_serendipity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_serendipity", "=", "[", "0.363915", ",", "0.53455", ",", "0.403775", "]", ")", "\n", ")", ",", "\n", "\"serendipity\"", ":", "pytest", ".", "approx", "(", "0.43408", ",", "TOL", ")", ",", "\n", "# serendipity values when using item features to calculate item similarity", "\n", "\"user_item_serendipity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "ItemId", "=", "[", "3", ",", "5", ",", "2", ",", "5", ",", "1", ",", "2", "]", ",", "\n", "user_item_serendipity", "=", "[", "\n", "0.5000", ",", "\n", "0.0", ",", "\n", "0.75", ",", "\n", "0.5000", ",", "\n", "0.6667", ",", "\n", "0.0", ",", "\n", "]", ",", "\n", ")", "\n", ")", ",", "\n", "\"user_serendipity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_serendipity", "=", "[", "0.2500", ",", "0.625", ",", "0.3333", "]", ")", "\n", ")", ",", "\n", "\"serendipity_item_feature_vector\"", ":", "pytest", ".", "approx", "(", "0.4028", ",", "TOL", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.python_data": [[99, 135], ["pytest.fixture", "pandas.DataFrame", "pandas.DataFrame"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_data", "(", ")", ":", "\n", "    ", "rating_true", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"userID\"", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "4", ",", "5", ",", "6", ",", "7", ",", "2", ",", "5", ",", "6", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", "]", ",", "\n", "\"rating\"", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "1", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "1", "]", ",", "\n", "}", "\n", ")", "\n", "rating_pred", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"userID\"", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "\"itemID\"", ":", "[", "3", ",", "10", ",", "12", ",", "10", ",", "3", ",", "5", ",", "11", ",", "13", ",", "4", ",", "10", ",", "7", ",", "13", ",", "1", ",", "3", ",", "5", ",", "2", ",", "11", ",", "14", "]", ",", "\n", "\"prediction\"", ":", "[", "\n", "14", ",", "\n", "13", ",", "\n", "12", ",", "\n", "14", ",", "\n", "13", ",", "\n", "12", ",", "\n", "11", ",", "\n", "10", ",", "\n", "14", ",", "\n", "13", ",", "\n", "12", ",", "\n", "11", ",", "\n", "10", ",", "\n", "9", ",", "\n", "8", ",", "\n", "7", ",", "\n", "6", ",", "\n", "5", ",", "\n", "]", ",", "\n", "}", "\n", ")", "\n", "return", "rating_true", ",", "rating_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.spark_data": [[137, 145], ["pytest.fixture", "spark.createDataFrame", "spark.createDataFrame"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "spark_data", "(", "python_data", ",", "spark", ")", ":", "\n", "    ", "rating_true", ",", "rating_pred", "=", "python_data", "\n", "\n", "df_true", "=", "spark", ".", "createDataFrame", "(", "rating_true", ")", "\n", "df_pred", "=", "spark", ".", "createDataFrame", "(", "rating_pred", ")", "\n", "\n", "return", "df_true", ",", "df_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.spark_diversity_data": [[147, 188], ["pytest.fixture", "spark.createDataFrame", "spark.createDataFrame", "StructType", "spark.createDataFrame", "StructField", "StructField", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "Row", "IntegerType", "VectorUDT", "Row", "Row", "Row", "Row", "Row", "Vectors.sparse", "Vectors.sparse", "Vectors.sparse", "Vectors.sparse", "Vectors.sparse"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "spark_diversity_data", "(", "spark", ")", ":", "\n", "    ", "train_df", "=", "spark", ".", "createDataFrame", "(", "\n", "[", "\n", "Row", "(", "UserId", "=", "1", ",", "ItemId", "=", "1", ")", ",", "\n", "Row", "(", "UserId", "=", "1", ",", "ItemId", "=", "2", ")", ",", "\n", "Row", "(", "UserId", "=", "1", ",", "ItemId", "=", "4", ")", ",", "\n", "Row", "(", "UserId", "=", "2", ",", "ItemId", "=", "3", ")", ",", "\n", "Row", "(", "UserId", "=", "2", ",", "ItemId", "=", "4", ")", ",", "\n", "Row", "(", "UserId", "=", "3", ",", "ItemId", "=", "3", ")", ",", "\n", "Row", "(", "UserId", "=", "3", ",", "ItemId", "=", "4", ")", ",", "\n", "Row", "(", "UserId", "=", "3", ",", "ItemId", "=", "5", ")", ",", "\n", "]", "\n", ")", "\n", "reco_df", "=", "spark", ".", "createDataFrame", "(", "\n", "[", "\n", "Row", "(", "UserId", "=", "1", ",", "ItemId", "=", "3", ",", "Relevance", "=", "1", ")", ",", "\n", "Row", "(", "UserId", "=", "1", ",", "ItemId", "=", "5", ",", "Relevance", "=", "0", ")", ",", "\n", "Row", "(", "UserId", "=", "2", ",", "ItemId", "=", "2", ",", "Relevance", "=", "1", ")", ",", "\n", "Row", "(", "UserId", "=", "2", ",", "ItemId", "=", "5", ",", "Relevance", "=", "1", ")", ",", "\n", "Row", "(", "UserId", "=", "3", ",", "ItemId", "=", "1", ",", "Relevance", "=", "1", ")", ",", "\n", "Row", "(", "UserId", "=", "3", ",", "ItemId", "=", "2", ",", "Relevance", "=", "0", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "field", "=", "[", "\n", "StructField", "(", "\"ItemId\"", ",", "IntegerType", "(", ")", ",", "True", ")", ",", "\n", "StructField", "(", "\"features\"", ",", "VectorUDT", "(", ")", ",", "True", ")", ",", "\n", "]", "\n", "schema", "=", "StructType", "(", "field", ")", "\n", "item_feature_df", "=", "spark", ".", "createDataFrame", "(", "\n", "[", "\n", "Row", "(", "ItemId", "=", "1", ",", "features", "=", "Vectors", ".", "sparse", "(", "5", ",", "[", "1", ",", "2", "]", ",", "[", "1.0", ",", "1.0", "]", ")", ")", ",", "\n", "Row", "(", "ItemId", "=", "2", ",", "features", "=", "Vectors", ".", "sparse", "(", "5", ",", "[", "1", ",", "3", "]", ",", "[", "1.0", ",", "1.0", "]", ")", ")", ",", "\n", "Row", "(", "ItemId", "=", "3", ",", "features", "=", "Vectors", ".", "sparse", "(", "5", ",", "[", "2", ",", "3", "]", ",", "[", "1.0", ",", "1.0", "]", ")", ")", ",", "\n", "Row", "(", "ItemId", "=", "4", ",", "features", "=", "Vectors", ".", "sparse", "(", "5", ",", "[", "2", ",", "4", "]", ",", "[", "1.0", ",", "1.0", "]", ")", ")", ",", "\n", "Row", "(", "ItemId", "=", "5", ",", "features", "=", "Vectors", ".", "sparse", "(", "5", ",", "[", "3", ",", "4", "]", ",", "[", "1.0", ",", "1.0", "]", ")", ")", ",", "\n", "]", ",", "\n", "schema", ",", "\n", ")", "\n", "return", "train_df", ",", "reco_df", ",", "item_feature_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_init_spark": [[190, 193], ["None"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_init_spark", "(", "spark", ")", ":", "\n", "    ", "assert", "spark", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_init_spark_rating_eval": [[195, 200], ["SparkRatingEvaluation"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_init_spark_rating_eval", "(", "spark_data", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "evaluator", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_rmse": [[202, 211], ["SparkRatingEvaluation", "SparkRatingEvaluation", "SparkRatingEvaluation.rmse", "SparkRatingEvaluation.rmse"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_rmse", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator1", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_true", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator1", ".", "rmse", "(", ")", "==", "0", "\n", "\n", "evaluator2", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator2", ".", "rmse", "(", ")", "==", "target_metrics", "[", "\"rmse\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_mae": [[213, 222], ["SparkRatingEvaluation", "SparkRatingEvaluation", "SparkRatingEvaluation.mae", "SparkRatingEvaluation.mae"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_mae", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator1", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_true", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator1", ".", "mae", "(", ")", "==", "0", "\n", "\n", "evaluator2", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator2", ".", "mae", "(", ")", "==", "target_metrics", "[", "\"mae\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_rsquared": [[224, 233], ["SparkRatingEvaluation", "SparkRatingEvaluation", "SparkRatingEvaluation.rsquared", "pytest.approx", "SparkRatingEvaluation.rsquared"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_rsquared", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator1", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_true", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator1", ".", "rsquared", "(", ")", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", "\n", "evaluator2", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator2", ".", "rsquared", "(", ")", "==", "target_metrics", "[", "\"rsquared\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_exp_var": [[235, 244], ["SparkRatingEvaluation", "SparkRatingEvaluation", "SparkRatingEvaluation.exp_var", "pytest.approx", "SparkRatingEvaluation.exp_var"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_exp_var", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator1", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_true", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator1", ".", "exp_var", "(", ")", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", "\n", "evaluator2", "=", "SparkRatingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator2", ".", "exp_var", "(", ")", "==", "target_metrics", "[", "\"exp_var\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_recall": [[246, 257], ["SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation.recall_at_k", "SparkRankingEvaluation.recall_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_recall", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator", "=", "SparkRankingEvaluation", "(", "df_true", ",", "df_pred", ")", "\n", "assert", "evaluator", ".", "recall_at_k", "(", ")", "==", "target_metrics", "[", "\"recall\"", "]", "\n", "\n", "evaluator1", "=", "SparkRankingEvaluation", "(", "\n", "df_true", ",", "df_pred", ",", "relevancy_method", "=", "\"by_threshold\"", ",", "threshold", "=", "3.5", "\n", ")", "\n", "assert", "evaluator1", ".", "recall_at_k", "(", ")", "==", "target_metrics", "[", "\"recall\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_precision": [[259, 296], ["SparkRankingEvaluation", "SparkRankingEvaluation", "pandas.DataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "pandas.DataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.precision_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_precision", "(", "spark_data", ",", "target_metrics", ",", "spark", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator", "=", "SparkRankingEvaluation", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "\n", "assert", "evaluator", ".", "precision_at_k", "(", ")", "==", "target_metrics", "[", "\"precision\"", "]", "\n", "\n", "evaluator1", "=", "SparkRankingEvaluation", "(", "\n", "df_true", ",", "df_pred", ",", "relevancy_method", "=", "\"by_threshold\"", ",", "threshold", "=", "3.5", "\n", ")", "\n", "assert", "evaluator1", ".", "precision_at_k", "(", ")", "==", "target_metrics", "[", "\"precision\"", "]", "\n", "\n", "# Check normalization", "\n", "single_user", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"userID\"", ":", "[", "1", ",", "1", ",", "1", "]", ",", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", "]", ",", "\"rating\"", ":", "[", "5", ",", "4", ",", "3", "]", "}", "\n", ")", "\n", "df_single", "=", "spark", ".", "createDataFrame", "(", "single_user", ")", "\n", "evaluator2", "=", "SparkRankingEvaluation", "(", "\n", "df_single", ",", "df_single", ",", "k", "=", "3", ",", "col_prediction", "=", "\"rating\"", "\n", ")", "\n", "assert", "evaluator2", ".", "precision_at_k", "(", ")", "==", "1", "\n", "\n", "same_items", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"userID\"", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "\"itemID\"", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "2", ",", "3", "]", ",", "\n", "\"rating\"", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", "]", ",", "\n", "}", "\n", ")", "\n", "df_same", "=", "spark", ".", "createDataFrame", "(", "same_items", ")", "\n", "evaluator3", "=", "SparkRankingEvaluation", "(", "df_same", ",", "df_same", ",", "k", "=", "3", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator3", ".", "precision_at_k", "(", ")", "==", "1", "\n", "\n", "# Check that if the sample size is smaller than k, the maximum precision can not be 1", "\n", "# if we do precision@5 when there is only 3 items, we can get a maximum of 3/5.", "\n", "evaluator4", "=", "SparkRankingEvaluation", "(", "df_same", ",", "df_same", ",", "k", "=", "5", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator4", ".", "precision_at_k", "(", ")", "==", "0.6", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_ndcg": [[298, 312], ["SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.ndcg_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_ndcg", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator0", "=", "SparkRankingEvaluation", "(", "df_true", ",", "df_true", ",", "k", "=", "10", ",", "col_prediction", "=", "\"rating\"", ")", "\n", "assert", "evaluator0", ".", "ndcg_at_k", "(", ")", "==", "1.0", "\n", "\n", "evaluator", "=", "SparkRankingEvaluation", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "\n", "assert", "evaluator", ".", "ndcg_at_k", "(", ")", "==", "target_metrics", "[", "\"ndcg\"", "]", "\n", "\n", "evaluator1", "=", "SparkRankingEvaluation", "(", "\n", "df_true", ",", "df_pred", ",", "relevancy_method", "=", "\"by_threshold\"", ",", "threshold", "=", "3.5", "\n", ")", "\n", "assert", "evaluator1", ".", "ndcg_at_k", "(", ")", "==", "target_metrics", "[", "\"ndcg\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_map": [[314, 330], ["SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation", "SparkRankingEvaluation.map_at_k", "SparkRankingEvaluation.map_at_k", "SparkRankingEvaluation.map_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_map", "(", "spark_data", ",", "target_metrics", ")", ":", "\n", "    ", "df_true", ",", "df_pred", "=", "spark_data", "\n", "\n", "evaluator1", "=", "SparkRankingEvaluation", "(", "\n", "k", "=", "10", ",", "rating_true", "=", "df_true", ",", "rating_pred", "=", "df_true", ",", "col_prediction", "=", "\"rating\"", "\n", ")", "\n", "assert", "evaluator1", ".", "map_at_k", "(", ")", "==", "1.0", "\n", "\n", "evaluator", "=", "SparkRankingEvaluation", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "\n", "assert", "evaluator", ".", "map_at_k", "(", ")", "==", "target_metrics", "[", "\"map\"", "]", "\n", "\n", "evaluator1", "=", "SparkRankingEvaluation", "(", "\n", "df_true", ",", "df_pred", ",", "relevancy_method", "=", "\"by_threshold\"", ",", "threshold", "=", "3.5", "\n", ")", "\n", "assert", "evaluator1", ".", "map_at_k", "(", ")", "==", "target_metrics", "[", "\"map\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_spark_python_match": [[332, 413], ["spark.createDataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "spark.createDataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "spark.createDataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "spark.createDataFrame", "spark.createDataFrame", "SparkRankingEvaluation", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.map_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.map_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.map_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.map_at_k", "pytest.approx", "SparkRankingEvaluation.recall_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.map_at_k", "SparkRankingEvaluation.recall_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.map_at_k", "SparkRankingEvaluation.recall_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.map_at_k", "SparkRankingEvaluation.recall_at_k", "SparkRankingEvaluation.precision_at_k", "SparkRankingEvaluation.ndcg_at_k", "SparkRankingEvaluation.map_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_spark_python_match", "(", "python_data", ",", "spark", ")", ":", "\n", "# Test on the original data with k = 10.", "\n", "    ", "df_true", ",", "df_pred", "=", "python_data", "\n", "\n", "dfs_true", "=", "spark", ".", "createDataFrame", "(", "df_true", ")", "\n", "dfs_pred", "=", "spark", ".", "createDataFrame", "(", "df_pred", ")", "\n", "\n", "eval_spark1", "=", "SparkRankingEvaluation", "(", "dfs_true", ",", "dfs_pred", ",", "k", "=", "10", ")", "\n", "\n", "assert", "recall_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark1", ".", "recall_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "precision_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark1", ".", "precision_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "ndcg_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark1", ".", "ndcg_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "map_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark1", ".", "map_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "\n", "# Test on the original data with k = 3.", "\n", "dfs_true", "=", "spark", ".", "createDataFrame", "(", "df_true", ")", "\n", "dfs_pred", "=", "spark", ".", "createDataFrame", "(", "df_pred", ")", "\n", "\n", "eval_spark2", "=", "SparkRankingEvaluation", "(", "dfs_true", ",", "dfs_pred", ",", "k", "=", "3", ")", "\n", "\n", "assert", "recall_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "3", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark2", ".", "recall_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "precision_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "3", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark2", ".", "precision_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "ndcg_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "3", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark2", ".", "ndcg_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "map_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "3", ")", "==", "pytest", ".", "approx", "(", "eval_spark2", ".", "map_at_k", "(", ")", ",", "TOL", ")", "\n", "\n", "# Remove the first row from the original data.", "\n", "df_pred", "=", "df_pred", "[", "1", ":", "-", "1", "]", "\n", "\n", "dfs_true", "=", "spark", ".", "createDataFrame", "(", "df_true", ")", "\n", "dfs_pred", "=", "spark", ".", "createDataFrame", "(", "df_pred", ")", "\n", "\n", "eval_spark3", "=", "SparkRankingEvaluation", "(", "dfs_true", ",", "dfs_pred", ",", "k", "=", "10", ")", "\n", "\n", "assert", "recall_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark3", ".", "recall_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "precision_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark3", ".", "precision_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "ndcg_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark3", ".", "ndcg_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "map_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark3", ".", "map_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "\n", "# Test with one user", "\n", "df_pred", "=", "df_pred", ".", "loc", "[", "df_pred", "[", "\"userID\"", "]", "==", "3", "]", "\n", "df_true", "=", "df_true", ".", "loc", "[", "df_true", "[", "\"userID\"", "]", "==", "3", "]", "\n", "\n", "dfs_true", "=", "spark", ".", "createDataFrame", "(", "df_true", ")", "\n", "dfs_pred", "=", "spark", ".", "createDataFrame", "(", "df_pred", ")", "\n", "\n", "eval_spark4", "=", "SparkRankingEvaluation", "(", "dfs_true", ",", "dfs_pred", ",", "k", "=", "10", ")", "\n", "\n", "assert", "recall_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark4", ".", "recall_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "precision_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark4", ".", "precision_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "ndcg_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark4", ".", "ndcg_at_k", "(", ")", ",", "TOL", "\n", ")", "\n", "assert", "map_at_k", "(", "df_true", ",", "df_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "\n", "eval_spark4", ".", "map_at_k", "(", ")", ",", "TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_catalog_coverage": [[416, 424], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.catalog_coverage"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.catalog_coverage"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_catalog_coverage", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "c_coverage", "=", "evaluator", ".", "catalog_coverage", "(", ")", "\n", "assert", "c_coverage", "==", "target_metrics", "[", "\"c_coverage\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_distributional_coverage": [[426, 434], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.distributional_coverage"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.distributional_coverage"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_distributional_coverage", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "d_coverage", "=", "evaluator", ".", "distributional_coverage", "(", ")", "\n", "assert", "d_coverage", "==", "target_metrics", "[", "\"d_coverage\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_item_novelty": [[436, 454], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.historical_item_novelty().toPandas", "pandas.util.testing.assert_frame_equal", "numpy.all", "train_df.filter", "SparkDiversityEvaluation", "SparkDiversityEvaluation.historical_item_novelty().toPandas", "SparkDiversityEvaluation.historical_item_novelty", "SparkDiversityEvaluation.historical_item_novelty"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_item_novelty", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "actual", "=", "evaluator", ".", "historical_item_novelty", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"item_novelty\"", "]", ",", "actual", ",", "check_exact", "=", "False", ",", "check_less_precise", "=", "4", "\n", ")", "\n", "assert", "np", ".", "all", "(", "actual", "[", "\"item_novelty\"", "]", ".", "values", ">=", "0", ")", "\n", "# Test that novelty is zero when data includes only one item", "\n", "train_df_new", "=", "train_df", ".", "filter", "(", "\"ItemId == 3\"", ")", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df_new", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "actual", "=", "evaluator", ".", "historical_item_novelty", "(", ")", ".", "toPandas", "(", ")", "\n", "assert", "actual", "[", "\"item_novelty\"", "]", ".", "values", "[", "0", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_novelty": [[456, 472], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.novelty", "train_df.filter", "reco_df.filter", "SparkDiversityEvaluation", "SparkDiversityEvaluation.novelty"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.novelty", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.novelty"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_novelty", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "novelty", "=", "evaluator", ".", "novelty", "(", ")", "\n", "assert", "target_metrics", "[", "\"novelty\"", "]", "==", "novelty", "\n", "assert", "novelty", ">=", "0", "\n", "# Test that novelty is zero when data includes only one item", "\n", "train_df_new", "=", "train_df", ".", "filter", "(", "\"ItemId == 3\"", ")", "\n", "reco_df_new", "=", "reco_df", ".", "filter", "(", "\"ItemId == 3\"", ")", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df_new", ",", "reco_df", "=", "reco_df_new", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "evaluator", ".", "novelty", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_diversity": [[474, 486], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_diversity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_diversity", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_diversity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_diversity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_diversity": [[489, 496], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.diversity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_diversity", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "target_metrics", "[", "\"diversity\"", "]", "==", "evaluator", ".", "diversity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_item_serendipity": [[498, 514], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_item_serendipity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_item_serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_item_serendipity", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_item_serendipity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_item_serendipity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_serendipity": [[517, 533], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_serendipity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_serendipity", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_serendipity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_serendipity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_serendipity": [[536, 547], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_serendipity", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert", "target_metrics", "[", "\"serendipity\"", "]", "==", "evaluator", ".", "serendipity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_diversity_item_feature_vector": [[549, 566], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_diversity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_diversity_item_feature_vector", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_diversity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_diversity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_diversity_item_feature_vector": [[569, 581], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.diversity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_diversity_item_feature_vector", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", ")", "\n", "assert", "target_metrics", "[", "\"diversity_item_feature_vector\"", "]", "==", "evaluator", ".", "diversity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_item_serendipity_item_feature_vector": [[583, 603], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_item_serendipity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_item_serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_item_serendipity_item_feature_vector", "(", "\n", "spark_diversity_data", ",", "target_metrics", "\n", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_item_serendipity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_item_serendipity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_user_serendipity_item_feature_vector": [[606, 624], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.user_serendipity().toPandas", "pandas.util.testing.assert_frame_equal", "SparkDiversityEvaluation.user_serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_user_serendipity_item_feature_vector", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "actual", "=", "evaluator", ".", "user_serendipity", "(", ")", ".", "toPandas", "(", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_serendipity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_spark_evaluation.test_serendipity_item_feature_vector": [[627, 640], ["SparkDiversityEvaluation", "SparkDiversityEvaluation.serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.serendipity"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_serendipity_item_feature_vector", "(", "spark_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "spark_diversity_data", "\n", "evaluator", "=", "SparkDiversityEvaluation", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert", "target_metrics", "[", "\"serendipity_item_feature_vector\"", "]", "==", "evaluator", ".", "serendipity", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.rating_true": [[46, 53], ["pandas.DataFrame"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "rating_true", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "1", ",", "1", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "3", ",", "1", ",", "4", ",", "5", ",", "6", ",", "7", ",", "2", ",", "5", ",", "6", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "1", ",", "2", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "1", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "1", ",", "5", ",", "4", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.rating_pred": [[57, 65], ["pandas.DataFrame"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "rating_pred", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "1", ",", "1", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "12", ",", "10", ",", "3", ",", "5", ",", "11", ",", "13", ",", "4", ",", "10", ",", "7", ",", "13", ",", "1", ",", "3", ",", "5", ",", "2", ",", "11", ",", "14", ",", "3", ",", "10", "]", ",", "\n", "DEFAULT_PREDICTION_COL", ":", "[", "12", ",", "14", ",", "13", ",", "12", ",", "11", ",", "10", ",", "14", ",", "13", ",", "12", ",", "11", ",", "10", ",", "9", ",", "8", ",", "7", ",", "6", ",", "5", ",", "14", ",", "13", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "1", ",", "5", ",", "5", ",", "5", ",", "4", ",", "4", ",", "3", ",", "3", ",", "3", ",", "2", ",", "1", ",", "5", ",", "4", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.rating_nohit": [[69, 76], ["pandas.DataFrame"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "rating_nohit", "(", ")", ":", "\n", "    ", "return", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "3", ",", "1", ",", "1", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "100", "]", "*", "18", ",", "\n", "DEFAULT_PREDICTION_COL", ":", "[", "12", ",", "14", ",", "13", ",", "12", ",", "11", ",", "10", ",", "14", ",", "13", ",", "12", ",", "11", ",", "10", ",", "9", ",", "8", ",", "7", ",", "6", ",", "5", ",", "14", ",", "13", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.rating_true_binary": [[81, 88], ["rating_true[].apply"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "rating_true_binary", "(", "rating_true", ")", ":", "\n", "# Convert true ratings to binary", "\n", "    ", "rating_true", "[", "DEFAULT_RATING_COL", "]", "=", "rating_true", "[", "DEFAULT_RATING_COL", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "1.0", "if", "x", ">=", "3", "else", "0.0", "\n", ")", "\n", "return", "rating_true", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.rating_pred_binary": [[90, 97], ["sklearn.preprocessing.minmax_scale", "rating_pred[].astype"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "rating_pred_binary", "(", "rating_pred", ")", ":", "\n", "# Normalize the predictions", "\n", "    ", "rating_pred", "[", "DEFAULT_PREDICTION_COL", "]", "=", "minmax_scale", "(", "\n", "rating_pred", "[", "DEFAULT_PREDICTION_COL", "]", ".", "astype", "(", "float", ")", "\n", ")", "\n", "return", "rating_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_column_dtypes_match": [[99, 113], ["rating_true[].astype", "rating_true[].astype", "pytest.raises", "recommenders.evaluation.python_evaluation._check_column_dtypes", "unittest.mock.Mock"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation._check_column_dtypes"], ["", "def", "test_column_dtypes_match", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "# Change data types of true and prediction data, and there should type error produced", "\n", "    ", "rating_true", "[", "DEFAULT_USER_COL", "]", "=", "rating_true", "[", "DEFAULT_USER_COL", "]", ".", "astype", "(", "str", ")", "\n", "rating_true", "[", "DEFAULT_RATING_COL", "]", "=", "rating_true", "[", "DEFAULT_RATING_COL", "]", ".", "astype", "(", "str", ")", "\n", "\n", "expected_error", "=", "\"Columns in provided DataFrames are not the same datatype\"", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ",", "match", "=", "expected_error", ")", ":", "\n", "        ", "_check_column_dtypes", "(", "Mock", "(", ")", ")", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_merge_rating": [[116, 131], ["recommenders.evaluation.python_evaluation.merge_rating_true_pred", "numpy.array", "numpy.array", "numpy.all", "numpy.all"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_rating_true_pred"], ["", "", "def", "test_merge_rating", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "y_true", ",", "y_pred", "=", "merge_rating_true_pred", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "target_y_true", "=", "np", ".", "array", "(", "[", "3", ",", "3", ",", "5", ",", "5", ",", "3", ",", "3", ",", "2", ",", "1", "]", ")", "\n", "target_y_pred", "=", "np", ".", "array", "(", "[", "14", ",", "12", ",", "7", ",", "8", ",", "13", ",", "6", ",", "11", ",", "5", "]", ")", "\n", "\n", "assert", "y_true", ".", "shape", "==", "y_pred", ".", "shape", "\n", "assert", "np", ".", "all", "(", "y_true", "==", "target_y_true", ")", "\n", "assert", "np", ".", "all", "(", "y_pred", "==", "target_y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_merge_ranking": [[133, 153], ["recommenders.evaluation.python_evaluation.merge_ranking_true_pred", "isinstance", "isinstance", "set().intersection", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.merge_ranking_true_pred"], ["", "def", "test_merge_ranking", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "\n", "    ", "data_hit", ",", "data_hit_count", ",", "n_users", "=", "merge_ranking_true_pred", "(", "\n", "rating_true", ",", "\n", "rating_pred", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "relevancy_method", "=", "\"top_k\"", ",", "\n", ")", "\n", "\n", "assert", "isinstance", "(", "data_hit", ",", "pd", ".", "DataFrame", ")", "\n", "\n", "assert", "isinstance", "(", "data_hit_count", ",", "pd", ".", "DataFrame", ")", "\n", "columns", "=", "data_hit_count", ".", "columns", "\n", "columns_exp", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", ",", "DEFAULT_PREDICTION_COL", "]", "\n", "assert", "set", "(", "columns", ")", ".", "intersection", "(", "set", "(", "columns_exp", ")", ")", "is", "not", "None", "\n", "\n", "assert", "n_users", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_rmse": [[155, 165], ["recommenders.evaluation.python_evaluation.rmse", "recommenders.evaluation.python_evaluation.rmse", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse"], ["", "def", "test_python_rmse", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "assert", "(", "\n", "rmse", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "0", "\n", ")", "\n", "assert", "rmse", "(", "rating_true", ",", "rating_pred", ")", "==", "pytest", ".", "approx", "(", "7.254309", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_mae": [[167, 177], ["recommenders.evaluation.python_evaluation.mae", "recommenders.evaluation.python_evaluation.mae", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae"], ["", "def", "test_python_mae", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "assert", "(", "\n", "mae", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "0", "\n", ")", "\n", "assert", "mae", "(", "rating_true", ",", "rating_pred", ")", "==", "pytest", ".", "approx", "(", "6.375", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_rsquared": [[179, 189], ["recommenders.evaluation.python_evaluation.rsquared", "pytest.approx", "recommenders.evaluation.python_evaluation.rsquared", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared"], ["", "def", "test_python_rsquared", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "assert", "(", "\n", "rsquared", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", ")", "\n", "assert", "rsquared", "(", "rating_true", ",", "rating_pred", ")", "==", "pytest", ".", "approx", "(", "-", "31.699029", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_exp_var": [[191, 201], ["recommenders.evaluation.python_evaluation.exp_var", "pytest.approx", "recommenders.evaluation.python_evaluation.exp_var", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var"], ["", "def", "test_python_exp_var", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "assert", "(", "\n", "exp_var", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", ")", "\n", "assert", "exp_var", "(", "rating_true", ",", "rating_pred", ")", "==", "pytest", ".", "approx", "(", "-", "6.4466", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_ndcg_at_k": [[203, 215], ["recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.ndcg_at_k", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k"], ["", "def", "test_python_ndcg_at_k", "(", "rating_true", ",", "rating_pred", ",", "rating_nohit", ")", ":", "\n", "    ", "assert", "(", "\n", "ndcg_at_k", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "10", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", ")", "\n", "assert", "ndcg_at_k", "(", "rating_true", ",", "rating_nohit", ",", "k", "=", "10", ")", "==", "0.0", "\n", "assert", "ndcg_at_k", "(", "rating_true", ",", "rating_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "0.38172", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_map_at_k": [[217, 229], ["recommenders.evaluation.python_evaluation.map_at_k", "recommenders.evaluation.python_evaluation.map_at_k", "recommenders.evaluation.python_evaluation.map_at_k", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k"], ["", "def", "test_python_map_at_k", "(", "rating_true", ",", "rating_pred", ",", "rating_nohit", ")", ":", "\n", "    ", "assert", "(", "\n", "map_at_k", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "10", ",", "\n", ")", "\n", "==", "1", "\n", ")", "\n", "assert", "map_at_k", "(", "rating_true", ",", "rating_nohit", ",", "k", "=", "10", ")", "==", "0.0", "\n", "assert", "map_at_k", "(", "rating_true", ",", "rating_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "0.23613", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_precision": [[231, 290], ["pandas.DataFrame", "pandas.DataFrame", "recommenders.evaluation.python_evaluation.precision_at_k", "recommenders.evaluation.python_evaluation.precision_at_k", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.precision_at_k", "recommenders.evaluation.python_evaluation.precision_at_k", "recommenders.evaluation.python_evaluation.precision_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k"], ["", "def", "test_python_precision", "(", "rating_true", ",", "rating_pred", ",", "rating_nohit", ")", ":", "\n", "    ", "assert", "(", "\n", "precision_at_k", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "10", ",", "\n", ")", "\n", "==", "0.6", "\n", ")", "\n", "assert", "precision_at_k", "(", "rating_true", ",", "rating_nohit", ",", "k", "=", "10", ")", "==", "0.0", "\n", "assert", "precision_at_k", "(", "rating_true", ",", "rating_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "0.26666", ",", "TOL", ")", "\n", "\n", "# Check normalization", "\n", "single_user", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "1", ",", "2", ",", "3", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", "]", ",", "\n", "}", "\n", ")", "\n", "assert", "(", "\n", "precision_at_k", "(", "\n", "rating_true", "=", "single_user", ",", "\n", "rating_pred", "=", "single_user", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "3", ",", "\n", ")", "\n", "==", "1", "\n", ")", "\n", "\n", "same_items", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "DEFAULT_USER_COL", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "DEFAULT_ITEM_COL", ":", "[", "1", ",", "2", ",", "3", ",", "1", ",", "2", ",", "3", "]", ",", "\n", "DEFAULT_RATING_COL", ":", "[", "5", ",", "4", ",", "3", ",", "5", ",", "5", ",", "3", "]", ",", "\n", "}", "\n", ")", "\n", "assert", "(", "\n", "precision_at_k", "(", "\n", "rating_true", "=", "same_items", ",", "\n", "rating_pred", "=", "same_items", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "3", ",", "\n", ")", "\n", "==", "1", "\n", ")", "\n", "\n", "# Check that if the sample size is smaller than k, the maximum precision can not be 1", "\n", "# if we do precision@5 when there is only 3 items, we can get a maximum of 3/5.", "\n", "assert", "(", "\n", "precision_at_k", "(", "\n", "rating_true", "=", "same_items", ",", "\n", "rating_pred", "=", "same_items", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "5", ",", "\n", ")", "\n", "==", "0.6", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_recall": [[293, 305], ["recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx", "recommenders.evaluation.python_evaluation.recall_at_k", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "def", "test_python_recall", "(", "rating_true", ",", "rating_pred", ",", "rating_nohit", ")", ":", "\n", "    ", "assert", "(", "\n", "recall_at_k", "(", "\n", "rating_true", "=", "rating_true", ",", "\n", "rating_pred", "=", "rating_true", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", "k", "=", "10", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "1", ",", "TOL", ")", "\n", ")", "\n", "assert", "recall_at_k", "(", "rating_true", ",", "rating_nohit", ",", "k", "=", "10", ")", "==", "0.0", "\n", "assert", "recall_at_k", "(", "rating_true", ",", "rating_pred", ",", "k", "=", "10", ")", "==", "pytest", ".", "approx", "(", "0.37777", ",", "TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_auc": [[307, 325], ["recommenders.evaluation.python_evaluation.auc", "pytest.approx", "recommenders.evaluation.python_evaluation.auc", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.auc", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.auc"], ["", "def", "test_python_auc", "(", "rating_true_binary", ",", "rating_pred_binary", ")", ":", "\n", "    ", "assert", "(", "\n", "auc", "(", "\n", "rating_true", "=", "rating_true_binary", ",", "\n", "rating_pred", "=", "rating_true_binary", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "1.0", ",", "TOL", ")", "\n", ")", "\n", "\n", "assert", "(", "\n", "auc", "(", "\n", "rating_true", "=", "rating_true_binary", ",", "\n", "rating_pred", "=", "rating_pred_binary", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "0.75", ",", "TOL", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_logloss": [[328, 346], ["recommenders.evaluation.python_evaluation.logloss", "pytest.approx", "recommenders.evaluation.python_evaluation.logloss", "pytest.approx"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.logloss", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.python_evaluation.logloss"], ["", "def", "test_python_logloss", "(", "rating_true_binary", ",", "rating_pred_binary", ")", ":", "\n", "    ", "assert", "(", "\n", "logloss", "(", "\n", "rating_true", "=", "rating_true_binary", ",", "\n", "rating_pred", "=", "rating_true_binary", ",", "\n", "col_prediction", "=", "DEFAULT_RATING_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "0", ",", "TOL", ")", "\n", ")", "\n", "\n", "assert", "(", "\n", "logloss", "(", "\n", "rating_true", "=", "rating_true_binary", ",", "\n", "rating_pred", "=", "rating_pred_binary", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_prediction", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "==", "pytest", ".", "approx", "(", "0.7835", ",", "TOL", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_python_errors": [[349, 387], ["pytest.raises", "recommenders.evaluation.python_evaluation.rmse", "pytest.raises", "recommenders.evaluation.python_evaluation.mae", "pytest.raises", "recommenders.evaluation.python_evaluation.rsquared", "pytest.raises", "recommenders.evaluation.python_evaluation.exp_var", "pytest.raises", "recommenders.evaluation.python_evaluation.precision_at_k", "pytest.raises", "recommenders.evaluation.python_evaluation.recall_at_k", "pytest.raises", "recommenders.evaluation.python_evaluation.ndcg_at_k", "pytest.raises", "recommenders.evaluation.python_evaluation.map_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k"], ["", "def", "test_python_errors", "(", "rating_true", ",", "rating_pred", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "rmse", "(", "rating_true", ",", "rating_true", ",", "col_user", "=", "\"not_user\"", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "mae", "(", "\n", "rating_pred", ",", "\n", "rating_pred", ",", "\n", "col_rating", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "col_user", "=", "\"not_user\"", ",", "\n", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "rsquared", "(", "rating_true", ",", "rating_pred", ",", "col_item", "=", "\"not_item\"", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "exp_var", "(", "\n", "rating_pred", ",", "\n", "rating_pred", ",", "\n", "col_rating", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "col_item", "=", "\"not_item\"", ",", "\n", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "precision_at_k", "(", "rating_true", ",", "rating_pred", ",", "col_rating", "=", "\"not_rating\"", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "recall_at_k", "(", "rating_true", ",", "rating_pred", ",", "col_prediction", "=", "\"not_prediction\"", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "ndcg_at_k", "(", "rating_true", ",", "rating_true", ",", "col_user", "=", "\"not_user\"", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "map_at_k", "(", "\n", "rating_pred", ",", "\n", "rating_pred", ",", "\n", "col_rating", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "col_user", "=", "\"not_user\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.target_metrics": [[391, 446], ["pytest.fixture", "pytest.approx", "pytest.approx", "pandas.DataFrame", "pytest.approx", "pytest.approx", "pandas.DataFrame", "pytest.approx", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pytest.approx", "pandas.DataFrame", "pandas.DataFrame", "pytest.approx", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["None"], ["", "", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "target_metrics", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"c_coverage\"", ":", "pytest", ".", "approx", "(", "0.8", ",", "TOL", ")", ",", "\n", "\"d_coverage\"", ":", "pytest", ".", "approx", "(", "1.9183", ",", "TOL", ")", ",", "\n", "\"item_novelty\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "ItemId", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "item_novelty", "=", "[", "3.0", ",", "3.0", ",", "2.0", ",", "1.41504", ",", "3.0", "]", ")", "\n", ")", ",", "\n", "\"novelty\"", ":", "pytest", ".", "approx", "(", "2.83333", ",", "TOL", ")", ",", "\n", "\"diversity\"", ":", "pytest", ".", "approx", "(", "0.43096", ",", "TOL", ")", ",", "\n", "\"user_diversity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_diversity", "=", "[", "0.29289", ",", "1.0", ",", "0.0", "]", ")", "\n", ")", ",", "\n", "# diversity values when using item features to calculate item similarity", "\n", "\"diversity_item_feature_vector\"", ":", "pytest", ".", "approx", "(", "0.5000", ",", "TOL", ")", ",", "\n", "\"user_diversity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_diversity", "=", "[", "0.5000", ",", "0.5000", ",", "0.5000", "]", ")", "\n", ")", ",", "\n", "\"user_item_serendipity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "ItemId", "=", "[", "3", ",", "5", ",", "2", ",", "5", ",", "1", ",", "2", "]", ",", "\n", "user_item_serendipity", "=", "[", "\n", "0.72783", ",", "\n", "0.0", ",", "\n", "0.71132", ",", "\n", "0.35777", ",", "\n", "0.80755", ",", "\n", "0.0", ",", "\n", "]", ",", "\n", ")", "\n", ")", ",", "\n", "\"user_serendipity\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_serendipity", "=", "[", "0.363915", ",", "0.53455", ",", "0.403775", "]", ")", "\n", ")", ",", "\n", "\"serendipity\"", ":", "pytest", ".", "approx", "(", "0.43408", ",", "TOL", ")", ",", "\n", "# serendipity values when using item features to calculate item similarity", "\n", "\"user_item_serendipity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "\n", "UserId", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "ItemId", "=", "[", "3", ",", "5", ",", "2", ",", "5", ",", "1", ",", "2", "]", ",", "\n", "user_item_serendipity", "=", "[", "\n", "0.5000", ",", "\n", "0.0", ",", "\n", "0.75", ",", "\n", "0.5000", ",", "\n", "0.6667", ",", "\n", "0.0", ",", "\n", "]", ",", "\n", ")", "\n", ")", ",", "\n", "\"user_serendipity_item_feature_vector\"", ":", "pd", ".", "DataFrame", "(", "\n", "dict", "(", "UserId", "=", "[", "1", ",", "2", ",", "3", "]", ",", "user_serendipity", "=", "[", "0.2500", ",", "0.625", ",", "0.3333", "]", ")", "\n", ")", ",", "\n", "\"serendipity_item_feature_vector\"", ":", "pytest", ".", "approx", "(", "0.4028", ",", "TOL", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.python_diversity_data": [[449, 476], ["pytest.fixture", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "python_diversity_data", "(", ")", ":", "\n", "    ", "train_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\"UserId\"", ":", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "3", "]", ",", "\"ItemId\"", ":", "[", "1", ",", "2", ",", "4", ",", "3", ",", "4", ",", "3", ",", "4", ",", "5", "]", "}", "\n", ")", "\n", "\n", "reco_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"UserId\"", ":", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "\"ItemId\"", ":", "[", "3", ",", "5", ",", "2", ",", "5", ",", "1", ",", "2", "]", ",", "\n", "\"Relevance\"", ":", "[", "1", ",", "0", ",", "1", ",", "1", ",", "1", ",", "0", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "item_feature_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"ItemId\"", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", "\"features\"", ":", "[", "\n", "np", ".", "array", "(", "[", "0.0", ",", "1.0", ",", "1.0", ",", "0.0", ",", "0.0", "]", ",", "dtype", "=", "float", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0", ",", "1.0", ",", "0.0", ",", "1.0", ",", "0.0", "]", ",", "dtype", "=", "float", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", ",", "0.0", "]", ",", "dtype", "=", "float", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "0.0", ",", "1.0", "]", ",", "dtype", "=", "float", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ",", "dtype", "=", "float", ")", ",", "\n", "]", ",", "\n", "}", "\n", ")", "\n", "return", "train_df", ",", "reco_df", ",", "item_feature_df", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_catalog_coverage": [[478, 484], ["recommenders.evaluation.python_evaluation.catalog_coverage"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.catalog_coverage"], ["", "def", "test_catalog_coverage", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "c_coverage", "=", "catalog_coverage", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "c_coverage", "==", "target_metrics", "[", "\"c_coverage\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_distributional_coverage": [[486, 492], ["recommenders.evaluation.python_evaluation.distributional_coverage"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.distributional_coverage"], ["", "def", "test_distributional_coverage", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "d_coverage", "=", "distributional_coverage", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "d_coverage", "==", "target_metrics", "[", "\"d_coverage\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_item_novelty": [[494, 509], ["recommenders.evaluation.python_evaluation.historical_item_novelty", "pandas.util.testing.assert_frame_equal", "numpy.all", "recommenders.evaluation.python_evaluation.historical_item_novelty"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.historical_item_novelty"], ["", "def", "test_item_novelty", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "actual", "=", "historical_item_novelty", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"item_novelty\"", "]", ",", "actual", ",", "check_exact", "=", "False", ",", "check_less_precise", "=", "4", "\n", ")", "\n", "assert", "np", ".", "all", "(", "actual", "[", "\"item_novelty\"", "]", ".", "values", ">=", "0", ")", "\n", "# Test that novelty is zero when data includes only one item", "\n", "train_df_new", "=", "train_df", ".", "loc", "[", "train_df", "[", "\"ItemId\"", "]", "==", "3", "]", "\n", "actual", "=", "historical_item_novelty", "(", "\n", "train_df", "=", "train_df_new", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "actual", "[", "\"item_novelty\"", "]", ".", "values", "[", "0", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_novelty": [[511, 529], ["recommenders.evaluation.python_evaluation.novelty", "recommenders.evaluation.python_evaluation.novelty"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.novelty", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.novelty"], ["", "def", "test_novelty", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "actual", "=", "novelty", "(", "\n", "train_df", "=", "train_df", ",", "reco_df", "=", "reco_df", ",", "col_user", "=", "\"UserId\"", ",", "col_item", "=", "\"ItemId\"", "\n", ")", "\n", "assert", "target_metrics", "[", "\"novelty\"", "]", "==", "actual", "\n", "assert", "actual", ">=", "0", "\n", "# Test that novelty is zero when data includes only one item", "\n", "train_df_new", "=", "train_df", ".", "loc", "[", "train_df", "[", "\"ItemId\"", "]", "==", "3", "]", "\n", "reco_df_new", "=", "reco_df", ".", "loc", "[", "reco_df", "[", "\"ItemId\"", "]", "==", "3", "]", "\n", "assert", "(", "\n", "novelty", "(", "\n", "train_df", "=", "train_df_new", ",", "\n", "reco_df", "=", "reco_df_new", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", ")", "\n", "==", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_diversity": [[532, 549], ["recommenders.evaluation.python_evaluation.user_diversity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "def", "test_user_diversity", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "actual", "=", "user_diversity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "\"item_cooccurrence_count\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_diversity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_diversity": [[552, 563], ["recommenders.evaluation.python_evaluation.diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.diversity"], ["", "def", "test_diversity", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "assert", "target_metrics", "[", "\"diversity\"", "]", "==", "diversity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "\"item_cooccurrence_count\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_item_serendipity": [[566, 583], ["recommenders.evaluation.python_evaluation.user_item_serendipity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "def", "test_user_item_serendipity", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "actual", "=", "user_item_serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "\"item_cooccurrence_count\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_item_serendipity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_serendipity": [[586, 603], ["recommenders.evaluation.python_evaluation.user_serendipity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "def", "test_user_serendipity", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "actual", "=", "user_serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "\"item_cooccurrence_count\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_serendipity\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_serendipity": [[606, 617], ["recommenders.evaluation.python_evaluation.serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.serendipity"], ["", "def", "test_serendipity", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "_", "=", "python_diversity_data", "\n", "assert", "target_metrics", "[", "\"serendipity\"", "]", "==", "serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "None", ",", "\n", "item_sim_measure", "=", "\"item_cooccurrence_count\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_diversity_item_feature_vector": [[620, 637], ["recommenders.evaluation.python_evaluation.user_diversity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_diversity"], ["", "def", "test_user_diversity_item_feature_vector", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "python_diversity_data", "\n", "actual", "=", "user_diversity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_diversity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_diversity_item_feature_vector": [[640, 651], ["recommenders.evaluation.python_evaluation.diversity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.diversity"], ["", "def", "test_diversity_item_feature_vector", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "python_diversity_data", "\n", "assert", "target_metrics", "[", "\"diversity_item_feature_vector\"", "]", "==", "diversity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_item_serendipity_item_feature_vector": [[654, 673], ["recommenders.evaluation.python_evaluation.user_item_serendipity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_item_serendipity"], ["", "def", "test_user_item_serendipity_item_feature_vector", "(", "\n", "python_diversity_data", ",", "target_metrics", "\n", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "python_diversity_data", "\n", "actual", "=", "user_item_serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_item_serendipity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_user_serendipity_item_feature_vector": [[676, 693], ["recommenders.evaluation.python_evaluation.user_serendipity", "pandas.util.testing.assert_frame_equal"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.user_serendipity"], ["", "def", "test_user_serendipity_item_feature_vector", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "python_diversity_data", "\n", "actual", "=", "user_serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n", "assert_frame_equal", "(", "\n", "target_metrics", "[", "\"user_serendipity_item_feature_vector\"", "]", ",", "\n", "actual", ",", "\n", "check_exact", "=", "False", ",", "\n", "check_less_precise", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.test_python_evaluation.test_serendipity_item_feature_vector": [[696, 707], ["recommenders.evaluation.python_evaluation.serendipity"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkDiversityEvaluation.serendipity"], ["", "def", "test_serendipity_item_feature_vector", "(", "python_diversity_data", ",", "target_metrics", ")", ":", "\n", "    ", "train_df", ",", "reco_df", ",", "item_feature_df", "=", "python_diversity_data", "\n", "assert", "target_metrics", "[", "\"serendipity_item_feature_vector\"", "]", "==", "serendipity", "(", "\n", "train_df", "=", "train_df", ",", "\n", "reco_df", "=", "reco_df", ",", "\n", "item_feature_df", "=", "item_feature_df", ",", "\n", "item_sim_measure", "=", "\"item_feature_vector\"", ",", "\n", "col_user", "=", "\"UserId\"", ",", "\n", "col_item", "=", "\"ItemId\"", ",", "\n", "col_sim", "=", "\"sim\"", ",", "\n", "col_relevance", "=", "\"Relevance\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tools.databricks_install.dbfs_file_exists": [[97, 113], ["databricks_cli.dbfs.api.DbfsApi().list_files", "databricks_cli.dbfs.api.DbfsApi", "databricks_cli.dbfs.dbfs_path.DbfsPath"], "function", ["None"], ["def", "dbfs_file_exists", "(", "api_client", ",", "dbfs_path", ")", ":", "\n", "    ", "\"\"\"Checks to determine whether a file exists.\n\n    Args:\n        api_client (ApiClient object): Object used for authenticating to the workspace\n        dbfs_path (str): Path to check\n\n    Returns:\n        bool: True if file exists on dbfs, False otherwise.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "DbfsApi", "(", "api_client", ")", ".", "list_files", "(", "dbfs_path", "=", "DbfsPath", "(", "dbfs_path", ")", ")", "\n", "file_exists", "=", "True", "\n", "", "except", "Exception", ":", "\n", "        ", "file_exists", "=", "False", "\n", "", "return", "file_exists", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tools.databricks_install.get_installed_libraries": [[115, 128], ["databricks_cli.libraries.api.LibrariesApi().cluster_status", "databricks_cli.libraries.api.LibrariesApi", "pkg_resources.Requirement.parse"], "function", ["None"], ["", "def", "get_installed_libraries", "(", "api_client", ",", "cluster_id", ")", ":", "\n", "    ", "\"\"\"Returns the installed PyPI packages and the ones that failed.\n\n    Args:\n        api_client (ApiClient object): object used for authenticating to the workspace\n        cluster_id (str): id of the cluster\n\n    Returns:\n        Dict[str, str]: dictionary of {package: status}\n    \"\"\"", "\n", "cluster_status", "=", "LibrariesApi", "(", "api_client", ")", ".", "cluster_status", "(", "cluster_id", ")", "\n", "libraries", "=", "{", "lib", "[", "\"library\"", "]", "[", "\"pypi\"", "]", "[", "\"package\"", "]", ":", "lib", "[", "\"status\"", "]", "for", "lib", "in", "cluster_status", "[", "\"library_statuses\"", "]", "if", "\"pypi\"", "in", "lib", "[", "\"library\"", "]", "}", "\n", "return", "{", "pkg_resources", ".", "Requirement", ".", "parse", "(", "package", ")", ".", "name", ":", "libraries", "[", "package", "]", "for", "package", "in", "libraries", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tools.databricks_install.prepare_for_operationalization": [[130, 176], ["print", "os.path.basename", "pathlib.Path().as_posix", "print", "databricks_cli.dbfs.api.DbfsApi().cp", "libs2install.extend", "print", "databricks_cli.libraries.api.LibrariesApi().install_libraries", "print", "urllib.request.urlretrieve", "print", "databricks_install.dbfs_file_exists", "print", "os.path.exists", "pathlib.Path", "databricks_cli.dbfs.api.DbfsApi", "databricks_cli.libraries.api.LibrariesApi"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tools.databricks_install.dbfs_file_exists"], ["", "def", "prepare_for_operationalization", "(", "\n", "cluster_id", ",", "api_client", ",", "dbfs_path", ",", "overwrite", ",", "spark_version", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Installs appropriate versions of several libraries to support operationalization.\n\n    Args:\n        cluster_id (str): cluster_id representing the cluster to prepare for operationalization\n        api_client (ApiClient): the ApiClient object used to authenticate to the workspace\n        dbfs_path (str): the path on dbfs to upload libraries to\n        overwrite (bool): whether to overwrite existing files on dbfs with new files of the same name\n        spark_version (str): str version indicating which version of spark is installed on the databricks cluster\n\n    Returns:\n        A dictionary of libraries installed\n    \"\"\"", "\n", "print", "(", "\"Preparing for operationlization...\"", ")", "\n", "\n", "cosmosdb_jar_url", "=", "COSMOSDB_JAR_FILE_OPTIONS", "[", "spark_version", "]", "\n", "\n", "# download the cosmosdb jar", "\n", "local_jarname", "=", "os", ".", "path", ".", "basename", "(", "cosmosdb_jar_url", ")", "\n", "# only download if you need it:", "\n", "if", "overwrite", "or", "not", "os", ".", "path", ".", "exists", "(", "local_jarname", ")", ":", "\n", "        ", "print", "(", "\"Downloading {}...\"", ".", "format", "(", "cosmosdb_jar_url", ")", ")", "\n", "local_jarname", ",", "_", "=", "urlretrieve", "(", "cosmosdb_jar_url", ",", "local_jarname", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"File {} already downloaded.\"", ".", "format", "(", "local_jarname", ")", ")", "\n", "\n", "# upload jar to dbfs:", "\n", "", "upload_path", "=", "Path", "(", "dbfs_path", ",", "local_jarname", ")", ".", "as_posix", "(", ")", "\n", "print", "(", "\"Uploading CosmosDB driver to databricks at {}\"", ".", "format", "(", "upload_path", ")", ")", "\n", "if", "dbfs_file_exists", "(", "api_client", ",", "upload_path", ")", "and", "overwrite", ":", "\n", "        ", "print", "(", "\"Overwriting file at {}\"", ".", "format", "(", "upload_path", ")", ")", "\n", "", "DbfsApi", "(", "api_client", ")", ".", "cp", "(", "\n", "recursive", "=", "False", ",", "src", "=", "local_jarname", ",", "dst", "=", "upload_path", ",", "overwrite", "=", "overwrite", "\n", ")", "\n", "\n", "# setup the list of libraries to install:", "\n", "# jar library setup", "\n", "libs2install", "=", "[", "{", "\"jar\"", ":", "upload_path", "}", "]", "\n", "# setup libraries to install:", "\n", "libs2install", ".", "extend", "(", "[", "{", "\"pypi\"", ":", "{", "\"package\"", ":", "i", "}", "}", "for", "i", "in", "PYPI_O16N_LIBS", "]", ")", "\n", "print", "(", "\"Installing jar and pypi libraries required for operationalization...\"", ")", "\n", "LibrariesApi", "(", "api_client", ")", ".", "install_libraries", "(", "cluster_id", ",", "libs2install", ")", "\n", "return", "libs2install", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_als": [[50, 61], ["pyspark.sql.types.StructType", "recommenders.utils.spark_utils.start_or_get_spark", "recommenders.utils.spark_utils.start_or_get_spark.createDataFrame", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.IntegerType", "pyspark.sql.types.IntegerType", "pyspark.sql.types.FloatType", "pyspark.sql.types.LongType"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.spark_utils.start_or_get_spark"], ["def", "prepare_training_als", "(", "train", ",", "test", ")", ":", "\n", "    ", "schema", "=", "StructType", "(", "\n", "(", "\n", "StructField", "(", "DEFAULT_USER_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_ITEM_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_RATING_COL", ",", "FloatType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_TIMESTAMP_COL", ",", "LongType", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "spark", "=", "start_or_get_spark", "(", ")", "\n", "return", "spark", ".", "createDataFrame", "(", "train", ",", "schema", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_als": [[63, 68], ["pyspark.ml.recommendation.ALS", "recommenders.utils.timer.Timer", "pyspark.ml.recommendation.ALS.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_als", "(", "params", ",", "data", ")", ":", "\n", "    ", "symbol", "=", "ALS", "(", "**", "params", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", "=", "symbol", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_metrics_als": [[70, 81], ["pyspark.sql.types.StructType", "recommenders.utils.spark_utils.start_or_get_spark", "recommenders.utils.spark_utils.start_or_get_spark.createDataFrame", "recommenders.utils.spark_utils.start_or_get_spark.createDataFrame", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.IntegerType", "pyspark.sql.types.IntegerType", "pyspark.sql.types.FloatType", "pyspark.sql.types.LongType"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.spark_utils.start_or_get_spark"], ["", "def", "prepare_metrics_als", "(", "train", ",", "test", ")", ":", "\n", "    ", "schema", "=", "StructType", "(", "\n", "(", "\n", "StructField", "(", "DEFAULT_USER_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_ITEM_COL", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_RATING_COL", ",", "FloatType", "(", ")", ")", ",", "\n", "StructField", "(", "DEFAULT_TIMESTAMP_COL", ",", "LongType", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "spark", "=", "start_or_get_spark", "(", ")", "\n", "return", "spark", ".", "createDataFrame", "(", "train", ",", "schema", ")", ",", "spark", ".", "createDataFrame", "(", "test", ",", "schema", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.predict_als": [[83, 87], ["recommenders.utils.timer.Timer", "model.transform"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform"], ["", "def", "predict_als", "(", "model", ",", "test", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "preds", "=", "model", ".", "transform", "(", "test", ")", "\n", "", "return", "preds", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_als": [[89, 112], ["recommenders.utils.timer.Timer", "train.select().distinct", "train.select().distinct", "train.select().distinct.crossJoin", "model.transform", "model.transform.alias().join", "dfs_pred.alias().join.filter().select", "train.alias", "train.select", "train.select", "model.transform.alias", "dfs_pred.alias().join.filter", "dfs_pred_exclude_train[].isNull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.lightgbm.lightgbm_utils.NumEncoder.transform"], ["", "def", "recommend_k_als", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "# Get the cross join of all user-item pairs and score them.", "\n", "        ", "users", "=", "train", ".", "select", "(", "DEFAULT_USER_COL", ")", ".", "distinct", "(", ")", "\n", "items", "=", "train", ".", "select", "(", "DEFAULT_ITEM_COL", ")", ".", "distinct", "(", ")", "\n", "user_item", "=", "users", ".", "crossJoin", "(", "items", ")", "\n", "dfs_pred", "=", "model", ".", "transform", "(", "user_item", ")", "\n", "\n", "# Remove seen items", "\n", "dfs_pred_exclude_train", "=", "dfs_pred", ".", "alias", "(", "\"pred\"", ")", ".", "join", "(", "\n", "train", ".", "alias", "(", "\"train\"", ")", ",", "\n", "(", "dfs_pred", "[", "DEFAULT_USER_COL", "]", "==", "train", "[", "DEFAULT_USER_COL", "]", ")", "\n", "&", "(", "dfs_pred", "[", "DEFAULT_ITEM_COL", "]", "==", "train", "[", "DEFAULT_ITEM_COL", "]", ")", ",", "\n", "how", "=", "\"outer\"", ",", "\n", ")", "\n", "topk_scores", "=", "dfs_pred_exclude_train", ".", "filter", "(", "\n", "dfs_pred_exclude_train", "[", "\"train.\"", "+", "DEFAULT_RATING_COL", "]", ".", "isNull", "(", ")", "\n", ")", ".", "select", "(", "\n", "\"pred.\"", "+", "DEFAULT_USER_COL", ",", "\n", "\"pred.\"", "+", "DEFAULT_ITEM_COL", ",", "\n", "\"pred.\"", "+", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_svd": [[114, 118], ["surprise.Reader", "surprise.Dataset.load_from_df().build_full_trainset", "surprise.Dataset.load_from_df", "train.drop"], "function", ["None"], ["", "def", "prepare_training_svd", "(", "train", ",", "test", ")", ":", "\n", "    ", "reader", "=", "surprise", ".", "Reader", "(", "\"ml-100k\"", ",", "rating_scale", "=", "(", "1", ",", "5", ")", ")", "\n", "return", "surprise", ".", "Dataset", ".", "load_from_df", "(", "\n", "train", ".", "drop", "(", "DEFAULT_TIMESTAMP_COL", ",", "axis", "=", "1", ")", ",", "reader", "=", "reader", "\n", ")", ".", "build_full_trainset", "(", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_svd": [[121, 126], ["surprise.SVD", "recommenders.utils.timer.Timer", "surprise.SVD.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_svd", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "surprise", ".", "SVD", "(", "**", "params", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.predict_svd": [[128, 138], ["recommenders.utils.timer.Timer", "recommenders.models.surprise.surprise_utils.predict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "predict_svd", "(", "model", ",", "test", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "preds", "=", "predict", "(", "\n", "model", ",", "\n", "test", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "", "return", "preds", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_svd": [[140, 151], ["recommenders.utils.timer.Timer", "recommenders.models.surprise.surprise_utils.compute_ranking_predictions"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions"], ["", "def", "recommend_k_svd", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "topk_scores", "=", "compute_ranking_predictions", "(", "\n", "model", ",", "\n", "train", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "remove_seen", "=", "remove_seen", ",", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_fastai": [[153, 165], ["train.copy", "data[].astype", "data[].astype", "fastai.collab.CollabDataBunch.from_df"], "function", ["None"], ["", "def", "prepare_training_fastai", "(", "train", ",", "test", ")", ":", "\n", "    ", "data", "=", "train", ".", "copy", "(", ")", "\n", "data", "[", "DEFAULT_USER_COL", "]", "=", "data", "[", "DEFAULT_USER_COL", "]", ".", "astype", "(", "\"str\"", ")", "\n", "data", "[", "DEFAULT_ITEM_COL", "]", "=", "data", "[", "DEFAULT_ITEM_COL", "]", ".", "astype", "(", "\"str\"", ")", "\n", "data", "=", "CollabDataBunch", ".", "from_df", "(", "\n", "data", ",", "\n", "user_name", "=", "DEFAULT_USER_COL", ",", "\n", "item_name", "=", "DEFAULT_ITEM_COL", ",", "\n", "rating_name", "=", "DEFAULT_RATING_COL", ",", "\n", "valid_pct", "=", "0", ",", "\n", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_fastai": [[167, 174], ["fastai.collab.collab_learner", "recommenders.utils.timer.Timer", "fastai.collab.collab_learner.fit_one_cycle"], "function", ["None"], ["", "def", "train_fastai", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "collab_learner", "(", "\n", "data", ",", "n_factors", "=", "params", "[", "\"n_factors\"", "]", ",", "y_range", "=", "params", "[", "\"y_range\"", "]", ",", "wd", "=", "params", "[", "\"wd\"", "]", "\n", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit_one_cycle", "(", "cyc_len", "=", "params", "[", "\"epochs\"", "]", ",", "max_lr", "=", "params", "[", "\"max_lr\"", "]", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_metrics_fastai": [[176, 181], ["test.copy", "data[].astype", "data[].astype"], "function", ["None"], ["", "def", "prepare_metrics_fastai", "(", "train", ",", "test", ")", ":", "\n", "    ", "data", "=", "test", ".", "copy", "(", ")", "\n", "data", "[", "DEFAULT_USER_COL", "]", "=", "data", "[", "DEFAULT_USER_COL", "]", ".", "astype", "(", "\"str\"", ")", "\n", "data", "[", "DEFAULT_ITEM_COL", "]", "=", "data", "[", "DEFAULT_ITEM_COL", "]", ".", "astype", "(", "\"str\"", ")", "\n", "return", "train", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.predict_fastai": [[183, 193], ["recommenders.utils.timer.Timer", "recommenders.models.fastai.fastai_utils.score"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score"], ["", "def", "predict_fastai", "(", "model", ",", "test", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "preds", "=", "score", "(", "\n", "model", ",", "\n", "test_df", "=", "test", ",", "\n", "user_col", "=", "DEFAULT_USER_COL", ",", "\n", "item_col", "=", "DEFAULT_ITEM_COL", ",", "\n", "prediction_col", "=", "DEFAULT_PREDICTION_COL", ",", "\n", ")", "\n", "", "return", "preds", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_fastai": [[195, 224], ["recommenders.utils.timer.Timer", "model.data.train_ds.x.classes.values", "test[].unique", "numpy.intersect1d", "recommenders.models.fastai.fastai_utils.cartesian_product", "pandas.DataFrame", "pandas.merge", "recommenders.models.fastai.fastai_utils.score", "train.astype", "training_removed[].isna"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.HParams.values", "home.repos.pwc.inspect_result.microsoft_recommenders.fastai.fastai_utils.cartesian_product", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.score"], ["", "def", "recommend_k_fastai", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "total_users", ",", "total_items", "=", "model", ".", "data", ".", "train_ds", ".", "x", ".", "classes", ".", "values", "(", ")", "\n", "total_items", "=", "total_items", "[", "1", ":", "]", "\n", "total_users", "=", "total_users", "[", "1", ":", "]", "\n", "test_users", "=", "test", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", "\n", "test_users", "=", "np", ".", "intersect1d", "(", "test_users", ",", "total_users", ")", "\n", "users_items", "=", "cartesian_product", "(", "test_users", ",", "total_items", ")", "\n", "users_items", "=", "pd", ".", "DataFrame", "(", "\n", "users_items", ",", "columns", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", "\n", ")", "\n", "training_removed", "=", "pd", ".", "merge", "(", "\n", "users_items", ",", "\n", "train", ".", "astype", "(", "str", ")", ",", "\n", "on", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", ",", "\n", "how", "=", "\"left\"", ",", "\n", ")", "\n", "training_removed", "=", "training_removed", "[", "\n", "training_removed", "[", "DEFAULT_RATING_COL", "]", ".", "isna", "(", ")", "\n", "]", "[", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", "]", "\n", "topk_scores", "=", "score", "(", "\n", "model", ",", "\n", "test_df", "=", "training_removed", ",", "\n", "user_col", "=", "DEFAULT_USER_COL", ",", "\n", "item_col", "=", "DEFAULT_ITEM_COL", ",", "\n", "prediction_col", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "top_k", "=", "top_k", ",", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_ncf": [[226, 234], ["recommenders.models.ncf.dataset.Dataset"], "function", ["None"], ["", "def", "prepare_training_ncf", "(", "train", ",", "test", ")", ":", "\n", "    ", "return", "NCFDataset", "(", "\n", "train", "=", "train", ",", "\n", "col_user", "=", "DEFAULT_USER_COL", ",", "\n", "col_item", "=", "DEFAULT_ITEM_COL", ",", "\n", "col_rating", "=", "DEFAULT_RATING_COL", ",", "\n", "col_timestamp", "=", "DEFAULT_TIMESTAMP_COL", ",", "\n", "seed", "=", "SEED", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_ncf": [[237, 242], ["recommenders.models.ncf.ncf_singlenode.NCF", "recommenders.utils.timer.Timer", "recommenders.models.ncf.ncf_singlenode.NCF.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_ncf", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "NCF", "(", "n_users", "=", "data", ".", "n_users", ",", "n_items", "=", "data", ".", "n_items", ",", "**", "params", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_ncf": [[244, 267], ["recommenders.utils.timer.Timer", "list", "train[].unique", "pandas.DataFrame", "pandas.merge", "merged[].drop", "train[].unique", "users.extend", "items.extend", "preds.extend", "len", "list", "model.predict", "merged[].isnull"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "recommend_k_ncf", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "users", ",", "items", ",", "preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "item", "=", "list", "(", "train", "[", "DEFAULT_ITEM_COL", "]", ".", "unique", "(", ")", ")", "\n", "for", "user", "in", "train", "[", "DEFAULT_USER_COL", "]", ".", "unique", "(", ")", ":", "\n", "            ", "user", "=", "[", "user", "]", "*", "len", "(", "item", ")", "\n", "users", ".", "extend", "(", "user", ")", "\n", "items", ".", "extend", "(", "item", ")", "\n", "preds", ".", "extend", "(", "list", "(", "model", ".", "predict", "(", "user", ",", "item", ",", "is_list", "=", "True", ")", ")", ")", "\n", "", "topk_scores", "=", "pd", ".", "DataFrame", "(", "\n", "data", "=", "{", "\n", "DEFAULT_USER_COL", ":", "users", ",", "\n", "DEFAULT_ITEM_COL", ":", "items", ",", "\n", "DEFAULT_PREDICTION_COL", ":", "preds", ",", "\n", "}", "\n", ")", "\n", "merged", "=", "pd", ".", "merge", "(", "\n", "train", ",", "topk_scores", ",", "on", "=", "[", "DEFAULT_USER_COL", ",", "DEFAULT_ITEM_COL", "]", ",", "how", "=", "\"outer\"", "\n", ")", "\n", "topk_scores", "=", "merged", "[", "merged", "[", "DEFAULT_RATING_COL", "]", ".", "isnull", "(", ")", "]", ".", "drop", "(", "\n", "DEFAULT_RATING_COL", ",", "axis", "=", "1", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_cornac": [[269, 272], ["cornac.data.Dataset.from_uir", "train.drop().itertuples", "train.drop"], "function", ["None"], ["", "def", "prepare_training_cornac", "(", "train", ",", "test", ")", ":", "\n", "    ", "return", "cornac", ".", "data", ".", "Dataset", ".", "from_uir", "(", "\n", "train", ".", "drop", "(", "DEFAULT_TIMESTAMP_COL", ",", "axis", "=", "1", ")", ".", "itertuples", "(", "index", "=", "False", ")", ",", "seed", "=", "SEED", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_cornac": [[275, 286], ["recommenders.utils.timer.Timer", "recommenders.models.cornac.cornac_utils.predict_ranking"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.cornac.cornac_utils.predict_ranking"], ["", "def", "recommend_k_cornac", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "topk_scores", "=", "predict_ranking", "(", "\n", "model", ",", "\n", "train", ",", "\n", "usercol", "=", "DEFAULT_USER_COL", ",", "\n", "itemcol", "=", "DEFAULT_ITEM_COL", ",", "\n", "predcol", "=", "DEFAULT_PREDICTION_COL", ",", "\n", "remove_seen", "=", "remove_seen", ",", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_bpr": [[288, 293], ["cornac.models.BPR", "recommenders.utils.timer.Timer", "cornac.models.BPR.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_bpr", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "cornac", ".", "models", ".", "BPR", "(", "**", "params", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_bivae": [[295, 300], ["cornac.models.BiVAECF", "recommenders.utils.timer.Timer", "cornac.models.BiVAECF.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_bivae", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "cornac", ".", "models", ".", "BiVAECF", "(", "**", "params", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_sar": [[302, 304], ["None"], "function", ["None"], ["", "def", "prepare_training_sar", "(", "train", ",", "test", ")", ":", "\n", "    ", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_sar": [[306, 312], ["recommenders.models.sar.sar_singlenode.SARSingleNode", "recommenders.models.sar.sar_singlenode.SARSingleNode.set_index", "recommenders.utils.timer.Timer", "recommenders.models.sar.sar_singlenode.SARSingleNode.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_sar", "(", "params", ",", "data", ")", ":", "\n", "    ", "model", "=", "SARSingleNode", "(", "**", "params", ")", "\n", "model", ".", "set_index", "(", "data", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", "data", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_sar": [[314, 320], ["recommenders.utils.timer.Timer", "model.recommend_k_items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "def", "recommend_k_sar", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "topk_scores", "=", "model", ".", "recommend_k_items", "(", "\n", "test", ",", "top_k", "=", "top_k", ",", "remove_seen", "=", "remove_seen", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.prepare_training_lightgcn": [[322, 324], ["recommenders.models.deeprec.DataModel.ImplicitCF.ImplicitCF"], "function", ["None"], ["", "def", "prepare_training_lightgcn", "(", "train", ",", "test", ")", ":", "\n", "    ", "return", "ImplicitCF", "(", "train", "=", "train", ",", "test", "=", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.train_lightgcn": [[326, 332], ["recommenders.models.deeprec.deeprec_utils.prepare_hparams", "recommenders.models.deeprec.models.graphrec.lightgcn.LightGCN", "recommenders.utils.timer.Timer", "recommenders.models.deeprec.models.graphrec.lightgcn.LightGCN.fit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "def", "train_lightgcn", "(", "params", ",", "data", ")", ":", "\n", "    ", "hparams", "=", "prepare_hparams", "(", "**", "params", ")", "\n", "model", "=", "LightGCN", "(", "hparams", ",", "data", ")", "\n", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "model", ".", "fit", "(", ")", "\n", "", "return", "model", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.recommend_k_lightgcn": [[334, 340], ["recommenders.utils.timer.Timer", "model.recommend_k_items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "def", "recommend_k_lightgcn", "(", "model", ",", "test", ",", "train", ",", "top_k", "=", "DEFAULT_K", ",", "remove_seen", "=", "True", ")", ":", "\n", "    ", "with", "Timer", "(", ")", "as", "t", ":", "\n", "        ", "topk_scores", "=", "model", ".", "recommend_k_items", "(", "\n", "test", ",", "top_k", "=", "top_k", ",", "remove_seen", "=", "remove_seen", "\n", ")", "\n", "", "return", "topk_scores", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.rating_metrics_pyspark": [[342, 349], ["recommenders.evaluation.spark_evaluation.SparkRatingEvaluation", "recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var", "recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared"], ["", "def", "rating_metrics_pyspark", "(", "test", ",", "predictions", ")", ":", "\n", "    ", "rating_eval", "=", "SparkRatingEvaluation", "(", "test", ",", "predictions", ",", "**", "COL_DICT", ")", "\n", "return", "{", "\n", "\"RMSE\"", ":", "rating_eval", ".", "rmse", "(", ")", ",", "\n", "\"MAE\"", ":", "rating_eval", ".", "mae", "(", ")", ",", "\n", "\"R2\"", ":", "rating_eval", ".", "exp_var", "(", ")", ",", "\n", "\"Explained Variance\"", ":", "rating_eval", ".", "rsquared", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.ranking_metrics_pyspark": [[352, 361], ["recommenders.evaluation.spark_evaluation.SparkRankingEvaluation", "recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "def", "ranking_metrics_pyspark", "(", "test", ",", "predictions", ",", "k", "=", "DEFAULT_K", ")", ":", "\n", "    ", "rank_eval", "=", "SparkRankingEvaluation", "(", "\n", "test", ",", "predictions", ",", "k", "=", "k", ",", "relevancy_method", "=", "\"top_k\"", ",", "**", "COL_DICT", "\n", ")", "\n", "return", "{", "\n", "\"MAP\"", ":", "rank_eval", ".", "map_at_k", "(", ")", ",", "\n", "\"nDCG@k\"", ":", "rank_eval", ".", "ndcg_at_k", "(", ")", ",", "\n", "\"Precision@k\"", ":", "rank_eval", ".", "precision_at_k", "(", ")", ",", "\n", "\"Recall@k\"", ":", "rank_eval", ".", "recall_at_k", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.rating_metrics_python": [[364, 370], ["recommenders.evaluation.python_evaluation.rmse", "recommenders.evaluation.python_evaluation.mae", "recommenders.evaluation.python_evaluation.rsquared", "recommenders.evaluation.python_evaluation.exp_var"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rmse", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.mae", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.rsquared", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRatingEvaluation.exp_var"], ["", "def", "rating_metrics_python", "(", "test", ",", "predictions", ")", ":", "\n", "    ", "return", "{", "\n", "\"RMSE\"", ":", "rmse", "(", "test", ",", "predictions", ",", "**", "COL_DICT", ")", ",", "\n", "\"MAE\"", ":", "mae", "(", "test", ",", "predictions", ",", "**", "COL_DICT", ")", ",", "\n", "\"R2\"", ":", "rsquared", "(", "test", ",", "predictions", ",", "**", "COL_DICT", ")", ",", "\n", "\"Explained Variance\"", ":", "exp_var", "(", "test", ",", "predictions", ",", "**", "COL_DICT", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.06_benchmarks.benchmark_utils.ranking_metrics_python": [[373, 379], ["recommenders.evaluation.python_evaluation.map_at_k", "recommenders.evaluation.python_evaluation.ndcg_at_k", "recommenders.evaluation.python_evaluation.precision_at_k", "recommenders.evaluation.python_evaluation.recall_at_k"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.map_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.ndcg_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.precision_at_k", "home.repos.pwc.inspect_result.microsoft_recommenders.evaluation.spark_evaluation.SparkRankingEvaluation.recall_at_k"], ["", "def", "ranking_metrics_python", "(", "test", ",", "predictions", ",", "k", "=", "DEFAULT_K", ")", ":", "\n", "    ", "return", "{", "\n", "\"MAP\"", ":", "map_at_k", "(", "test", ",", "predictions", ",", "k", "=", "k", ",", "**", "COL_DICT", ")", ",", "\n", "\"nDCG@k\"", ":", "ndcg_at_k", "(", "test", ",", "predictions", ",", "k", "=", "k", ",", "**", "COL_DICT", ")", ",", "\n", "\"Precision@k\"", ":", "precision_at_k", "(", "test", ",", "predictions", ",", "k", "=", "k", ",", "**", "COL_DICT", ")", ",", "\n", "\"Recall@k\"", ":", "recall_at_k", "(", "test", ",", "predictions", ",", "k", "=", "k", ",", "**", "COL_DICT", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.wide_deep_training._log": [[33, 50], ["print", "isinstance", "isinstance", "run.log_list", "run.log", "len", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["def", "_log", "(", "metric", ",", "value", ")", ":", "\n", "    ", "\"\"\"AzureML log wrapper.\n\n    Record list of int or float as a list metrics so that we can plot it from AzureML workspace portal.\n    Otherwise, record as a single value of the metric.\n    \"\"\"", "\n", "if", "run", "is", "not", "None", ":", "\n", "        ", "if", "(", "\n", "isinstance", "(", "value", ",", "list", ")", "\n", "and", "len", "(", "value", ")", ">", "0", "\n", "and", "isinstance", "(", "value", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", "\n", ")", ":", "\n", "            ", "run", ".", "log_list", "(", "metric", ",", "value", ")", "\n", "", "else", ":", "\n", "# Force cast to str since run.log will raise an error if the value is iterable.", "\n", "            ", "run", ".", "log", "(", "metric", ",", "str", "(", "value", ")", ")", "\n", "", "", "print", "(", "metric", ",", "\"=\"", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.svd_training.svd_training": [[24, 94], ["print", "pandas.read_pickle", "pandas.read_pickle", "surprise.SVD", "surprise.Dataset.load_from_df().build_full_trainset", "surprise.SVD.fit", "print", "len", "recommenders.models.surprise.surprise_utils.predict", "len", "recommenders.models.surprise.surprise_utils.compute_ranking_predictions", "ValueError", "os.path.join", "os.path.join", "surprise.Dataset.load_from_df", "print", "print", "len", "len", "eval", "run.log", "eval", "run.log", "surprise.Reader"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.surprise.surprise_utils.compute_ranking_predictions", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log", "home.repos.pwc.inspect_result.microsoft_recommenders.models.dkn_item2item.DKNItem2Item.eval", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["def", "svd_training", "(", "params", ")", ":", "\n", "    ", "\"\"\"\n    Train Surprise SVD using the given hyper-parameters\n    \"\"\"", "\n", "logger", ".", "debug", "(", "\"Start training...\"", ")", "\n", "train_data", "=", "pd", ".", "read_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"train_datapath\"", "]", ")", "\n", ")", "\n", "validation_data", "=", "pd", ".", "read_pickle", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "\"datastore\"", "]", ",", "params", "[", "\"validation_datapath\"", "]", ")", "\n", ")", "\n", "\n", "svd_params", "=", "{", "\n", "p", ":", "params", "[", "p", "]", "\n", "for", "p", "in", "[", "\n", "\"random_state\"", ",", "\n", "\"n_epochs\"", ",", "\n", "\"verbose\"", ",", "\n", "\"biased\"", ",", "\n", "\"n_factors\"", ",", "\n", "\"init_mean\"", ",", "\n", "\"init_std_dev\"", ",", "\n", "\"lr_all\"", ",", "\n", "\"reg_all\"", ",", "\n", "\"lr_bu\"", ",", "\n", "\"lr_bi\"", ",", "\n", "\"lr_pu\"", ",", "\n", "\"lr_qi\"", ",", "\n", "\"reg_bu\"", ",", "\n", "\"reg_bi\"", ",", "\n", "\"reg_pu\"", ",", "\n", "\"reg_qi\"", ",", "\n", "]", "\n", "}", "\n", "svd", "=", "surprise", ".", "SVD", "(", "**", "svd_params", ")", "\n", "\n", "train_set", "=", "surprise", ".", "Dataset", ".", "load_from_df", "(", "\n", "train_data", ",", "reader", "=", "surprise", ".", "Reader", "(", "params", "[", "\"surprise_reader\"", "]", ")", "\n", ")", ".", "build_full_trainset", "(", ")", "\n", "svd", ".", "fit", "(", "train_set", ")", "\n", "\n", "logger", ".", "debug", "(", "\"Evaluating...\"", ")", "\n", "\n", "metrics_dict", "=", "{", "}", "\n", "rating_metrics", "=", "params", "[", "\"rating_metrics\"", "]", "\n", "if", "len", "(", "rating_metrics", ")", ">", "0", ":", "\n", "        ", "predictions", "=", "predict", "(", "\n", "svd", ",", "validation_data", ",", "usercol", "=", "params", "[", "\"usercol\"", "]", ",", "itemcol", "=", "params", "[", "\"itemcol\"", "]", "\n", ")", "\n", "for", "metric", "in", "rating_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "validation_data", ",", "predictions", ")", "\n", "logger", ".", "debug", "(", "\"%s = %g\"", ",", "metric", ",", "result", ")", "\n", "if", "metric", "==", "params", "[", "\"primary_metric\"", "]", ":", "\n", "                ", "metrics_dict", "[", "\"default\"", "]", "=", "result", "\n", "", "else", ":", "\n", "                ", "metrics_dict", "[", "metric", "]", "=", "result", "\n", "\n", "", "", "", "ranking_metrics", "=", "params", "[", "\"ranking_metrics\"", "]", "\n", "if", "len", "(", "ranking_metrics", ")", ">", "0", ":", "\n", "        ", "all_predictions", "=", "compute_ranking_predictions", "(", "\n", "svd", ",", "\n", "train_data", ",", "\n", "usercol", "=", "params", "[", "\"usercol\"", "]", ",", "\n", "itemcol", "=", "params", "[", "\"itemcol\"", "]", ",", "\n", "remove_seen", "=", "params", "[", "\"remove_seen\"", "]", ",", "\n", ")", "\n", "k", "=", "params", "[", "\"k\"", "]", "\n", "for", "metric", "in", "ranking_metrics", ":", "\n", "            ", "result", "=", "getattr", "(", "evaluation", ",", "metric", ")", "(", "\n", "validation_data", ",", "all_predictions", ",", "col_prediction", "=", "\"prediction\"", ",", "k", "=", "k", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.svd_training.main": [[96, 148], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "svd_training.svd_training", "os.makedirs", "surprise.dump.dump", "str", "run.log", "os.path.join", "vars"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.train_scripts.svd_training.svd_training", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.tf_utils.MetricsLogger.log"], ["if", "metric", "==", "params", "[", "\"primary_metric\"", "]", ":", "\n", "                ", "metrics_dict", "[", "\"default\"", "]", "=", "result", "\n", "", "else", ":", "\n", "                ", "metrics_dict", "[", "metric", "]", "=", "result", "\n", "\n", "", "", "", "if", "len", "(", "ranking_metrics", ")", "==", "0", "and", "len", "(", "rating_metrics", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"No metrics were specified.\"", ")", "\n", "\n", "# Report the metrics", "\n", "", "nni", ".", "report_final_result", "(", "metrics_dict", ")", "\n", "\n", "# Save the metrics in a JSON file", "\n", "output_dir", "=", "os", ".", "environ", ".", "get", "(", "\"NNI_OUTPUT_DIR\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"metrics.json\"", ")", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "temp_dict", "=", "metrics_dict", ".", "copy", "(", ")", "\n", "temp_dict", "[", "params", "[", "\"primary_metric\"", "]", "]", "=", "temp_dict", ".", "pop", "(", "\"default\"", ")", "\n", "json", ".", "dump", "(", "temp_dict", ",", "fp", ")", "\n", "\n", "", "return", "svd", "\n", "\n", "\n", "", "def", "get_params", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Data path", "\n", "parser", ".", "add_argument", "(", "\n", "\"--datastore\"", ",", "type", "=", "str", ",", "dest", "=", "\"datastore\"", ",", "help", "=", "\"Datastore path\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"train_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-datapath\"", ",", "type", "=", "str", ",", "dest", "=", "\"validation_datapath\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--surprise-reader\"", ",", "type", "=", "str", ",", "dest", "=", "\"surprise_reader\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--usercol\"", ",", "type", "=", "str", ",", "dest", "=", "\"usercol\"", ",", "default", "=", "\"userID\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--itemcol\"", ",", "type", "=", "str", ",", "dest", "=", "\"itemcol\"", ",", "default", "=", "\"itemID\"", ")", "\n", "# Metrics", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rating-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"rating_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ranking-metrics\"", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "dest", "=", "\"ranking_metrics\"", ",", "default", "=", "[", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "dest", "=", "\"k\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--remove-seen\"", ",", "dest", "=", "\"remove_seen\"", ",", "action", "=", "\"store_false\"", ")", "\n", "# Training parameters", "\n", "parser", ".", "add_argument", "(", "\"--random-state\"", ",", "type", "=", "int", ",", "dest", "=", "\"random_state\"", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "dest", "=", "\"verbose\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_epochs\"", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "\"--biased\"", ",", "dest", "=", "\"biased\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--primary-metric\"", ",", "dest", "=", "\"primary_metric\"", ",", "default", "=", "\"rmse\"", ")", "\n", "# Hyperparameters to be tuned", "\n", "parser", ".", "add_argument", "(", "\"--n_factors\"", ",", "type", "=", "int", ",", "dest", "=", "\"n_factors\"", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--init_mean\"", ",", "type", "=", "float", ",", "dest", "=", "\"init_mean\"", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--init_std_dev\"", ",", "type", "=", "float", ",", "dest", "=", "\"init_std_dev\"", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_all\"", ",", "type", "=", "float", ",", "dest", "=", "\"lr_all\"", ",", "default", "=", "0.005", ")", "\n", "parser", ".", "add_argument", "(", "\"--reg_all\"", ",", "type", "=", "float", ",", "dest", "=", "\"reg_all\"", ",", "default", "=", "0.02", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.ScoreSARModule.__init__": [[39, 42], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "input_data", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_input_data", "=", "input_data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.ScoreSARModule.model": [[43, 46], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.ScoreSARModule.input_data": [[47, 50], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_input_data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.ScoreSARModule.recommend_items": [[51, 71], ["ValueError", "score_sar_entry.ScoreSARModule.model.recommend_k_items", "score_sar_entry.ScoreSARModule.model.get_item_based_topk", "score_sar_entry.ScoreSARModule.model.get_popularity_based_topk"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_item_based_topk", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.get_popularity_based_topk"], ["", "def", "recommend_items", "(", "\n", "self", ",", "ranking_metric", ",", "top_k", ",", "sort_top_k", ",", "remove_seen", ",", "normalize", "\n", ")", ":", "\n", "        ", "if", "ranking_metric", "==", "RankingMetric", ".", "RATING", ":", "\n", "            ", "return", "self", ".", "model", ".", "recommend_k_items", "(", "\n", "test", "=", "self", ".", "input_data", ",", "\n", "top_k", "=", "top_k", ",", "\n", "sort_top_k", "=", "sort_top_k", ",", "\n", "remove_seen", "=", "remove_seen", ",", "\n", "normalize", "=", "normalize", ",", "\n", ")", "\n", "", "if", "ranking_metric", "==", "RankingMetric", ".", "SIMILARITY", ":", "\n", "            ", "return", "self", ".", "model", ".", "get_item_based_topk", "(", "\n", "items", "=", "self", ".", "input_data", ",", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "", "if", "ranking_metric", "==", "RankingMetric", ".", "POPULARITY", ":", "\n", "            ", "return", "self", ".", "model", ".", "get_popularity_based_topk", "(", "\n", "top_k", "=", "top_k", ",", "sort_top_k", "=", "sort_top_k", "\n", ")", "\n", "", "raise", "ValueError", "(", "f\"Got unexpected ranking metric: {ranking_metric}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.ScoreSARModule.predict_ratings": [[72, 80], ["ValueError", "score_sar_entry.ScoreSARModule.model.predict_training_items", "score_sar_entry.ScoreSARModule.model.predict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "predict_ratings", "(", "self", ",", "items_to_predict", ",", "normalize", ")", ":", "\n", "        ", "if", "items_to_predict", "==", "ItemSet", ".", "TRAIN_ONLY", ":", "\n", "            ", "return", "self", ".", "model", ".", "predict_training_items", "(", "\n", "test", "=", "self", ".", "input_data", ",", "normalize", "=", "normalize", "\n", ")", "\n", "", "if", "items_to_predict", "==", "ItemSet", ".", "SCORE_ONLY", ":", "\n", "            ", "return", "self", ".", "model", ".", "predict", "(", "test", "=", "self", ".", "input_data", ",", "normalize", "=", "normalize", ")", "\n", "", "raise", "ValueError", "(", "f\"Got unexpected 'items to predict': {items_to_predict}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.score_sar_entry.joblib_loader": [[32, 36], ["open", "joblib.load", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.load"], ["", "def", "joblib_loader", "(", "load_from_dir", ",", "model_spec", ")", ":", "\n", "    ", "file_name", "=", "model_spec", "[", "\"file_name\"", "]", "\n", "with", "open", "(", "Path", "(", "load_from_dir", ")", "/", "file_name", ",", "\"rb\"", ")", "as", "fin", ":", "\n", "        ", "return", "joblib", ".", "load", "(", "fin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.entries.train_sar_entry.joblib_dumper": [[15, 30], ["azureml.studio.core.utils.fileutils.ensure_folder", "pathlib.Path", "pathlib.Path", "open", "joblib.dump"], "function", ["None"], ["def", "joblib_dumper", "(", "data", ",", "file_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return a dumper to dump a model with pickle.\"\"\"", "\n", "if", "not", "file_name", ":", "\n", "        ", "file_name", "=", "\"_data.pkl\"", "\n", "\n", "", "def", "model_dumper", "(", "save_to", ")", ":", "\n", "        ", "full_path", "=", "Path", "(", "save_to", ")", "/", "file_name", "\n", "ensure_folder", "(", "Path", "(", "save_to", ")", ")", "\n", "with", "open", "(", "full_path", ",", "\"wb\"", ")", "as", "fout", ":", "\n", "            ", "joblib", ".", "dump", "(", "data", ",", "fout", ",", "protocol", "=", "4", ")", "\n", "\n", "", "model_spec", "=", "{", "\"model_type\"", ":", "\"joblib\"", ",", "\"file_name\"", ":", "file_name", "}", "\n", "return", "model_spec", "\n", "\n", "", "return", "model_dumper", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.python.setup.get_pybind_include.__init__": [[10, 12], ["None"], "methods", ["None"], ["\n", "# workround for enabling editable user pip installs", "\n", "site", ".", "ENABLE_USER_SITE", "=", "\"--user\"", "in", "sys", ".", "argv", "[", "1", ":", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.python.setup.get_pybind_include.__str__": [[13, 17], ["pybind11.get_include"], "methods", ["None"], ["\n", "# version", "\n", "here", "=", "Path", "(", "__file__", ")", ".", "absolute", "(", ")", ".", "parent", "\n", "version_data", "=", "{", "}", "\n", "with", "open", "(", "here", ".", "joinpath", "(", "\"recommenders\"", ",", "\"__init__.py\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare": [[15, 19], ["math.isclose"], "function", ["None"], ["def", "assert_compare", "(", "expected_id", ",", "expected_score", ",", "actual_prediction", ")", ":", "\n", "    ", "assert", "expected_id", "==", "actual_prediction", ".", "id", "\n", "assert", "math", ".", "isclose", "(", "\n", "expected_score", ",", "actual_prediction", ".", "score", ",", "rel_tol", "=", "1e-3", ",", "abs_tol", "=", "1e-3", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.spark": [[22, 56], ["pytest.fixture", "pyspark.sql.SparkSession.builder.appName().master().config().config().config().config().config().config().config().getOrCreate", "next().absolute", "Exception", "pyspark.sql.SparkSession.builder.appName().master().config().config().config().config().config().config().config", "next", "str", "pathlib.Path().parents[].joinpath().glob", "pyspark.sql.SparkSession.builder.appName().master().config().config().config().config().config().config", "tmp_path_factory.mktemp", "pathlib.Path().parents[].joinpath", "pyspark.sql.SparkSession.builder.appName().master().config().config().config().config().config", "pyspark.sql.SparkSession.builder.appName().master().config().config().config().config", "pathlib.Path", "pyspark.sql.SparkSession.builder.appName().master().config().config().config", "pyspark.sql.SparkSession.builder.appName().master().config().config", "pyspark.sql.SparkSession.builder.appName().master().config", "pyspark.sql.SparkSession.builder.appName().master", "pyspark.sql.SparkSession.builder.appName", "test_pyspark_sar.pandas_dummy_dataset"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.pandas_dummy_dataset"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "spark", "(", "tmp_path_factory", ",", "app_name", "=", "\"Sample\"", ",", "url", "=", "\"local[*]\"", ",", "memory", "=", "\"1G\"", ")", ":", "\n", "    ", "\"\"\"Start Spark if not started\n    Args:\n        app_name (str): sets name of the application\n        url (str): url for spark master\n        memory (str): size of memory for spark driver\n    \"\"\"", "\n", "\n", "try", ":", "\n", "        ", "sarplus_jar_path", "=", "next", "(", "\n", "Path", "(", "__file__", ")", "\n", ".", "parents", "[", "2", "]", "\n", ".", "joinpath", "(", "\"scala\"", ",", "\"target\"", ")", "\n", ".", "glob", "(", "\"**/sarplus*.jar\"", ")", "\n", ")", ".", "absolute", "(", ")", "\n", "", "except", "StopIteration", ":", "\n", "        ", "raise", "Exception", "(", "\"Could not find Sarplus JAR file\"", ")", "\n", "\n", "", "spark", "=", "(", "\n", "SparkSession", ".", "builder", ".", "appName", "(", "app_name", ")", "\n", ".", "master", "(", "url", ")", "\n", ".", "config", "(", "\"spark.jars\"", ",", "sarplus_jar_path", ")", "\n", ".", "config", "(", "\"spark.driver.memory\"", ",", "memory", ")", "\n", ".", "config", "(", "\"spark.sql.shuffle.partitions\"", ",", "\"1\"", ")", "\n", ".", "config", "(", "\"spark.default.parallelism\"", ",", "\"1\"", ")", "\n", ".", "config", "(", "\"spark.sql.crossJoin.enabled\"", ",", "True", ")", "\n", ".", "config", "(", "\"spark.ui.enabled\"", ",", "False", ")", "\n", ".", "config", "(", "\"spark.sql.warehouse.dir\"", ",", "str", "(", "tmp_path_factory", ".", "mktemp", "(", "\"spark\"", ")", ")", ")", "\n", "# .config(\"spark.eventLog.enabled\", True) # only for local debugging, breaks on build server", "\n", ".", "getOrCreate", "(", ")", "\n", ")", "\n", "\n", "return", "spark", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.sample_cache": [[58, 67], ["pytest.fixture", "spark.read.csv", "spark.read.csv.coalesce().write.format().mode().save", "spark.read.csv.coalesce().write.format().mode", "spark.read.csv.coalesce().write.format", "spark.read.csv.coalesce"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "sample_cache", "(", "spark", ")", ":", "\n", "    ", "df", "=", "spark", ".", "read", ".", "csv", "(", "\"tests/sample-input.txt\"", ",", "header", "=", "True", ",", "inferSchema", "=", "True", ")", "\n", "\n", "path", "=", "\"tests/sample-output.sar\"", "\n", "\n", "df", ".", "coalesce", "(", "1", ")", ".", "write", ".", "format", "(", "\"com.microsoft.sarplus\"", ")", ".", "mode", "(", "\"overwrite\"", ")", ".", "save", "(", "path", ")", "\n", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.pandas_dummy_dataset": [[69, 81], ["pytest.fixture", "pandas.DataFrame"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "pandas_dummy_dataset", "(", "header", ")", ":", "\n", "    ", "\"\"\"Load sample dataset in pandas for testing; can be used to create a Spark dataframe\n    Returns:\n        single Pandas dataframe\n    \"\"\"", "\n", "ratings_dict", "=", "{", "\n", "header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "1", ",", "2", ",", "7", ",", "8", ",", "9", ",", "10", ",", "1", ",", "2", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "}", "\n", "return", "pd", ".", "DataFrame", "(", "ratings_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_good": [[83, 91], ["pysarplus.SARModel", "pysarplus.SARModel.predict", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_good", "(", "spark", ",", "sample_cache", ")", ":", "\n", "    ", "model", "=", "SARModel", "(", "sample_cache", ")", "\n", "y", "=", "model", ".", "predict", "(", "[", "0", ",", "1", "]", ",", "[", "10", ",", "20", "]", ",", "top_k", "=", "10", ",", "remove_seen", "=", "False", ")", "\n", "\n", "assert_compare", "(", "0", ",", "5", ",", "y", "[", "0", "]", ")", "\n", "assert_compare", "(", "1", ",", "44", ",", "y", "[", "1", "]", ")", "\n", "assert_compare", "(", "2", ",", "64", ",", "y", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_good_less": [[93, 101], ["pysarplus.SARModel", "pysarplus.SARModel.predict", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_good_less", "(", "spark", ",", "sample_cache", ")", ":", "\n", "    ", "model", "=", "SARModel", "(", "sample_cache", ")", "\n", "y", "=", "model", ".", "predict", "(", "[", "0", ",", "2", "]", ",", "[", "10", ",", "3", "]", ",", "top_k", "=", "5", ",", "remove_seen", "=", "False", ")", "\n", "\n", "assert_compare", "(", "0", ",", "1", ",", "y", "[", "0", "]", ")", "\n", "assert_compare", "(", "1", ",", "11.6", ",", "y", "[", "1", "]", ")", "\n", "assert_compare", "(", "2", ",", "12.3", ",", "y", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_good_require_sort": [[103, 113], ["pysarplus.SARModel", "pysarplus.SARModel.predict", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_good_require_sort", "(", "spark", ",", "sample_cache", ")", ":", "\n", "    ", "model", "=", "SARModel", "(", "sample_cache", ")", "\n", "y", "=", "model", ".", "predict", "(", "[", "1", ",", "0", "]", ",", "[", "20", ",", "10", "]", ",", "top_k", "=", "10", ",", "remove_seen", "=", "False", ")", "\n", "\n", "assert_compare", "(", "0", ",", "5", ",", "y", "[", "0", "]", ")", "\n", "assert_compare", "(", "1", ",", "44", ",", "y", "[", "1", "]", ")", "\n", "assert_compare", "(", "2", ",", "64", ",", "y", "[", "2", "]", ")", "\n", "\n", "assert", "3", "==", "len", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_good_require_sort_remove_seen": [[115, 122], ["pysarplus.SARModel", "pysarplus.SARModel.predict", "test_pyspark_sar.assert_compare", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_good_require_sort_remove_seen", "(", "spark", ",", "sample_cache", ")", ":", "\n", "    ", "model", "=", "SARModel", "(", "sample_cache", ")", "\n", "y", "=", "model", ".", "predict", "(", "[", "1", ",", "0", "]", ",", "[", "20", ",", "10", "]", ",", "top_k", "=", "10", ",", "remove_seen", "=", "True", ")", "\n", "\n", "assert_compare", "(", "2", ",", "64", ",", "y", "[", "0", "]", ")", "\n", "assert", "1", "==", "len", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_pandas": [[124, 139], ["pandas.DataFrame", "pysarplus.SARModel", "pysarplus.SARModel.predict", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare", "test_pyspark_sar.assert_compare"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare", "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.assert_compare"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_pandas", "(", "spark", ",", "sample_cache", ")", ":", "\n", "    ", "item_scores", "=", "pd", ".", "DataFrame", "(", "[", "(", "0", ",", "2.3", ")", ",", "(", "1", ",", "3.1", ")", "]", ",", "columns", "=", "[", "\"itemID\"", ",", "\"score\"", "]", ")", "\n", "\n", "model", "=", "SARModel", "(", "sample_cache", ")", "\n", "y", "=", "model", ".", "predict", "(", "\n", "item_scores", "[", "\"itemID\"", "]", ".", "values", ",", "\n", "item_scores", "[", "\"score\"", "]", ".", "values", ",", "\n", "top_k", "=", "10", ",", "\n", "remove_seen", "=", "False", ",", "\n", ")", "\n", "\n", "assert_compare", "(", "0", ",", "0.85", ",", "y", "[", "0", "]", ")", "\n", "assert_compare", "(", "1", ",", "6.9699", ",", "y", "[", "1", "]", ")", "\n", "assert_compare", "(", "2", ",", "9.92", ",", "y", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_e2e": [[141, 174], ["pysarplus.SARPlus", "spark.createDataFrame", "pysarplus.SARPlus.fit", "spark.createDataFrame", "pysarplus.SARPlus.recommend_k_items().toPandas().sort_values().reset_index", "pysarplus.SARPlus.recommend_k_items().toPandas().sort_values().reset_index", "numpy.allclose", "pandas.DataFrame", "pysarplus.SARPlus.recommend_k_items().toPandas().sort_values", "pysarplus.SARPlus.recommend_k_items().toPandas().sort_values", "pysarplus.SARPlus.recommend_k_items().toPandas", "pysarplus.SARPlus.recommend_k_items().toPandas", "pysarplus.SARPlus.recommend_k_items", "pysarplus.SARPlus.recommend_k_items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "@", "pytest", ".", "mark", ".", "spark", "\n", "def", "test_e2e", "(", "spark", ",", "pandas_dummy_dataset", ",", "header", ")", ":", "\n", "    ", "sar", "=", "SARPlus", "(", "spark", ",", "**", "header", ",", "cache_path", "=", "\"tests/test_e2e_cache\"", ")", "\n", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "pandas_dummy_dataset", ")", "\n", "sar", ".", "fit", "(", "df", ")", "\n", "\n", "test_df", "=", "spark", ".", "createDataFrame", "(", "\n", "pd", ".", "DataFrame", "(", "{", "header", "[", "\"col_user\"", "]", ":", "[", "3", "]", ",", "header", "[", "\"col_item\"", "]", ":", "[", "2", "]", "}", ")", "\n", ")", "\n", "\n", "r1", "=", "(", "\n", "sar", ".", "recommend_k_items", "(", "test_df", ",", "top_k", "=", "3", ",", "remove_seen", "=", "False", ")", "\n", ".", "toPandas", "(", ")", "\n", ".", "sort_values", "(", "[", "header", "[", "\"col_user\"", "]", ",", "header", "[", "\"col_item\"", "]", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "r2", "=", "(", "\n", "sar", ".", "recommend_k_items", "(", "\n", "test_df", ",", "\n", "top_k", "=", "3", ",", "\n", "n_user_prediction_partitions", "=", "2", ",", "\n", "remove_seen", "=", "False", ",", "\n", "use_cache", "=", "True", ",", "\n", ")", "\n", ".", "toPandas", "(", ")", "\n", ".", "sort_values", "(", "[", "header", "[", "\"col_user\"", "]", ",", "header", "[", "\"col_item\"", "]", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "assert", "(", "r1", ".", "iloc", "[", ":", ",", ":", "2", "]", "==", "r2", ".", "iloc", "[", ":", ",", ":", "2", "]", ")", ".", "all", "(", ")", ".", "all", "(", ")", "\n", "assert", "np", ".", "allclose", "(", "r1", ".", "score", ".", "values", ",", "r2", ".", "score", ".", "values", ",", "1e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_fit": [[176, 197], ["pytest.mark.parametrize", "pysarplus.SARPlus", "spark.createDataFrame", "spark.table.write.mode().saveAsTable", "spark.table", "pysarplus.SARPlus.fit", "spark.table.write.mode"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"similarity_type, timedecay_formula\"", ",", "[", "(", "\"jaccard\"", ",", "False", ")", ",", "(", "\"lift\"", ",", "True", ")", "]", "\n", ")", "\n", "def", "test_fit", "(", "\n", "spark", ",", "similarity_type", ",", "timedecay_formula", ",", "train_test_dummy_timestamp", ",", "header", "\n", ")", ":", "\n", "    ", "model", "=", "SARPlus", "(", "\n", "spark", ",", "\n", "**", "header", ",", "\n", "timedecay_formula", "=", "timedecay_formula", ",", "\n", "similarity_type", "=", "similarity_type", ",", "\n", ")", "\n", "\n", "trainset", ",", "testset", "=", "train_test_dummy_timestamp", "\n", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "trainset", ")", "\n", "df", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\"trainset\"", ")", "\n", "\n", "df", "=", "spark", ".", "table", "(", "\"trainset\"", ")", "\n", "\n", "model", ".", "fit", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_sar_item_similarity": [[205, 276], ["pytest.mark.parametrize", "pysarplus.SARPlus", "spark.createDataFrame", "pysarplus.SARPlus.fit", "pandas.read_csv", "pandas.melt", "item_similarity_ref[].sort_values().reset_index", "pysarplus.SARPlus.item_similarity.toPandas().sort_values().reset_index", "numpy.allclose", "item_similarity_ref[].sort_values", "pysarplus.SARPlus.item_similarity.toPandas().sort_values", "str", "pysarplus.SARPlus.item_similarity.toPandas"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"threshold,similarity_type,file\"", ",", "\n", "[", "\n", "(", "1", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "\n", "(", "1", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "\n", "(", "1", ",", "\"lift\"", ",", "\"lift\"", ")", ",", "\n", "(", "3", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "\n", "(", "3", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "\n", "(", "3", ",", "\"lift\"", ",", "\"lift\"", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_sar_item_similarity", "(", "\n", "spark", ",", "\n", "threshold", ",", "\n", "similarity_type", ",", "\n", "file", ",", "\n", "demo_usage_data", ",", "\n", "sar_settings", ",", "\n", "header", ",", "\n", ")", ":", "\n", "\n", "    ", "model", "=", "SARPlus", "(", "\n", "spark", ",", "\n", "**", "header", ",", "\n", "timedecay_formula", "=", "False", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "None", ",", "\n", "threshold", "=", "threshold", ",", "\n", "similarity_type", "=", "similarity_type", ",", "\n", ")", "\n", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "demo_usage_data", ")", "\n", "model", ".", "fit", "(", "df", ")", "\n", "\n", "# reference", "\n", "item_similarity_ref", "=", "pd", ".", "read_csv", "(", "\n", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"sim_\"", "+", "file", "+", "str", "(", "threshold", ")", "+", "\".csv\"", "\n", ")", "\n", "\n", "item_similarity_ref", "=", "pd", ".", "melt", "(", "\n", "item_similarity_ref", ",", "\n", "item_similarity_ref", ".", "columns", "[", "0", "]", ",", "\n", "item_similarity_ref", ".", "columns", "[", "1", ":", "]", ",", "\n", "\"i2\"", ",", "\n", "\"value\"", ",", "\n", ")", "\n", "item_similarity_ref", ".", "columns", "=", "[", "\"i1\"", ",", "\"i2\"", ",", "\"value\"", "]", "\n", "\n", "item_similarity_ref", "=", "(", "\n", "item_similarity_ref", "[", "item_similarity_ref", ".", "value", ">", "0", "]", "\n", ".", "sort_values", "(", "[", "\"i1\"", ",", "\"i2\"", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "# actual", "\n", "item_similarity", "=", "(", "\n", "model", ".", "item_similarity", ".", "toPandas", "(", ")", "\n", ".", "sort_values", "(", "[", "\"i1\"", ",", "\"i2\"", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "if", "similarity_type", "==", "\"cooccurrence\"", ":", "\n", "        ", "assert", "(", "item_similarity_ref", "==", "item_similarity", ")", ".", "all", "(", ")", ".", "all", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "(", "\n", "(", "item_similarity", ".", "iloc", "[", ":", ",", ":", "1", "]", "==", "item_similarity_ref", ".", "iloc", "[", ":", ",", ":", "1", "]", ")", ".", "all", "(", ")", ".", "all", "(", ")", "\n", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "\n", "item_similarity", ".", "value", ".", "values", ",", "\n", "item_similarity_ref", ".", "value", ".", "values", ",", "\n", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_user_affinity": [[280, 345], ["demo_usage_data[].max", "pysarplus.SARPlus", "spark.createDataFrame", "pysarplus.SARPlus.fit", "pandas.read_csv", "pandas.melt", "user_affinity_ref[].reset_index", "spark.createDataFrame", "pysarplus.SARPlus.get_user_affinity().toPandas().reset_index", "numpy.allclose", "pandas.read_csv().iloc[].squeeze", "pysarplus.SARPlus", "pysarplus.SARPlus.fit", "pandas.DataFrame", "spark.createDataFrame", "pysarplus.SARPlus.get_user_affinity().toPandas", "numpy.allclose", "pandas.DataFrame", "spark.createDataFrame", "model.get_user_affinity().toPandas.set_index", "pysarplus.SARPlus.get_user_affinity().toPandas", "pysarplus.SARPlus.get_user_affinity", "demo_usage_data[].max", "pysarplus.SARPlus.get_user_affinity", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.get_user_affinity", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.get_user_affinity"], ["", "", "def", "test_user_affinity", "(", "spark", ",", "demo_usage_data", ",", "sar_settings", ",", "header", ")", ":", "\n", "    ", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "\n", "\n", "model", "=", "SARPlus", "(", "\n", "spark", ",", "\n", "**", "header", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "time_now", ",", "\n", "similarity_type", "=", "\"cooccurrence\"", ",", "\n", ")", "\n", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "demo_usage_data", ")", "\n", "model", ".", "fit", "(", "df", ")", "\n", "\n", "user_affinity_ref", "=", "pd", ".", "read_csv", "(", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"user_aff.csv\"", ")", "\n", "user_affinity_ref", "=", "pd", ".", "melt", "(", "\n", "user_affinity_ref", ",", "\n", "user_affinity_ref", ".", "columns", "[", "0", "]", ",", "\n", "user_affinity_ref", ".", "columns", "[", "1", ":", "]", ",", "\n", "\"ItemId\"", ",", "\n", "\"Rating\"", ",", "\n", ")", "\n", "user_affinity_ref", "=", "user_affinity_ref", "[", "user_affinity_ref", ".", "Rating", ">", "0", "]", ".", "reset_index", "(", "\n", "drop", "=", "True", "\n", ")", "\n", "\n", "# construct dataframe with test user id we'd like to get the affinity for", "\n", "df_test", "=", "spark", ".", "createDataFrame", "(", "\n", "pd", ".", "DataFrame", "(", "{", "header", "[", "\"col_user\"", "]", ":", "[", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "]", "}", ")", "\n", ")", "\n", "user_affinity", "=", "model", ".", "get_user_affinity", "(", "df_test", ")", ".", "toPandas", "(", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# verify the that item ids are the same", "\n", "assert", "(", "user_affinity", "[", "header", "[", "\"col_item\"", "]", "]", "==", "user_affinity_ref", ".", "ItemId", ")", ".", "all", "(", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "\n", "user_affinity_ref", "[", "header", "[", "\"col_rating\"", "]", "]", ".", "values", ",", "\n", "user_affinity", "[", "\"Rating\"", "]", ".", "values", ",", "\n", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ",", "\n", ")", "\n", "\n", "# Set time_now to 60 days later", "\n", "user_affinity_ref", "=", "pd", ".", "read_csv", "(", "\n", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"user_aff_2_months_later.csv\"", "\n", ")", ".", "iloc", "[", ":", ",", "1", ":", "]", ".", "squeeze", "(", ")", "\n", "user_affinity_ref", "=", "user_affinity_ref", "[", "user_affinity_ref", ">", "0", "]", "\n", "\n", "two_months", "=", "2", "*", "30", "*", "(", "24", "*", "60", "*", "60", ")", "\n", "model", "=", "SARPlus", "(", "\n", "spark", ",", "\n", "**", "header", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "+", "two_months", ",", "\n", "similarity_type", "=", "\"cooccurrence\"", ",", "\n", ")", "\n", "model", ".", "fit", "(", "spark", ".", "createDataFrame", "(", "demo_usage_data", ")", ")", "\n", "df_test", "=", "pd", ".", "DataFrame", "(", "{", "header", "[", "\"col_user\"", "]", ":", "[", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "]", "}", ")", "\n", "df_test", "=", "spark", ".", "createDataFrame", "(", "df_test", ")", "\n", "user_affinity", "=", "model", ".", "get_user_affinity", "(", "df_test", ")", ".", "toPandas", "(", ")", "\n", "user_affinity", "=", "user_affinity", ".", "set_index", "(", "header", "[", "\"col_item\"", "]", ")", "[", "header", "[", "\"col_rating\"", "]", "]", "\n", "user_affinity", "=", "user_affinity", "[", "user_affinity_ref", ".", "index", "]", "\n", "\n", "assert", "np", ".", "allclose", "(", "user_affinity_ref", ",", "user_affinity", ",", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.test_pyspark_sar.test_userpred": [[348, 407], ["pytest.mark.parametrize", "demo_usage_data[].max", "pysarplus.SARPlus", "spark.createDataFrame", "pysarplus.SARPlus.fit", "pandas.read_csv", "pandas.wide_to_long().sort_values().reset_index", "pysarplus.SARPlus.recommend_k_items", "pred.toPandas().sort_values().reset_index.toPandas().sort_values().reset_index", "numpy.allclose", "spark.createDataFrame", "str", "str", "pandas.wide_to_long().sort_values", "pred.toPandas().sort_values().reset_index.toPandas().sort_values", "tmp_path.joinpath", "pandas.wide_to_long", "pred.toPandas().sort_values().reset_index.toPandas"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"threshold,similarity_type,file\"", ",", "\n", "[", "(", "3", ",", "\"cooccurrence\"", ",", "\"count\"", ")", ",", "(", "3", ",", "\"jaccard\"", ",", "\"jac\"", ")", ",", "(", "3", ",", "\"lift\"", ",", "\"lift\"", ")", "]", ",", "\n", ")", "\n", "def", "test_userpred", "(", "\n", "spark", ",", "\n", "tmp_path", ",", "\n", "threshold", ",", "\n", "similarity_type", ",", "\n", "file", ",", "\n", "header", ",", "\n", "sar_settings", ",", "\n", "demo_usage_data", ",", "\n", ")", ":", "\n", "    ", "time_now", "=", "demo_usage_data", "[", "header", "[", "\"col_timestamp\"", "]", "]", ".", "max", "(", ")", "\n", "\n", "test_id", "=", "\"{0}_{1}_{2}\"", ".", "format", "(", "threshold", ",", "similarity_type", ",", "file", ")", "\n", "\n", "model", "=", "SARPlus", "(", "\n", "spark", ",", "\n", "**", "header", ",", "\n", "table_prefix", "=", "test_id", ",", "\n", "timedecay_formula", "=", "True", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "time_now", ",", "\n", "threshold", "=", "threshold", ",", "\n", "similarity_type", "=", "similarity_type", ",", "\n", "cache_path", "=", "str", "(", "tmp_path", ".", "joinpath", "(", "\"test_userpred-\"", "+", "test_id", ")", ")", ",", "\n", ")", "\n", "\n", "df", "=", "spark", ".", "createDataFrame", "(", "demo_usage_data", ")", "\n", "model", ".", "fit", "(", "df", ")", "\n", "\n", "url", "=", "sar_settings", "[", "\"FILE_DIR\"", "]", "+", "\"userpred_\"", "+", "file", "+", "str", "(", "threshold", ")", "+", "\"_userid_only.csv\"", "\n", "\n", "pred_ref", "=", "pd", ".", "read_csv", "(", "url", ")", "\n", "pred_ref", "=", "(", "\n", "pd", ".", "wide_to_long", "(", "pred_ref", ",", "[", "\"rec\"", ",", "\"score\"", "]", ",", "\"user\"", ",", "\"idx\"", ")", "\n", ".", "sort_values", "(", "\"score\"", ",", "ascending", "=", "False", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "\n", "# Note: it's important to have a separate cache_path for each run as they're interfering with each other", "\n", "pred", "=", "model", ".", "recommend_k_items", "(", "\n", "spark", ".", "createDataFrame", "(", "\n", "demo_usage_data", "[", "\n", "demo_usage_data", "[", "header", "[", "\"col_user\"", "]", "]", "==", "sar_settings", "[", "\"TEST_USER_ID\"", "]", "\n", "]", "\n", ")", ",", "\n", "top_k", "=", "10", ",", "\n", "n_user_prediction_partitions", "=", "1", ",", "\n", "use_cache", "=", "True", ",", "\n", ")", "\n", "\n", "pred", "=", "pred", ".", "toPandas", "(", ")", ".", "sort_values", "(", "\"score\"", ",", "ascending", "=", "False", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "assert", "(", "pred", ".", "MovieId", ".", "values", "==", "pred_ref", ".", "rec", ".", "values", ")", ".", "all", "(", ")", "\n", "assert", "np", ".", "allclose", "(", "\n", "pred", ".", "score", ".", "values", ",", "pred_ref", ".", "score", ".", "values", ",", "atol", "=", "sar_settings", "[", "\"ATOL\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.demo_usage_data": [[138, 162], ["pytest.fixture", "pandas.read_csv", "pandas.Series", "data.rename.rename", "data[].apply", "float", "calendar.timegm", "datetime.datetime.strptime().timetuple", "datetime.datetime.strptime"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.header": [[102, 111], ["pytest.fixture"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.pandas_dummy": [[113, 122], ["pytest.fixture", "pandas.DataFrame"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.pandas_dummy_timestamp": [[124, 131], ["pytest.fixture", "range"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.sar_settings": [[90, 99], ["pytest.fixture"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.train_test_dummy_timestamp": [[133, 136], ["pytest.fixture", "sklearn.model_selection.train_test_split"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.output_notebook": [[33, 36], ["pytest.fixture"], "function", ["None"], [")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.kernel_name": [[38, 43], ["pytest.fixture"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "header", "(", ")", ":", "\n", "    ", "header", "=", "{", "\n", "\"col_user\"", ":", "\"UserId\"", ",", "\n", "\"col_item\"", ":", "\"MovieId\"", ",", "\n", "\"col_rating\"", ":", "\"Rating\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.path_notebooks": [[45, 49], ["os.path.abspath", "os.path.join", "os.path.dirname"], "function", ["None"], ["}", "\n", "return", "header", "\n", "\n", "\n", "", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.tmp": [[52, 56], ["tempfile.TemporaryDirectory", "tmp_path_factory.getbasetemp"], "function", ["None"], ["header", "[", "\"col_user\"", "]", ":", "[", "1", ",", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "header", "[", "\"col_item\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", ",", "\n", "header", "[", "\"col_rating\"", "]", ":", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "ratings_dict", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.spark": [[58, 88], ["pytest.fixture", "tempfile.TemporaryDirectory", "recommenders.utils.spark_utils.start_or_get_spark", "recommenders.utils.spark_utils.start_or_get_spark.stop", "tmp_path_factory.getbasetemp"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.spark_utils.start_or_get_spark", "home.repos.pwc.inspect_result.microsoft_recommenders.utils.timer.Timer.stop"], ["\n", "\n", "", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "pandas_dummy_timestamp", "(", "pandas_dummy", ",", "header", ")", ":", "\n", "    ", "time", "=", "1535133442", "\n", "time_series", "=", "[", "time", "+", "20", "*", "i", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "df", "=", "pandas_dummy", "\n", "df", "[", "header", "[", "\"col_timestamp\"", "]", "]", "=", "time_series", "\n", "return", "df", "\n", "\n", "\n", "", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "sar_settings", "(", ")", ":", "\n", "    ", "return", "{", "\n", "# absolute tolerance parameter for matrix equivalence in SAR tests", "\n", "\"ATOL\"", ":", "1e-8", ",", "\n", "# directory of the current file - used to link unit test data", "\n", "\"FILE_DIR\"", ":", "\"https://recodatasets.z20.web.core.windows.net/sarunittest/\"", ",", "\n", "# user ID used in the test files (they are designed for this user ID, this is part of the test)", "\n", "\"TEST_USER_ID\"", ":", "\"0003000098E85347\"", ",", "\n", "}", "\n", "\n", "\n", "", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "train_test_dummy_timestamp", "(", "pandas_dummy_timestamp", ")", ":", "\n", "    ", "return", "train_test_split", "(", "pandas_dummy_timestamp", ",", "test_size", "=", "0.2", ",", "random_state", "=", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.demo_usage_data_spark": [[164, 168], ["pytest.fixture", "spark.createDataFrame", "header.items"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.criteo_first_row": [[170, 213], ["pytest.fixture"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.notebooks": [[216, 340], ["pytest.fixture", "conftest.path_notebooks", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.path_notebooks"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.test_specs_ncf": [[345, 354], ["pytest.fixture"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf": [[357, 396], ["pytest.fixture", "numpy.random.seed", "pandas.DataFrame", "recommenders.datasets.python_splitters.python_chrono_split", "numpy.arange", "range", "random_dates.append", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "conftest.dataset_ncf.random_date_generator"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_chrono_split"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf_files": [[398, 407], ["train.sort_values.sort_values", "test.sort_values.sort_values", "test.sort_values.groupby().last().reset_index", "test[].isin", "test[].isin", "test.sort_values.groupby().last", "train[].unique", "train[].unique", "test.sort_values.groupby"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.data_paths": [[409, 415], ["os.path.join", "os.path.join", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf_files_sorted": [[417, 425], ["train.to_csv", "test.to_csv", "leave_one_out_test.to_csv"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf_files_unsorted": [[427, 439], ["train.apply.apply", "test.apply.apply", "leave_one_out_test.apply.apply", "train.apply.to_csv", "test.apply.to_csv", "leave_one_out_test.apply.to_csv"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf_files_empty": [[441, 452], ["train.to_csv", "test.to_csv", "leave_one_out_test.to_csv"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.dataset_ncf_files_missing_column": [[454, 465], ["train.drop.drop", "test.drop.drop", "leave_one_out_test.drop.drop", "train.drop.to_csv", "test.drop.to_csv", "leave_one_out_test.drop.to_csv"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.test_specs": [[470, 479], ["pytest.fixture"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.affinity_matrix": [[482, 516], ["pytest.fixture", "numpy.random.seed", "s.append", "numpy.random.choice", "recommenders.datasets.python_splitters.numpy_stratified_split"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.numpy_stratified_split"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.deeprec_resource_path": [[521, 524], ["pytest.fixture", "pathlib.Path().absolute().parent.joinpath", "pathlib.Path().absolute", "pathlib.Path"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.mind_resource_path": [[526, 529], ["pytest.fixture", "pathlib.Path().absolute().parent.joinpath", "pathlib.Path().absolute", "pathlib.Path"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.tests.conftest.deeprec_config_path": [[531, 538], ["pytest.fixture", "pathlib.Path().absolute().parents[].joinpath", "pathlib.Path().absolute", "pathlib.Path"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.__init__": [[15, 29], ["list", "list.sort", "pysarplus_cpp.SARModelCpp", "pathlib.Path().glob", "len", "ValueError", "str", "pathlib.Path"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "SARModel", ".", "__model", "is", "not", "None", "and", "SARModel", ".", "__path", "==", "path", ":", "\n", "            ", "self", ".", "model", "=", "SARModel", ".", "__model", "\n", "return", "\n", "\n", "# find the .sar.related & .sar.offsets files", "\n", "", "sar_files", "=", "list", "(", "Path", "(", "path", ")", ".", "glob", "(", "\"*\"", "+", "SARModel", ".", "__extension", ")", ")", "\n", "sar_files", ".", "sort", "(", "key", "=", "os", ".", "path", ".", "getmtime", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "sar_files", ")", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Directory '{path}' must contain at least 1 file ending in '{SARModel.__extension}'\"", ")", "\n", "\n", "# instantiate C++ backend", "\n", "", "SARModel", ".", "__model", "=", "self", ".", "model", "=", "pysarplus_cpp", ".", "SARModelCpp", "(", "str", "(", "sar_files", "[", "0", "]", ")", ")", "\n", "SARModel", ".", "__path", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict": [[30, 32], ["SARModel.SARModel.model.predict"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "def", "predict", "(", "self", ",", "items", ",", "ratings", ",", "top_k", ",", "remove_seen", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "predict", "(", "items", ",", "ratings", ",", "top_k", ",", "remove_seen", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.__init__": [[28, 85], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "spark", ",", "\n", "col_user", "=", "\"userID\"", ",", "\n", "col_item", "=", "\"itemID\"", ",", "\n", "col_rating", "=", "\"rating\"", ",", "\n", "col_timestamp", "=", "\"timestamp\"", ",", "\n", "table_prefix", "=", "\"\"", ",", "\n", "similarity_type", "=", "\"jaccard\"", ",", "\n", "time_decay_coefficient", "=", "30", ",", "\n", "time_now", "=", "None", ",", "\n", "timedecay_formula", "=", "False", ",", "\n", "threshold", "=", "1", ",", "\n", "cache_path", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"Initialize model parameters\n        Args:\n            spark (pyspark.sql.SparkSession): Spark session\n            col_user (str): user column name\n            col_item (str): item column name\n            col_rating (str): rating column name\n            col_timestamp (str): timestamp column name\n            table_prefix (str): name prefix of the generated tables\n            similarity_type (str): ['cooccurrence', 'jaccard', 'lift']\n                option for computing item-item similarity\n            time_decay_coefficient (float): number of days till\n                ratings are decayed by 1/2.  denominator in time\n                decay.  Zero makes time decay irrelevant\n            time_now (int | None): current time for time decay\n                calculation\n            timedecay_formula (bool): flag to apply time decay\n            threshold (int): item-item co-occurrences below this\n                threshold will be removed\n            cache_path (str): user specified local cache directory for\n                recommend_k_items().  If specified,\n                recommend_k_items() will do C++ based fast\n                predictions.\n        \"\"\"", "\n", "assert", "threshold", ">", "0", "\n", "\n", "self", ".", "spark", "=", "spark", "\n", "self", ".", "header", "=", "{", "\n", "\"col_user\"", ":", "col_user", ",", "\n", "\"col_item\"", ":", "col_item", ",", "\n", "\"col_rating\"", ":", "col_rating", ",", "\n", "\"col_timestamp\"", ":", "col_timestamp", ",", "\n", "\"prefix\"", ":", "table_prefix", ",", "\n", "\"time_now\"", ":", "time_now", ",", "\n", "\"time_decay_half_life\"", ":", "time_decay_coefficient", "*", "24", "*", "60", "*", "60", ",", "\n", "\"threshold\"", ":", "threshold", ",", "\n", "}", "\n", "\n", "self", ".", "similarity_type", "=", "similarity_type", "\n", "self", ".", "timedecay_formula", "=", "timedecay_formula", "\n", "self", ".", "item_similarity", "=", "None", "\n", "self", ".", "cache_path", "=", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format": [[86, 88], ["string.format"], "methods", ["None"], ["", "def", "_format", "(", "self", ",", "string", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "string", ".", "format", "(", "**", "self", ".", "header", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit": [[89, 250], ["SARPlus.SARPlus.createOrReplaceTempView", "SARPlus.SARPlus.createOrReplaceTempView", "log.info", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.write.mode().saveAsTable", "log.info", "SARPlus.SARPlus.item_similarity.write.mode().saveAsTable", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.item_similarity.write.mode().saveAsTable", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.spark.table", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.createOrReplaceTempView", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.header[].lower", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.write.mode", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.item_similarity.write.mode", "SARPlus.SARPlus.item_similarity.write.mode", "SARPlus.SARPlus.spark.sql().first", "s.name.lower", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "ValueError", "SARPlus.SARPlus.spark.sql"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format"], ["", "def", "fit", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\"Main fit method for SAR.\n\n        Expects the dataframes to have row_id, col_id columns which\n        are indexes, i.e. contain the sequential integer index of the\n        original alphanumeric user and item IDs.  Dataframe also\n        contains rating and timestamp as floats; timestamp is in\n        seconds since Epoch by default.\n\n        Arguments:\n            df (pySpark.DataFrame): input dataframe which contains the\n                index of users and items.\n        \"\"\"", "\n", "\n", "df", ".", "createOrReplaceTempView", "(", "self", ".", "_format", "(", "\"{prefix}df_train_input\"", ")", ")", "\n", "\n", "if", "self", ".", "timedecay_formula", ":", "\n", "# With time decay, we compute a sum over ratings given by", "\n", "# a user in the case when T=np.inf, so user gets a", "\n", "# cumulative sum of ratings for a particular item and not", "\n", "# the last rating.  Time Decay does a group by on user", "\n", "# item pairs and apply the formula for time decay there", "\n", "# Time T parameter is in days and input time is in", "\n", "# seconds, so we do dt/60/(T*24*60)=dt/(T*24*3600) the", "\n", "# following is the query which we want to run", "\n", "\n", "            ", "if", "self", ".", "header", "[", "\"time_now\"", "]", "is", "None", ":", "\n", "                ", "query", "=", "self", ".", "_format", "(", "\"\"\"\n                    SELECT CAST(MAX({col_timestamp}) AS long)\n                    FROM {prefix}df_train_input\n                \"\"\"", ")", "\n", "self", ".", "header", "[", "\"time_now\"", "]", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", ".", "first", "(", ")", "[", "0", "]", "\n", "\n", "", "query", "=", "self", ".", "_format", "(", "\"\"\"\n                SELECT {col_user},\n                       {col_item},\n                       SUM(\n                           {col_rating} *\n                           POW(2, (CAST({col_timestamp} AS LONG) - {time_now}) / {time_decay_half_life})\n                          ) AS {col_rating}\n                FROM {prefix}df_train_input\n                GROUP BY {col_user}, {col_item}\n                CLUSTER BY {col_user}\n            \"\"\"", ")", "\n", "\n", "# replace with time-decayed version", "\n", "df", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "", "else", ":", "\n", "# since SQL is case-insensitive, this check needs to be performed similar", "\n", "            ", "if", "self", ".", "header", "[", "\"col_timestamp\"", "]", ".", "lower", "(", ")", "in", "[", "\n", "s", ".", "name", ".", "lower", "(", ")", "for", "s", "in", "df", ".", "schema", "\n", "]", ":", "\n", "# we need to de-duplicate items by using the latest item", "\n", "                ", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n                SELECT {col_user}, {col_item}, {col_rating}\n                FROM\n                (\n                SELECT\n                    {col_user}, {col_item}, {col_rating}, \n                    ROW_NUMBER() OVER (PARTITION BY {col_user}, {col_item} ORDER BY {col_timestamp} DESC) latest\n                FROM {prefix}df_train_input\n                )\n                WHERE latest = 1\n                \"\"\"", "\n", ")", "\n", "\n", "df", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "\n", "", "", "df", ".", "createOrReplaceTempView", "(", "self", ".", "_format", "(", "\"{prefix}df_train\"", ")", ")", "\n", "\n", "log", ".", "info", "(", "\"sarplus.fit 1/2: compute item cooccurrences...\"", ")", "\n", "\n", "# compute cooccurrence above minimum threshold", "\n", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n        SELECT A.{col_item} i1, B.{col_item} i2, COUNT(*) value\n        FROM   {prefix}df_train A INNER JOIN {prefix}df_train B\n               ON A.{col_user} = B.{col_user} AND A.{col_item} <= b.{col_item}  \n        GROUP  BY A.{col_item}, B.{col_item}\n        HAVING COUNT(*) >= {threshold}\n        CLUSTER BY i1, i2\n        \"\"\"", "\n", ")", "\n", "\n", "item_cooccurrence", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "item_cooccurrence", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\n", "self", ".", "_format", "(", "\"{prefix}item_cooccurrence\"", ")", "\n", ")", "\n", "\n", "# compute the diagonal used later for Jaccard and Lift", "\n", "if", "self", ".", "similarity_type", "==", "SIM_LIFT", "or", "self", ".", "similarity_type", "==", "SIM_JACCARD", ":", "\n", "            ", "item_marginal", "=", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"SELECT i1 i, value AS margin FROM {prefix}item_cooccurrence WHERE i1 = i2\"", "\n", ")", "\n", ")", "\n", "item_marginal", ".", "createOrReplaceTempView", "(", "self", ".", "_format", "(", "\"{prefix}item_marginal\"", ")", ")", "\n", "\n", "", "if", "self", ".", "similarity_type", "==", "SIM_COOCCUR", ":", "\n", "            ", "self", ".", "item_similarity", "=", "item_cooccurrence", "\n", "", "elif", "self", ".", "similarity_type", "==", "SIM_JACCARD", ":", "\n", "            ", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n            SELECT i1, i2, value / (M1.margin + M2.margin - value) AS value\n            FROM {prefix}item_cooccurrence A \n                INNER JOIN {prefix}item_marginal M1 ON A.i1 = M1.i \n                INNER JOIN {prefix}item_marginal M2 ON A.i2 = M2.i\n            CLUSTER BY i1, i2\n            \"\"\"", "\n", ")", "\n", "self", ".", "item_similarity", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "", "elif", "self", ".", "similarity_type", "==", "SIM_LIFT", ":", "\n", "            ", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n            SELECT i1, i2, value / (M1.margin * M2.margin) AS value\n            FROM {prefix}item_cooccurrence A \n                INNER JOIN {prefix}item_marginal M1 ON A.i1 = M1.i \n                INNER JOIN {prefix}item_marginal M2 ON A.i2 = M2.i\n            CLUSTER BY i1, i2\n            \"\"\"", "\n", ")", "\n", "self", ".", "item_similarity", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unknown similarity type: {0}\"", ".", "format", "(", "self", ".", "similarity_type", ")", "\n", ")", "\n", "\n", "# store upper triangular", "\n", "", "log", ".", "info", "(", "\n", "\"sarplus.fit 2/2: compute similarity metric %s...\"", "%", "self", ".", "similarity_type", "\n", ")", "\n", "self", ".", "item_similarity", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\n", "self", ".", "_format", "(", "\"{prefix}item_similarity_upper\"", ")", "\n", ")", "\n", "\n", "# expand upper triangular to full matrix", "\n", "\n", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n        SELECT i1, i2, value\n        FROM\n        (\n          (SELECT i1, i2, value FROM {prefix}item_similarity_upper)\n          UNION ALL\n          (SELECT i2 i1, i1 i2, value FROM {prefix}item_similarity_upper WHERE i1 <> i2)\n        )\n        CLUSTER BY i1\n        \"\"\"", "\n", ")", "\n", "\n", "self", ".", "item_similarity", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "self", ".", "item_similarity", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\n", "self", ".", "_format", "(", "\"{prefix}item_similarity\"", ")", "\n", ")", "\n", "\n", "# free space", "\n", "self", ".", "spark", ".", "sql", "(", "self", ".", "_format", "(", "\"DROP TABLE {prefix}item_cooccurrence\"", ")", ")", "\n", "self", ".", "spark", ".", "sql", "(", "self", ".", "_format", "(", "\"DROP TABLE {prefix}item_similarity_upper\"", ")", ")", "\n", "\n", "self", ".", "item_similarity", "=", "self", ".", "spark", ".", "table", "(", "self", ".", "_format", "(", "\"{prefix}item_similarity\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.get_user_affinity": [[251, 279], ["test.createOrReplaceTempView", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.write.mode().saveAsTable", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.write.mode"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format"], ["", "def", "get_user_affinity", "(", "self", ",", "test", ")", ":", "\n", "        ", "\"\"\"Prepare test set for C++ SAR prediction code.\n        Find all items the test users have seen in the past.\n\n        Arguments:\n            test (pySpark.DataFrame): input dataframe which contains test users.\n        \"\"\"", "\n", "test", ".", "createOrReplaceTempView", "(", "self", ".", "_format", "(", "\"{prefix}df_test\"", ")", ")", "\n", "\n", "query", "=", "self", ".", "_format", "(", "\n", "\"SELECT DISTINCT {col_user} FROM {prefix}df_test CLUSTER BY {col_user}\"", "\n", ")", "\n", "\n", "df_test_users", "=", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "df_test_users", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\n", "self", ".", "_format", "(", "\"{prefix}df_test_users\"", ")", "\n", ")", "\n", "\n", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n          SELECT a.{col_user}, a.{col_item}, CAST(a.{col_rating} AS double) {col_rating}\n          FROM {prefix}df_train a INNER JOIN {prefix}df_test_users b ON a.{col_user} = b.{col_user} \n          DISTRIBUTE BY {col_user}\n          SORT BY {col_user}, {col_item}\n        \"\"\"", "\n", ")", "\n", "\n", "return", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._recommend_k_items_fast": [[280, 403], ["log.info", "SARPlus.SARPlus.spark.sql().write.mode().saveAsTable", "SARPlus.SARPlus.spark.sql().write.mode().saveAsTable", "SARPlus.SARPlus.cache_path.startswith", "log.info", "SARPlus.SARPlus.spark.sql().coalesce().write.format().mode().save", "SARPlus.SARPlus.get_user_affinity().createOrReplaceTempView", "SARPlus.SARPlus.spark.sql", "pyspark.sql.types.StructType", "pyspark.sql.functions.pandas_udf", "log.info", "SARPlus.SARPlus.repartition().groupby().apply", "SARPlus.SARPlus.repartition().groupby().apply.createOrReplaceTempView", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.cache_path.startswith", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "pysarplus.SARModel", "pysarplus.SARModel.predict", "pandas.DataFrame", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql().write.mode", "SARPlus.SARPlus.spark.sql().write.mode", "SARPlus.SARPlus.spark.sql().coalesce().write.format().mode", "SARPlus.SARPlus.get_user_affinity", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "pyspark.sql.types.StructField", "SARPlus.SARPlus.repartition().groupby", "pyspark.sql.types.IntegerType", "pyspark.sql.types.FloatType", "range", "SARPlus.SARPlus.spark.sql().coalesce().write.format", "SARPlus.SARPlus.repartition", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus._format", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql().coalesce", "SARPlus.SARPlus.spark.sql", "SARPlus.SARPlus._format"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.rbm.rbm.RBM.save", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.get_user_affinity", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format"], ["", "def", "_recommend_k_items_fast", "(", "\n", "self", ",", "\n", "test", ",", "\n", "top_k", "=", "10", ",", "\n", "remove_seen", "=", "True", ",", "\n", "n_user_prediction_partitions", "=", "200", ",", "\n", ")", ":", "\n", "\n", "        ", "assert", "self", ".", "cache_path", "is", "not", "None", "\n", "\n", "# create item id to continuous index mapping", "\n", "log", ".", "info", "(", "\"sarplus.recommend_k_items 1/3: create item index\"", ")", "\n", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"SELECT i1, row_number() OVER(ORDER BY i1)-1 idx FROM (SELECT DISTINCT i1 FROM {prefix}item_similarity) CLUSTER BY i1\"", "\n", ")", "\n", ")", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "self", ".", "_format", "(", "\"{prefix}item_mapping\"", ")", ")", "\n", "\n", "# map similarity matrix into index space", "\n", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"\"\"\n            SELECT a.idx i1, b.idx i2, is.value\n            FROM {prefix}item_similarity is, {prefix}item_mapping a, {prefix}item_mapping b\n            WHERE is.i1 = a.i1 AND i2 = b.i1\n        \"\"\"", "\n", ")", "\n", ")", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "self", ".", "_format", "(", "\"{prefix}item_similarity_mapped\"", ")", ")", "\n", "\n", "cache_path_output", "=", "self", ".", "cache_path", "\n", "if", "self", ".", "cache_path", ".", "startswith", "(", "\"dbfs:\"", ")", ":", "\n", "# Databricks DBFS", "\n", "            ", "cache_path_input", "=", "\"/dbfs\"", "+", "self", ".", "cache_path", "[", "5", ":", "]", "\n", "", "elif", "self", ".", "cache_path", ".", "startswith", "(", "\"synfs:\"", ")", ":", "\n", "# Azure Synapse", "\n", "# See https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/synapse-file-mount-api", "\n", "            ", "cache_path_input", "=", "\"/synfs\"", "+", "self", ".", "cache_path", "[", "6", ":", "]", "\n", "", "else", ":", "\n", "            ", "cache_path_input", "=", "self", ".", "cache_path", "\n", "\n", "# export similarity matrix for C++ backed UDF", "\n", "", "log", ".", "info", "(", "\"sarplus.recommend_k_items 2/3: prepare similarity matrix\"", ")", "\n", "\n", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"SELECT i1, i2, CAST(value AS DOUBLE) value FROM {prefix}item_similarity_mapped ORDER BY i1, i2\"", "\n", ")", "\n", ")", ".", "coalesce", "(", "1", ")", ".", "write", ".", "format", "(", "\"com.microsoft.sarplus\"", ")", ".", "mode", "(", "\"overwrite\"", ")", ".", "save", "(", "\n", "cache_path_output", "\n", ")", "\n", "\n", "self", ".", "get_user_affinity", "(", "test", ")", ".", "createOrReplaceTempView", "(", "\n", "self", ".", "_format", "(", "\"{prefix}user_affinity\"", ")", "\n", ")", "\n", "\n", "# map item ids to index space", "\n", "pred_input", "=", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"\"\"\n            SELECT {col_user}, idx, rating\n            FROM \n            (\n                SELECT {col_user}, b.idx, {col_rating} rating\n                FROM {prefix}user_affinity JOIN {prefix}item_mapping b ON {col_item} = b.i1 \n            )\n            CLUSTER BY {col_user}\n        \"\"\"", "\n", ")", "\n", ")", "\n", "\n", "schema", "=", "StructType", "(", "\n", "[", "\n", "StructField", "(", "\n", "\"userID\"", ",", "pred_input", ".", "schema", "[", "self", ".", "header", "[", "\"col_user\"", "]", "]", ".", "dataType", ",", "True", "\n", ")", ",", "\n", "StructField", "(", "\"itemID\"", ",", "IntegerType", "(", ")", ",", "True", ")", ",", "\n", "StructField", "(", "\"score\"", ",", "FloatType", "(", ")", ",", "True", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# make sure only the header is pickled", "\n", "local_header", "=", "self", ".", "header", "\n", "\n", "# bridge to python/C++", "\n", "@", "pandas_udf", "(", "schema", ",", "PandasUDFType", ".", "GROUPED_MAP", ")", "\n", "def", "sar_predict_udf", "(", "df", ")", ":", "\n", "# Magic happening here", "\n", "# The cache_path points to file write to by com.microsoft.sarplus", "\n", "# This has exactly the memory layout we need and since the file is", "\n", "# memory mapped, the memory consumption only happens once per worker", "\n", "# for all python processes", "\n", "            ", "model", "=", "SARModel", "(", "cache_path_input", ")", "\n", "preds", "=", "model", ".", "predict", "(", "\n", "df", "[", "\"idx\"", "]", ".", "values", ",", "df", "[", "\"rating\"", "]", ".", "values", ",", "top_k", ",", "remove_seen", "\n", ")", "\n", "\n", "user", "=", "df", "[", "local_header", "[", "\"col_user\"", "]", "]", ".", "iloc", "[", "0", "]", "\n", "\n", "preds_ret", "=", "pd", ".", "DataFrame", "(", "\n", "[", "(", "user", ",", "x", ".", "id", ",", "x", ".", "score", ")", "for", "x", "in", "preds", "]", ",", "columns", "=", "range", "(", "3", ")", "\n", ")", "\n", "\n", "return", "preds_ret", "\n", "\n", "", "log", ".", "info", "(", "\"sarplus.recommend_k_items 3/3: compute recommendations\"", ")", "\n", "\n", "df_preds", "=", "(", "\n", "pred_input", ".", "repartition", "(", "\n", "n_user_prediction_partitions", ",", "self", ".", "header", "[", "\"col_user\"", "]", "\n", ")", "\n", ".", "groupby", "(", "self", ".", "header", "[", "\"col_user\"", "]", ")", "\n", ".", "apply", "(", "sar_predict_udf", ")", "\n", ")", "\n", "\n", "df_preds", ".", "createOrReplaceTempView", "(", "self", ".", "_format", "(", "\"{prefix}predictions\"", ")", ")", "\n", "\n", "return", "self", ".", "spark", ".", "sql", "(", "\n", "self", ".", "_format", "(", "\n", "\"\"\"\n        SELECT userID {col_user}, b.i1 {col_item}, score\n        FROM {prefix}predictions p, {prefix}item_mapping b\n        WHERE p.itemID = b.idx\n        \"\"\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._recommend_k_items_slow": [[406, 446], ["SARPlus.SARPlus.get_user_affinity().write.mode().saveAsTable", "SARPlus.SARPlus._format", "SARPlus.SARPlus.spark.sql", "ValueError", "SARPlus.SARPlus._format", "SARPlus.SARPlus.get_user_affinity().write.mode", "SARPlus.SARPlus.get_user_affinity"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._format", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.get_user_affinity"], ["", "def", "_recommend_k_items_slow", "(", "self", ",", "test", ",", "top_k", "=", "10", ",", "remove_seen", "=", "True", ")", ":", "\n", "        ", "\"\"\"Recommend top K items for all users which are in the test set.\n\n        Args:\n            test: test Spark dataframe\n            top_k: top n items to return\n            remove_seen: remove items test users have already seen in the past from the recommended set.\n        \"\"\"", "\n", "\n", "# TODO: remove seen", "\n", "if", "remove_seen", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "self", ".", "get_user_affinity", "(", "test", ")", ".", "write", ".", "mode", "(", "\"overwrite\"", ")", ".", "saveAsTable", "(", "\n", "self", ".", "_format", "(", "\"{prefix}user_affinity\"", ")", "\n", ")", "\n", "\n", "# user_affinity * item_similarity", "\n", "# filter top-k", "\n", "query", "=", "self", ".", "_format", "(", "\n", "\"\"\"\n        SELECT {col_user}, {col_item}, score\n        FROM\n        (\n          SELECT df.{col_user},\n                 S.i2 {col_item},\n                 SUM(df.{col_rating} * S.value) AS score,\n                 row_number() OVER(PARTITION BY {col_user} ORDER BY SUM(df.{col_rating} * S.value) DESC) rank\n          FROM   \n            {prefix}user_affinity df, \n            {prefix}item_similarity S\n          WHERE df.{col_item} = S.i1\n          GROUP BY df.{col_user}, S.i2\n        )\n        WHERE rank <= {top_k} \n        \"\"\"", ",", "\n", "top_k", "=", "top_k", ",", "\n", ")", "\n", "\n", "return", "self", ".", "spark", ".", "sql", "(", "query", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items": [[447, 474], ["SARPlus.SARPlus._recommend_k_items_slow", "SARPlus.SARPlus._recommend_k_items_fast", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._recommend_k_items_slow", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus._recommend_k_items_fast"], ["", "def", "recommend_k_items", "(", "\n", "self", ",", "\n", "test", ",", "\n", "top_k", "=", "10", ",", "\n", "remove_seen", "=", "True", ",", "\n", "use_cache", "=", "False", ",", "\n", "n_user_prediction_partitions", "=", "200", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Recommend top K items for all users which are in the test set.\n\n        Args:\n            test (pyspark.sql.DataFrame): test Spark dataframe.\n            top_k (int): top n items to return.\n            remove_seen (bool): remove items test users have already seen in the past from the recommended set.\n            use_cache (bool): use specified local directory stored in `self.cache_path` as cache for C++ based fast\n                predictions.\n            n_user_prediction_partitions (int): prediction partitions.\n\n        Returns:\n            pyspark.sql.DataFrame: Spark dataframe with recommended items\n        \"\"\"", "\n", "if", "not", "use_cache", ":", "\n", "            ", "return", "self", ".", "_recommend_k_items_slow", "(", "test", ",", "top_k", ",", "remove_seen", ")", "\n", "", "elif", "self", ".", "cache_path", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_recommend_k_items_fast", "(", "test", ",", "top_k", ",", "remove_seen", ",", "n_user_prediction_partitions", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"No cache_path specified\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip": [[238, 242], ["None"], "function", ["None"], ["def", "skip", "(", "app", ",", "what", ",", "name", ",", "obj", ",", "would_skip", ",", "options", ")", ":", "\n", "    ", "if", "name", "==", "\"__init__\"", ":", "\n", "        ", "return", "False", "\n", "", "return", "would_skip", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.setup": [[244, 246], ["app.connect"], "function", ["None"], ["", "def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "connect", "(", "\"autodoc-skip-member\"", ",", "skip", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_gpu_vm": [[15, 19], ["recommenders.utils.gpu_utils.get_number_gpus"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.utils.gpu_utils.get_number_gpus"], ["\n", "\n", "TOL", "=", "0.5", "\n", "ABS_TOL", "=", "0.05", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf_integration": [[27, 64], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "10", ",", "\n", "{", "\n", "\"map\"", ":", "0.0255283", ",", "\n", "\"ndcg\"", ":", "0.15656", ",", "\n", "\"precision\"", ":", "0.145646", ",", "\n", "\"recall\"", ":", "0.0557367", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", ",", "\n", "# (\"10m\", 5, {\"map\": 0.024821, \"ndcg\": 0.153396, \"precision\": 0.143046, \"recall\": 0.056590})# takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_ncf_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", ",", "seed", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"ncf\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ",", "EPOCHS", "=", "epochs", ",", "BATCH_SIZE", "=", "512", ",", "SEED", "=", "seed", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf_deep_dive_integration": [[66, 118], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, batch_size, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"100k\"", ",", "\n", "10", ",", "\n", "512", ",", "\n", "{", "\n", "\"map\"", ":", "0.0435856", ",", "\n", "\"ndcg\"", ":", "0.37586", ",", "\n", "\"precision\"", ":", "0.169353", ",", "\n", "\"recall\"", ":", "0.0923963", ",", "\n", "\"map2\"", ":", "0.0510391", ",", "\n", "\"ndcg2\"", ":", "0.202186", ",", "\n", "\"precision2\"", ":", "0.179533", ",", "\n", "\"recall2\"", ":", "0.106434", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_ncf_deep_dive_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "size", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"ncf_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "\n", "MOVIELENS_DATA_SIZE", "=", "size", ",", "\n", "EPOCHS", "=", "epochs", ",", "\n", "BATCH_SIZE", "=", "batch_size", ",", "\n", "SEED", "=", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_fastai_integration": [[120, 158], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "10", ",", "\n", "{", "\n", "\"map\"", ":", "0.025739", ",", "\n", "\"ndcg\"", ":", "0.183417", ",", "\n", "\"precision\"", ":", "0.167246", ",", "\n", "\"recall\"", ":", "0.054307", ",", "\n", "\"rmse\"", ":", "0.881267", ",", "\n", "\"mae\"", ":", "0.700747", ",", "\n", "\"rsquared\"", ":", "0.379963", ",", "\n", "\"exp_var\"", ":", "0.382842", ",", "\n", "}", ",", "\n", ")", ",", "\n", "# (\"10m\", 5, ), # it gets an OOM on pred = learner.model.forward(u, m)", "\n", "]", ",", "\n", ")", "\n", "def", "test_fastai_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"fastai\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ",", "EPOCHS", "=", "epochs", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_xdeepfm_integration": [[160, 206], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"syn_epochs, criteo_epochs, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "15", ",", "\n", "10", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\"auc\"", ":", "0.9716", ",", "\"logloss\"", ":", "0.699", "}", ",", "\n", "\"res_real\"", ":", "{", "\"auc\"", ":", "0.749", ",", "\"logloss\"", ":", "0.4926", "}", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_xdeepfm_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "syn_epochs", ",", "\n", "criteo_epochs", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"xdeepfm_quickstart\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "EPOCHS_FOR_SYNTHETIC_RUN", "=", "syn_epochs", ",", "\n", "EPOCHS_FOR_CRITEO_RUN", "=", "criteo_epochs", ",", "\n", "BATCH_SIZE_SYNTHETIC", "=", "1024", ",", "\n", "BATCH_SIZE_CRITEO", "=", "1024", ",", "\n", "RANDOM_SEED", "=", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "value", "[", "\"auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"logloss\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"logloss\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_wide_deep_integration": [[209, 255], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, steps, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "10000", ",", "\n", "{", "\n", "\"rmse\"", ":", "0.924958", ",", "\n", "\"mae\"", ":", "0.741425", ",", "\n", "\"rsquared\"", ":", "0.316534", ",", "\n", "\"exp_var\"", ":", "0.322202", ",", "\n", "\"ndcg_at_k\"", ":", "0.118114", ",", "\n", "\"map_at_k\"", ":", "0.0139213", ",", "\n", "\"precision_at_k\"", ":", "0.107087", ",", "\n", "\"recall_at_k\"", ":", "0.0328638", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_wide_deep_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "steps", ",", "expected_values", ",", "seed", ",", "tmp", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"wide_deep\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"MOVIELENS_DATA_SIZE\"", ":", "size", ",", "\n", "\"STEPS\"", ":", "steps", ",", "\n", "\"EVALUATE_WHILE_TRAINING\"", ":", "False", ",", "\n", "\"MODEL_DIR\"", ":", "tmp", ",", "\n", "\"EXPORT_DIR_BASE\"", ":", "tmp", ",", "\n", "\"RATING_METRICS\"", ":", "[", "\"rmse\"", ",", "\"mae\"", ",", "\"rsquared\"", ",", "\"exp_var\"", "]", ",", "\n", "\"RANKING_METRICS\"", ":", "[", "\"ndcg_at_k\"", ",", "\"map_at_k\"", ",", "\"precision_at_k\"", ",", "\"recall_at_k\"", "]", ",", "\n", "\"RANDOM_SEED\"", ":", "seed", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_slirec_quickstart_integration": [[257, 301], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "os.path.join", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"yaml_file, data_path, epochs, batch_size, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"recommenders/models/deeprec/config/sli_rec.yaml\"", ",", "\n", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"resources\"", ",", "\"deeprec\"", ",", "\"slirec\"", ")", ",", "\n", "10", ",", "\n", "400", ",", "\n", "{", "\"res_syn\"", ":", "{", "\"auc\"", ":", "0.7183", ",", "\"logloss\"", ":", "0.6045", "}", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_slirec_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "yaml_file", ",", "\n", "data_path", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"slirec_quickstart\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"yaml_file\"", ":", "yaml_file", ",", "\n", "\"data_path\"", ":", "data_path", ",", "\n", "\"EPOCHS\"", ":", "epochs", ",", "\n", "\"BATCH_SIZE\"", ":", "batch_size", ",", "\n", "\"RANDOM_SEED\"", ":", "seed", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "value", "[", "\"auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_nrms_quickstart_integration": [[308, 366], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"epochs, batch_size, seed, MIND_type, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "5", ",", "\n", "64", ",", "\n", "42", ",", "\n", "\"demo\"", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\n", "\"group_auc\"", ":", "0.6217", ",", "\n", "\"mean_mrr\"", ":", "0.2783", ",", "\n", "\"ndcg@5\"", ":", "0.3024", ",", "\n", "\"ndcg@10\"", ":", "0.3719", ",", "\n", "}", "\n", "}", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_nrms_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "seed", ",", "\n", "MIND_type", ",", "\n", "expected_values", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"nrms_quickstart\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"epochs\"", ":", "epochs", ",", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"seed\"", ":", "seed", ",", "\n", "\"MIND_type\"", ":", "MIND_type", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"group_auc\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"group_auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"mean_mrr\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"mean_mrr\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@5\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@5\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@10\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@10\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_naml_quickstart_integration": [[369, 427], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"epochs, batch_size, seed, MIND_type, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "5", ",", "\n", "64", ",", "\n", "42", ",", "\n", "\"demo\"", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\n", "\"group_auc\"", ":", "0.6436", ",", "\n", "\"mean_mrr\"", ":", "0.2990", ",", "\n", "\"ndcg@5\"", ":", "0.3297", ",", "\n", "\"ndcg@10\"", ":", "0.3933", ",", "\n", "}", "\n", "}", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_naml_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "batch_size", ",", "\n", "epochs", ",", "\n", "seed", ",", "\n", "MIND_type", ",", "\n", "expected_values", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"naml_quickstart\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"epochs\"", ":", "epochs", ",", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"seed\"", ":", "seed", ",", "\n", "\"MIND_type\"", ":", "MIND_type", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"group_auc\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"group_auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"mean_mrr\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"mean_mrr\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@5\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@5\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@10\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@10\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_lstur_quickstart_integration": [[430, 488], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"epochs, batch_size, seed, MIND_type, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "5", ",", "\n", "64", ",", "\n", "42", ",", "\n", "\"demo\"", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\n", "\"group_auc\"", ":", "0.6444", ",", "\n", "\"mean_mrr\"", ":", "0.2983", ",", "\n", "\"ndcg@5\"", ":", "0.3287", ",", "\n", "\"ndcg@10\"", ":", "0.3938", ",", "\n", "}", "\n", "}", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_lstur_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "seed", ",", "\n", "MIND_type", ",", "\n", "expected_values", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"lstur_quickstart\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"epochs\"", ":", "epochs", ",", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"seed\"", ":", "seed", ",", "\n", "\"MIND_type\"", ":", "MIND_type", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"group_auc\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"group_auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"mean_mrr\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"mean_mrr\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@5\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@5\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@10\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@10\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_npa_quickstart_integration": [[491, 549], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"epochs, batch_size, seed, MIND_type, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "5", ",", "\n", "64", ",", "\n", "42", ",", "\n", "\"demo\"", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\n", "\"group_auc\"", ":", "0.6035", ",", "\n", "\"mean_mrr\"", ":", "0.2765", ",", "\n", "\"ndcg@5\"", ":", "0.2977", ",", "\n", "\"ndcg@10\"", ":", "0.3637", ",", "\n", "}", "\n", "}", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_npa_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "seed", ",", "\n", "MIND_type", ",", "\n", "expected_values", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"npa_quickstart\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"epochs\"", ":", "epochs", ",", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"seed\"", ":", "seed", ",", "\n", "\"MIND_type\"", ":", "MIND_type", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"group_auc\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"group_auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"mean_mrr\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"mean_mrr\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@5\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@5\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"ndcg@10\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"ndcg@10\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_lightgcn_deep_dive_integration": [[552, 607], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "os.path.join", "os.path.join", "os.path.join", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"yaml_file, data_path, size, epochs, batch_size, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"recommenders/models/deeprec/config/lightgcn.yaml\"", ",", "\n", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"resources\"", ",", "\"deeprec\"", ",", "\"lightgcn\"", ")", ",", "\n", "\"100k\"", ",", "\n", "5", ",", "\n", "1024", ",", "\n", "{", "\n", "\"map\"", ":", "0.094794", ",", "\n", "\"ndcg\"", ":", "0.354145", ",", "\n", "\"precision\"", ":", "0.308165", ",", "\n", "\"recall\"", ":", "0.163034", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_lightgcn_deep_dive_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "yaml_file", ",", "\n", "data_path", ",", "\n", "size", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"lightgcn_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "\n", "MOVIELENS_DATA_SIZE", "=", "size", ",", "\n", "EPOCHS", "=", "epochs", ",", "\n", "BATCH_SIZE", "=", "batch_size", ",", "\n", "SEED", "=", "seed", ",", "\n", "yaml_file", "=", "yaml_file", ",", "\n", "user_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_embeddings\"", ")", ",", "\n", "item_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_embeddings\"", ")", ",", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_dkn_quickstart_integration": [[609, 627], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_dkn_quickstart_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"dkn_quickstart\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "epochs", "=", "5", ",", "batch_size", "=", "500", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"res\"", "]", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "0.5651", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"res\"", "]", "[", "\"mean_mrr\"", "]", "==", "pytest", ".", "approx", "(", "0.1639", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"res\"", "]", "[", "\"ndcg@5\"", "]", "==", "pytest", ".", "approx", "(", "0.1735", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"res\"", "]", "[", "\"ndcg@10\"", "]", "==", "pytest", ".", "approx", "(", "0.2301", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_cornac_bivae_integration": [[629, 654], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\"1m\"", ",", "dict", "(", "map", "=", "0.081794", ",", "ndcg", "=", "0.400983", ",", "precision", "=", "0.367997", ",", "recall", "=", "0.138352", ")", ")", ",", "\n", "# 10m works but takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_cornac_bivae_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"cornac_bivae_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_sasrec_quickstart_integration": [[656, 712], ["pytest.mark.parametrize", "print", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "os.path.join", "os.path.join", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"data_dir, num_epochs, batch_size, model_name, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"recsys_data\"", ",", "\"RecSys\"", ",", "\"SASRec-tf2\"", ",", "\"data\"", ")", ",", "\n", "1", ",", "\n", "128", ",", "\n", "\"sasrec\"", ",", "\n", "{", "\"ndcg@10\"", ":", "0.2626", ",", "\"Hit@10\"", ":", "0.4244", "}", ",", "\n", "42", ",", "\n", ")", ",", "\n", "(", "\n", "os", ".", "path", ".", "join", "(", "\"tests\"", ",", "\"recsys_data\"", ",", "\"RecSys\"", ",", "\"SASRec-tf2\"", ",", "\"data\"", ")", ",", "\n", "1", ",", "\n", "128", ",", "\n", "\"ssept\"", ",", "\n", "{", "\"ndcg@10\"", ":", "0.2626", ",", "\"Hit@10\"", ":", "0.4244", "}", ",", "\n", "42", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_sasrec_quickstart_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "data_dir", ",", "\n", "num_epochs", ",", "\n", "batch_size", ",", "\n", "model_name", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"sasrec_quickstart\"", "]", "\n", "params", "=", "{", "\n", "\"data_dir\"", ":", "data_dir", ",", "\n", "\"num_epochs\"", ":", "num_epochs", ",", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"model_name\"", ":", "model_name", ",", "\n", "\"seed\"", ":", "seed", ",", "\n", "}", "\n", "\n", "print", "(", "\"Executing notebook ... \"", ")", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "params", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_sar_single_node_integration": [[18, 58], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.060579", ",", "\n", "\"ndcg\"", ":", "0.299245", ",", "\n", "\"precision\"", ":", "0.270116", ",", "\n", "\"recall\"", ":", "0.104350", ",", "\n", "}", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.098745", ",", "\n", "\"ndcg\"", ":", "0.319625", ",", "\n", "\"precision\"", ":", "0.275756", ",", "\n", "\"recall\"", ":", "0.154014", ",", "\n", "}", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_sar_single_node_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"sar_single_node\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_baseline_deep_dive_integration": [[60, 92], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.033914", ",", "\n", "\"ndcg\"", ":", "0.231570", ",", "\n", "\"precision\"", ":", "0.211923", ",", "\n", "\"recall\"", ":", "0.064663", ",", "\n", "}", ",", "\n", ")", ",", "\n", "# (\"10m\", {\"map\": , \"ndcg\": , \"precision\": , \"recall\": }), # OOM on test machine", "\n", "]", ",", "\n", ")", "\n", "def", "test_baseline_deep_dive_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"baseline_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_surprise_svd_integration": [[94, 130], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "dict", "(", "\n", "rmse", "=", "0.89", ",", "\n", "mae", "=", "0.70", ",", "\n", "rsquared", "=", "0.36", ",", "\n", "exp_var", "=", "0.36", ",", "\n", "map", "=", "0.011", ",", "\n", "ndcg", "=", "0.10", ",", "\n", "precision", "=", "0.093", ",", "\n", "recall", "=", "0.025", ",", "\n", ")", ",", "\n", ")", ",", "\n", "# 10m works but takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_surprise_svd_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"surprise_svd_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_vw_deep_dive_integration": [[132, 168], ["pytest.mark.parametrize", "pytest.mark.skip", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "dict", "(", "\n", "rmse", "=", "0.959885", ",", "\n", "mae", "=", "0.690133", ",", "\n", "rsquared", "=", "0.264014", ",", "\n", "exp_var", "=", "0.264417", ",", "\n", "map", "=", "0.004857", ",", "\n", "ndcg", "=", "0.055128", ",", "\n", "precision", "=", "0.061142", ",", "\n", "recall", "=", "0.017789", ",", "\n", ")", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"VW pip package has installation incompatibilities\"", ")", "\n", "def", "test_vw_deep_dive_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"vowpal_wabbit_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ",", "TOP_K", "=", "10", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_nni_tuning_svd": [[171, 187], ["pytest.mark.skip", "pm.execute_notebook", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"NNI pip package has installation incompatibilities\"", ")", "\n", "def", "test_nni_tuning_svd", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "tmp", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"nni_tuning_svd\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "MOVIELENS_DATA_SIZE", "=", "\"100k\"", ",", "\n", "SURPRISE_READER", "=", "\"ml-100k\"", ",", "\n", "TMP_DIR", "=", "tmp", ",", "\n", "MAX_TRIAL_NUM", "=", "1", ",", "\n", "NUM_EPOCHS", "=", "1", ",", "\n", "WAITING_TIME", "=", "20", ",", "\n", "MAX_RETRIES", "=", "50", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_wikidata_integration": [[191, 209], ["pytest.mark.skip", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"Wikidata API is unstable\"", ")", "\n", "def", "test_wikidata_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "tmp", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"wikidata_knowledge_graph\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "MOVIELENS_DATA_SIZE", "=", "\"100k\"", ",", "MOVIELENS_SAMPLE", "=", "True", ",", "MOVIELENS_SAMPLE_SIZE", "=", "5", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "# NOTE: The return number should be always 5, but sometimes we get less because wikidata is unstable", "\n", "assert", "results", "[", "\"length_result\"", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_cornac_bpr_integration": [[211, 235], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\"1m\"", ",", "dict", "(", "map", "=", "0.081390", ",", "ndcg", "=", "0.406627", ",", "precision", "=", "0.373228", ",", "recall", "=", "0.132444", ")", ")", ",", "\n", "# 10m works but takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_cornac_bpr_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"cornac_bpr_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_lightfm_integration": [[237, 269], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "dict", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"100k\"", ",", "\n", "10", ",", "\n", "dict", "(", "\n", "eval_precision", "=", "0.131601", ",", "\n", "eval_recall", "=", "0.038056", ",", "\n", "eval_precision2", "=", "0.145599", ",", "\n", "eval_recall2", "=", "0.051338", ",", "\n", ")", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_lightfm_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"lightfm_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ",", "NO_EPOCHS", "=", "epochs", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_geoimc_integration": [[271, 286], ["pytest.mark.parametrize", "pm.execute_notebook", "expected_values.items", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.ncf.dataset.DataFile.items", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "experimental", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"expected_values\"", ",", "\n", "[", "(", "{", "\"rmse\"", ":", "0.4969", ",", "\"mae\"", ":", "0.4761", "}", ")", "]", ",", "\n", ")", "\n", "def", "test_geoimc_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "expected_values", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"geoimc_quickstart\"", "]", "\n", "pm", ".", "execute_notebook", "(", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_xlearn_fm_integration": [[288, 303], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "experimental", "\n", "def", "test_xlearn_fm_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"xlearn_fm_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "LEARNING_RATE", "=", "0.2", ",", "EPOCH", "=", "10", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"auc_score\"", "]", "==", "pytest", ".", "approx", "(", "0.75", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_als_pyspark_integration": [[19, 42], ["pytest.mark.flaky", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["@", "pytest", ".", "mark", ".", "flaky", "(", "reruns", "=", "5", ",", "reruns_delay", "=", "2", ")", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_als_pyspark_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"als_pyspark\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "\"1m\"", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"map\"", "]", "==", "pytest", ".", "approx", "(", "0.00201", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"ndcg\"", "]", "==", "pytest", ".", "approx", "(", "0.02516", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"precision\"", "]", "==", "pytest", ".", "approx", "(", "0.03172", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"recall\"", "]", "==", "pytest", ".", "approx", "(", "0.009302", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"rmse\"", "]", "==", "pytest", ".", "approx", "(", "0.8621", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"mae\"", "]", "==", "pytest", ".", "approx", "(", "0.68023", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"exp_var\"", "]", "==", "pytest", ".", "approx", "(", "0.4094", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"rsquared\"", "]", "==", "pytest", ".", "approx", "(", "0.4038", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_mmlspark_lightgbm_criteo_integration": [[45, 63], ["pytest.mark.flaky", "pytest.mark.skip", "pytest.mark.skipif", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["", "@", "pytest", ".", "mark", ".", "flaky", "(", "reruns", "=", "5", ",", "reruns_delay", "=", "2", ")", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"It takes too long in the current test machine\"", ")", "\n", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"Not implemented on Windows\"", ")", "\n", "def", "test_mmlspark_lightgbm_criteo_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"mmlspark_lightgbm_criteo\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "DATA_SIZE", "=", "\"full\"", ",", "NUM_ITERATIONS", "=", "50", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "0.68895", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf_smoke": [[26, 45], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\n", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "10", ",", "\n", "{", "\n", "\"map\"", ":", "0.0255283", ",", "\n", "\"ndcg\"", ":", "0.15656", ",", "\n", "\"precision\"", ":", "0.145646", ",", "\n", "\"recall\"", ":", "0.0557367", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", ",", "\n", "# (\"10m\", 5, {\"map\": 0.024821, \"ndcg\": 0.153396, \"precision\": 0.143046, \"recall\": 0.056590})# takes too long", "\n", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf_deep_dive_smoke": [[47, 73], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", ",", "seed", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"ncf\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ",", "EPOCHS", "=", "epochs", ",", "BATCH_SIZE", "=", "512", ",", "SEED", "=", "seed", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, batch_size, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"100k\"", ",", "\n", "10", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_fastai_smoke": [[75, 98], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["{", "\n", "\"map\"", ":", "0.0435856", ",", "\n", "\"ndcg\"", ":", "0.37586", ",", "\n", "\"precision\"", ":", "0.169353", ",", "\n", "\"recall\"", ":", "0.0923963", ",", "\n", "\"map2\"", ":", "0.0510391", ",", "\n", "\"ndcg2\"", ":", "0.202186", ",", "\n", "\"precision2\"", ":", "0.179533", ",", "\n", "\"recall2\"", ":", "0.106434", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_ncf_deep_dive_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "size", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_xdeepfm_smoke": [[100, 125], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "\n", "MOVIELENS_DATA_SIZE", "=", "size", ",", "\n", "EPOCHS", "=", "epochs", ",", "\n", "BATCH_SIZE", "=", "batch_size", ",", "\n", "SEED", "=", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values\"", ",", "\n", "[", "\n", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_wide_deep_smoke": [[127, 154], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["10", ",", "\n", "{", "\n", "\"map\"", ":", "0.025739", ",", "\n", "\"ndcg\"", ":", "0.183417", ",", "\n", "\"precision\"", ":", "0.167246", ",", "\n", "\"recall\"", ":", "0.054307", ",", "\n", "\"rmse\"", ":", "0.881267", ",", "\n", "\"mae\"", ":", "0.700747", ",", "\n", "\"rsquared\"", ":", "0.379963", ",", "\n", "\"exp_var\"", ":", "0.382842", ",", "\n", "}", ",", "\n", ")", ",", "\n", "# (\"10m\", 5, ), # it gets an OOM on pred = learner.model.forward(u, m)", "\n", "]", ",", "\n", ")", "\n", "def", "test_fastai_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"fastai\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ",", "EPOCHS", "=", "epochs", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_naml_smoke": [[156, 175], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"syn_epochs, criteo_epochs, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "15", ",", "\n", "10", ",", "\n", "{", "\n", "\"res_syn\"", ":", "{", "\"auc\"", ":", "0.9716", ",", "\"logloss\"", ":", "0.699", "}", ",", "\n", "\"res_real\"", ":", "{", "\"auc\"", ":", "0.749", ",", "\"logloss\"", ":", "0.4926", "}", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_nrms_smoke": [[177, 196], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "syn_epochs", ",", "\n", "criteo_epochs", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"xdeepfm_quickstart\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "EPOCHS_FOR_SYNTHETIC_RUN", "=", "syn_epochs", ",", "\n", "EPOCHS_FOR_CRITEO_RUN", "=", "criteo_epochs", ",", "\n", "BATCH_SIZE_SYNTHETIC", "=", "1024", ",", "\n", "BATCH_SIZE_CRITEO", "=", "1024", ",", "\n", "RANDOM_SEED", "=", "seed", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_npa_smoke": [[198, 217], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "value", "[", "\"auc\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "key", "]", "[", "\"logloss\"", "]", "==", "pytest", ".", "approx", "(", "\n", "value", "[", "\"logloss\"", "]", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", "\n", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, steps, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "10000", ",", "\n", "{", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_lstur_smoke": [[219, 238], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\"mae\"", ":", "0.741425", ",", "\n", "\"rsquared\"", ":", "0.316534", ",", "\n", "\"exp_var\"", ":", "0.322202", ",", "\n", "\"ndcg_at_k\"", ":", "0.118114", ",", "\n", "\"map_at_k\"", ":", "0.0139213", ",", "\n", "\"precision_at_k\"", ":", "0.107087", ",", "\n", "\"recall_at_k\"", ":", "0.0328638", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_wide_deep_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "steps", ",", "expected_values", ",", "seed", ",", "tmp", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"wide_deep\"", "]", "\n", "\n", "params", "=", "{", "\n", "\"MOVIELENS_DATA_SIZE\"", ":", "size", ",", "\n", "\"STEPS\"", ":", "steps", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_cornac_bivae_smoke": [[240, 259], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\"MODEL_DIR\"", ":", "tmp", ",", "\n", "\"EXPORT_DIR_BASE\"", ":", "tmp", ",", "\n", "\"RATING_METRICS\"", ":", "[", "\"rmse\"", ",", "\"mae\"", ",", "\"rsquared\"", ",", "\"exp_var\"", "]", ",", "\n", "\"RANKING_METRICS\"", ":", "[", "\"ndcg_at_k\"", ",", "\"map_at_k\"", ",", "\"precision_at_k\"", ",", "\"recall_at_k\"", "]", ",", "\n", "\"RANDOM_SEED\"", ":", "seed", ",", "\n", "}", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "output_notebook", ",", "kernel_name", "=", "kernel_name", ",", "parameters", "=", "params", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_sar_single_node_smoke": [[17, 34], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.060579", ",", "\n", "\"ndcg\"", ":", "0.299245", ",", "\n", "\"precision\"", ":", "0.270116", ",", "\n", "\"recall\"", ":", "0.104350", ",", "\n", "}", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.098745", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_baseline_deep_dive_smoke": [[36, 57], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\"precision\"", ":", "0.275756", ",", "\n", "\"recall\"", ":", "0.154014", ",", "\n", "}", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_sar_single_node_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"sar_single_node\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_surprise_svd_smoke": [[59, 80], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["\n", "", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.033914", ",", "\n", "\"ndcg\"", ":", "0.231570", ",", "\n", "\"precision\"", ":", "0.211923", ",", "\n", "\"recall\"", ":", "0.064663", ",", "\n", "}", ",", "\n", ")", ",", "\n", "# (\"10m\", {\"map\": , \"ndcg\": , \"precision\": , \"recall\": }), # OOM on test machine", "\n", "]", ",", "\n", ")", "\n", "def", "test_baseline_deep_dive_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"baseline_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_vw_deep_dive_smoke": [[82, 104], ["pytest.mark.skip", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip", "home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "dict", "(", "\n", "rmse", "=", "0.89", ",", "\n", "mae", "=", "0.70", ",", "\n", "rsquared", "=", "0.36", ",", "\n", "exp_var", "=", "0.36", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_lightgbm_quickstart_smoke": [[106, 133], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["ndcg", "=", "0.10", ",", "\n", "precision", "=", "0.093", ",", "\n", "recall", "=", "0.025", ",", "\n", ")", ",", "\n", ")", ",", "\n", "# 10m works but takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_surprise_svd_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"surprise_svd_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_cornac_bpr_smoke": [[136, 153], ["pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["(", "\n", "\"1m\"", ",", "\n", "dict", "(", "\n", "rmse", "=", "0.959885", ",", "\n", "mae", "=", "0.690133", ",", "\n", "rsquared", "=", "0.264014", ",", "\n", "exp_var", "=", "0.264417", ",", "\n", "map", "=", "0.004857", ",", "\n", "ndcg", "=", "0.055128", ",", "\n", "precision", "=", "0.061142", ",", "\n", "recall", "=", "0.017789", ",", "\n", ")", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"VW pip package has installation incompatibilities\"", ")", "\n", "def", "test_vw_deep_dive_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_mind_utils": [[155, 164], ["pm.execute_notebook", "dict"], "function", ["None"], ["    ", "notebook_path", "=", "notebooks", "[", "\"vowpal_wabbit_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "MOVIELENS_DATA_SIZE", "=", "size", ",", "TOP_K", "=", "10", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_als_pyspark_smoke": [[19, 43], ["pytest.mark.flaky", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["@", "pytest", ".", "mark", ".", "flaky", "(", "reruns", "=", "5", ",", "reruns_delay", "=", "2", ")", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_als_pyspark_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"als_pyspark\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "\"1m\"", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"map\"", "]", "==", "pytest", ".", "approx", "(", "0.00201", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"ndcg\"", "]", "==", "pytest", ".", "approx", "(", "0.02516", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"precision\"", "]", "==", "pytest", ".", "approx", "(", "0.03172", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"recall\"", "]", "==", "pytest", ".", "approx", "(", "0.009302", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"rmse\"", "]", "==", "pytest", ".", "approx", "(", "0.8621", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"mae\"", "]", "==", "pytest", ".", "approx", "(", "0.68023", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"exp_var\"", "]", "==", "pytest", ".", "approx", "(", "0.4094", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"rsquared\"", "]", "==", "pytest", ".", "approx", "(", "0.4038", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_mmlspark_lightgbm_criteo_smoke": [[46, 63], ["pytest.mark.flaky", "pytest.mark.skipif", "pm.execute_notebook", "sb.read_notebook().scraps.dataframe.set_index", "pytest.approx", "dict", "sb.read_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.sar.sar_singlenode.SARSingleNode.set_index"], ["@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"It takes too long in the current test machine\"", ")", "\n", "@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"Not implemented on Windows\"", ")", "\n", "def", "test_mmlspark_lightgbm_criteo_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"mmlspark_lightgbm_criteo\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "DATA_SIZE", "=", "\"full\"", ",", "NUM_ITERATIONS", "=", "50", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "0.68895", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_fastai": [[21, 30], ["pm.execute_notebook", "dict"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_gpu_vm", "(", ")", ":", "\n", "    ", "assert", "get_number_gpus", "(", ")", ">=", "1", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values, seed\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf": [[33, 43], ["pm.execute_notebook", "dict"], "function", ["None"], ["\"1m\"", ",", "\n", "10", ",", "\n", "{", "\n", "\"map\"", ":", "0.0255283", ",", "\n", "\"ndcg\"", ":", "0.15656", ",", "\n", "\"precision\"", ":", "0.145646", ",", "\n", "\"recall\"", ":", "0.0557367", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", ",", "\n", "# (\"10m\", 5, {\"map\": 0.024821, \"ndcg\": 0.153396, \"precision\": 0.143046, \"recall\": 0.056590})# takes too long", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_ncf_deep_dive": [[47, 57], ["pm.execute_notebook", "dict"], "function", ["None"], ["notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "epochs", ",", "expected_values", ",", "seed", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"ncf\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ",", "EPOCHS", "=", "epochs", ",", "BATCH_SIZE", "=", "512", ",", "SEED", "=", "seed", "\n", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_xdeepfm": [[61, 74], ["pm.execute_notebook", "dict"], "function", ["None"], ["\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, batch_size, expected_values, seed\"", ",", "\n", "[", "\n", "(", "\n", "\"100k\"", ",", "\n", "10", ",", "\n", "512", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_wide_deep": [[78, 114], ["os.path.join", "os.mkdir", "pm.execute_notebook", "os.path.join", "os.mkdir", "pm.execute_notebook"], "function", ["None"], ["\"precision\"", ":", "0.169353", ",", "\n", "\"recall\"", ":", "0.0923963", ",", "\n", "\"map2\"", ":", "0.0510391", ",", "\n", "\"ndcg2\"", ":", "0.202186", ",", "\n", "\"precision2\"", ":", "0.179533", ",", "\n", "\"recall2\"", ":", "0.106434", ",", "\n", "}", ",", "\n", "42", ",", "\n", ")", "\n", "]", ",", "\n", ")", "\n", "def", "test_ncf_deep_dive_integration", "(", "\n", "notebooks", ",", "\n", "output_notebook", ",", "\n", "kernel_name", ",", "\n", "size", ",", "\n", "epochs", ",", "\n", "batch_size", ",", "\n", "expected_values", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"ncf_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "\n", "TOP_K", "=", "10", ",", "\n", "MOVIELENS_DATA_SIZE", "=", "size", ",", "\n", "EPOCHS", "=", "epochs", ",", "\n", "BATCH_SIZE", "=", "batch_size", ",", "\n", "SEED", "=", "seed", ",", "\n", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_gpu.test_dkn_quickstart": [[117, 126], ["pm.execute_notebook", "dict"], "function", ["None"], ["        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, epochs, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_template_runs": [[18, 32], ["pm.execute_notebook", "sb.read_notebook", "dict"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.060579", ",", "\n", "\"ndcg\"", ":", "0.299245", ",", "\n", "\"precision\"", ":", "0.270116", ",", "\n", "\"recall\"", ":", "0.104350", ",", "\n", "}", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_sar_single_node_runs": [[34, 38], ["pm.execute_notebook"], "function", ["None"], ["\"map\"", ":", "0.098745", ",", "\n", "\"ndcg\"", ":", "0.319625", ",", "\n", "\"precision\"", ":", "0.275756", ",", "\n", "\"recall\"", ":", "0.154014", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_sar_deep_dive_runs": [[40, 44], ["pm.execute_notebook"], "function", ["None"], ["]", ",", "\n", ")", "\n", "def", "test_sar_single_node_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_baseline_deep_dive_runs": [[46, 50], ["pm.execute_notebook"], "function", ["None"], ["pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_surprise_deep_dive_runs": [[52, 60], ["pm.execute_notebook", "dict"], "function", ["None"], ["results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "integration", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_vw_deep_dive_runs": [[63, 68], ["pytest.mark.skip", "pm.execute_notebook"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip"], ["[", "\n", "(", "\n", "\"1m\"", ",", "\n", "{", "\n", "\"map\"", ":", "0.033914", ",", "\n", "\"ndcg\"", ":", "0.231570", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_lightgbm": [[70, 84], ["pm.execute_notebook", "dict"], "function", ["None"], ["\"recall\"", ":", "0.064663", ",", "\n", "}", ",", "\n", ")", ",", "\n", "# (\"10m\", {\"map\": , \"ndcg\": , \"precision\": , \"recall\": }), # OOM on test machine", "\n", "]", ",", "\n", ")", "\n", "def", "test_baseline_deep_dive_integration", "(", "\n", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "size", ",", "expected_values", "\n", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"baseline_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "size", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_wikidata_runs": [[88, 101], ["pytest.mark.skip", "pm.execute_notebook", "dict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.source.conf.skip"], ["]", "\n", "\n", "for", "key", ",", "value", "in", "expected_values", ".", "items", "(", ")", ":", "\n", "        ", "assert", "results", "[", "key", "]", "==", "pytest", ".", "approx", "(", "value", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, expected_values\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "dict", "(", "\n", "rmse", "=", "0.89", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_rlrmc_quickstart_runs": [[105, 114], ["pm.execute_notebook", "dict"], "function", ["None"], ["map", "=", "0.011", ",", "\n", "ndcg", "=", "0.10", ",", "\n", "precision", "=", "0.093", ",", "\n", "recall", "=", "0.025", ",", "\n", ")", ",", "\n", ")", ",", "\n", "# 10m works but takes too long", "\n", "]", ",", "\n", ")", "\n", "def", "test_surprise_svd_integration", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_python.test_cornac_deep_dive_runs": [[117, 121], ["pm.execute_notebook"], "function", ["None"], ["    ", "notebook_path", "=", "notebooks", "[", "\"surprise_svd_deep_dive\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_als_pyspark_runs": [[20, 37], ["pytest.mark.flaky", "pytest.mark.skipif", "pm.execute_notebook", "dict"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_als_pyspark_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"als_pyspark\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "TOP_K", "=", "10", ",", "MOVIELENS_DATA_SIZE", "=", "\"1m\"", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"map\"", "]", "==", "pytest", ".", "approx", "(", "0.00201", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"ndcg\"", "]", "==", "pytest", ".", "approx", "(", "0.02516", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"precision\"", "]", "==", "pytest", ".", "approx", "(", "0.03172", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "assert", "results", "[", "\"recall\"", "]", "==", "pytest", ".", "approx", "(", "0.009302", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_data_split_runs": [[41, 46], ["pm.execute_notebook"], "function", ["None"], ["assert", "results", "[", "\"rsquared\"", "]", "==", "pytest", ".", "approx", "(", "0.4038", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "\n", "\n", "# This is a flaky test that can fail unexpectedly", "\n", "", "@", "pytest", ".", "mark", ".", "flaky", "(", "reruns", "=", "5", ",", "reruns_delay", "=", "2", ")", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_als_deep_dive_runs": [[49, 66], ["pytest.mark.flaky", "pytest.mark.skipif", "pm.execute_notebook", "dict"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "skipif", "(", "sys", ".", "platform", "==", "\"win32\"", ",", "reason", "=", "\"Not implemented on Windows\"", ")", "\n", "def", "test_mmlspark_lightgbm_criteo_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"mmlspark_lightgbm_criteo\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "DATA_SIZE", "=", "\"full\"", ",", "NUM_ITERATIONS", "=", "50", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"auc\"", "]", "==", "pytest", ".", "approx", "(", "0.68895", ",", "rel", "=", "TOL", ",", "abs", "=", "ABS_TOL", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_evaluation_runs": [[71, 80], ["pytest.mark.flaky", "pytest.mark.skipif", "pm.execute_notebook"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_evaluation_diversity_runs": [[83, 98], ["pytest.mark.flaky", "pm.execute_notebook", "dict"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_spark_tuning": [[103, 122], ["pytest.mark.flaky", "pytest.mark.skipif", "pm.execute_notebook", "dict"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.examples.test_notebooks_pyspark.test_mmlspark_lightgbm_criteo_runs": [[126, 136], ["pytest.mark.skipif", "pm.execute_notebook", "dict"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.setup_workspace": [[52, 101], ["logger.debug", "logger.debug", "logger.debug", "logger.debug", "azureml.core.Workspace.get", "logger.debug", "azureml.core.Workspace.create"], "function", ["None"], ["def", "setup_workspace", "(", "\n", "workspace_name", ",", "subscription_id", ",", "resource_group", ",", "cli_auth", ",", "location", "\n", ")", ":", "\n", "    ", "\"\"\"\n    This sets up an Azure Workspace.\n    An existing Azure Workspace is used or a new one is created if needed for\n    the pytest run.\n\n    Args:\n        workspace_name  (str): Centralized location on Azure to work\n                               with all the artifacts used by AzureML\n                               service\n        subscription_id (str): the Azure subscription id\n        resource_group  (str): Azure Resource Groups are logical collections of\n                         assets associated with a project. Resource groups\n                         make it easy to track or delete all resources\n                         associated with a project by tracking or deleting\n                         the Resource group.\n        cli_auth         Azure authentication\n        location        (str): workspace reference\n\n    Returns:\n        ws: workspace reference\n    \"\"\"", "\n", "logger", ".", "debug", "(", "\"setup: workspace_name is {}\"", ".", "format", "(", "workspace_name", ")", ")", "\n", "logger", ".", "debug", "(", "\"setup: resource_group is {}\"", ".", "format", "(", "resource_group", ")", ")", "\n", "logger", ".", "debug", "(", "\"setup: subid is {}\"", ".", "format", "(", "subscription_id", ")", ")", "\n", "logger", ".", "debug", "(", "\"setup: location is {}\"", ".", "format", "(", "location", ")", ")", "\n", "\n", "try", ":", "\n", "# use existing workspace if there is one", "\n", "        ", "ws", "=", "Workspace", ".", "get", "(", "\n", "name", "=", "workspace_name", ",", "\n", "subscription_id", "=", "subscription_id", ",", "\n", "resource_group", "=", "resource_group", ",", "\n", "auth", "=", "cli_auth", ",", "\n", ")", "\n", "", "except", "WorkspaceException", ":", "\n", "# this call might take a minute or two.", "\n", "        ", "logger", ".", "debug", "(", "\"Creating new workspace\"", ")", "\n", "ws", "=", "Workspace", ".", "create", "(", "\n", "name", "=", "workspace_name", ",", "\n", "subscription_id", "=", "subscription_id", ",", "\n", "resource_group", "=", "resource_group", ",", "\n", "# create_resource_group=True,", "\n", "location", "=", "location", ",", "\n", "auth", "=", "cli_auth", ",", "\n", ")", "\n", "", "return", "ws", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.setup_persistent_compute_target": [[103, 140], ["logger.debug", "ComputeTarget.create.wait_for_completion", "azureml.core.compute.ComputeTarget", "logger.debug", "logger.debug", "azureml.core.compute.AmlCompute.provisioning_configuration", "azureml.core.compute.ComputeTarget.create"], "function", ["None"], ["", "def", "setup_persistent_compute_target", "(", "workspace", ",", "cluster_name", ",", "vm_size", ",", "max_nodes", ")", ":", "\n", "    ", "\"\"\"\n    Set up a persistent compute target on AzureML.\n    A persistent compute target runs noticeably faster than a\n    regular compute target for subsequent runs.  The benefit\n    is that AzureML manages turning the compute on/off as needed for\n    each job so the user does not need to do this.\n\n    Args:\n        workspace    (str): Centralized location on Azure to work with\n                         all the\n                                artifacts used by AzureML service\n        cluster_name (str): the Azure cluster for this run. It can\n                            already exist or it will be created.\n        vm_size      (str): Azure VM size, like STANDARD_D3_V2\n        max_nodes    (int): Number of VMs, max_nodes=4 will\n                            autoscale up to 4 VMs\n    Returns:\n        cpu_cluster : cluster reference\n    \"\"\"", "\n", "# setting vmsize and num nodes creates a persistent AzureML", "\n", "# compute resource", "\n", "\n", "logger", ".", "debug", "(", "\"setup: cluster_name {}\"", ".", "format", "(", "cluster_name", ")", ")", "\n", "# https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets", "\n", "\n", "try", ":", "\n", "        ", "cpu_cluster", "=", "ComputeTarget", "(", "workspace", "=", "workspace", ",", "name", "=", "cluster_name", ")", "\n", "logger", ".", "debug", "(", "\"setup: Found existing cluster, use it.\"", ")", "\n", "", "except", "ComputeTargetException", ":", "\n", "        ", "logger", ".", "debug", "(", "\"setup: create cluster\"", ")", "\n", "compute_config", "=", "AmlCompute", ".", "provisioning_configuration", "(", "\n", "vm_size", "=", "vm_size", ",", "max_nodes", "=", "max_nodes", "\n", ")", "\n", "cpu_cluster", "=", "ComputeTarget", ".", "create", "(", "workspace", ",", "cluster_name", ",", "compute_config", ")", "\n", "", "cpu_cluster", ".", "wait_for_completion", "(", "show_output", "=", "True", ")", "\n", "return", "cpu_cluster", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.create_run_config": [[142, 216], ["azureml.core.runconfig.RunConfiguration", "azureml.core.runconfig.RunConfiguration.environment.add_private_pip_wheel", "azureml.core.conda_dependencies.CondaDependencies", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_channel", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package", "azureml.core.conda_dependencies.CondaDependencies.add_channel", "azureml.core.conda_dependencies.CondaDependencies.add_conda_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package", "azureml.core.conda_dependencies.CondaDependencies.add_pip_package"], "function", ["None"], ["", "def", "create_run_config", "(", "cpu_cluster", ",", "\n", "docker_proc_type", ",", "\n", "workspace", ",", "\n", "add_gpu_dependencies", ",", "\n", "add_spark_dependencies", ",", "\n", "conda_pkg_cudatoolkit", ",", "\n", "conda_pkg_cudnn", ",", "\n", "conda_pkg_jdk", ",", "\n", "conda_pkg_python", ",", "\n", "reco_wheel_path", ")", ":", "\n", "    ", "\"\"\"\n    AzureML requires the run environment to be setup prior to submission.\n    This configures a docker persistent compute.  Even though\n    it is called Persistent compute, AzureML handles startup/shutdown\n    of the compute environment.\n\n    Args:\n            cpu_cluster      (str)          : Names the cluster for the test\n                                                In the case of unit tests, any of\n                                                the following:\n                                                - Reco_cpu_test\n                                                - Reco_gpu_test\n            docker_proc_type (str)          : processor type, cpu or gpu\n            workspace                       : workspace reference\n            add_gpu_dependencies (bool)     : True if gpu packages should be\n                                        added to the conda environment, else False\n            add_spark_dependencies (bool)   : True if PySpark packages should be\n                                        added to the conda environment, else False\n    Return:\n          run_azuremlcompute : AzureML run config\n    \"\"\"", "\n", "\n", "run_azuremlcompute", "=", "RunConfiguration", "(", ")", "\n", "run_azuremlcompute", ".", "target", "=", "cpu_cluster", "\n", "run_azuremlcompute", ".", "environment", ".", "docker", ".", "enabled", "=", "True", "\n", "run_azuremlcompute", ".", "environment", ".", "docker", ".", "base_image", "=", "docker_proc_type", "\n", "\n", "# Use conda_dependencies.yml to create a conda environment in", "\n", "# the Docker image for execution", "\n", "# False means the user will provide a conda file for setup", "\n", "# True means the user will manually configure the environment", "\n", "run_azuremlcompute", ".", "environment", ".", "python", ".", "user_managed_dependencies", "=", "False", "\n", "\n", "# install local version of recommenders on AzureML compute using .whl file", "\n", "whl_url", "=", "run_azuremlcompute", ".", "environment", ".", "add_private_pip_wheel", "(", "\n", "workspace", "=", "workspace", ",", "\n", "file_path", "=", "reco_wheel_path", ",", "\n", "exist_ok", "=", "True", ",", "\n", ")", "\n", "conda_dep", "=", "CondaDependencies", "(", ")", "\n", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_python", ")", "\n", "conda_dep", ".", "add_pip_package", "(", "whl_url", ")", "\n", "conda_dep", ".", "add_pip_package", "(", "\"pymanopt@https://github.com/pymanopt/pymanopt/archive/fb36a272cdeecb21992cfd9271eb82baafeb316d.zip\"", ")", "\n", "\n", "# install extra dependencies", "\n", "if", "add_gpu_dependencies", "and", "add_spark_dependencies", ":", "\n", "        ", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_cudatoolkit", ")", "\n", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_cudnn", ")", "\n", "conda_dep", ".", "add_channel", "(", "\"conda-forge\"", ")", "\n", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_jdk", ")", "\n", "conda_dep", ".", "add_pip_package", "(", "\"recommenders[dev,examples,spark,gpu]\"", ")", "\n", "", "elif", "add_gpu_dependencies", ":", "\n", "        ", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_cudatoolkit", ")", "\n", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_cudnn", ")", "\n", "conda_dep", ".", "add_pip_package", "(", "\"recommenders[dev,examples,gpu]\"", ")", "\n", "", "elif", "add_spark_dependencies", ":", "\n", "        ", "conda_dep", ".", "add_channel", "(", "\"conda-forge\"", ")", "\n", "conda_dep", ".", "add_conda_package", "(", "conda_pkg_jdk", ")", "\n", "conda_dep", ".", "add_pip_package", "(", "\"recommenders[dev,examples,spark]\"", ")", "\n", "", "else", ":", "\n", "        ", "conda_dep", ".", "add_pip_package", "(", "\"recommenders[dev,examples]\"", ")", "\n", "\n", "", "run_azuremlcompute", ".", "environment", ".", "python", ".", "conda_dependencies", "=", "conda_dep", "\n", "return", "run_azuremlcompute", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.create_experiment": [[218, 234], ["logger.debug", "azureml.core.Experiment"], "function", ["None"], ["", "def", "create_experiment", "(", "workspace", ",", "experiment_name", ")", ":", "\n", "    ", "\"\"\"\n    AzureML requires an experiment as a container of trials.\n    This will either create a new experiment or use an\n    existing one.\n\n    Args:\n        workspace (str) : name of AzureML workspace\n        experiment_name (str) : AzureML experiment name\n    Return:\n        exp - AzureML experiment\n    \"\"\"", "\n", "\n", "logger", ".", "debug", "(", "\"create: experiment_name {}\"", ".", "format", "(", "experiment_name", ")", ")", "\n", "exp", "=", "Experiment", "(", "workspace", "=", "workspace", ",", "name", "=", "experiment_name", ")", "\n", "return", "exp", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.submit_experiment_to_azureml": [[236, 281], ["azureml.core.script_run_config.ScriptRunConfig", "experiment.submit", "experiment.submit.wait_for_completion", "logger.debug"], "function", ["None"], ["", "def", "submit_experiment_to_azureml", "(", "\n", "test", ",", "run_config", ",", "experiment", ",", "test_group", ",", "test_kind", "\n", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Submitting the experiment to AzureML actually runs the script.\n\n    Args:\n        test         (str) - pytest script, folder/test\n                             such as ./tests/ci/run_pytest.py\n        test_folder  (str) - folder where tests to run are stored,\n                             like ./tests/unit\n        test_markers (str) - test markers used by pytest\n                             \"not notebooks and not spark and not gpu\"\n        run_config - environment configuration\n        experiment - instance of an Experiment, a collection of\n                     trials where each trial is a run.\n    Return:\n          run : AzureML run or trial\n    \"\"\"", "\n", "\n", "project_folder", "=", "\".\"", "\n", "\n", "script_run_config", "=", "ScriptRunConfig", "(", "\n", "source_directory", "=", "project_folder", ",", "\n", "script", "=", "test", ",", "\n", "run_config", "=", "run_config", ",", "\n", "arguments", "=", "[", "\n", "\"--testgroup\"", ",", "\n", "test_group", ",", "\n", "\"--testkind\"", ",", "\n", "test_kind", ",", "\n", "]", ",", "\n", "# docker_runtime_config=dc", "\n", ")", "\n", "run", "=", "experiment", ".", "submit", "(", "script_run_config", ")", "\n", "# waits only for configuration to complete", "\n", "run", ".", "wait_for_completion", "(", "show_output", "=", "True", ",", "wait_post_processing", "=", "True", ")", "\n", "\n", "# test logs can also be found on azure", "\n", "# go to azure portal to see log in azure ws and look for experiment name", "\n", "# and look for individual run", "\n", "logger", ".", "debug", "(", "\"files {}\"", ".", "format", "(", "run", ".", "get_file_names", ")", ")", "\n", "\n", "return", "run", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.azureml_tests.submit_groupwise_azureml_pytest.create_arg_parser": [[283, 431], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "create_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Many of the argument defaults are used as arg_parser makes it easy to\n    use defaults. The user has many options they can select.\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Process some inputs\"", ")", "\n", "# script to run pytest", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"./tests/ci/azureml_tests/run_groupwise_pytest.py\"", ",", "\n", "help", "=", "\"location of script to run pytest\"", ",", "\n", ")", "\n", "# max num nodes in Azure cluster", "\n", "parser", ".", "add_argument", "(", "\n", "\"--maxnodes\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "4", ",", "\n", "help", "=", "\"specify the maximum number of nodes for the run\"", ",", "\n", ")", "\n", "# Test group", "\n", "parser", ".", "add_argument", "(", "\n", "\"--testgroup\"", ",", "action", "=", "\"store\"", ",", "default", "=", "\"group_criteo\"", ",", "help", "=", "\"Test Group\"", "\n", ")", "\n", "# Azure resource group", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rg\"", ",", "action", "=", "\"store\"", ",", "default", "=", "\"recommender\"", ",", "help", "=", "\"Azure Resource Group\"", "\n", ")", "\n", "# AzureML workspace Name", "\n", "parser", ".", "add_argument", "(", "\n", "\"--wsname\"", ",", "action", "=", "\"store\"", ",", "default", "=", "\"RecoWS\"", ",", "help", "=", "\"AzureML workspace name\"", "\n", ")", "\n", "# AzureML clustername", "\n", "parser", ".", "add_argument", "(", "\n", "\"--clustername\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"azuremlcompute\"", ",", "\n", "help", "=", "\"Set name of Azure cluster\"", ",", "\n", ")", "\n", "# Azure VM size", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vmsize\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"STANDARD_D3_V2\"", ",", "\n", "help", "=", "\"Set the size of the VM either STANDARD_D3_V2\"", ",", "\n", ")", "\n", "# cpu or gpu", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dockerproc\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"cpu\"", ",", "\n", "help", "=", "\"Base image used in docker container\"", ",", "\n", ")", "\n", "# Azure subscription id, when used in a pipeline, it is stored in keyvault", "\n", "parser", ".", "add_argument", "(", "\n", "\"--subid\"", ",", "action", "=", "\"store\"", ",", "default", "=", "\"123456\"", ",", "help", "=", "\"Azure Subscription ID\"", "\n", ")", "\n", "# reco wheel is created in the GitHub action workflow.", "\n", "# Not recommended to change this.", "\n", "parser", ".", "add_argument", "(", "\n", "\"--wheelfile\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"./dist/recommenders-1.0.0-py3-none-any.whl\"", ",", "\n", "help", "=", "\"recommenders whl file path\"", ",", "\n", ")", "\n", "# AzureML experiment name", "\n", "parser", ".", "add_argument", "(", "\n", "\"--expname\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"persistentAzureML\"", ",", "\n", "help", "=", "\"experiment name on Azure\"", ",", "\n", ")", "\n", "# Azure datacenter location", "\n", "parser", ".", "add_argument", "(", "\"--location\"", ",", "default", "=", "\"EastUS\"", ",", "help", "=", "\"Azure location\"", ")", "\n", "# github repo, stored in AzureML experiment for info purposes", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reponame\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"--reponame MyGithubRepo\"", ",", "\n", "help", "=", "\"GitHub repo being tested\"", ",", "\n", ")", "\n", "# github branch, stored in AzureML experiment for info purposes", "\n", "parser", ".", "add_argument", "(", "\n", "\"--branch\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"--branch MyGithubBranch\"", ",", "\n", "help", "=", "\" Identify the branch test test is run on\"", ",", "\n", ")", "\n", "# github pull request, stored in AzureML experiment for info purposes", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pr\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"--pr PRTestRun\"", ",", "\n", "help", "=", "\"If a pr triggered the test, list it here\"", ",", "\n", ")", "\n", "# flag to indicate whether gpu dependencies should be included in conda env", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add_gpu_dependencies\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"include packages for GPU support\"", "\n", ")", "\n", "# flag to indicate whether pyspark dependencies should be included in conda env    ", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add_spark_dependencies\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"include packages for PySpark support\"", "\n", ")", "\n", "# path where test logs should be downloaded", "\n", "parser", ".", "add_argument", "(", "\n", "\"--testlogs\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"test_logs.log\"", ",", "\n", "help", "=", "\"Test logs will be downloaded to this path\"", ",", "\n", ")", "\n", "# conda package name for cudatoolkit", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conda_pkg_cudatoolkit\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"cudatoolkit=11.2\"", ",", "\n", "help", "=", "\"conda package name for cudatoolkit\"", ",", "\n", ")", "\n", "# conda package name for cudnn", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conda_pkg_cudnn\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"cudnn=8.1\"", ",", "\n", "help", "=", "\"conda package name for cudnn\"", ",", "\n", ")", "\n", "# conda package name for jdk", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conda_pkg_jdk\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"openjdk=8\"", ",", "\n", "help", "=", "\"conda package name for jdk\"", ",", "\n", ")", "\n", "# conda package name for python", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conda_pkg_python\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"python=3.7\"", ",", "\n", "help", "=", "\"conda package name for jdk\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--testkind\"", ",", "\n", "action", "=", "\"store\"", ",", "\n", "default", "=", "\"unit\"", ",", "\n", "help", "=", "\"Test kind - nightly or unit\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_mind.test_mind_url": [[10, 65], ["pytest.mark.parametrize", "requests.head"], "function", ["None"], ["\n", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_download_mind", "(", "tmp_path", ")", ":", "\n", "    ", "train_path", ",", "valid_path", "=", "download_mind", "(", "size", "=", "\"large\"", ",", "dest_path", "=", "tmp_path", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "train_path", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "530196631", "\n", "statinfo", "=", "os", ".", "stat", "(", "valid_path", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "103456245", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_extract_mind", "(", "tmp", ")", ":", "\n", "    ", "train_zip", ",", "valid_zip", "=", "download_mind", "(", "size", "=", "\"large\"", ",", "dest_path", "=", "tmp", ")", "\n", "train_path", ",", "valid_path", "=", "extract_mind", "(", "train_zip", ",", "valid_zip", ")", "\n", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"behaviors.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1373844151", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"entity_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "40305151", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"news.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "84881998", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "train_path", ",", "\"relation_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1044588", "\n", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"behaviors.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "230662527", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"entity_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "31958202", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"news.tsv\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "59055351", "\n", "statinfo", "=", "os", ".", "stat", "(", "os", ".", "path", ".", "join", "(", "valid_path", ",", "\"relation_embedding.vec\"", ")", ")", "\n", "assert", "statinfo", ".", "st_size", "==", "1044588", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "notebooks", "\n", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_mind_utils_integration", "(", "notebooks", ",", "output_notebook", ",", "kernel_name", ",", "tmp", ")", ":", "\n", "    ", "notebook_path", "=", "notebooks", "[", "\"mind_utils\"", "]", "\n", "pm", ".", "execute_notebook", "(", "\n", "notebook_path", ",", "\n", "output_notebook", ",", "\n", "kernel_name", "=", "kernel_name", ",", "\n", "parameters", "=", "dict", "(", "mind_type", "=", "\"small\"", ",", "word_embedding_dim", "=", "300", ")", ",", "\n", ")", "\n", "results", "=", "sb", ".", "read_notebook", "(", "output_notebook", ")", ".", "scraps", ".", "dataframe", ".", "set_index", "(", "\"name\"", ")", "[", "\n", "\"data\"", "\n", "]", "\n", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"vert_num\"", "]", "==", "17", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"subvert_num\"", "]", "==", "17", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"word_num\"", "]", "==", "23404", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"word_num_all\"", "]", "==", "41074", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"embedding_exist_num\"", "]", "==", "22408", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"embedding_exist_num_all\"", "]", "==", "37634", "\n", "assert", "results", "[", "\"utils_state\"", "]", "[", "\"uid2index\"", "]", "==", "5000", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_mind.test_extract_mind": [[67, 109], ["pytest.mark.parametrize", "recommenders.datasets.mind.download_mind", "recommenders.datasets.mind.extract_mind", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.stat", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.download_mind", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.mind.extract_mind"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_criteo.test_criteo_load_pandas_df": [[10, 16], ["recommenders.datasets.criteo.load_pandas_df", "criteo.load_pandas_df.loc[].equals", "pandas.Series"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["def", "test_criteo_load_pandas_df", "(", "criteo_first_row", ")", ":", "\n", "    ", "df", "=", "criteo", ".", "load_pandas_df", "(", "size", "=", "\"full\"", ")", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "45840617", "\n", "assert", "df", ".", "shape", "[", "1", "]", "==", "40", "\n", "assert", "df", ".", "loc", "[", "0", "]", ".", "equals", "(", "pd", ".", "Series", "(", "criteo_first_row", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_criteo.test_criteo_load_spark_df": [[18, 26], ["recommenders.datasets.criteo.load_spark_df", "[].asDict", "criteo.load_spark_df.count", "len", "criteo.load_spark_df.limit().collect", "criteo.load_spark_df.limit"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], ["@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_criteo_load_spark_df", "(", "spark", ",", "criteo_first_row", ")", ":", "\n", "    ", "df", "=", "criteo", ".", "load_spark_df", "(", "spark", ",", "size", "=", "\"full\"", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "45840617", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "40", "\n", "first_row", "=", "df", ".", "limit", "(", "1", ")", ".", "collect", "(", ")", "[", "0", "]", ".", "asDict", "(", ")", "\n", "assert", "first_row", "==", "criteo_first_row", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_criteo.test_download_criteo": [[28, 33], ["recommenders.datasets.criteo.download_criteo", "os.stat"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.download_criteo"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_criteo.test_extract_criteo": [[35, 41], ["recommenders.datasets.criteo.download_criteo", "recommenders.datasets.criteo.extract_criteo", "os.stat"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.download_criteo", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.criteo.extract_criteo"], []], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_movielens.test_load_pandas_df": [[25, 92], ["pytest.mark.parametrize", "recommenders.datasets.movielens.load_pandas_df", "recommenders.datasets.movielens.load_pandas_df", "len", "len", "len", "len", "pytest.warns", "recommenders.datasets.movielens.load_pandas_df", "len", "len", "os.listdir", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_samples, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "1000209", ",", "\n", "3883", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Animation|Children's|Comedy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10000054", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "20000263", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_pandas_df", "(", "\n", "size", ",", "\n", "num_samples", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test MovieLens dataset load as pd.DataFrame\"\"\"", "\n", "# Test if correct data are loaded", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", "]", "\n", "df", "=", "load_pandas_df", "(", "size", "=", "size", ",", "local_cache_path", "=", "tmp", ",", "header", "=", "header", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "len", "(", "header", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "\n", "# Test title, genres, and released year load", "\n", "header", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ",", "\"e\"", "]", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_pandas_df", "(", "\n", "size", "=", "size", ",", "\n", "header", "=", "header", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "title_col", "=", "\"Title\"", ",", "\n", "genres_col", "=", "\"Genres\"", ",", "\n", "year_col", "=", "\"Year\"", ",", "\n", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "assert", "(", "\n", "len", "(", "df", ".", "columns", ")", "==", "7", "\n", ")", "# 4 header columns (user, item, rating, timestamp) and 3 feature columns", "\n", "assert", "\"e\"", "not", "in", "df", ".", "columns", "# only the first 4 header columns are used", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_movielens.test_load_item_df": [[94, 130], ["pytest.mark.parametrize", "recommenders.datasets.movielens.load_item_df", "recommenders.datasets.movielens.load_item_df", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_item_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_item_df"], ["head", "=", "df", ".", "loc", "[", "df", "[", "\"b\"", "]", "==", "movie_example", "]", "[", ":", "2", "]", "\n", "title", "=", "head", "[", "\"Title\"", "]", ".", "values", "\n", "assert", "title", "[", "0", "]", "==", "title", "[", "1", "]", "\n", "assert", "title", "[", "0", "]", "==", "title_example", "\n", "genres", "=", "head", "[", "\"Genres\"", "]", ".", "values", "\n", "assert", "genres", "[", "0", "]", "==", "genres", "[", "1", "]", "\n", "assert", "genres", "[", "0", "]", "==", "genres_example", "\n", "year", "=", "head", "[", "\"Year\"", "]", ".", "values", "\n", "assert", "year", "[", "0", "]", "==", "year", "[", "1", "]", "\n", "assert", "year", "[", "0", "]", "==", "year_example", "\n", "\n", "# Test default arguments", "\n", "", "df", "=", "load_pandas_df", "(", "size", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_samples", "\n", "# user, item, rating and timestamp", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "4", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\"1m\"", ",", "3883", ",", "1", ",", "\"Toy Story (1995)\"", ",", "\"Animation|Children's|Comedy\"", ",", "\"1995\"", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_movielens.test_load_spark_df": [[132, 213], ["pytest.mark.parametrize", "StructType", "recommenders.datasets.movielens.load_spark_df", "pytest.warns", "recommenders.datasets.movielens.load_spark_df", "pytest.warns", "recommenders.datasets.movielens.load_spark_df", "recommenders.datasets.movielens.load_spark_df.filter().limit", "df.filter().limit.select().collect", "df.filter().limit.select().collect", "df.filter().limit.select().collect", "recommenders.datasets.movielens.load_spark_df.count", "len", "StructField", "StructField", "recommenders.datasets.movielens.load_spark_df.count", "len", "len", "len", "recommenders.datasets.movielens.load_spark_df.count", "len", "IntegerType", "IntegerType", "os.listdir", "recommenders.datasets.movielens.load_spark_df.filter", "df.filter().limit.select", "df.filter().limit.select", "df.filter().limit.select", "col"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.load_spark_df"], [")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_item_df", "(", "\n", "size", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test movielens item data load (not rating data)\"\"\"", "\n", "df", "=", "load_item_df", "(", "size", ",", "local_cache_path", "=", "tmp", ",", "title_col", "=", "\"title\"", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_movies", "\n", "# movie_col and title_col should be loaded", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "2", "\n", "assert", "df", "[", "\"title\"", "]", "[", "0", "]", "==", "title_example", "\n", "\n", "# Test title and genres", "\n", "df", "=", "load_item_df", "(", "\n", "size", ",", "\n", "local_cache_path", "=", "tmp", ",", "\n", "movie_col", "=", "\"item\"", ",", "\n", "genres_col", "=", "\"genres\"", ",", "\n", "year_col", "=", "\"year\"", ",", "\n", ")", "\n", "assert", "len", "(", "df", ")", "==", "num_movies", "\n", "# movile_col, genres_col and year_col", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "3", "\n", "\n", "assert", "df", "[", "\"item\"", "]", "[", "0", "]", "==", "movie_example", "\n", "assert", "df", "[", "\"genres\"", "]", "[", "0", "]", "==", "genres_example", "\n", "assert", "df", "[", "\"year\"", "]", "[", "0", "]", "==", "year_example", "\n", "\n", "\n", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "@", "pytest", ".", "mark", ".", "spark", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size, num_samples, num_movies, movie_example, title_example, genres_example, year_example\"", ",", "\n", "[", "\n", "(", "\n", "\"1m\"", ",", "\n", "1000209", ",", "\n", "3883", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Animation|Children's|Comedy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"10m\"", ",", "\n", "10000054", ",", "\n", "10681", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "(", "\n", "\"20m\"", ",", "\n", "20000263", ",", "\n", "27278", ",", "\n", "1", ",", "\n", "\"Toy Story (1995)\"", ",", "\n", "\"Adventure|Animation|Children|Comedy|Fantasy\"", ",", "\n", "\"1995\"", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_load_spark_df", "(", "\n", "size", ",", "\n", "num_samples", ",", "\n", "num_movies", ",", "\n", "movie_example", ",", "\n", "title_example", ",", "\n", "genres_example", ",", "\n", "year_example", ",", "\n", "tmp", ",", "\n", "spark", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Test MovieLens dataset load into pySpark.DataFrame\"\"\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.dataset.test_movielens.test_download_and_extract_movielens": [[215, 233], ["pytest.mark.parametrize", "os.path.join", "recommenders.datasets.movielens.download_movielens", "os.path.exists", "os.path.join", "os.path.join", "recommenders.datasets.movielens.extract_movielens", "os.path.exists", "os.path.exists", "len", "len", "os.listdir", "os.listdir"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.download_movielens", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.movielens.extract_movielens"], ["# Test if correct data are loaded", "\n", "header", "=", "[", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "schema", "=", "StructType", "(", "\n", "[", "\n", "StructField", "(", "\"u\"", ",", "IntegerType", "(", ")", ")", ",", "\n", "StructField", "(", "\"m\"", ",", "IntegerType", "(", ")", ")", ",", "\n", "]", "\n", ")", "\n", "with", "pytest", ".", "warns", "(", "Warning", ")", ":", "\n", "        ", "df", "=", "load_spark_df", "(", "\n", "spark", ",", "size", "=", "size", ",", "local_cache_path", "=", "tmp", ",", "header", "=", "header", ",", "schema", "=", "schema", "\n", ")", "\n", "assert", "df", ".", "count", "(", ")", "==", "num_samples", "\n", "# Test if schema is used when both schema and header are provided", "\n", "assert", "len", "(", "df", ".", "columns", ")", "==", "len", "(", "schema", ")", "\n", "# Test if raw-zip file, rating file, and item file are cached", "\n", "assert", "len", "(", "os", ".", "listdir", "(", "tmp", ")", ")", "==", "3", "\n", "\n", "# Test title, genres, and released year load", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_utils.test_DKN_iterator": [[26, 83], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_deeprec_resources", "prepare_hparams", "DKNTextIterator", "DKNTextIterator.load_data_from_file", "prepare_hparams", "DKNItem2itemTextIterator", "DKNItem2itemTextIterator.load_data_from_file", "tf.Graph", "isinstance", "tf.Graph", "os.path.join", "isinstance", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_DKN_iterator", "(", "deeprec_resource_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_mind_demo.txt\"", ")", "\n", "news_feature_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"doc_feature.txt\"", ")", "\n", "user_history_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_history.txt\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"word_embeddings_100.npy\"", ")", "\n", "entityEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"TransE_entity2vec_100.npy\"", ")", "\n", "contextEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"TransE_context2vec_100.npy\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"dkn.yaml\"", ")", "\n", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"mind-demo.zip\"", ",", "\n", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "news_feature_file", "=", "news_feature_file", ",", "\n", "user_history_file", "=", "user_history_file", ",", "\n", "wordEmb_file", "=", "\"\"", ",", "\n", "entityEmb_file", "=", "\"\"", ",", "\n", "contextEmb_file", "=", "\"\"", ",", "\n", ")", "\n", "iterator", "=", "DKNTextIterator", "(", "hparams", ",", "tf", ".", "Graph", "(", ")", ")", "\n", "assert", "iterator", "is", "not", "None", "\n", "for", "res", ",", "impression", ",", "data_size", "in", "iterator", ".", "load_data_from_file", "(", "data_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "\n", "# test DKN item2item iterator", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "news_feature_file", "=", "news_feature_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "entityEmb_file", "=", "entityEmb_file", ",", "\n", "contextEmb_file", "=", "contextEmb_file", ",", "\n", "epochs", "=", "1", ",", "\n", "is_clip_norm", "=", "True", ",", "\n", "max_grad_norm", "=", "0.5", ",", "\n", "his_size", "=", "20", ",", "\n", "MODEL_DIR", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"save_models\"", ")", ",", "\n", "use_entity", "=", "True", ",", "\n", "use_context", "=", "True", ",", "\n", ")", "\n", "hparams", ".", "neg_num", "=", "9", "\n", "\n", "iterator_item2item", "=", "DKNItem2itemTextIterator", "(", "hparams", ",", "tf", ".", "Graph", "(", ")", ")", "\n", "assert", "iterator_item2item", "is", "not", "None", "\n", "test_round", "=", "3", "\n", "for", "res", ",", "impression", ",", "data_size", "in", "iterator_item2item", ".", "load_data_from_file", "(", "\n", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"doc_list.txt\"", ")", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "test_round", "-=", "1", "\n", "if", "test_round", "<=", "0", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_utils.test_Sequential_Iterator": [[85, 137], ["os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "SequentialIterator", "SequentialIterator.load_data_from_file", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_and_extract", "download_and_extract", "data_preprocessing", "tf.Graph", "isinstance"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.data_preprocessing"], ["", "", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_Sequential_Iterator", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"slirec\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"sli_rec.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_data\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file", ")", ":", "\n", "        ", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_data\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"test_data\"", ")", "\n", "user_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_vocab.pkl\"", ")", "\n", "item_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_vocab.pkl\"", ")", "\n", "cate_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"category_vocab.pkl\"", ")", "\n", "\n", "reviews_name", "=", "\"reviews_Movies_and_TV_5.json\"", "\n", "meta_name", "=", "\"meta_Movies_and_TV.json\"", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "reviews_name", ")", "\n", "meta_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "meta_name", ")", "\n", "valid_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for validation", "\n", ")", "\n", "test_num_ngs", "=", "(", "\n", "9", "# number of negative instances with a positive instance for testing", "\n", ")", "\n", "sample_rate", "=", "(", "\n", "0.01", "# sample a small item set for training and testing here for example", "\n", ")", "\n", "\n", "input_files", "=", "[", "\n", "reviews_file", ",", "\n", "meta_file", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "]", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "download_and_extract", "(", "meta_name", ",", "meta_file", ")", "\n", "data_preprocessing", "(", "\n", "*", "input_files", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "valid_num_ngs", "=", "valid_num_ngs", ",", "\n", "test_num_ngs", "=", "test_num_ngs", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "yaml_file", ")", "\n", "iterator", "=", "SequentialIterator", "(", "hparams", ",", "tf", ".", "Graph", "(", ")", ")", "\n", "assert", "iterator", "is", "not", "None", "\n", "for", "res", "in", "iterator", ".", "load_data_from_file", "(", "train_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_model.test_model_nrms": [[20, 69], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "NRMSModel", "isinstance", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "NRMSModel.run_eval", "NRMSModel.fit", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_nrms", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"nrms.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "iterator", "=", "MINDIterator", "\n", "model", "=", "NRMSModel", "(", "hparams", ",", "iterator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_model.test_model_naml": [[72, 123], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "NAMLModel", "isinstance", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "NAMLModel.run_eval", "NAMLModel.fit", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_naml", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding_all.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict_all.pkl\"", ")", "\n", "vertDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"vert_dict.pkl\"", ")", "\n", "subvertDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"subvert_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"naml.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "vertDict_file", "=", "vertDict_file", ",", "\n", "subvertDict_file", "=", "subvertDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "\n", "iterator", "=", "MINDAllIterator", "\n", "model", "=", "NAMLModel", "(", "hparams", ",", "iterator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_model.test_model_lstur": [[126, 175], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "LSTURModel", "isinstance", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "LSTURModel.run_eval", "LSTURModel.fit", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_lstur", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"lstur.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "iterator", "=", "MINDIterator", "\n", "model", "=", "LSTURModel", "(", "hparams", ",", "iterator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_model.test_model_npa": [[178, 227], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "LSTURModel", "isinstance", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "LSTURModel.run_eval", "LSTURModel.fit", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_model_npa", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"lstur.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "iterator", "=", "MINDIterator", "\n", "model", "=", "LSTURModel", "(", "hparams", ",", "iterator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "valid_news_file", ",", "valid_behaviors_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "\n", "train_news_file", ",", "train_behaviors_file", ",", "valid_news_file", ",", "valid_behaviors_file", "\n", ")", ",", "\n", "BaseModel", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_utils.test_news_iterator": [[16, 70], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "MINDIterator", "MINDIterator", "MINDIterator.load_data_from_file", "MINDIterator.load_data_from_file", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "isinstance", "isinstance", "os.path.join", "os.path.join", "os.path.join", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_news_iterator", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"nrms.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", ")", "\n", "train_iterator", "=", "MINDIterator", "(", "hparams", ",", "hparams", ".", "npratio", ")", "\n", "test_iterator", "=", "MINDIterator", "(", "hparams", ",", "-", "1", ")", "\n", "\n", "assert", "train_iterator", "is", "not", "None", "\n", "for", "res", "in", "train_iterator", ".", "load_data_from_file", "(", "\n", "train_news_file", ",", "train_behaviors_file", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "assert", "len", "(", "res", ")", "==", "5", "\n", "break", "\n", "\n", "", "assert", "test_iterator", "is", "not", "None", "\n", "for", "res", "in", "test_iterator", ".", "load_data_from_file", "(", "valid_news_file", ",", "valid_behaviors_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "assert", "len", "(", "res", ")", "==", "5", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_newsrec_utils.test_naml_iterator": [[72, 131], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "MINDAllIterator", "MINDAllIterator", "MINDAllIterator.load_data_from_file", "MINDAllIterator.load_data_from_file", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "os.path.exists", "download_deeprec_resources", "isinstance", "isinstance", "os.path.join", "os.path.join", "os.path.join", "len", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "def", "test_naml_iterator", "(", "mind_resource_path", ")", ":", "\n", "    ", "train_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"news.tsv\"", ")", "\n", "train_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ",", "r\"behaviors.tsv\"", ")", "\n", "valid_news_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"news.tsv\"", ")", "\n", "valid_behaviors_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ",", "r\"behaviors.tsv\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"embedding_all.npy\"", ")", "\n", "userDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"uid2index.pkl\"", ")", "\n", "wordDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"word_dict_all.pkl\"", ")", "\n", "vertDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"vert_dict.pkl\"", ")", "\n", "subvertDict_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "\"subvert_dict.pkl\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ",", "r\"naml.yaml\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"train\"", ")", ",", "\n", "\"MINDdemo_train.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "valid_news_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"valid\"", ")", ",", "\n", "\"MINDdemo_dev.zip\"", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "r\"https://recodatasets.z20.web.core.windows.net/newsrec/\"", ",", "\n", "os", ".", "path", ".", "join", "(", "mind_resource_path", ",", "\"utils\"", ")", ",", "\n", "\"MINDdemo_utils.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "wordDict_file", "=", "wordDict_file", ",", "\n", "userDict_file", "=", "userDict_file", ",", "\n", "vertDict_file", "=", "vertDict_file", ",", "\n", "subvertDict_file", "=", "subvertDict_file", ",", "\n", "epochs", "=", "1", ",", "\n", "batch_size", "=", "1024", ",", "\n", ")", "\n", "train_iterator", "=", "MINDAllIterator", "(", "hparams", ",", "hparams", ".", "npratio", ")", "\n", "test_iterator", "=", "MINDAllIterator", "(", "hparams", ",", "-", "1", ")", "\n", "\n", "assert", "train_iterator", "is", "not", "None", "\n", "for", "res", "in", "train_iterator", ".", "load_data_from_file", "(", "\n", "train_news_file", ",", "train_behaviors_file", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "assert", "len", "(", "res", ")", "==", "11", "\n", "break", "\n", "\n", "", "assert", "test_iterator", "is", "not", "None", "\n", "for", "res", "in", "test_iterator", ".", "load_data_from_file", "(", "valid_news_file", ",", "valid_behaviors_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "dict", ")", "\n", "assert", "len", "(", "res", ")", "==", "11", "\n", "break", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_FFM_iterator": [[33, 53], ["os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "FFMTextIterator", "FFMTextIterator.load_data_from_file", "os.path.exists", "download_deeprec_resources", "tf.Graph", "isinstance"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.io.sequential_iterator.SequentialIterator.load_data_from_file", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "def", "test_FFM_iterator", "(", "deeprec_resource_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"xdeepfm\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"xDeepFM.yaml\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"sample_FFM_data.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"xdeepfmresources.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "yaml_file", ")", "\n", "iterator", "=", "FFMTextIterator", "(", "hparams", ",", "tf", ".", "Graph", "(", ")", ")", "\n", "assert", "iterator", "is", "not", "None", "\n", "for", "res", "in", "iterator", ".", "load_data_from_file", "(", "data_file", ")", ":", "\n", "        ", "assert", "isinstance", "(", "res", ",", "tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_model_xdeepfm": [[55, 80], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "XDeepFMModel", "isinstance", "os.path.exists", "download_deeprec_resources", "XDeepFMModel.run_eval", "XDeepFMModel.fit", "XDeepFMModel.predict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "def", "test_model_xdeepfm", "(", "deeprec_resource_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"xdeepfm\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"xDeepFM.yaml\"", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"sample_FFM_data.txt\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "yaml_file", ")", ":", "\n", "        ", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"xdeepfmresources.zip\"", ",", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "yaml_file", ",", "learning_rate", "=", "0.01", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "FFMTextIterator", "\n", "model", "=", "XDeepFMModel", "(", "hparams", ",", "input_creator", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", "data_file", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "model", ".", "fit", "(", "data_file", ",", "data_file", ")", ",", "BaseModel", ")", "\n", "assert", "model", ".", "predict", "(", "data_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_model_dkn": [[82, 117], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_deeprec_resources", "prepare_hparams", "DKN", "isinstance", "DKN.fit", "DKN.run_eval"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.download_deeprec_resources", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "def", "test_model_dkn", "(", "deeprec_resource_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"dkn.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_mind_demo.txt\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_mind_demo.txt\"", ")", "\n", "news_feature_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"doc_feature.txt\"", ")", "\n", "user_history_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_history.txt\"", ")", "\n", "wordEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"word_embeddings_100.npy\"", ")", "\n", "entityEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"TransE_entity2vec_100.npy\"", ")", "\n", "contextEmb_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"TransE_context2vec_100.npy\"", ")", "\n", "\n", "download_deeprec_resources", "(", "\n", "\"https://recodatasets.z20.web.core.windows.net/deeprec/\"", ",", "\n", "data_path", ",", "\n", "\"mind-demo.zip\"", ",", "\n", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "\n", "news_feature_file", "=", "news_feature_file", ",", "\n", "user_history_file", "=", "user_history_file", ",", "\n", "wordEmb_file", "=", "wordEmb_file", ",", "\n", "entityEmb_file", "=", "entityEmb_file", ",", "\n", "contextEmb_file", "=", "contextEmb_file", ",", "\n", "epochs", "=", "1", ",", "\n", "learning_rate", "=", "0.0001", ",", "\n", ")", "\n", "input_creator", "=", "DKNTextIterator", "\n", "model", "=", "DKN", "(", "hparams", ",", "input_creator", ")", "\n", "\n", "assert", "isinstance", "(", "model", ".", "fit", "(", "train_file", ",", "valid_file", ")", ",", "BaseModel", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_model_slirec": [[119, 183], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "SLI_RECModel", "isinstance", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_and_extract", "download_and_extract", "data_preprocessing", "SLI_RECModel.run_eval", "SLI_RECModel.fit", "SLI_RECModel.predict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.data_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "@", "pytest", ".", "mark", ".", "sequential", "\n", "def", "test_model_slirec", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"slirec\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"sli_rec.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_data\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_data\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"test_data\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "train_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for training", "\n", ")", "\n", "valid_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for validation", "\n", ")", "\n", "test_num_ngs", "=", "(", "\n", "9", "# number of negative instances with a positive instance for testing", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file", ")", ":", "\n", "        ", "user_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_vocab.pkl\"", ")", "\n", "item_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_vocab.pkl\"", ")", "\n", "cate_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"category_vocab.pkl\"", ")", "\n", "reviews_name", "=", "\"reviews_Movies_and_TV_5.json\"", "\n", "meta_name", "=", "\"meta_Movies_and_TV.json\"", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "reviews_name", ")", "\n", "meta_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "meta_name", ")", "\n", "sample_rate", "=", "(", "\n", "0.005", "# sample a small item set for training and testing here for example", "\n", ")", "\n", "\n", "input_files", "=", "[", "\n", "reviews_file", ",", "\n", "meta_file", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "]", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "download_and_extract", "(", "meta_name", ",", "meta_file", ")", "\n", "data_preprocessing", "(", "\n", "*", "input_files", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "valid_num_ngs", "=", "valid_num_ngs", ",", "\n", "test_num_ngs", "=", "test_num_ngs", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "learning_rate", "=", "0.01", ",", "epochs", "=", "3", ",", "train_num_ngs", "=", "train_num_ngs", "\n", ")", "# confirm train_num_ngs before initializing a SLi_Rec model.", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "SequentialIterator", "\n", "model", "=", "SLI_RECModel", "(", "hparams", ",", "input_creator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ",", "num_ngs", "=", "valid_num_ngs", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "train_file", ",", "valid_file", ",", "valid_num_ngs", "=", "valid_num_ngs", ")", ",", "BaseModel", "\n", ")", "\n", "assert", "model", ".", "predict", "(", "test_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_model_sum": [[185, 249], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "prepare_hparams", "SUMModel", "isinstance", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "download_and_extract", "download_and_extract", "data_preprocessing", "SUMModel.run_eval", "SUMModel.fit", "SUMModel.predict"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.download_and_extract", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.amazon_reviews.data_preprocessing", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARModel.SARModel.predict"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "@", "pytest", ".", "mark", ".", "sequential", "\n", "def", "test_model_sum", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"slirec\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"sum.yaml\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"train_data\"", ")", "\n", "valid_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"valid_data\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"test_data\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"output.txt\"", ")", "\n", "train_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for training", "\n", ")", "\n", "valid_num_ngs", "=", "(", "\n", "4", "# number of negative instances with a positive instance for validation", "\n", ")", "\n", "test_num_ngs", "=", "(", "\n", "9", "# number of negative instances with a positive instance for testing", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file", ")", ":", "\n", "        ", "user_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_vocab.pkl\"", ")", "\n", "item_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_vocab.pkl\"", ")", "\n", "cate_vocab", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"category_vocab.pkl\"", ")", "\n", "reviews_name", "=", "\"reviews_Movies_and_TV_5.json\"", "\n", "meta_name", "=", "\"meta_Movies_and_TV.json\"", "\n", "reviews_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "reviews_name", ")", "\n", "meta_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "meta_name", ")", "\n", "sample_rate", "=", "(", "\n", "0.005", "# sample a small item set for training and testing here for example", "\n", ")", "\n", "\n", "input_files", "=", "[", "\n", "reviews_file", ",", "\n", "meta_file", ",", "\n", "train_file", ",", "\n", "valid_file", ",", "\n", "test_file", ",", "\n", "user_vocab", ",", "\n", "item_vocab", ",", "\n", "cate_vocab", ",", "\n", "]", "\n", "download_and_extract", "(", "reviews_name", ",", "reviews_file", ")", "\n", "download_and_extract", "(", "meta_name", ",", "meta_file", ")", "\n", "data_preprocessing", "(", "\n", "*", "input_files", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "valid_num_ngs", "=", "valid_num_ngs", ",", "\n", "test_num_ngs", "=", "test_num_ngs", "\n", ")", "\n", "\n", "", "hparams", "=", "prepare_hparams", "(", "\n", "yaml_file", ",", "learning_rate", "=", "0.01", ",", "epochs", "=", "1", ",", "train_num_ngs", "=", "train_num_ngs", "\n", ")", "\n", "assert", "hparams", "is", "not", "None", "\n", "\n", "input_creator", "=", "SequentialIterator", "\n", "model", "=", "SUMModel", "(", "hparams", ",", "input_creator", ")", "\n", "assert", "model", ".", "run_eval", "(", "valid_file", ",", "num_ngs", "=", "valid_num_ngs", ")", "is", "not", "None", "\n", "assert", "isinstance", "(", "\n", "model", ".", "fit", "(", "train_file", ",", "valid_file", ",", "valid_num_ngs", "=", "valid_num_ngs", ")", ",", "BaseModel", "\n", ")", "\n", "assert", "model", ".", "predict", "(", "valid_file", ",", "output_file", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_recommenders.recommender.test_deeprec_model.test_model_lightgcn": [[251, 274], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "movielens.load_pandas_df", "python_stratified_split", "ImplicitCF", "prepare_hparams", "LightGCN", "LightGCN.fit", "LightGCN.infer_embedding", "LightGCN.run_eval", "LightGCN.recommend_k_items", "os.path.getsize", "os.path.getsize"], "function", ["home.repos.pwc.inspect_result.microsoft_recommenders.datasets.covid_utils.load_pandas_df", "home.repos.pwc.inspect_result.microsoft_recommenders.datasets.python_splitters.python_stratified_split", "home.repos.pwc.inspect_result.microsoft_recommenders.deeprec.deeprec_utils.prepare_hparams", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.fit", "home.repos.pwc.inspect_result.microsoft_recommenders.graphrec.lightgcn.LightGCN.infer_embedding", "home.repos.pwc.inspect_result.microsoft_recommenders.sequential.sequential_base_model.SequentialBaseModel.run_eval", "home.repos.pwc.inspect_result.microsoft_recommenders.pysarplus.SARPlus.SARPlus.recommend_k_items"], ["", "@", "pytest", ".", "mark", ".", "smoke", "\n", "@", "pytest", ".", "mark", ".", "gpu", "\n", "@", "pytest", ".", "mark", ".", "deeprec", "\n", "def", "test_model_lightgcn", "(", "deeprec_resource_path", ",", "deeprec_config_path", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "deeprec_resource_path", ",", "\"dkn\"", ")", "\n", "yaml_file", "=", "os", ".", "path", ".", "join", "(", "deeprec_config_path", ",", "\"lightgcn.yaml\"", ")", "\n", "user_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"user_embeddings.csv\"", ")", "\n", "item_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "r\"item_embeddings.csv\"", ")", "\n", "\n", "df", "=", "movielens", ".", "load_pandas_df", "(", "size", "=", "\"100k\"", ")", "\n", "train", ",", "test", "=", "python_stratified_split", "(", "df", ",", "ratio", "=", "0.75", ")", "\n", "\n", "data", "=", "ImplicitCF", "(", "train", "=", "train", ",", "test", "=", "test", ")", "\n", "\n", "hparams", "=", "prepare_hparams", "(", "yaml_file", ",", "epochs", "=", "1", ")", "\n", "model", "=", "LightGCN", "(", "hparams", ",", "data", ")", "\n", "\n", "assert", "model", ".", "run_eval", "(", ")", "is", "not", "None", "\n", "model", ".", "fit", "(", ")", "\n", "assert", "model", ".", "recommend_k_items", "(", "test", ")", "is", "not", "None", "\n", "model", ".", "infer_embedding", "(", "user_file", ",", "item_file", ")", "\n", "assert", "os", ".", "path", ".", "getsize", "(", "user_file", ")", "!=", "0", "\n", "assert", "os", ".", "path", ".", "getsize", "(", "item_file", ")", "!=", "0", "\n", "", ""]]}