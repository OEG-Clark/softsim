{"home.repos.pwc.inspect_result.helboukkouri_character-bert.None.main.parse_args": [[32, 142], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "datetime.datetime.now().strftime", "os.path.join", "logging.basicConfig", "torch.cuda.is_available", "utils.misc.set_seed", "torch.device", "logging.info", "torch.device", "logging.info", "datetime.datetime.now", "torch.cuda.device_count", "torch.cuda.get_device_name"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.None.main.parse_args", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.misc.set_seed"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\" Parse command line arguments and initialize experiment. \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "[", "'classification'", ",", "'sequence_labelling'", "]", ",", "\n", "help", "=", "\"The evaluation task.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "AVAILABLE_MODELS", ",", "\n", "help", "=", "\"The model to use.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to apply lowercasing during tokenization.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_batch_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Batch size to use for training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_batch_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Batch size to use for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of gradient accumulation steps.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "3", ",", "\n", "help", "=", "\"Number of training epochs.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--validation_ratio\"", ",", "\n", "default", "=", "0.5", ",", "type", "=", "float", ",", "help", "=", "\"Proportion of training set to use as a validation set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight_decay\"", ",", "\n", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_ratio\"", ",", "\n", "default", "=", "0.1", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_ratio*total_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adam_epsilon\"", ",", "\n", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_grad_norm\"", ",", "\n", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_train\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do training & validation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_predict\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do prediction on the test set.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"Random seed.\"", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "start_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%d-%m-%Y_%Hh%Mm%Ss'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "'results'", ",", "\n", "args", ".", "task", ",", "\n", "args", ".", "embedding", ",", "\n", "f'{args.start_time}__seed-{args.seed}'", ")", "\n", "\n", "# --------------------------------- INIT ---------------------------------", "\n", "\n", "# Set up logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(filename)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%d/%m/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", ")", "\n", "\n", "# Check for GPUs", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "assert", "torch", ".", "cuda", ".", "device_count", "(", ")", "==", "1", "# This script doesn't support multi-gpu", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "logging", ".", "info", "(", "\"Using GPU (`%s`)\"", ",", "torch", ".", "cuda", ".", "get_device_name", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "logging", ".", "info", "(", "\"Using CPU\"", ")", "\n", "\n", "# Set random seed for reproducibility", "\n", "", "set_seed", "(", "seed_value", "=", "args", ".", "seed", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.main.main": [[143, 344], ["logging.disable", "logging.disable", "logging.info", "logging.info", "logging.info", "sorted", "len", "logging.info", "enumerate", "logging.info", "logging.info", "logging.disable", "transformers.BertConfig.from_pretrained", "logging.disable", "model.to", "logging.info", "logging.info", "vars().items", "transformers.BertTokenizer.from_pretrained", "func", "utils.data.retokenize", "len", "len", "collections.Counter", "collections.Counter", "min", "collections.Counter.keys", "logging.info", "utils.data.build_features", "os.path.join", "model.from_pretrained", "model.", "modeling.character_bert.CharacterBertModel.from_pretrained", "logging.info", "utils.training.train", "logging.info", "logging.info", "logging.disable", "logging.disable", "model.to", "utils.training.evaluate", "os.path.join", "transformers.BertTokenizer.from_pretrained", "utils.character_cnn.CharacterIndexer", "int", "int", "collections.Counter", "collections.Counter", "min", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "torch.nn.CrossEntropyLoss", "os.path.join", "os.path.join", "vars", "model.from_pretrained", "torch.load", "model.", "modeling.character_bert.CharacterBertModel", "model.load_state_dict", "open", "f.write", "f.write", "f.write", "results.items", "os.path.join", "max", "os.path.join", "os.path.join", "f.write", "len", "len", "map", "max", "map"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.retokenize", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.build_features", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.train", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.evaluate"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "\"\"\" Main function. \"\"\"", "\n", "\n", "# --------------------------------- DATA ---------------------------------", "\n", "\n", "# Tokenizer", "\n", "logging", ".", "disable", "(", "logging", ".", "INFO", ")", "\n", "try", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "args", ".", "embedding", ")", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "except", "OSError", ":", "\n", "# For CharacterBert models use BertTokenizer.basic_tokenizer for tokenization", "\n", "# and CharacterIndexer for indexing ", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "'bert-base-uncased'", ")", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "tokenizer", "=", "tokenizer", ".", "basic_tokenizer", "\n", "characters_indexer", "=", "CharacterIndexer", "(", ")", "\n", "", "logging", ".", "disable", "(", "logging", ".", "NOTSET", ")", "\n", "\n", "tokenization_function", "=", "tokenizer", ".", "tokenize", "\n", "\n", "# Pre-processsing: apply basic tokenization (both) then split into wordpieces (BERT only)", "\n", "data", "=", "{", "}", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "if", "args", ".", "task", "==", "'classification'", ":", "\n", "            ", "func", "=", "load_classification_dataset", "\n", "", "elif", "args", ".", "task", "==", "'sequence_labelling'", ":", "\n", "            ", "func", "=", "load_sequence_labelling_dataset", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "data", "[", "split", "]", "=", "func", "(", "step", "=", "split", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "retokenize", "(", "data", "[", "split", "]", ",", "tokenization_function", ")", "\n", "\n", "", "logging", ".", "info", "(", "'Splitting training data into train / validation sets...'", ")", "\n", "data", "[", "'validation'", "]", "=", "data", "[", "'train'", "]", "[", ":", "int", "(", "args", ".", "validation_ratio", "*", "len", "(", "data", "[", "'train'", "]", ")", ")", "]", "\n", "data", "[", "'train'", "]", "=", "data", "[", "'train'", "]", "[", "int", "(", "args", ".", "validation_ratio", "*", "len", "(", "data", "[", "'train'", "]", ")", ")", ":", "]", "\n", "logging", ".", "info", "(", "'New number of training sequences: %d'", ",", "len", "(", "data", "[", "'train'", "]", ")", ")", "\n", "logging", ".", "info", "(", "'New number of validation sequences: %d'", ",", "len", "(", "data", "[", "'validation'", "]", ")", ")", "\n", "\n", "# Count target labels or classes", "\n", "if", "args", ".", "task", "==", "'classification'", ":", "\n", "        ", "counter_all", "=", "Counter", "(", "\n", "[", "example", ".", "label", "for", "example", "in", "data", "[", "'train'", "]", "+", "data", "[", "'validation'", "]", "+", "data", "[", "'test'", "]", "]", ")", "\n", "counter", "=", "Counter", "(", "\n", "[", "example", ".", "label", "for", "example", "in", "data", "[", "'train'", "]", "]", ")", "\n", "\n", "# Maximum sequence length is either 512 or maximum token sequence length + 3", "\n", "max_seq_length", "=", "min", "(", "\n", "512", ",", "\n", "3", "+", "max", "(", "\n", "map", "(", "len", ",", "[", "\n", "e", ".", "tokens_a", "if", "e", ".", "tokens_b", "is", "None", "else", "e", ".", "tokens_a", "+", "e", ".", "tokens_b", "\n", "for", "e", "in", "data", "[", "'train'", "]", "+", "data", "[", "'validation'", "]", "+", "data", "[", "'test'", "]", "\n", "]", ")", "\n", ")", "\n", ")", "\n", "", "elif", "args", ".", "task", "==", "'sequence_labelling'", ":", "\n", "        ", "counter_all", "=", "Counter", "(", "\n", "[", "label", "\n", "for", "example", "in", "data", "[", "'train'", "]", "+", "data", "[", "'validation'", "]", "+", "data", "[", "'test'", "]", "\n", "for", "label", "in", "example", ".", "label_sequence", "]", ")", "\n", "counter", "=", "Counter", "(", "\n", "[", "label", "\n", "for", "example", "in", "data", "[", "'train'", "]", "\n", "for", "label", "in", "example", ".", "label_sequence", "]", ")", "\n", "\n", "# Maximum sequence length is either 512 or maximum token sequence length + 5", "\n", "max_seq_length", "=", "min", "(", "\n", "512", ",", "\n", "5", "+", "max", "(", "\n", "map", "(", "len", ",", "[", "\n", "e", ".", "token_sequence", "\n", "for", "e", "in", "data", "[", "'train'", "]", "+", "data", "[", "'validation'", "]", "+", "data", "[", "'test'", "]", "\n", "]", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "labels", "=", "sorted", "(", "counter_all", ".", "keys", "(", ")", ")", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "\n", "logging", ".", "info", "(", "\"Goal: predict the following labels\"", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"* %s: %s (count: %s)\"", ",", "label", ",", "i", ",", "counter", "[", "label", "]", ")", "\n", "\n", "# Input features: list[token indices] (BERT) or list[list[character indices]] (CharacterBERT)", "\n", "", "pad_token_id", "=", "None", "\n", "if", "'character'", "not", "in", "args", ".", "embedding", ":", "\n", "        ", "pad_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", "\n", "\n", "", "pad_token_label_id", "=", "None", "\n", "if", "args", ".", "task", "==", "'sequence_labelling'", ":", "\n", "        ", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "\n", "\n", "", "dataset", "=", "{", "}", "\n", "logging", ".", "info", "(", "\"Maximum sequence lenght: %s\"", ",", "max_seq_length", ")", "\n", "for", "split", "in", "data", ":", "\n", "        ", "dataset", "[", "split", "]", "=", "build_features", "(", "\n", "args", ",", "\n", "split", "=", "split", ",", "\n", "tokenizer", "=", "tokenizer", "if", "'character'", "not", "in", "args", ".", "embedding", "else", "characters_indexer", ",", "\n", "examples", "=", "data", "[", "split", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", ",", "\n", "max_seq_length", "=", "max_seq_length", ")", "\n", "\n", "", "del", "data", "# Not used anymore", "\n", "\n", "# --------------------------------- MODEL ---------------------------------", "\n", "\n", "# Initialize model", "\n", "if", "args", ".", "task", "==", "'classification'", ":", "\n", "        ", "model", "=", "BertForSequenceClassification", "\n", "", "elif", "args", ".", "task", "==", "'sequence_labelling'", ":", "\n", "        ", "model", "=", "BertForTokenClassification", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "logging", ".", "info", "(", "'Loading `%s` model...'", ",", "args", ".", "embedding", ")", "\n", "logging", ".", "disable", "(", "logging", ".", "INFO", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "\n", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "args", ".", "embedding", ")", ",", "\n", "num_labels", "=", "num_labels", ")", "\n", "if", "'character'", "not", "in", "args", ".", "embedding", ":", "\n", "        ", "model", "=", "model", ".", "from_pretrained", "(", "\n", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "args", ".", "embedding", ")", ",", "\n", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model", "(", "config", "=", "config", ")", "\n", "model", ".", "bert", "=", "CharacterBertModel", ".", "from_pretrained", "(", "\n", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "args", ".", "embedding", ")", ",", "\n", "config", "=", "config", ")", "\n", "", "logging", ".", "disable", "(", "logging", ".", "NOTSET", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "logging", ".", "info", "(", "'Model:\\n%s'", ",", "model", ")", "\n", "\n", "# ------------------------------ TRAIN / EVAL ------------------------------", "\n", "\n", "# Log args", "\n", "logging", ".", "info", "(", "'Using the following arguments for training:'", ")", "\n", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"* %s: %s\"", ",", "k", ",", "v", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "global_step", ",", "train_loss", ",", "best_val_metric", ",", "best_val_epoch", "=", "train", "(", "\n", "args", "=", "args", ",", "\n", "dataset", "=", "dataset", ",", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "labels", "=", "labels", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "logging", ".", "info", "(", "\"global_step = %s, average training loss = %s\"", ",", "global_step", ",", "train_loss", ")", "\n", "logging", ".", "info", "(", "\"Best performance: Epoch=%d, Value=%s\"", ",", "best_val_epoch", ",", "best_val_metric", ")", "\n", "\n", "# Evaluation on test data", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "\n", "# Load best model", "\n", "        ", "if", "args", ".", "task", "==", "'classification'", ":", "\n", "            ", "model", "=", "BertForSequenceClassification", "\n", "", "elif", "args", ".", "task", "==", "'sequence_labelling'", ":", "\n", "            ", "model", "=", "BertForTokenClassification", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "logging", ".", "disable", "(", "logging", ".", "INFO", ")", "\n", "if", "'character'", "not", "in", "args", ".", "embedding", ":", "\n", "            ", "model", "=", "model", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'pytorch_model.bin'", ")", ",", "map_location", "=", "'cpu'", ")", "\n", "model", "=", "model", "(", "config", "=", "config", ")", "\n", "model", ".", "bert", "=", "CharacterBertModel", "(", "config", "=", "config", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "", "logging", ".", "disable", "(", "logging", ".", "NOTSET", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Compute predictions and metrics", "\n", "results", ",", "_", "=", "evaluate", "(", "\n", "args", "=", "args", ",", "\n", "eval_dataset", "=", "dataset", "[", "\"test\"", "]", ",", "\n", "model", "=", "model", ",", "labels", "=", "labels", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "\n", "# Save metrics", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'performance_on_test_set.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f'best validation score: {best_val_metric}\\n'", ")", "\n", "f", ".", "write", "(", "f'best validation epoch: {best_val_epoch}\\n'", ")", "\n", "f", ".", "write", "(", "'--- Performance on test set ---\\n'", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "f'{k}: {v}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.data.load_classification_dataset": [[18, 41], ["transformers.BasicTokenizer", "os.path.join", "logging.info", "open", "data_file.readlines", "tqdm.tqdm", "len", "enumerate", "line.strip().split", "examples.append", "splitline[].split", "ClassificationExample", "line.strip", "os.path.basename", "transformers.BasicTokenizer.tokenize"], "function", ["None"], ["def", "load_classification_dataset", "(", "step", ",", "do_lower_case", ")", ":", "\n", "    ", "\"\"\" Loads classification exampels from a dataset. \"\"\"", "\n", "assert", "step", "in", "[", "'train'", ",", "'test'", "]", "\n", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "'classification'", ",", "f'{step}.txt'", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "data_file", ":", "\n", "        ", "lines", "=", "data_file", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "tqdm", "(", "enumerate", "(", "lines", ")", ",", "desc", "=", "f'reading `{os.path.basename(path)}`...'", ")", ":", "\n", "# example: __label__negative I don't like tomatoes.", "\n", "            ", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "splitline", "[", "0", "]", ".", "split", "(", "'__label__'", ")", "[", "-", "1", "]", "\n", "tokens", "=", "' '", ".", "join", "(", "splitline", "[", "1", ":", "]", ")", "\n", "examples", ".", "append", "(", "\n", "ClassificationExample", "(", "\n", "id", "=", "i", ",", "\n", "tokens_a", "=", "basic_tokenizer", ".", "tokenize", "(", "tokens", ")", ",", "\n", "tokens_b", "=", "None", ",", "\n", "label", "=", "label", ",", "\n", ")", "\n", ")", "\n", "", "", "logging", ".", "info", "(", "'Number of `%s` examples: %d'", ",", "step", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.data.load_sequence_labelling_dataset": [[42, 91], ["os.path.join", "utils.data.retokenize", "logging.info", "open", "data_file.readlines", "tqdm.tqdm", "examples.append", "len", "line.strip().split", "SequenceLabellingExample", "token_sequence.append", "label_sequence.append", "examples.append", "transformers.BasicTokenizer", "line.strip", "SequenceLabellingExample", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.retokenize"], ["", "def", "load_sequence_labelling_dataset", "(", "step", ",", "do_lower_case", ")", ":", "\n", "    ", "\"\"\" Loads sequence labelling examples from a dataset. \"\"\"", "\n", "assert", "step", "in", "[", "'train'", ",", "'test'", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "'sequence_labelling'", ",", "f'{step}.txt'", ")", "\n", "i", "=", "0", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "data_file", ":", "\n", "        ", "lines", "=", "data_file", ".", "readlines", "(", ")", "\n", "token_sequence", "=", "[", "]", "\n", "label_sequence", "=", "[", "]", "\n", "for", "line", "in", "tqdm", "(", "lines", ",", "desc", "=", "f'reading `{os.path.basename(path)}`...'", ")", ":", "\n", "# example:", "\n", "#          My O", "\n", "#          name O", "\n", "#          is O", "\n", "#          Hicham B-PER", "\n", "#          . O", "\n", "            ", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "splitline", ":", "\n", "                ", "token", ",", "label", "=", "splitline", "\n", "token_sequence", ".", "append", "(", "token", ")", "\n", "label_sequence", ".", "append", "(", "label", ")", "\n", "", "else", ":", "\n", "                ", "examples", ".", "append", "(", "\n", "SequenceLabellingExample", "(", "\n", "id", "=", "i", ",", "\n", "token_sequence", "=", "token_sequence", ",", "\n", "label_sequence", "=", "label_sequence", ",", "\n", ")", "\n", ")", "\n", "i", "+=", "1", "\n", "token_sequence", "=", "[", "]", "\n", "label_sequence", "=", "[", "]", "\n", "\n", "# Don't forget to add the last example", "\n", "", "", "", "if", "token_sequence", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "SequenceLabellingExample", "(", "\n", "id", "=", "i", ",", "\n", "token_sequence", "=", "token_sequence", ",", "\n", "label_sequence", "=", "label_sequence", ",", "\n", ")", "\n", ")", "\n", "\n", "", "retokenize", "(", "\n", "examples", ",", "\n", "tokenization_function", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", ".", "tokenize", ")", "\n", "logging", ".", "info", "(", "'Number of `%s` examples: %d'", ",", "step", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "", ""]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.download_file_from_google_drive": [[23, 36], ["requests.Session", "requests.Session.get", "download.get_confirm_token", "download.save_response_content", "requests.Session.get"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.get_confirm_token", "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.save_response_content"], ["def", "download_file_from_google_drive", "(", "id", ",", "destination", ")", ":", "\n", "    ", "URL", "=", "\"https://docs.google.com/uc?export=download\"", "\n", "\n", "session", "=", "requests", ".", "Session", "(", ")", "\n", "\n", "response", "=", "session", ".", "get", "(", "URL", ",", "params", "=", "{", "'id'", ":", "id", "}", ",", "stream", "=", "True", ")", "\n", "token", "=", "get_confirm_token", "(", "response", ")", "\n", "\n", "if", "token", ":", "\n", "        ", "params", "=", "{", "'id'", ":", "id", ",", "'confirm'", ":", "token", "}", "\n", "response", "=", "session", ".", "get", "(", "URL", ",", "params", "=", "params", ",", "stream", "=", "True", ")", "\n", "\n", "", "save_response_content", "(", "response", ",", "destination", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.get_confirm_token": [[37, 43], ["response.cookies.items", "key.startswith"], "function", ["None"], ["", "def", "get_confirm_token", "(", "response", ")", ":", "\n", "    ", "for", "key", ",", "value", "in", "response", ".", "cookies", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "'download_warning'", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.save_response_content": [[44, 51], ["open", "response.iter_content", "f.write"], "function", ["None"], ["", "def", "save_response_content", "(", "response", ",", "destination", ")", ":", "\n", "    ", "CHUNK_SIZE", "=", "32768", "\n", "\n", "with", "open", "(", "destination", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "for", "chunk", "in", "response", ".", "iter_content", "(", "CHUNK_SIZE", ")", ":", "\n", "            ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "                ", "f", ".", "write", "(", "chunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.download_model": [[52, 86], ["os.path.exists", "os.path.join", "logging.info", "logging.info", "os.makedirs", "logging.info", "os.path.join", "logging.info", "urls.items", "os.path.join", "logging.info", "download.download_file_from_google_drive", "logging.info", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "logging.info", "os.remove", "os.path.join", "requests.get", "MODEL_TO_URL[].split", "os.path.join", "os.path.basename().split", "open", "f.write", "os.path.dirname", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.download_file_from_google_drive"], ["", "", "", "", "def", "download_model", "(", "name", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "name", ")", ")", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Path {os.path.join('pretrained-models', name)} already exists.\"", ")", "\n", "logging", ".", "info", "(", "f'Skipped download of {name} model.'", ")", "\n", "", "else", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "name", ")", ",", "exist_ok", "=", "False", ")", "\n", "if", "name", "==", "'bert-base-uncased'", ":", "\n", "            ", "urls", "=", "{", "\n", "'model'", ":", "'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin'", ",", "\n", "'vocabulary'", ":", "'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt'", ",", "\n", "'config'", ":", "'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json'", "\n", "}", "\n", "logging", ".", "info", "(", "f'Downloading {name} model (~420MB folder)'", ")", "\n", "for", "_", ",", "url", "in", "urls", ".", "items", "(", ")", ":", "\n", "                ", "file_name", "=", "os", ".", "path", ".", "basename", "(", "url", ")", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "file_destination", "=", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "name", ",", "file_name", ")", "\n", "response", "=", "requests", ".", "get", "(", "url", ")", "\n", "with", "open", "(", "file_destination", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "response", ".", "content", ")", "\n", "", "", "", "else", ":", "\n", "            ", "file_destination", "=", "os", ".", "path", ".", "join", "(", "'pretrained-models'", ",", "'model.tar.xz'", ")", "\n", "file_id", "=", "MODEL_TO_URL", "[", "name", "]", ".", "split", "(", "'id='", ")", "[", "-", "1", "]", "\n", "\n", "logging", ".", "info", "(", "f'Downloading {name} model (~200MB tar.xz archive)'", ")", "\n", "download_file_from_google_drive", "(", "file_id", ",", "file_destination", ")", "\n", "\n", "logging", ".", "info", "(", "'Extracting model from archive (~420MB folder)'", ")", "\n", "tar", "=", "tarfile", ".", "open", "(", "file_destination", ",", "\"r:xz\"", ")", "\n", "tar", ".", "extractall", "(", "path", "=", "os", ".", "path", ".", "dirname", "(", "file_destination", ")", ")", "\n", "tar", ".", "close", "(", ")", "\n", "\n", "logging", ".", "info", "(", "'Removing archive'", ")", "\n", "os", ".", "remove", "(", "file_destination", ")", "\n", "", "logging", ".", "info", "(", "'Done.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.main": [[87, 103], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "download.download_model", "list", "download.download_model", "list", "MODEL_TO_URL.keys", "MODEL_TO_URL.keys"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.None.main.parse_args", "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.download_model", "home.repos.pwc.inspect_result.helboukkouri_character-bert.None.download.download_model"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "list", "(", "MODEL_TO_URL", ".", "keys", "(", ")", ")", "+", "[", "'bert-base-uncased'", ",", "'all'", "]", ",", "\n", "help", "=", "\"A keyword for downloading a specific pre-trained model\"", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "model", "==", "'all'", ":", "\n", "        ", "for", "model", "in", "list", "(", "MODEL_TO_URL", ".", "keys", "(", ")", ")", "+", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "download_model", "(", "name", "=", "model", ")", "\n", "", "", "else", ":", "\n", "        ", "download_model", "(", "name", "=", "args", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterMapper.__init__": [[97, 99], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokens_to_add", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "tokens_to_add", "=", "tokens_to_add", "or", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterMapper.convert_word_to_char_ids": [[100, 126], ["enumerate", "word.encode", "len"], "methods", ["None"], ["", "def", "convert_word_to_char_ids", "(", "self", ",", "word", ":", "str", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "if", "word", "in", "self", ".", "tokens_to_add", ":", "\n", "            ", "char_ids", "=", "[", "CharacterMapper", ".", "padding_character", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "CharacterMapper", ".", "beginning_of_word_character", "\n", "char_ids", "[", "1", "]", "=", "self", ".", "tokens_to_add", "[", "word", "]", "\n", "char_ids", "[", "2", "]", "=", "CharacterMapper", ".", "end_of_word_character", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "bos_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "beginning_of_sentence_characters", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "eos_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "end_of_sentence_characters", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "mask_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "mask_characters", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "pad_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "pad_characters", "\n", "", "else", ":", "\n", "            ", "word_encoded", "=", "word", ".", "encode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "[", "\n", ":", "(", "CharacterMapper", ".", "max_word_length", "-", "2", ")", "\n", "]", "\n", "char_ids", "=", "[", "CharacterMapper", ".", "padding_character", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "CharacterMapper", ".", "beginning_of_word_character", "\n", "for", "k", ",", "chr_id", "in", "enumerate", "(", "word_encoded", ",", "start", "=", "1", ")", ":", "\n", "                ", "char_ids", "[", "k", "]", "=", "chr_id", "\n", "", "char_ids", "[", "len", "(", "word_encoded", ")", "+", "1", "]", "=", "CharacterMapper", ".", "end_of_word_character", "\n", "\n", "# +1 one for masking", "\n", "", "return", "[", "c", "+", "1", "for", "c", "in", "char_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterMapper.__eq__": [[127, 131], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", "->", "bool", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.__init__": [[134, 136], ["character_cnn.CharacterMapper"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_mapper", "=", "CharacterMapper", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.tokens_to_indices": [[137, 139], ["character_cnn.CharacterIndexer._mapper.convert_word_to_char_ids"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterMapper.convert_word_to_char_ids"], ["", "def", "tokens_to_indices", "(", "self", ",", "tokens", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "        ", "return", "[", "self", ".", "_mapper", ".", "convert_word_to_char_ids", "(", "token", ")", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer._default_value_for_padding": [[140, 142], ["None"], "methods", ["None"], ["", "def", "_default_value_for_padding", "(", "self", ")", ":", "\n", "        ", "return", "[", "PADDING_VALUE", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.as_padded_tensor": [[143, 157], ["max", "character_cnn.CharacterIndexer.tokens_to_indices", "character_cnn.pad_sequence_to_length", "torch.LongTensor", "map"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.tokens_to_indices", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.pad_sequence_to_length"], ["", "def", "as_padded_tensor", "(", "self", ",", "batch", ":", "List", "[", "List", "[", "str", "]", "]", ",", "as_tensor", "=", "True", ",", "maxlen", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "maxlen", "is", "None", ":", "\n", "            ", "maxlen", "=", "max", "(", "map", "(", "len", ",", "batch", ")", ")", "\n", "", "batch_indices", "=", "[", "self", ".", "tokens_to_indices", "(", "tokens", ")", "for", "tokens", "in", "batch", "]", "\n", "padded_batch", "=", "[", "\n", "pad_sequence_to_length", "(", "\n", "indices", ",", "maxlen", ",", "\n", "default_value", "=", "self", ".", "_default_value_for_padding", ")", "\n", "for", "indices", "in", "batch_indices", "\n", "]", "\n", "if", "as_tensor", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "padded_batch", ")", "\n", "", "else", ":", "\n", "            ", "return", "padded_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn._make_bos_eos": [[11, 23], ["None"], "function", ["None"], ["def", "_make_bos_eos", "(", "\n", "character", ":", "int", ",", "\n", "padding_character", ":", "int", ",", "\n", "beginning_of_word_character", ":", "int", ",", "\n", "end_of_word_character", ":", "int", ",", "\n", "max_word_length", ":", "int", ")", ":", "\n", "\n", "    ", "char_ids", "=", "[", "padding_character", "]", "*", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "beginning_of_word_character", "\n", "char_ids", "[", "1", "]", "=", "character", "\n", "char_ids", "[", "2", "]", "=", "end_of_word_character", "\n", "return", "char_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.pad_sequence_to_length": [[25, 51], ["len", "default_value"], "function", ["None"], ["", "def", "pad_sequence_to_length", "(", "\n", "sequence", ":", "List", ",", "\n", "desired_length", ":", "int", ",", "\n", "default_value", ":", "Callable", "[", "[", "]", ",", "Any", "]", "=", "lambda", ":", "0", ",", "\n", "padding_on_right", ":", "bool", "=", "True", ",", "\n", ")", "->", "List", ":", "\n", "    ", "\"\"\"\n    Take a list of objects and pads it to the desired length, returning the padded list.\n    The original list is not modified.\n    \"\"\"", "\n", "\n", "# Truncates the sequence to the desired length.", "\n", "if", "padding_on_right", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", ":", "desired_length", "]", "\n", "", "else", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", "-", "desired_length", ":", "]", "\n", "# Continues to pad with default_value() until we reach the desired length.", "\n", "", "pad_length", "=", "desired_length", "-", "len", "(", "padded_sequence", ")", "\n", "# This just creates the default value once, so if it's a list, and if it gets mutated", "\n", "# later, it could cause subtle bugs. But the risk there is low, and this is much faster.", "\n", "values_to_pad", "=", "[", "default_value", "(", ")", "]", "*", "pad_length", "\n", "if", "padding_on_right", ":", "\n", "        ", "padded_sequence", "=", "padded_sequence", "+", "values_to_pad", "\n", "", "else", ":", "\n", "        ", "padded_sequence", "=", "values_to_pad", "+", "padded_sequence", "\n", "", "return", "padded_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.retokenize": [[15, 65], ["tqdm.tqdm", "enumerate", "example._replace._replace", "type", "new_tokens_a.extend", "example._replace._replace", "zip", "tokenization_function", "new_tokens_b.extend", "type", "len", "len", "tokenization_function", "example._replace._replace", "example._replace._replace", "example._replace._replace", "example._replace._replace", "tokenization_function", "new_tokens.extend", "new_labels.extend", "new_tokens.append", "new_labels.append", "label.split", "len", "len", "len"], "function", ["None"], ["'SequenceLabellingExample'", ",", "[", "'id'", ",", "'token_sequence'", ",", "'label_sequence'", "]", ")", "\n", "\n", "\n", "def", "load_classification_dataset", "(", "step", ",", "do_lower_case", ")", ":", "\n", "    ", "\"\"\" Loads classification exampels from a dataset. \"\"\"", "\n", "assert", "step", "in", "[", "'train'", ",", "'test'", "]", "\n", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "'classification'", ",", "f'{step}.txt'", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "data_file", ":", "\n", "        ", "lines", "=", "data_file", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "tqdm", "(", "enumerate", "(", "lines", ")", ",", "desc", "=", "f'reading `{os.path.basename(path)}`...'", ")", ":", "\n", "# example: __label__negative I don't like tomatoes.", "\n", "            ", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "splitline", "[", "0", "]", ".", "split", "(", "'__label__'", ")", "[", "-", "1", "]", "\n", "tokens", "=", "' '", ".", "join", "(", "splitline", "[", "1", ":", "]", ")", "\n", "examples", ".", "append", "(", "\n", "ClassificationExample", "(", "\n", "id", "=", "i", ",", "\n", "tokens_a", "=", "basic_tokenizer", ".", "tokenize", "(", "tokens", ")", ",", "\n", "tokens_b", "=", "None", ",", "\n", "label", "=", "label", ",", "\n", ")", "\n", ")", "\n", "", "", "logging", ".", "info", "(", "'Number of `%s` examples: %d'", ",", "step", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n", "", "def", "load_sequence_labelling_dataset", "(", "step", ",", "do_lower_case", ")", ":", "\n", "    ", "\"\"\" Loads sequence labelling examples from a dataset. \"\"\"", "\n", "assert", "step", "in", "[", "'train'", ",", "'test'", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "DATA_PATH", ",", "'sequence_labelling'", ",", "f'{step}.txt'", ")", "\n", "i", "=", "0", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "data_file", ":", "\n", "        ", "lines", "=", "data_file", ".", "readlines", "(", ")", "\n", "token_sequence", "=", "[", "]", "\n", "label_sequence", "=", "[", "]", "\n", "for", "line", "in", "tqdm", "(", "lines", ",", "desc", "=", "f'reading `{os.path.basename(path)}`...'", ")", ":", "\n", "# example:", "\n", "#          My O", "\n", "#          name O", "\n", "#          is O", "\n", "#          Hicham B-PER", "\n", "#          . O", "\n", "            ", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "splitline", ":", "\n", "                ", "token", ",", "label", "=", "splitline", "\n", "token_sequence", ".", "append", "(", "token", ")", "\n", "label_sequence", ".", "append", "(", "label", ")", "\n", "", "else", ":", "\n", "                ", "examples", ".", "append", "(", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data._truncate_seq_pair": [[67, 82], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["id", "=", "i", ",", "\n", "token_sequence", "=", "token_sequence", ",", "\n", "label_sequence", "=", "label_sequence", ",", "\n", ")", "\n", ")", "\n", "i", "+=", "1", "\n", "token_sequence", "=", "[", "]", "\n", "label_sequence", "=", "[", "]", "\n", "\n", "# Don't forget to add the last example", "\n", "", "", "", "if", "token_sequence", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "SequenceLabellingExample", "(", "\n", "id", "=", "i", ",", "\n", "token_sequence", "=", "token_sequence", ",", "\n", "label_sequence", "=", "label_sequence", ",", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.convert_examples_to_features__classification": [[84, 177], ["collections.namedtuple", "enumerate", "features.append", "enumerate", "data._truncate_seq_pair", "len", "len", "tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "collections.namedtuple.", "len", "len", "len", "tokenizer.as_padded_tensor", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data._truncate_seq_pair", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.as_padded_tensor"], [")", "\n", "\n", "", "retokenize", "(", "\n", "examples", ",", "\n", "tokenization_function", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", ".", "tokenize", ")", "\n", "logging", ".", "info", "(", "'Number of `%s` examples: %d'", ",", "step", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "", ""]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.convert_examples_to_features__tagging": [[179, 280], ["collections.namedtuple", "tqdm.tqdm", "enumerate", "zip", "features.append", "enumerate", "len", "token.startswith", "len", "len", "tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "len", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "collections.namedtuple.", "label_ids.append", "label_ids.append", "tokenizer.as_padded_tensor", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.character_cnn.CharacterIndexer.as_padded_tensor"], []], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.data.build_features": [[282, 310], ["logging.info", "func", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "f.input_ids.tolist"], "function", ["None"], []], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.misc.set_seed": [[8, 16], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "logging.info", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "seed_value", ")", ":", "\n", "    ", "\"\"\" Sets the random seed to a given value. \"\"\"", "\n", "random", ".", "seed", "(", "seed_value", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_value", ")", "\n", "torch", ".", "manual_seed", "(", "seed_value", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed_value", ")", "\n", "", "logging", ".", "info", "(", "\"Random seed: %d\"", ",", "seed_value", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.train": [[21, 144], ["torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "model.zero_grad", "tqdm.trange", "utils.misc.set_seed", "len", "len", "int", "tqdm.tqdm", "enumerate", "int", "model.train", "tuple", "model", "loss.backward", "loss.item", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "model.zero_grad", "model.named_parameters", "model.named_parameters", "any", "t.to", "model.parameters", "training.evaluate", "any", "model.save_pretrained", "torch.save", "logging.info", "os.path.exists", "os.makedirs", "tokenizer.save_pretrained", "os.path.join"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.misc.set_seed", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.train", "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.evaluate"], ["def", "train", "(", "args", ",", "dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Trains the given model on the given dataset. \"\"\"", "\n", "\n", "train_dataset", "=", "dataset", "[", "'train'", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "n_train_steps__single_epoch", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "\n", "n_train_steps", "=", "n_train_steps__single_epoch", "*", "args", ".", "num_train_epochs", "\n", "args", ".", "logging_steps", "=", "n_train_steps__single_epoch", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "int", "(", "args", ".", "warmup_ratio", "*", "n_train_steps", ")", ",", "\n", "num_training_steps", "=", "n_train_steps", "\n", ")", "\n", "\n", "# Train!", "\n", "logging", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logging", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logging", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logging", ".", "info", "(", "\n", "\"  Total train batch size (w. accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "logging", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logging", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "n_train_steps", ")", "\n", "logging", ".", "info", "(", "\"  Using linear warmup (ratio=%s)\"", ",", "args", ".", "warmup_ratio", ")", "\n", "logging", ".", "info", "(", "\"  Using weight decay (value=%s)\"", ",", "args", ".", "weight_decay", ")", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_metric", ",", "best_epoch", "=", "-", "1.0", ",", "-", "1", "# Init best -1 so that 0 > best", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "tqdm", ".", "trange", "(", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", "\n", "\n", "set_seed", "(", "seed_value", "=", "args", ".", "seed", ")", "# Added here for reproductibility", "\n", "for", "num_epoch", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", ".", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "# -- Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "results", ",", "_", "=", "evaluate", "(", "\n", "args", "=", "args", ",", "\n", "eval_dataset", "=", "dataset", "[", "\"validation\"", "]", ",", "\n", "model", "=", "model", ",", "labels", "=", "labels", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "\n", "logging_loss", "=", "tr_loss", "\n", "metric", "=", "results", "[", "'f1'", "]", "\n", "\n", "if", "metric", ">", "best_metric", ":", "\n", "                        ", "best_metric", "=", "metric", "\n", "best_epoch", "=", "num_epoch", "\n", "\n", "# Save model checkpoint", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "model", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "if", "'character'", "not", "in", "args", ".", "embedding", ":", "\n", "                            ", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logging", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "\n", "#torch.save(optimizer.state_dict(), os.path.join(args.output_dir, \"optimizer.pt\"))", "\n", "#torch.save(scheduler.state_dict(), os.path.join(args.output_dir, \"scheduler.pt\"))", "\n", "#logging.info(\"Saving optimizer and scheduler states to %s\", args.output_dir)", "\n", "\n", "", "", "", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_metric", ",", "best_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.utils.training.evaluate": [[146, 220], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logging.info", "logging.info", "logging.info", "model.eval", "tqdm.tqdm", "logging.info", "sorted", "len", "tuple", "numpy.argmax", "numpy.argmax", "range", "results.keys", "logging.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "sklearn.precision_score", "sklearn.recall_score", "sklearn.f1_score", "sklearn.accuracy_score", "range", "metrics.precision_score", "metrics.recall_score", "metrics.f1_score", "str", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "range", "range", "logits.detach().cpu", "inputs[].detach().cpu", "out_label_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.precision_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.recall_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.f1_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.accuracy_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.precision_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.recall_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.f1_score"], ["", "def", "evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Evaluates the given model on the given dataset. \"\"\"", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "\n", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Evaluate!", "\n", "logging", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logging", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "tqdm", ".", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "if", "args", ".", "task", "==", "'classification'", ":", "\n", "        ", "preds_list", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "results", "=", "{", "\n", "\"loss\"", ":", "eval_loss", ",", "\n", "\"precision\"", ":", "sklearn_metrics", ".", "precision_score", "(", "out_label_ids", ",", "preds_list", ",", "average", "=", "'micro'", ")", ",", "\n", "\"recall\"", ":", "sklearn_metrics", ".", "recall_score", "(", "out_label_ids", ",", "preds_list", ",", "average", "=", "'micro'", ")", ",", "\n", "\"f1\"", ":", "sklearn_metrics", ".", "f1_score", "(", "out_label_ids", ",", "preds_list", ",", "average", "=", "'micro'", ")", ",", "\n", "\"accuracy\"", ":", "sklearn_metrics", ".", "accuracy_score", "(", "out_label_ids", ",", "preds_list", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "        ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "2", ")", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "preds_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                    ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "preds_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "preds", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "", "", "results", "=", "{", "\n", "\"loss\"", ":", "eval_loss", ",", "\n", "\"precision\"", ":", "seqeval_metrics", ".", "precision_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"recall\"", ":", "seqeval_metrics", ".", "recall_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"f1\"", ":", "seqeval_metrics", ".", "f1_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "}", "\n", "\n", "", "logging", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", ",", "preds_list", "\n", "", ""]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.Highway.__init__": [[36, 54], ["super().__init__", "torch.nn.ModuleList", "layer.bias[].data.fill_", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.__init__"], ["# Truncates the sequence to the desired length.", "\n", "if", "padding_on_right", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", ":", "desired_length", "]", "\n", "", "else", ":", "\n", "        ", "padded_sequence", "=", "sequence", "[", "-", "desired_length", ":", "]", "\n", "# Continues to pad with default_value() until we reach the desired length.", "\n", "", "pad_length", "=", "desired_length", "-", "len", "(", "padded_sequence", ")", "\n", "# This just creates the default value once, so if it's a list, and if it gets mutated", "\n", "# later, it could cause subtle bugs. But the risk there is low, and this is much faster.", "\n", "values_to_pad", "=", "[", "default_value", "(", ")", "]", "*", "pad_length", "\n", "if", "padding_on_right", ":", "\n", "        ", "padded_sequence", "=", "padded_sequence", "+", "values_to_pad", "\n", "", "else", ":", "\n", "        ", "padded_sequence", "=", "values_to_pad", "+", "padded_sequence", "\n", "", "return", "padded_sequence", "\n", "\n", "\n", "", "class", "CharacterMapper", ":", "\n", "    "]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.Highway.forward": [[55, 67], ["layer", "layer.chunk", "character_cnn.Highway._activation", "torch.sigmoid"], "methods", ["None"], ["\n", "\n", "max_word_length", "=", "50", "\n", "\n", "# char ids 0-255 come from utf-8 encoding bytes", "\n", "# assign 256-300 to special chars", "\n", "beginning_of_sentence_character", "=", "256", "# <begin sentence>", "\n", "end_of_sentence_character", "=", "257", "# <end sentence>", "\n", "beginning_of_word_character", "=", "258", "# <begin word>", "\n", "end_of_word_character", "=", "259", "# <end word>", "\n", "padding_character", "=", "260", "# <padding>", "\n", "mask_character", "=", "261", "# <mask>", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN.__init__": [[74, 108], ["super().__init__", "character_cnn.CharacterCNN._init_weights", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.__init__", "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_weights"], ["max_word_length", ",", "\n", ")", "\n", "end_of_sentence_characters", "=", "_make_bos_eos", "(", "\n", "end_of_sentence_character", ",", "\n", "padding_character", ",", "\n", "beginning_of_word_character", ",", "\n", "end_of_word_character", ",", "\n", "max_word_length", ",", "\n", ")", "\n", "mask_characters", "=", "_make_bos_eos", "(", "\n", "mask_character", ",", "\n", "padding_character", ",", "\n", "beginning_of_word_character", ",", "\n", "end_of_word_character", ",", "\n", "max_word_length", ",", "\n", ")", "\n", "pad_characters", "=", "[", "PADDING_VALUE", "-", "1", "]", "*", "max_word_length", "\n", "\n", "bos_token", "=", "\"[CLS]\"", "\n", "eos_token", "=", "\"[SEP]\"", "\n", "pad_token", "=", "\"[PAD]\"", "\n", "mask_token", "=", "\"[MASK]\"", "\n", "\n", "def", "__init__", "(", "self", ",", "tokens_to_add", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "self", ".", "tokens_to_add", "=", "tokens_to_add", "or", "{", "}", "\n", "\n", "", "def", "convert_word_to_char_ids", "(", "self", ",", "word", ":", "str", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "if", "word", "in", "self", ".", "tokens_to_add", ":", "\n", "            ", "char_ids", "=", "[", "CharacterMapper", ".", "padding_character", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "CharacterMapper", ".", "beginning_of_word_character", "\n", "char_ids", "[", "1", "]", "=", "self", ".", "tokens_to_add", "[", "word", "]", "\n", "char_ids", "[", "2", "]", "=", "CharacterMapper", ".", "end_of_word_character", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "bos_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "beginning_of_sentence_characters", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "eos_token", ":", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_weights": [[110, 115], ["character_cnn.CharacterCNN._init_char_embedding", "character_cnn.CharacterCNN._init_cnn_weights", "character_cnn.CharacterCNN._init_highway", "character_cnn.CharacterCNN._init_projection"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_char_embedding", "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_cnn_weights", "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_highway", "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_projection"], ["", "elif", "word", "==", "CharacterMapper", ".", "mask_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "mask_characters", "\n", "", "elif", "word", "==", "CharacterMapper", ".", "pad_token", ":", "\n", "            ", "char_ids", "=", "CharacterMapper", ".", "pad_characters", "\n", "", "else", ":", "\n", "            ", "word_encoded", "=", "word", ".", "encode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "[", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_char_embedding": [[116, 126], ["numpy.zeros", "torch.nn.Parameter", "torch.FloatTensor"], "methods", ["None"], [":", "(", "CharacterMapper", ".", "max_word_length", "-", "2", ")", "\n", "]", "\n", "char_ids", "=", "[", "CharacterMapper", ".", "padding_character", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "char_ids", "[", "0", "]", "=", "CharacterMapper", ".", "beginning_of_word_character", "\n", "for", "k", ",", "chr_id", "in", "enumerate", "(", "word_encoded", ",", "start", "=", "1", ")", ":", "\n", "                ", "char_ids", "[", "k", "]", "=", "chr_id", "\n", "", "char_ids", "[", "len", "(", "word_encoded", ")", "+", "1", "]", "=", "CharacterMapper", ".", "end_of_word_character", "\n", "\n", "# +1 one for masking", "\n", "", "return", "[", "c", "+", "1", "for", "c", "in", "char_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_cnn_weights": [[128, 143], ["enumerate", "torch.nn.Conv1d", "convolutions.append", "character_cnn.CharacterCNN.add_module"], "methods", ["None"], ["        ", "if", "isinstance", "(", "self", ",", "other", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "", "return", "NotImplemented", "\n", "\n", "\n", "", "", "class", "CharacterIndexer", ":", "\n", "    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_mapper", "=", "CharacterMapper", "(", ")", "\n", "\n", "", "def", "tokens_to_indices", "(", "self", ",", "tokens", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "        ", "return", "[", "self", ".", "_mapper", ".", "convert_word_to_char_ids", "(", "token", ")", "for", "token", "in", "tokens", "]", "\n", "\n", "", "def", "_default_value_for_padding", "(", "self", ")", ":", "\n", "        ", "return", "[", "PADDING_VALUE", "]", "*", "CharacterMapper", ".", "max_word_length", "\n", "\n", "", "def", "as_padded_tensor", "(", "self", ",", "batch", ":", "List", "[", "List", "[", "str", "]", "]", ",", "as_tensor", "=", "True", ",", "maxlen", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_highway": [[144, 157], ["sum", "character_cnn.Highway", "range"], "methods", ["None"], ["        ", "if", "maxlen", "is", "None", ":", "\n", "            ", "maxlen", "=", "max", "(", "map", "(", "len", ",", "batch", ")", ")", "\n", "", "batch_indices", "=", "[", "self", ".", "tokens_to_indices", "(", "tokens", ")", "for", "tokens", "in", "batch", "]", "\n", "padded_batch", "=", "[", "\n", "pad_sequence_to_length", "(", "\n", "indices", ",", "maxlen", ",", "\n", "default_value", "=", "self", ".", "_default_value_for_padding", ")", "\n", "for", "indices", "in", "batch_indices", "\n", "]", "\n", "if", "as_tensor", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "padded_batch", ")", "\n", "", "else", ":", "\n", "            ", "return", "padded_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN._init_projection": [[158, 165], ["sum", "torch.nn.Linear"], "methods", ["None"], ["\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "inputs", "=", "[", "\n", "'[CLS] hi [PAD] [SEP]'", ".", "split", "(", ")", ",", "\n", "'[CLS] hello , my [MASK] is hicham [SEP]'", ".", "split", "(", ")", "\n", "]", "\n", "output", "=", "CharacterIndexer", "(", ")", ".", "as_padded_tensor", "(", "inputs", ")", "\n", "print", "(", "'input:'", ",", "inputs", ")", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN.get_output_dim": [[166, 168], ["None"], "methods", ["None"], ["print", "(", "'output.shape:'", ",", "output", ".", "shape", ")", "\n", "print", "(", "'output:'", ",", "output", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_cnn.CharacterCNN.forward": [[169, 229], ["torch.nn.functional.embedding", "torch.transpose", "range", "torch.cat", "character_cnn.CharacterCNN._highways", "character_cnn.CharacterCNN._projection", "character_ids_with_bos_eos.size", "character_cnn.CharacterCNN.view", "character_ids_with_bos_eos.view", "len", "getattr", "getattr.", "torch.max", "activation", "convs.append", "Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.BertCharacterEmbeddings.__init__": [[14, 29], ["torch.nn.Module.__init__", "modeling.character_cnn.CharacterCNN", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertCharacterEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# This is the module that computes word embeddings from a token's characters", "\n", "self", ".", "word_embeddings", "=", "CharacterCNN", "(", "\n", "requires_grad", "=", "True", ",", "\n", "output_dim", "=", "config", ".", "hidden_size", ")", "\n", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.BertCharacterEmbeddings.forward": [[30, 46], ["input_ids[].size", "character_bert.BertCharacterEmbeddings.word_embeddings", "character_bert.BertCharacterEmbeddings.position_embeddings", "character_bert.BertCharacterEmbeddings.token_type_embeddings", "character_bert.BertCharacterEmbeddings.LayerNorm", "character_bert.BertCharacterEmbeddings.dropout", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", "[", ":", ",", ":", ",", "0", "]", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", "[", ":", ",", ":", ",", "0", "]", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.__init__": [[51, 60], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "character_bert.BertCharacterEmbeddings", "transformers.modeling_bert.BertEncoder", "transformers.modeling_bert.BertPooler", "character_bert.CharacterBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "BertCharacterEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.get_input_embeddings": [[61, 63], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.set_input_embeddings": [[64, 66], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel._prune_heads": [[67, 70], ["heads_to_prune.items", "character_bert.CharacterBertModel.encoder.layer[].attention.prune_heads"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.modeling.character_bert.CharacterBertModel.forward": [[71, 196], ["extended_attention_mask.to.to.to", "character_bert.CharacterBertModel.embeddings", "character_bert.CharacterBertModel.encoder", "character_bert.CharacterBertModel.pooler", "ValueError", "torch.ones", "torch.zeros", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids[].size", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "character_bert.CharacterBertModel.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "character_bert.CharacterBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "character_bert.CharacterBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", "[", ":", ",", ":", ",", "0", "]", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "\n", "attention_mask", ".", "dtype", "\n", ")", "# causal and attention masks must have same type with pytorch version < 1.3", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities": [[16, 55], ["any", "enumerate", "sequence_labelling.end_of_chunk", "sequence_labelling.start_of_chunk", "isinstance", "chunks.append", "chunk.split", "chunk.split"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.end_of_chunk", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.start_of_chunk"], ["def", "get_entities", "(", "seq", ",", "suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Gets entities from sequence.\n\n    Args:\n        seq (list): sequence of labels.\n\n    Returns:\n        list: list of (chunk_type, chunk_start, chunk_end).\n\n    Example:\n        >>> from seqeval.metrics.sequence_labeling import get_entities\n        >>> seq = ['B-PER', 'I-PER', 'O', 'B-LOC']\n        >>> get_entities(seq)\n        [('PER', 0, 1), ('LOC', 3, 3)]\n    \"\"\"", "\n", "# for nested list", "\n", "if", "any", "(", "isinstance", "(", "s", ",", "list", ")", "for", "s", "in", "seq", ")", ":", "\n", "        ", "seq", "=", "[", "item", "for", "sublist", "in", "seq", "for", "item", "in", "sublist", "+", "[", "'O'", "]", "]", "\n", "\n", "", "prev_tag", "=", "'O'", "\n", "prev_type", "=", "''", "\n", "begin_offset", "=", "0", "\n", "chunks", "=", "[", "]", "\n", "for", "i", ",", "chunk", "in", "enumerate", "(", "seq", "+", "[", "'O'", "]", ")", ":", "\n", "        ", "if", "suffix", ":", "\n", "            ", "tag", "=", "chunk", "[", "-", "1", "]", "\n", "type_", "=", "chunk", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "tag", "=", "chunk", "[", "0", "]", "\n", "type_", "=", "chunk", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "\n", "", "if", "end_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "            ", "chunks", ".", "append", "(", "(", "prev_type", ",", "begin_offset", ",", "i", "-", "1", ")", ")", "\n", "", "if", "start_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "            ", "begin_offset", "=", "i", "\n", "", "prev_tag", "=", "tag", "\n", "prev_type", "=", "type_", "\n", "\n", "", "return", "chunks", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.end_of_chunk": [[57, 85], ["None"], "function", ["None"], ["", "def", "end_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "    ", "\"\"\"Checks if a chunk ended between the previous and current word.\n\n    Args:\n        prev_tag: previous chunk tag.\n        tag: current chunk tag.\n        prev_type: previous type.\n        type_: current type.\n\n    Returns:\n        chunk_end: boolean.\n    \"\"\"", "\n", "chunk_end", "=", "False", "\n", "\n", "if", "prev_tag", "==", "'E'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'S'", ":", "chunk_end", "=", "True", "\n", "\n", "if", "prev_tag", "==", "'B'", "and", "tag", "==", "'B'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'B'", "and", "tag", "==", "'S'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'B'", "and", "tag", "==", "'O'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'I'", "and", "tag", "==", "'B'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'I'", "and", "tag", "==", "'S'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'I'", "and", "tag", "==", "'O'", ":", "chunk_end", "=", "True", "\n", "\n", "if", "prev_tag", "!=", "'O'", "and", "prev_tag", "!=", "'.'", "and", "prev_type", "!=", "type_", ":", "\n", "        ", "chunk_end", "=", "True", "\n", "\n", "", "return", "chunk_end", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.start_of_chunk": [[87, 115], ["None"], "function", ["None"], ["", "def", "start_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "    ", "\"\"\"Checks if a chunk started between the previous and current word.\n\n    Args:\n        prev_tag: previous chunk tag.\n        tag: current chunk tag.\n        prev_type: previous type.\n        type_: current type.\n\n    Returns:\n        chunk_start: boolean.\n    \"\"\"", "\n", "chunk_start", "=", "False", "\n", "\n", "if", "tag", "==", "'B'", ":", "chunk_start", "=", "True", "\n", "if", "tag", "==", "'S'", ":", "chunk_start", "=", "True", "\n", "\n", "if", "prev_tag", "==", "'E'", "and", "tag", "==", "'E'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'E'", "and", "tag", "==", "'I'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'S'", "and", "tag", "==", "'E'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'S'", "and", "tag", "==", "'I'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'O'", "and", "tag", "==", "'E'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'O'", "and", "tag", "==", "'I'", ":", "chunk_start", "=", "True", "\n", "\n", "if", "tag", "!=", "'O'", "and", "tag", "!=", "'.'", "and", "prev_type", "!=", "type_", ":", "\n", "        ", "chunk_start", "=", "True", "\n", "\n", "", "return", "chunk_start", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.f1_score": [[117, 153], ["set", "set", "len", "len", "len", "sequence_labelling.get_entities", "sequence_labelling.get_entities"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities"], ["", "def", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute the F1 score.\n\n    The F1 score can be interpreted as a weighted average of the precision and\n    recall, where an F1 score reaches its best value at 1 and worst score at 0.\n    The relative contribution of precision and recall to the F1 score are\n    equal. The formula for the F1 score is::\n\n        F1 = 2 * (precision * recall) / (precision + recall)\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a tagger.\n\n    Returns:\n        score : float.\n\n    Example:\n        >>> from seqeval.metrics import f1_score\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> f1_score(y_true, y_pred)\n        0.50\n    \"\"\"", "\n", "true_entities", "=", "set", "(", "get_entities", "(", "y_true", ",", "suffix", ")", ")", "\n", "pred_entities", "=", "set", "(", "get_entities", "(", "y_pred", ",", "suffix", ")", ")", "\n", "\n", "nb_correct", "=", "len", "(", "true_entities", "&", "pred_entities", ")", "\n", "nb_pred", "=", "len", "(", "pred_entities", ")", "\n", "nb_true", "=", "len", "(", "true_entities", ")", "\n", "\n", "p", "=", "nb_correct", "/", "nb_pred", "if", "nb_pred", ">", "0", "else", "0", "\n", "r", "=", "nb_correct", "/", "nb_true", "if", "nb_true", ">", "0", "else", "0", "\n", "score", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "p", "+", "r", ">", "0", "else", "0", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.accuracy_score": [[155, 186], ["any", "sum", "len", "isinstance", "zip"], "function", ["None"], ["", "def", "accuracy_score", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\"Accuracy classification score.\n\n    In multilabel classification, this function computes subset accuracy:\n    the set of labels predicted for a sample must *exactly* match the\n    corresponding set of labels in y_true.\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a tagger.\n\n    Returns:\n        score : float.\n\n    Example:\n        >>> from seqeval.metrics import accuracy_score\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> accuracy_score(y_true, y_pred)\n        0.80\n    \"\"\"", "\n", "if", "any", "(", "isinstance", "(", "s", ",", "list", ")", "for", "s", "in", "y_true", ")", ":", "\n", "        ", "y_true", "=", "[", "item", "for", "sublist", "in", "y_true", "for", "item", "in", "sublist", "]", "\n", "y_pred", "=", "[", "item", "for", "sublist", "in", "y_pred", "for", "item", "in", "sublist", "]", "\n", "\n", "", "nb_correct", "=", "sum", "(", "y_t", "==", "y_p", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", ")", "\n", "nb_true", "=", "len", "(", "y_true", ")", "\n", "\n", "score", "=", "nb_correct", "/", "nb_true", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.precision_score": [[188, 220], ["set", "set", "len", "len", "sequence_labelling.get_entities", "sequence_labelling.get_entities"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities"], ["", "def", "precision_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute the precision.\n\n    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n    true positives and ``fp`` the number of false positives. The precision is\n    intuitively the ability of the classifier not to label as positive a sample.\n\n    The best value is 1 and the worst value is 0.\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a tagger.\n\n    Returns:\n        score : float.\n\n    Example:\n        >>> from seqeval.metrics import precision_score\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> precision_score(y_true, y_pred)\n        0.50\n    \"\"\"", "\n", "true_entities", "=", "set", "(", "get_entities", "(", "y_true", ",", "suffix", ")", ")", "\n", "pred_entities", "=", "set", "(", "get_entities", "(", "y_pred", ",", "suffix", ")", ")", "\n", "\n", "nb_correct", "=", "len", "(", "true_entities", "&", "pred_entities", ")", "\n", "nb_pred", "=", "len", "(", "pred_entities", ")", "\n", "\n", "score", "=", "nb_correct", "/", "nb_pred", "if", "nb_pred", ">", "0", "else", "0", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.recall_score": [[222, 254], ["set", "set", "len", "len", "sequence_labelling.get_entities", "sequence_labelling.get_entities"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities"], ["", "def", "recall_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute the recall.\n\n    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n    true positives and ``fn`` the number of false negatives. The recall is\n    intuitively the ability of the classifier to find all the positive samples.\n\n    The best value is 1 and the worst value is 0.\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a tagger.\n\n    Returns:\n        score : float.\n\n    Example:\n        >>> from seqeval.metrics import recall_score\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> recall_score(y_true, y_pred)\n        0.50\n    \"\"\"", "\n", "true_entities", "=", "set", "(", "get_entities", "(", "y_true", ",", "suffix", ")", ")", "\n", "pred_entities", "=", "set", "(", "get_entities", "(", "y_pred", ",", "suffix", ")", ")", "\n", "\n", "nb_correct", "=", "len", "(", "true_entities", "&", "pred_entities", ")", "\n", "nb_true", "=", "len", "(", "true_entities", ")", "\n", "\n", "score", "=", "nb_correct", "/", "nb_true", "if", "nb_true", ">", "0", "else", "0", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.performance_measure": [[256, 287], ["dict", "any", "sum", "sum", "sum", "sum", "isinstance", "zip", "zip", "zip", "zip"], "function", ["None"], ["", "def", "performance_measure", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\"\n    Compute the performance metrics: TP, FP, FN, TN\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a tagger.\n\n    Returns:\n        performance_dict : dict\n\n    Example:\n        >>> from seqeval.metrics import performance_measure\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-ORG'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> performance_measure(y_true, y_pred)\n        (3, 3, 1, 4)\n    \"\"\"", "\n", "performace_dict", "=", "dict", "(", ")", "\n", "if", "any", "(", "isinstance", "(", "s", ",", "list", ")", "for", "s", "in", "y_true", ")", ":", "\n", "        ", "y_true", "=", "[", "item", "for", "sublist", "in", "y_true", "for", "item", "in", "sublist", "]", "\n", "y_pred", "=", "[", "item", "for", "sublist", "in", "y_pred", "for", "item", "in", "sublist", "]", "\n", "", "performace_dict", "[", "'TP'", "]", "=", "sum", "(", "y_t", "==", "y_p", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", "\n", "if", "(", "(", "y_t", "!=", "'O'", ")", "or", "(", "y_p", "!=", "'O'", ")", ")", ")", "\n", "performace_dict", "[", "'FP'", "]", "=", "sum", "(", "y_t", "!=", "y_p", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", ")", "\n", "performace_dict", "[", "'FN'", "]", "=", "sum", "(", "(", "(", "y_t", "!=", "'O'", ")", "and", "(", "y_p", "==", "'O'", ")", ")", "\n", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", ")", "\n", "performace_dict", "[", "'TN'", "]", "=", "sum", "(", "(", "y_t", "==", "y_p", "==", "'O'", ")", "\n", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", ")", "\n", "\n", "return", "performace_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.classification_report": [[289, 371], ["set", "set", "collections.defaultdict", "collections.defaultdict", "max", "head_fmt.format", "collections.defaultdict.items", "row_fmt.format", "row_fmt.format", "sequence_labelling.get_entities", "sequence_labelling.get_entities", "d1[].add", "max", "d2[].add", "len", "len", "len", "len", "row_fmt.format", "ps.append", "rs.append", "f1s.append", "s.append", "sequence_labelling.precision_score", "sequence_labelling.recall_score", "sequence_labelling.f1_score", "numpy.sum", "numpy.average", "numpy.average", "numpy.average", "numpy.sum", "len", "len"], "function", ["home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.get_entities", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.precision_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.recall_score", "home.repos.pwc.inspect_result.helboukkouri_character-bert.metrics.sequence_labelling.f1_score"], ["", "def", "classification_report", "(", "y_true", ",", "y_pred", ",", "digits", "=", "2", ",", "suffix", "=", "False", ")", ":", "\n", "    ", "\"\"\"Build a text report showing the main classification metrics.\n\n    Args:\n        y_true : 2d array. Ground truth (correct) target values.\n        y_pred : 2d array. Estimated targets as returned by a classifier.\n        digits : int. Number of digits for formatting output floating point values.\n\n    Returns:\n        report : string. Text summary of the precision, recall, F1 score for each class.\n\n    Examples:\n        >>> from seqeval.metrics import classification_report\n        >>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n        >>> print(classification_report(y_true, y_pred))\n                     precision    recall  f1-score   support\n        <BLANKLINE>\n               MISC       0.00      0.00      0.00         1\n                PER       1.00      1.00      1.00         1\n        <BLANKLINE>\n          micro avg       0.50      0.50      0.50         2\n          macro avg       0.50      0.50      0.50         2\n        <BLANKLINE>\n    \"\"\"", "\n", "true_entities", "=", "set", "(", "get_entities", "(", "y_true", ",", "suffix", ")", ")", "\n", "pred_entities", "=", "set", "(", "get_entities", "(", "y_pred", ",", "suffix", ")", ")", "\n", "\n", "name_width", "=", "0", "\n", "d1", "=", "defaultdict", "(", "set", ")", "\n", "d2", "=", "defaultdict", "(", "set", ")", "\n", "for", "e", "in", "true_entities", ":", "\n", "        ", "d1", "[", "e", "[", "0", "]", "]", ".", "add", "(", "(", "e", "[", "1", "]", ",", "e", "[", "2", "]", ")", ")", "\n", "name_width", "=", "max", "(", "name_width", ",", "len", "(", "e", "[", "0", "]", ")", ")", "\n", "", "for", "e", "in", "pred_entities", ":", "\n", "        ", "d2", "[", "e", "[", "0", "]", "]", ".", "add", "(", "(", "e", "[", "1", "]", ",", "e", "[", "2", "]", ")", ")", "\n", "\n", "", "last_line_heading", "=", "'macro avg'", "\n", "width", "=", "max", "(", "name_width", ",", "len", "(", "last_line_heading", ")", ",", "digits", ")", "\n", "\n", "headers", "=", "[", "\"precision\"", ",", "\"recall\"", ",", "\"f1-score\"", ",", "\"support\"", "]", "\n", "head_fmt", "=", "u'{:>{width}s} '", "+", "u' {:>9}'", "*", "len", "(", "headers", ")", "\n", "report", "=", "head_fmt", ".", "format", "(", "u''", ",", "*", "headers", ",", "width", "=", "width", ")", "\n", "report", "+=", "u'\\n\\n'", "\n", "\n", "row_fmt", "=", "u'{:>{width}s} '", "+", "u' {:>9.{digits}f}'", "*", "3", "+", "u' {:>9}\\n'", "\n", "\n", "ps", ",", "rs", ",", "f1s", ",", "s", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "type_name", ",", "true_entities", "in", "d1", ".", "items", "(", ")", ":", "\n", "        ", "pred_entities", "=", "d2", "[", "type_name", "]", "\n", "nb_correct", "=", "len", "(", "true_entities", "&", "pred_entities", ")", "\n", "nb_pred", "=", "len", "(", "pred_entities", ")", "\n", "nb_true", "=", "len", "(", "true_entities", ")", "\n", "\n", "p", "=", "nb_correct", "/", "nb_pred", "if", "nb_pred", ">", "0", "else", "0", "\n", "r", "=", "nb_correct", "/", "nb_true", "if", "nb_true", ">", "0", "else", "0", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "p", "+", "r", ">", "0", "else", "0", "\n", "\n", "report", "+=", "row_fmt", ".", "format", "(", "*", "[", "type_name", ",", "p", ",", "r", ",", "f1", ",", "nb_true", "]", ",", "width", "=", "width", ",", "digits", "=", "digits", ")", "\n", "\n", "ps", ".", "append", "(", "p", ")", "\n", "rs", ".", "append", "(", "r", ")", "\n", "f1s", ".", "append", "(", "f1", ")", "\n", "s", ".", "append", "(", "nb_true", ")", "\n", "\n", "", "report", "+=", "u'\\n'", "\n", "\n", "# compute averages", "\n", "report", "+=", "row_fmt", ".", "format", "(", "'micro avg'", ",", "\n", "precision_score", "(", "y_true", ",", "y_pred", ",", "suffix", "=", "suffix", ")", ",", "\n", "recall_score", "(", "y_true", ",", "y_pred", ",", "suffix", "=", "suffix", ")", ",", "\n", "f1_score", "(", "y_true", ",", "y_pred", ",", "suffix", "=", "suffix", ")", ",", "\n", "np", ".", "sum", "(", "s", ")", ",", "\n", "width", "=", "width", ",", "digits", "=", "digits", ")", "\n", "report", "+=", "row_fmt", ".", "format", "(", "last_line_heading", ",", "\n", "np", ".", "average", "(", "ps", ",", "weights", "=", "s", ")", ",", "\n", "np", ".", "average", "(", "rs", ",", "weights", "=", "s", ")", ",", "\n", "np", ".", "average", "(", "f1s", ",", "weights", "=", "s", ")", ",", "\n", "np", ".", "sum", "(", "s", ")", ",", "\n", "width", "=", "width", ",", "digits", "=", "digits", ")", "\n", "\n", "return", "report", "\n", "\n"]]}