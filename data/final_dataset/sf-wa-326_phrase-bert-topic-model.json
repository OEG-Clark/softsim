{"home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ParaphraseDataset.__init__": [[103, 106], ["torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", ")", ":", "\n", "        ", "self", ".", "concat_input", "=", "torch", ".", "cat", "(", "(", "phrase1_tensor", ",", "phrase2_tensor", ")", ",", "1", ")", "\n", "self", ".", "label", "=", "label_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ParaphraseDataset.__getitem__": [[107, 109], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "self", ".", "concat_input", "[", "index", "]", ",", "self", ".", "label", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ParaphraseDataset.__len__": [[110, 112], ["cls_utils.ParaphraseDataset.concat_input.size"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "concat_input", ".", "size", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.__init__": [[115, 131], ["pytorch_lightning.LightningModule.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", "=", "1536", ",", "train_dataset", "=", "None", ",", "valid_dataset", "=", "None", ",", "test_dataset", "=", "None", ")", ":", "\n", "        ", "super", "(", "ProbingModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Network layers", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "256", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "256", ",", "1", ")", "\n", "self", ".", "output", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "# Hyper-parameters, that we will auto-tune using lightning!", "\n", "self", ".", "lr", "=", "0.0001", "\n", "self", ".", "batch_size", "=", "200", "\n", "\n", "# datasets", "\n", "self", ".", "train_dataset", "=", "train_dataset", "\n", "self", ".", "valid_dataset", "=", "valid_dataset", "\n", "self", ".", "test_dataset", "=", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.forward": [[132, 138], ["cls_utils.ProbingModel.linear", "torch.relu", "torch.relu", "cls_utils.ProbingModel.linear2", "cls_utils.ProbingModel.output", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "linear", "(", "x", ")", "\n", "x1a", "=", "F", ".", "relu", "(", "x1", ")", "\n", "x2", "=", "self", ".", "linear2", "(", "x1a", ")", "\n", "output", "=", "self", ".", "output", "(", "x2", ")", "\n", "return", "reshape", "(", "output", ",", "(", "-", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.configure_optimizers": [[139, 141], ["torch.optim.Adam", "torch.optim.Adam", "cls_utils.ProbingModel.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.train_dataloader": [[142, 145], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.val_dataloader": [[146, 149], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "self", ".", "valid_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.test_dataloader": [[150, 153], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "self", ".", "test_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.compute_accuracy": [[155, 163], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "y_pred.float", "torch.sum", "torch.sum", "float", "torch.div", "torch.div", "torch.div", "torch.div", "y.size"], "methods", ["None"], ["", "def", "compute_accuracy", "(", "self", ",", "y_hat", ",", "y", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "y_pred", "=", "(", "y_hat", ">=", "0.5", ")", "\n", "y_pred_f", "=", "y_pred", ".", "float", "(", ")", "\n", "num_correct", "=", "tsum", "(", "y_pred_f", "==", "y", ")", "\n", "denom", "=", "float", "(", "y", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "accuracy", "=", "torch", ".", "div", "(", "num_correct", ",", "denom", ")", "\n", "", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.training_step": [[164, 173], ["cls_utils.ProbingModel.", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "cls_utils.ProbingModel.compute_accuracy", "cls_utils.ProbingModel.log", "cls_utils.ProbingModel.log"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.compute_accuracy"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mode", "=", "'train'", "\n", "x", ",", "y", "=", "batch", "\n", "y_hat", "=", "self", "(", "x", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy", "(", "y_hat", ",", "y", ")", "\n", "accuracy", "=", "self", ".", "compute_accuracy", "(", "y_hat", ",", "y", ")", "\n", "self", ".", "log", "(", "f'{mode}_loss'", ",", "loss", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "f'{mode}_accuracy'", ",", "accuracy", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "return", "{", "f'loss'", ":", "loss", ",", "f'{mode}_accuracy'", ":", "accuracy", ",", "'log'", ":", "{", "f'{mode}_loss'", ":", "loss", "}", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.training_epoch_end": [[175, 183], ["cls_utils.ProbingModel.log", "print", "cls_utils.ProbingModel.log", "print", "torch.sum", "torch.sum", "len", "torch.sum", "torch.sum", "len", "loss_mean.item", "accuracy_mean.item"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "mode", "=", "'train'", "\n", "loss_mean", "=", "sum", "(", "[", "o", "[", "f'loss'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "accuracy_mean", "=", "sum", "(", "[", "o", "[", "f'{mode}_accuracy'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_loss'", ",", "loss_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} loss is {loss_mean.item():.4f}'", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_accuracy'", ",", "accuracy_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} accuracy is {accuracy_mean.item():.4f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.validation_step": [[185, 194], ["cls_utils.ProbingModel.", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "cls_utils.ProbingModel.compute_accuracy", "cls_utils.ProbingModel.log", "cls_utils.ProbingModel.log"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.compute_accuracy"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mode", "=", "'val'", "\n", "x", ",", "y", "=", "batch", "\n", "y_hat", "=", "self", "(", "x", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy", "(", "y_hat", ",", "y", ")", "\n", "accuracy", "=", "self", ".", "compute_accuracy", "(", "y_hat", ",", "y", ")", "\n", "self", ".", "log", "(", "f'{mode}_loss'", ",", "loss", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "f'{mode}_accuracy'", ",", "accuracy", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "return", "{", "f'{mode}_loss'", ":", "loss", ",", "f'{mode}_accuracy'", ":", "accuracy", ",", "'log'", ":", "{", "f'{mode}_loss'", ":", "loss", "}", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.validation_epoch_end": [[196, 204], ["cls_utils.ProbingModel.log", "print", "cls_utils.ProbingModel.log", "print", "torch.sum", "torch.sum", "len", "torch.sum", "torch.sum", "len", "loss_mean.item", "accuracy_mean.item"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "mode", "=", "'val'", "\n", "loss_mean", "=", "sum", "(", "[", "o", "[", "f'{mode}_loss'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "accuracy_mean", "=", "sum", "(", "[", "o", "[", "f'{mode}_accuracy'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_loss'", ",", "loss_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} loss is {loss_mean.item():.4f}'", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_accuracy'", ",", "accuracy_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} accuracy is {accuracy_mean.item():.4f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.test_step": [[205, 214], ["cls_utils.ProbingModel.", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "cls_utils.ProbingModel.compute_accuracy", "cls_utils.ProbingModel.log", "cls_utils.ProbingModel.log"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.compute_accuracy"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mode", "=", "'test'", "\n", "x", ",", "y", "=", "batch", "\n", "y_hat", "=", "self", "(", "x", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy", "(", "y_hat", ",", "y", ")", "\n", "accuracy", "=", "self", ".", "compute_accuracy", "(", "y_hat", ",", "y", ")", "\n", "self", ".", "log", "(", "f'{mode}_loss'", ",", "loss", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "f'{mode}_accuracy'", ",", "accuracy", ",", "on_epoch", "=", "True", ",", "on_step", "=", "True", ")", "\n", "return", "{", "f'{mode}_loss'", ":", "loss", ",", "f'{mode}_accuracy'", ":", "accuracy", ",", "'log'", ":", "{", "f'{mode}_loss'", ":", "loss", "}", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.test_epoch_end": [[215, 223], ["cls_utils.ProbingModel.log", "print", "cls_utils.ProbingModel.log", "print", "torch.sum", "torch.sum", "len", "torch.sum", "torch.sum", "len", "loss_mean.item", "accuracy_mean.item"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "mode", "=", "'test'", "\n", "loss_mean", "=", "sum", "(", "[", "o", "[", "f'{mode}_loss'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "accuracy_mean", "=", "sum", "(", "[", "o", "[", "f'{mode}_accuracy'", "]", "for", "o", "in", "outputs", "]", ")", "/", "len", "(", "outputs", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_loss'", ",", "loss_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} loss is {loss_mean.item():.4f}'", ")", "\n", "self", ".", "log", "(", "f'epoch_{mode}_accuracy'", ",", "accuracy_mean", ",", "on_epoch", "=", "True", ",", "on_step", "=", "False", ")", "\n", "print", "(", "f'\\nThe end of epoch {mode} accuracy is {accuracy_mean.item():.4f}'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_data_emb": [[16, 52], ["utils.utils.load_model", "utils.utils.load_model.to", "print", "cls_utils.encode_in_batch", "cls_utils.encode_in_batch", "random.seed", "list", "random.shuffle", "zip", "torch.FloatTensor", "torch.FloatTensor", "cls_utils.get_glove_data_emb", "open", "json.load", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.encode_in_batch", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.encode_in_batch", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_glove_data_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load"], ["def", "get_data_emb", "(", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", ":", "\n", "    ", "if", "'glove'", "in", "model_path", ":", "\n", "        ", "return", "get_glove_data_emb", "(", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", "\n", "\n", "\n", "", "with", "open", "(", "data_fname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data_list", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "phrase1_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "data_list", "]", "\n", "phrase2_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "data_list", "]", "\n", "label", "=", "[", "item", "[", "2", "]", "for", "item", "in", "data_list", "]", "\n", "\n", "if", "not", "full_run_mode", ":", "\n", "        ", "subset_size", "=", "50", "\n", "phrase1_list", "=", "phrase1_list", "[", ":", "subset_size", "]", "\n", "phrase2_list", "=", "phrase2_list", "[", ":", "subset_size", "]", "\n", "label", "=", "label", "[", ":", "subset_size", "]", "\n", "\n", "", "model", "=", "load_model", "(", "model_path", ",", "device", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "print", "(", "device", ")", "\n", "emb_batch_size", "=", "8", "\n", "\n", "phrase1_emb_tensor_list", "=", "encode_in_batch", "(", "model", ",", "emb_batch_size", ",", "phrase1_list", ")", "\n", "phrase2_emb_tensor_list", "=", "encode_in_batch", "(", "model", ",", "emb_batch_size", ",", "phrase2_list", ")", "\n", "\n", "label_list", "=", "[", "1", "if", "e", "==", "'pos'", "else", "0", "for", "e", "in", "label", "]", "\n", "\n", "import", "random", "\n", "random", ".", "seed", "(", "42", ")", "\n", "combined", "=", "list", "(", "zip", "(", "phrase1_emb_tensor_list", ",", "phrase2_emb_tensor_list", ",", "label_list", ")", ")", "\n", "random", ".", "shuffle", "(", "combined", ")", "\n", "phrase1_emb_tensor_list_shuffled", ",", "phrase2_emb_tensor_list_shuffled", ",", "label_list_shuffled", "=", "zip", "(", "*", "combined", ")", "\n", "label_tensor", "=", "torch", ".", "FloatTensor", "(", "label_list_shuffled", ")", "\n", "\n", "return", "torch", ".", "stack", "(", "phrase1_emb_tensor_list_shuffled", ")", ",", "torch", ".", "stack", "(", "phrase2_emb_tensor_list_shuffled", ")", ",", "label_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_glove_data_emb": [[55, 92], ["utils.utils.load_model", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "random.seed", "list", "random.shuffle", "zip", "torch.FloatTensor", "torch.FloatTensor", "open", "json.load", "utils.glove_utils.get_phrase_emb", "emb_list.append", "utils.glove_utils.get_phrase_emb", "emb_list.append", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_phrase_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_phrase_emb"], ["", "def", "get_glove_data_emb", "(", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", ":", "\n", "    ", "with", "open", "(", "data_fname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data_list", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "phrase1_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "data_list", "]", "\n", "phrase2_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "data_list", "]", "\n", "label", "=", "[", "item", "[", "2", "]", "for", "item", "in", "data_list", "]", "\n", "\n", "if", "not", "full_run_mode", ":", "\n", "        ", "subset_size", "=", "50", "\n", "phrase1_list", "=", "phrase1_list", "[", ":", "subset_size", "]", "\n", "phrase2_list", "=", "phrase2_list", "[", ":", "subset_size", "]", "\n", "label", "=", "label", "[", ":", "subset_size", "]", "\n", "\n", "", "word2coef_dict", ",", "average_emb", "=", "load_model", "(", "model_path", ",", "device", ")", "\n", "\n", "emb_list", "=", "[", "]", "\n", "for", "term", "in", "phrase1_list", ":", "\n", "        ", "emb", "=", "get_phrase_emb", "(", "word2coef_dict", ",", "term", ",", "average_emb", ")", "\n", "emb_list", ".", "append", "(", "emb", ")", "\n", "", "phrase1_emb_tensor_list", "=", "torch", ".", "tensor", "(", "emb_list", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "emb_list", "=", "[", "]", "\n", "for", "term", "in", "phrase1_list", ":", "\n", "        ", "emb", "=", "get_phrase_emb", "(", "word2coef_dict", ",", "term", ",", "average_emb", ")", "\n", "emb_list", ".", "append", "(", "emb", ")", "\n", "", "phrase2_emb_tensor_list", "=", "torch", ".", "tensor", "(", "emb_list", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "label_list", "=", "[", "1", "if", "e", "==", "'pos'", "else", "0", "for", "e", "in", "label", "]", "\n", "\n", "import", "random", "\n", "random", ".", "seed", "(", "42", ")", "\n", "combined", "=", "list", "(", "zip", "(", "phrase1_emb_tensor_list", ",", "phrase2_emb_tensor_list", ",", "label_list", ")", ")", "\n", "random", ".", "shuffle", "(", "combined", ")", "\n", "phrase1_emb_tensor_list_shuffled", ",", "phrase2_emb_tensor_list_shuffled", ",", "label_list_shuffled", "=", "zip", "(", "*", "combined", ")", "\n", "label_tensor", "=", "torch", ".", "FloatTensor", "(", "label_list_shuffled", ")", "\n", "\n", "\n", "return", "torch", ".", "stack", "(", "phrase1_emb_tensor_list_shuffled", ")", ",", "torch", ".", "stack", "(", "phrase2_emb_tensor_list_shuffled", ")", ",", "label_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.encode_in_batch": [[93, 100], ["range", "len", "model.encode", "all_emb_tensor_list.extend"], "function", ["None"], ["", "def", "encode_in_batch", "(", "model", ",", "batch_size", ",", "text_list", ")", ":", "\n", "    ", "all_emb_tensor_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "text_list", ")", ",", "batch_size", ")", ":", "\n", "        ", "batch_text_list", "=", "text_list", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "batch_emb_list", "=", "model", ".", "encode", "(", "batch_text_list", ",", "batch_size", "=", "batch_size", ",", "convert_to_tensor", "=", "True", ",", "show_progress_bar", "=", "False", ")", "\n", "all_emb_tensor_list", ".", "extend", "(", "batch_emb_list", ")", "\n", "", "return", "all_emb_tensor_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.__init__": [[15, 36], ["torch.nn.Module.__init__", "sum"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "word_embedding_dimension", ":", "int", ",", "\n", "pooling_mode_cls_token", ":", "bool", "=", "False", ",", "\n", "pooling_mode_max_tokens", ":", "bool", "=", "False", ",", "\n", "pooling_mode_mean_tokens", ":", "bool", "=", "True", ",", "\n", "pooling_mode_mean_sqrt_len_tokens", ":", "bool", "=", "False", ",", "\n", "pooling_mode_span", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "spanPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config_keys", "=", "[", "'word_embedding_dimension'", ",", "'pooling_mode_cls_token'", ",", "'pooling_mode_mean_tokens'", ",", "'pooling_mode_max_tokens'", ",", "'pooling_mode_mean_sqrt_len_tokens'", "]", "\n", "\n", "self", ".", "word_embedding_dimension", "=", "word_embedding_dimension", "\n", "self", ".", "pooling_mode_cls_token", "=", "pooling_mode_cls_token", "\n", "self", ".", "pooling_mode_mean_tokens", "=", "pooling_mode_mean_tokens", "\n", "self", ".", "pooling_mode_max_tokens", "=", "pooling_mode_max_tokens", "\n", "self", ".", "pooling_mode_mean_sqrt_len_tokens", "=", "pooling_mode_mean_sqrt_len_tokens", "\n", "self", ".", "pooling_mode_span", "=", "pooling_mode_span", "\n", "\n", "pooling_mode_multiplier", "=", "sum", "(", "[", "pooling_mode_cls_token", ",", "pooling_mode_max_tokens", ",", "pooling_mode_mean_tokens", ",", "pooling_mode_mean_sqrt_len_tokens", "]", ")", "\n", "self", ".", "pooling_output_dimension", "=", "(", "pooling_mode_multiplier", "*", "word_embedding_dimension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.forward": [[37, 77], ["torch.cat", "features.update", "output_vectors.append", "attention_mask.unsqueeze().expand().float", "output_vectors.append", "attention_mask.unsqueeze().expand().float", "torch.sum", "torch.clamp", "torch.cat", "output_vectors.append", "torch.max", "features[].unsqueeze().expand", "attention_mask.unsqueeze().expand().float.sum", "output_vectors.append", "output_vectors.append", "attention_mask.unsqueeze().expand", "attention_mask.unsqueeze().expand", "torch.sum.size", "token_embeddings.size", "token_embeddings.size", "features[].unsqueeze", "torch.sqrt", "attention_mask.unsqueeze", "attention_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "token_embeddings", "=", "features", "[", "'token_embeddings'", "]", "\n", "cls_token", "=", "features", "[", "'cls_token_embeddings'", "]", "\n", "attention_mask", "=", "features", "[", "'attention_mask'", "]", "\n", "\n", "## Pooling strategy", "\n", "output_vectors", "=", "[", "]", "\n", "if", "self", ".", "pooling_mode_cls_token", ":", "\n", "            ", "output_vectors", ".", "append", "(", "cls_token", ")", "\n", "", "if", "self", ".", "pooling_mode_max_tokens", ":", "\n", "            ", "input_mask_expanded", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "token_embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "token_embeddings", "[", "input_mask_expanded", "==", "0", "]", "=", "-", "1e9", "# Set padding tokens to large negative value", "\n", "max_over_time", "=", "torch", ".", "max", "(", "token_embeddings", ",", "1", ")", "[", "0", "]", "\n", "output_vectors", ".", "append", "(", "max_over_time", ")", "\n", "", "if", "self", ".", "pooling_mode_mean_tokens", "or", "self", ".", "pooling_mode_mean_sqrt_len_tokens", ":", "\n", "            ", "input_mask_expanded", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "token_embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "sum_embeddings", "=", "torch", ".", "sum", "(", "token_embeddings", "*", "input_mask_expanded", ",", "1", ")", "\n", "\n", "#If tokens are weighted (by WordWeights layer), feature 'token_weights_sum' will be present", "\n", "if", "'token_weights_sum'", "in", "features", ":", "\n", "                ", "sum_mask", "=", "features", "[", "'token_weights_sum'", "]", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "sum_embeddings", ".", "size", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "sum_mask", "=", "input_mask_expanded", ".", "sum", "(", "1", ")", "\n", "\n", "", "sum_mask", "=", "torch", ".", "clamp", "(", "sum_mask", ",", "min", "=", "1e-9", ")", "\n", "\n", "if", "self", ".", "pooling_mode_mean_tokens", ":", "\n", "                ", "output_vectors", ".", "append", "(", "sum_embeddings", "/", "sum_mask", ")", "\n", "", "if", "self", ".", "pooling_mode_mean_sqrt_len_tokens", ":", "\n", "                ", "output_vectors", ".", "append", "(", "sum_embeddings", "/", "torch", ".", "sqrt", "(", "sum_mask", ")", ")", "\n", "\n", "", "", "if", "self", ".", "pooling_mode_span", ":", "\n", "            ", "last_emb", "=", "token_embeddings", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "# result = last_emb - cls_token", "\n", "concat", "=", "torch", ".", "cat", "(", "(", "cls_token", ",", "last_emb", ")", ",", "1", ")", "\n", "output_vectors", ".", "append", "(", "concat", ")", "\n", "\n", "", "output_vector", "=", "torch", ".", "cat", "(", "output_vectors", ",", "1", ")", "\n", "features", ".", "update", "(", "{", "'sentence_embedding'", ":", "output_vector", "}", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.find_last_emb": [[78, 82], ["None"], "methods", ["None"], ["", "def", "find_last_emb", "(", "token_emb", ",", "attention_mask", ")", ":", "\n", "\n", "\n", "        ", "return", "last_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.get_sentence_embedding_dimension": [[84, 86], ["None"], "methods", ["None"], ["", "def", "get_sentence_embedding_dimension", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pooling_output_dimension", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.get_config_dict": [[87, 89], ["None"], "methods", ["None"], ["", "def", "get_config_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "key", ":", "self", ".", "__dict__", "[", "key", "]", "for", "key", "in", "self", ".", "config_keys", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.save": [[90, 93], ["open", "json.dump", "os.path.join", "spanPooling.spanPooling.get_config_dict"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.get_config_dict"], ["", "def", "save", "(", "self", ",", "output_path", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "'config.json'", ")", ",", "'w'", ")", "as", "fOut", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "get_config_dict", "(", ")", ",", "fOut", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load": [[94, 100], ["Pooling", "open", "json.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load"], ["", "", "@", "staticmethod", "\n", "def", "load", "(", "input_path", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "input_path", ",", "'config.json'", ")", ")", "as", "fIn", ":", "\n", "            ", "config", "=", "json", ".", "load", "(", "fIn", ")", "\n", "\n", "", "return", "Pooling", "(", "**", "config", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_word_emb": [[4, 6], ["word2coef_dict.get"], "function", ["None"], ["def", "get_word_emb", "(", "word2coef_dict", ",", "word", ",", "default_value", ")", ":", "\n", "    ", "return", "word2coef_dict", ".", "get", "(", "word", ",", "default_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_phrase_emb": [[7, 11], ["phrase.split", "numpy.mean", "glove_utils.get_word_emb"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_word_emb"], ["", "def", "get_phrase_emb", "(", "word2coef_dict", ",", "phrase", ",", "default_value", ")", ":", "\n", "    ", "words", "=", "phrase", ".", "split", "(", "' '", ")", "\n", "embs", "=", "[", "get_word_emb", "(", "word2coef_dict", ",", "word", ",", "default_value", ")", "for", "word", "in", "words", "]", "\n", "return", "np", ".", "mean", "(", "embs", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.init_glove_data": [[12, 29], ["print", "numpy.zeros", "numpy.save", "print", "open", "enumerate", "open", "pickle.dump", "os.path.join", "os.path.join", "tqdm.tqdm", "line.split", "numpy.asarray", "os.path.join", "list"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.save"], ["", "def", "init_glove_data", "(", "glove_fname", ",", "glove_outname", ")", ":", "\n", "    ", "print", "(", "f'Constructing glove dictionary from {glove_fname} ...... '", ")", "\n", "word2coef_dict", "=", "{", "}", "\n", "running_sum", "=", "np", ".", "zeros", "(", "(", "300", ",", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "glove_fname", ")", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "tqdm", "(", "list", "(", "f", ")", ")", ")", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "''", ".", "join", "(", "values", "[", "0", ":", "-", "300", "]", ")", "\n", "coefs", "=", "np", ".", "asarray", "(", "values", "[", "-", "300", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "running_sum", "+=", "coefs", "\n", "word2coef_dict", "[", "word", "]", "=", "coefs", "\n", "", "average_emb", "=", "running_sum", "/", "(", "idx", "+", "1", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "glove_outname", ",", "'glove_dict.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "word2coef_dict", ",", "f", ")", "\n", "", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "glove_outname", ",", "'default_value'", ")", ",", "average_emb", ")", "\n", "print", "(", "f'Glove dictionary saved at {glove_outname}'", ")", "", "", ""]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model": [[17, 46], ["os.path.join", "os.path.join", "numpy.load", "sentence_transformers.models.Transformer", "sentence_transformers.models.Pooling", "sentence_transformers.SentenceTransformer", "utils.glove_utils.init_glove_data", "open", "pickle.load", "models.Transformer.get_word_embedding_dimension", "sentence_transformers.SentenceTransformer", "os.path.exists", "os.path.exists", "sentence_transformers.models.Transformer", "utils.spanPooling.spanPooling", "sentence_transformers.SentenceTransformer", "sentence_transformers.models.Transformer", "sentence_transformers.models.Pooling", "sentence_transformers.SentenceTransformer", "models.Transformer.get_word_embedding_dimension", "models.Transformer.get_word_embedding_dimension"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.init_glove_data", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.spanPooling.spanPooling.load"], ["def", "load_model", "(", "model_path", ",", "spanRep", "=", "False", ")", ":", "\n", "    ", "if", "'glove'", "in", "model_path", ":", "\n", "        ", "glove_dict_fname", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'glove_dict.pkl'", ")", "\n", "average_emb_fname", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'default_value.npy'", ")", "\n", "if", "not", "(", "os", ".", "path", ".", "exists", "(", "glove_dict_fname", ")", "and", "os", ".", "path", ".", "exists", "(", "average_emb_fname", ")", ")", ":", "\n", "# initialize the glove dictionary if never used", "\n", "            ", "init_glove_data", "(", "GLOVE_FILE_PATH", ",", "model_path", ")", "\n", "# glove model is loaded in the the form of a dictionary and a default value for oov", "\n", "", "with", "open", "(", "glove_dict_fname", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "word2coeff_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "average_emb", "=", "np", ".", "load", "(", "average_emb_fname", ")", "\n", "return", "word2coeff_dict", ",", "average_emb", "\n", "\n", "", "if", "model_path", "==", "'bert-base-uncased'", "or", "model_path", "==", "'bert-large-uncased'", ":", "\n", "        ", "word_embedding_model", "=", "models", ".", "Transformer", "(", "model_path", ")", "\n", "pooling_model", "=", "models", ".", "Pooling", "(", "word_embedding_model", ".", "get_word_embedding_dimension", "(", ")", ")", "\n", "model", "=", "SentenceTransformer", "(", "modules", "=", "[", "word_embedding_model", ",", "pooling_model", "]", ")", "\n", "", "elif", "'spanbert'", "in", "model_path", ":", "\n", "        ", "if", "spanRep", ":", "\n", "            ", "word_embedding_model", "=", "models", ".", "Transformer", "(", "model_path", ")", "\n", "pooling_model", "=", "spanPooling", "(", "word_embedding_model", ".", "get_word_embedding_dimension", "(", ")", ",", "pooling_mode_span", "=", "True", ")", "\n", "model", "=", "SentenceTransformer", "(", "modules", "=", "[", "word_embedding_model", ",", "pooling_model", "]", ")", "\n", "", "else", ":", "\n", "            ", "word_embedding_model", "=", "models", ".", "Transformer", "(", "model_path", ")", "\n", "pooling_model", "=", "models", ".", "Pooling", "(", "word_embedding_model", ".", "get_word_embedding_dimension", "(", ")", ")", "\n", "model", "=", "SentenceTransformer", "(", "modules", "=", "[", "word_embedding_model", ",", "pooling_model", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "model", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_ppdb_paws.main": [[32, 109], ["config.model_path.MODEL_PATH.items", "model_name_acc_dict.items", "print", "pytorch_lightning.callbacks.EarlyStopping", "utils.cls_utils.ProbingModel().to", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "pytorch_lightning.Trainer.test", "print", "os.path.join", "print", "print", "print", "config.model_path.MODEL_PATH.keys", "os.path.join", "utils.cls_utils.get_data_emb", "phrase1_tensor.to", "phrase2_tensor.to", "label_tensor.to", "math.ceil", "math.ceil", "utils.cls_utils.ParaphraseDataset", "utils.cls_utils.ParaphraseDataset", "utils.cls_utils.ParaphraseDataset", "open", "json.dump", "os.path.join", "utils.cls_utils.get_data_emb", "phrase1_tensor.to", "phrase2_tensor.to", "label_tensor.to", "utils.cls_utils.ParaphraseDataset", "os.path.join", "utils.cls_utils.get_data_emb", "phrase1_tensor.to", "phrase2_tensor.to", "label_tensor.to", "utils.cls_utils.ParaphraseDataset", "os.path.join", "utils.cls_utils.get_data_emb", "phrase1_tensor.to", "phrase2_tensor.to", "label_tensor.to", "utils.cls_utils.ParaphraseDataset", "print", "utils.cls_utils.ProbingModel", "ProbingModel().to.test_dataloader", "phrase1_tensor.size", "phrase1_tensor.size"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_data_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_data_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_data_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.get_data_emb", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.cls_utils.ProbingModel.test_dataloader"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "device", "=", "f'cuda:{args.device_id}'", "\n", "\n", "model_name_acc_dict", "=", "{", "\n", "k", ":", "0.0", "for", "k", "in", "MODEL_PATH", ".", "keys", "(", ")", "\n", "}", "\n", "for", "model_name", ",", "model_path", "in", "MODEL_PATH", ".", "items", "(", ")", ":", "\n", "        ", "if", "'ppdb'", "in", "args", ".", "task", ":", "\n", "# for ppdb dataset, we split the constructed the dataset and store the train / val / test splits in cache", "\n", "            ", "data_fname", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'examples.json'", ")", "\n", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", "=", "get_data_emb", "(", "args", ".", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", "\n", "phrase1_tensor", ".", "to", "(", "device", ")", "\n", "phrase2_tensor", ".", "to", "(", "device", ")", "\n", "label_tensor", ".", "to", "(", "device", ")", "\n", "split1", "=", "math", ".", "ceil", "(", "phrase1_tensor", ".", "size", "(", ")", "[", "0", "]", "*", "0.7", ")", "\n", "split2", "=", "math", ".", "ceil", "(", "phrase1_tensor", ".", "size", "(", ")", "[", "0", "]", "*", "0.85", ")", "\n", "\n", "train_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", "[", ":", "split1", ",", ":", "]", ",", "\n", "phrase2_tensor", "[", ":", "split1", ",", ":", "]", ",", "\n", "label_tensor", "[", ":", "split1", "]", ")", "\n", "valid_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", "[", "split1", ":", "split2", ",", ":", "]", ",", "\n", "phrase2_tensor", "[", "split1", ":", "split2", ",", ":", "]", ",", "\n", "label_tensor", "[", "split1", ":", "split2", "]", ")", "\n", "test_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", "[", "split2", ":", ",", ":", "]", ",", "\n", "phrase2_tensor", "[", "split2", ":", ",", ":", "]", ",", "\n", "label_tensor", "[", "split2", ":", "]", ")", "\n", "", "elif", "'paws'", "in", "args", ".", "task", ":", "\n", "# for paws dataset, we use the train / val / test split defined by the authors", "\n", "            ", "data_fname", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train_examples.json'", ")", "\n", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", "=", "get_data_emb", "(", "args", ".", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", "\n", "phrase1_tensor", ".", "to", "(", "device", ")", "\n", "phrase2_tensor", ".", "to", "(", "device", ")", "\n", "label_tensor", ".", "to", "(", "device", ")", "\n", "train_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", ")", "\n", "\n", "data_fname", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'dev_examples.json'", ")", "\n", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", "=", "get_data_emb", "(", "args", ".", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", "\n", "phrase1_tensor", ".", "to", "(", "device", ")", "\n", "phrase2_tensor", ".", "to", "(", "device", ")", "\n", "label_tensor", ".", "to", "(", "device", ")", "\n", "valid_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", ")", "\n", "\n", "data_fname", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'test_examples.json'", ")", "\n", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", "=", "get_data_emb", "(", "args", ".", "full_run_mode", ",", "data_fname", ",", "model_path", ",", "device", ")", "\n", "phrase1_tensor", ".", "to", "(", "device", ")", "\n", "phrase2_tensor", ".", "to", "(", "device", ")", "\n", "label_tensor", ".", "to", "(", "device", ")", "\n", "test_dataset", "=", "ParaphraseDataset", "(", "phrase1_tensor", ",", "phrase2_tensor", ",", "label_tensor", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Not a valid task'", ")", "\n", "\n", "", "early_stop_callback", "=", "EarlyStopping", "(", "monitor", "=", "'epoch_val_accuracy'", ",", "min_delta", "=", "0.00", ",", "patience", "=", "5", ",", "verbose", "=", "True", ",", "mode", "=", "'max'", ")", "\n", "model", "=", "ProbingModel", "(", "input_dim", "=", "phrase1_tensor", ".", "shape", "[", "1", "]", "*", "2", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "valid_dataset", "=", "valid_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ")", ".", "to", "(", "device", ")", "\n", "trainer", "=", "Trainer", "(", "max_epochs", "=", "100", ",", "min_epochs", "=", "3", ",", "auto_lr_find", "=", "False", ",", "auto_scale_batch_size", "=", "False", ",", "\n", "progress_bar_refresh_rate", "=", "10", ",", "callbacks", "=", "[", "early_stop_callback", "]", ",", "gpus", "=", "[", "args", ".", "device_id", "]", ")", "\n", "# trainer.tune(model)", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "result", "=", "trainer", ".", "test", "(", "test_dataloaders", "=", "model", ".", "test_dataloader", "(", ")", ")", "\n", "print", "(", "f'\\n finished {model_name}\\n'", ")", "\n", "output_fname", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "f'{args.task}_{model_name}.json'", ")", "\n", "\n", "with", "open", "(", "output_fname", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "result", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "model_name_acc_dict", "[", "model_name", "]", "=", "result", "[", "0", "]", "[", "'epoch_test_accuracy'", "]", "\n", "v", "=", "model_name_acc_dict", "[", "model_name", "]", "\n", "print", "(", "result", ")", "\n", "print", "(", ")", "\n", "\n", "# print(str( model_name_acc_dict))", "\n", "", "for", "k", ",", "v", "in", "model_name_acc_dict", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f' model: {k}, testing accuracy: {v:.4f} '", ")", "\n", "\n", "", "print", "(", "'Done with main'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_bird.main": [[24, 76], ["config.model_path.MODEL_PATH.items", "print", "open", "enumerate", "torch.nn.CosineSimilarity", "scipy.stats.stats.pearsonr", "print", "line.rstrip().split", "text_list.append", "scores.append", "utils.utils.load_model", "utils.utils.load_model", "nn.CosineSimilarity.", "cos_sim_list.append", "float", "utils.utils.load_model.encode", "all_emb_list.append", "all_emb_list.append", "torch.tensor", "torch.tensor", "cos_sim.item", "line.rstrip", "utils.glove_utils.get_phrase_emb", "model.encode.append", "len"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_phrase_emb"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "data_fname", "=", "args", ".", "bird_fname", "\n", "\n", "# iterate through each model to be tested", "\n", "for", "model_name", ",", "model_path", "in", "MODEL_PATH", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "model_name", ")", "\n", "\n", "text_list", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "\n", "# read in BiRD data", "\n", "bird_handler", "=", "open", "(", "data_fname", ",", "\"r\"", ")", "\n", "for", "line_no", ",", "line", "in", "enumerate", "(", "bird_handler", ")", ":", "\n", "            ", "if", "line_no", "==", "0", ":", "\n", "# skip header", "\n", "                ", "continue", "\n", "", "words", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "p1", ",", "p2", ",", "score", "=", "words", "[", "1", "]", ",", "words", "[", "2", "]", ",", "float", "(", "words", "[", "-", "2", "]", ")", "\n", "text_list", ".", "append", "(", "[", "p1", ",", "p2", "]", ")", "\n", "scores", ".", "append", "(", "score", ")", "\n", "\n", "", "all_emb_list", "=", "[", "]", "\n", "\n", "# load the model and perform inference on data to obtain embeddings", "\n", "if", "'glove'", "not", "in", "model_name", ":", "\n", "            ", "model", "=", "load_model", "(", "model_path", ")", "\n", "\n", "for", "text_sublist", "in", "text_list", ":", "\n", "                ", "emb_list", "=", "model", ".", "encode", "(", "text_sublist", ",", "batch_size", "=", "len", "(", "text_sublist", ")", ",", "show_progress_bar", "=", "False", ")", "\n", "all_emb_list", ".", "append", "(", "emb_list", ")", "\n", "", "", "else", ":", "\n", "            ", "word2coef_dict", ",", "average_emb", "=", "load_model", "(", "model_path", ")", "\n", "for", "text_sublist", "in", "text_list", ":", "\n", "                ", "emb_list", "=", "[", "]", "\n", "for", "term", "in", "text_sublist", ":", "\n", "                    ", "emb", "=", "get_phrase_emb", "(", "word2coef_dict", ",", "term", ",", "average_emb", ")", "\n", "emb_list", ".", "append", "(", "emb", ")", "\n", "", "all_emb_list", ".", "append", "(", "emb_list", ")", "\n", "\n", "\n", "# Following Yu and Ettinger, which uses Cosine similarity on BiRD task evaluation", "\n", "", "", "cos_sim", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "0", ")", "\n", "normalized", "=", "True", "\n", "cos_sim_list", "=", "[", "]", "\n", "for", "emb_list", "in", "all_emb_list", ":", "\n", "            ", "[", "e1", ",", "e2", "]", "=", "emb_list", "\n", "sim", "=", "cos_sim", "(", "torch", ".", "tensor", "(", "e1", ")", ",", "torch", ".", "tensor", "(", "e2", ")", ")", "\n", "if", "normalized", ":", "\n", "                ", "sim", "=", "(", "sim", "+", "1", ")", "/", "2.0", "\n", "", "cos_sim_list", ".", "append", "(", "sim", ".", "item", "(", ")", ")", "\n", "", "cor", ",", "_", "=", "pearsonr", "(", "cos_sim_list", ",", "scores", ")", "\n", "print", "(", "cor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_turney.compute_emb_given_nested_data": [[22, 46], ["utils.utils.load_model", "utils.utils.load_model", "all_emb_list.append", "utils.utils.load_model.encode", "all_emb_list.append", "utils.glove_utils.get_phrase_emb", "model.encode.append", "len"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.utils.load_model", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.utils.glove_utils.get_phrase_emb"], ["def", "compute_emb_given_nested_data", "(", "text_list", ",", "model_path", ",", "spanRep", "=", "False", ")", ":", "\n", "    ", "'''\n        data: a list of sublist, each element a string, of the word to be distinguished\n              In Turney, each sublist has 8 entries, \n              1 - bigram query, 2 - correct, 3 - component, 4 - component, 5/6/7/8 - other candidates\n    '''", "\n", "if", "'glove'", "in", "model_path", ":", "\n", "        ", "word2coeff_dict", ",", "average_emb", "=", "load_model", "(", "model_path", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "load_model", "(", "model_path", ")", "\n", "\n", "", "all_emb_list", "=", "[", "]", "\n", "if", "'glove'", "in", "model_path", ":", "\n", "        ", "for", "text_sublist", "in", "text_list", ":", "\n", "            ", "emb_list", "=", "[", "]", "\n", "for", "entry", "in", "text_sublist", ":", "\n", "                ", "emb", "=", "get_phrase_emb", "(", "word2coeff_dict", ",", "entry", ",", "average_emb", ")", "\n", "emb_list", ".", "append", "(", "emb", ")", "\n", "", "all_emb_list", ".", "append", "(", "emb_list", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "text_sublist", "in", "text_list", ":", "\n", "            ", "emb_list", "=", "model", ".", "encode", "(", "text_sublist", ",", "batch_size", "=", "len", "(", "text_sublist", ")", ",", "show_progress_bar", "=", "False", ")", "\n", "all_emb_list", ".", "append", "(", "emb_list", ")", "\n", "", "", "return", "all_emb_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_turney.conduct_turney_test": [[48, 75], ["enumerate", "print", "numpy.concatenate", "numpy.array", "numpy.dot", "numpy.argmax", "len"], "function", ["None"], ["", "def", "conduct_turney_test", "(", "data_list", ",", "all_emb_list", ")", ":", "\n", "    ", "\"\"\"\n        data: a list of sublist, each element a string, of the word to be distinguished\n              In Turney, each sublist has 8 entries, \n              1 - bigram query, 2 - correct, 3 - component, 4 - component, 5/6/7/8 - other candidates\n        \n        all_emb_list: a list of sublist, each element a np array, of the entry's emb\n              In Turney, each sublist has 8 entries, \n              1 - bigram query, 2 - correct, 3 - component, 4 - component, 5/6/7/8 - other candidates\n        \n    \"\"\"", "\n", "num_correct", "=", "0", "\n", "for", "idx", ",", "emb_list", "in", "enumerate", "(", "all_emb_list", ")", ":", "\n", "        ", "text_list", "=", "data_list", "[", "idx", "]", "\n", "\n", "emb_array", "=", "np", ".", "concatenate", "(", "(", "emb_list", "[", ":", "2", "]", ",", "emb_list", "[", "4", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "text_list", "=", "text_list", "[", ":", "2", "]", "+", "text_list", "[", "4", ":", "]", "\n", "query", "=", "emb_array", "[", "0", ",", ":", "]", "\n", "matrix", "=", "np", ".", "array", "(", "emb_array", "[", "1", ":", ",", ":", "]", ")", "\n", "scores", "=", "np", ".", "dot", "(", "matrix", ",", "query", ")", "\n", "chosen", "=", "np", ".", "argmax", "(", "scores", ")", "\n", "\n", "if", "chosen", "==", "0", ":", "\n", "            ", "num_correct", "+=", "1", "\n", "\n", "", "", "accuracy", "=", "num_correct", "/", "len", "(", "data_list", ")", "\n", "print", "(", "f'Accuracy on Turney = {accuracy}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_turney.main": [[76, 90], ["config.model_path.MODEL_PATH.items", "open", "f.readlines", "print", "eval_turney.compute_emb_given_nested_data", "eval_turney.conduct_turney_test", "line.strip().split", "data_list.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_turney.compute_emb_given_nested_data", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-semantic-eval.eval_turney.conduct_turney_test"], ["", "def", "main", "(", "args", ")", ":", "\n", "# load the data for the turney task", "\n", "    ", "turney_data_fname", "=", "args", ".", "turney_fname", "\n", "with", "open", "(", "turney_data_fname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "readlines", "(", ")", "\n", "data_list", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "            ", "components", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "' | '", ")", "\n", "data_list", ".", "append", "(", "components", ")", "\n", "\n", "", "", "for", "model_name", ",", "model_path", "in", "MODEL_PATH", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "model_name", ")", "\n", "all_emb_list", "=", "compute_emb_given_nested_data", "(", "data_list", ",", "model_path", ")", "\n", "conduct_turney_test", "(", "data_list", ",", "all_emb_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.l2_normalize_batch": [[15, 17], ["x.div", "x.norm"], "function", ["None"], ["def", "l2_normalize_batch", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "div", "(", "x", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.soft_cross_entropy": [[20, 22], ["torch.mean", "torch.sum", "torch.nn.functional.log_softmax"], "function", ["None"], ["", "def", "soft_cross_entropy", "(", "input", ",", "target", ")", ":", "\n", "    ", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "-", "target", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "input", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.compute_triplet_loss": [[23, 36], ["anchor.size", "model_utils.l2_normalize_batch", "model_utils.l2_normalize_batch", "model_utils.l2_normalize_batch", "torch.bmm", "torch.bmm", "torch.nn.functional.relu", "torch.nn.functional.relu.mean", "l2_normalize_batch.view", "l2_normalize_batch.view", "l2_normalize_batch.view", "l2_normalize_batch.view"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.l2_normalize_batch", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.l2_normalize_batch", "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.l2_normalize_batch"], ["", "def", "compute_triplet_loss", "(", "anchor", ",", "positive", ",", "negative", ",", "margin", ")", ":", "\n", "    ", "b_size", ",", "dim_size", "=", "anchor", ".", "size", "(", ")", "\n", "\n", "anchor_normalized", "=", "l2_normalize_batch", "(", "anchor", ")", "\n", "positive_normalized", "=", "l2_normalize_batch", "(", "positive", ")", "\n", "negative_normalized", "=", "l2_normalize_batch", "(", "negative", ")", "\n", "\n", "\n", "positive_dot", "=", "torch", ".", "bmm", "(", "anchor_normalized", ".", "view", "(", "b_size", ",", "1", ",", "dim_size", ")", ",", "positive_normalized", ".", "view", "(", "b_size", ",", "dim_size", ",", "1", ")", ")", "\n", "negative_dot", "=", "torch", ".", "bmm", "(", "anchor_normalized", ".", "view", "(", "b_size", ",", "1", ",", "dim_size", ")", ",", "negative_normalized", ".", "view", "(", "b_size", ",", "dim_size", ",", "1", ")", ")", "\n", "\n", "losses", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "1.0", "+", "negative_dot", "-", "positive_dot", ")", "\n", "return", "losses", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.run_epoch": [[37, 158], ["time.time", "net.train", "enumerate", "print", "net.named_parameters", "torch.FloatTensor().to", "net", "torch.LongTensor().to", "torch.tensor", "torch.tensor", "torch.nn.functional.normalize", "batch_loss.item", "triplet_loss.item", "ortho_loss.item", "torch.tensor.item", "torch.tensor.item", "len", "len", "len", "len", "len", "torch.FloatTensor().to", "model_utils.compute_triplet_loss", "X.view.permute", "torch.bmm", "torch.eye", "torch.cat", "X.view.view", "torch.sum", "batch_loss.backward", "optim.step", "optim.zero_grad", "print", "torch.FloatTensor", "torch.LongTensor", "len", "torch.sum", "X.view.permute", "torch.bmm", "torch.eye", "torch.cat", "X.view.view", "X.view.view", "torch.sum", "time.time", "torch.FloatTensor", "numpy.array", "numpy.array", "torch.cat.to", "len", "torch.sum", "numpy.array", "torch.eye.unsqueeze", "torch.cat.to", "torch.mm", "torch.eye().to", "torch.eye.unsqueeze", "X.view.t", "torch.eye", "X.view.size"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.compute_triplet_loss"], ["", "def", "run_epoch", "(", "net", ",", "optim", ",", "batch_intervals_train", ",", "uid_input_vector_list", ",", "uid_input_vector_list_neg", ",", "args", ",", "train", ",", "h_model", ",", "epoch", ",", "freeze_begin_epoch", ")", ":", "\n", "    ", "device", "=", "args", ".", "device", "\n", "triplet_loss_margin", "=", "args", ".", "triplet_loss_margin", "\n", "triplet_loss_weight", "=", "args", ".", "triplet_loss_weight", "\n", "ortho_weight", "=", "args", ".", "ortho_weight", "\n", "neighbour_loss_weight", "=", "args", ".", "neighbour_loss_weight", "\n", "offset_loss_weight", "=", "args", ".", "offset_loss_weight", "\n", "\n", "ep_loss", "=", "0.", "\n", "ep_tri_loss", "=", "0.", "\n", "ep_re_loss", "=", "0.", "\n", "ep_or_loss", "=", "0.", "\n", "ep_world_class_loss", "=", "0.", "\n", "ep_off_loss", "=", "0.", "\n", "ep_nei_loss", "=", "0.", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "net", ".", "train", "(", ")", "\n", "\n", "# After reaching freeze_begin_epoch, freeze all weights but X", "\n", "if", "epoch", "==", "freeze_begin_epoch", ":", "\n", "        ", "for", "name", ",", "param", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "==", "'X'", ":", "# allow gradients update for the sub topic offsets", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "", "else", ":", "# freeze gradient updates for all other topic offsets", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "if", "epoch", "<", "freeze_begin_epoch", ":", "\n", "        ", "ortho_weight", "=", "0.", "\n", "neighbour_loss_weight", "=", "0.", "\n", "offset_loss_weight", "=", "0.", "\n", "\n", "\n", "", "for", "b_idx", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "batch_intervals_train", ")", ":", "\n", "# print(start, end)", "\n", "\n", "        ", "batch_data", "=", "uid_input_vector_list", "[", "start", ":", "end", "]", "\n", "batch_input_vec", "=", "[", "uid_vec_pair", "[", "1", "]", "for", "uid_vec_pair", "in", "batch_data", "]", "\n", "try", ":", "\n", "            ", "batch_data_t", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "batch_input_vec", ")", ")", ".", "to", "(", "device", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "\n", "", "batch_data_neg", "=", "uid_input_vector_list_neg", "[", "start", ":", "end", "]", "\n", "batch_data_neg_t", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "batch_data_neg", ")", ")", ".", "to", "(", "device", ")", "\n", "\n", "recomb", "=", "net", "(", "batch_data_t", ",", "epoch", ",", "freeze_begin_epoch", ")", "\n", "\n", "\n", "triplet_loss", "=", "triplet_loss_weight", "*", "compute_triplet_loss", "(", "recomb", ",", "batch_data_t", ",", "batch_data_neg_t", ",", "triplet_loss_margin", ")", "\n", "\n", "# construct world classification target", "\n", "world_targets", "=", "[", "vec_id_pair", "[", "1", "]", "for", "vec_id_pair", "in", "batch_data", "]", "\n", "world_targets_t", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "world_targets", ")", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "\n", "# compute world loss using the doc here: https://pytorch.org/docs/stable/nn.html#crossentropyloss", "\n", "\n", "# compute orthogonality penalty on dictionary", "\n", "X", "=", "net", ".", "X", "\n", "offset_loss", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "device", "=", "args", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "neighbour_loss", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "device", "=", "args", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "if", "len", "(", "X", ".", "shape", ")", ">", "2", "and", "h_model", "==", "1", ":", "\n", "# neighbour_loss", "\n", "            ", "Xp", "=", "X", ".", "permute", "(", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "y", "=", "torch", ".", "bmm", "(", "X", ",", "Xp", ")", "\n", "e", "=", "torch", ".", "eye", "(", "y", ".", "shape", "[", "-", "1", "]", ")", "\n", "new_e", "=", "torch", ".", "cat", "(", "args", ".", "num_topics", "*", "[", "e", ".", "unsqueeze", "(", "0", ")", "]", ")", "\n", "z", "=", "(", "y", "-", "new_e", ".", "to", "(", "device", ")", ")", "**", "2", "\n", "neighbour_loss", "=", "-", "ortho_weight", "*", "0.01", "*", "torch", ".", "sum", "(", "z", ")", "\n", "X", "=", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "elif", "len", "(", "X", ".", "shape", ")", ">", "2", "and", "h_model", "==", "2", ":", "\n", "# neighbour_loss", "\n", "            ", "Xp", "=", "X", ".", "permute", "(", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "y", "=", "torch", ".", "bmm", "(", "X", ",", "Xp", ")", "\n", "e", "=", "torch", ".", "eye", "(", "y", ".", "shape", "[", "-", "1", "]", ")", "\n", "new_e", "=", "torch", ".", "cat", "(", "args", ".", "num_topics", "*", "[", "e", ".", "unsqueeze", "(", "0", ")", "]", ")", "\n", "z", "=", "(", "y", "-", "new_e", ".", "to", "(", "device", ")", ")", "**", "2", "\n", "neighbour_loss", "=", "-", "neighbour_loss_weight", "*", "torch", ".", "sum", "(", "z", ")", "\n", "X", "=", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", "# prepare X for orthogonality loss", "\n", "# will add a loss to enforce small magnitude on X", "\n", "X", "=", "X", ".", "view", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "Xr_squared", "=", "X", "**", "2", "\n", "X_l2", "=", "torch", ".", "sum", "(", "Xr_squared", ")", "\n", "offset_loss", "=", "offset_loss_weight", "*", "X_l2", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "X", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "X", ",", "dim", "=", "0", ")", "\n", "ortho_loss", "=", "ortho_weight", "*", "torch", ".", "sum", "(", "(", "torch", ".", "mm", "(", "X", ",", "X", ".", "t", "(", ")", ")", "-", "torch", ".", "eye", "(", "X", ".", "size", "(", ")", "[", "0", "]", ")", ".", "to", "(", "device", ")", ")", "**", "2", ")", "\n", "\n", "\n", "\n", "batch_loss", "=", "triplet_loss", "+", "ortho_loss", "+", "neighbour_loss", "+", "offset_loss", "\n", "\n", "if", "train", ":", "# at training time we perform gradient updates", "\n", "            ", "batch_loss", ".", "backward", "(", ")", "\n", "optim", ".", "step", "(", ")", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# else: # at validation time we compute prediction accuracies", "\n", "\n", "\n", "", "ep_loss", "+=", "batch_loss", ".", "item", "(", ")", "\n", "ep_tri_loss", "+=", "triplet_loss", ".", "item", "(", ")", "\n", "ep_or_loss", "+=", "ortho_loss", ".", "item", "(", ")", "\n", "ep_off_loss", "+=", "offset_loss", ".", "item", "(", ")", "\n", "ep_nei_loss", "+=", "neighbour_loss", ".", "item", "(", ")", "\n", "\n", "", "ep_loss", "=", "ep_loss", "/", "len", "(", "batch_intervals_train", ")", "\n", "ep_tri_loss", "=", "ep_tri_loss", "/", "len", "(", "batch_intervals_train", ")", "\n", "ep_or_loss", "=", "ep_or_loss", "/", "len", "(", "batch_intervals_train", ")", "\n", "ep_off_loss", "=", "ep_off_loss", "/", "len", "(", "batch_intervals_train", ")", "\n", "ep_nei_loss", "=", "ep_nei_loss", "/", "len", "(", "batch_intervals_train", ")", "\n", "signature", "=", "'TRAIN'", "if", "train", "==", "True", "else", "'VALID'", "\n", "\n", "ep_info", "=", "'[%s] loss: %0.4f, %0.4f, %0.4f, %0.4f, %0.4f (all, tri, or, off, nei), time: %0.2f s'", "%", "(", "signature", ",", "\n", "ep_loss", ",", "ep_tri_loss", ",", "ep_or_loss", ",", "ep_off_loss", ",", "ep_nei_loss", ",", "time", ".", "time", "(", ")", "-", "start_time", ")", "\n", "\n", "print", "(", "ep_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.smart_rank_vocab_for_topics": [[161, 214], ["torch.FloatTensor().to", "torch.no_grad", "model.get_query", "torch.nn.functional.normalize", "torch.mm", "torch.nn.functional.softmax", "torch.nn.functional.softmax.cpu().detach().numpy", "numpy.argsort", "range", "torch.FloatTensor", "model.get_query.t", "len", "torch.nn.functional.softmax.cpu().detach", "topics_print_list.append", "topics_print_list.append", "print", "torch.nn.functional.softmax.cpu", "top_10_words_list.append", "len"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.get_query"], ["", "def", "smart_rank_vocab_for_topics", "(", "model", "=", "None", ",", "word_embedding_matrix", "=", "None", ",", "to_be_removed", "=", "None", ",", "sorted_ids", "=", "None", ",", "top_activation_J", "=", "10", ",", "return_format", "=", "'str'", ")", ":", "\n", "# if self.mode == 'glove':", "\n", "#     id2word_dict = self.vrev", "\n", "#     vocab_input = [[i] for i in range(len(id2word_dict))]", "\n", "#     vocab_input_t = torch.LongTensor(vocab_input).to(self.device)", "\n", "# if self.mode == 'bert':", "\n", "\n", "    ", "if", "top_activation_J", "==", "0", ":", "# this means that we do not use top J reranking and therefore get the top 10 candidates", "\n", "        ", "top_activation_J", "=", "10", "\n", "sorted_ids", "=", "None", "\n", "\n", "", "if", "True", ":", "\n", "        ", "vocab_input", "=", "word_embedding_matrix", "\n", "vocab_input_t", "=", "torch", ".", "FloatTensor", "(", "vocab_input", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "topics_print_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# in torch", "\n", "            ", "dict_queries", "=", "model", ".", "get_query", "(", "vocab_input_t", ")", "\n", "topic_dict", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "model", ".", "X", ",", "dim", "=", "1", ")", "\n", "scores_over_vocab", "=", "torch", ".", "mm", "(", "topic_dict", ",", "dict_queries", ".", "t", "(", ")", ")", "# K by num_vocab", "\n", "prob_over_vocab", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores_over_vocab", ",", "dim", "=", "1", ")", "# K by num_vocab", "\n", "prob_over_vocab_np", "=", "prob_over_vocab", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "len", "(", "to_be_removed", ")", ">", "0", ":", "\n", "                ", "prob_over_vocab_np", "[", ":", ",", "to_be_removed", "]", "=", "0.", "\n", "# print('removed some words')", "\n", "\n", "\n", "", "top_probable", "=", "np", ".", "argsort", "(", "prob_over_vocab_np", ")", "\n", "top_J", "=", "top_probable", "[", ":", ",", "-", "top_activation_J", ":", "]", "\n", "\n", "for", "topic_id", "in", "range", "(", "top_J", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "sorted_ids", "is", "not", "None", ":", "\n", "                    ", "top_10_words_list", "=", "[", "]", "\n", "for", "id", "in", "sorted_ids", ":", "\n", "                        ", "if", "id", "in", "top_J", "[", "topic_id", "]", ":", "\n", "                            ", "top_10_words_list", ".", "append", "(", "model", ".", "vrev", "[", "id", "]", ")", "\n", "", "if", "len", "(", "top_10_words_list", ")", "==", "10", ":", "\n", "                            ", "break", "\n", "", "", "", "else", ":", "\n", "                    ", "top_10_words_list", "=", "[", "model", ".", "vrev", "[", "x", "]", "for", "x", "in", "top_J", "[", "topic_id", "]", "]", "\n", "\n", "", "if", "return_format", "==", "'str'", ":", "\n", "                    ", "top_10_words_joined", "=", "', '", ".", "join", "(", "top_10_words_list", ")", "\n", "topic_print", "=", "f'topic {topic_id} : '", "+", "top_10_words_joined", "\n", "# print(topic_print)", "\n", "topics_print_list", ".", "append", "(", "topic_print", ")", "\n", "", "elif", "return_format", "==", "'list'", ":", "\n", "                    ", "topics_print_list", ".", "append", "(", "top_10_words_list", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'wrong format'", ")", "\n", "\n", "", "", "", "return", "topics_print_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.text_to_topic": [[216, 229], ["numpy.empty", "enumerate", "tqdm.tqdm", "torch.FloatTensor().to", "torch.max", "ind.data.cpu().numpy", "numpy.concatenate", "range", "torch.no_grad", "model.evaluate_topics", "len", "torch.FloatTensor", "ind.data.cpu", "numpy.array"], "function", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.evaluate_topics"], ["", "", "def", "text_to_topic", "(", "input_vector_list", ",", "model", ",", "device", ",", "batch_size", "=", "400", ")", ":", "\n", "    ", "batch_intervals", "=", "[", "(", "start", ",", "start", "+", "batch_size", ")", "for", "start", "in", "range", "(", "0", ",", "len", "(", "input_vector_list", ")", ",", "batch_size", ")", "]", "\n", "\n", "result", "=", "np", ".", "empty", "(", "(", "0", ")", ",", "dtype", "=", "int", ")", "\n", "for", "b_idx", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "tqdm", "(", "batch_intervals", ")", ")", ":", "\n", "        ", "batch_data", "=", "input_vector_list", "[", "start", ":", "end", "]", "\n", "batch_data_t", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "batch_data", ")", ")", ".", "to", "(", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "model", ".", "evaluate_topics", "(", "batch_data_t", ")", "\n", "", "_", ",", "ind", "=", "torch", ".", "max", "(", "scores", ",", "1", ")", "\n", "ind_np", "=", "ind", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "result", "=", "np", ".", "concatenate", "(", "(", "result", ",", "ind_np", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.phrase-topic-model.model_utils.rank_topics_by_percentage": [[232, 247], ["Counter", "len", "enumerate", "Counter.most_common", "topic_id_ranked.append", "str", "topic_percentage_ranked.append", "round", "len"], "function", ["None"], ["", "def", "rank_topics_by_percentage", "(", "topic_pred_list", ")", ":", "\n", "    ", "from", "collections", "import", "Counter", "\n", "topics_counter", "=", "Counter", "(", "topic_pred_list", ")", "\n", "num_topic", "=", "len", "(", "topics_counter", ")", "\n", "\n", "topic_id_ranked", "=", "[", "]", "\n", "topic_percentage_ranked", "=", "[", "]", "\n", "\n", "for", "rank", ",", "(", "topic_id", ",", "cnt", ")", "in", "enumerate", "(", "topics_counter", ".", "most_common", "(", ")", ")", ":", "\n", "# print(f'Rank: {rank}, Topic: {topic_id}, Percentage { cnt/ len(topic_pred_list) }')", "\n", "        ", "topic_id_ranked", ".", "append", "(", "topic_id", ")", "\n", "perc", "=", "str", "(", "round", "(", "100", "*", "cnt", "/", "len", "(", "topic_pred_list", ")", ",", "2", ")", ")", "\n", "topic_percentage_ranked", ".", "append", "(", "perc", ")", "\n", "\n", "", "return", "topic_id_ranked", ",", "topic_percentage_ranked", "", "", ""]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.__init__": [[10, 60], ["base_model.BaseModel.__init__", "torch.nn.Embedding", "dae_model.DictionaryAutoencoder.embeddings.weight.data.copy_", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "dae_model.DictionaryAutoencoder.W_out.weight.data.copy_", "torch.nn.Parameter", "torch.nn.init.orthogonal_", "torch.nn.Linear", "torch.from_numpy", "torch.from_numpy", "torch.nn.Linear", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "net_params", ")", ":", "\n", "        ", "super", "(", "DictionaryAutoencoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# print(\"We got here\")", "\n", "# store for interpretation", "\n", "self", ".", "vrev", "=", "net_params", "[", "\"vrev\"", "]", "# idx to word mapping", "\n", "self", ".", "mode", "=", "net_params", "[", "\"mode\"", "]", "# bert or GloVe", "\n", "\n", "# hyperparams", "\n", "self", ".", "vocab_size", "=", "net_params", "[", "\"embedding\"", "]", ".", "shape", "[", "0", "]", "\n", "\n", "self", ".", "d_emb", "=", "net_params", "[", "\"embedding\"", "]", ".", "shape", "[", "1", "]", "\n", "self", ".", "d_hid", "=", "net_params", "[", "\"d_hid\"", "]", "\n", "self", ".", "K", "=", "net_params", "[", "\"num_rows\"", "]", "# number of topics", "\n", "self", ".", "device", "=", "net_params", "[", "\"device\"", "]", "\n", "self", ".", "pred_world", "=", "net_params", "[", "\"pred_world\"", "]", "\n", "if", "self", ".", "pred_world", ":", "\n", "            ", "self", ".", "num_world", "=", "net_params", "[", "\"num_world\"", "]", "\n", "self", ".", "W_world", "=", "nn", ".", "Linear", "(", "self", ".", "d_emb", ",", "self", ".", "num_world", ")", "\n", "\n", "# glove params params", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "self", ".", "d_emb", ")", "\n", "self", ".", "embeddings", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "net_params", "[", "\"embedding\"", "]", ")", ")", "\n", "self", ".", "embeddings", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "# put an MLP on top of embeddings for more params", "\n", "self", ".", "W_proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_emb", ",", "self", ".", "d_hid", ")", "# bottleneck", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "# self.dropout = nn.Dropout(p=0.2)", "\n", "self", ".", "word_dropout_prob", "=", "net_params", "[", "\"word_dropout_prob\"", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "word_dropout_prob", ")", "\n", "\n", "# fully-connected layer to project back to emb. dimension", "\n", "self", ".", "W_att", "=", "nn", ".", "Linear", "(", "self", ".", "d_hid", ",", "self", ".", "d_emb", ")", "# back to d_emb for attention", "\n", "\n", "\n", "# reconstruction output", "\n", "self", ".", "W_out", "=", "nn", ".", "Linear", "(", "self", ".", "d_emb", ",", "self", ".", "vocab_size", ")", "# output matrix", "\n", "self", ".", "W_out", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "net_params", "[", "\"embedding\"", "]", ")", ")", "\n", "self", ".", "W_out", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "# predict world info", "\n", "if", "self", ".", "pred_world", ":", "\n", "            ", "self", ".", "W_world", "=", "nn", ".", "Linear", "(", "self", ".", "d_emb", ",", "self", ".", "num_world", ")", "\n", "\n", "# dictionary, each row is a \"topic\" embedding", "\n", "", "self", ".", "X", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "net_params", "[", "\"num_rows\"", "]", ",", "self", ".", "d_emb", ")", ")", "\n", "\n", "# rows should initially be (semi) orthogonal", "\n", "torch", ".", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.interpret_dictionary": [[62, 75], ["dae_model.DictionaryAutoencoder.embeddings.weight.data.detach", "torch.nn.functional.normalize().cpu().numpy", "torch.nn.functional.normalize", "torch.nn.functional.normalize.detach().cpu().numpy", "range", "torch.nn.functional.normalize().cpu().numpy.dot", "print", "torch.nn.functional.normalize().cpu", "torch.nn.functional.normalize.detach().cpu", "numpy.argsort", "torch.nn.functional.normalize", "torch.nn.functional.normalize.detach"], "methods", ["None"], ["", "def", "interpret_dictionary", "(", "self", ")", ":", "\n", "# get current embeddings and normalize them", "\n", "        ", "We", "=", "self", ".", "embeddings", ".", "weight", ".", "data", ".", "detach", "(", ")", "\n", "We", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "We", ",", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "topic_dict", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "X", ",", "dim", "=", "1", ")", "\n", "\n", "X", "=", "topic_dict", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "K", ")", ":", "\n", "            ", "desc", "=", "X", "[", "i", "]", "\n", "sims", "=", "We", ".", "dot", "(", "desc", ".", "T", ")", "\n", "ordered_words", "=", "np", ".", "argsort", "(", "sims", ")", "[", ":", ":", "-", "1", "]", "\n", "desc_list", "=", "[", "self", ".", "vrev", "[", "w", "]", "for", "w", "in", "ordered_words", "[", ":", "10", "]", "]", "\n", "print", "(", "\"topic %d: %s\"", "%", "(", "i", ",", "\", \"", ".", "join", "(", "desc_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.get_query": [[76, 85], ["batch.size", "dae_model.DictionaryAutoencoder.dropout", "dae_model.DictionaryAutoencoder.dropout", "dae_model.DictionaryAutoencoder.dropout", "dae_model.DictionaryAutoencoder.act", "dae_model.DictionaryAutoencoder.act", "dae_model.DictionaryAutoencoder.W_proj", "dae_model.DictionaryAutoencoder.W_att"], "methods", ["None"], ["", "", "def", "get_query", "(", "self", ",", "batch", ")", ":", "\n", "        ", "bsz", ",", "d_emb", "=", "batch", ".", "size", "(", ")", "\n", "embs", "=", "self", ".", "dropout", "(", "batch", ")", "\n", "proj", "=", "self", ".", "dropout", "(", "self", ".", "act", "(", "self", ".", "W_proj", "(", "embs", ")", ")", ")", "\n", "latent", "=", "proj", "\n", "\n", "# project back to embedding size", "\n", "dict_query", "=", "self", ".", "dropout", "(", "self", ".", "act", "(", "self", ".", "W_att", "(", "latent", ")", ")", ")", "\n", "return", "dict_query", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.forward": [[86, 104], ["dae_model.DictionaryAutoencoder.get_query", "torch.nn.functional.normalize", "torch.mm", "torch.nn.functional.softmax", "torch.mm", "torch.nn.functional.normalize.t", "dae_model.DictionaryAutoencoder.W_world"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.get_query"], ["", "def", "forward", "(", "self", ",", "batch", ",", "epoch", ",", "freeze_begin_epoch", ")", ":", "\n", "        ", "dict_query", "=", "self", ".", "get_query", "(", "batch", ")", "\n", "# normalize dictionary", "\n", "topic_dict", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "X", ",", "dim", "=", "1", ")", "\n", "\n", "# now compute attention over dictionary matrix X", "\n", "scores", "=", "torch", ".", "mm", "(", "dict_query", ",", "topic_dict", ".", "t", "(", ")", ")", "\n", "scores", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "dim", "=", "1", ")", "# bsz x K", "\n", "\n", "# now get weighted aves", "\n", "recomb", "=", "torch", ".", "mm", "(", "scores", ",", "topic_dict", ")", "# bsz x d_emb", "\n", "\n", "# use the weighted aves to classify world label", "\n", "if", "self", ".", "pred_world", ":", "\n", "            ", "world_logits", "=", "self", ".", "W_world", "(", "recomb", ")", "\n", "return", "recomb", ",", "world_logits", "\n", "\n", "", "return", "recomb", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.evaluate_topics": [[108, 127], ["torch.no_grad", "batch.size", "dae_model.DictionaryAutoencoder.get_query", "torch.nn.functional.normalize", "torch.mm", "torch.nn.functional.softmax", "torch.nn.functional.normalize.t"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.get_query"], ["", "def", "evaluate_topics", "(", "self", ",", "batch", ")", ":", "\n", "# each example in a batch is of the form w1 w2 ... wn", "\n", "\n", "        ", "\"\"\"\n        :param batch: input in the form of word IDs (tensor)\n        :return: the score, probability distribution, over all K topics\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "bsz", ",", "d_emb", "=", "batch", ".", "size", "(", ")", "\n", "\n", "# project back to embedding size", "\n", "dict_query", "=", "self", ".", "get_query", "(", "batch", ")", "\n", "\n", "# normalize dictionary", "\n", "topic_dict", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "X", ",", "dim", "=", "1", ")", "\n", "\n", "# now compute attention over dictionary matrix X", "\n", "scores", "=", "torch", ".", "mm", "(", "dict_query", ",", "topic_dict", ".", "t", "(", ")", ")", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "dim", "=", "1", ")", "# bsz x K", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.rank_vocab_for_topics": [[128, 156], ["torch.FloatTensor().to", "torch.no_grad", "dae_model.DictionaryAutoencoder.get_query", "torch.nn.functional.normalize", "torch.mm", "torch.nn.functional.softmax", "torch.nn.functional.softmax.cpu().detach().numpy", "numpy.argsort", "range", "torch.FloatTensor", "dae_model.DictionaryAutoencoder.t", "len", "print", "topics_print_list.append", "torch.nn.functional.softmax.cpu().detach", "torch.nn.functional.softmax.cpu"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.dae_model.DictionaryAutoencoder.get_query"], ["", "", "def", "rank_vocab_for_topics", "(", "self", ",", "word_embedding_matrix", ",", "to_be_removed", ")", ":", "\n", "\n", "        ", "vocab_input", "=", "word_embedding_matrix", "\n", "vocab_input_t", "=", "torch", ".", "FloatTensor", "(", "vocab_input", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "topics_print_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# in torch", "\n", "            ", "dict_queries", "=", "self", ".", "get_query", "(", "vocab_input_t", ")", "\n", "topic_dict", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "X", ",", "dim", "=", "1", ")", "\n", "scores_over_vocab", "=", "torch", ".", "mm", "(", "topic_dict", ",", "dict_queries", ".", "t", "(", ")", ")", "# K by num_vocab", "\n", "prob_over_vocab", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "\n", "scores_over_vocab", ",", "dim", "=", "1", "\n", ")", "# K by num_vocab", "\n", "prob_over_vocab_np", "=", "prob_over_vocab", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "len", "(", "to_be_removed", ")", ">", "0", ":", "\n", "                ", "prob_over_vocab_np", "[", ":", ",", "to_be_removed", "]", "=", "0.0", "\n", "# print('removed some words')", "\n", "\n", "", "top_probable", "=", "np", ".", "argsort", "(", "prob_over_vocab_np", ")", "\n", "top_10", "=", "top_probable", "[", ":", ",", "-", "10", ":", "]", "\n", "for", "topic_id", "in", "range", "(", "top_10", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "top_10_words_list", "=", "[", "self", ".", "vrev", "[", "x", "]", "for", "x", "in", "top_10", "[", "topic_id", "]", "]", "\n", "top_10_words_joined", "=", "\", \"", ".", "join", "(", "top_10_words_list", ")", "\n", "topic_print", "=", "f\"topic {topic_id} : \"", "+", "top_10_words_joined", "\n", "print", "(", "topic_print", ")", "\n", "topics_print_list", ".", "append", "(", "topic_print", ")", "\n", "", "", "return", "topics_print_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.__init__": [[16, 18], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.forward": [[19, 22], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sf-wa-326_phrase-bert-topic-model.model.base_model.BaseModel.interpret_topics": [[24, 27], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "interpret_topics", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]]}