{"home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.set_random_seed": [[9, 19], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_random_seed", "(", "seed", "=", "0", ")", ":", "\n", "# Esp important for ensuring deterministic behavior with CNNs", "\n", "\t", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "cuda_available", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "cuda_available", ":", "\n", "\t\t", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "", "return", "cuda_available", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.get_model": [[21, 25], ["model.WideResnet", "model.WideResnet.cuda"], "function", ["None"], ["", "def", "get_model", "(", "output_classes_dict", ")", ":", "\n", "\t", "model", "=", "WideResnet", "(", "output_classes_dict", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.get_optimizer": [[27, 30], ["torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "def", "get_optimizer", "(", "model", ",", "lr", "=", "1e-3", ")", ":", "\n", "\t", "optimizer", "=", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.run_epoch": [[31, 94], ["data.iterator_", "data.iterator_", "data.iterator_", "model", "model.criterion", "model.accuracy", "torch.autograd.grad", "model.criterion", "torch.autograd.grad", "tartan_.weighted_grads", "tartan_.update_weights", "loss_.backward", "optim.step", "optim.zero_grad", "model.parameters", "next", "model", "model.parameters", "mdev_head.learn_meta_dev_head", "mdev_head.get_meta_grads", "tartan_.update_weight_gradients", "torch.no_grad", "enumerate", "data.iterator_", "next", "next", "next", "model.parameters", "next", "next", "data.iterator_"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.criterion", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.accuracy", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.criterion", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.weighted_grads", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.update_weights", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.learn_meta_dev_head", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.get_meta_grads", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.update_weight_gradients", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_"], ["", "def", "run_epoch", "(", "model", ",", "dataset", ",", "optim", ",", "bsz", ",", "target_head", "=", "'target'", ",", "tartan_", "=", "None", ",", "mdev_head", "=", "None", ",", "dev_data", "=", "None", ")", ":", "\n", "\t", "data_itr", "=", "iterator_", "(", "dataset", "[", "0", "]", ",", "bsz", ")", "\n", "dev_head_itr", "=", "None", "if", "tartan_", "is", "None", "else", "iterator_", "(", "dev_data", ",", "16", ")", "# Iterator for fitting the dev head", "\n", "aux_itr", "=", "None", "if", "tartan_", "is", "None", "else", "iterator_", "(", "dataset", "[", "1", "]", ",", "bsz", ")", "# Iterator for the auxiliary data", "\n", "total_correct", ",", "total_egs", ",", "total_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "\n", "for", "batch_", "in", "data_itr", ":", "\n", "\t\t", "xs", ",", "ys", "=", "batch_", "\n", "model_outs", "=", "model", "(", "xs", ",", "head_name", "=", "target_head", ")", "\n", "loss_", ",", "acc_stats", "=", "model", ".", "criterion", "(", "model_outs", ",", "ys", ")", ",", "model", ".", "accuracy", "(", "model_outs", ",", "ys", ")", "\n", "if", "aux_itr", ":", "\n", "# Get the target gradients", "\n", "\t\t\t", "target_grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_", ",", "model", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "\n", "# Get the auxiliary gradients", "\n", "# This is the simple case where there is only 1 auxiliary loss.", "\n", "# If there are n, auxiliary losses then we would need n iterators.", "\n", "try", ":", "\n", "\t\t\t\t", "aux_xs", ",", "aux_ys", "=", "next", "(", "aux_itr", ")", "\n", "", "except", ":", "\n", "\t\t\t\t", "aux_itr", "=", "iterator_", "(", "dataset", "[", "1", "]", ",", "bsz", ")", "\n", "aux_xs", ",", "aux_ys", "=", "next", "(", "aux_itr", ")", "\n", "\n", "", "aux_loss_", "=", "model", ".", "criterion", "(", "model", "(", "aux_xs", ",", "head_name", "=", "'aux'", ")", ",", "aux_ys", ")", "\n", "aux_grads", "=", "torch", ".", "autograd", ".", "grad", "(", "aux_loss_", ",", "model", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "\n", "all_gradients", "=", "[", "target_grads", ",", "aux_grads", "]", "\n", "# Fit the dev-head", "\n", "if", "mdev_head", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "dev_batch", "=", "next", "(", "dev_head_itr", ")", "\n", "meta_batch", "=", "next", "(", "dev_head_itr", ")", "\n", "", "except", ":", "\n", "\t\t\t\t\t", "dev_head_itr", "=", "None", "if", "tartan_", "is", "None", "else", "iterator_", "(", "dev_data", ",", "16", ")", "\n", "dev_batch", "=", "next", "(", "dev_head_itr", ")", "\n", "meta_batch", "=", "next", "(", "dev_head_itr", ")", "\n", "\n", "", "mdev_head", ".", "learn_meta_dev_head", "(", "dev_batch", ",", "model", ".", "loss_fn", ")", "\n", "meta_grads", "=", "mdev_head", ".", "get_meta_grads", "(", "meta_batch", ",", "model", ".", "loss_fn", ")", "\n", "\n", "tartan_", ".", "update_weight_gradients", "(", "all_gradients", ",", "meta_grads", ")", "\n", "\n", "# Get the combined gradients", "\n", "", "combo_grads", "=", "tartan_", ".", "weighted_grads", "(", "all_gradients", ")", "\n", "# Set the combined gradients", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "for", "idx_", ",", "param", "in", "enumerate", "(", "model", ".", "parameters", "(", ")", ")", ":", "\n", "\t\t\t\t\t", "if", "combo_grads", "[", "idx_", "]", "is", "not", "None", ":", "\n", "\t\t\t\t\t\t", "param", ".", "grad", "=", "combo_grads", "[", "idx_", "]", "\n", "\n", "", "", "", "tartan_", ".", "update_weights", "(", ")", "\n", "", "else", ":", "\n", "# There is no auxiliary data. Just do a normal backward", "\n", "\t\t\t", "loss_", ".", "backward", "(", ")", "\n", "\n", "", "total_correct", "+=", "acc_stats", "[", "0", "]", "[", "0", "]", "\n", "total_egs", "+=", "acc_stats", "[", "0", "]", "[", "1", "]", "\n", "total_loss", "+=", "loss_", "*", "acc_stats", "[", "0", "]", "[", "1", "]", "\n", "if", "optim", ":", "\n", "\t\t\t", "optim", ".", "step", "(", ")", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "return", "(", "total_loss", "/", "total_egs", ",", "total_correct", "/", "total_egs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.graph_task_weights": [[95, 103], ["numpy.stack", "range", "plt.legend", "plt.savefig", "plt.plot"], "function", ["None"], ["", "def", "graph_task_weights", "(", "task_names", ",", "weights", ",", "name", ")", ":", "\n", "\t", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "all_weights", "=", "np", ".", "stack", "(", "weights", ")", "\n", "for", "i_", "in", "range", "(", "all_weights", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "\t\t", "plt", ".", "plot", "(", "all_weights", "[", ":", ",", "i_", "]", ",", "label", "=", "task_names", "[", "i_", "]", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "\"{}.png\"", ".", "format", "(", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.run_tartan": [[105, 131], ["run_tartan.get_optimizer", "tartan_plugin.TartanTrainer", "range", "model.get_new_head", "model.MetaDevHead", "run_tartan.run_epoch", "run_tartan.run_epoch", "run_tartan.run_epoch", "print", "print", "print", "dev_accs.append", "test_accs.append", "run_tartan.graph_task_weights", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.get_optimizer", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.get_new_head", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.run_epoch", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.run_epoch", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.run_epoch", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.run_tartan.graph_task_weights"], ["", "def", "run_tartan", "(", "model", ",", "data", ",", "task_names", ",", "bsz", "=", "64", ",", "n_epochs", "=", "30", ",", "is_meta_tartan", "=", "True", ")", ":", "\n", "# Instantiate the optimizer and the tartan trainer", "\n", "\t", "optim", "=", "get_optimizer", "(", "model", ",", "lr", "=", "3e-4", ")", "\n", "tartan_trainer", "=", "TartanTrainer", "(", "task_names", ",", "is_meta_tartan", "=", "is_meta_tartan", ")", "\n", "meta_dev_head", "=", "None", "\n", "if", "is_meta_tartan", ":", "\n", "# Setup the dev head if doing meta-tartan", "\n", "\t\t", "dev_head", "=", "model", ".", "get_new_head", "(", "NUM_TARGET_CLASSES", ",", "'dev_head'", ")", "\n", "meta_dev_head", "=", "MetaDevHead", "(", "model", ",", "dev_head", ")", "\n", "\n", "", "dev_accs", ",", "test_accs", "=", "[", "]", ",", "[", "]", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "\t\t", "train_stats", "=", "run_epoch", "(", "model", ",", "data", ".", "train", ",", "optim", ",", "bsz", ",", "tartan_", "=", "tartan_trainer", ",", "mdev_head", "=", "meta_dev_head", ",", "dev_data", "=", "data", ".", "dev", "[", "0", "]", ")", "\n", "\n", "dev_stats", "=", "run_epoch", "(", "model", ",", "data", ".", "dev", ",", "None", ",", "bsz", ")", "\n", "test_stats", "=", "run_epoch", "(", "model", ",", "data", ".", "test", ",", "None", ",", "bsz", ")", "\n", "print", "(", "'Epoch {}: Train Loss {:.3f}, Train Ac {:.3f}'", ".", "format", "(", "epoch", ",", "*", "train_stats", ")", ")", "\n", "print", "(", "'        : Dev   Loss {:.3f}, Dev   Ac {:.3f}'", ".", "format", "(", "*", "dev_stats", ")", ")", "\n", "print", "(", "'        : Test  Loss {:.3f}, Test  Ac {:.3f}'", ".", "format", "(", "*", "test_stats", ")", ")", "\n", "\n", "dev_accs", ".", "append", "(", "dev_stats", "[", "-", "1", "]", ")", "\n", "test_accs", ".", "append", "(", "test_stats", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "is_meta_tartan", ":", "\n", "\t\t", "graph_task_weights", "(", "task_names", ",", "tartan_trainer", ".", "old_weights", ",", "'meta-tartan'", ")", "\n", "", "return", "test_accs", "[", "np", ".", "argmax", "(", "dev_accs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.BasicBlock.__init__": [[21, 32], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "stride", ",", "dropRate", "=", "0.0", ")", ":", "\n", "\t\t", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "out_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "droprate", "=", "dropRate", "\n", "self", ".", "equalInOut", "=", "(", "in_planes", "==", "out_planes", ")", "\n", "self", ".", "convShortcut", "=", "(", "not", "self", ".", "equalInOut", ")", "and", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "or", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.BasicBlock.forward": [[33, 43], ["wideresnet.BasicBlock.relu2", "wideresnet.BasicBlock.conv2", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "wideresnet.BasicBlock.relu1", "wideresnet.BasicBlock.relu1", "wideresnet.BasicBlock.bn2", "torch.dropout", "torch.dropout", "torch.dropout", "wideresnet.BasicBlock.bn1", "wideresnet.BasicBlock.bn1", "wideresnet.BasicBlock.conv1", "wideresnet.BasicBlock.convShortcut"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "if", "not", "self", ".", "equalInOut", ":", "\n", "\t\t\t", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv1", "(", "out", "if", "self", ".", "equalInOut", "else", "x", ")", ")", ")", "\n", "if", "self", ".", "droprate", ">", "0", ":", "\n", "\t\t\t", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "droprate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "return", "torch", ".", "add", "(", "x", "if", "self", ".", "equalInOut", "else", "self", ".", "convShortcut", "(", "x", ")", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.NetworkBlock.__init__": [[46, 49], ["torch.Module.__init__", "wideresnet.NetworkBlock._make_layer"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.NetworkBlock._make_layer"], ["\t", "def", "__init__", "(", "self", ",", "nb_layers", ",", "in_planes", ",", "out_planes", ",", "block", ",", "stride", ",", "dropRate", "=", "0.0", ")", ":", "\n", "\t\t", "super", "(", "NetworkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "self", ".", "_make_layer", "(", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "dropRate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.NetworkBlock._make_layer": [[50, 55], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "dropRate", ")", ":", "\n", "\t\t", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_layers", ")", ")", ":", "\n", "\t\t\t", "layers", ".", "append", "(", "block", "(", "i", "==", "0", "and", "in_planes", "or", "out_planes", ",", "out_planes", ",", "i", "==", "0", "and", "stride", "or", "1", ",", "dropRate", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.NetworkBlock.forward": [[56, 58], ["wideresnet.NetworkBlock.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.WideResNet.__init__": [[61, 83], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "wideresnet.NetworkBlock", "wideresnet.NetworkBlock", "wideresnet.NetworkBlock", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "out_dict.items", "torch.Linear", "torch.Linear", "torch.Linear", "wideresnet.WideResNet.add_module"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["\t", "def", "__init__", "(", "self", ",", "depth", ",", "out_dict", ",", "widen_factor", "=", "1", ",", "dropRate", "=", "0.0", ")", ":", "\n", "\t\t", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nChannels", "=", "[", "16", ",", "16", "*", "widen_factor", ",", "32", "*", "widen_factor", ",", "64", "*", "widen_factor", "]", "\n", "assert", "(", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ")", "\n", "n", "=", "(", "depth", "-", "4", ")", "/", "6", "\n", "block", "=", "BasicBlock", "\n", "# 1st conv before any network block", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "nChannels", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "# 1st block", "\n", "self", ".", "block1", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "0", "]", ",", "nChannels", "[", "1", "]", ",", "block", ",", "1", ",", "dropRate", ")", "\n", "# 2nd block", "\n", "self", ".", "block2", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "1", "]", ",", "nChannels", "[", "2", "]", ",", "block", ",", "2", ",", "dropRate", ")", "\n", "# 3rd block", "\n", "self", ".", "block3", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "2", "]", ",", "nChannels", "[", "3", "]", ",", "block", ",", "2", ",", "dropRate", ")", "\n", "# global average pooling and classifier", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nChannels", "[", "3", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "# Add these new heads to represent the new output tasks", "\n", "for", "head_name", ",", "num_classes", "in", "out_dict", ".", "items", "(", ")", ":", "\n", "\t\t\t", "this_head", "=", "nn", ".", "Linear", "(", "nChannels", "[", "3", "]", ",", "num_classes", ")", "\n", "self", ".", "add_module", "(", "\"fc-{}\"", ".", "format", "(", "head_name", ")", ",", "this_head", ")", "\n", "", "self", ".", "nChannels", "=", "nChannels", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.WideResNet.get_new_head": [[84, 89], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear.cuda", "wideresnet.WideResNet.add_module"], "methods", ["None"], ["", "def", "get_new_head", "(", "self", ",", "num_classes", ",", "head_name", ")", ":", "\n", "\t\t", "this_head", "=", "nn", ".", "Linear", "(", "self", ".", "nChannels", ",", "num_classes", ")", "\n", "this_head", ".", "cuda", "(", ")", "\n", "self", ".", "add_module", "(", "\"fc-{}\"", ".", "format", "(", "head_name", ")", ",", "this_head", ")", "\n", "return", "this_head", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.wideresnet.WideResNet.forward": [[91, 104], ["wideresnet.WideResNet.conv1", "wideresnet.WideResNet.block1", "wideresnet.WideResNet.block2", "wideresnet.WideResNet.block3", "wideresnet.WideResNet.relu", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "out.view.view.view", "getattr", "wideresnet.WideResNet.bn1", "getattr."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "head_name", "=", "None", ")", ":", "\n", "\t\t", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "block1", "(", "out", ")", "\n", "out", "=", "self", ".", "block2", "(", "out", ")", "\n", "out", "=", "self", ".", "block3", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "8", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "nChannels", ")", "\n", "this_fc", "=", "getattr", "(", "self", ",", "\"fc-{}\"", ".", "format", "(", "head_name", ")", ",", "None", ")", "\n", "if", "this_fc", "is", "None", ":", "\n", "\t\t\t", "return", "out", "\n", "", "else", ":", "\n", "\t\t\t", "return", "this_fc", "(", "out", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.CIFAR100_MSMammals.__init__": [[27, 41], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "data.CIFAR100_MSMammals.group_data", "data.CIFAR100_MSMammals.group_data", "torchvision.transforms.ToTensor"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.CIFAR100_MSMammals.group_data", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.CIFAR100_MSMammals.group_data"], ["\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "save_path", "=", "\"~/\"", "\n", "normalize", "=", "torchvision", ".", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", ",", "\n", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", "\n", ")", "\n", "tform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "\n", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "train", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "save_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "tform", ")", "\n", "test", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "save_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "tform", ")", "\n", "self", ".", "train", "=", "self", ".", "group_data", "(", "train", ",", "dev_split", "=", "0.2", ")", "\n", "self", ".", "test", "=", "self", ".", "group_data", "(", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.CIFAR100_MSMammals.group_data": [[43, 66], ["numpy.random.binomial", "auxiliary[].append", "auxiliary[].append", "target[].append", "target[].append", "[].append", "[].append", "other_classes.index", "len", "msize_mammals_classes.index", "len", "msize_mammals_classes.index"], "methods", ["None"], ["", "def", "group_data", "(", "self", ",", "data_", ",", "dev_split", "=", "-", "1", ")", ":", "\n", "\t\t", "target", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "auxiliary", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "if", "dev_split", ">", "0", ":", "\n", "\t\t\t", "self", ".", "dev", "=", "(", "[", "[", "]", ",", "[", "]", "]", ",", "[", "[", "]", ",", "[", "]", "]", ")", "\n", "", "for", "x", ",", "y", "in", "data_", ":", "\n", "\t\t\t", "if", "y", "in", "msize_mammals_classes", ":", "\n", "\t\t\t\t", "split_proba", "=", "dev_split", "*", "(", "dev_split", ">", "0", ")", "\n", "res", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "1.0", "-", "split_proba", ",", "1", ")", "\n", "if", "res", "[", "0", "]", ":", "\n", "\t\t\t\t\t", "if", "len", "(", "target", "[", "0", "]", ")", ">=", "N_SMALL_TRAIN", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "target", "[", "0", "]", ".", "append", "(", "x", ")", "\n", "target", "[", "1", "]", ".", "append", "(", "msize_mammals_classes", ".", "index", "(", "y", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "if", "len", "(", "self", ".", "dev", "[", "0", "]", "[", "0", "]", ")", ">", "N_SMALL_DEV", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "self", ".", "dev", "[", "0", "]", "[", "0", "]", ".", "append", "(", "x", ")", "\n", "self", ".", "dev", "[", "0", "]", "[", "1", "]", ".", "append", "(", "msize_mammals_classes", ".", "index", "(", "y", ")", ")", "\n", "", "", "else", ":", "\n", "\t\t\t\t", "auxiliary", "[", "0", "]", ".", "append", "(", "x", ")", "\n", "auxiliary", "[", "1", "]", ".", "append", "(", "other_classes", ".", "index", "(", "y", ")", ")", "\n", "", "", "return", "(", "target", ",", "auxiliary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.to_tensor": [[14, 22], ["torch.cuda.is_available", "len", "torch.stack", "torch.tensor", "data[].cuda", "data[].cuda"], "function", ["None"], ["def", "to_tensor", "(", "data", ")", ":", "\n", "\t", "if", "not", "len", "(", "data", "[", "0", "]", ")", ":", "\n", "\t\t", "return", "None", ",", "None", "\n", "", "data", "=", "[", "torch", ".", "stack", "(", "data", "[", "0", "]", ")", ",", "torch", ".", "tensor", "(", "data", "[", "1", "]", ")", "]", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "\t\t", "data", "[", "0", "]", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", "\n", "data", "[", "1", "]", "=", "data", "[", "1", "]", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.iterator_": [[67, 79], ["len", "numpy.array_split", "numpy.random.permutation", "list", "data.to_tensor", "range", "data[].append", "data[].append"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.data.to_tensor"], ["", "", "def", "iterator_", "(", "dataset", ",", "bsz", ",", "shuffle", "=", "True", ")", ":", "\n", "\t", "n_egs", "=", "len", "(", "dataset", "[", "0", "]", ")", "\n", "order", "=", "np", ".", "random", ".", "permutation", "(", "n_egs", ")", "if", "shuffle", "else", "list", "(", "range", "(", "n_egs", ")", ")", "\n", "nchunkz", "=", "n_egs", "//", "bsz", "\n", "chunks", "=", "np", ".", "array_split", "(", "order", ",", "nchunkz", ")", "\n", "for", "this_chunk", "in", "chunks", ":", "\n", "\t\t", "data", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "for", "id_", "in", "this_chunk", ":", "\n", "\t\t\t", "data", "[", "0", "]", ".", "append", "(", "dataset", "[", "0", "]", "[", "id_", "]", ")", "\n", "data", "[", "1", "]", ".", "append", "(", "dataset", "[", "1", "]", "[", "id_", "]", ")", "\n", "", "tensors", "=", "to_tensor", "(", "data", ")", "\n", "yield", "tensors", "", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.__init__": [[14, 21], ["tartan_utils.create_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.create_tensor"], ["\t", "def", "__init__", "(", "self", ",", "task_names", ",", "weight_lr", "=", "5e-2", ",", "is_meta_tartan", "=", "True", ")", ":", "\n", "\t\t", "self", ".", "is_meta_tartan", "=", "is_meta_tartan", "\n", "# Create task weights here. ", "\n", "self", ".", "task_names", "=", "task_names", "\n", "self", ".", "weights", "=", "create_tensor", "(", "(", "len", "(", "task_names", ")", ",", ")", ",", "init", "=", "0.0", ",", "requires_grad", "=", "is_meta_tartan", ",", "is_cuda", "=", "True", ")", "\n", "self", ".", "weight_lr", "=", "weight_lr", "if", "is_meta_tartan", "else", "0.0", "\n", "self", ".", "old_weights", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.get_weights": [[23, 31], ["tartan_plugin.TartanTrainer.weights.cpu().numpy", "torch.no_grad", "torch.softmax", "torch.softmax.cpu().numpy", "tartan_plugin.TartanTrainer.weights.cpu", "torch.softmax.cpu"], "methods", ["None"], ["", "def", "get_weights", "(", "self", ",", "softmax", "=", "True", ")", ":", "\n", "\t\t", "if", "softmax", ":", "\n", "\t\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "sm_", "=", "F", ".", "softmax", "(", "self", ".", "weights", ",", "dim", "=", "-", "1", ")", "\n", "weights", "=", "sm_", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "weights", "=", "self", ".", "weights", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "self", ".", "task_names", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.update_weights": [[33, 39], ["torch.no_grad", "tartan_plugin.TartanTrainer.weights.copy_", "tartan_plugin.TartanTrainer.weights.grad.zero_"], "methods", ["None"], ["", "def", "update_weights", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "is_meta_tartan", ":", "\n", "\t\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "new_weights", "=", "self", ".", "weights", "-", "(", "self", ".", "weight_lr", "*", "self", ".", "weights", ".", "grad", ")", "\n", "self", ".", "weights", ".", "copy_", "(", "new_weights", ")", "\n", "self", ".", "weights", ".", "grad", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.weighted_grads": [[42, 57], ["len", "tartan_plugin.TartanTrainer.get_weights", "torch.no_grad", "range", "range", "combo_grad.append", "len", "torch.zeros_like.add_", "torch.zeros_like", "softmax_[].item"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.get_weights"], ["", "", "", "def", "weighted_grads", "(", "self", ",", "task_gradients", ")", ":", "\n", "\t\t", "nparams", "=", "len", "(", "task_gradients", "[", "0", "]", ")", "\n", "combo_grad", "=", "[", "]", "\n", "softmax_", "=", "self", ".", "get_weights", "(", ")", "[", "-", "1", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "for", "i_", "in", "range", "(", "nparams", ")", ":", "\n", "\t\t\t\t", "new_grad", "=", "None", "\n", "for", "j_", "in", "range", "(", "len", "(", "self", ".", "task_names", ")", ")", ":", "\n", "\t\t\t\t\t", "this_grad", "=", "task_gradients", "[", "j_", "]", "[", "i_", "]", "\n", "if", "this_grad", "is", "not", "None", ":", "\n", "\t\t\t\t\t\t", "if", "new_grad", "is", "None", ":", "# Initialize to all zeros here", "\n", "\t\t\t\t\t\t\t", "new_grad", "=", "torch", ".", "zeros_like", "(", "this_grad", ")", "\n", "", "new_grad", ".", "add_", "(", "this_grad", "*", "softmax_", "[", "j_", "]", ".", "item", "(", ")", ")", "\n", "", "", "combo_grad", ".", "append", "(", "new_grad", ")", "\n", "", "", "return", "combo_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.update_weight_gradients": [[59, 68], ["tartan_plugin.TartanTrainer.old_weights.append", "tartan_plugin.TartanTrainer.get_weights", "torch.zeros_like", "torch.no_grad", "range", "len", "tartan_utils.cosine", "tartan_plugin.TartanTrainer.weights.grad[].add_"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_plugin.TartanTrainer.get_weights", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.cosine"], ["", "def", "update_weight_gradients", "(", "self", ",", "task_gradients", ",", "dev_head_gradients", ")", ":", "\n", "\t\t", "self", ".", "old_weights", ".", "append", "(", "self", ".", "get_weights", "(", ")", "[", "-", "1", "]", ")", "\n", "if", "self", ".", "is_meta_tartan", ":", "\n", "\t\t\t", "if", "self", ".", "weights", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t", "self", ".", "weights", ".", "grad", "=", "torch", ".", "zeros_like", "(", "self", ".", "weights", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "for", "i_", "in", "range", "(", "len", "(", "task_gradients", ")", ")", ":", "\n", "\t\t\t\t\t", "cos_sim", "=", "cosine", "(", "task_gradients", "[", "i_", "]", ",", "dev_head_gradients", ")", "\n", "self", ".", "weights", ".", "grad", "[", "i_", "]", ".", "add_", "(", "-", "cos_sim", ")", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.__init__": [[8, 15], ["torch.Module.__init__", "wideresnet.WideResNet", "model.WideResnet.model.apply", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "tartan_utils.weight_init"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.weight_init"], ["\t", "def", "__init__", "(", "\n", "self", ",", "output_classes_dict", ",", "depth", "=", "16", ",", "widen_factor", "=", "2", ",", "loss_name", "=", "'CE'", ",", "dropRate", "=", "0.1", "\n", ")", ":", "\n", "\t\t", "super", "(", "WideResnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "WideResNet", "(", "depth", ",", "output_classes_dict", ",", "widen_factor", "=", "widen_factor", ",", "dropRate", "=", "dropRate", ")", "\n", "self", ".", "model", ".", "apply", "(", "weight_init", "(", "'kaiming_normal'", ")", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.get_new_head": [[16, 18], ["model.WideResnet.model.get_new_head"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.get_new_head"], ["", "def", "get_new_head", "(", "self", ",", "num_classes", ",", "head_name", ")", ":", "\n", "\t\t", "return", "self", ".", "model", ".", "get_new_head", "(", "num_classes", ",", "head_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.forward": [[19, 22], ["model.WideResnet.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "head_name", "=", "None", ")", ":", "\n", "\t\t", "m_out", "=", "self", ".", "model", "(", "x", ",", "head_name", "=", "head_name", ")", "\n", "return", "m_out", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.criterion": [[23, 25], ["model.WideResnet.loss_fn"], "methods", ["None"], ["", "def", "criterion", "(", "self", ",", "outs", ",", "target", ")", ":", "\n", "\t\t", "return", "self", ".", "loss_fn", "(", "outs", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.WideResnet.accuracy": [[26, 30], ["torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.eq().sum().item", "torch.argmax.eq().sum().item", "torch.argmax.eq().sum", "torch.argmax.eq().sum", "len", "len", "torch.argmax.eq", "torch.argmax.eq"], "methods", ["None"], ["", "def", "accuracy", "(", "self", ",", "outs", ",", "target", ")", ":", "\n", "\t\t", "preds", "=", "torch", ".", "argmax", "(", "outs", ",", "dim", "=", "-", "1", ")", "\n", "ncorrect", "=", "(", "preds", ".", "eq", "(", "target", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "(", "ncorrect", ",", "len", "(", "target", ")", ")", ",", "ncorrect", "/", "(", "len", "(", "target", ")", "*", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.__init__": [[34, 45], ["torch.Module.__init__", "tartan_utils.weight_init"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__", "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.weight_init"], ["\t", "def", "__init__", "(", "\n", "self", ",", "model_body", ",", "dev_head", ",", "head_init_fn", "=", "None", ",", "\n", "optim_wd", "=", "0.1", ",", "optim_lr", "=", "3e-2", ",", "optim_steps", "=", "10", "\n", ")", ":", "\n", "\t\t", "super", "(", "MetaDevHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_body", "=", "model_body", "\n", "self", ".", "dev_head", "=", "dev_head", "\n", "self", ".", "head_init_fn", "=", "head_init_fn", "if", "head_init_fn", "else", "weight_init", "(", "'kaiming_unif'", ")", "\n", "self", ".", "optim_wd", "=", "optim_wd", "\n", "self", ".", "optim_lr", "=", "optim_lr", "\n", "self", ".", "optim_gd_steps", "=", "optim_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.reset_dev_head": [[47, 49], ["model.MetaDevHead.dev_head.apply"], "methods", ["None"], ["", "def", "reset_dev_head", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "dev_head", ".", "apply", "(", "self", ".", "head_init_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.learn_meta_dev_head": [[51, 71], ["model.MetaDevHead.reset_dev_head", "model.MetaDevHead.dev_head.parameters", "torch.optim.AdamW", "torch.optim.AdamW", "range", "dev_loss_fn", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.optim.AdamW.step", "torch.optim.AdamW.step", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.zero_grad", "model.MetaDevHead.dev_head", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "model.MetaDevHead.model_body", "p.grad.add_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.reset_dev_head"], ["", "def", "learn_meta_dev_head", "(", "self", ",", "dev_batch", ",", "dev_loss_fn", ")", ":", "\n", "\t\t", "self", ".", "reset_dev_head", "(", ")", "\n", "dev_head_params", "=", "self", ".", "dev_head", ".", "parameters", "(", ")", "\n", "optim", "=", "AdamW", "(", "dev_head_params", ",", "weight_decay", "=", "self", ".", "optim_wd", ",", "lr", "=", "self", ".", "optim_lr", ")", "\n", "dev_in", ",", "dev_out", "=", "dev_batch", "\n", "for", "j_", "in", "range", "(", "self", ".", "optim_gd_steps", ")", ":", "\n", "\t\t\t", "loss", "=", "dev_loss_fn", "(", "self", ".", "dev_head", "(", "self", ".", "model_body", "(", "dev_in", ")", ")", ",", "dev_out", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "dev_head_params", ",", "allow_unused", "=", "True", ")", "\n", "\n", "# Populate the gradients", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "for", "p", ",", "g", "in", "zip", "(", "dev_head_params", ",", "grads", ")", ":", "\n", "\t\t\t\t\t", "if", "p", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t\t", "p", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "p", ".", "grad", ".", "add_", "(", "g", ")", "\n", "del", "g", "\n", "\n", "# Perform descent on only the dev-head", "\n", "", "", "optim", ".", "step", "(", ")", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.model.MetaDevHead.get_meta_grads": [[73, 79], ["dev_loss_fn", "list", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "model.MetaDevHead.dev_head", "model.MetaDevHead.model_body.parameters", "model.MetaDevHead.model_body"], "methods", ["None"], ["", "", "def", "get_meta_grads", "(", "self", ",", "dev_batch", ",", "dev_loss_fn", ")", ":", "\n", "\t\t", "dev_in", ",", "dev_out", "=", "dev_batch", "\n", "loss", "=", "dev_loss_fn", "(", "self", ".", "dev_head", "(", "self", ".", "model_body", "(", "dev_in", ")", ")", ",", "dev_out", ")", "\n", "all_params", "=", "list", "(", "self", ".", "model_body", ".", "parameters", "(", ")", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "all_params", ",", "allow_unused", "=", "True", ")", "\n", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.dot_prod": [[9, 18], ["zip", "isinstance", "total.item"], "function", ["None"], ["def", "dot_prod", "(", "g1", ",", "g2", ")", ":", "\n", "\t", "total", "=", "0.0", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "g1", ",", "g2", ")", ":", "\n", "\t\t", "if", "p1", "is", "None", "or", "p2", "is", "None", ":", "\n", "\t\t\t", "continue", "\n", "", "sum_", "=", "(", "p1", "*", "p2", ")", ".", "sum", "(", ")", "\n", "total", "+=", "sum_", "\n", "", "total", "=", "total", ".", "item", "(", ")", "if", "isinstance", "(", "total", ",", "torch", ".", "Tensor", ")", "else", "total", "\n", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.calc_norm": [[20, 26], ["numpy.sqrt", "norm.item"], "function", ["None"], ["", "def", "calc_norm", "(", "list_of_vec", ")", ":", "\n", "\t", "norm", "=", "0.0", "\n", "for", "g_", "in", "list_of_vec", ":", "\n", "\t\t", "if", "g_", "is", "not", "None", ":", "\n", "\t\t\t", "norm", "+=", "(", "g_", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "", "return", "np", ".", "sqrt", "(", "norm", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.cosine": [[28, 33], ["tartan_utils.calc_norm", "tartan_utils.calc_norm", "tartan_utils.dot_prod"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.dot_prod"], ["", "def", "cosine", "(", "vec_list_a", ",", "vec_list_b", ")", ":", "\n", "\t", "a_norm", "=", "calc_norm", "(", "vec_list_a", ")", "\n", "b_norm", "=", "calc_norm", "(", "vec_list_b", ")", "\n", "cos_", "=", "dot_prod", "(", "vec_list_a", ",", "vec_list_b", ")", "/", "(", "a_norm", "*", "b_norm", "+", "EPS", ")", "\n", "return", "cos_", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.create_tensor": [[35, 42], ["torch.ones", "torch.ones", "inits.float().cuda", "inits.float", "inits.float"], "function", ["None"], ["", "def", "create_tensor", "(", "shape", ",", "init", "=", "0.0", ",", "requires_grad", "=", "True", ",", "is_cuda", "=", "True", ")", ":", "\n", "\t", "inits", "=", "torch", ".", "ones", "(", "*", "shape", ")", "*", "init", "\n", "# Create the weights", "\n", "weights", "=", "inits", ".", "float", "(", ")", ".", "cuda", "(", ")", "if", "is_cuda", "else", "inits", ".", "float", "(", ")", "\n", "if", "requires_grad", ":", "\n", "\t\t", "weights", ".", "requires_grad", "=", "True", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.simple_vision_tartan.tartan_utils.weight_init": [[45, 60], ["isinstance", "isinstance", "isinstance", "torch.nn.init.xavier_uniform_", "torch.nn.init.zeros_", "layer.weight.data.fill_", "layer.bias.data.zero_", "torch.nn.init.kaiming_uniform_", "torch.nn.init.kaiming_normal_"], "function", ["None"], ["", "def", "weight_init", "(", "init_method", ")", ":", "\n", "\t", "def", "initfn", "(", "layer", ")", ":", "\n", "\t\t", "if", "isinstance", "(", "layer", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "\t\t\t", "if", "init_method", "==", "'xavier_unif'", ":", "\n", "\t\t\t\t", "xavier_uniform_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "", "elif", "init_method", "==", "'kaiming_unif'", ":", "\n", "\t\t\t\t", "kaiming_uniform_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "", "elif", "init_method", "==", "'kaiming_normal'", ":", "\n", "\t\t\t\t", "kaiming_normal_", "(", "layer", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "\t\t\t\t", "zeros_", "(", "layer", ".", "bias", ".", "data", ")", "\n", "", "", "elif", "isinstance", "(", "layer", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "\t\t\t", "layer", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "layer", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "return", "initfn", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.__init__": [[39, 91], ["isinstance", "endtask_aware.TartanModel.setup_datasets", "endtask_aware.TartanModel.setup_classifier", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_datasets", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_classifier"], ["\t", "def", "__init__", "(", "\n", "self", ",", "\n", "model_name", ",", "# 'name of base lm model - eg - robertabase'", "\n", "base_lm_model", ",", "\n", "base_task_dataset_files", ",", "# Dictionary of task_split : task_file", "\n", "\n", "max_seq_len", "=", "512", ",", "\n", "dropout", "=", "0.0", ",", "\n", "embedding_dim", "=", "768", ",", "\n", "ff_multiplier", "=", "1", ",", "\n", "num_layers", "=", "1", ",", "\n", "max_norm", "=", "1.0", ",", "\n", "\n", "batch_sz", "=", "8", ",", "\n", "save_path", "=", "None", ",", "\n", "primary_task_id", "=", "None", ",", "\n", "grad_accum_factor", "=", "8", ",", "\n", "dev_batch_sz", "=", "128", ",", "\n", ")", ":", "\n", "\t\t", "assert", "save_path", "is", "not", "None", ",", "'Invalid Save Path Provided for Classifier Head'", "\n", "assert", "isinstance", "(", "base_task_dataset_files", ",", "dict", ")", ",", "'Invalid type of base_task_dataset_files. Expected dictionary'", "\n", "assert", "primary_task_id", "is", "not", "None", ",", "'No primary task id is given'", "\n", "assert", "'train'", "in", "base_task_dataset_files", ",", "'Primary Task not included in the list of dataset files'", "\n", "\n", "self", ".", "base_lm_model", "=", "base_lm_model", "\n", "self", ".", "file_for_split", "=", "base_task_dataset_files", "\n", "self", ".", "primary_task_id", "=", "primary_task_id", "\n", "prim_dataset_map", "=", "{", "self", ".", "primary_task_id", ":", "base_task_dataset_files", "[", "'train'", "]", "}", "\n", "self", ".", "datasets", "=", "self", ".", "setup_datasets", "(", "prim_dataset_map", ",", "model_name", ",", "max_seq_len", ",", "lazy", "=", "False", ")", "\n", "\n", "\n", "self", ".", "model_name", "=", "model_name", "\n", "\n", "# Cached for later use", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "ff_multiplier", "=", "ff_multiplier", "\n", "self", ".", "setup_classifier", "(", "\n", "dropout", ",", "self", ".", "primary_task_id", ",", "self", ".", "datasets", "[", "self", ".", "primary_task_id", "]", ",", "\n", "embedding_dim", ",", "ff_multiplier", ",", "num_layers", "=", "num_layers", "\n", ")", "\n", "self", ".", "batch_sz", "=", "batch_sz", "\n", "self", ".", "max_norm", "=", "1.0", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "grad_accum_factor", "=", "grad_accum_factor", "\n", "self", ".", "aux_grads", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "dev_batch_sz", "=", "dev_batch_sz", "# Batch Size for dev-set", "\n", "self", ".", "label_vocab", "=", "None", "\n", "self", ".", "data_splits", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_alpha_generator": [[96, 109], ["alpha_generator.get_alpha_generator", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.get_alpha_generator"], ["def", "setup_alpha_generator", "(", "self", ",", "options", ")", ":", "\n", "# Remove the primary task name if in list of auxiliary tasks", "\n", "\t\t", "aux_tasks", "=", "[", "x", "for", "x", "in", "options", ".", "aux_task_names", "if", "x", "!=", "self", ".", "primary_task_id", "]", "\n", "self", ".", "aux_tasks", "=", "aux_tasks", "\n", "for", "x", "in", "self", ".", "aux_tasks", ":", "\n", "\t\t\t", "self", ".", "aux_grads", "[", "x", "]", "=", "None", "\n", "", "self", ".", "alpha_generator_algo", "=", "get_alpha_generator", "(", "options", ",", "self", ".", "primary_task_id", ",", "aux_tasks", ")", "\n", "# Setup datastructures for logging performance metrics", "\n", "if", "self", ".", "alpha_generator_algo", ".", "is_meta", ":", "\n", "\t\t\t", "self", ".", "options", "=", "options", "\n", "self", ".", "dp_stats", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "weight_stats", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "meta_head_perfs", "=", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_classifier": [[112, 125], ["modules.seq2vec_encoders.cls_pooler.CLSPooler", "allennlp.modules.FeedForward", "models.BasicClassifierWithF1", "models.BasicClassifierWithF1.to", "endtask_aware.TartanModel.set_model", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_model"], ["", "", "def", "setup_classifier", "(", "self", ",", "dropout", ",", "task_idx", ",", "dataset_dict", ",", "embedding_dim", ",", "ff_multiplier", ",", "num_layers", "=", "1", ")", ":", "\n", "\t\t", "vocab", "=", "dataset_dict", "[", "'vocab'", "]", "\n", "text_field_embedder", "=", "self", ".", "base_lm_model", "\n", "seq2vec_encoder", "=", "CLSPooler", "(", "embedding_dim", ")", "\n", "hidden_dim", "=", "embedding_dim", "*", "ff_multiplier", "\n", "feedforward", "=", "FeedForward", "(", "\n", "embedding_dim", ",", "num_layers", ",", "hidden_dims", "=", "hidden_dim", ",", "\n", "activations", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", ",", "dropout", "=", "dropout", "\n", ")", "\n", "classifier", "=", "BasicClassifierWithF1", "(", "vocab", ",", "text_field_embedder", ",", "seq2vec_encoder", ",", "feedforward", ",", "dropout", "=", "dropout", ",", "initializer", "=", "None", ")", "\n", "classifier", ".", "to", "(", "self", ".", "base_lm_model", ".", "device", ")", "\n", "self", ".", "set_model", "(", "task_idx", ",", "classifier", ")", "\n", "return", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to": [[127, 133], ["endtask_aware.TartanModel.datasets.keys", "endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.to"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "\t\t", "for", "key", "in", "self", ".", "datasets", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "this_classf", "=", "self", ".", "get_model", "(", "key", ")", "\n", "this_classf", ".", "to", "(", "device", ")", "\n", "# Since we have moved this to gpu, we need to re-set the base.", "\n", "this_classf", ".", "_text_field_embedder", "=", "self", ".", "base_lm_model", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_optim": [[136, 140], ["None"], "methods", ["None"], ["", "", "def", "set_optim", "(", "self", ",", "optimizer", ",", "scheduler", ")", ":", "\n", "# Do this to set the optimizer", "\n", "\t\t", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "ft_lr_scheduler", "=", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save": [[146, 162], ["endtask_aware.TartanModel.datasets.keys", "torch.save", "endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.state_dict", "hasattr", "endtask_aware.TartanModel.optimizer.state_dict", "hasattr", "endtask_aware.TartanModel.ft_lr_scheduler.state_dict", "hasattr", "dict", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model"], ["def", "save", "(", "self", ")", ":", "\n", "\t\t", "path", "=", "self", ".", "save_path", "\n", "save_dict", "=", "{", "\n", "'optimizer_sd'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "if", "hasattr", "(", "self", ",", "'optimizer'", ")", "else", "None", ",", "\n", "'scheduler'", ":", "self", ".", "ft_lr_scheduler", ".", "state_dict", "(", ")", "if", "hasattr", "(", "self", ",", "'ft_lr_scheduler'", ")", "else", "None", ",", "\n", "'perfs'", ":", "dict", "(", "self", ".", "perfs", ")", "if", "hasattr", "(", "self", ",", "'perfs'", ")", "else", "None", ",", "\n", "'dp_stats'", ":", "self", ".", "dp_stats", "if", "hasattr", "(", "self", ",", "'dp_stats'", ")", "else", "None", ",", "\n", "'weight_stats'", ":", "self", ".", "weight_stats", "if", "hasattr", "(", "self", ",", "'weight_stats'", ")", "else", "None", ",", "\n", "'meta_head_perfs'", ":", "self", ".", "meta_head_perfs", "if", "hasattr", "(", "self", ",", "'meta_head_perfs'", ")", "else", "None", ",", "\n", "}", "\n", "for", "key", "in", "self", ".", "datasets", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "this_classf", "=", "self", ".", "get_model", "(", "key", ")", "\n", "save_dict", "[", "key", "]", "=", "this_classf", ".", "state_dict", "(", ")", "\n", "", "torch", ".", "save", "(", "\n", "save_dict", ",", "\n", "path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load": [[165, 175], ["torch.load", "endtask_aware.TartanModel.datasets.keys", "endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.load_state_dict", "hasattr", "endtask_aware.TartanModel.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model"], ["", "def", "load", "(", "self", ")", ":", "\n", "\t\t", "state_dict", "=", "torch", ".", "load", "(", "self", ".", "save_path", ")", "\n", "for", "key", "in", "self", ".", "datasets", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "this_classf", "=", "self", ".", "get_model", "(", "key", ")", "\n", "this_classf", ".", "load_state_dict", "(", "state_dict", "[", "key", "]", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'optimizer'", ")", "and", "(", "'optimizer_sd'", "in", "state_dict", ")", ":", "\n", "\t\t\t", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer_sd'", "]", ")", "\n", "self", ".", "ft_lr_scheduler", "=", "state_dict", "[", "'scheduler'", "]", "\n", "", "self", ".", "base_lm_model", "=", "this_classf", ".", "_text_field_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load_primary": [[178, 185], ["endtask_aware.TartanModel.get_model", "torch.load", "endtask_aware.TartanModel.load_state_dict", "endtask_aware.TartanModel.to"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to"], ["", "def", "load_primary", "(", "self", ",", "device", ")", ":", "\n", "# We are assuming that what we care about is the primary task parameters", "\n", "\t\t", "primary_classifier", "=", "self", ".", "get_model", "(", "self", ".", "primary_task_id", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "self", ".", "save_path", ")", "# Load the state dict from the save path", "\n", "primary_classifier", ".", "load_state_dict", "(", "state_dict", "[", "self", ".", "primary_task_id", "]", ")", "\n", "primary_classifier", ".", "to", "(", "device", ")", "\n", "self", ".", "base_lm_model", "=", "primary_classifier", ".", "_text_field_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_save_path": [[187, 189], ["None"], "methods", ["None"], ["", "def", "set_save_path", "(", "self", ",", "save_path", ")", ":", "\n", "\t\t", "self", ".", "save_path", "=", "save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model": [[191, 196], ["getattr"], "methods", ["None"], ["", "def", "get_model", "(", "self", ",", "model_name", ",", "check_", "=", "True", ")", ":", "\n", "\t\t", "this_classf", "=", "getattr", "(", "self", ",", "\"AuxHead-{}\"", ".", "format", "(", "model_name", ")", ",", "None", ")", "\n", "if", "check_", ":", "\n", "\t\t\t", "assert", "this_classf", "is", "not", "None", ",", "'Auxiliary Classifier {} not found'", ".", "format", "(", "model_name", ")", "\n", "", "return", "this_classf", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_model": [[198, 201], ["setattr"], "methods", ["None"], ["", "def", "set_model", "(", "self", ",", "model_name", ",", "new_model", ")", ":", "\n", "\t\t", "model_name", "=", "\"AuxHead-{}\"", ".", "format", "(", "model_name", ")", "\n", "setattr", "(", "self", ",", "model_name", ",", "new_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_metrics": [[203, 208], ["endtask_aware.TartanModel.get_metrics", "endtask_aware.TartanModel.get_model"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model"], ["", "def", "get_metrics", "(", "self", ",", "this_classf", "=", "None", ",", "reset", "=", "False", ")", ":", "\n", "\t\t", "if", "this_classf", "is", "None", ":", "\n", "\t\t\t", "this_classf", "=", "self", ".", "get_model", "(", "self", ".", "primary_task_id", ")", "\n", "# Get the metrics from the classifier", "\n", "", "return", "this_classf", ".", "get_metrics", "(", "reset", "=", "reset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_classifier_params": [[210, 225], ["enumerate", "endtask_aware.TartanModel.datasets.keys", "endtask_aware.TartanModel.get_model", "param_list.extend", "param_list.extend", "endtask_aware.TartanModel.named_parameters", "endtask_aware.TartanModel.named_parameters"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model"], ["", "def", "get_classifier_params", "(", "self", ",", "keys", "=", "None", ",", "withbase", "=", "False", ")", ":", "\n", "\t\t", "param_list", "=", "[", "]", "\n", "# Get all the classifier params if keys is not specified", "\n", "if", "keys", "is", "None", ":", "\n", "\t\t\t", "keys", "=", "self", ".", "datasets", ".", "keys", "(", ")", "\n", "", "for", "_", ",", "key", "in", "enumerate", "(", "keys", ")", ":", "\n", "\t\t\t", "this_classf", "=", "self", ".", "get_model", "(", "key", ")", "\n", "if", "withbase", "and", "key", "==", "self", ".", "primary_task_id", ":", "\n", "# This is the case where we need all the parameters for optional finetuning the primary task.", "\n", "\t\t\t\t", "param_list", ".", "extend", "(", "this_classf", ".", "named_parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "# Removing the base RoBERTa model so we have only the added on classifier heads", "\n", "\t\t\t\t", "filtered_param_list", "=", "[", "param", "for", "pname", ",", "param", "in", "this_classf", ".", "named_parameters", "(", ")", "if", "'_text_field_embedder'", "not", "in", "pname", "]", "\n", "param_list", ".", "extend", "(", "filtered_param_list", ")", "\n", "", "", "return", "param_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.learn_dev_head": [[232, 291], ["hasattr", "endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.get_data_samples", "range", "endtask_aware.TartanModel.meta_head_perfs[].append", "endtask_aware.TartanModel.meta_head_perfs[].append", "endtask_aware.TartanModel.meta_head_perfs[].append", "endtask_aware.TartanModel.setup_classifier", "endtask_aware.TartanModel.get_classifier_params", "transformers.AdamW", "endtask_aware.TartanModel.", "torch.autograd.grad", "zip", "transformers.AdamW.step", "endtask_aware.TartanModel.get_metrics", "all_metrics[].append", "all_metrics[].append", "all_metrics[].append", "loss_.item", "torch.cuda.empty_cache", "numpy.mean", "numpy.mean", "numpy.mean", "endtask_aware.TartanModel.get_dataset", "loss_.item", "abs", "eval"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_data_samples", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_classifier_params", "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_dataset"], ["def", "learn_dev_head", "(", "self", ",", "sample_sz", "=", "-", "1", ")", ":", "\n", "\t\t", "assert", "hasattr", "(", "self", ",", "'options'", ")", ",", "'The options need to be set for training of the dev head'", "\n", "\n", "dev_head_name", "=", "\"{}-{}\"", ".", "format", "(", "'dev'", ",", "self", ".", "primary_task_id", ")", "\n", "this_classf", "=", "self", ".", "get_model", "(", "dev_head_name", ",", "check_", "=", "False", ")", "\n", "\n", "if", "this_classf", "is", "None", ":", "\n", "# Need to instantiate the classifier head", "\n", "\t\t\t", "this_classf", "=", "self", ".", "setup_classifier", "(", "\n", "self", ".", "dropout", ",", "dev_head_name", ",", "self", ".", "get_dataset", "(", "'dev'", ")", ",", "# We use the dev-data to instantiate the classifier", "\n", "self", ".", "embedding_dim", ",", "self", ".", "ff_multiplier", ",", "num_layers", "=", "self", ".", "num_layers", "\n", ")", "\n", "# Setup optimizer for dev head", "\n", "dev_params", "=", "self", ".", "get_classifier_params", "(", "[", "dev_head_name", "]", ",", "withbase", "=", "False", ")", "\n", "dev_optim", "=", "AdamW", "(", "\n", "dev_params", ",", "betas", "=", "eval", "(", "self", ".", "options", ".", "classf_betas", ")", ",", "\n", "weight_decay", "=", "self", ".", "options", ".", "classf_dev_wd", ",", "lr", "=", "self", ".", "options", ".", "classf_dev_lr", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "this_classf", "# We train this once and re-use", "\n", "\n", "# This is the first time instantiating this head so we need to train it", "\n", "", "assert", "dev_optim", "is", "not", "None", ",", "'The optimizer for the dev head has not been instantiated'", "\n", "assert", "dev_params", "is", "not", "None", ",", "'Dev Params should have been instantiated above'", "\n", "\n", "\n", "# perform gradient descent to get the dev-head", "\n", "sample_sz", "=", "sample_sz", "if", "sample_sz", ">", "0", "else", "self", ".", "dev_batch_sz", "\n", "samples", "=", "self", ".", "get_data_samples", "(", "'dev'", ",", "sample_sz", ")", "\n", "prev_loss_", ",", "tol", "=", "1e10", ",", "1e-3", "\n", "all_metrics", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "options", ".", "classf_ft_iters", ")", ":", "\n", "\t\t\t", "output", "=", "this_classf", "(", "*", "samples", ")", "\n", "loss_", "=", "output", "[", "'loss'", "]", "\n", "# This ensures that we only train the dev-head and keep the body fixed", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_", ",", "dev_params", ",", "allow_unused", "=", "True", ")", "\n", "for", "p", ",", "g", "in", "zip", "(", "dev_params", ",", "grads", ")", ":", "\n", "\t\t\t\t", "assert", "g", "is", "not", "None", ",", "'This should have a gradient'", "\n", "p", ".", "grad", "=", "g", "\n", "", "dev_optim", ".", "step", "(", ")", "\n", "\n", "# Save performance for analysis", "\n", "metrics", "=", "self", ".", "get_metrics", "(", "this_classf", "=", "this_classf", ",", "reset", "=", "True", ")", "\n", "all_metrics", "[", "0", "]", ".", "append", "(", "metrics", "[", "'f1'", "]", ")", "\n", "all_metrics", "[", "1", "]", ".", "append", "(", "metrics", "[", "'accuracy'", "]", ")", "\n", "all_metrics", "[", "2", "]", ".", "append", "(", "loss_", ".", "item", "(", ")", ")", "\n", "\n", "if", "abs", "(", "loss_", "-", "prev_loss_", ")", "<", "tol", ":", "\n", "\t\t\t\t", "break", "\n", "", "prev_loss_", "=", "loss_", ".", "item", "(", ")", "\n", "del", "grads", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# Save performance for analysis", "\n", "", "self", ".", "meta_head_perfs", "[", "'f1'", "]", ".", "append", "(", "np", ".", "mean", "(", "all_metrics", "[", "0", "]", ")", ")", "\n", "self", ".", "meta_head_perfs", "[", "'accuracy'", "]", ".", "append", "(", "np", ".", "mean", "(", "all_metrics", "[", "1", "]", ")", ")", "\n", "self", ".", "meta_head_perfs", "[", "'loss'", "]", ".", "append", "(", "np", ".", "mean", "(", "all_metrics", "[", "2", "]", ")", ")", "\n", "return", "this_classf", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_dev_and_get_grads_head": [[293, 311], ["endtask_aware.TartanModel.learn_dev_head", "endtask_aware.TartanModel.get_data_samples", "torch.autograd.grad", "endtask_aware.TartanModel.", "endtask_aware.TartanModel.parameters", "str", "print", "torch.cuda.empty_cache", "torch.autograd.grad", "endtask_aware.TartanModel.", "endtask_aware.TartanModel.parameters"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.learn_dev_head", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_data_samples"], ["", "def", "set_dev_and_get_grads_head", "(", "self", ")", ":", "\n", "# Learn the meta-dev head here", "\n", "\t\t", "this_classf", "=", "self", ".", "learn_dev_head", "(", ")", "\n", "\n", "# Get the dev gradient here", "\n", "dev_sent", ",", "dev_labels", "=", "self", ".", "get_data_samples", "(", "'dev'", ",", "self", ".", "batch_sz", ")", "\n", "try", ":", "\n", "\t\t\t", "loss_", "=", "this_classf", "(", "dev_sent", ",", "dev_labels", ")", "[", "'loss'", "]", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_", ",", "this_classf", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "\t\t\t", "if", "'out of memory'", "in", "str", "(", "e", ")", ":", "\n", "\t\t\t\t", "print", "(", "'| WARNING: ran out of memory, retrying batch in set_dev_head'", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "loss_", "=", "this_classf", "(", "dev_sent", ",", "dev_labels", ")", "[", "'loss'", "]", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_", ",", "this_classf", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "raise", "e", "\n", "", "", "return", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.reset_dev_head": [[313, 319], ["endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.set_model"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_model"], ["", "def", "reset_dev_head", "(", "self", ")", ":", "\n", "\t\t", "dev_head_name", "=", "\"{}-{}\"", ".", "format", "(", "'dev'", ",", "self", ".", "primary_task_id", ")", "\n", "this_classf", "=", "self", ".", "get_model", "(", "dev_head_name", ")", "\n", "if", "this_classf", "is", "not", "None", ":", "\n", "\t\t\t", "del", "this_classf", "\n", "", "self", ".", "set_model", "(", "dev_head_name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_aux_grads": [[326, 332], ["None"], "methods", ["None"], ["def", "set_aux_grads", "(", "self", ",", "grads", ",", "aux_task_name", "=", "'MLM'", ")", ":", "\n", "\t\t", "if", "grads", "is", "not", "None", ":", "\n", "\t\t\t", "assert", "self", ".", "aux_grads", "[", "aux_task_name", "]", "is", "None", ",", "'Need to make sure grads are none before setting'", "\n", "", "else", ":", "\n", "\t\t\t", "assert", "self", ".", "aux_grads", "[", "aux_task_name", "]", "is", "not", "None", ",", "'Need to make sure grads are set before setting to none'", "\n", "", "self", ".", "aux_grads", "[", "aux_task_name", "]", "=", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.classifier_sample_grad": [[337, 385], ["endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.get_data_samples", "torch.autograd.grad", "endtask_aware.TartanModel.", "endtask_aware.TartanModel.parameters", "endtask_aware.TartanModel.aux_grads.items", "endtask_aware.TartanModel.set_dev_and_get_grads_head", "endtask_aware.TartanModel.alpha_generator_algo.set_weight_gradients", "torch.no_grad", "enumerate", "hasattr", "utils.get_body_end", "zip", "p.grad.add_", "endtask_aware.TartanModel.parameters", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_data_samples", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_dev_and_get_grads_head", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.set_weight_gradients", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.get_body_end"], ["", "def", "classifier_sample_grad", "(", "self", ")", ":", "\n", "\n", "# Get the gradients w.r.t the primary task", "\n", "\t\t", "this_classf", "=", "self", ".", "get_model", "(", "self", ".", "primary_task_id", ")", "\n", "sent_dict", ",", "labels", "=", "self", ".", "get_data_samples", "(", "'train'", ",", "self", ".", "batch_sz", ")", "\n", "loss_", "=", "this_classf", "(", "sent_dict", ",", "labels", ")", "[", "'loss'", "]", "\n", "prim_gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_", ",", "this_classf", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "\n", "if", "self", ".", "alpha_generator_algo", ".", "is_meta", ":", "\n", "# We are doing meta-learning the task weights.", "\n", "\t\t\t", "gradient_dict", "=", "{", "}", "\n", "gradient_dict", "[", "self", ".", "primary_task_id", "]", "=", "prim_gradients", "\n", "\n", "# We only use the gradients of the shared body of the network for when updating the task weightings.", "\n", "if", "not", "hasattr", "(", "self", ",", "'body_params_end'", ")", ":", "\n", "\t\t\t\t", "self", ".", "body_params_end", "=", "get_body_end", "(", "this_classf", ")", "\n", "\n", "# Set the gradients of the other tasks involved", "\n", "", "for", "key", ",", "grad_list", "in", "self", ".", "aux_grads", ".", "items", "(", ")", ":", "\n", "# Get the current auxiliary task gradient.", "\n", "\t\t\t\t", "assert", "grad_list", "is", "not", "None", ",", "'MLM Grads for {} should have been set by now'", ".", "format", "(", "key", ")", "\n", "gradient_dict", "[", "key", "]", "=", "grad_list", "[", ":", "self", ".", "body_params_end", "]", "\n", "\n", "# Get the dev-head gradient", "\n", "", "gradient_dict", "[", "\"dev-{}\"", ".", "format", "(", "self", ".", "primary_task_id", ")", "]", "=", "self", ".", "set_dev_and_get_grads_head", "(", ")", "\n", "dev_task_grads", "=", "gradient_dict", "[", "\"dev-{}\"", ".", "format", "(", "self", ".", "primary_task_id", ")", "]", "[", ":", "self", ".", "body_params_end", "]", "\n", "\n", "# Caculate the gradients of the task weights based on the dev-head", "\n", "# Todo [ldery] - move this code to a better location", "\n", "all_tasks_names", "=", "self", ".", "aux_tasks", "+", "[", "self", ".", "primary_task_id", "]", "\n", "self", ".", "alpha_generator_algo", ".", "set_weight_gradients", "(", "\n", "dev_task_grads", ",", "all_tasks_names", ",", "gradient_dict", ",", "\n", "self", ".", "body_params_end", ",", "self", ".", "dp_stats", ",", "\n", "self", ".", "grad_accum_factor", ",", "self", ".", "weight_stats", "\n", ")", "\n", "\n", "\n", "# Add the primary task gradients after scaling appropriately.", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "scaling", "=", "self", ".", "alpha_generator_algo", "[", "self", ".", "primary_task_id", "]", "/", "self", ".", "grad_accum_factor", "\n", "for", "idx", ",", "(", "p", ",", "g", ")", "in", "enumerate", "(", "zip", "(", "this_classf", ".", "parameters", "(", ")", ",", "prim_gradients", ")", ")", ":", "\n", "\t\t\t\t", "if", "p", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t", "p", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "if", "g", "is", "None", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "p", ".", "grad", ".", "add_", "(", "scaling", "*", "g", ")", "\n", "del", "g", "\n", "", "", "del", "prim_gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.forward": [[388, 391], ["endtask_aware.TartanModel.base_lm_model"], "methods", ["None"], ["", "def", "forward", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# If we want forward pass to respond to specific head, then we have to run forward on model obtained from self.get_model(...)", "\n", "\t\t", "return", "self", ".", "base_lm_model", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier": [[393, 414], ["endtask_aware.TartanModel.get_dataset", "endtask_aware.TartanModel.get_model", "torch.cuda.empty_cache", "endtask_aware.TartanModel.eval", "endtask_aware.TartanModel.train", "torch.cuda.empty_cache", "endtask_aware.TartanModel.get_metrics", "endtask_aware.TartanModel.get_metrics", "torch.no_grad", "endtask_aware.TartanModel.dataset_iterator", "print", "endtask_aware.TartanModel."], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_dataset", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.train", "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.dataset_iterator"], ["", "def", "evaluate_classifier", "(", "self", ",", "set_", "=", "'dev'", ")", ":", "\n", "# Get the data and the classifier", "\n", "\t\t", "assert", "set_", "in", "[", "'dev'", ",", "'test'", "]", ",", "'Wrong split specified'", "\n", "dataset", "=", "self", ".", "get_dataset", "(", "set_", ")", "\n", "this_classf", "=", "self", ".", "get_model", "(", "self", ".", "primary_task_id", ")", "\n", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "# reset the metrics before running new stuff", "\n", "try", ":", "\n", "\t\t\t", "_", "=", "self", ".", "get_metrics", "(", "this_classf", "=", "this_classf", ",", "reset", "=", "True", ")", "\n", "", "except", ":", "\n", "\t\t\t", "print", "(", "'This classifier does not need to reset metrics.'", ")", "\n", "# Run the classifier", "\n", "", "this_classf", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "for", "samples", "in", "self", ".", "dataset_iterator", "(", "dataset", ",", "batchsz", "=", "self", ".", "batch_sz", ")", ":", "\n", "\t\t\t\t", "_", "=", "this_classf", "(", "*", "samples", ")", "\n", "", "", "this_classf", ".", "train", "(", ")", "\n", "# Get the metrics from the classifier", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "self", ".", "get_metrics", "(", "this_classf", "=", "this_classf", ",", "reset", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.train_primary": [[416, 467], ["collections.defaultdict", "endtask_aware.TartanModel.get_model", "endtask_aware.TartanModel.train", "endtask_aware.TartanModel.get_dataset", "range", "print", "endtask_aware.TartanModel.dataset_iterator", "math.ceil", "tqdm.tqdm.tqdm", "enumerate", "endtask_aware.TartanModel.get_metrics", "endtask_aware.TartanModel.evaluate_classifier", "endtask_aware.TartanModel.evaluate_classifier", "endtask_aware.TartanModel.items", "endtask_aware.TartanModel.perfs[].append", "endtask_aware.TartanModel.perfs[].append", "endtask_aware.TartanModel.perfs[].append", "endtask_aware.TartanModel.", "total_loss.backward", "print", "len", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "optimizer.zero_grad", "print", "endtask_aware.TartanModel.parameters", "lr_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_model", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.train", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_dataset", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.dataset_iterator", "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier"], ["", "def", "train_primary", "(", "self", ",", "n_iters", ",", "optimizer", ",", "lr_scheduler", ",", "max_grad_norm", ",", "patience", "=", "3", ",", "metric", "=", "'f1'", ")", ":", "\n", "\n", "\t\t", "best_iter", ",", "iters_since_improvement", "=", "0", ",", "0", "\n", "self", ".", "perfs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "# Get the primary task model and training data", "\n", "prim_classf", "=", "self", ".", "get_model", "(", "self", ".", "primary_task_id", ")", "\n", "prim_classf", ".", "train", "(", ")", "\n", "dataset", "=", "self", ".", "get_dataset", "(", "'train'", ")", "\n", "\n", "# Finetune for specified # of iterations", "\n", "for", "iter_", "in", "range", "(", "n_iters", ")", ":", "\n", "\t\t\t", "print", "(", "'Currently on Classifier Epoch {}/{}'", ".", "format", "(", "iter_", "+", "1", ",", "n_iters", ")", ")", "\n", "iterator", "=", "self", ".", "dataset_iterator", "(", "dataset", ",", "shuffle", "=", "True", ")", "\n", "total_iters", "=", "math", ".", "ceil", "(", "len", "(", "dataset", "[", "'tokens'", "]", ")", "/", "self", ".", "batch_sz", ")", "\n", "# Get the primary classifier", "\n", "iterator", "=", "tqdm", "(", "iterator", ",", "total", "=", "total_iters", ",", "desc", "=", "\"Classifier Train Iterator\"", ")", "\n", "for", "idx", ",", "samples", "in", "enumerate", "(", "iterator", ")", ":", "\n", "\t\t\t\t", "if", "(", "idx", "+", "1", ")", "%", "self", ".", "grad_accum_factor", "==", "0", ":", "\n", "# We want to take a gradient step after accumulating gradients", "\n", "\t\t\t\t\t", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "prim_classf", ".", "parameters", "(", ")", ",", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "\t\t\t\t\t\t", "lr_scheduler", ".", "step", "(", ")", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "output_dict", "=", "prim_classf", "(", "*", "samples", ")", "\n", "total_loss", "=", "output_dict", "[", "'loss'", "]", "/", "self", ".", "grad_accum_factor", "# Account for fact that we are accumulating gradients", "\n", "total_loss", ".", "backward", "(", ")", "\n", "# We want to evaluate the classifier", "\n", "", "train_metrics", "=", "self", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "dev_metrics", "=", "self", ".", "evaluate_classifier", "(", "set_", "=", "'dev'", ")", "\n", "test_metrics", "=", "self", ".", "evaluate_classifier", "(", "set_", "=", "'test'", ")", "\n", "# Report the metrics", "\n", "for", "k", ",", "v", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "\t\t\t\t", "to_show", "=", "k", ",", "v", ",", "dev_metrics", "[", "k", "]", ",", "test_metrics", "[", "k", "]", "\n", "print_out", "=", "\"[{}] | Train : {:.3f} | Dev Set : {:.3f} | Test Set : {:.3f}\"", ".", "format", "(", "*", "to_show", ")", "\n", "print", "(", "print_out", ")", "\n", "", "self", ".", "perfs", "[", "'train'", "]", ".", "append", "(", "(", "train_metrics", "[", "'f1'", "]", ",", "train_metrics", "[", "'accuracy'", "]", ")", ")", "\n", "self", ".", "perfs", "[", "'dev'", "]", ".", "append", "(", "(", "dev_metrics", "[", "'f1'", "]", ",", "dev_metrics", "[", "'accuracy'", "]", ")", ")", "\n", "self", ".", "perfs", "[", "'test'", "]", ".", "append", "(", "(", "test_metrics", "[", "'f1'", "]", ",", "test_metrics", "[", "'accuracy'", "]", ")", ")", "\n", "metric_idx", "=", "0", "if", "metric", "==", "'f1'", "else", "1", "\n", "if", "dev_metrics", "[", "metric", "]", ">=", "self", ".", "perfs", "[", "'dev'", "]", "[", "best_iter", "]", "[", "metric_idx", "]", ":", "\n", "\t\t\t\t", "best_iter", "=", "iter_", "\n", "iters_since_improvement", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t", "iters_since_improvement", "+=", "1", "\n", "if", "iters_since_improvement", ">=", "patience", ":", "\n", "\t\t\t\t\t", "print", "(", "'Breaking because we have no improvement in {} epochs'", ".", "format", "(", "patience", ")", ")", "\n", "break", "\n", "", "", "", "best_f1", ",", "best_acc", "=", "self", ".", "perfs", "[", "'test'", "]", "[", "best_iter", "]", "\n", "return", "best_f1", ",", "best_acc", ",", "self", ".", "perfs", ",", "self", ".", "perfs", "[", "'dev'", "]", "[", "best_iter", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_dataset": [[473, 487], ["endtask_aware.TartanModel.setup_datasets"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_datasets"], ["def", "get_dataset", "(", "self", ",", "split", ")", ":", "\n", "\t\t", "if", "self", ".", "data_splits", "[", "split", "]", "is", "not", "None", ":", "\n", "\t\t\t", "return", "self", ".", "data_splits", "[", "split", "]", "\n", "\n", "", "inputdict", "=", "{", "split", ":", "self", ".", "file_for_split", "[", "split", "]", "}", "\n", "dataset", "=", "self", ".", "setup_datasets", "(", "\n", "inputdict", ",", "self", ".", "model_name", ",", "self", ".", "max_seq_len", ",", "\n", "label_vocab", "=", "self", ".", "label_vocab", "\n", ")", "[", "split", "]", "\n", "self", ".", "data_splits", "[", "split", "]", "=", "dataset", "\n", "if", "split", "==", "'train'", ":", "\n", "# Initialize the label vocab if this is the first time we are accessing the training dataset", "\n", "\t\t\t", "self", ".", "label_vocab", "=", "dataset", "[", "'vocab'", "]", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_datasets": [[490, 530], ["collections.defaultdict", "allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer", "data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling", "dataset_files.items", "allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer", "data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._read", "tokens.index", "all_sentences.append", "all_instances.append", "lens.append", "allennlp.data.Vocabulary.from_instances", "label.index", "label.as_tensor", "all_labels.append", "numpy.array", "tokens.as_tensor", "label.get_padding_lengths", "tokens.get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._read"], ["", "def", "setup_datasets", "(", "self", ",", "dataset_files", ",", "model_name", ",", "max_seq_len", ",", "label_vocab", "=", "None", ",", "lazy", "=", "False", ")", ":", "\n", "# Instantiate dataset reader", "\n", "\t\t", "datasets", "=", "defaultdict", "(", "dict", ")", "\n", "indexers", "=", "{", "'tokens'", ":", "PretrainedTransformerIndexer", "(", "model_name", ",", "do_lowercase", "=", "False", ")", "}", "\n", "tokenizer", "=", "PretrainedTransformerTokenizer", "(", "model_name", ",", "do_lowercase", "=", "False", ",", "start_tokens", "=", "[", "\"<s>\"", "]", ",", "end_tokens", "=", "[", "\"</s>\"", "]", ")", "\n", "dataset_reader", "=", "TextClassificationJsonReaderWithSampling", "(", "\n", "token_indexers", "=", "indexers", ",", "tokenizer", "=", "tokenizer", ",", "\n", "max_sequence_length", "=", "max_seq_len", ",", "lazy", "=", "lazy", "\n", ")", "\n", "# Read from the dataset", "\n", "pretrain_vocab", "=", "tokenizer", ".", "_tokenizer", ".", "encoder", "\n", "for", "idx_", ",", "fname", "in", "dataset_files", ".", "items", "(", ")", ":", "\n", "\t\t\t", "all_samples", "=", "dataset_reader", ".", "_read", "(", "fname", ")", "\n", "all_sentences", ",", "all_instances", "=", "[", "]", ",", "[", "]", "\n", "lens", "=", "[", "]", "\n", "for", "instance", "in", "all_samples", ":", "\n", "\t\t\t\t", "tokens", "=", "instance", ".", "fields", "[", "'tokens'", "]", "\n", "tokens", ".", "index", "(", "pretrain_vocab", ")", "\n", "sentence", "=", "tokens", ".", "as_tensor", "(", "tokens", ".", "get_padding_lengths", "(", ")", ")", "[", "'tokens'", "]", "\n", "all_sentences", ".", "append", "(", "sentence", ")", "\n", "all_instances", ".", "append", "(", "instance", ")", "\n", "lens", ".", "append", "(", "sentence", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "label_vocab", "is", "not", "None", ":", "\n", "\t\t\t\t", "vocab", "=", "label_vocab", "\n", "", "else", ":", "\n", "\t\t\t\t", "vocab", "=", "Vocabulary", ".", "from_instances", "(", "all_instances", ")", "\n", "", "all_labels", "=", "[", "]", "\n", "for", "instance", "in", "all_instances", ":", "\n", "\t\t\t\t", "label", "=", "instance", ".", "fields", "[", "'label'", "]", "\n", "label", ".", "index", "(", "vocab", ")", "\n", "this_label", "=", "label", ".", "as_tensor", "(", "label", ".", "get_padding_lengths", "(", ")", ")", "\n", "all_labels", ".", "append", "(", "this_label", ")", "\n", "", "datasets", "[", "idx_", "]", "=", "{", "\n", "'tokens'", ":", "all_sentences", ",", "\n", "'labels'", ":", "np", ".", "array", "(", "all_labels", ")", ",", "\n", "'pad_idx'", ":", "tokenizer", ".", "_tokenizer", ".", "pad_token_id", ",", "\n", "'vocab'", ":", "vocab", "\n", "}", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_data_samples": [[532, 541], ["endtask_aware.TartanModel.get_dataset", "len", "numpy.random.choice", "utils.collate", "sentences.to.to.to", "torch.IntTensor().to", "torch.IntTensor"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_dataset", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to"], ["", "def", "get_data_samples", "(", "self", ",", "split", ",", "nsamples", ")", ":", "\n", "\t\t", "dataset", "=", "self", ".", "get_dataset", "(", "split", ")", "\n", "num_egs", "=", "len", "(", "dataset", "[", "'tokens'", "]", ")", "\n", "idxs", "=", "np", ".", "random", ".", "choice", "(", "num_egs", ",", "size", "=", "nsamples", ",", "replace", "=", "(", "num_egs", "<", "nsamples", ")", ")", "\n", "sentences", ",", "labels", "=", "[", "dataset", "[", "'tokens'", "]", "[", "i", "]", "for", "i", "in", "idxs", "]", ",", "dataset", "[", "'labels'", "]", "[", "idxs", "]", "\n", "sentences", "=", "collate", "(", "sentences", ",", "dataset", "[", "'pad_idx'", "]", ")", "\n", "sentences", "=", "sentences", ".", "to", "(", "self", ".", "base_lm_model", ".", "device", ")", "\n", "labels", "=", "torch", ".", "IntTensor", "(", "labels", ")", ".", "to", "(", "sentences", ".", "device", ")", "\n", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.dataset_iterator": [[544, 565], ["len", "math.ceil", "range", "numpy.random.permutation", "list", "utils.collate", "sentences.to.to.to", "torch.IntTensor().to", "range", "torch.IntTensor"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to"], ["", "def", "dataset_iterator", "(", "self", ",", "dataset", ",", "shuffle", "=", "False", ",", "batchsz", "=", "-", "1", ")", ":", "\n", "\t\t", "if", "batchsz", "<", "0", ":", "\n", "# Use the prescribed default batch size", "\n", "\t\t\t", "batchsz", "=", "self", ".", "batch_sz", "\n", "", "total_egs", "=", "len", "(", "dataset", "[", "'tokens'", "]", ")", "\n", "num_batches", "=", "math", ".", "ceil", "(", "total_egs", "/", "batchsz", ")", "\n", "if", "shuffle", ":", "\n", "\t\t\t", "idxs", "=", "np", ".", "random", ".", "permutation", "(", "total_egs", ")", "\n", "", "else", ":", "\n", "\t\t\t", "idxs", "=", "list", "(", "range", "(", "total_egs", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num_batches", ")", ":", "\n", "\t\t\t", "this_idxs", "=", "idxs", "[", "(", "i", "*", "batchsz", ")", ":", "(", "(", "i", "+", "1", ")", "*", "batchsz", ")", "]", "\n", "sentences", "=", "[", "dataset", "[", "'tokens'", "]", "[", "id_", "]", "for", "id_", "in", "this_idxs", "]", "\n", "labels", "=", "dataset", "[", "'labels'", "]", "[", "this_idxs", "]", "\n", "sentences", "=", "collate", "(", "sentences", ",", "dataset", "[", "'pad_idx'", "]", ")", "\n", "sentences", "=", "sentences", ".", "to", "(", "self", ".", "base_lm_model", ".", "device", ")", "\n", "labels", "=", "torch", ".", "IntTensor", "(", "labels", ")", ".", "to", "(", "self", ".", "base_lm_model", ".", "device", ")", "\n", "yield", "sentences", ",", "labels", "\n", "# Clean up after yielding", "\n", "del", "sentences", "\n", "del", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.add_tartan_args": [[28, 36], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_tartan_args", "(", "parser", ")", ":", "\n", "\t", "parser", ".", "add_argument", "(", "'--dev_batch_sz'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'Batch sz for dev-set for meta-learning'", ")", "\n", "parser", ".", "add_argument", "(", "\"--primary_task_id\"", ",", "type", "=", "str", ",", "default", "=", "'citation_intent'", ",", "choices", "=", "[", "\"citation_intent\"", ",", "\"chemprot\"", ",", "\"sciie\"", ",", "\"hyperpartisan\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_dev_lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "\"Learning rate of dev-head\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_dev_wd\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_max_seq_len\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_iter_batchsz\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'Batch Size per iteration. True batch_sz is this x number of grad accumulation steps'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.__init__": [[31, 40], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "prim_key", ",", "aux_keys", ",", "init_val", "=", "1.0", ")", ":", "\n", "\t\t", "self", ".", "weights", "=", "{", "key", ":", "init_val", "for", "key", "in", "aux_keys", "}", "\n", "self", ".", "aux_keys", "=", "aux_keys", "\n", "self", ".", "weights", "[", "prim_key", "]", "=", "init_val", "\n", "self", ".", "prim_key", "=", "prim_key", "\n", "self", ".", "init_val", "=", "init_val", "\n", "self", ".", "result_logs", "=", "[", "]", "\n", "self", ".", "class_norm_logs", "=", "[", "]", "\n", "self", ".", "is_meta", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.__getitem__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "\t\t", "return", "self", ".", "weights", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.prep_epoch_start": [[44, 47], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "prep_epoch_start", "(", "self", ",", "epoch", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.record_epoch_end": [[48, 58], ["alpha_generator.Weighter.class_norm_logs.append", "entry.extend", "alpha_generator.Weighter.result_logs.append", "isinstance", "alpha_generator.Weighter.item", "alpha_generator.Weighter.weights.keys", "len", "kwargs[].items"], "methods", ["None"], ["", "def", "record_epoch_end", "(", "self", ",", "epoch", ",", "val_stat", ",", "test_stat", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "entry", "=", "[", "self", "[", "k", "]", ".", "item", "(", ")", "if", "isinstance", "(", "self", "[", "k", "]", ",", "torch", ".", "Tensor", ")", "else", "self", "[", "k", "]", "for", "k", "in", "self", ".", "weights", ".", "keys", "(", ")", "]", "\n", "if", "'class_norms'", "in", "kwargs", ":", "\n", "\t\t\t", "class_norm_entry", "=", "[", "v", "for", "_", ",", "v", "in", "kwargs", "[", "'class_norms'", "]", ".", "items", "(", ")", "]", "\n", "", "else", ":", "\n", "\t\t\t", "class_norm_entry", "=", "[", "1.0", "]", "*", "len", "(", "self", ".", "weights", ")", "\n", "", "self", ".", "class_norm_logs", ".", "append", "(", "class_norm_entry", ")", "\n", "# Place the statistic to record in the final position", "\n", "entry", ".", "extend", "(", "[", "val_stat", ",", "test_stat", "]", ")", "\n", "self", ".", "result_logs", ".", "append", "(", "entry", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.viz_results": [[59, 91], ["numpy.array", "numpy.array", "list", "list.index", "matplotlib.subplots", "ax[].plot", "enumerate", "range", "ax[].twinx", "ax[].twinx.plot", "ax[].twinx.plot", "ax[].twinx.set_ylim", "ax[].twinx.set_ylabel", "ax[].twinx.legend", "matplotlib.tight_layout", "matplotlib.savefig", "alpha_generator.Weighter.weights.keys", "range", "ax[].plot", "ax[].plot", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].legend", "range", "range", "len", "ax[].plot", "range", "range", "len", "len", "numpy.min", "numpy.max", "range", "len", "len", "len"], "methods", ["None"], ["", "def", "viz_results", "(", "self", ",", "save_loc", ",", "group_aux", "=", "True", ")", ":", "\n", "\t\t", "to_viz_classnorms", "=", "np", ".", "array", "(", "self", ".", "class_norm_logs", ")", "\n", "to_viz", "=", "np", ".", "array", "(", "self", ".", "result_logs", ")", "\n", "all_keys", "=", "list", "(", "self", ".", "weights", ".", "keys", "(", ")", ")", "\n", "prim_idx", "=", "all_keys", ".", "index", "(", "self", ".", "prim_key", ")", "\n", "prim_vals", "=", "to_viz", "[", ":", ",", "prim_idx", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "2", ",", "figsize", "=", "(", "16", ",", "8", ")", ")", "\n", "ax", "[", "0", "]", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "prim_vals", ",", "label", "=", "'Primary Task Weighting'", ")", "\n", "for", "idx_", ",", "key", "in", "enumerate", "(", "all_keys", ")", ":", "\n", "\t\t\t", "if", "idx_", "==", "prim_idx", ":", "\n", "\t\t\t\t", "desc", "=", "'{} Norm'", ".", "format", "(", "key", ")", "if", "not", "group_aux", "else", "'Norm Per-Auxiliary Task'", "\n", "ax", "[", "1", "]", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "to_viz_classnorms", "[", ":", ",", "idx_", "]", ",", "linestyle", "=", "'-.'", ",", "label", "=", "desc", ")", "\n", "continue", "\n", "", "desc", "=", "'{}'", ".", "format", "(", "key", ")", "if", "not", "group_aux", "else", "'Weight Per-Auxiliary Task'", "\n", "ax", "[", "0", "]", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "to_viz", "[", ":", ",", "idx_", "]", ",", "linestyle", "=", "'dashed'", ",", "label", "=", "desc", ")", "\n", "desc", "=", "'{} Norm'", ".", "format", "(", "key", ")", "if", "not", "group_aux", "else", "'Norm Per-Auxiliary Task'", "\n", "ax", "[", "1", "]", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "to_viz_classnorms", "[", ":", ",", "idx_", "]", ",", "linestyle", "=", "'-.'", ",", "label", "=", "desc", ")", "\n", "if", "group_aux", ":", "\n", "\t\t\t\t", "break", "\n", "", "", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "\t\t\t", "ax", "[", "i", "]", ".", "set_xlabel", "(", "'Epoch'", ")", "\n", "ax", "[", "i", "]", ".", "set_ylabel", "(", "'Weighting'", ")", "\n", "ax", "[", "i", "]", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "", "ax2", "=", "ax", "[", "0", "]", ".", "twinx", "(", ")", "\n", "ax2", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "to_viz", "[", ":", ",", "-", "1", "]", ",", "color", "=", "'tab:red'", ",", "label", "=", "'Test Metric'", ")", "\n", "ax2", ".", "plot", "(", "range", "(", "len", "(", "prim_vals", ")", ")", ",", "to_viz", "[", ":", ",", "-", "2", "]", ",", "color", "=", "'tab:cyan'", ",", "label", "=", "'Val Metric'", ")", "\n", "min_", ",", "max_", "=", "np", ".", "min", "(", "to_viz", "[", ":", ",", "-", "2", ":", "]", ")", "-", "0.01", ",", "np", ".", "max", "(", "to_viz", "[", ":", ",", "-", "2", ":", "]", ")", "+", "0.01", "\n", "ax2", ".", "set_ylim", "(", "min_", ",", "max_", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Test/Val Metric'", ",", "color", "=", "'tab:red'", ")", "\n", "ax2", ".", "legend", "(", "loc", "=", "'upper left'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'{}/weighting_vrs_stat.png'", ".", "format", "(", "save_loc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.__init__": [[94, 103], ["alpha_generator.Weighter.__init__", "alpha_generator.MetaWeighter.create_weights", "print"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.create_weights"], ["\t", "def", "__init__", "(", "self", ",", "prim_key", ",", "aux_keys", ",", "meta_lr_weight", "=", "1e-2", ",", "init_", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "MetaWeighter", ",", "self", ")", ".", "__init__", "(", "prim_key", ",", "aux_keys", ")", "\n", "# Finished setting up here", "\n", "# perform approriate intialization here", "\n", "all_classes", "=", "[", "prim_key", ",", "*", "aux_keys", "]", "\n", "self", ".", "weights", "=", "self", ".", "create_weights", "(", "all_classes", ",", "init", "=", "init_", ")", "\n", "self", ".", "meta_lr_weight", "=", "meta_lr_weight", "\n", "print", "(", "'Starting learning with initial weights at : '", ",", "self", ".", "weights", ")", "\n", "self", ".", "is_meta", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.create_weights": [[104, 118], ["numpy.array", "numpy.array", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "weights.items", "len", "len", "sum", "enumerate", "len", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "create_weights", "(", "self", ",", "classes", ",", "norm", "=", "1.0", ",", "requires_grad", "=", "True", ",", "init", "=", "None", ")", ":", "\n", "\t\t", "if", "init", "is", "None", ":", "\n", "\t\t\t", "inits", "=", "np", ".", "array", "(", "[", "1.0", "]", "*", "len", "(", "classes", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t", "assert", "len", "(", "init", ")", "==", "len", "(", "classes", ")", "\n", "inits", "=", "np", ".", "array", "(", "init", ")", "\n", "", "if", "norm", ">", "0", ":", "\n", "\t\t\t", "inits", "=", "norm", "*", "inits", "/", "(", "sum", "(", "inits", ")", ")", "\n", "# Create the weights", "\n", "", "weights", "=", "{", "class_", ":", "torch", ".", "tensor", "(", "[", "inits", "[", "id_", "]", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "for", "id_", ",", "class_", "in", "enumerate", "(", "classes", ")", "}", "\n", "if", "requires_grad", ":", "\n", "\t\t\t", "for", "_", ",", "v", "in", "weights", ".", "items", "(", ")", ":", "\n", "\t\t\t\t", "v", ".", "requires_grad", "=", "True", "\n", "", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.__getitem__": [[120, 124], ["hasattr", "alpha_generator.MetaWeighter.get_softmax"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.get_softmax"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "\t\t", "if", "not", "hasattr", "(", "self", ",", "'sm_weights'", ")", ":", "\n", "\t\t\t", "self", ".", "sm_weights", "=", "self", ".", "get_softmax", "(", ")", "\n", "", "return", "self", ".", "sm_weights", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.get_softmax": [[126, 136], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "alpha_generator.MetaWeighter.weights.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "keys.append", "values.append", "zip"], "methods", ["None"], ["", "def", "get_softmax", "(", "self", ")", ":", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "keys", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "weights", ".", "items", "(", ")", ":", "\n", "\t\t\t\t", "keys", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "v", ")", "\n", "", "joint_vec", "=", "torch", ".", "cat", "(", "values", ")", "\n", "softmax", "=", "F", ".", "softmax", "(", "joint_vec", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "keys", ",", "softmax", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.set_weight_gradients": [[138, 165], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.calc_norm", "utils.calc_norm", "utils.dot_prod", "dp_stats[].append", "weight_stats[].append", "meta_weights[].grad.add_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "meta_weights[].item", "meta_weights[].grad.item"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.dot_prod"], ["", "def", "set_weight_gradients", "(", "\n", "self", ",", "dev_task_grads", ",", "all_tasks_names", ",", "gradient_dict", ",", "\n", "body_params_end", ",", "dp_stats", ",", "\n", "scaling_factor", ",", "weight_stats", "\n", ")", ":", "\n", "\t\t", "meta_weights", "=", "self", ".", "weights", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "dev_norm", "=", "calc_norm", "(", "dev_task_grads", ")", "# Get the norm of the meta-dev gradients", "\n", "\n", "for", "task_id", "in", "all_tasks_names", ":", "\n", "# Core computation here", "\n", "\t\t\t\t", "task_norm", "=", "calc_norm", "(", "gradient_dict", "[", "task_id", "]", "[", ":", "body_params_end", "]", ")", "\n", "cos_sim", "=", "dot_prod", "(", "dev_task_grads", ",", "gradient_dict", "[", "task_id", "]", "[", ":", "body_params_end", "]", ")", "\n", "cos_sim", "=", "cos_sim", "/", "(", "dev_norm", "*", "task_norm", ")", "\n", "\n", "# Save state for visualization", "\n", "dp_stats", "[", "task_id", "]", ".", "append", "(", "cos_sim", ")", "\n", "\n", "# Gradient is negative cosine similarity. Calculate and use that to set task weight gradients", "\n", "cos_sim", "=", "(", "torch", ".", "zeros_like", "(", "meta_weights", "[", "task_id", "]", ")", "-", "cos_sim", ")", "/", "scaling_factor", "\n", "if", "meta_weights", "[", "task_id", "]", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t", "meta_weights", "[", "task_id", "]", ".", "grad", "=", "cos_sim", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "meta_weights", "[", "task_id", "]", ".", "grad", ".", "add_", "(", "cos_sim", ")", "\n", "\n", "# Save state for visualization", "\n", "", "weight_stats", "[", "task_id", "]", ".", "append", "(", "(", "meta_weights", "[", "task_id", "]", ".", "item", "(", ")", ",", "meta_weights", "[", "task_id", "]", ".", "grad", ".", "item", "(", ")", ",", "dev_norm", ",", "task_norm", ",", "dp_stats", "[", "task_id", "]", "[", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.update_meta_weights": [[168, 179], ["alpha_generator.MetaWeighter.get_softmax", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "meta_weights.keys", "meta_weights[].copy_", "meta_weights[].grad.zero_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.get_softmax"], ["", "", "", "def", "update_meta_weights", "(", "self", ")", ":", "\n", "\t\t", "meta_weights", "=", "self", ".", "weights", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "for", "key", "in", "meta_weights", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "if", "meta_weights", "[", "key", "]", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t", "meta_weights", "[", "key", "]", ".", "grad", "=", "torch", ".", "zeros_like", "(", "meta_weights", "[", "key", "]", ")", "\n", "", "new_val", "=", "meta_weights", "[", "key", "]", "-", "(", "self", ".", "meta_lr_weight", "*", "meta_weights", "[", "key", "]", ".", "grad", ")", "\n", "meta_weights", "[", "key", "]", ".", "copy_", "(", "new_val", ")", "\n", "meta_weights", "[", "key", "]", ".", "grad", ".", "zero_", "(", ")", "\n", "\n", "", "", "self", ".", "sm_weights", "=", "self", ".", "get_softmax", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.DefaultWeighter.__init__": [[182, 185], ["alpha_generator.Weighter.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["\t", "def", "__init__", "(", "self", ",", "prim_key", ",", "aux_keys", ",", "init_val", "=", "1.0", ")", ":", "\n", "\t\t", "init_val", "=", "1.0", "/", "(", "1", "+", "len", "(", "aux_keys", ")", ")", "\n", "super", "(", "DefaultWeighter", ",", "self", ")", ".", "__init__", "(", "prim_key", ",", "aux_keys", ",", "init_val", "=", "init_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.DefaultWeighter.__getitem__": [[186, 188], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "\t\t", "return", "self", ".", "init_val", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.DefaultWeighter.prep_epoch_start": [[189, 191], ["None"], "methods", ["None"], ["", "def", "prep_epoch_start", "(", "self", ",", "epoch", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.add_config_args": [[11, 18], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_config_args", "(", "parser", ")", ":", "\n", "\t", "parser", ".", "add_argument", "(", "\n", "'-weight-strgy'", ",", "type", "=", "str", ",", "default", "=", "'default'", ",", "\n", "choices", "=", "[", "'default'", ",", "'meta'", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'-init-val'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'Initial Task weightings'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta-lr-weight'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'learning rate for meta-learning'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.get_alpha_generator": [[20, 28], ["alpha_generator.DefaultWeighter", "alpha_generator.MetaWeighter"], "function", ["None"], ["", "def", "get_alpha_generator", "(", "opts", ",", "prim_key", ",", "aux_keys", ")", ":", "\n", "\t", "weight_strgy", "=", "opts", ".", "weight_strgy", "\n", "if", "weight_strgy", "==", "'default'", ":", "\n", "\t\t", "return", "DefaultWeighter", "(", "prim_key", ",", "aux_keys", ",", "init_val", "=", "opts", ".", "init_val", ")", "\n", "", "elif", "weight_strgy", "==", "'meta'", ":", "\n", "\t\t", "return", "MetaWeighter", "(", "prim_key", ",", "aux_keys", ",", "meta_lr_weight", "=", "opts", ".", "meta_lr_weight", ")", "\n", "", "else", ":", "\n", "\t\t", "assert", "'Invalid Value for Weighting strategy - {}'", ".", "format", "(", "weight_strgy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.TextDataset.__init__": [[73, 105], ["os.path.isfile", "os.path.split", "os.path.join", "tokenizer.num_special_tokens_to_add", "os.path.exists", "logger.info", "logger.info", "tokenizer.convert_tokens_to_ids", "range", "logger.info", "open", "pickle.load", "open", "f.read", "tokenizer.tokenize", "run_mlm_auxiliary.TextDataset.examples.append", "open", "pickle.dump", "tokenizer.build_inputs_with_special_tokens", "str", "len"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load"], ["\t", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "block_size", "=", "512", ")", ":", "\n", "\t\t", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "\n", "block_size", "=", "block_size", "-", "tokenizer", ".", "num_special_tokens_to_add", "(", "pair", "=", "False", ")", "\n", "\n", "directory", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "file_path", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "directory", ",", "args", ".", "model_type", "+", "\"_cached_lm_\"", "+", "str", "(", "block_size", ")", "+", "\"_\"", "+", "filename", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "\t\t\t", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "\t\t\t\t", "self", ".", "examples", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "directory", ")", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "text", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "tokenized_text", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "tokenized_text", ")", "-", "block_size", "+", "1", ",", "block_size", ")", ":", "# Truncate in block of block_size", "\n", "\t\t\t\t", "self", ".", "examples", ".", "append", "(", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "tokenized_text", "[", "i", ":", "i", "+", "block_size", "]", ")", ")", "\n", "# Note that we are loosing the last truncated example here for the sake of simplicity (no padding)", "\n", "# If your dataset is small, first you should loook for a bigger one :-) and second you", "\n", "# can change this behavior by adding (model specific) padding.", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "\t\t\t\t", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.TextDataset.__len__": [[106, 108], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "\t\t", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.TextDataset.__getitem__": [[109, 111], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "\t\t", "return", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.LineByLineTextDataset.__init__": [[127, 137], ["os.path.isfile", "run_mlm_auxiliary.get_tokenized_file"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.get_tokenized_file"], ["\t", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "lazy", ":", "bool", ",", "file_path", ":", "str", ",", "block_size", "=", "512", ")", ":", "\n", "\t\t", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "self", ".", "lazy", "=", "lazy", "\n", "self", ".", "block_size", "=", "block_size", "\n", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "examples", "=", "get_tokenized_file", "(", "file_path", ",", "tokenizer", ",", "block_size", ",", "lazy", "=", "lazy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.LineByLineTextDataset.__len__": [[139, 141], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "\t\t", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.LineByLineTextDataset.__getitem__": [[142, 147], ["torch.tensor", "run_mlm_auxiliary.LineByLineTextDataset.tokenizer.encode_plus"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "\t\t", "tokenized", "=", "self", ".", "examples", "[", "i", "]", "\n", "if", "self", ".", "lazy", ":", "\n", "\t\t\t", "tokenized", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "tokenized", ",", "truncation", "=", "True", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "self", ".", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "", "return", "torch", ".", "tensor", "(", "tokenized", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.set_seed": [[61, 67], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "\t", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "\t\t", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.get_tokenized_file": [[112, 124], ["logger.info", "logger.info", "logger.info", "open", "tokenizer.batch_encode_plus", "lines.append", "len", "line.isspace"], "function", ["None"], ["", "", "def", "get_tokenized_file", "(", "file_path", ":", "str", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "block_size", "=", "512", ",", "shuffle", "=", "False", ",", "lazy", "=", "False", ")", ":", "\n", "\t", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "logger", ".", "info", "(", "\"Reading Line by Line\"", ")", "\n", "lines", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "if", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ":", "\n", "\t\t\t\t", "lines", ".", "append", "(", "line", ")", "\n", "", "", "", "logger", ".", "info", "(", "\"Done Reading Line By Line. About to pass through the tokenize\"", ")", "\n", "if", "lazy", ":", "\n", "\t\t", "return", "lines", "\n", "", "return", "tokenizer", ".", "batch_encode_plus", "(", "lines", ",", "truncation", "=", "True", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.load_and_cache_examples": [[149, 160], ["enumerate", "len", "len", "run_mlm_auxiliary.LineByLineTextDataset", "run_mlm_auxiliary.TextDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ")", ":", "\n", "\t", "file_paths", "=", "args", ".", "train_data_file", "\n", "assert", "len", "(", "args", ".", "train_data_file", ")", "==", "len", "(", "args", ".", "aux_task_names", ")", ",", "'Mismatch between the number of train files for MLM and the number of aux task names'", "\n", "datasets", "=", "{", "}", "\n", "for", "idx", ",", "file_path", "in", "enumerate", "(", "file_paths", ")", ":", "\n", "\t\t", "task_name", "=", "args", ".", "aux_task_names", "[", "idx", "]", "\n", "if", "args", ".", "line_by_line", ":", "\n", "\t\t\t", "datasets", "[", "task_name", "]", "=", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "lazy", "=", "args", ".", "lazy_dataset", ",", "file_path", "=", "file_path", ",", "block_size", "=", "args", ".", "block_size", ")", "\n", "", "else", ":", "\n", "\t\t\t", "datasets", "[", "task_name", "]", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "block_size", "=", "args", ".", "block_size", ")", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary._sorted_checkpoints": [[165, 179], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "List", "[", "str", "]", ":", "\n", "\t", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "\t\t", "if", "use_mtime", ":", "\n", "\t\t\t", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "\t\t\t\t", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary._rotate_checkpoints": [[181, 197], ["run_mlm_auxiliary._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "\t", "if", "not", "args", ".", "save_total_limit", ":", "\n", "\t\t", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "\t\t", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "\t\t", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "\t\t", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.save_chkpt": [[198, 217], ["os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "hasattr", "os.path.join", "run_mlm_auxiliary._rotate_checkpoints", "optimizer.state_dict", "os.path.join", "scheduler.state_dict", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary._rotate_checkpoints"], ["", "", "def", "save_chkpt", "(", "args", ",", "id_", ",", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "rotate_chkpt", "=", "True", ")", ":", "\n", "\t", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "id_", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "if", "rotate_chkpt", ":", "\n", "\t\t", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.mask_tokens": [[221, 255], ["inputs.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "torch.randint", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "len", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli().bool", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["None"], ["def", "mask_tokens", "(", "inputs", ":", "torch", ".", "Tensor", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "\t", "\"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"", "\n", "\n", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "\t\t", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked\"", "\n", "\" language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training", "\n", "# (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "\t\t", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "&", "~", "indices_replaced", "\n", "random_words", "=", "torch", ".", "randint", "(", "len", "(", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.run_batch": [[258, 280], ["inputs.to.to", "labels.to.to", "model.train", "model", "run_mlm_auxiliary.mask_tokens", "gc.collect", "torch.cuda.empty_cache", "str", "print", "run_mlm_auxiliary.run_batch", "print", "print", "str"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.train", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.mask_tokens", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.run_batch"], ["", "def", "run_batch", "(", "model", ",", "batch", ",", "tokenizer", ",", "args", ",", "task_name", ",", "try_again", "=", "True", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "inputs", ",", "labels", "=", "mask_tokens", "(", "batch", ",", "tokenizer", ",", "args", ")", "if", "args", ".", "mlm", "else", "(", "batch", ",", "batch", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "\t\t", "gc", ".", "collect", "(", ")", "\n", "if", "'out of memory'", "in", "str", "(", "e", ")", ":", "\n", "\t\t\t", "if", "try_again", ":", "\n", "\t\t\t\t", "print", "(", "'| WARNING: ran out of memory during forward. Trying batch again'", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "print", "(", "'| WARNING: ran out of memory during forward. Skipping batch'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "print", "(", "'Run into this new error : '", ",", "str", "(", "e", ")", ")", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "not", "try_again", ":", "\n", "\t\t\t", "return", "None", "\n", "", "else", ":", "\n", "\t\t\t", "outputs", "=", "run_batch", "(", "model", ",", "batch", ",", "tokenizer", ",", "args", ",", "task_name", ",", "try_again", "=", "False", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.process_task_batch": [[282, 314], ["run_mlm_auxiliary.run_batch", "torch.autograd.grad", "tartan_model.set_aux_grads", "loss.backward", "loss.item", "mlm_model.parameters", "torch.no_grad", "zip", "mlm_model.parameters", "p.grad.add_", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.run_batch", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_aux_grads"], ["", "def", "process_task_batch", "(", "tartan_model", ",", "mlm_model", ",", "batch", ",", "tokenizer", ",", "args", ",", "task_name", ")", ":", "\n", "\t", "outputs", "=", "run_batch", "(", "mlm_model", ",", "batch", ",", "tokenizer", ",", "args", ",", "task_name", ")", "\n", "\n", "# This could return none if we aren't able to process the batch even after clearing", "\n", "# the cuda cache after an out of memory erorr and re-trying", "\n", "loss_", "=", "0", "\n", "if", "outputs", "is", "not", "None", ":", "\n", "\t\t", "loss", "=", "outputs", "[", "0", "]", "# mlm_model outputs are always tuple in transformers (see doc)", "\n", "\n", "# Store the gradients for the meta-learner", "\n", "scale", "=", "tartan_model", ".", "alpha_generator_algo", "[", "task_name", "]", "/", "args", ".", "gradient_accumulation_steps", "\n", "if", "tartan_model", ".", "alpha_generator_algo", ".", "is_meta", ":", "\n", "\t\t\t", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "mlm_model", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "tartan_model", ".", "set_aux_grads", "(", "gradients", ",", "aux_task_name", "=", "task_name", ")", "\n", "\n", "# Update the parameter gradients with the computed gradients", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "for", "(", "p", ",", "g", ")", "in", "zip", "(", "mlm_model", ".", "parameters", "(", ")", ",", "gradients", ")", ":", "\n", "\t\t\t\t\t", "if", "g", "is", "None", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "if", "p", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t\t", "p", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "p", ".", "grad", ".", "add_", "(", "g", "*", "scale", ")", "# scaling included here because we are weighting the tasks which influences the gradients", "\n", "del", "g", "\n", "\n", "", "", "loss_", "=", "(", "loss", "*", "scale", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "# We are doing mt-tartan. No need to store the gradients - can just back-prop", "\n", "\t\t\t", "loss", "=", "loss", "*", "scale", "\n", "loss", ".", "backward", "(", ")", "\n", "loss_", "=", "loss", ".", "item", "(", ")", "\n", "", "", "return", "loss_", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.train": [[317, 570], ["train_dataset.items", "model.resize_token_embeddings", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "auxTaskModel.get_classifier_params", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "auxTaskModel.setup_alpha_generator", "logger.info", "train_dataset.items", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "tqdm.trange", "run_mlm_auxiliary.set_seed", "auxTaskModel.alpha_generator_algo.prep_epoch_start", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "logger.info", "len", "logger.info", "int", "os.path.exists", "int", "gc.collect", "print", "tqdm.tqdm", "train_dataloader.items", "enumerate", "len", "len", "eval", "int", "eval", "int", "int", "logger.info", "logger.info", "logger.info", "logger.info", "iter", "list", "enumerate", "auxTaskModel.classifier_sample_grad", "tqdm.trange.close", "utils.collate_fn", "len", "[].split", "logger.info", "auxTaskModel.alpha_generator_algo.weights.keys", "run_mlm_auxiliary.process_task_batch", "next", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "transformers.AdamW.zero_grad", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "model.zero_grad", "auxTaskModel.alpha_generator_algo.prep_epoch_start", "torch.cuda.empty_cache", "tqdm.tqdm.close", "model.named_parameters", "model.named_parameters", "any", "len", "print", "gc.collect", "torch.cuda.empty_cache", "print", "set", "set", "iter", "next", "run_mlm_auxiliary.process_task_batch", "auxTaskModel.set_aux_grads", "model.parameters", "auxTaskModel.get_classifier_params", "auxTaskModel.reset_dev_head", "auxTaskModel.alpha_generator_algo.update_meta_weights", "run_mlm_auxiliary.save_chkpt", "print", "auxTaskModel.get_metrics", "auxTaskModel.evaluate_classifier", "auxTaskModel.evaluate_classifier", "auxTaskModel.get_metrics.items", "classifier_dev_perfs.append", "auxTaskModel.alpha_generator_algo.record_epoch_end", "any", "len", "gc.collect", "torch.cuda.empty_cache", "print", "str", "logger.info", "max", "print", "logger.info", "auxTaskModel.save", "logger.info", "run_mlm_auxiliary.save_chkpt", "len", "max", "max", "args.model_name_or_path.split", "auxTaskModel.alpha_generator_algo.weights.keys", "print", "tqdm.trange.close"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_classifier_params", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.setup_alpha_generator", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.set_seed", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.DefaultWeighter.prep_epoch_start", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.classifier_sample_grad", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate_fn", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.process_task_batch", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.DefaultWeighter.prep_epoch_start", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.process_task_batch", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.set_aux_grads", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_classifier_params", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.reset_dev_head", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.MetaWeighter.update_meta_weights", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.save_chkpt", "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.record_epoch_end", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.save_chkpt"], ["", "def", "train", "(", "\n", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "auxTaskModel", ":", "TartanModel", "=", "None", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "\t", "\"\"\" Train the model \"\"\"", "\n", "\n", "# Setup data iterators", "\n", "train_dataloader", "=", "{", "}", "\n", "max_dataset_len", ",", "largest_dataset_name", "=", "-", "1", ",", "None", "\n", "for", "task_name", ",", "dataset", "in", "train_dataset", ".", "items", "(", ")", ":", "\n", "\t\t", "train_sampler", "=", "RandomSampler", "(", "dataset", ")", "\n", "bsz_", "=", "args", ".", "per_gpu_train_batch_size", "\n", "if", "args", ".", "tapt_primsize", ":", "\n", "# Make the batch size for tapt the same as the batch size for the primary task.", "\n", "\t\t\t", "bsz_", "=", "args", ".", "classf_iter_batchsz", "if", "'TAPT'", "in", "task_name", "else", "args", ".", "per_gpu_train_batch_size", "\n", "", "train_dataloader", "[", "task_name", "]", "=", "DataLoader", "(", "\n", "dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "bsz_", ",", "collate_fn", "=", "collate_fn", "(", "tokenizer", ".", "pad_token_id", ")", ",", "drop_last", "=", "True", "\n", ")", "\n", "if", "max_dataset_len", "<", "len", "(", "dataset", ")", ":", "\n", "\t\t\t", "max_dataset_len", "=", "len", "(", "dataset", ")", "\n", "largest_dataset_name", "=", "task_name", "\n", "\n", "# Setup training duration details", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "\t\t", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "max_dataset_len", "//", "(", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "per_gpu_train_batch_size", ")", ")", "+", "1", "\n", "logger", ".", "info", "(", "'The number of epochs is : {}'", ".", "format", "(", "args", ".", "num_train_epochs", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "t_total", "=", "(", "max_dataset_len", "//", "(", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "per_gpu_train_batch_size", ")", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "\n", "# Pre-trained model housekeeping", "\n", "", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "# Setup the optimizer for the base model", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "betas", "=", "eval", "(", "args", ".", "classf_betas", ")", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ",", "weight_decay", "=", "args", ".", "base_wd", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "int", "(", "args", ".", "classf_warmup_frac", "*", "t_total", ")", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Setup an optimizer for the parameters of the classifier heads", "\n", "classifier_params", "=", "auxTaskModel", ".", "get_classifier_params", "(", "withbase", "=", "False", ")", "\n", "classifier_optim", "=", "AdamW", "(", "\n", "classifier_params", ",", "betas", "=", "eval", "(", "args", ".", "classf_betas", ")", ",", "\n", "weight_decay", "=", "args", ".", "classf_wd", ",", "lr", "=", "args", ".", "classf_lr", "\n", ")", "\n", "\n", "classifier_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "classifier_optim", ",", "num_warmup_steps", "=", "int", "(", "args", ".", "classf_warmup_frac", "*", "t_total", ")", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Setup the auxiliary task weight generator", "\n", "args", ".", "train_epochs", "=", "t_total", "\n", "auxTaskModel", ".", "setup_alpha_generator", "(", "args", ")", "\n", "\n", "\n", "# Log info before beginning training.", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "for", "k", ",", "v", "in", "train_dataset", ".", "items", "(", ")", ":", "\n", "\t\t", "logger", ".", "info", "(", "\" Task= {} Num examples = {}\"", ".", "format", "(", "k", ",", "len", "(", "v", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Num Warmup Steps = %d\"", ",", "int", "(", "args", ".", "classf_warmup_frac", "*", "t_total", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "per_gpu_train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = {}. Will eval every {}\"", ".", "format", "(", "t_total", ",", "args", ".", "eval_every", ")", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "\t\t", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "\t\t\t", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "max_dataset_len", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "max_dataset_len", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "\t\t\t", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "classifier_dev_perfs", "=", "[", "]", "# For saving the dev set performance so we can checkpoint best.", "\n", "auxTaskModel", ".", "alpha_generator_algo", ".", "prep_epoch_start", "(", "global_step", ")", "\n", "early_stop", "=", "False", "# Indicator for early stopping", "\n", "\n", "for", "epoch", "in", "train_iterator", ":", "\n", "\t\t", "gc", ".", "collect", "(", ")", "\n", "if", "early_stop", ":", "\n", "\t\t\t", "break", "\n", "\n", "# Log the current task weightings", "\n", "", "weights", "=", "{", "k", ":", "auxTaskModel", ".", "alpha_generator_algo", "[", "k", "]", "for", "k", "in", "auxTaskModel", ".", "alpha_generator_algo", ".", "weights", ".", "keys", "(", ")", "}", "\n", "print", "(", "'\\nGStep = {} Weights : '", ".", "format", "(", "global_step", ")", ",", "weights", ",", "'\\n'", ")", "\n", "\n", "# Setup iterator for task with the most amount of data", "\n", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", "[", "largest_dataset_name", "]", ",", "desc", "=", "\"Iteration\"", ")", "\n", "\n", "# Setup Iterators for the other tasks.", "\n", "aux_task_iterators", "=", "{", "}", "\n", "for", "task_id", ",", "task_data", "in", "train_dataloader", ".", "items", "(", ")", ":", "\n", "\t\t\t", "if", "task_id", "==", "largest_dataset_name", ":", "\n", "\t\t\t\t", "continue", "\n", "", "aux_task_iterators", "[", "task_id", "]", "=", "iter", "(", "task_data", ")", "\n", "\n", "# Loop through the auxiliary datasets ", "\n", "", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "# Skip past any already trained steps if resuming training", "\n", "\t\t\t", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "\t\t\t\t", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "try", ":", "\n", "# Forward mode for the task with the largest dataset size", "\n", "\t\t\t\t", "this_loss", "=", "process_task_batch", "(", "auxTaskModel", ",", "model", ",", "batch", ",", "tokenizer", ",", "args", ",", "largest_dataset_name", ")", "\n", "tr_loss", "+=", "this_loss", "/", "len", "(", "args", ".", "aux_task_names", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "\t\t\t\t", "print", "(", "e", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "print", "(", "'Run into error when process_task_batch. Skipping'", ")", "\n", "\n", "# Perform forward mode for the other tasks", "\n", "", "other_tasks", "=", "list", "(", "set", "(", "args", ".", "aux_task_names", ")", "-", "set", "(", "[", "largest_dataset_name", "]", ")", ")", "\n", "for", "task_id", ",", "task_name", "in", "enumerate", "(", "other_tasks", ")", ":", "\n", "\t\t\t\t", "other_batch", "=", "next", "(", "aux_task_iterators", "[", "task_name", "]", ",", "None", ")", "\n", "if", "other_batch", "is", "None", ":", "\n", "\t\t\t\t\t", "aux_task_iterators", "[", "task_name", "]", "=", "iter", "(", "train_dataloader", "[", "task_name", "]", ")", "\n", "other_batch", "=", "next", "(", "aux_task_iterators", "[", "task_name", "]", ",", "None", ")", "\n", "\n", "", "assert", "other_batch", "is", "not", "None", ",", "'We should have more data for {} since we have reset the iterator'", ".", "format", "(", "task_name", ")", "\n", "try", ":", "\n", "\t\t\t\t\t", "this_loss", "=", "process_task_batch", "(", "auxTaskModel", ",", "model", ",", "other_batch", ",", "tokenizer", ",", "args", ",", "task_name", ")", "\n", "tr_loss", "+=", "this_loss", "/", "len", "(", "args", ".", "aux_task_names", ")", "\n", "", "except", ":", "\n", "\t\t\t\t\t", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "print", "(", "'Run into error when process_task_batch. Skipping'", ")", "\n", "\n", "# We have run the auxiliary tasks. Now run the primary task and update the gradietns of the task weightings", "\n", "", "", "auxTaskModel", ".", "classifier_sample_grad", "(", ")", "\n", "\n", "\n", "if", "auxTaskModel", ".", "alpha_generator_algo", ".", "is_meta", ":", "\n", "# Zero-out the aux grads because we are done with them at the moment", "\n", "\t\t\t\t", "for", "task_name", "in", "args", ".", "aux_task_names", ":", "\n", "\t\t\t\t\t", "auxTaskModel", ".", "set_aux_grads", "(", "None", ",", "aux_task_name", "=", "task_name", ")", "\n", "\n", "\n", "# If we have accumulated enough gradients, we can now do a gradient descent step.", "\n", "", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "# Clip the gradients of the pre-trained model base and the classifier parameters", "\n", "\t\t\t\t", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "auxTaskModel", ".", "get_classifier_params", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "# Gradient descent on the classifier parameters", "\n", "classifier_optim", ".", "step", "(", ")", "\n", "classifier_scheduler", ".", "step", "(", ")", "\n", "classifier_optim", ".", "zero_grad", "(", ")", "\n", "\n", "# Gradient descent on the pre-trained model base parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "\n", "# Housekeeping for the task weight generator", "\n", "auxTaskModel", ".", "alpha_generator_algo", ".", "prep_epoch_start", "(", "global_step", ")", "\n", "if", "auxTaskModel", ".", "alpha_generator_algo", ".", "is_meta", ":", "\n", "# Reset the dev head so it is not based on stale pre-trained base parameters.", "\n", "\t\t\t\t\t", "auxTaskModel", ".", "reset_dev_head", "(", ")", "\n", "\n", "# Update the task weightings", "\n", "auxTaskModel", ".", "alpha_generator_algo", ".", "update_meta_weights", "(", ")", "\n", "\n", "# House keeping.", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\t\t\t\t\t", "save_chkpt", "(", "args", ",", "str", "(", "global_step", ")", ",", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "rotate_chkpt", "=", "True", ")", "\n", "\n", "# Log the current task weightings", "\n", "", "if", "global_step", "%", "(", "args", ".", "eval_every", "//", "2", ")", "==", "0", ":", "\n", "\t\t\t\t\t", "weights", "=", "{", "k", ":", "auxTaskModel", ".", "alpha_generator_algo", "[", "k", "]", "for", "k", "in", "auxTaskModel", ".", "alpha_generator_algo", ".", "weights", ".", "keys", "(", ")", "}", "\n", "print", "(", "'\\nGStep = {} Weights : '", ".", "format", "(", "global_step", ")", ",", "weights", ",", "'\\n'", ")", "\n", "\n", "# We will evaluate the model on the primary task and save if it is the current validation performance so far.", "\n", "", "if", "global_step", "%", "args", ".", "eval_every", "==", "0", ":", "\n", "\t\t\t\t\t", "train_metrics", "=", "auxTaskModel", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "dev_metrics", "=", "auxTaskModel", ".", "evaluate_classifier", "(", "set_", "=", "'dev'", ")", "\n", "test_metrics", "=", "auxTaskModel", ".", "evaluate_classifier", "(", "set_", "=", "'test'", ")", "\n", "for", "k", ",", "v", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "\t\t\t\t\t\t", "print_out", "=", "\"[{}] | Train : {:.3f} | Dev Set : {:.3f} | Test Set : {:.3f}\"", ".", "format", "(", "k", ",", "v", ",", "dev_metrics", "[", "k", "]", ",", "test_metrics", "[", "k", "]", ")", "\n", "logger", ".", "info", "(", "print_out", ")", "\n", "\n", "", "classifier_dev_perfs", ".", "append", "(", "dev_metrics", "[", "args", ".", "classf_metric", "]", ")", "\n", "if", "dev_metrics", "[", "args", ".", "classf_metric", "]", ">=", "max", "(", "classifier_dev_perfs", ")", ":", "\n", "# We want to save the best model here", "\n", "\t\t\t\t\t\t", "print", "(", "'Current best dev f1 = {} achieved. Saving model'", ".", "format", "(", "dev_metrics", "[", "args", ".", "classf_metric", "]", ")", ")", "\n", "logger", ".", "info", "(", "'Now Saving the Classifier Model'", ")", "\n", "auxTaskModel", ".", "save", "(", ")", "\n", "logger", ".", "info", "(", "'Saving Base Model'", ")", "\n", "save_chkpt", "(", "args", ",", "'best'", ",", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "rotate_chkpt", "=", "False", ")", "\n", "\n", "# Record the metrics for the alpha generator", "\n", "", "auxTaskModel", ".", "alpha_generator_algo", ".", "record_epoch_end", "(", "global_step", ",", "dev_metrics", "[", "args", ".", "classf_metric", "]", ",", "test_metrics", "[", "args", ".", "classf_metric", "]", ")", "\n", "if", "len", "(", "classifier_dev_perfs", ")", ">", "args", ".", "classf_patience", ":", "\n", "# If we have not seen any improvement in args.classf_patience, then we will early stop", "\n", "\t\t\t\t\t\t", "max_", "=", "max", "(", "classifier_dev_perfs", ")", "\n", "recent_max", "=", "max", "(", "classifier_dev_perfs", "[", "-", "args", ".", "classf_patience", ":", "]", ")", "\n", "if", "recent_max", "<", "max_", ":", "\n", "\t\t\t\t\t\t\t", "print", "(", "'Stopping Early at Epoch {} because No Improvement in Dev Set Accuracy'", ".", "format", "(", "epoch", ")", ")", "\n", "train_iterator", ".", "close", "(", ")", "\n", "early_stop", "=", "True", "\n", "break", "\n", "\n", "", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "\t\t\t\t", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "\t\t\t", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.finetune_primary_task": [[572, 624], ["auxTaskModel.load_primary", "auxTaskModel.evaluate_classifier", "auxTaskModel.evaluate_classifier", "print", "print", "auxTaskModel.get_classifier_params", "transformers.AdamW", "auxTaskModel.train_primary", "print", "pickle.dump", "logger.info", "auxTaskModel.save", "open", "eval", "os.path.join", "any", "any"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load_primary", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.evaluate_classifier", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.get_classifier_params", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.train_primary", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save"], ["", "def", "finetune_primary_task", "(", "args", ",", "auxTaskModel", ")", ":", "\n", "# Load the primary task classifier parameters", "\n", "\t", "auxTaskModel", ".", "load_primary", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluate the refreshed model", "\n", "test_metrics", "=", "auxTaskModel", ".", "evaluate_classifier", "(", "set_", "=", "'test'", ")", "\n", "dev_metrics", "=", "auxTaskModel", ".", "evaluate_classifier", "(", "set_", "=", "'dev'", ")", "\n", "print", "(", "'Before Training. Dev  (F1={:.3f}, Accuracy={:.3f})'", ".", "format", "(", "dev_metrics", "[", "'f1'", "]", ",", "dev_metrics", "[", "'accuracy'", "]", ")", ")", "\n", "print", "(", "'Before Training. Test (F1={:.3f}, Accuracy={:.3f})'", ".", "format", "(", "test_metrics", "[", "'f1'", "]", ",", "test_metrics", "[", "'accuracy'", "]", ")", ")", "\n", "\n", "\n", "# Setup fine-tuning optimizer and learning rate scheduler", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.bias\"", ",", "\"LayerNorm.weight\"", ",", "\"layer_norm.weight\"", "]", "\n", "classifier_params", "=", "auxTaskModel", ".", "get_classifier_params", "(", "keys", "=", "[", "auxTaskModel", ".", "primary_task_id", "]", ",", "withbase", "=", "True", ")", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "classifier_params", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "classifier_params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "this_optim", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "betas", "=", "eval", "(", "args", ".", "classf_betas", ")", ",", "\n", "weight_decay", "=", "args", ".", "classf_wd", ",", "lr", "=", "args", ".", "classf_ft_lr", "\n", ")", "\n", "this_lr_scheduler", "=", "None", "\n", "\n", "best_f1", ",", "best_acc", ",", "perfs", ",", "dev_perfs", "=", "auxTaskModel", ".", "train_primary", "(", "\n", "args", ".", "classf_ft_iters", ",", "this_optim", ",", "this_lr_scheduler", ",", "\n", "args", ".", "max_grad_norm", ",", "patience", "=", "args", ".", "classf_ft_patience", ",", "\n", "metric", "=", "args", ".", "classf_metric", "\n", ")", "\n", "\n", "# Caching the best performance based on the chosen metric", "\n", "save_model", "=", "False", "\n", "if", "args", ".", "classf_metric", "==", "'f1'", ":", "\n", "\t\t", "save_model", "=", "dev_perfs", "[", "0", "]", ">", "dev_metrics", "[", "'f1'", "]", "\n", "best_f1", "=", "best_f1", "if", "dev_perfs", "[", "0", "]", ">", "dev_metrics", "[", "'f1'", "]", "else", "test_metrics", "[", "'f1'", "]", "\n", "best_acc", "=", "best_acc", "if", "dev_perfs", "[", "0", "]", ">", "dev_metrics", "[", "'f1'", "]", "else", "test_metrics", "[", "'accuracy'", "]", "\n", "", "else", ":", "\n", "\t\t", "save_model", "=", "dev_perfs", "[", "1", "]", ">", "dev_metrics", "[", "'accuracy'", "]", "\n", "best_f1", "=", "best_f1", "if", "dev_perfs", "[", "1", "]", ">", "dev_metrics", "[", "'accuracy'", "]", "else", "test_metrics", "[", "'f1'", "]", "\n", "best_acc", "=", "best_acc", "if", "dev_perfs", "[", "1", "]", ">", "dev_metrics", "[", "'accuracy'", "]", "else", "test_metrics", "[", "'accuracy'", "]", "\n", "\n", "# Do the saving of the best model here", "\n", "", "if", "save_model", ":", "\n", "\t\t", "logger", ".", "info", "(", "'Now Saving the Classifier Model'", ")", "\n", "auxTaskModel", ".", "save", "(", ")", "\n", "\n", "", "print", "(", "'Final Test (F1={:.3f}, Accuracy={:.3f})'", ".", "format", "(", "best_f1", ",", "best_acc", ")", ")", "\n", "pickle", ".", "dump", "(", "perfs", ",", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'ftmodel.perf.pkl'", ")", ",", "'wb'", ")", ")", "\n", "return", "save_model", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.get_args": [[626, 778], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "alpha_generator.add_config_args", "endtask_aware.add_tartan_args", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.add_config_args", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.add_tartan_args"], ["", "def", "get_args", "(", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file(s). Number of files specified must match number of aux-task-names\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--aux-task-names\"", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"The names of the auxiliary tasks\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "default", "=", "'roberta-base'", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--line_by_line\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "'roberta-base'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-6", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--base_task_dataset_file\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Name of file for master task'", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lazy-dataset\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_every\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "30", ",", "\n", "help", "=", "\"Frequency with which to evaluate the model\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_final_finetuning\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'turns off further task-specific finetuing'", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--classf_warmup_frac\"", ",", "type", "=", "float", ",", "default", "=", "0.06", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_betas\"", ",", "type", "=", "str", ",", "default", "=", "\"(0.9,0.98)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--from-scratch\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_wd\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--base_wd\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_patience\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_lr\"", ",", "type", "=", "float", ",", "default", "=", "2e-5", ",", "help", "=", "\"Learning rate of classifier\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_ft_lr\"", ",", "type", "=", "float", ",", "default", "=", "2e-6", ",", "help", "=", "\"Learning rate of classifier for finetuning\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_ft_iters\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'Number of finetuning iterations'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf_ft_patience\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'finetuning patience iterations'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classf-metric\"", ",", "type", "=", "str", ",", "default", "=", "'f1'", ",", "choices", "=", "[", "'f1'", ",", "'accuracy'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--tapt-primsize\"", ",", "action", "=", "'store_true'", ",", "help", "=", "'Make tapt batch size the size of primary task'", ")", "\n", "\n", "add_config_args", "(", "parser", ")", "\n", "add_tartan_args", "(", "parser", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.main": [[779, 927], ["run_mlm_auxiliary.get_args", "logging.basicConfig", "torch.device", "run_mlm_auxiliary.set_seed", "os.makedirs", "run_mlm_auxiliary.load_and_cache_examples", "logger.info", "endtask_auxtasks.get_auxtask_files", "endtask_aware.TartanModel", "AutoModelWithLMHead.from_pretrained.to", "endtask_aware.TartanModel.to", "logger.info", "ValueError", "run_mlm_auxiliary._sorted_checkpoints", "os.path.exists", "os.listdir", "ValueError", "torch.cuda.device_count", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelWithLMHead.from_pretrained", "logger.info", "transformers.AutoModelWithLMHead.from_config", "min", "run_mlm_auxiliary.train", "logger.info", "endtask_aware.TartanModel.alpha_generator_algo.viz_results", "run_mlm_auxiliary.finetune_primary_task", "os.makedirs", "logger.info", "model_to_save.save_pretrained", "AutoTokenizer.from_pretrained.save_pretrained", "torch.save", "transformers.AutoModelWithLMHead.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoModelWithLMHead.from_pretrained.to", "len", "ValueError", "print", "transformers.AutoConfig.from_pretrained", "ValueError", "transformers.AutoTokenizer.from_pretrained", "ValueError", "os.path.join", "hasattr", "os.path.join", "torch.cuda.is_available", "bool"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.get_args", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.set_seed", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.load_and_cache_examples", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_auxtasks.get_auxtask_files", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary._sorted_checkpoints", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.train", "home.repos.pwc.inspect_result.ldery_tartan.scripts.alpha_generator.Weighter.viz_results", "home.repos.pwc.inspect_result.ldery_tartan.scripts.run_mlm_auxiliary.finetune_primary_task", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.to"], ["", "def", "main", "(", ")", ":", "\n", "\t", "args", "=", "get_args", "(", ")", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "and", "not", "args", ".", "mlm", ":", "\n", "\t\t", "raise", "ValueError", "(", "\n", "\"BERT and RoBERTa-like models do not have LM heads but masked LM heads. They must be run using the --mlm \"", "\n", "\"flag (masked language modeling).\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "\t\t", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Used --should_continue but no checkpoint was found in --output_dir.\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "print", "(", "'Used Should Continue and model found is : '", ",", "args", ".", "model_name_or_path", ")", "\n", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", "and", "not", "args", ".", "should_continue", "\n", ")", ":", "\n", "\t\t", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", ",", "\n", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "\t\t", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "output_hidden_states", "=", "True", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "\t\t", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "output_hidden_states", "=", "True", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "# When we release a pip version exposing CONFIG_MAPPING,", "\n", "# we can do `config = CONFIG_MAPPING[args.model_type]()`.", "\n", "\t\t", "raise", "ValueError", "(", "\n", "\"You are instantiating a new config instance from scratch. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --config_name\"", "\n", ")", "\n", "\n", "# Setting up tokenizer and pre-trained model", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "\t\t", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "\t\t", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "\t\t", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", "and", "not", "args", ".", "from_scratch", ":", "\n", "\t\t", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "\t\t", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_config", "(", "config", ")", "\n", "\n", "\n", "", "model_name", "=", "args", ".", "model_name_or_path", "\n", "assert", "model_name", ",", "'The name of the model is not Set. Maybe use roberta-base as the default'", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Setting up the dataset", "\n", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "\t\t", "args", ".", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "\t\t", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "\n", "# Instantiate the model with the auxiliary tasks", "\n", "", "logger", ".", "info", "(", "\"Instantiating AuxTaskModel\"", ")", "\n", "base_task_dataset_files", "=", "get_auxtask_files", "(", "args", ".", "primary_task_id", ")", "\n", "auxTaskModel", "=", "TartanModel", "(", "\n", "model_name", ",", "\n", "model", ",", "\n", "base_task_dataset_files", ",", "\n", "\n", "max_seq_len", "=", "args", ".", "classf_max_seq_len", ",", "\n", "dropout", "=", "args", ".", "classifier_dropout", ",", "\n", "\n", "batch_sz", "=", "args", ".", "classf_iter_batchsz", ",", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'modelWAuxTasks.pth'", ")", ",", "\n", "primary_task_id", "=", "args", ".", "primary_task_id", ",", "\n", "grad_accum_factor", "=", "args", ".", "gradient_accumulation_steps", ",", "\n", "dev_batch_sz", "=", "args", ".", "dev_batch_sz", "\n", ")", "\n", "\n", "# Move the model to the appropriate device", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "auxTaskModel", ".", "to", "(", "args", ".", "device", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Do end-task aware training", "\n", "if", "args", ".", "do_train", ":", "\n", "\t\t", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "auxTaskModel", "=", "auxTaskModel", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "# Saving the visualization", "\n", "group_aux", "=", "args", ".", "weight_strgy", "==", "'meta'", "\n", "auxTaskModel", ".", "alpha_generator_algo", ".", "viz_results", "(", "args", ".", "output_dir", ",", "group_aux", "=", "group_aux", ")", "\n", "\n", "# We want to now do finetuning the model on only the primary task", "\n", "", "if", "not", "args", ".", "no_final_finetuning", ":", "\n", "\t\t", "improved_fom_finetuning", "=", "finetune_primary_task", "(", "args", ",", "auxTaskModel", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer,", "\n", "# you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "improved_fom_finetuning", ":", "\n", "# Create output directory if needed", "\n", "\t\t", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate": [[9, 11], ["torch.nn.utils.rnn.pad_sequence"], "function", ["None"], ["def", "collate", "(", "examples", ",", "pad_token_id", ")", ":", "\n", "\t", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "pad_token_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate_fn": [[12, 16], ["utils.collate"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.collate"], ["", "def", "collate_fn", "(", "pad_token_id", ")", ":", "\n", "\t", "def", "this_collate", "(", "examples", ")", ":", "\n", "\t\t", "return", "collate", "(", "examples", ",", "pad_token_id", ")", "\n", "", "return", "this_collate", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.dot_prod": [[18, 27], ["zip", "isinstance", "total.item"], "function", ["None"], ["", "def", "dot_prod", "(", "g1", ",", "g2", ")", ":", "\n", "\t", "total", "=", "0.0", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "g1", ",", "g2", ")", ":", "\n", "\t\t", "if", "p1", "is", "None", "or", "p2", "is", "None", ":", "\n", "\t\t\t", "continue", "\n", "", "sum_", "=", "(", "p1", "*", "p2", ")", ".", "sum", "(", ")", "\n", "total", "+=", "sum_", "\n", "", "total", "=", "total", ".", "item", "(", ")", "if", "isinstance", "(", "total", ",", "torch", ".", "Tensor", ")", "else", "total", "\n", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm": [[29, 35], ["numpy.sqrt", "norm.item"], "function", ["None"], ["", "def", "calc_norm", "(", "list_of_vec", ")", ":", "\n", "\t", "norm", "=", "0.0", "\n", "for", "g_", "in", "list_of_vec", ":", "\n", "\t\t", "if", "g_", "is", "not", "None", ":", "\n", "\t\t\t", "norm", "+=", "(", "g_", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "", "return", "np", ".", "sqrt", "(", "norm", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.cosine": [[37, 43], ["utils.calc_norm", "utils.calc_norm", "utils.dot_prod"], "function", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.calc_norm", "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.dot_prod"], ["", "def", "cosine", "(", "vec_list_a", ",", "vec_list_b", ")", ":", "\n", "\t", "a_norm", "=", "calc_norm", "(", "vec_list_a", ")", "\n", "b_norm", "=", "calc_norm", "(", "vec_list_b", ")", "\n", "norm_product", "=", "(", "a_norm", "*", "b_norm", "+", "EPS", ")", "\n", "cos_", "=", "dot_prod", "(", "vec_list_a", ",", "vec_list_b", ")", "/", "norm_product", "\n", "return", "cos_", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.get_body_end": [[47, 53], ["model.named_parameters"], "function", ["None"], ["", "def", "get_body_end", "(", "model", ",", "body_marker", "=", "'_text_field_embedder'", ")", ":", "\n", "\t", "pos", "=", "0", "\n", "for", "k", ",", "_", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "\t\t", "if", "body_marker", "in", "k", ":", "\n", "\t\t\t", "pos", "+=", "1", "\n", "", "", "return", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.utils.create_tensor": [[55, 62], ["torch.ones", "torch.ones", "inits.float().cuda", "inits.float", "inits.float"], "function", ["None"], ["", "def", "create_tensor", "(", "shape", ",", "init", "=", "0.0", ",", "requires_grad", "=", "True", ",", "is_cuda", "=", "True", ")", ":", "\n", "\t", "inits", "=", "torch", ".", "ones", "(", "*", "shape", ")", "*", "init", "\n", "# Create the weights", "\n", "weights", "=", "inits", ".", "float", "(", ")", ".", "cuda", "(", ")", "if", "is_cuda", "else", "inits", ".", "float", "(", ")", "\n", "if", "requires_grad", ":", "\n", "\t\t", "weights", ".", "requires_grad", "=", "True", "\n", "", "return", "weights", "\n", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_auxtasks.get_auxtask_files": [[31, 42], ["None"], "function", ["None"], ["def", "get_auxtask_files", "(", "task_name", ")", ":", "\n", "\t", "if", "task_name", "==", "'citation_intent'", ":", "\n", "\t\t", "return", "CITATION", "\n", "", "elif", "task_name", "==", "'chemprot'", ":", "\n", "\t\t", "return", "CHEMPROT", "\n", "", "elif", "task_name", "==", "'sciie'", ":", "\n", "\t\t", "return", "SCIIE", "\n", "", "elif", "task_name", "==", "'hyperpartisan'", ":", "\n", "\t\t", "return", "HYPERPARTISAN", "\n", "", "else", ":", "\n", "\t\t", "raise", "ValueError", "", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.__init__": [[27, 34], ["allennlp.training.checkpointer.Checkpointer.__init__"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_epochs", ":", "int", ",", "\n", "serialization_dir", ":", "str", "=", "None", ",", "\n", "keep_serialized_model_every_num_seconds", ":", "int", "=", "None", ",", "\n", "num_serialized_models_to_keep", ":", "int", "=", "20", ")", "->", "None", ":", "\n", "        ", "self", ".", "_num_epochs", "=", "num_epochs", "\n", "super", "(", ")", ".", "__init__", "(", "serialization_dir", ",", "keep_serialized_model_every_num_seconds", ",", "num_serialized_models_to_keep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.save_checkpoint": [[35, 74], ["os.path.join", "torch.save", "os.path.join", "torch.save", "logger.info", "shutil.copyfile", "ft_checkpointer.FinetuningCheckpointer._serialized_paths.append", "os.path.join", "len", "ft_checkpointer.FinetuningCheckpointer._serialized_paths.pop", "time.time", "os.path.isfile", "os.remove"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.save"], ["", "def", "save_checkpoint", "(", "self", ",", "\n", "epoch", ":", "Union", "[", "int", ",", "str", "]", ",", "\n", "model_state", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "training_states", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "is_best_so_far", ":", "bool", ")", "->", "None", ":", "\n", "        ", "if", "epoch", "<", "self", ".", "_num_epochs", "-", "1", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_serialization_dir", "is", "not", "None", ":", "\n", "                ", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\"model_state_epoch_{}.th\"", ".", "format", "(", "epoch", ")", ")", "\n", "torch", ".", "save", "(", "model_state", ",", "model_path", ")", "\n", "training_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\n", "\"training_state_epoch_{}.th\"", ".", "format", "(", "epoch", ")", ")", "\n", "torch", ".", "save", "(", "{", "**", "training_states", ",", "\"epoch\"", ":", "epoch", "}", ",", "training_path", ")", "\n", "\n", "if", "is_best_so_far", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Best validation performance so far. \"", "\n", "\"Copying weights to '%s/best.th'.\"", ",", "self", ".", "_serialization_dir", ")", "\n", "shutil", ".", "copyfile", "(", "model_path", ",", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\"best.th\"", ")", ")", "\n", "\n", "", "if", "self", ".", "_num_serialized_models_to_keep", "is", "not", "None", "and", "self", ".", "_num_serialized_models_to_keep", ">=", "0", ":", "\n", "                    ", "self", ".", "_serialized_paths", ".", "append", "(", "(", "time", ".", "time", "(", ")", ",", "model_path", ",", "training_path", ")", ")", "\n", "if", "len", "(", "self", ".", "_serialized_paths", ")", ">", "self", ".", "_num_serialized_models_to_keep", ":", "\n", "                        ", "paths_to_remove", "=", "self", ".", "_serialized_paths", ".", "pop", "(", "0", ")", "\n", "# Check to see if we should keep this checkpoint, if it has been longer", "\n", "# then self._keep_serialized_model_every_num_seconds since the last", "\n", "# kept checkpoint.", "\n", "remove_path", "=", "True", "\n", "if", "self", ".", "_keep_serialized_model_every_num_seconds", "is", "not", "None", ":", "\n", "                            ", "save_time", "=", "paths_to_remove", "[", "0", "]", "\n", "time_since_checkpoint_kept", "=", "save_time", "-", "self", ".", "_last_permanent_saved_checkpoint_time", "\n", "if", "time_since_checkpoint_kept", ">", "self", ".", "_keep_serialized_model_every_num_seconds", ":", "\n", "# We want to keep this checkpoint.", "\n", "                                ", "remove_path", "=", "False", "\n", "self", ".", "_last_permanent_saved_checkpoint_time", "=", "save_time", "\n", "", "", "if", "remove_path", ":", "\n", "                            ", "for", "fname", "in", "paths_to_remove", "[", "1", ":", "]", ":", "\n", "                                ", "if", "os", ".", "path", ".", "isfile", "(", "fname", ")", ":", "\n", "                                    ", "os", ".", "remove", "(", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.find_latest_checkpoint": [[75, 116], ["os.listdir", "os.path.join", "os.path.join", "any", "re.search().group", "epoch.split", "sorted", "str", "len", "int_epochs.append", "int_epochs.append", "re.search", "os.listdir", "int", "int"], "methods", ["None"], ["", "", "", "", "", "", "", "", "def", "find_latest_checkpoint", "(", "self", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"\n        Return the location of the latest model and training state files.\n        If there isn't a valid checkpoint then return None.\n        \"\"\"", "\n", "have_checkpoint", "=", "(", "self", ".", "_serialization_dir", "is", "not", "None", "and", "\n", "any", "(", "\"model_state_epoch_\"", "in", "x", "for", "x", "in", "os", ".", "listdir", "(", "self", ".", "_serialization_dir", ")", ")", ")", "\n", "\n", "if", "not", "have_checkpoint", ":", "\n", "            ", "return", "None", "\n", "\n", "", "serialization_files", "=", "os", ".", "listdir", "(", "self", ".", "_serialization_dir", ")", "\n", "model_checkpoints", "=", "[", "x", "for", "x", "in", "serialization_files", "if", "\"model_state_epoch\"", "in", "x", "]", "\n", "# Get the last checkpoint file.  Epochs are specified as either an", "\n", "# int (for end of epoch files) or with epoch and timestamp for", "\n", "# within epoch checkpoints, e.g. 5.2018-02-02-15-33-42", "\n", "found_epochs", "=", "[", "\n", "re", ".", "search", "(", "r\"model_state_epoch_([0-9\\.\\-]+)\\.th\"", ",", "x", ")", ".", "group", "(", "1", ")", "\n", "for", "x", "in", "model_checkpoints", "\n", "]", "\n", "int_epochs", ":", "Any", "=", "[", "]", "\n", "for", "epoch", "in", "found_epochs", ":", "\n", "            ", "pieces", "=", "epoch", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "pieces", ")", "==", "1", ":", "\n", "# Just a single epoch without timestamp", "\n", "                ", "int_epochs", ".", "append", "(", "[", "int", "(", "pieces", "[", "0", "]", ")", ",", "'0'", "]", ")", "\n", "", "else", ":", "\n", "# has a timestamp", "\n", "                ", "int_epochs", ".", "append", "(", "[", "int", "(", "pieces", "[", "0", "]", ")", ",", "pieces", "[", "1", "]", "]", ")", "\n", "", "", "last_epoch", "=", "sorted", "(", "int_epochs", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "if", "last_epoch", "[", "1", "]", "==", "'0'", ":", "\n", "            ", "epoch_to_load", "=", "str", "(", "last_epoch", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "epoch_to_load", "=", "'{0}.{1}'", ".", "format", "(", "last_epoch", "[", "0", "]", ",", "last_epoch", "[", "1", "]", ")", "\n", "\n", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\n", "\"model_state_epoch_{}.th\"", ".", "format", "(", "epoch_to_load", ")", ")", "\n", "training_state_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "\n", "\"training_state_epoch_{}.th\"", ".", "format", "(", "epoch_to_load", ")", ")", "\n", "\n", "return", "(", "model_path", ",", "training_state_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.restore_checkpoint": [[117, 147], ["ft_checkpointer.FinetuningCheckpointer.find_latest_checkpoint", "torch.load", "torch.load", "allennlp.nn.util.device_mapping", "allennlp.nn.util.device_mapping"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.find_latest_checkpoint", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load", "home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load"], ["", "def", "restore_checkpoint", "(", "self", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"\n        Restores a model from a serialization_dir to the last saved checkpoint.\n        This includes a training state (typically consisting of an epoch count and optimizer state),\n        which is serialized separately from  model parameters. This function should only be used to\n        continue training - if you wish to load a model for inference/load parts of a model into a new\n        computation graph, you should use the native Pytorch functions:\n        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n        this function will do nothing and return empty dicts.\n        Returns\n        -------\n        states: Tuple[Dict[str, Any], Dict[str, Any]]\n            The model state and the training state.\n        \"\"\"", "\n", "latest_checkpoint", "=", "self", ".", "find_latest_checkpoint", "(", ")", "\n", "\n", "if", "latest_checkpoint", "is", "None", ":", "\n", "# No checkpoint to restore, start at 0", "\n", "            ", "return", "{", "}", ",", "{", "}", "\n", "\n", "", "model_path", ",", "training_state_path", "=", "latest_checkpoint", "\n", "\n", "# Load the parameters onto CPU, then transfer to GPU.", "\n", "# This avoids potential OOM on GPU for large models that", "\n", "# load parameters onto GPU then make a new GPU copy into the parameter", "\n", "# buffer. The GPU transfer happens implicitly in load_state_dict.", "\n", "model_state", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "nn_util", ".", "device_mapping", "(", "-", "1", ")", ")", "\n", "training_state", "=", "torch", ".", "load", "(", "training_state_path", ",", "map_location", "=", "nn_util", ".", "device_mapping", "(", "-", "1", ")", ")", "\n", "return", "model_state", ",", "training_state", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.training.ft_checkpointer.FinetuningCheckpointer.best_model_state": [[148, 157], ["logger.info", "os.path.join", "torch.load", "logger.info"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.scripts.endtask_aware.TartanModel.load"], ["", "def", "best_model_state", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "if", "self", ".", "_serialization_dir", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading best weights\"", ")", "\n", "best_model_state_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "'best.th'", ")", "\n", "return", "torch", ".", "load", "(", "best_model_state_path", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"cannot load best weights without `serialization_dir`, \"", "\n", "\"so you're just getting the last weights\"", ")", "\n", "return", "{", "}", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.seq2vec_encoders.cls_pooler.CLSPooler.__init__": [[37, 40], ["allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_embedding_dim", "=", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.seq2vec_encoders.cls_pooler.CLSPooler.get_input_dim": [[41, 44], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.seq2vec_encoders.cls_pooler.CLSPooler.get_output_dim": [[45, 48], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.seq2vec_encoders.cls_pooler.CLSPooler.forward": [[49, 52], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "# pylint: disable=arguments-differ,unused-argument", "\n", "        ", "pooled", "=", "tokens", "[", ":", ",", "0", ",", ":", "]", "\n", "return", "pooled", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.__init__": [[50, 95], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "basic_classifier_with_f1.BasicClassifierWithF1._seq2vec_encoder.get_output_dim", "torch.nn.Linear", "allennlp.training.metrics.CategoricalAccuracy", "range", "torch.nn.CrossEntropyLoss", "torch.nn.Dropout", "vocab.get_vocab_size", "allennlp.training.metrics.F1Measure", "initializer", "vocab.get_token_from_index"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__", "home.repos.pwc.inspect_result.ldery_tartan.seq2vec_encoders.cls_pooler.CLSPooler.get_output_dim"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "seq2vec_encoder", ":", "Seq2VecEncoder", ",", "\n", "feedforward_layer", ":", "FeedForward", ",", "\n", "seq2seq_encoder", ":", "Seq2SeqEncoder", "=", "None", ",", "\n", "dropout", ":", "float", "=", "None", ",", "\n", "num_labels", ":", "int", "=", "None", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "\n", "if", "seq2seq_encoder", ":", "\n", "\t\t\t", "self", ".", "_seq2seq_encoder", "=", "seq2seq_encoder", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "_seq2seq_encoder", "=", "None", "\n", "\n", "", "self", ".", "_seq2vec_encoder", "=", "seq2vec_encoder", "\n", "self", ".", "_classifier_input_dim", "=", "self", ".", "_seq2vec_encoder", ".", "get_output_dim", "(", ")", "\n", "\n", "if", "dropout", ":", "\n", "\t\t\t", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "_dropout", "=", "None", "\n", "\n", "", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "\n", "if", "num_labels", ":", "\n", "\t\t\t", "self", ".", "_num_labels", "=", "num_labels", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "self", ".", "_label_namespace", ")", "\n", "", "self", ".", "_feedforward_layer", "=", "feedforward_layer", "\n", "self", ".", "_classification_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_classifier_input_dim", ",", "self", ".", "_num_labels", ")", "\n", "self", ".", "_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_label_f1_metrics", ":", "Dict", "[", "str", ",", "F1Measure", "]", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_labels", ")", ":", "\n", "\t\t\t", "self", ".", "_label_f1_metrics", "[", "vocab", ".", "get_token_from_index", "(", "index", "=", "i", ",", "namespace", "=", "\"labels\"", ")", "]", "=", "F1Measure", "(", "positive_label", "=", "i", ")", "\n", "", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "if", "initializer", "is", "not", "None", ":", "\n", "\t\t\t", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.forward": [[96, 153], ["basic_classifier_with_f1.BasicClassifierWithF1._text_field_embedder", "isinstance", "basic_classifier_with_f1.BasicClassifierWithF1._seq2vec_encoder", "basic_classifier_with_f1.BasicClassifierWithF1._feedforward_layer", "basic_classifier_with_f1.BasicClassifierWithF1._classification_layer", "torch.nn.functional.softmax", "allennlp.nn.util.get_text_field_mask().float", "basic_classifier_with_f1.BasicClassifierWithF1._seq2seq_encoder", "basic_classifier_with_f1.BasicClassifierWithF1._dropout", "basic_classifier_with_f1.BasicClassifierWithF1._loss", "basic_classifier_with_f1.BasicClassifierWithF1.mean", "range", "basic_classifier_with_f1.BasicClassifierWithF1._accuracy", "label.long().view", "metric", "allennlp.nn.util.get_text_field_mask", "label.long", "basic_classifier_with_f1.BasicClassifierWithF1.vocab.get_token_from_index"], "methods", ["None"], ["", "", "def", "forward", "(", "# type: ignore", "\n", "self", ",", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "label", ":", "torch", ".", "IntTensor", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "\t\t", "\"\"\"\n\t\tParameters\n\t\t----------\n\t\ttokens : Dict[str, torch.LongTensor]\n\t\t\t\tFrom a ``TextField``\n\t\tlabel : torch.IntTensor, optional (default = None)\n\t\t\t\tFrom a ``LabelField``\n\n\t\tReturns\n\t\t-------\n\t\tAn output dictionary consisting of:\n\n\t\tlogits : torch.FloatTensor\n\t\t\t\tA tensor of shape ``(batch_size, num_labels)`` representing\n\t\t\t\tunnormalized log probabilities of the label.\n\t\tprobs : torch.FloatTensor\n\t\t\t\tA tensor of shape ``(batch_size, num_labels)`` representing\n\t\t\t\tprobabilities of the label.\n\t\tloss : torch.FloatTensor, optional\n\t\t\t\tA scalar loss to be optimised.\n\t\t\"\"\"", "\n", "embedded_text", "=", "self", ".", "_text_field_embedder", "(", "tokens", ")", "\n", "if", "isinstance", "(", "tokens", ",", "dict", ")", ":", "\n", "\t\t\t", "mask", "=", "get_text_field_mask", "(", "tokens", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t", "mask", "=", "None", "\n", "embedded_text", "=", "embedded_text", "[", "1", "]", "[", "-", "1", "]", "\n", "\n", "", "if", "self", ".", "_seq2seq_encoder", ":", "\n", "\t\t\t", "embedded_text", "=", "self", ".", "_seq2seq_encoder", "(", "embedded_text", ",", "mask", "=", "mask", ")", "\n", "\n", "", "embedded_text", "=", "self", ".", "_seq2vec_encoder", "(", "embedded_text", ",", "mask", "=", "mask", ")", "\n", "\n", "if", "self", ".", "_dropout", ":", "\n", "\t\t\t", "embedded_text", "=", "self", ".", "_dropout", "(", "embedded_text", ")", "\n", "\n", "", "feedforward_output", "=", "self", ".", "_feedforward_layer", "(", "embedded_text", ")", "\n", "\n", "logits", "=", "self", ".", "_classification_layer", "(", "feedforward_output", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"logits\"", ":", "logits", ",", "\"probs\"", ":", "probs", "}", "\n", "\n", "if", "label", "is", "not", "None", ":", "\n", "\t\t\t", "loss", "=", "self", ".", "_loss", "(", "logits", ",", "label", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "output_dict", "[", "\"loss_full\"", "]", "=", "loss", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", ".", "mean", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_labels", ")", ":", "\n", "\t\t\t\t", "metric", "=", "self", ".", "_label_f1_metrics", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "index", "=", "i", ",", "namespace", "=", "\"labels\"", ")", "]", "\n", "metric", "(", "probs", ",", "label", ")", "\n", "", "self", ".", "_accuracy", "(", "logits", ",", "label", ")", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.decode": [[154, 174], ["predictions.dim", "prediction.argmax().item", "basic_classifier_with_f1.BasicClassifierWithF1.vocab.get_index_to_token_vocabulary().get", "classes.append", "str", "range", "prediction.argmax", "basic_classifier_with_f1.BasicClassifierWithF1.vocab.get_index_to_token_vocabulary"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\t\t", "\"\"\"\n\t\tDoes a simple argmax over the probabilities, converts index to string label, and\n\t\tadd ``\"label\"`` key to the dictionary with the result.\n\t\t\"\"\"", "\n", "predictions", "=", "output_dict", "[", "\"probs\"", "]", "\n", "if", "predictions", ".", "dim", "(", ")", "==", "2", ":", "\n", "\t\t\t", "predictions_list", "=", "[", "predictions", "[", "i", "]", "for", "i", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "\t\t\t", "predictions_list", "=", "[", "predictions", "]", "\n", "", "classes", "=", "[", "]", "\n", "for", "prediction", "in", "predictions_list", ":", "\n", "\t\t\t", "label_idx", "=", "prediction", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "item", "(", ")", "\n", "label_str", "=", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "self", ".", "_label_namespace", ")", ".", "get", "(", "\n", "label_idx", ",", "str", "(", "label_idx", ")", "\n", ")", "\n", "classes", ".", "append", "(", "label_str", ")", "\n", "", "output_dict", "[", "\"label\"", "]", "=", "classes", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.models.basic_classifier_with_f1.BasicClassifierWithF1.get_metrics": [[175, 187], ["basic_classifier_with_f1.BasicClassifierWithF1._label_f1_metrics.items", "list", "len", "basic_classifier_with_f1.BasicClassifierWithF1._accuracy.get_metric", "metric.get_metric", "basic_classifier_with_f1.BasicClassifierWithF1._label_f1_metrics.keys"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "\t\t", "metric_dict", "=", "{", "}", "\n", "sum_f1", "=", "0.0", "\n", "for", "name", ",", "metric", "in", "self", ".", "_label_f1_metrics", ".", "items", "(", ")", ":", "\n", "\t\t\t", "metric_val", "=", "metric", ".", "get_metric", "(", "reset", ")", "\n", "sum_f1", "+=", "metric_val", "[", "2", "]", "\n", "", "names", "=", "list", "(", "self", ".", "_label_f1_metrics", ".", "keys", "(", ")", ")", "\n", "total_len", "=", "len", "(", "names", ")", "\n", "average_f1", "=", "sum_f1", "/", "total_len", "\n", "metric_dict", "[", "'f1'", "]", "=", "average_f1", "\n", "metric_dict", "[", "'accuracy'", "]", "=", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", "\n", "return", "metric_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__": [[62, 81], ["allennlp.data.dataset_readers.TextClassificationJsonReader.__init__", "WordTokenizer", "allennlp.data.tokenizers.sentence_splitter.SpacySentenceSplitter", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "max_sequence_length", ":", "int", "=", "None", ",", "\n", "sample", ":", "int", "=", "None", ",", "\n", "skip_label_indexing", ":", "bool", "=", "False", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "lazy", ",", "\n", "token_indexers", "=", "token_indexers", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_sequence_length", "=", "max_sequence_length", ",", "\n", "skip_label_indexing", "=", "skip_label_indexing", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "WordTokenizer", "(", ")", "\n", "self", ".", "_sample", "=", "sample", "\n", "self", ".", "_max_sequence_length", "=", "max_sequence_length", "\n", "self", ".", "_skip_label_indexing", "=", "skip_label_indexing", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "if", "self", ".", "_segment_sentences", ":", "\n", "            ", "self", ".", "_sentence_segmenter", "=", "SpacySentenceSplitter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._reservoir_sampling": [[82, 123], ["iter", "enumerate", "numpy.random.randint", "next", "allennlp.common.checks.ConfigurationError", "range"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_reservoir_sampling", "(", "file_", ":", "TextIOWrapper", ",", "sample", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        A function for reading random lines from file without loading the\n        entire file into memory.\n\n        For more information, see here: https://en.wikipedia.org/wiki/Reservoir_sampling\n\n        To create a k-length sample of a file, without knowing the length of the file in advance,\n        we first create a reservoir array containing the first k elements of the file. Then, we further\n        iterate through the file, replacing elements in the reservoir with decreasing probability.\n\n        By induction, one can prove that if there are n items in the file, each item is sampled with probability\n        k / n.\n\n        Parameters\n        ----------\n        file : `_io.TextIOWrapper` - file path\n        sample_size : `int` - size of random sample you want\n\n        Returns\n        -------\n        result : `List[str]` - sample lines of file\n        \"\"\"", "\n", "# instantiate file iterator", "\n", "file_iterator", "=", "iter", "(", "file_", ")", "\n", "\n", "try", ":", "\n", "# fill the reservoir array", "\n", "            ", "result", "=", "[", "next", "(", "file_iterator", ")", "for", "_", "in", "range", "(", "sample", ")", "]", "\n", "", "except", "StopIteration", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"sample size {sample} larger than number of lines in file.\"", ")", "\n", "\n", "# replace elements in reservoir array with decreasing probability", "\n", "", "for", "index", ",", "item", "in", "enumerate", "(", "file_iterator", ",", "start", "=", "sample", ")", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "index", ")", "\n", "if", "sample_index", "<", "sample", ":", "\n", "                ", "result", "[", "sample_index", "]", "=", "item", "\n", "\n", "", "", "for", "line", "in", "result", ":", "\n", "            ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._read": [[124, 136], ["open", "allennlp.common.file_utils.cached_path", "text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._reservoir_sampling", "json.loads", "str", "json.loads.get", "text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._reservoir_sampling", "home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.text_to_instance"], ["", "", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "if", "self", ".", "_sample", "is", "not", "None", ":", "\n", "                ", "data_file", "=", "self", ".", "_reservoir_sampling", "(", "data_file", ",", "self", ".", "_sample", ")", "\n", "", "for", "line", "in", "data_file", ":", "\n", "                ", "items", "=", "json", ".", "loads", "(", "line", ")", "\n", "text", "=", "items", "[", "\"text\"", "]", "\n", "label", "=", "str", "(", "items", ".", "get", "(", "'label'", ")", ")", "\n", "if", "text", ":", "\n", "                    ", "instance", "=", "self", ".", "text_to_instance", "(", "text", "=", "text", ",", "label", "=", "label", ")", "\n", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.ldery_tartan.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling.text_to_instance": [[137, 165], ["text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp.data.instance.Instance", "text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling._truncate", "allennlp.data.fields.LabelField"], "methods", ["None"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "text", ":", "str", ",", "label", ":", "str", "=", "None", ")", "->", "Instance", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        text : ``str``, required.\n            The text to classify\n        label ``str``, optional, (default = None).\n            The label for this text.\n\n        Returns\n        -------\n        An ``Instance`` containing the following fields:\n            tokens : ``TextField``\n                The tokens in the sentence or phrase.\n            label : ``LabelField``\n                The label label of the sentence or phrase.\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "if", "self", ".", "_max_sequence_length", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "self", ".", "_truncate", "(", "tokens", ")", "\n", "", "fields", "[", "'tokens'", "]", "=", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'label'", "]", "=", "LabelField", "(", "label", ",", "\n", "skip_indexing", "=", "self", ".", "_skip_label_indexing", ")", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]]}