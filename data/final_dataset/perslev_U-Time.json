{"home.repos.pwc.inspect_result.perslev_U-Time.usleep_dataset_prep.convert_dod_datasets.convert_h5_file": [[9, 45], ["h5_path.replace", "os.path.join", "os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "os.path.exists", "h5py.File", "json.loads", "numpy.all", "print", "utime.utils.scriptutils.extract.to_h5_file", "numpy.array", "numpy.save", "sample_rates.append", "data.append", "channel_names.append", "numpy.array", "int", "numpy.array", "[].replace", "numpy.array", "channel[].split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save"], ["def", "convert_h5_file", "(", "h5_path", ")", ":", "\n", "    ", "out_dir", "=", "h5_path", ".", "replace", "(", "\".h5\"", ",", "\"\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "", "out_h5_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"signals.h5\"", ")", "\n", "out_hyp_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"hypnogram.npy\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_h5_path", ")", "and", "os", ".", "path", ".", "exists", "(", "out_hyp_path", ")", ":", "\n", "        ", "return", "\n", "\n", "", "with", "h5py", ".", "File", "(", "h5_path", ",", "\"r\"", ")", "as", "in_f", ":", "\n", "        ", "description", "=", "json", ".", "loads", "(", "in_f", ".", "attrs", "[", "'description'", "]", ")", "\n", "\n", "data", "=", "[", "]", "\n", "sample_rates", "=", "[", "]", "\n", "channel_names", "=", "[", "]", "\n", "for", "channel", "in", "description", ":", "\n", "            ", "sample_rates", ".", "append", "(", "int", "(", "channel", "[", "'fs'", "]", ")", ")", "\n", "data", ".", "append", "(", "np", ".", "array", "(", "in_f", "[", "channel", "[", "\"path\"", "]", "]", ")", ")", "\n", "channel_names", ".", "append", "(", "channel", "[", "\"path\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", ")", "\n", "\n", "", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "sample_rates", ")", "==", "sample_rates", "[", "0", "]", ")", "\n", "sample_rate", "=", "sample_rates", "[", "0", "]", "\n", "data", "=", "np", ".", "array", "(", "data", ")", ".", "T", "\n", "\n", "print", "(", "channel_names", ")", "\n", "to_h5_file", "(", "\n", "out_path", "=", "out_h5_path", ",", "\n", "data", "=", "data", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "channel_names", "=", "channel_names", ",", "\n", "date", "=", "None", "\n", ")", "\n", "\n", "# Save hypnogram", "\n", "hyp", "=", "np", ".", "array", "(", "in_f", "[", "'hypnogram'", "]", ")", "\n", "np", ".", "save", "(", "out_hyp_path", ",", "hyp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_project_directory": [[33, 47], ["os.path.abspath", "logger.info", "os.path.exists", "OSError", "os.path.exists", "os.path.exists", "OSError", "cls.get_hparams_path", "cls.get_pre_processed_hparams_path"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_hparams_path"], ["@", "classmethod", "\n", "def", "set_project_directory", "(", "cls", ",", "project_directory", ",", "assert_project_dir", "=", "False", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "project_directory", ")", ":", "\n", "            ", "raise", "OSError", "(", "f\"Project directory at path '{project_directory}' does not exist.\"", ")", "\n", "", "project_directory", "=", "os", ".", "path", ".", "abspath", "(", "project_directory", ")", "\n", "cls", ".", "PROJECT_DIRECTORY", "=", "project_directory", "\n", "# Check if initialized by looking for hyperparameter file(s)", "\n", "is_init", "=", "(", "os", ".", "path", ".", "exists", "(", "cls", ".", "get_hparams_path", "(", "project_directory", ")", ")", "or", "\n", "os", ".", "path", ".", "exists", "(", "cls", ".", "get_pre_processed_hparams_path", "(", "project_directory", ")", ")", ")", "\n", "if", "assert_project_dir", "and", "not", "is_init", ":", "\n", "            ", "raise", "OSError", "(", "f\"Project directory at path '{project_directory}' does not appear to be a valid \"", "\n", "f\"{cls.PACKAGE_NAME} project dir as it is missing one or more expected \"", "\n", "f\"sub-folders or files (e.g., a {cls.HPARAMS_DIR} sub-dir).\"", ")", "\n", "", "logger", ".", "info", "(", "f\"Project directory set: {project_directory} (initialized project: {is_init})\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_logging_path": [[48, 54], ["os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_logging_path", "(", "cls", ",", "log_file_name", "=", "None", ",", "log_dir", "=", "None", ")", ":", "\n", "        ", "if", "log_dir", "and", "cls", ".", "LOG_DIR", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "log_dir", "or", "cls", ".", "LOG_DIR", ",", "log_file_name", "or", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.init_package_level_loggers": [[55, 71], ["logging.StreamHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "map", "package_logger.setLevel", "package_logger.addHandler", "cls.PACKAGE_LEVEL_LOGGERS.append"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "init_package_level_loggers", "(", "cls", ",", "\n", "level", ",", "\n", "package_names", "=", "None", ",", "\n", "format", "=", "'%(levelname)s | %(asctime)s | %(module)s:%(funcName)s:%(lineno)d | %(message)s'", ",", "\n", "datefmt", "=", "\"%Y/%m/%d %H:%M:%S\"", ",", "\n", "stream", "=", "sys", ".", "stdout", ")", ":", "\n", "        ", "handler", "=", "logging", ".", "StreamHandler", "(", "stream", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "format", ",", "datefmt", "=", "datefmt", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "# Set handler and log level on all passed package-level loggers or on the utime packe logger only by default", "\n", "cls", ".", "PACKAGE_LEVEL_LOGGERS", "=", "[", "]", "\n", "for", "package_logger", "in", "map", "(", "logging", ".", "getLogger", ",", "package_names", "or", "[", "cls", ".", "PACKAGE_NAME", "]", ")", ":", "\n", "            ", "package_logger", ".", "setLevel", "(", "level", ")", "\n", "package_logger", ".", "addHandler", "(", "handler", ")", "\n", "cls", ".", "PACKAGE_LEVEL_LOGGERS", ".", "append", "(", "package_logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_logging_file_handler": [[72, 97], ["cls.get_logging_path", "os.path.exists", "logging.getLogger", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "ValueError", "os.path.split", "os.path.exists", "logger.info", "os.makedirs", "passed_logger.addHandler", "os.remove", "logging.getLogger", "OSError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_logging_path"], ["", "", "@", "classmethod", "\n", "def", "set_logging_file_handler", "(", "cls", ",", "file_name", ",", "loggers", "=", "None", ",", "mode", "=", "\"w\"", ",", "log_dir", "=", "None", ",", "overwrite_existing", "=", "False", ")", ":", "\n", "        ", "if", "loggers", "is", "None", ":", "\n", "            ", "loggers", "=", "cls", ".", "PACKAGE_LEVEL_LOGGERS", "or", "[", "logging", ".", "getLogger", "(", "cls", ".", "PACKAGE_NAME", ")", "]", "\n", "", "path", "=", "cls", ".", "get_logging_path", "(", "file_name", ",", "log_dir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "if", "overwrite_existing", ":", "\n", "                ", "os", ".", "remove", "(", "path", ")", "\n", "", "elif", "\"a\"", "not", "in", "mode", ":", "\n", "                ", "raise", "OSError", "(", "f\"Logging path {path} already exists and 'overwrite_existing' argument is set False. \"", "\n", "f\"If using the utime scripts, set the --overwrite flag to overwrite or use the \"", "\n", "f\"--log_dir and/or --log_file flag(s) to specify a different logging path.\"", ")", "\n", "", "", "if", "path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Attribute 'LOG_DIR' on Defaults object has not yet been set.\"", ")", "\n", "", "folder", "=", "os", ".", "path", ".", "split", "(", "path", ")", "[", "0", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "            ", "global", "logger", "\n", "logger", ".", "info", "(", "f\"Creating logging directory at path: {folder}\"", ")", "\n", "os", ".", "makedirs", "(", "folder", ")", "\n", "", "top_level_logger", "=", "logging", ".", "getLogger", "(", "cls", ".", "PACKAGE_NAME", ")", "\n", "file_handler", "=", "logging", ".", "FileHandler", "(", "path", ",", "mode", "=", "mode", ")", "\n", "file_handler", ".", "setLevel", "(", "top_level_logger", ".", "level", ")", "\n", "file_handler", ".", "setFormatter", "(", "top_level_logger", ".", "handlers", "[", "0", "]", ".", "formatter", ")", "\n", "for", "passed_logger", "in", "loggers", ":", "\n", "            ", "passed_logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_global_seed": [[98, 108], ["int", "logger.info", "tf.random.set_seed", "np.random.seed", "random.seed"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed"], ["", "", "@", "classmethod", "\n", "def", "set_global_seed", "(", "cls", ",", "seed", ")", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "import", "numpy", "as", "np", "\n", "import", "random", "\n", "cls", ".", "GLOBAL_SEED", "=", "int", "(", "seed", ")", "\n", "logger", ".", "info", "(", "f\"Seeding TensorFlow, numpy and random modules with seed: {cls.GLOBAL_SEED}\"", ")", "\n", "tf", ".", "random", ".", "set_seed", "(", "cls", ".", "GLOBAL_SEED", ")", "\n", "np", ".", "random", ".", "seed", "(", "cls", ".", "GLOBAL_SEED", ")", "\n", "random", ".", "seed", "(", "cls", ".", "GLOBAL_SEED", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_dir": [[109, 112], ["os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_hparams_dir", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "project_dir", "or", "cls", ".", "PROJECT_DIRECTORY", ",", "cls", ".", "HPARAMS_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path": [[113, 116], ["os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_hparams_path", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "project_dir", "or", "cls", ".", "PROJECT_DIRECTORY", ",", "cls", ".", "HPARAMS_DIR", ",", "cls", ".", "HPARAMS_NAME", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_model_dir": [[117, 120], ["os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_model_dir", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "project_dir", "or", "cls", ".", "PROJECT_DIRECTORY", ",", "cls", ".", "MODEL_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_hparams_path": [[121, 125], ["os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_pre_processed_hparams_path", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "project_dir", "or", "cls", ".", "PROJECT_DIRECTORY", ",", "cls", ".", "HPARAMS_DIR", ",", "\n", "cls", ".", "PRE_PROCESSED_HPARAMS_NAME", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_dataset_configurations_dir": [[126, 130], ["os.path.join", "cls.get_hparams_dir"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_dir"], ["", "@", "classmethod", "\n", "def", "get_dataset_configurations_dir", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "cls", ".", "get_hparams_dir", "(", "project_dir", ")", ",", "\n", "cls", ".", "DATASET_CONF_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_data_configurations_dir": [[131, 135], ["os.path.join", "cls.get_dataset_configurations_dir"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_dataset_configurations_dir"], ["", "@", "classmethod", "\n", "def", "get_pre_processed_data_configurations_dir", "(", "cls", ",", "project_dir", "=", "None", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "cls", ".", "get_dataset_configurations_dir", "(", "project_dir", ")", ",", "\n", "cls", ".", "PRE_PROCESSED_DATA_CONF_DIR", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.plotting.plot_all_training_curves": [[11, 25], ["glob.glob", "OSError", "os.path.split", "plotting.plot_training_curves", "len", "os.path.join", "os.path.splitext", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.plotting.plot_training_curves"], ["def", "plot_all_training_curves", "(", "glob_path", ",", "out_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "paths", "=", "glob", "(", "glob_path", ")", "\n", "if", "not", "paths", ":", "\n", "        ", "raise", "OSError", "(", "f\"File pattern {glob_path} gave no matches matches '({paths})'\"", ")", "\n", "", "out_folder", "=", "os", ".", "path", ".", "split", "(", "out_path", ")", "[", "0", "]", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "len", "(", "paths", ")", ">", "1", ":", "\n", "# Set unique names", "\n", "            ", "uniq", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "p", ")", "[", "-", "1", "]", ")", "[", "0", "]", "\n", "f_name", "=", "uniq", "+", "\"_\"", "+", "os", ".", "path", ".", "split", "(", "out_path", ")", "[", "-", "1", "]", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "out_folder", ",", "f_name", ")", "\n", "", "else", ":", "\n", "            ", "save_path", "=", "out_path", "\n", "", "plot_training_curves", "(", "p", ",", "save_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.plotting.plot_training_curves": [[27, 101], ["pandas.read_csv", "matplotlib.figure", "plt.figure.add_subplot", "pd.read_csv.get", "fig.add_subplot.plot", "fig.add_subplot.legend", "ax2.legend.get_frame().set_linewidth", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "plt.figure.add_subplot", "re.compile", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "pd.read_csv.get", "plt.figure.tight_layout", "plt.figure.savefig", "matplotlib.close", "numpy.log10", "fig.add_subplot.plot", "fig.add_subplot.legend", "ax2.legend.get_frame().set_linewidth", "pd.read_csv.get", "plt.figure.add_subplot", "fig.add_subplot.step", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "numpy.log10", "ax2.legend.get_frame", "any", "re.match", "fig.add_subplot.plot", "int", "ax2.legend.get_frame", "numpy.ceil"], "function", ["None"], ["", "", "def", "plot_training_curves", "(", "csv_path", ",", "save_path", ",", "logy", "=", "False", ",", "\n", "exclude", "=", "(", "\"learning_rate\"", ",", "\"epoch\"", ",", "\"loss\"", ",", "\n", "\"epoch_minutes\"", ",", "\"train_hours\"", ",", "\n", "'memory_usage_gib'", ")", ",", "\n", "include_regex", "=", "None", ")", ":", "\n", "# Read CSV file", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "# Prepare plot", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "12", ")", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "311", ")", "\n", "\n", "# Get epoch, training and validation loss vectors", "\n", "epochs", "=", "df", "[", "\"epoch\"", "]", "+", "1", "\n", "train_loss", "=", "df", "[", "\"loss\"", "]", "\n", "val_loss", "=", "df", ".", "get", "(", "\"val_loss\"", ")", "\n", "\n", "if", "logy", ":", "\n", "        ", "train_loss", "=", "np", ".", "log10", "(", "train_loss", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "            ", "val_loss", "=", "np", ".", "log10", "(", "val_loss", ")", "\n", "\n", "# Plot", "\n", "", "", "ax1", ".", "plot", "(", "epochs", ",", "train_loss", ",", "lw", "=", "3", ",", "color", "=", "\"darkblue\"", ",", "label", "=", "\"Training loss\"", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "        ", "ax1", ".", "plot", "(", "epochs", ",", "val_loss", ",", "lw", "=", "3", ",", "color", "=", "\"darkred\"", ",", "label", "=", "\"Validation loss\"", ")", "\n", "\n", "# Add legend, labels and title", "\n", "", "leg", "=", "ax1", ".", "legend", "(", "loc", "=", "0", ")", "\n", "leg", ".", "get_frame", "(", ")", ".", "set_linewidth", "(", "0", ")", "\n", "ax1", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax1", ".", "set_ylabel", "(", "\"Loss\"", "if", "not", "logy", "else", "\"$\\log_{10}$(Loss)\"", ",", "size", "=", "16", ")", "\n", "ax1", ".", "set_title", "(", "\"Training %sloss\"", "%", "(", "\"and validation \"", "if", "val_loss", "is", "not", "None", "else", "\"\"", ")", ",", "size", "=", "20", ")", "\n", "\n", "# Make second plot", "\n", "ax2", "=", "fig", ".", "add_subplot", "(", "312", ")", "\n", "\n", "# Get all other columns, optionally only if matching 'include_regex'", "\n", "import", "re", "\n", "include_regex", "=", "re", ".", "compile", "(", "include_regex", "or", "\".*\"", ")", "\n", "\n", "plotted", "=", "0", "\n", "for", "col", "in", "df", ".", "columns", ":", "\n", "        ", "if", "any", "(", "[", "s", "in", "col", "for", "s", "in", "exclude", "[", "1", ":", "]", "]", ")", "or", "col", "==", "\"lr\"", ":", "\n", "            ", "continue", "\n", "", "elif", "not", "re", ".", "match", "(", "include_regex", ",", "col", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "plotted", "+=", "1", "\n", "ax2", ".", "plot", "(", "epochs", ",", "df", "[", "col", "]", ",", "label", "=", "col", ",", "lw", "=", "2", ")", "\n", "\n", "# Add legend, labels and title", "\n", "", "", "if", "plotted", "<=", "8", ":", "\n", "# Otherwise it takes up all the space", "\n", "        ", "leg", "=", "ax2", ".", "legend", "(", "loc", "=", "0", ",", "ncol", "=", "int", "(", "np", ".", "ceil", "(", "plotted", "/", "5", ")", ")", ")", "\n", "leg", ".", "get_frame", "(", ")", ".", "set_linewidth", "(", "0", ")", "\n", "", "ax2", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax2", ".", "set_ylabel", "(", "\"Metric\"", ",", "size", "=", "16", ")", "\n", "ax2", ".", "set_title", "(", "\"Training and validation metrics\"", ",", "size", "=", "20", ")", "\n", "\n", "# Plot learning rate", "\n", "lr", "=", "df", ".", "get", "(", "\"lr\"", ")", "\n", "if", "lr", "is", "None", ":", "\n", "        ", "lr", "=", "df", ".", "get", "(", "\"learning_rate\"", ")", "\n", "", "if", "lr", "is", "not", "None", ":", "\n", "        ", "ax3", "=", "fig", ".", "add_subplot", "(", "313", ")", "\n", "ax3", ".", "step", "(", "epochs", ",", "lr", ")", "\n", "ax3", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax3", ".", "set_ylabel", "(", "\"Learning Rate\"", ",", "size", "=", "16", ")", "\n", "ax3", ".", "set_title", "(", "\"Learning Rate\"", ",", "size", "=", "20", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "save_path", ")", "\n", "plt", ".", "close", "(", "fig", ".", "number", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_system_wide_set_gpus": [[11, 16], ["os.environ.get", "allowed_gpus.replace().split.replace().split", "allowed_gpus.replace().split.replace"], "function", ["None"], ["def", "_get_system_wide_set_gpus", "(", ")", ":", "\n", "    ", "allowed_gpus", "=", "os", ".", "environ", ".", "get", "(", "\"CUDA_VISIBLE_DEVICES\"", ")", "\n", "if", "allowed_gpus", ":", "\n", "        ", "allowed_gpus", "=", "allowed_gpus", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "", "return", "allowed_gpus", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.gpu_string_to_list": [[18, 23], ["re.findall", "str", "list", "map"], "function", ["None"], ["", "def", "gpu_string_to_list", "(", "gpu_visibility_string", ",", "as_int", "=", "False", ")", ":", "\n", "    ", "gpus", "=", "re", ".", "findall", "(", "r\"(\\d+)\"", ",", "str", "(", "gpu_visibility_string", ")", ")", "\n", "if", "as_int", ":", "\n", "        ", "gpus", "=", "list", "(", "map", "(", "int", ",", "gpus", ")", ")", "\n", "", "return", "gpus", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.get_free_gpus": [[25, 53], ["system._get_system_wide_set_gpus", "logger.info", "subprocess.check_output", "numpy.array", "subprocess.check_output", "re.findall", "list", "list", "re.findall", "len", "len", "map", "FileNotFoundError", "int"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_system_wide_set_gpus"], ["", "def", "get_free_gpus", "(", "max_allowed_mem_usage", "=", "400", ")", ":", "\n", "# Check if allowed GPUs are set in CUDA_VIS_DEV.", "\n", "    ", "allowed_gpus", "=", "_get_system_wide_set_gpus", "(", ")", "\n", "if", "allowed_gpus", ":", "\n", "        ", "logger", ".", "info", "(", "f\"[OBS] Considering only system-wise allowed GPUs: {allowed_gpus} (set in\"", "\n", "f\" CUDA_VISIBLE_DEVICES env variable).\"", ")", "\n", "return", "allowed_gpus", "\n", "# Else, check GPUs on the system and assume all non-used (mem. use less", "\n", "# than max_allowed_mem_usage) is fair game.", "\n", "", "try", ":", "\n", "# Get list of GPUs", "\n", "        ", "gpu_list", "=", "check_output", "(", "[", "\"nvidia-smi\"", ",", "\"-L\"", "]", ",", "universal_newlines", "=", "True", ")", "\n", "gpu_ids", "=", "np", ".", "array", "(", "re", ".", "findall", "(", "r\"GPU[ ]+(\\d+)\"", ",", "gpu_list", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "# Query memory usage stats from nvidia-smi", "\n", "output", "=", "check_output", "(", "[", "\"nvidia-smi\"", ",", "\"-q\"", ",", "\"-d\"", ",", "\"MEMORY\"", "]", ",", "universal_newlines", "=", "True", ")", "\n", "\n", "# Fetch the memory usage of each GPU", "\n", "mem_usage", "=", "re", ".", "findall", "(", "r\"FB Memory Usage.*?Used[ ]+:[ ]+(\\d+)\"", ",", "\n", "output", ",", "flags", "=", "re", ".", "DOTALL", ")", "\n", "assert", "len", "(", "gpu_ids", ")", "==", "len", "(", "mem_usage", ")", "\n", "\n", "# Return all GPU ids for which the memory usage is below or eq. to max allowed", "\n", "free", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", "<=", "max_allowed_mem_usage", "or", "0", ",", "mem_usage", ")", ")", "\n", "return", "list", "(", "gpu_ids", "[", "free", "]", ")", "\n", "", "except", "FileNotFoundError", "as", "e", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"[ERROR] nvidia-smi is not installed. \"", "\n", "\"Consider setting the --num_gpus=0 flag.\"", ")", "from", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_gpu_visibility_string": [[55, 58], ["map"], "function", ["None"], ["", "", "def", "_get_gpu_visibility_string", "(", "free_gpus", ":", "list", ",", "num_gpus", "=", "1", ")", ":", "\n", "    ", "visibility_string", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "free_gpus", "[", ":", "num_gpus", "]", ")", ")", "\n", "return", "visibility_string", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_free_gpus_visibility_string": [[60, 67], ["system.get_free_gpus", "system._get_gpu_visibility_string", "ResourceWarning", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.get_free_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_gpu_visibility_string"], ["", "def", "_get_free_gpus_visibility_string", "(", "num_gpus", "=", "1", ",", "max_allowed_mem_usage", "=", "400", ")", ":", "\n", "    ", "free", "=", "get_free_gpus", "(", "max_allowed_mem_usage", ")", "\n", "if", "not", "free", "or", "num_gpus", ">", "len", "(", "free", ")", ":", "\n", "        ", "raise", "ResourceWarning", "(", "f\"Requested N={num_gpus} GPUs, but only found {len(free)} GPUs available with memory \"", "\n", "f\"loads less than or equal to {max_allowed_mem_usage} MiB \"", "\n", "f\"('None' signals no memory requirement)\"", ")", "\n", "", "return", "_get_gpu_visibility_string", "(", "free", ",", "num_gpus", "=", "num_gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.get_visible_gpus": [[69, 75], ["os.environ[].strip", "list", "filter", "map", "os.environ[].strip.split", "s.strip"], "function", ["None"], ["", "def", "get_visible_gpus", "(", "as_list", "=", "True", ")", ":", "\n", "    ", "gpu_vis_string", "=", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", ".", "strip", "(", "\", \"", ")", "\n", "if", "as_list", ":", "\n", "        ", "return", "list", "(", "filter", "(", "None", ",", "map", "(", "lambda", "s", ":", "s", ".", "strip", "(", ")", ",", "gpu_vis_string", ".", "split", "(", "\",\"", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "gpu_vis_string", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.set_gpu": [[77, 81], ["logger.info", "system.gpu_string_to_list"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.gpu_string_to_list"], ["", "", "def", "set_gpu", "(", "gpu_visibility_string", ":", "str", ")", ":", "\n", "    ", "gpu_visibility_string", "=", "\",\"", ".", "join", "(", "gpu_string_to_list", "(", "gpu_visibility_string", ")", ")", "\n", "logger", ".", "info", "(", "f\"Setting CUDA_VISIBLE_DEVICES = '{gpu_visibility_string}'\"", ")", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "gpu_visibility_string", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.await_and_set_free_gpu": [[83, 101], ["system.set_gpu", "logger.info", "OSError", "system._get_free_gpus_visibility_string", "logger.warning", "logger.warning", "time.sleep", "str"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.set_gpu", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system._get_free_gpus_visibility_string"], ["", "def", "await_and_set_free_gpu", "(", "num_gpus", "=", "1", ",", "sleep_seconds", "=", "60", ",", "max_allowed_mem_usage", "=", "400", ",", "timeout_seconds", "=", "3600", ")", ":", "\n", "    ", "gpu_vis_string", "=", "\"\"", "\n", "wait_seconds", "=", "0", "\n", "if", "num_gpus", ">", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Waiting for free N={num_gpus} GPU(s)...\"", ")", "\n", "while", "not", "gpu_vis_string", ":", "\n", "            ", "if", "wait_seconds", ">=", "timeout_seconds", ":", "\n", "                ", "raise", "OSError", "(", "f\"Could not find {num_gpus} with max allowed memory usage \"", "\n", "f\"of {max_allowed_mem_usage} MiB within timeout of {timeout_seconds} seconds.\"", ")", "\n", "", "try", ":", "\n", "                ", "gpu_vis_string", "=", "_get_free_gpus_visibility_string", "(", "num_gpus", ",", "max_allowed_mem_usage", ")", "\n", "", "except", "ResourceWarning", "as", "e", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Not enough available GPUs. Original warning: {str(e)}\"", ")", "\n", "logger", ".", "warning", "(", "f\"No available GPUs... Sleeping {sleep_seconds}s \"", "\n", "f\"(current wait time is {wait_seconds}s. Timeout is {timeout_seconds}s).\"", ")", "\n", "sleep", "(", "sleep_seconds", ")", "\n", "wait_seconds", "+=", "sleep_seconds", "\n", "", "", "", "set_gpu", "(", "gpu_vis_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.find_and_set_gpus": [[103, 127], ["len", "ValueError", "system.await_and_set_free_gpu", "system.set_gpu", "system.get_visible_gpus"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.await_and_set_free_gpu", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.set_gpu", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.get_visible_gpus"], ["", "def", "find_and_set_gpus", "(", "num_gpus", "=", "None", ",", "force_gpus", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Utility function to either look for free GPUs and set them visible,\n    or set a forced set of GPUs visible.\n\n    Specifically, if force_gpus is specified, set the visibility accordingly,\n    count the number of GPUs set and return this number.\n    If not, use num_gpus currently available GPUs\n\n    Args:\n        num_gpus:  (int)        Number of free/available GPUs to automatically\n                                select using 'gpu_mon' when 'force_GPU' is not set.\n        force_gpus: (string)    A CUDA_VISIBLE_DEVICES type string to be set\n\n    Returns:\n        (int) The number of GPUs now visible\n    \"\"\"", "\n", "if", "num_gpus", "is", "None", "and", "force_gpus", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must specify at least one of 'num_gpus' and 'force_gpus'\"", ")", "\n", "", "if", "not", "force_gpus", ":", "\n", "        ", "await_and_set_free_gpu", "(", "num_gpus", ")", "\n", "", "else", ":", "\n", "        ", "set_gpu", "(", "force_gpus", ")", "\n", "", "return", "len", "(", "get_visible_gpus", "(", "as_list", "=", "True", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.expand_to_dim": [[7, 18], ["isinstance", "expanded.append", "isinstance", "list", "len", "numpy.array"], "function", ["None"], ["def", "expand_to_dim", "(", "values", ",", "dim", ")", ":", "\n", "    ", "expanded", "=", "[", "]", "\n", "for", "v", "in", "values", ":", "\n", "        ", "if", "not", "isinstance", "(", "v", ",", "(", "tuple", ",", "list", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "v", "=", "[", "v", "]", "\n", "", "if", "isinstance", "(", "v", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "v", "=", "list", "(", "v", ")", "\n", "", "if", "len", "(", "v", ")", "!=", "dim", ":", "\n", "            ", "v", "*=", "dim", "\n", "", "expanded", ".", "append", "(", "np", ".", "array", "(", "v", ")", ")", "\n", "", "return", "expanded", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_features": [[20, 28], ["conv_arithmetics.expand_to_dim", "numpy.floor().astype", "numpy.floor"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.expand_to_dim"], ["", "def", "output_features", "(", "in_filter_size", ",", "padding", ",", "kernel_size", ",", "stride", "=", "1", ",", "dim", "=", "2", ")", ":", "\n", "    ", "in_filter_size", ",", "padding", ",", "kernel_size", ",", "stride", "=", "expand_to_dim", "(", "[", "in_filter_size", ",", "\n", "padding", ",", "\n", "kernel_size", ",", "\n", "stride", "]", ",", "\n", "dim", "=", "dim", ")", "\n", "\n", "return", "np", ".", "floor", "(", "(", "in_filter_size", "+", "(", "2", "*", "padding", ")", "-", "kernel_size", ")", "/", "stride", ")", ".", "astype", "(", "np", ".", "int", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_feature_distance": [[30, 34], ["conv_arithmetics.expand_to_dim"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.expand_to_dim"], ["", "def", "output_feature_distance", "(", "input_feature_distance", ",", "stride", ",", "dim", "=", "2", ")", ":", "\n", "    ", "input_feature_distance", ",", "stride", "=", "expand_to_dim", "(", "[", "input_feature_distance", ",", "\n", "stride", "]", ",", "dim", "=", "dim", ")", "\n", "return", "input_feature_distance", "*", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_receptive_field": [[36, 44], ["conv_arithmetics.expand_to_dim"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.expand_to_dim"], ["", "def", "output_receptive_field", "(", "input_receptive_field", ",", "kernel_size", ",", "\n", "input_feature_distacne", ",", "dim", "=", "2", ")", ":", "\n", "    ", "input_receptive_field", ",", "kernel_size", ",", "input_feature_distacne", "=", "expand_to_dim", "(", "[", "input_receptive_field", ",", "\n", "kernel_size", ",", "\n", "input_feature_distacne", "]", ",", "\n", "dim", "=", "dim", ")", "\n", "return", "input_receptive_field", "+", "(", "kernel_size", "-", "1", ")", "*", "input_feature_distacne", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_first_feature_center": [[46, 57], ["conv_arithmetics.expand_to_dim"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.expand_to_dim"], ["", "def", "output_first_feature_center", "(", "input_first_feature_center", ",", "kernel_size", ",", "\n", "padding", ",", "input_feature_distance", ",", "dim", "=", "2", ")", ":", "\n", "    ", "input_first_feature_center", ",", "kernel_size", ",", "padding", ",", "input_feature_distance", "=", "expand_to_dim", "(", "[", "input_first_feature_center", ",", "\n", "kernel_size", ",", "padding", ",", "\n", "input_feature_distance", "]", ",", "\n", "dim", "=", "dim", ")", "\n", "\n", "return", "input_first_feature_center", "+", "(", "(", "kernel_size", "-", "1", ")", "/", "2", "-", "padding", ")", "*", "input_feature_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.compute_receptive_fields": [[59, 120], ["len", "enumerate", "input_.input.get_shape().as_list", "numpy.array", "hasattr", "numpy.where", "numpy.array", "conv_arithmetics.output_feature_distance", "conv_arithmetics.output_receptive_field", "values.append", "numpy.array().astype", "numpy.array", "logger.info", "input_.input.get_shape", "numpy.ones", "layer.output.get_shape().as_list", "numpy.array", "dilation[].argmax", "tuple", "layer.output.get_shape", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_feature_distance", "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.output_receptive_field"], ["", "def", "compute_receptive_fields", "(", "layers", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "input_", "=", "layers", "[", "0", "]", "\n", "layers", "=", "layers", "[", "1", ":", "]", "\n", "size", "=", "input_", ".", "input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "dim", "=", "len", "(", "size", ")", "\n", "\n", "# Set first layer parameters", "\n", "receptive_field", "=", "1", "\n", "jump", "=", "1", "\n", "\n", "# Loop over all layers", "\n", "values", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "layers", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "kernel_size", "=", "layer", ".", "kernel_size", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "            ", "try", ":", "\n", "# Pooling layer?", "\n", "                ", "kernel_size", "=", "layer", ".", "pool_size", "\n", "", "except", "AttributeError", ":", "\n", "# Batch norm, flatten etc.", "\n", "                ", "continue", "\n", "", "", "kernel_size", "=", "np", ".", "array", "(", "kernel_size", ")", "\n", "\n", "# Get potential dilation rates", "\n", "try", ":", "\n", "            ", "dilation", "=", "np", ".", "array", "(", "layer", ".", "dilation_rate", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "dilation", "=", "np", ".", "ones", "(", "shape", "=", "[", "dim", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "", "if", "hasattr", "(", "layer", ",", "\"dilations\"", ")", ":", "\n", "            ", "assert", "(", "dilation", "==", "1", ")", ".", "all", "(", ")", "\n", "dilation", "=", "np", ".", "array", "(", "layer", ".", "dilations", ")", "\n", "dilation", "=", "dilation", "[", "dilation", "[", ":", ",", "0", "]", ".", "argmax", "(", ")", "]", "\n", "\n", "# Get strides", "\n", "", "stride", "=", "layer", ".", "strides", "\n", "\n", "# Get kernel size taking into account dilation rate", "\n", "ks", "=", "kernel_size", "*", "dilation", "\n", "m", "=", "np", ".", "where", "(", "dilation", ">", "1", ")", "\n", "ks", "[", "m", "]", "-=", "(", "dilation", "[", "m", "]", "-", "1", ")", "\n", "\n", "size", "=", "np", ".", "array", "(", "layer", ".", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "jump", "=", "output_feature_distance", "(", "jump", ",", "stride", ",", "dim", ")", "\n", "receptive_field", "=", "output_receptive_field", "(", "receptive_field", ",", "ks", ",", "jump", ",", "dim", ")", "\n", "\n", "# Add to list", "\n", "values", ".", "append", "(", "(", "size", ",", "jump", ",", "receptive_field", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "s", "=", "\"\\nLayer %i %s(kernel_size=%s, stride=%s, dilation=%s)\"", "%", "(", "i", "+", "1", ",", "layer", ".", "__class__", ".", "__name__", ",", "kernel_size", ",", "\n", "stride", ",", "tuple", "(", "dilation", ")", ")", "\n", "logger", ".", "info", "(", "f\"{s}\\n\"", "\n", "f\"{'-' * (len(s) - 1)}\\n\"", "\n", "\"Num feature:\"", ".", "ljust", "(", "25", ")", "+", "f\"{size}\\n\"", "+", "\n", "\"Feature distance:\"", ".", "ljust", "(", "25", ")", "+", "f\"{jump}\\n\"", "+", "\n", "\"Receptive field:\"", ".", "ljust", "(", "25", ")", "+", "f\"{receptive_field}\"", "\n", ")", "\n", "\n", "", "", "return", "values", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.create_folders": [[10, 28], ["isinstance", "list", "make_func", "os.path.exists", "utils.create_folders.safe_make"], "function", ["None"], ["def", "create_folders", "(", "folders", ",", "create_deep", "=", "False", ")", ":", "\n", "    ", "def", "safe_make", "(", "path", ",", "make_func", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "make_func", "(", "path", ")", "\n", "", "except", "FileExistsError", ":", "\n", "# If running many jobs in parallel this may occur", "\n", "            ", "pass", "\n", "", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f", ")", ":", "\n", "                ", "safe_make", "(", "f", ",", "make_func", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.flatten_lists_recursively": [[30, 36], ["isinstance", "isinstance", "utils.flatten_lists_recursively"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.flatten_lists_recursively"], ["", "", "", "", "def", "flatten_lists_recursively", "(", "list_of_lists", ")", ":", "\n", "    ", "for", "list_", "in", "list_of_lists", ":", "\n", "        ", "if", "isinstance", "(", "list_", ",", "Iterable", ")", "and", "not", "isinstance", "(", "list_", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.highlighted": [[38, 42], ["len", "max", "len", "string.split"], "function", ["None"], ["", "", "", "def", "highlighted", "(", "string", ")", ":", "\n", "    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.await_pids": [[44, 50], ["isinstance", "pids.split", "utils.wait_for", "utils.wait_for", "int"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.wait_for", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.wait_for"], ["", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "if", "isinstance", "(", "pids", ",", "str", ")", ":", "\n", "        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.wait_for": [[52, 65], ["utils._wait_for", "isinstance", "int", "ValueError"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils._wait_for"], ["", "", "def", "wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n", "if", "not", "pid", ":", "\n", "        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pid", "=", "int", "(", "pid", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n", "", "", "_wait_for", "(", "pid", ",", "check_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils._wait_for": [[67, 81], ["logging.info", "subprocess.Popen", "subprocess.Popen.wait", "bool", "subprocess.check_output", "logging.info", "time.sleep"], "function", ["None"], ["", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "still_running", "=", "True", "\n", "logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "try", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "(", "\"grep\"", ",", "f\"{pid}\"", ")", ",", "stdin", "=", "ps", ".", "stdout", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "output", "=", "False", "\n", "", "ps", ".", "wait", "(", ")", "\n", "still_running", "=", "bool", "(", "output", ")", "\n", "if", "still_running", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Process {pid} still running... (sleeping {check_every} seconds)\"", ")", "\n", "time", ".", "sleep", "(", "check_every", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler": [[16, 29], ["utime.Defaults.set_logging_file_handler", "logger.info", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_logging_file_handler"], ["def", "add_logging_file_handler", "(", "log_file_name", ",", "overwrite", ",", "logger_objects", "=", "None", ",", "log_dir", "=", "None", ",", "mode", "=", "\"w\"", ")", ":", "\n", "# Log to file if specified", "\n", "    ", "if", "log_file_name", ":", "\n", "        ", "Defaults", ".", "set_logging_file_handler", "(", "file_name", "=", "log_file_name", ",", "\n", "loggers", "=", "logger_objects", ",", "\n", "overwrite_existing", "=", "overwrite", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "        ", "relevant_loggers", "=", "logger_objects", "or", "Defaults", ".", "PACKAGE_LEVEL_LOGGERS", "or", "[", "logging", ".", "getLogger", "(", "Defaults", ".", "PACKAGE_NAME", ")", "]", "\n", "logger", ".", "info", "(", "f\"Logs will not be saved to file for these loggers: {relevant_loggers} (--log_file_name is empty)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.with_logging_level_wrapper": [[31, 44], ["functools.wraps", "func", "logging.getLogger", "logger.setLevel", "logger.setLevel", "logging.getLogger"], "function", ["None"], ["", "", "def", "with_logging_level_wrapper", "(", "func", ",", "level", ",", "logger_names", "=", "None", ")", ":", "\n", "    ", "loggers", "=", "[", "logging", ".", "getLogger", "(", "name", ")", "for", "name", "in", "logger_names", "]", "if", "logger_names", "else", "Defaults", ".", "PACKAGE_LEVEL_LOGGERS", "or", "[", "logging", ".", "getLogger", "(", "Defaults", ".", "PACKAGE_NAME", ")", "]", "\n", "old_levels", "=", "{", "logger", ":", "logger", ".", "level", "for", "logger", "in", "loggers", "}", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "with_logging_level", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "logger", "in", "loggers", ":", "\n", "            ", "logger", ".", "setLevel", "(", "level", ")", "\n", "", "outs", "=", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "logger", "in", "loggers", ":", "\n", "            ", "logger", ".", "setLevel", "(", "old_levels", "[", "logger", "]", ")", "\n", "", "return", "outs", "\n", "", "return", "with_logging_level", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder": [[46, 84], ["os.path.abspath", "os.path.join", "RuntimeError", "glob.glob", "os.path.exists", "bool", "os.path.exists", "os.path.exists", "os.path.exists", "RuntimeError", "os.path.join", "RuntimeError", "os.listdir", "utime.Defaults.get_hparams_path", "utime.Defaults.get_pre_processed_hparams_path"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_hparams_path"], ["", "def", "assert_project_folder", "(", "project_folder", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Raises RuntimeError if a folder 'project_folder' does not seem to be a\n    valid U-Time folder in the training phase (evaluation=False) or evaluation\n    phase (evaluation=True).\n\n    Args:\n        project_folder: A path to a folder to check for U-Time compat.\n        evaluation:     Should the folder adhere to train- or eval time checks.\n\n    Returns:\n        empty_models_dir: Bool, whether the project_folder/models dir is empty or not.\n    \"\"\"", "\n", "import", "os", "\n", "import", "glob", "\n", "project_folder", "=", "os", ".", "path", ".", "abspath", "(", "project_folder", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "Defaults", ".", "get_hparams_path", "(", "project_folder", ")", ")", "and", "not", "os", ".", "path", ".", "exists", "(", "Defaults", ".", "get_pre_processed_hparams_path", "(", "project_folder", ")", ")", ":", "\n", "# Folder must contain a 'hparams.yaml' file in all cases.", "\n", "        ", "raise", "RuntimeError", "(", "\"Folder {} is not a valid project folder.\"", "\n", "\" Must contain a hyperparameter \"", "\n", "\"file.\"", ".", "format", "(", "project_folder", ")", ")", "\n", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "project_folder", ",", "\"model\"", ")", "\n", "if", "evaluation", ":", "\n", "# Folder must contain a 'model' subfolder storing saved model files", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Folder {} is not a valid project \"", "\n", "\"folder for model evaluation. Must contain a 'model' \"", "\n", "\"subfolder.\"", ".", "format", "(", "project_folder", ")", ")", "\n", "# There must be a least 1 model file (.h5) in the folder", "\n", "", "models", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"*.h5\"", ")", ")", "\n", "if", "not", "models", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Did not find any model parameter files in \"", "\n", "\"model subfolder {}. Model files should have\"", "\n", "\" extension '.h5' to \"", "\n", "\"be recognized.\"", ".", "format", "(", "project_folder", ")", ")", "\n", "", "", "files_in_model_dir", "=", "os", ".", "path", ".", "exists", "(", "model_path", ")", "and", "bool", "(", "os", ".", "listdir", "(", "model_path", ")", ")", "\n", "return", "not", "files_in_model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_all_dataset_hparams": [[86, 133], ["hparams.get", "hparams[].items", "ValueError", "os.path.join", "YAMLHParams", "logger.warning", "utime.Defaults.get_hparams_dir"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_dir"], ["", "def", "get_all_dataset_hparams", "(", "hparams", ",", "project_dir", "=", "None", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Takes a YAMLHParams object and returns a dictionary of one or more entries\n    of dataset ID to YAMLHParams objects pairs; one for each dataset described\n    in 'hparams'.\n\n    If 'hparams' has the 'datasets' attribute each mentioned dataset under this\n    field will be loaded and returned. Otherwise, it is assumed that a single\n    dataset is described directly in 'hparams', in which case 'hparams' as-is\n    will be the only returned value (with no ID).\n\n    Args:\n        hparams: (YAMLHParams)    A hyperparameter object storing reference to\n                                  one or more datasets in the 'datasets' field, or\n                                  directly in 'hparams.\n        project_dir: [None, str]  Optional path to a project directory storing\n                                  hyperparameters relevant to the 'hparams' object.\n                                  If not specified, will use the Default.PROJECT_DIR\n                                  value which is set at runtime for all utime scripts.\n        dataset_ids (None, list)  Only returns hparams for datasets with IDs in 'dataset_ids'.\n                                  If None, return hparams for all datasets.\n\n    Returns:\n        A dictonary if dataset ID to YAMLHParams object pairs\n        One entry for each dataset\n    \"\"\"", "\n", "from", "utime", ".", "hyperparameters", "import", "YAMLHParams", "\n", "dataset_hparams", "=", "{", "}", "\n", "if", "hparams", ".", "get", "(", "\"datasets\"", ")", ":", "\n", "# Multiple datasets specified in hparams configuration files", "\n", "        ", "ids_and_paths", "=", "hparams", "[", "\"datasets\"", "]", ".", "items", "(", ")", "\n", "project_dir", "=", "project_dir", "or", "Defaults", ".", "PROJECT_DIRECTORY", "\n", "if", "not", "project_dir", ":", "\n", "            ", "raise", "ValueError", "(", "\"Must specify either the 'project_dir' argument or the \"", "\n", "\"Defaults.PROJECT_DIRECTORY property must have been set before calling \"", "\n", "\"this function (e.g., by invoking the utime entry script).\"", ")", "\n", "", "for", "id_", ",", "path", "in", "ids_and_paths", ":", "\n", "            ", "if", "dataset_ids", "and", "id_", "not", "in", "dataset_ids", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Ignoring dataset '{id_}' in hparams (not in 'dataset_ids' list).\"", ")", "\n", "continue", "\n", "", "yaml_path", "=", "os", ".", "path", ".", "join", "(", "Defaults", ".", "get_hparams_dir", "(", "project_dir", ")", ",", "path", ")", "\n", "dataset_hparams", "[", "id_", "]", "=", "YAMLHParams", "(", "yaml_path", ",", "\n", "no_version_control", "=", "True", ")", "\n", "", "", "else", ":", "\n", "# Return as-is with no ID", "\n", "        ", "dataset_hparams", "[", "\"\"", "]", "=", "hparams", "\n", "", "return", "dataset_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_splits_from_hparams": [[135, 173], ["hparams.get", "psg_utils.utils.ensure_list_or_tuple", "psg_utils.preprocessing.utils.select_sample_strip_scale_quality", "psg_utils.dataset.SleepStudyDataset", "datasets.append", "ValueError"], "function", ["None"], ["", "def", "get_dataset_splits_from_hparams", "(", "hparams", ",", "splits_to_load", ",", "id", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    Return all initialized and prepared (according to the prep. function of\n    'select_sample_strip_scale_quality') SleepStudyDataset objects as described\n    in a YAMLHparams object.\n\n    Args:\n        hparams:        A YAMLHparams object describing one or more datasets to\n                        load\n        splits_to_load: A string, list or tuple of strings giving the name of\n                        all (sub-)datasets to load according to their hparams\n                        descriptions. That is, 'load' could be ('TRAIN', 'VAL')\n                        to load the training and validation data.\n        id:             An optional id to prepend to the identifier of the\n                        dataset. For instance, with id 'ABC' and sub-dataset\n                        identifier 'TRAIN' the resulting dataset will have\n                        identifier 'ABC/TRAIN'.\n\n    Returns:\n        A list of initialized and prepared datasets according to hparams.\n    \"\"\"", "\n", "ann_dict", "=", "hparams", ".", "get", "(", "\"sleep_stage_annotations\"", ")", "\n", "datasets", "=", "[", "]", "\n", "for", "data_key", "in", "ensure_list_or_tuple", "(", "splits_to_load", ")", ":", "\n", "        ", "if", "data_key", "not", "in", "hparams", ":", "\n", "            ", "raise", "ValueError", "(", "\"Dataset with key '{}' does not exists in the \"", "\n", "\"hyperparameters file\"", ".", "format", "(", "data_key", ")", ")", "\n", "", "new_id", "=", "f\"{id}{'/' if id else ''}{hparams[data_key]['identifier']}\"", "\n", "hparams", "[", "data_key", "]", "[", "\"identifier\"", "]", "=", "new_id", "\n", "\n", "# Load either a standard SleepStudyDataset or from the SingleH5Dataset", "\n", "dataset", "=", "SleepStudyDataset", "(", "**", "hparams", "[", "data_key", "]", ",", "\n", "annotation_dict", "=", "ann_dict", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "# Apply transformations, scaler etc.", "\n", "", "select_sample_strip_scale_quality", "(", "*", "datasets", ",", "hparams", "=", "hparams", ")", "\n", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_splits_from_hparams_file": [[175, 188], ["YAMLHParams", "scriptutils.get_dataset_splits_from_hparams"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_splits_from_hparams"], ["", "def", "get_dataset_splits_from_hparams_file", "(", "hparams_path", ",", "splits_to_load", ",", "id", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    Loads one or more datasets according to hyperparameters described in yaml\n    file at path 'hparams_path'. Specifically, this functions creates a temp.\n    YAMLHparams object from the yaml file data and applies redirects to the\n    'get_dataset_splits_from_hparams' function.\n\n    Please refer to the docstring of 'get_dataset_splits_from_hparams' for\n    details.\n    \"\"\"", "\n", "from", "utime", ".", "hyperparameters", "import", "YAMLHParams", "\n", "hparams", "=", "YAMLHParams", "(", "hparams_path", ",", "no_version_control", "=", "True", ")", "\n", "return", "get_dataset_splits_from_hparams", "(", "hparams", ",", "splits_to_load", ",", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_splits_from_all_datasets": [[190, 229], ["scriptutils.get_all_dataset_hparams", "get_all_dataset_hparams.items", "scriptutils.get_dataset_splits_from_hparams"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_all_dataset_hparams", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_splits_from_hparams"], ["", "def", "get_splits_from_all_datasets", "(", "hparams", ",", "splits_to_load", ",", "return_data_hparams", "=", "False", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper around the 'get_dataset_splits_from_hparams_file' and\n    'get_dataset_splits_from_hparams' files loading all sub-datasets according\n    to 'splits_to_load from each dataset specified in the file.\n    The dataset is processed according to hparams in the prep. function\n    'select_sample_strip_scale_quality'.\n\n    I.e. if hparams refer to 2 different datasets, e.g. 'Sleep-EDF-153' and\n    'DCSM' and you want to load the training and validation data from each\n    of those you would pass load=('TRAIN', 'VAL') and the train/val pairs\n    of each dataset would be yielded one by one.\n\n    Please refer to 'get_dataset_splits_from_hparams' for details.\n\n    Args:\n        hparams:                  A YAMLHparams object storing references to one or more\n                                  datasets\n        splits_to_load:           A string, list or tuple of strings giving the name\n                                  of all sub-datasets to load according to their hparams\n                                  descriptions.\n        return_data_hparams:      TODO\n        dataset_ids (None, list)  Only returns hparams for datasets with IDs in 'dataset_ids'.\n                                  If None, return hparams for all datasets.\n\n    Returns:\n        Yields one or more splits of data from datasets as described by\n        'hparams'\n    \"\"\"", "\n", "data_hparams", "=", "get_all_dataset_hparams", "(", "hparams", ",", "dataset_ids", "=", "dataset_ids", ")", "\n", "for", "dataset_id", ",", "hparams", "in", "data_hparams", ".", "items", "(", ")", ":", "\n", "        ", "ds", "=", "get_dataset_splits_from_hparams", "(", "\n", "hparams", "=", "hparams", ",", "\n", "splits_to_load", "=", "splits_to_load", ",", "\n", "id", "=", "dataset_id", ")", "\n", "if", "return_data_hparams", ":", "\n", "            ", "yield", "ds", ",", "hparams", "\n", "", "else", ":", "\n", "            ", "yield", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_from_regex_pattern": [[231, 263], ["hparams.get", "os.path.split", "psg_utils.dataset.SleepStudyDataset", "psg_utils.preprocessing.utils.select_sample_strip_scale_quality", "hparams[].get", "os.path.abspath", "hparams.get", "hparams.get"], "function", ["None"], ["", "", "", "def", "get_dataset_from_regex_pattern", "(", "regex_pattern", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"\n    Initializes a SleepStudy dataset and applies prep. function\n    'select_sample_strip_scale_quality' from all subject folders that match\n    a regex statement.\n\n    Args:\n        regex_pattern: A string regex pattern used to match to all subject dirs\n                       to include in the dataset\n        hparams:       A YAMLHparams object to read settings from that should\n                       apply to the initialized dataset.\n\n    Returns:\n        A SleepStudy object with settings set as per 'hparams'\n    \"\"\"", "\n", "ann_dict", "=", "hparams", ".", "get", "(", "\"sleep_stage_annotations\"", ")", "\n", "if", "'prediction_params'", "in", "hparams", ":", "\n", "        ", "period_length_sec", "=", "hparams", "[", "'prediction_params'", "]", ".", "get", "(", "'period_length_sec'", ",", "None", ")", "\n", "pre_proc_params", "=", "hparams", "[", "'prediction_params'", "]", "\n", "", "else", ":", "\n", "        ", "period_length_sec", "=", "(", "hparams", ".", "get", "(", "\"train_data\"", ")", "or", "\n", "hparams", ".", "get", "(", "\"test_data\"", ")", ")", ".", "get", "(", "'period_length_sec'", ",", "None", ")", "\n", "pre_proc_params", "=", "hparams", "\n", "", "data_dir", ",", "pattern", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "regex_pattern", ")", ")", "\n", "ssd", "=", "SleepStudyDataset", "(", "folder_regex", "=", "pattern", ",", "\n", "data_dir", "=", "data_dir", ",", "\n", "period_length_sec", "=", "period_length_sec", ",", "\n", "annotation_dict", "=", "ann_dict", ")", "\n", "# Apply transformations, scaler etc.", "\n", "from", "utime", ".", "utils", ".", "scriptutils", "import", "select_sample_strip_scale_quality", "\n", "select_sample_strip_scale_quality", "(", "ssd", ",", "hparams", "=", "pre_proc_params", ")", "\n", "return", "ssd", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.predict_on_generator": [[11, 41], ["numpy.vstack", "next", "model.predict_on_batch", "pred.append", "pred_batch.argmax().reshape.argmax().reshape", "pred_batch.argmax().reshape.argmax"], "function", ["None"], ["def", "predict_on_generator", "(", "model", ",", "generator", ",", "argmax", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a tf.keras model and uses it to predict on all batches in a generator\n    Stacks the predictions over all batches on axis 0 (vstack)\n\n    Args:\n        model:      A tf.keras module instance. Should accept batches as output\n                    from 'generator'\n        generator:  A generator object yielding one or more batches of data to\n                    predict on\n        argmax:     Whether to return argmax values or model output values\n\n    Returns:\n        If argmax is true, returns integer predictions of shape [-1, 1].\n        Otherwise, returns floating values of shape [-1, n_classes]\n    \"\"\"", "\n", "pred", "=", "[", "]", "\n", "end_of_data", "=", "False", "\n", "while", "not", "end_of_data", ":", "\n", "        ", "try", ":", "\n", "            ", "X_batch", ",", "_", "=", "next", "(", "generator", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "end_of_data", "=", "True", "\n", "", "else", ":", "\n", "# Predict", "\n", "            ", "pred_batch", "=", "model", ".", "predict_on_batch", "(", "X_batch", ")", "\n", "if", "argmax", ":", "\n", "                ", "pred_batch", "=", "pred_batch", ".", "argmax", "(", "-", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "pred", ".", "append", "(", "pred_batch", ")", "\n", "", "", "return", "np", ".", "vstack", "(", "pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.predict_by_id": [[43, 63], ["sequencer.to_batch_generator", "predict.predict_on_generator"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.predict_on_generator"], ["", "def", "predict_by_id", "(", "model", ",", "sequencer", ",", "study_id", ",", "argmax", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a tf.keras model and predicts on all batches of data in a SleepStudy\n    object.\n\n    Args:\n        model:      A tf.keras model instance. Should accept batches of data\n                    as output by the 'sequence' Sequence object.\n        sequencer:  A Sequence object which stores at least the passed\n                    SleepStudy object of 'sleep_study'.\n        study_id:   The identifier string of a SleepStudy object in 'sequence'.\n        argmax:     See predict_on_generator docstring.\n\n    Returns:\n        Predictions of 'model' on all batches of data in a SleepStudy\n        Please refer to the 'predict_on_generator' docstring.\n    \"\"\"", "\n", "# Get generator", "\n", "gen", "=", "sequencer", ".", "to_batch_generator", "(", "study_id", "=", "study_id", ")", "\n", "return", "predict_on_generator", "(", "model", ",", "gen", ",", "argmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.sequence_predict_generator": [[65, 112], ["model.outputs[].get_shape().as_list", "numpy.zeros", "print", "model.outputs[].get_shape", "model.predict_on_batch", "pred.argmax.argmax", "model.outputs[].get_shape", "print", "batch_pred.reshape.reshape"], "function", ["None"], ["", "def", "sequence_predict_generator", "(", "model", ",", "total_seq_length", ",", "generator", ",", "\n", "argmax", "=", "False", ",", "overlapping", "=", "True", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Takes a tf.keras model and predicts on segments of data from a generator.\n    This function takes a few additional values needed to derive an\n    understanding of the data produced by 'generator', see below:\n\n    Args:\n        model:             A tf.keras model to predict with. Should accept data\n                           as output by the generator.\n        total_seq_length:  The total number of 'segments/epochs/stages' in the\n                           generator. This is needed to initialize the\n                           predictions array.\n        generator:         A generator which produces batches of data\n        argmax:            Whether to return argmax values or model output values\n        overlapping:       Specifies whether the sequences output of 'generator'\n                           represent overlapping segments or contagious data.\n        verbose:           If True, prints the prediction progess to screen.\n\n    Returns:\n        An array of shape [total_seq_length, n_classes] or\n        [total_seq_length, -1, n_classes] if data_per_prediction != input_dims.\n        If argmax = True axis -1 (now shape 1) is squeezed.\n    \"\"\"", "\n", "n_classes", "=", "model", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "s", "=", "model", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "pred", "=", "np", ".", "zeros", "(", "shape", "=", "[", "total_seq_length", "]", "+", "s", "[", "2", ":", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "cur_pos", "=", "0", "\n", "for", "X", ",", "_", ",", "_", "in", "generator", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"  pos: {}/{}\"", ".", "format", "(", "cur_pos", "+", "1", ",", "total_seq_length", ")", ",", "\n", "end", "=", "\"\\r\"", ",", "flush", "=", "True", ")", "\n", "", "batch_pred", "=", "model", ".", "predict_on_batch", "(", "X", ")", "\n", "if", "overlapping", ":", "\n", "            ", "for", "p", "in", "batch_pred", ":", "\n", "                ", "pred", "[", "cur_pos", ":", "cur_pos", "+", "p", ".", "shape", "[", "0", "]", "]", "+=", "p", "\n", "cur_pos", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "batch_pred", "=", "batch_pred", ".", "reshape", "(", "-", "1", ",", "n_classes", ")", "\n", "n_vals", "=", "batch_pred", ".", "shape", "[", "0", "]", "\n", "pred", "[", "cur_pos", ":", "cur_pos", "+", "n_vals", "]", "+=", "batch_pred", "\n", "cur_pos", "+=", "n_vals", "\n", "", "", "if", "argmax", ":", "\n", "        ", "pred", "=", "pred", ".", "argmax", "(", "-", "1", ")", "\n", "", "print", "(", ")", "\n", "return", "pred", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.remove_previous_session": [[19, 36], ["filter", "os.path.join", "os.path.isdir", "shutil.rmtree", "os.remove"], "function", ["None"], ["def", "remove_previous_session", "(", "project_folder", ")", ":", "\n", "    ", "\"\"\"\n    Deletes various utime project folders and files from\n    [project_folder].\n\n    Args:\n        project_folder: A path to a utime project folder\n    \"\"\"", "\n", "# Remove old files and directories of logs, images etc if existing", "\n", "paths", "=", "[", "os", ".", "path", ".", "join", "(", "project_folder", ",", "p", ")", "for", "p", "in", "(", "\"logs\"", ",", "\n", "\"model\"", ",", "\n", "\"tensorboard\"", ")", "]", "\n", "for", "p", "in", "filter", "(", "os", ".", "path", ".", "exists", ",", "paths", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "p", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "p", ")", "\n", "", "else", ":", "\n", "            ", "os", ".", "remove", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.init_default_project_structure": [[38, 42], ["os.path.join", "os.mkdir"], "function", ["None"], ["", "", "", "def", "init_default_project_structure", "(", "project_folder", ",", "required_folders", "=", "(", "'logs'", ",", "'model'", ")", ")", ":", "\n", "    ", "for", "folder", "in", "required_folders", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "join", "(", "project_folder", ",", "folder", ")", "\n", "os", ".", "mkdir", "(", "folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_train_and_val_datasets": [[44, 88], ["any", "logger.info", "zip", "ValueError", "utime.utils.scriptutils.get_splits_from_all_datasets", "ValueError", "train.merge_train_and_val", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_splits_from_all_datasets", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.merge_train_and_val"], ["", "", "def", "get_train_and_val_datasets", "(", "hparams", ",", "no_val", ",", "train_on_val", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return all pairs of (train, validation) SleepStudyDatasets as described in\n    the YAMLHParams object 'hparams'. A list is returned, as more than 1\n    dataset may be described in the parameter file.\n\n    Also returns an updated version of 'no_val', see below. Specifically, if\n    'train_on_val' is True, then no_val will be set to true no matter its\n    initial value.\n\n    Args:\n        hparams:      (YAMLHParams) A hyperparameter object to load dataset\n                                    configurations from.\n        no_val:       (bool)        Do not load validation data\n        train_on_val: (bool)        Load validation data, but merge it into\n                                    the training data. Then return only the\n                                    'trainin' (train+val) dataset.\n        dataset_ids (None, list)    Only load datasets with IDs in 'dataset_ids'.\n                                    If None, load all datasets.\n\n    Returns:\n        A list of training SleepStudyDataset objects\n        A list of validation SleepStudyDataset objects, or [] if not val.\n    \"\"\"", "\n", "if", "no_val", ":", "\n", "        ", "load", "=", "(", "\"train_data\"", ",", ")", "\n", "if", "train_on_val", ":", "\n", "            ", "raise", "ValueError", "(", "\"Should not specify --no_val with --train_on_val\"", ")", "\n", "", "", "else", ":", "\n", "        ", "load", "=", "(", "\"train_data\"", ",", "\"val_data\"", ")", "\n", "", "datasets", "=", "[", "*", "get_splits_from_all_datasets", "(", "hparams", ",", "load", ",", "dataset_ids", "=", "dataset_ids", ")", "]", "\n", "if", "train_on_val", ":", "\n", "        ", "if", "any", "(", "[", "len", "(", "ds", ")", "!=", "2", "for", "ds", "in", "datasets", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Did not find a validation set for one or more \"", "\n", "\"pairs in {}\"", ".", "format", "(", "datasets", ")", ")", "\n", "", "logger", ".", "info", "(", "\"[OBS] Merging training and validation sets\"", ")", "\n", "datasets", "=", "[", "merge_train_and_val", "(", "*", "ds", ")", "for", "ds", "in", "datasets", "]", "\n", "no_val", "=", "True", "\n", "", "if", "not", "no_val", ":", "\n", "        ", "train_datasets", ",", "val_datasets", "=", "zip", "(", "*", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "train_datasets", "=", "[", "d", "[", "0", "]", "for", "d", "in", "datasets", "]", "\n", "val_datasets", "=", "[", "]", "\n", "", "return", "train_datasets", ",", "val_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_h5_train_and_val_datasets": [[90, 151], ["utime.utils.scriptutils.get_all_dataset_hparams", "utime.utils.scriptutils.get_all_dataset_hparams.items", "psg_utils.dataset.sleep_study_dataset.SingleH5Dataset.get_datasets", "NotImplementedError", "train.get_h5_train_and_val_datasets._get_dataset"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_all_dataset_hparams", "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_datasets"], ["", "def", "get_h5_train_and_val_datasets", "(", "hparams", ",", "no_val", ",", "train_on_val", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        hparams:      (YAMLHParams) A hyperparameter object to load dataset\n                                    configurations from.\n        no_val:       (bool)        Do not load validation data\n        train_on_val: (bool)        Load validation data, but merge it into\n                                    the training data. Then return only the\n                                    'trainin' (train+val) dataset.\n        dataset_ids (None, list)    Only load datasets with IDs in 'dataset_ids'.\n                                    If None, load all datasets.\n\n    Returns:\n        A list of training SleepStudyDataset objects\n        A list of validation SleepStudyDataset objects, or [] if not val.\n    \"\"\"", "\n", "def", "_get_dataset", "(", "h5_dataset", ",", "regex", ",", "hparams", ")", ":", "\n", "        ", "\"\"\"\n        Helper for returning a dataset from a H5Dataset object according to\n        regex and a hyperparameter set for a single dataset.\n        \"\"\"", "\n", "h5_path", "=", "hparams", "[", "'data_dir'", "]", "\n", "if", "os", ".", "path", ".", "abspath", "(", "h5_path", ")", "!=", "os", ".", "path", ".", "abspath", "(", "h5_dataset", ".", "h5_path", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently all data must be stored in a single \"", "\n", "\".h5 file. Found two or more different files.\"", ")", "\n", "", "dataset", "=", "h5_dataset", ".", "get_datasets", "(", "\n", "load_match_regex", "=", "regex", ",", "\n", "period_length_sec", "=", "hparams", ".", "get", "(", "'period_length_sec'", ")", ",", "\n", "annotation_dict", "=", "hparams", ".", "get", "(", "'sleep_stage_annotations'", ")", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "1", "\n", "return", "dataset", "[", "0", "]", "\n", "\n", "", "if", "train_on_val", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Training on validation data is not yet \"", "\n", "\"implemented for preprocessed H5 datasets.\"", ")", "\n", "", "data_hparams", "=", "get_all_dataset_hparams", "(", "hparams", ",", "dataset_ids", "=", "dataset_ids", ")", "\n", "h5_dataset", "=", "None", "\n", "train_datasets", ",", "val_datasets", "=", "[", "]", ",", "[", "]", "\n", "for", "dataset_id", ",", "hparams", "in", "data_hparams", ".", "items", "(", ")", ":", "\n", "        ", "if", "h5_dataset", "is", "None", ":", "\n", "            ", "h5_dataset", "=", "SingleH5Dataset", "(", "hparams", "[", "'train_data'", "]", "[", "'data_dir'", "]", ")", "\n", "", "train", "=", "_get_dataset", "(", "\n", "h5_dataset", "=", "h5_dataset", ",", "\n", "regex", "=", "f'/{dataset_id}/TRAIN'", ",", "\n", "hparams", "=", "hparams", "[", "'train_data'", "]", "\n", ")", "\n", "train_datasets", ".", "append", "(", "train", ")", "\n", "ds", "=", "[", "train", "]", "\n", "if", "not", "no_val", ":", "\n", "            ", "val", "=", "_get_dataset", "(", "\n", "h5_dataset", "=", "h5_dataset", ",", "\n", "regex", "=", "f'/{dataset_id}/VAL'", ",", "\n", "hparams", "=", "hparams", "[", "'val_data'", "]", "\n", ")", "\n", "ds", ".", "append", "(", "val", ")", "\n", "val_datasets", ".", "append", "(", "val", ")", "\n", "", "select_sample_strip_scale_quality", "(", "*", "ds", ",", "hparams", "=", "hparams", ")", "\n", "", "return", "train_datasets", ",", "val_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_generators": [[153, 198], ["hparams.get_group", "utime.sequences.get_batch_sequence", "len", "utime.sequences.MultiSequence", "utime.sequences.ValidationMultiSequence", "utime.sequences.get_batch_sequence", "len", "len", "hparams.get"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_batch_sequence", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_batch_sequence"], ["", "def", "get_generators", "(", "train_datasets_queues", ",", "hparams", ",", "val_dataset_queues", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Takes a list of training and optionally validation utime.dataset.queue\n    type objects and returns a training and validation sequence object\n    (see utime.sequences). If val_dataset_queues is None, returns only a\n    training sequencer.\n\n    With multiple training sequence objects, a MultiSequence object is returned\n    which is a light wrapper around multiple sequences that samples across them\n\n    With validation data, a ValidationMultiSequence is always returned, even\n    for 1 dataset, as this data structure is expected in the Validation\n    callback.\n\n    Args:\n        train_datasets_queues: (list)        TODO\n        hparams:               (YAMLHParams) The hyperparameters to init the\n                                             sequencers with\n        val_dataset_queues:    (list)        TODO\n\n    Returns:\n        A training Sequence or MultiSequence objects\n        A ValidatonMultiSequence object if no_val=False, otherwise None\n    \"\"\"", "\n", "n_classes", "=", "hparams", ".", "get_group", "(", "'/build/n_classes'", ")", "\n", "train_seqs", "=", "[", "get_batch_sequence", "(", "dataset_queue", "=", "d", ",", "\n", "random_batches", "=", "True", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "augmenters", "=", "hparams", ".", "get", "(", "\"augmenters\"", ")", ",", "\n", "**", "hparams", "[", "\"fit\"", "]", ")", "for", "d", "in", "train_datasets_queues", "]", "\n", "val_seq", "=", "None", "\n", "if", "val_dataset_queues", ":", "\n", "        ", "val_seq", "=", "[", "get_batch_sequence", "(", "dataset_queue", "=", "d", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "hparams", "[", "'fit'", "]", ")", "for", "d", "in", "val_dataset_queues", "]", "\n", "", "if", "len", "(", "train_seqs", ")", ">", "1", ":", "\n", "# Wrap sequencers in MultiSequence object which creates batches by sampling", "\n", "# across its stores individual sequencers", "\n", "        ", "train_seq", "=", "MultiSequence", "(", "train_seqs", ",", "hparams", "[", "'fit'", "]", "[", "'batch_size'", "]", ")", "\n", "", "else", ":", "\n", "        ", "train_seq", "=", "train_seqs", "[", "0", "]", "\n", "", "if", "val_seq", ":", "\n", "        ", "assert", "len", "(", "val_seq", ")", "==", "len", "(", "train_seqs", ")", "\n", "val_seq", "=", "ValidationMultiSequence", "(", "val_seq", ")", "\n", "", "return", "train_seq", ",", "val_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.merge_train_and_val": [[200, 219], ["train.add_pairs", "train.log", "val.identifier.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log"], ["", "def", "merge_train_and_val", "(", "train", ",", "val", ")", ":", "\n", "    ", "\"\"\"\n    Takes two SleepStudyDataset objects 'train' and 'val' and merges them by\n    adding all stored SleepStudy pairs of 'val' to the list of pairs in 'train'\n    Then changes the 'identifier' attribute of the 'train' sequencer to reflect\n    the changes and returns the, now merged, 'train' dataset only (in a list).\n\n    Args:\n        train: A SleepStudyDataset object\n        val:   A SleepStudyDataset object\n\n    Returns:\n        A list of 1 SleepStudyDataset object storing data from both 'train'\n        and 'val'\n    \"\"\"", "\n", "train", ".", "add_pairs", "(", "val", ".", "pairs", ")", "\n", "train", ".", "_identifier", "=", "train", ".", "identifier", "+", "\"_\"", "+", "val", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "train", ".", "log", "(", ")", "\n", "return", "[", "train", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_samples_per_epoch": [[221, 262], ["min", "int", "logger.warning"], "function", ["None"], ["", "def", "get_samples_per_epoch", "(", "train_seq", ",", "max_train_samples_per_epoch", ")", ":", "\n", "    ", "\"\"\"\n    Returns the number of samples to take from the training sequence objects\n    for 1 epoch to be considered finished.\n\n    Specifically, the specified number of training 'samples' in args\n    (number of sleep 'epochs'/'segments'/'periods') will be divided by the\n    total number of such segments that the model takes as input in each pass\n    I.e. if train_samples_per_epoch is set to 100 for a model which considers\n    10 epochs at a time, this function will return 100/10 = 10 steps per train\n    epoch.\n\n    Note: The (non-standardized) training samples is upper bounded by the\n    total number of samples in the dataset.\n\n    Args:\n        train_seq:                  (Sequence) The training Sequence or\n                                               MultiSequence object\n        max_train_samples_per_epoch (int)      Maximum number of samples for\n                                               training. The actual number will\n                                               be the lesser of this value and\n                                               the total number of samples.\n\n    Returns:\n        Number of samples to take in training and validation\n    \"\"\"", "\n", "try", ":", "\n", "        ", "total_periods", "=", "train_seq", ".", "total_periods", "\n", "", "except", "(", "NotLoadedError", ",", "TypeError", ")", ":", "\n", "# train_seq.total_period is not available (not all samples loaded or limitation queue). Use estimate.", "\n", "        ", "n_studies", "=", "train_seq", ".", "num_pairs", "\n", "total_periods", "=", "2000", "*", "n_studies", "\n", "logger", ".", "warning", "(", "f\"Property 'total_periods' not available on sequence {train_seq}. \"", "\n", "f\"Using (over)estimate total periods of {total_periods} based on dataset length of {n_studies}.\"", ")", "\n", "", "train_samples_per_epoch", "=", "min", "(", "total_periods", ",", "max_train_samples_per_epoch", ")", "\n", "if", "train_seq", ".", "margin", ":", "\n", "# For sequence models, we only sample a number of batches to cover", "\n", "# all data in once (in expectation).", "\n", "        ", "m", "=", "train_seq", ".", "margin", "*", "2", "+", "1", "\n", "train_samples_per_epoch", "=", "int", "(", "train_samples_per_epoch", "/", "m", ")", "\n", "", "return", "train_samples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_lr_at_epoch": [[264, 281], ["os.path.join", "pandas.read_csv", "os.path.exists", "print", "float", "int"], "function", ["None"], ["", "def", "get_lr_at_epoch", "(", "epoch", ",", "log_dir", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training.csv\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_path", ")", ":", "\n", "        ", "print", "(", "\"No training.csv file found at %s. Continuing with default \"", "\n", "\"learning rate found in parameter file.\"", "%", "log_dir", ")", "\n", "return", "None", ",", "None", "\n", "", "df", "=", "pd", ".", "read_csv", "(", "log_path", ")", "\n", "possible_names", "=", "(", "\"lr\"", ",", "\"LR\"", ",", "\"learning_rate\"", ",", "\"LearningRate\"", ")", "\n", "try", ":", "\n", "        ", "in_df", "=", "[", "l", "in", "df", ".", "columns", "for", "l", "in", "possible_names", "]", ".", "index", "(", "True", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "col_name", "=", "possible_names", "[", "in_df", "]", "\n", "return", "float", "(", "df", "[", "col_name", "]", "[", "int", "(", "epoch", ")", "]", ")", ",", "col_name", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.clear_csv_after_epoch": [[283, 303], ["os.path.exists", "pandas.read_csv", "open", "out_f.write", "os.remove", "pd.read_csv.to_csv", "numpy.flatnonzero"], "function", ["None"], ["", "def", "clear_csv_after_epoch", "(", "epoch", ",", "csv_file", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "csv_file", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "csv_file", ")", "\n", "", "except", "pd", ".", "errors", ".", "EmptyDataError", ":", "\n", "# Remove the file", "\n", "            ", "os", ".", "remove", "(", "csv_file", ")", "\n", "return", "\n", "# Remove any trailing runs and remove after 'epoch'", "\n", "", "try", ":", "\n", "            ", "df", "=", "df", "[", "np", ".", "flatnonzero", "(", "df", "[", "\"epoch\"", "]", "==", "0", ")", "[", "-", "1", "]", ":", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "pass", "\n", "", "df", "=", "df", "[", ":", "epoch", "+", "1", "]", "\n", "# Save again", "\n", "with", "open", "(", "csv_file", ",", "\"w\"", ")", "as", "out_f", ":", "\n", "            ", "out_f", ".", "write", "(", "df", ".", "to_csv", "(", "index", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_last_epoch": [[305, 314], ["os.path.exists", "pandas.read_csv", "int", "df[].to_numpy"], "function", ["None"], ["", "", "", "def", "get_last_epoch", "(", "csv_file", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "epoch", "=", "0", "\n", "if", "os", ".", "path", ".", "exists", "(", "csv_file", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "csv_file", ")", "\n", "epoch", "=", "int", "(", "df", "[", "\"epoch\"", "]", ".", "to_numpy", "(", ")", "[", "-", "1", "]", ")", "\n", "", "return", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.save_final_weights": [[316, 339], ["logger.info", "os.path.exists", "model.save_weights", "os.path.exists", "os.mkdir", "os.remove", "os.path.splitext"], "function", ["None"], ["", "def", "save_final_weights", "(", "project_dir", ",", "model", ",", "file_name", ")", ":", "\n", "    ", "\"\"\"\n    Saves the current (normally 'final') weights of 'model' to h5 archive at\n    path project_dir/model/'file_name'.\n\n    If a model of the same name exists, it will be overwritten.\n    If the directory 'project_dir'/model does not exist, it will be created.\n\n    Args:\n        project_dir: (string)         Path to the project directory\n        model:       (tf.keras Model) The model instance which weights will be\n                                      saved.\n        file_name:   (string)         Name of the saved parameter file\n    \"\"\"", "\n", "# Save final model weights", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"%s/model\"", "%", "project_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "\"%s/model\"", "%", "project_dir", ")", "\n", "", "model_path", "=", "\"{}/model/{}.h5\"", ".", "format", "(", "project_dir", ",", "\n", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "f\"Saving current model to: {model_path}\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "        ", "os", ".", "remove", "(", "model_path", ")", "\n", "", "model", ".", "save_weights", "(", "model_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.label_smoothing.label_smoothing.smooth_by_neighbours": [[9, 15], ["numpy.array().reshape", "tensorflow.keras.utils.to_categorical", "scipy.signal.convolve2d", "numpy.array"], "function", ["None"], ["def", "smooth_by_neighbours", "(", "labels", ",", "kernel", ",", "n_classes", ")", ":", "\n", "    ", "kernel", "=", "np", ".", "array", "(", "kernel", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "one_hot_labels", "=", "to_categorical", "(", "labels", ",", "n_classes", ")", "\n", "return", "convolve2d", "(", "one_hot_labels", ",", "\n", "kernel", ",", "\n", "mode", "=", "\"same\"", ",", "boundary", "=", "'symm'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.label_smoothing.label_smoothing.smoothen": [[17, 20], ["numpy.random.rand"], "function", ["None"], ["", "def", "smoothen", "(", "one_hot_labels", ",", "max_alpha", ",", "n_classes", ")", ":", "\n", "    ", "alpha", "=", "np", ".", "random", ".", "rand", "(", ")", "*", "max_alpha", "\n", "return", "(", "1", "-", "alpha", ")", "*", "one_hot_labels", "+", "(", "alpha", "/", "n_classes", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.__init__": [[41, 83], ["multi_sequence._assert_comparable_sequencers", "utime.sequences.base_sequence._BaseSequence.__init__", "numpy.arange", "numpy.array", "len", "len", "numpy.sum", "multi_sequence.MultiSequence.log", "len", "len"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence._assert_comparable_sequencers", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log"], ["def", "__init__", "(", "self", ",", "\n", "sequencers", ",", "\n", "batch_size", ",", "\n", "dataset_sample_alpha", "=", "0.5", ",", "\n", "no_log", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        TODO\n\n        Args:\n            sequencers:\n            batch_size:\n            dataset_sample_alpha:  TODO\n            no_log:\n        \"\"\"", "\n", "# Make sure we can use the 0th sequencer as a reference that respects", "\n", "# all the sequences (same batch-size, margins etc.)", "\n", "_assert_comparable_sequencers", "(", "sequencers", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sequences", "=", "sequencers", "\n", "self", ".", "sequences_idxs", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "sequences", ")", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "margin", "=", "sequencers", "[", "0", "]", ".", "margin", "\n", "self", ".", "n_classes", "=", "sequencers", "[", "0", "]", ".", "n_classes", "\n", "\n", "# Compute probability of sampling a given dataset", "\n", "# We sample a given dataset either:", "\n", "#   1) Uniformly across datasets, independent of dataset size", "\n", "#   2) Unifomrly across records, sample a dataset according to size", "\n", "# The 'dataset_sample_alpha' parameter in [0...1] determines the", "\n", "# degree to which strategy 1 or 2 is followed:", "\n", "#   P = (1-alpha)*P_r + alpha*P_d", "\n", "# If alpha = 0, sample only according to", "\n", "n_samples", "=", "[", "len", "(", "s", ".", "dataset_queue", ")", "for", "s", "in", "sequencers", "]", "\n", "linear", "=", "n_samples", "/", "np", ".", "sum", "(", "n_samples", ")", "\n", "uniform", "=", "np", ".", "array", "(", "[", "1", "/", "len", "(", "self", ".", "sequences", ")", "]", "*", "len", "(", "self", ".", "sequences", ")", ")", "\n", "self", ".", "alpha", "=", "dataset_sample_alpha", "\n", "self", ".", "sample_prob", "=", "(", "1", "-", "self", ".", "alpha", ")", "*", "linear", "+", "self", ".", "alpha", "*", "uniform", "\n", "\n", "for", "s", "in", "self", ".", "sequences", ":", "\n", "            ", "s", ".", "batch_size", "=", "1", "\n", "", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.log": [[84, 86], ["logger.info", "len"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"\\n[*] MultiSequence initialized:\\n\"", "\n", "f\"    --- Contains {len(self.sequences)} sequences\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.__len__": [[91, 99], ["numpy.sum", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the sum over stored sequencer lengths \"\"\"", "\n", "try", ":", "\n", "            ", "return", "np", ".", "sum", "(", "[", "len", "(", "s", ")", "for", "s", "in", "self", ".", "sequences", "]", ")", "\n", "", "except", "NotLoadedError", ":", "\n", "# Queued data - return some reasonably large number, does not", "\n", "# matter as batches are normally randomly selected anyway.", "\n", "            ", "return", "10000", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.batch_shape": [[100, 106], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "batch_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the batch shape as output from the MultiSequence \"\"\"", "\n", "bs", "=", "self", ".", "sequences", "[", "0", "]", ".", "batch_shape", "\n", "bs", "[", "0", "]", "=", "self", ".", "batch_size", "\n", "return", "bs", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.num_pairs": [[107, 110], ["numpy.sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_pairs", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "s", ".", "num_pairs", "for", "s", "in", "self", ".", "sequences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.total_periods": [[111, 115], ["numpy.sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "total_periods", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the sum of total periods over all sequences \"\"\"", "\n", "return", "np", ".", "sum", "(", "[", "s", ".", "total_periods", "for", "s", "in", "self", ".", "sequences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.get_class_counts": [[116, 122], ["numpy.zeros", "seq.get_class_counts"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_counts"], ["", "def", "get_class_counts", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the sum of class counts over all sequences \"\"\"", "\n", "counts", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "sequences", "[", "0", "]", ".", "n_classes", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "seq", "in", "self", ".", "sequences", ":", "\n", "            ", "counts", "+=", "seq", ".", "get_class_counts", "(", ")", "\n", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.get_class_frequencies": [[123, 127], ["multi_sequence.MultiSequence.get_class_counts", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_counts"], ["", "def", "get_class_frequencies", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the frequencies of classes over all sequences \"\"\"", "\n", "counts", "=", "self", ".", "get_class_counts", "(", ")", "\n", "return", "counts", "/", "np", ".", "sum", "(", "counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.MultiSequence.__getitem__": [[128, 158], ["multi_sequence.MultiSequence.seed", "numpy.random.choice", "multi_sequence.MultiSequence.get_empty_batch_arrays", "enumerate", "multi_sequence.MultiSequence.sequences[].process_batch", "sequence.get_class_balanced_random_period", "sequence.get_random_period"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_empty_batch_arrays", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_period", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.get_random_period"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Returns a batch of size self.batch_size uniformly selected across the\n        stored sequencer objects.\n        \"\"\"", "\n", "self", ".", "seed", "(", ")", "\n", "\n", "# OBS: Do not choose from self.sequences! The Sequence typed object is", "\n", "# array-like and numpy will attempt to iterate it to construct an", "\n", "# ndarray. For H5 datasets that may lead to all data stored in a", "\n", "# potentially very large dataset to be loaded every time this method is", "\n", "# called.", "\n", "sequences_idxs", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "sequences_idxs", ",", "\n", "size", "=", "self", ".", "batch_size", ",", "\n", "replace", "=", "True", ",", "\n", "p", "=", "self", ".", "sample_prob", ")", "\n", "\n", "X", ",", "y", "=", "self", ".", "get_empty_batch_arrays", "(", ")", "\n", "for", "i", ",", "sequence_idx", "in", "enumerate", "(", "sequences_idxs", ")", ":", "\n", "            ", "sequence", "=", "self", ".", "sequences", "[", "sequence_idx", "]", "\n", "try", ":", "\n", "# Currently only supported BalancedRandomBatchSequence", "\n", "# and RandomBatchSequence. Try balanced first.", "\n", "                ", "xx", ",", "yy", "=", "sequence", ".", "get_class_balanced_random_period", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "# Fall back to RandomBatchSequence", "\n", "                ", "xx", ",", "yy", "=", "sequence", ".", "get_random_period", "(", ")", "\n", "", "X", "[", "i", "]", "=", "xx", "\n", "y", "[", "i", "]", "=", "yy", "\n", "", "return", "self", ".", "sequences", "[", "0", "]", ".", "process_batch", "(", "X", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.ValidationMultiSequence.__init__": [[172, 179], ["multi_sequence._assert_comparable_sequencers", "multi_sequence.ValidationMultiSequence.log", "s.identifier.split"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence._assert_comparable_sequencers", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log"], ["def", "__init__", "(", "self", ",", "sequences", ",", "no_log", "=", "False", ")", ":", "\n", "        ", "_assert_comparable_sequencers", "(", "sequences", ")", "\n", "self", ".", "sequences", "=", "sequences", "\n", "self", ".", "IDs", "=", "[", "s", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "for", "s", "in", "self", ".", "sequences", "]", "\n", "self", ".", "n_classes", "=", "self", ".", "sequences", "[", "0", "]", ".", "n_classes", "\n", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.ValidationMultiSequence.log": [[180, 182], ["logger.info", "len"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"\\n[*] ValidationMultiSequence initialized:\\n\"", "\n", "f\"    --- Contains {len(self.sequences)} sequences\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.ValidationMultiSequence.__len__": [[185, 188], ["numpy.sum", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the sum over stored sequencer lengths \"\"\"", "\n", "return", "np", ".", "sum", "(", "[", "len", "(", "s", ")", "for", "s", "in", "self", ".", "sequences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.ValidationMultiSequence.get_minimum_total_periods": [[189, 198], ["numpy.min", "vspe.append"], "methods", ["None"], ["", "def", "get_minimum_total_periods", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the minimum number of total periods in any of the stored\n        validation sequences.\n        \"\"\"", "\n", "vspe", "=", "[", "]", "\n", "for", "vs", "in", "self", ".", "sequences", ":", "\n", "            ", "vspe", ".", "append", "(", "vs", ".", "total_periods", ")", "\n", "", "return", "np", ".", "min", "(", "vspe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence.ValidationMultiSequence.batch_size": [[206, 216], ["None"], "methods", ["None"], ["", "@", "batch_size", ".", "setter", "\n", "def", "batch_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"\n        Updates the batch size on all stores sequnce objects\n\n        Args:\n            value: (int) New batch size to set\n        \"\"\"", "\n", "for", "s", "in", "self", ".", "sequences", ":", "\n", "            ", "s", ".", "batch_size", "=", "value", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.multi_sequence._assert_comparable_sequencers": [[9, 28], ["list_.append", "all", "ValueError", "getattr", "numpy.asarray"], "function", ["None"], ["def", "_assert_comparable_sequencers", "(", "sequencers", ")", ":", "\n", "    ", "\"\"\"\n    Takes a list of utime.sequencer Sequence objects and compares them for\n    equality on a number of specified parameters.\n\n    Raises ValueError if any sequence in the list deviates from the others\n    with respect to any of the tested attributes.\n\n    Args:\n        sequencers: A list of Sequence objects\n    \"\"\"", "\n", "tests", "=", "(", "(", "[", "]", ",", "\"margin\"", ")", ",", "(", "[", "]", ",", "\"batch_size\"", ")", ",", "(", "[", "]", ",", "\"n_classes\"", ")", ",", "\n", "(", "[", "]", ",", "\"data_per_period\"", ")", ",", "(", "[", "]", ",", "\"n_channels\"", ")", ")", "\n", "for", "s", "in", "sequencers", ":", "\n", "        ", "for", "list_", ",", "key", "in", "tests", ":", "\n", "            ", "list_", ".", "append", "(", "getattr", "(", "s", ",", "key", ")", ")", "\n", "", "", "for", "list_", ",", "key", "in", "tests", ":", "\n", "        ", "if", "not", "all", "(", "np", ".", "asarray", "(", "list_", ")", "==", "list_", "[", "0", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"All sequences must have the same '{key}' property. Got {list_}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.__init__": [[25, 62], ["utime.sequences.BatchSequence.__init__", "balanced_random_batch_sequence.BalancedRandomBatchSequence.log"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log"], ["def", "__init__", "(", "self", ",", "\n", "dataset_queue", ",", "\n", "batch_size", ",", "\n", "data_per_period", ",", "\n", "n_classes", ",", "\n", "n_channels", ",", "\n", "sample_prob", "=", "None", ",", "\n", "margin", "=", "0", ",", "\n", "augmenters", "=", "None", ",", "\n", "batch_scaler", "=", "None", ",", "\n", "no_log", "=", "False", ",", "\n", "identifier", "=", "\"\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sample_prob: (list, None) A list of length n_classes of sample\n                                      probability values or None, in which\n                                      case uniform class sampling will occur.\n\n        See BatchSequence docstring for other argument descriptions\n        \"\"\"", "\n", "self", ".", "_sample_prob", "=", "None", "\n", "super", "(", ")", ".", "__init__", "(", "dataset_queue", "=", "dataset_queue", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "data_per_period", "=", "data_per_period", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "n_channels", "=", "n_channels", ",", "\n", "margin", "=", "margin", ",", "\n", "augmenters", "=", "augmenters", ",", "\n", "batch_scaler", "=", "batch_scaler", ",", "\n", "no_log", "=", "True", ",", "\n", "identifier", "=", "identifier", ",", "\n", "require_all_loaded", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "sample_prob", "=", "sample_prob", "\n", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.log": [[63, 66], ["logger.info", "type", "len", "bool"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "\"\"\" Log basic information on this object \"\"\"", "\n", "logger", ".", "info", "(", "f\"\\n[*] BalancedRandomBatchSequence initialized{f' ({self.identifier})' if self.identifier else ''}:\\n\"", "\n", "f\"    Data queue type: {type(self.dataset_queue)}\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.sample_prob": [[82, 101], ["numpy.array", "numpy.sum", "ValueError", "isinstance", "len", "type"], "methods", ["None"], ["", "@", "sample_prob", ".", "setter", "\n", "def", "sample_prob", "(", "self", ",", "values", ")", ":", "\n", "        ", "\"\"\"\n        Set a class-sampling probability vector.\n\n        Args:\n            values: A list of length self.n_classes of class-sampling\n                    probability values. The list is normalized to sum to 1\n        \"\"\"", "\n", "if", "values", "is", "None", ":", "\n", "            ", "self", ".", "_sample_prob", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "values", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", "or", "len", "(", "values", ")", "!=", "self", ".", "n_classes", ":", "\n", "                ", "raise", "ValueError", "(", "f\"'sample_prob' should be an array of\"", "\n", "f\" length n_classes={self.n_classes}. \"", "\n", "f\"Got {values} (type {type(values)})\"", ")", "\n", "", "self", ".", "_sample_prob", "=", "np", ".", "array", "(", "values", ")", "\n", "self", ".", "_sample_prob", "/=", "np", ".", "sum", "(", "self", ".", "_sample_prob", ")", "# sum 1", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.__getitem__": [[102, 110], ["balanced_random_batch_sequence.BalancedRandomBatchSequence.seed", "balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_batch"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_batch"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Return a random batch of data\n        See self.get_class_balanced_random_batch for docstring\n        \"\"\"", "\n", "# If multiprocessing, set unique seed for this particular process", "\n", "self", ".", "seed", "(", ")", "\n", "return", "self", ".", "get_class_balanced_random_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_period": [[111, 156], ["numpy.arange", "RuntimeError", "numpy.random.choice", "balanced_random_batch_sequence.BalancedRandomBatchSequence.dataset_queue.get_random_study", "sleep_study.get_class_indicies", "balanced_random_batch_sequence.BalancedRandomBatchSequence.get_period", "len", "logger.warning", "numpy.random.choice", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_period"], ["", "def", "get_class_balanced_random_period", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sample a class-balanced random 'period/epoch/segment' of data\n        according to sample probabilities in self.sample_prob from\n        a (uniformly) random SleepStudy object in self.dataset_queue.\n\n        With self.margin > 0 multiple, connected periods is returned in a\n        single call.\n\n        Returns:\n            X, a [data_per_prediction, n_channels] ndarray if margin == 0, else\n               a list of len margin*2+1 of [data_per_prediction, n_channels]\n               ndarrays if margin > 0\n            y, integer label value if margin == 0 else a list of len margin*2+1\n               of integer label values if margin >0\n        \"\"\"", "\n", "# Get random class according to the sample probs.", "\n", "classes", "=", "np", ".", "arange", "(", "self", ".", "n_classes", ")", "\n", "cls", "=", "np", ".", "random", ".", "choice", "(", "classes", ",", "size", "=", "1", ",", "p", "=", "self", ".", "sample_prob", ")", "[", "0", "]", "\n", "tries", ",", "max_tries", "=", "0", ",", "1000", "\n", "while", "tries", "<", "max_tries", ":", "\n", "            ", "with", "self", ".", "dataset_queue", ".", "get_random_study", "(", ")", "as", "sleep_study", ":", "\n", "                ", "try", ":", "\n", "                    ", "class_inds", "=", "sleep_study", ".", "get_class_indicies", "(", "cls", ")", "\n", "if", "len", "(", "class_inds", ")", "==", "0", ":", "\n", "                        ", "logger", ".", "warning", "(", "f\"Found empty class inds array for study {sleep_study} and class {cls}\"", ")", "\n", "raise", "KeyError", "\n", "", "", "except", "KeyError", ":", "\n", "# This SS does not have the given class", "\n", "                    ", "tries", "+=", "1", "\n", "continue", "\n", "", "else", ":", "\n", "# Get the period index of a randomly sampled class", "\n", "# (according to sample_prob distribution) within the", "\n", "# SleepStudy pair", "\n", "                    ", "idx", "=", "np", ".", "random", ".", "choice", "(", "class_inds", ",", "1", ")", "[", "0", "]", "\n", "if", "self", ".", "margin", ">", "0", ":", "\n", "# Shift the idx randomly within the window", "\n", "                        ", "idx", "+=", "np", ".", "random", ".", "randint", "(", "-", "self", ".", "margin", ",", "self", ".", "margin", "+", "1", ")", "\n", "", "X_", ",", "y_", "=", "self", ".", "get_period", "(", "sleep_study", "=", "sleep_study", ",", "\n", "period_idx", "=", "idx", ",", "\n", "allow_shift_at_border", "=", "True", ")", "\n", "return", "X_", ",", "y_", "\n", "# Probably something is wrong, raise error.", "\n", "", "", "", "raise", "RuntimeError", "(", "f\"Could not sample period for class {cls}, stopping after {max_tries} tries.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_batch": [[157, 193], ["balanced_random_batch_sequence.BalancedRandomBatchSequence.get_empty_batch_arrays", "range", "balanced_random_batch_sequence.BalancedRandomBatchSequence.process_batch", "balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_period"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_empty_batch_arrays", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.balanced_random_batch_sequence.BalancedRandomBatchSequence.get_class_balanced_random_period"], ["", "def", "get_class_balanced_random_batch", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a batch of data sampled uniformly across SleepStudy pairs and\n        randomly across target classes according to the distribution of\n        self.sample_prob (for instance, [0.2, 0.2, 0.2, 0.2, 0.2] will sample\n        uniformly across 5 classes from the uniformly chosen SleepStudy pair).\n\n        Note: If the sampled SleepStudy object does not display the sampled\n        target class, a new SleepStudy is sampled until success for the given\n        label class.\n\n        Note: For self.margin > 0 ('sequence' mode), sampling is conducted as\n        normally, but the sampled position is shifted randomly by +- margin\n        to either side to enforce sequence variation around rare classes.\n\n        Note: For self.margin > 0 the output target classes may not be uniform\n        in distribution as the sampling only ensures that at least one of each\n        classes appear according to the sample distribution in a given sequence\n        The remaining margin*2 targets in the sequence takes whatever values\n        occur at these positions in the target sequence and are thus subject\n        to class imbalance.\n\n        Returns:\n            X, float32 ndarray, batch of input data,\n               shape [batch_size, data_per_prediction, n_channels] if margin=0\n               else [batch_size, margin*2+1, data_per_prediction, n_channels]\n            y, uint8 ndarray, batch of integer target values,\n               shape [batch_size, 1] if margin=0\n               else [batch_size, margin*2+1, 1]\n        \"\"\"", "\n", "X", ",", "y", "=", "self", ".", "get_empty_batch_arrays", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_size", ")", ":", "\n", "            ", "xx", ",", "yy", "=", "self", ".", "get_class_balanced_random_period", "(", ")", "\n", "X", "[", "i", "]", "=", "xx", "\n", "y", "[", "i", "]", "=", "yy", "\n", "", "return", "self", ".", "process_batch", "(", "X", ",", "y", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.__init__": [[41, 50], ["tensorflow.keras.utils.Sequence.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# A dictionary mapping process names to whether the process has been", "\n", "# seeded", "\n", "self", ".", "is_seeded", "=", "{", "}", "\n", "self", ".", "_all_loaded", "=", "None", "\n", "self", ".", "_periods_per_pair", "=", "None", "\n", "self", ".", "_cum_periods_per_pair", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.all_loaded": [[51, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_loaded", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_all_loaded", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.cum_periods_per_pair": [[55, 59], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cum_periods_per_pair", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a list of cumulative sums over periods per pair \"\"\"", "\n", "return", "self", ".", "_cum_periods_per_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.periods_per_pair": [[60, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "periods_per_pair", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a list of n_periods for each stored pair \"\"\"", "\n", "return", "self", ".", "_periods_per_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.__call__": [[65, 73], ["range", "len", "base_sequence._BaseSequence.__getitem__", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.__getitem__"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns an iterator that iterates the dataset indefinitely, converting numpy arrays to tensors\n        \"\"\"", "\n", "while", "True", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "x", ",", "y", "=", "self", ".", "__getitem__", "(", "i", ")", "# index does not matter", "\n", "yield", "tf", ".", "convert_to_tensor", "(", "x", ")", ",", "tf", ".", "convert_to_tensor", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.__getitem__": [[74, 76], ["None"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.__iter__": [[77, 79], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.__len__": [[80, 82], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_pairs": [[83, 85], ["None"], "methods", ["None"], ["", "def", "get_pairs", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.num_pairs": [[86, 89], ["len", "base_sequence._BaseSequence.get_pairs"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_pairs"], ["", "@", "property", "\n", "def", "num_pairs", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "get_pairs", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.batch_shape": [[90, 92], ["None"], "methods", ["None"], ["", "def", "batch_shape", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_class_counts": [[93, 95], ["None"], "methods", ["None"], ["", "def", "get_class_counts", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_class_frequencies": [[96, 98], ["None"], "methods", ["None"], ["", "def", "get_class_frequencies", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_batch_shapes": [[99, 107], ["None"], "methods", ["None"], ["", "def", "get_batch_shapes", "(", "self", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "x_shape", "=", "self", ".", "batch_shape", "\n", "y_shape", "=", "x_shape", "[", ":", "-", "2", "]", "+", "[", "1", "]", "\n", "if", "batch_size", ":", "\n", "# Overwrite", "\n", "            ", "x_shape", "[", "0", "]", "=", "batch_size", "\n", "y_shape", "[", "0", "]", "=", "batch_size", "\n", "", "return", "x_shape", ",", "y_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_empty_batch_arrays": [[108, 119], ["base_sequence._BaseSequence.get_batch_shapes", "numpy.empty", "numpy.empty"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_batch_shapes"], ["", "def", "get_empty_batch_arrays", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        TODO\n\n        Returns:\n\n        \"\"\"", "\n", "x_shape", ",", "y_shape", "=", "self", ".", "get_batch_shapes", "(", ")", "\n", "x", "=", "np", ".", "empty", "(", "shape", "=", "x_shape", ",", "dtype", "=", "Defaults", ".", "PSG_DTYPE", ")", "\n", "y", "=", "np", ".", "empty", "(", "shape", "=", "y_shape", ",", "dtype", "=", "Defaults", ".", "HYP_DTYPE", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed": [[120, 141], ["multiprocessing.current_process", "numpy.random.seed", "int", "pname.split"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed"], ["", "def", "seed", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        If multiprocessing, the processes will inherit the RNG state of the\n        main process - here we reseed each process once so that the batches\n        are randomly generated across multi-processes calls to the Sequence\n        batch generator methods\n\n        If multi-threading this method will just re-seed the 'MainProcess'\n        process once\n        \"\"\"", "\n", "pname", "=", "current_process", "(", ")", ".", "name", "\n", "if", "pname", "not", "in", "self", ".", "is_seeded", "or", "not", "self", ".", "is_seeded", "[", "pname", "]", ":", "\n", "            ", "try", ":", "\n", "# Try fetch process number, add this to global seed to get different seeds in each process", "\n", "                ", "proc_seed", "=", "int", "(", "pname", ".", "split", "(", "\"-\"", ")", "[", "1", "]", ")", "\n", "", "except", "IndexError", ":", "\n", "                ", "proc_seed", "=", "0", "\n", "# Re-seed this process", "\n", "", "proc_seed", "=", "(", "Defaults", ".", "GLOBAL_SEED", "+", "proc_seed", ")", "if", "Defaults", ".", "GLOBAL_SEED", "is", "not", "None", "else", "None", "\n", "np", ".", "random", ".", "seed", "(", "proc_seed", ")", "\n", "self", ".", "is_seeded", "[", "pname", "]", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.__init__": [[148, 193], ["base_sequence._BaseSequence.__init__", "psg_utils.dataset.utils.assert_all_loaded", "int", "int", "bool", "numpy.array", "numpy.cumsum", "psg_utils.preprocessing.scaling.assert_scaler", "ValueError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset_queue", ",", "\n", "n_classes", ",", "\n", "n_channels", ",", "\n", "batch_size", ",", "\n", "augmenters", ",", "\n", "batch_scaler", ",", "\n", "require_all_loaded", "=", "False", ",", "\n", "identifier", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_queue:   (queue)    TODO\n            n_classes:         (int)    Number of classes (sleep stages)\n            n_channels:        (int)    The number of PSG channels to expect in\n                                        data extracted from a SleepStudy object\n            batch_size:        (int)    The size of the generated batch\n            augmenters:        (list)   List of utime.augmentation.augmenters\n            batch_scaler:      (string) The name of a sklearn.preprocessing\n                                        Scaler object to apply to each sampled\n                                        batch (optional)\n            identifier:        (string) A string identifier name\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_all_loaded", "=", "assert_all_loaded", "(", "dataset_queue", ".", "dataset", ".", "pairs", ",", "\n", "raise_", "=", "require_all_loaded", ")", "\n", "self", ".", "identifier", "=", "identifier", "\n", "self", ".", "dataset_queue", "=", "dataset_queue", "\n", "self", ".", "n_classes", "=", "int", "(", "n_classes", ")", "\n", "self", ".", "n_channels", "=", "int", "(", "n_channels", ")", "\n", "self", ".", "augmenters", "=", "augmenters", "or", "[", "]", "\n", "self", ".", "augmentation_enabled", "=", "bool", "(", "augmenters", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "if", "self", ".", "all_loaded", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_periods_per_pair", "=", "np", ".", "array", "(", "[", "ss", ".", "n_periods", "for", "ss", "in", "self", ".", "dataset_queue", "]", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "self", ".", "_cum_periods_per_pair", "=", "np", ".", "cumsum", "(", "self", ".", "periods_per_pair", ")", "\n", "", "", "if", "batch_scaler", "not", "in", "(", "None", ",", "False", ")", ":", "\n", "            ", "if", "not", "assert_scaler", "(", "batch_scaler", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid batch scaler {}\"", ".", "format", "(", "batch_scaler", ")", ")", "\n", "", "self", ".", "batch_scaler", "=", "batch_scaler", "\n", "", "else", ":", "\n", "            ", "self", ".", "batch_scaler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_pairs": [[194, 196], ["base_sequence.BaseSequence.dataset_queue.get_pairs"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_pairs"], ["", "", "def", "get_pairs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset_queue", ".", "get_pairs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_counts": [[197, 210], ["numpy.zeros", "im.get_class_counts", "im.get_class_counts.items"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_counts"], ["", "@", "requires_all_loaded", "\n", "def", "get_class_counts", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            An ndarray of class counts across all stored SleepStudy objects\n            Shape [self.n_classes], dtype np.int\n        \"\"\"", "\n", "counts", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "n_classes", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "im", "in", "self", ".", "dataset_queue", ":", "\n", "            ", "count_dict", "=", "im", ".", "get_class_counts", "(", "as_dict", "=", "True", ")", "\n", "for", "cls", ",", "count", "in", "count_dict", ".", "items", "(", ")", ":", "\n", "                ", "counts", "[", "cls", "]", "+=", "count", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_frequencies": [[211, 220], ["base_sequence.BaseSequence.get_class_counts", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_class_counts"], ["", "@", "requires_all_loaded", "\n", "def", "get_class_frequencies", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            An ndarray of class frequencies comptued over all stored\n            SleepStudy objects. Shape [self.n_classes], dtype np.int\n        \"\"\"", "\n", "counts", "=", "self", ".", "get_class_counts", "(", ")", "\n", "return", "counts", "/", "np", ".", "sum", "(", "counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence._assert_scaled": [[221, 252], ["range", "logger.info", "logger.info", "batches.extend", "numpy.abs", "numpy.std", "logger.warning", "base_sequence.BaseSequence.dataset_queue.get_random_study", "numpy.random.randint", "xs.append", "numpy.mean", "ss.extract_from_psg"], "methods", ["None"], ["", "def", "_assert_scaled", "(", "self", ",", "warn_mean", "=", "5", ",", "warn_std", "=", "5", ",", "n_studies", "=", "3", ",", "\n", "periods_per_study", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Samples n_batches random batches from the sub-class Sequencer object\n        and computes the mean and STD of the values across the batches. If\n        their absolute values are higher than 'warn_mean' and 'warn_std'\n        respectively, a warning is printed.\n\n        Note: Does not raise an Error or Warning\n\n        Args:\n            warn_mean:         Maximum allowed abs(mean) before warning is invoked\n            warn_std:          Maximum allowed std before warning is invoked\n            n_studies:         Number of studies to (+ potentially load) sample from\n            periods_per_study: Number of periods to sample from each study\n        \"\"\"", "\n", "# Get a set of random batches", "\n", "batches", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n_studies", ")", ":", "\n", "            ", "xs", "=", "[", "]", "\n", "with", "self", ".", "dataset_queue", ".", "get_random_study", "(", ")", "as", "ss", ":", "\n", "                ", "seconds_per_study", "=", "periods_per_study", "*", "ss", ".", "period_length_sec", "\n", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "ss", ".", "last_period_start_second", "-", "seconds_per_study", ")", "\n", "start", "-=", "start", "%", "ss", ".", "period_length_sec", "\n", "xs", ".", "append", "(", "ss", ".", "extract_from_psg", "(", "start", ",", "start", "+", "seconds_per_study", ")", ")", "\n", "", "batches", ".", "extend", "(", "xs", ")", "\n", "", "mean", ",", "std", "=", "np", ".", "abs", "(", "np", ".", "mean", "(", "batches", ")", ")", ",", "np", ".", "std", "(", "batches", ")", "\n", "logger", ".", "info", "(", "f\"Mean assertion ({periods_per_study} periods from each of {n_studies} studies): {mean:.3f}\"", ")", "\n", "logger", ".", "info", "(", "f\"Scale assertion ({periods_per_study} periods from each of {n_studies} studies):  {std:.3f}\"", ")", "\n", "if", "mean", ">", "warn_mean", "or", "std", ">", "warn_std", ":", "\n", "            ", "logger", ".", "warning", "(", "\"OBS: Found large abs(mean) and std values over 5\"", "\n", "f\" sampled batches ({mean:.3f} and {std:.3f}).\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.augmentation_enabled": [[265, 284], ["isinstance", "TypeError", "ValueError", "type"], "methods", ["None"], ["", "@", "augmentation_enabled", ".", "setter", "\n", "def", "augmentation_enabled", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"\n        Set augmentation on/off on this Sequence object.\n        If augmentation_enabled = False no augmentation will be performed even\n        if Augmenter objects are set in the self.augmenters list.\n        If no Augmenter objects are set, augmentation_enabled has no effect.\n\n        Args:\n            value: (bool) Set augmentation enabled or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Argument to 'augmentation_enabled' must be a \"", "\n", "\"boolean value. Got {} ({})\"", ".", "format", "(", "value", ",", "\n", "type", "(", "value", ")", ")", ")", "\n", "", "if", "value", "is", "True", "and", "not", "self", ".", "augmenters", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot set 'augmentation_enabled' 'True' with \"", "\n", "\"empty 'augmenters' list: {}\"", ".", "format", "(", "self", ".", "augmenters", ")", ")", "\n", "", "self", ".", "_do_augmentation", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.batch_size": [[290, 302], ["int", "ValueError"], "methods", ["None"], ["", "@", "batch_size", ".", "setter", "\n", "def", "batch_size", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Change the batch size of sampled batches\n\n        Args:\n            batch_size: (int) New batch size\n        \"\"\"", "\n", "batch_size", "=", "int", "(", "batch_size", ")", "\n", "if", "batch_size", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Batch size must be a positive integer.\"", ")", "\n", "", "self", ".", "_batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.augmenters": [[308, 336], ["isinstance", "all", "TypeError", "init_aug.append", "logger.info", "cls", "isinstance"], "methods", ["None"], ["", "@", "augmenters", ".", "setter", "\n", "def", "augmenters", "(", "self", ",", "list_of_augs", ")", ":", "\n", "        ", "\"\"\"\n        Initialize and set a list of utime.augmentation.augmenters Augmentor\n        objects.\n\n        Args:\n            list_of_augs:\n\n        Returns:\n\n        \"\"\"", "\n", "from", "utime", ".", "augmentation", "import", "augmenters", "\n", "if", "list_of_augs", "is", "None", ":", "\n", "            ", "init_aug", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "c1", "=", "not", "isinstance", "(", "list_of_augs", ",", "(", "tuple", ",", "list", ",", "np", ".", "ndarray", ")", ")", "\n", "c2", "=", "not", "all", "(", "[", "isinstance", "(", "o", ",", "dict", ")", "for", "o", "in", "list_of_augs", "]", ")", "\n", "if", "c1", "or", "c2", ":", "\n", "                ", "raise", "TypeError", "(", "\"Property 'augmenters' must be a list or tuple \"", "\n", "\"of dictionary elements, \"", "\n", "\"got {}\"", ".", "format", "(", "list_of_augs", ")", ")", "\n", "", "init_aug", "=", "[", "]", "\n", "for", "d", "in", "list_of_augs", ":", "\n", "                ", "cls", "=", "augmenters", ".", "__dict__", "[", "d", "[", "\"cls_name\"", "]", "]", "\n", "init_aug", ".", "append", "(", "cls", "(", "**", "d", "[", "\"kwargs\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "f\"Setting augmenter: {d['cls_name']}({d['kwargs']})\"", ")", "\n", "", "", "self", ".", "_augmenters", "=", "init_aug", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.augment": [[337, 358], ["RuntimeError", "aug", "TypeError"], "methods", ["None"], ["", "def", "augment", "(", "self", ",", "X", ",", "y", ",", "w", ")", ":", "\n", "        ", "\"\"\"\n        Apply Augmenters in self.augmenters to batch (X, y, w)\n        OBS: Augmenters operate in-place\n\n        Args:\n            X: (ndarray) A batch of data\n            y: (ndarray) A batch of corresponding labels\n            w: (ndarray) A batch of weights associated to each sample in (X, y)\n\n        Returns:\n            None, performs in-place operations\n        \"\"\"", "\n", "if", "not", "self", ".", "augmentation_enabled", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Tried to do augmentation, but \"", "\n", "\"augmentation_enabled is set to 'False'\"", ")", "\n", "", "for", "aug", "in", "self", ".", "augmenters", ":", "\n", "# OBS: in-place operations", "\n", "            ", "a", "=", "aug", "(", "X", ",", "y", ",", "w", ")", "\n", "if", "a", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "\"Output of augmenter {} was not None. Make \"", "\n", "\"sure to implement all augmenters with \"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.scale": [[361, 379], ["enumerate", "input_.reshape.reshape.reshape", "scaled_input.reshape", "psg_utils.preprocessing.scaling.apply_scaling"], "methods", ["None"], ["", "", "", "def", "scale", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Fit and apply scaler 'self.batch_scaler' to batch X\n        Used only when self.batch_scaler is set, typically the entire PSG is\n        scaled before training and this is not used.\n\n        Args:\n            X: (ndarray) A batch of data\n\n        Returns:\n            X (ndarray), scaled batch of data\n        \"\"\"", "\n", "# Loop over batch and scale each element", "\n", "for", "i", ",", "input_", "in", "enumerate", "(", "X", ")", ":", "\n", "            ", "org_shape", "=", "input_", ".", "shape", "\n", "input_", "=", "input_", ".", "reshape", "(", "-", "1", ",", "org_shape", "[", "-", "1", "]", ")", "\n", "scaled_input", "=", "apply_scaling", "(", "input_", ",", "self", ".", "batch_scaler", ")", "[", "0", "]", "\n", "X", "[", "i", "]", "=", "scaled_input", ".", "reshape", "(", "org_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch": [[380, 432], ["numpy.squeeze().astype", "numpy.expand_dims", "len", "numpy.ones", "ValueError", "numpy.expand_dims", "numpy.expand_dims.astype().squeeze", "base_sequence.BaseSequence.scale", "len", "base_sequence.BaseSequence.augment", "isinstance", "isinstance", "numpy.squeeze", "numpy.expand_dims", "numpy.expand_dims", "RuntimeError", "numpy.expand_dims.astype"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalAmplitude.scale", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.augment"], ["", "", "def", "process_batch", "(", "self", ",", "X", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Process a batch (X, y) of sampled data.\n\n        The process_batch method should always be called in the end of any\n        method that implements batch sampling.\n\n        Processing includes:\n          1) Casting of X to ndarray of dtype float32\n          2) Ensures X has a channel dimension, even if self.n_channels == 1\n          3) Ensures y has dtype uint8 and shape [-1, 1]\n          4) Ensures both X and y has a 'batch dimension', even if batch_size\n             is 1.\n          5) If a 'batch_scaler' is set, scales the X data\n          6) Performs augmentation on the batch if self.augmenters is set and\n             self.augmentation_enabled is True\n\n        Args:\n            X:     A list of ndarrays corresponding to a batch of X data\n            y:     A list of ndarrays corresponding to a batch of y labels\n\n        Returns:\n            Batch of (X, y) data\n            OBS: Currently does not return the w (weights) array\n        \"\"\"", "\n", "# Cast and reshape arrays", "\n", "if", "not", "isinstance", "(", "X", ",", "np", ".", "ndarray", ")", "or", "not", "isinstance", "(", "y", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected numpy array inputs.\"", ")", "\n", "", "X", "=", "np", ".", "squeeze", "(", "X", ")", ".", "astype", "(", "Defaults", ".", "PSG_DTYPE", ")", "\n", "\n", "if", "self", ".", "n_channels", "==", "1", ":", "\n", "            ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "-", "1", ")", "\n", "", "y", "=", "np", ".", "expand_dims", "(", "y", ".", "astype", "(", "Defaults", ".", "HYP_DTYPE", ")", ".", "squeeze", "(", ")", ",", "-", "1", ")", "\n", "\n", "expected_dim", "=", "len", "(", "self", ".", "batch_shape", ")", "\n", "if", "X", ".", "ndim", "==", "expected_dim", "-", "1", ":", "\n", "            ", "X", ",", "y", "=", "np", ".", "expand_dims", "(", "X", ",", "0", ")", ",", "np", ".", "expand_dims", "(", "y", ",", "0", ")", "\n", "", "elif", "X", ".", "ndim", "!=", "expected_dim", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Dimensionality of X is {} (shape {}), but \"", "\n", "\"expected {}\"", ".", "format", "(", "X", ".", "ndim", ",", "\n", "X", ".", "shape", ",", "\n", "expected_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "batch_scaler", ":", "\n", "# Scale the batch", "\n", "            ", "self", ".", "scale", "(", "X", ")", "\n", "", "w", "=", "np", ".", "ones", "(", "len", "(", "X", ")", ")", "\n", "if", "self", ".", "augmentation_enabled", ":", "\n", "# Perform augmentation", "\n", "            ", "self", ".", "augment", "(", "X", ",", "y", ",", "w", "=", "w", ")", "\n", "\n", "", "return", "X", ",", "y", "# , w  <- weights currently disabled, fix dice-loss first", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.requires_all_loaded": [[15, 31], ["functools.wraps", "method", "psg_utils.errors.NotLoadedError"], "function", ["None"], ["def", "requires_all_loaded", "(", "method", ")", ":", "\n", "    ", "\"\"\"\n    Decorator for _BaseSequence derived class methods that ensures that all\n    SleepStudies were loaded at init time. Otherwise, a NotLoadedError will\n    be raised.\n\n    OBS: Does not check the current status of loaded objects, but relies on the\n         load check that occurred at init.\n    \"\"\"", "\n", "@", "wraps", "(", "method", ")", "\n", "def", "check_loaded_and_raise", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "all_loaded", ":", "\n", "            ", "raise", "NotLoadedError", "(", "f\"Method '{method.__name__}' requires all stored SleepStudy \"", "\n", "\"objects to be loaded.\"", ")", "\n", "", "return", "method", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "check_loaded_and_raise", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.__init__": [[74, 131], ["batch_sequence._infer_n_classes", "utime.sequences.base_sequence.BaseSequence.__init__", "batch_sequence.BatchSequence.log", "batch_sequence.BatchSequence._assert_scaled"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence._infer_n_classes", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence._assert_scaled"], ["def", "__init__", "(", "self", ",", "\n", "dataset_queue", ",", "\n", "batch_size", ",", "\n", "data_per_period", ",", "\n", "n_classes", ",", "\n", "n_channels", ",", "\n", "margin", "=", "0", ",", "\n", "augmenters", "=", "None", ",", "\n", "batch_scaler", "=", "None", ",", "\n", "no_log", "=", "False", ",", "\n", "scale_assertion", "=", "True", ",", "\n", "require_all_loaded", "=", "True", ",", "\n", "identifier", "=", "\"\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_queue:     (queue)  TODO\n            batch_size:        (int)    The size of each sampled batch\n            data_per_period    (int)    The dimensionality/number of samples\n                                        in each 'period/epoch/segment' of data\n            n_classes:         (int)    Number of classes (sleep stages)\n            n_channels:        (int)    The number of PSG channels to expect in\n                                        data extracted from a SleepStudy object\n            margin             (int)    The margin (number of periods/segments)\n                                        to include down- and up-stream from\n                                        a selected center segment. E.g. a\n                                        margin of 3 will lead to 7 connected\n                                        segments being returned in a sample.\n            augmenters:        (list)   List of utime.augmentation.augmenters\n            batch_scaler:      (string) The name of a sklearn.preprocessing\n                                        Scaler object to apply to each sampled\n                                        batch (optional)\n            no_log:            (bool)   Do not log information on this Sequence\n            identifier:        (string) A string identifier name\n        \"\"\"", "\n", "self", ".", "_inferred", "=", "n_classes", "is", "None", "\n", "n_classes", "=", "_infer_n_classes", "(", "n_classes", ",", "dataset_queue", ")", "\n", "super", "(", ")", ".", "__init__", "(", "identifier", "=", "identifier", ",", "\n", "dataset_queue", "=", "dataset_queue", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "n_channels", "=", "n_channels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "augmenters", "=", "augmenters", ",", "\n", "batch_scaler", "=", "batch_scaler", ",", "\n", "require_all_loaded", "=", "require_all_loaded", ")", "\n", "\n", "self", ".", "_cum_periods_per_pair_minus_margins", "=", "None", "# Set in margin setter", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "data_per_period", "=", "data_per_period", "\n", "\n", "if", "scale_assertion", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_assert_scaled", "(", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "pass", "\n", "", "", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.log": [[132, 135], ["logger.info", "type", "len", "bool"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "\"\"\" Log basic information on this object \"\"\"", "\n", "logger", ".", "info", "(", "f\"[*] BatchSequence initialized{' ({})'.format(self.identifier) if self.identifier else ''}:\\n\"", "\n", "f\"    Data queue type: {type(self.dataset_queue)}\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.total_periods": [[145, 152], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "requires_all_loaded", "\n", "def", "total_periods", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the sum of n_periods across all SleepStudy objects.\n        \"\"\"", "\n", "return", "self", ".", "cum_periods_per_pair", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.total_periods_minus_margins": [[153, 158], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "requires_all_loaded", "\n", "def", "total_periods_minus_margins", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the som of n_periods across all SleepStudy objects \"\"\"", "\n", "return", "self", ".", "cum_periods_per_pair_minus_margins", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.batch_shape": [[159, 167], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the shape of the X output array that will be sampled \"\"\"", "\n", "if", "self", ".", "margin", "==", "0", ":", "\n", "            ", "return", "[", "self", ".", "batch_size", ",", "self", ".", "data_per_period", ",", "self", ".", "n_channels", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "batch_size", ",", "self", ".", "margin", "*", "2", "+", "1", ",", "\n", "self", ".", "data_per_period", ",", "self", ".", "n_channels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.margin": [[173, 189], ["ValueError", "numpy.cumsum"], "methods", ["None"], ["", "@", "margin", ".", "setter", "\n", "def", "margin", "(", "self", ",", "new_margin", ")", ":", "\n", "        ", "\"\"\"\n        Set a new margin\n\n        Args:\n            new_margin: (int) new margin value\n        \"\"\"", "\n", "if", "new_margin", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Margin must be >= 0, got {}\"", ".", "format", "(", "new_margin", ")", ")", "\n", "", "self", ".", "_margin", "=", "new_margin", "\n", "if", "self", ".", "all_loaded", "and", "self", ".", "_cum_periods_per_pair_minus_margins", "is", "not", "None", ":", "\n", "# Compute cum. number of periods per pair minus newly set margin", "\n", "            ", "minus_margin_cum_periods", "=", "np", ".", "cumsum", "(", "self", ".", "periods_per_pair", "-", "\n", "(", "new_margin", "*", "2", ")", ")", "\n", "self", ".", "_cum_periods_per_pair_minus_margins", "=", "minus_margin_cum_periods", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.cum_periods_per_pair_minus_margins": [[190, 197], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "@", "requires_all_loaded", "\n", "def", "cum_periods_per_pair_minus_margins", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the cum. sum of N periods over SleepStudies minus the margins\n        \"\"\"", "\n", "return", "self", ".", "_cum_periods_per_pair_minus_margins", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.__len__": [[198, 205], ["int", "int", "numpy.ceil"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the total number of batches in this dataset \"\"\"", "\n", "if", "self", ".", "all_loaded", "and", "self", ".", "_cum_periods_per_pair_minus_margins", "is", "not", "None", ":", "\n", "            ", "return", "int", "(", "np", ".", "ceil", "(", "self", ".", "total_periods_minus_margins", "/", "self", ".", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "# We don't really know, return some reasonably large number (this number is not really used anyway)", "\n", "            ", "return", "int", "(", "1e6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.__iter__": [[206, 210], ["range", "len", "batch_sequence.BatchSequence.get_batch"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_batch"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Yields the entire dataset in fixed ordered batches \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.__getitem__": [[211, 222], ["batch_sequence.BatchSequence.seed", "batch_sequence.BatchSequence.get_batch", "len"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_batch"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Return a batch of data by overall dataset batch index\n        See self.get_batch for docstring\n        \"\"\"", "\n", "if", "idx", "<", "0", ":", "\n", "# Allow negative indexing", "\n", "            ", "idx", "=", "len", "(", "self", ")", "+", "idx", "\n", "# If multiprocessing, set unique seed for this particular process", "\n", "", "self", ".", "seed", "(", ")", "\n", "return", "self", ".", "get_batch", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_pair_by_id": [[223, 234], ["None"], "methods", ["None"], ["", "def", "get_pair_by_id", "(", "self", ",", "study_id", ")", ":", "\n", "        ", "\"\"\"\n        Return a SleepStudy object by its identifier string\n\n        Args:\n            study_id: String identifier of a specific SleepStudy\n\n        Returns:\n            A stored SleepStudy object\n        \"\"\"", "\n", "return", "self", ".", "id_to_pair", "[", "study_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_single_study_full_seq": [[235, 263], ["batch_sequence.BatchSequence.dataset_queue.get_study_by_id", "ss.get_all_periods", "batch_sequence.BatchSequence.process_batch", "x.reshape.reshape.reshape", "y.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch"], ["", "def", "get_single_study_full_seq", "(", "self", ",", "study_id", ",", "reshape", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return all periods/epochs/segments of data (X, y) of a SleepStudy.\n        Differs only from 'SleepStudy.get_all_periods' in that the batch is\n        processed and thus may be scaled and/or augmented.\n\n        Args:\n            study_id: A string identifier matching a single SleepStudy object\n            reshape:  TODO\n\n        Returns:\n            X: ndarray of PSG data, shape [-1, data_per_period, n_channels]\n            y: ndarray of labels, shape [-1, 1]\n        \"\"\"", "\n", "with", "self", ".", "dataset_queue", ".", "get_study_by_id", "(", "study_id", ")", "as", "ss", ":", "\n", "            ", "x", ",", "y", "=", "ss", ".", "get_all_periods", "(", ")", "\n", "if", "reshape", ":", "\n", "# x is shape [-1, data_per_period, n_channels]", "\n", "# reshape to [-1, seq_length, data_per_period, n_channels]", "\n", "                ", "shape", "=", "[", "-", "1", "]", "+", "self", ".", "batch_shape", "[", "1", ":", "]", "\n", "border", "=", "x", ".", "shape", "[", "0", "]", "%", "shape", "[", "1", "]", "\n", "if", "border", ":", "\n", "# OBS: We remove border if needed", "\n", "                    ", "x", "=", "x", "[", ":", "-", "border", "]", "\n", "y", "=", "y", "[", ":", "-", "border", "]", "\n", "", "x", "=", "x", ".", "reshape", "(", "shape", ")", "\n", "y", "=", "y", ".", "reshape", "(", "shape", "[", ":", "2", "]", "+", "[", "1", "]", ")", "\n", "", "return", "self", ".", "process_batch", "(", "x", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.single_study_seq_generator": [[264, 303], ["ValueError", "batch_sequence.BatchSequence.dataset_queue.get_study_by_id", "ss.to_batch_generator", "batch_sequence.BatchSequence.get_batch_shapes", "batch_wrapper", "batch_sequence.BatchSequence.process_batch"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_batch_shapes", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.batch_wrapper", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch"], ["", "", "def", "single_study_seq_generator", "(", "self", ",", "study_id", ",", "margin", "=", "None", ",", "\n", "overlapping", "=", "True", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Yields single (batch-size 1) sequence elements (margin > 0) from a\n        SleepStudy object of identifier 'study_id'. A margin may be passed,\n        otherwise the set self.margin property is used. One of the two must be\n        set. A batch_size may be set, otherwise uses the self.batch_size\n        property.\n\n        Args:\n            study_id:     A string identifier matching a single SleepStudy obj.\n            margin:       Optional value to use for margin instead of self.margin\n            overlapping:  Yield overlapping batches (sliding window). Otherwise\n                          return non-overlapping, connected segments.\n            batch_size:   Optional value to use for batch_size instead of\n                          self.batch_size\n\n        Yields:\n            X: ndarray of PSG data,\n               shape [1, 2*margin+1, data_per_period, n_channels]\n            y: ndarray of labels, shape [1, 2*margin+1, 1]\n        \"\"\"", "\n", "margin", "=", "margin", "or", "self", ".", "margin", "\n", "if", "not", "margin", ":", "\n", "            ", "raise", "ValueError", "(", "\"Must set the self.margin property or pass a \"", "\n", "\"margin to the 'single_study_seq_generator' \"", "\n", "\"function. Consider using the \"", "\n", "\"'single_study_batch_generator' function.\"", ")", "\n", "", "from", "utime", ".", "sequences", "import", "batch_wrapper", "\n", "seq_length", "=", "margin", "*", "2", "+", "1", "\n", "with", "self", ".", "dataset_queue", ".", "get_study_by_id", "(", "study_id", ")", "as", "ss", ":", "\n", "            ", "sequence_generator", "=", "ss", ".", "to_batch_generator", "(", "batch_size", "=", "seq_length", ",", "\n", "overlapping", "=", "overlapping", ")", "\n", "shapes", "=", "self", ".", "get_batch_shapes", "(", "batch_size", ")", "\n", "for", "X", ",", "y", "in", "batch_wrapper", "(", "sequence_generator", ",", "*", "shapes", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "yield", "self", ".", "process_batch", "(", "X", ",", "y", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                    ", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.single_study_batch_generator": [[304, 329], ["ValueError", "batch_sequence.BatchSequence.dataset_queue.get_study_by_id", "ss.to_batch_generator", "batch_sequence.BatchSequence.process_batch"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch"], ["", "", "", "", "def", "single_study_batch_generator", "(", "self", ",", "study_id", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Yield batches of data from a single SleepStudy object. A batch_size may\n        be set, otherwise uses the self.batch_size property.\n\n        Cannot be used with the self.margin property set.\n\n        Args:\n            study_id:   A string identifier matching a single SleepStudy obj.\n            batch_size: Optional value to use for batch_size instead of\n                        self.batch_size\n\n        Yields:\n            X: ndarray of PSG data,\n               shape [batch_size, data_per_period, n_channels]\n            y: ndarray of labels, shape [batch_size, 1]\n        \"\"\"", "\n", "if", "self", ".", "margin", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use 'single_study_batch_generator' with \"", "\n", "\"self.margin set. Consider using \"", "\n", "\"'single_study_seq_generator' instead.\"", ")", "\n", "", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "with", "self", ".", "dataset_queue", ".", "get_study_by_id", "(", "study_id", ")", "as", "ss", ":", "\n", "            ", "for", "batch", "in", "ss", ".", "to_batch_generator", "(", "batch_size", "=", "batch_size", ")", ":", "\n", "                ", "yield", "self", ".", "process_batch", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_period": [[330, 375], ["sleep_study.get_periods_by_idx", "batch_sequence._check_margin", "psg_utils.errors.MarginError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence._check_margin"], ["", "", "", "def", "get_period", "(", "self", ",", "sleep_study", ",", "period_idx", ",", "allow_shift_at_border", "=", "True", ",", "\n", "return_shifted_idx", "=", "False", ",", "margin", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return period with index 'period_idx' of SleepStudy 'sleep_study'.\n        If self.margin > 0 a sequence will be returned with the period at\n        period_idx in the center. The upper or lower tails of such sequence may\n        extend beyond the boarders of the total sequence. If\n        allow_shift_at_border is set to True, get_period will return the\n        nearest sequence of the same length that fits within the full sequence\n        (the center will be shifted by the number of periods that were out-of-\n        bounds with the original index).\n\n        Args:\n            sleep_study:           A SleepStudy obj.\n            period_idx:            The period/segment/epoch index within the\n                                   SleepStudy to return\n            allow_shift_at_border: Allow shifting of the index if margin > 0\n                                   makes the sequence extend beyond the PSG\n                                   boundaries\n            return_shifted_idx:    Return the index to which the center was\n                                   shifted (if not shifted, equal to input\n                                   'period_idx'\n            margin:                Optional value to use for margin instead of\n                                   self.margin\n\n        Returns:\n            X, ndarray of shape [margin*2+1, data_per_period, n_channels]\n            y, ndarray of shape [margin*2+1, 1] class labels\n        \"\"\"", "\n", "margin", "=", "margin", "or", "self", ".", "margin", "\n", "n_periods", "=", "sleep_study", ".", "n_periods", "\n", "try", ":", "\n", "            ", "_check_margin", "(", "n_periods", ",", "margin", ",", "at_idx", "=", "period_idx", ")", "\n", "", "except", "MarginError", "as", "e", ":", "\n", "            ", "if", "allow_shift_at_border", ":", "\n", "                ", "period_idx", "+=", "e", ".", "shift", "\n", "", "else", ":", "\n", "                ", "raise", "MarginError", "(", "\"Margin error with \"", "\n", "\"'allow_shift_at_border=False'\"", ")", "from", "e", "\n", "", "", "Xs", ",", "ys", "=", "sleep_study", ".", "get_periods_by_idx", "(", "start_idx", "=", "period_idx", "-", "margin", ",", "\n", "end_idx", "=", "period_idx", "+", "margin", ")", "\n", "if", "return_shifted_idx", ":", "\n", "            ", "return", "Xs", ",", "ys", ",", "period_idx", "\n", "", "else", ":", "\n", "            ", "return", "Xs", ",", "ys", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence._get_periods_in_range": [[376, 390], ["range", "batch_sequence.BatchSequence.get_period", "X.append", "y.append"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_period"], ["", "", "def", "_get_periods_in_range", "(", "self", ",", "sleep_study", ",", "start", ",", "end", ")", ":", "\n", "        ", "\"\"\"\n        Helper method for the self.get_batch method.\n        Returns a list of periods with indices in [start, ..., end-1] using\n        self.get_period from SleepStudy 'sleep_study'\n\n        See self.get_batch docstring.\n        \"\"\"", "\n", "X", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "for", "period_idx", "in", "range", "(", "start", ",", "end", ")", ":", "\n", "            ", "X_", ",", "y_", "=", "self", ".", "get_period", "(", "sleep_study", ",", "period_idx", ",", "\n", "allow_shift_at_border", "=", "False", ")", "\n", "X", ".", "append", "(", "X_", ")", ",", "y", ".", "append", "(", "y_", ")", "\n", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_batch": [[391, 453], ["batch_sequence.BatchSequence.get_empty_batch_arrays", "numpy.searchsorted", "batch_sequence.BatchSequence.process_batch", "batch_sequence.BatchSequence.dataset_queue.get_study_by_idx", "abs", "batch_sequence.BatchSequence._get_periods_in_range", "min", "len", "batch_sequence.BatchSequence.dataset_queue.get_study_by_idx", "batch_sequence.BatchSequence._get_periods_in_range", "len", "len", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_empty_batch_arrays", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence._get_periods_in_range", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence._get_periods_in_range"], ["", "@", "requires_all_loaded", "\n", "def", "get_batch", "(", "self", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"\n        Return a batch of data index by overall batch index across the dataset.\n        The order of the stored SleepStudy pairs is assumed fixed.\n\n        Note that the final batch may be smaller than self.batch_size due to\n        boundary effects.\n\n        Args:\n            batch_idx: Overall batch index across the stored SleepStudy objects\n\n        Returns:\n            X: A batch of PSG data, ndarray of shape\n               [batch_size, margin*2+1, data_per_period, n_channels] if margin\n               else [batch_size, data_per_period, n_channels]\n            y: A batch of label values, ndarray of shape\n               [batch_size, margin*2+1, 1] if margin, else\n               [batch_size, 1]\n        \"\"\"", "\n", "X", ",", "y", "=", "self", ".", "get_empty_batch_arrays", "(", ")", "\n", "\n", "# batch_idx is the batch number. We first find the total period index", "\n", "# at which we should start sampling", "\n", "global_period_start", "=", "batch_idx", "*", "self", ".", "batch_size", "\n", "\n", "# Find the SleepStudy object in which the given period occurs", "\n", "study_idx", "=", "np", ".", "searchsorted", "(", "self", ".", "cum_periods_per_pair_minus_margins", ",", "\n", "1", "+", "global_period_start", ")", "\n", "with", "self", ".", "dataset_queue", ".", "get_study_by_idx", "(", "study_idx", ")", "as", "sleep_study", ":", "\n", "            ", "if", "study_idx", ">", "0", ":", "\n", "                ", "previous_periods", "=", "self", ".", "cum_periods_per_pair_minus_margins", "[", "study_idx", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "previous_periods", "=", "0", "\n", "\n", "# Get the number of periods to sample in the given pair", "\n", "", "local_period_start", "=", "global_period_start", "-", "previous_periods", "+", "self", ".", "margin", "\n", "local_period_end", "=", "local_period_start", "+", "self", ".", "batch_size", "\n", "\n", "# Get number of periods that span into the next pair", "\n", "max_", "=", "sleep_study", ".", "n_periods", "-", "self", ".", "margin", "\n", "periods_in_next_ss", "=", "abs", "(", "min", "(", "max_", "-", "local_period_end", ",", "0", ")", ")", "\n", "local_period_end", "-=", "periods_in_next_ss", "\n", "\n", "# Get all periods in the current SS", "\n", "xx", ",", "yy", "=", "self", ".", "_get_periods_in_range", "(", "sleep_study", ",", "\n", "local_period_start", ",", "\n", "local_period_end", ")", "\n", "X", "[", "len", "(", "xx", ")", "]", "=", "xx", "\n", "y", "[", "len", "(", "yy", ")", "]", "=", "yy", "\n", "\n", "", "if", "periods_in_next_ss", "and", "len", "(", "self", ".", "dataset_queue", ")", ">", "study_idx", "+", "1", ":", "\n", "            ", "with", "self", ".", "dataset_queue", ".", "get_study_by_idx", "(", "study_idx", "+", "1", ")", "as", "next_sleep_study", ":", "\n", "                ", "if", "periods_in_next_ss", ">", "next_sleep_study", ".", "n_periods", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"Batch spans three SleepPairs. \"", "\n", "\"Handling this situation is not \"", "\n", "\"yet implemented.\"", ")", "\n", "", "xx", ",", "yy", "=", "self", ".", "_get_periods_in_range", "(", "sleep_study", ",", "self", ".", "margin", ",", "\n", "self", ".", "margin", "+", "periods_in_next_ss", ")", "\n", "X", "[", "-", "periods_in_next_ss", ":", "]", "=", "xx", "\n", "y", "[", "-", "periods_in_next_ss", ":", "]", "=", "yy", "\n", "", "", "return", "self", ".", "process_batch", "(", "X", ",", "y", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence._infer_n_classes": [[16, 26], ["int", "queue.get_random_study"], "function", ["None"], ["def", "_infer_n_classes", "(", "n_classes", ",", "queue", ")", ":", "\n", "    ", "\"\"\"\n    Helper function for inferring the n_classes parameter from a list of\n    SleepStudy pairs\n    \"\"\"", "\n", "if", "n_classes", "is", "not", "None", ":", "\n", "        ", "return", "int", "(", "n_classes", ")", "\n", "", "else", ":", "\n", "        ", "with", "queue", ".", "get_random_study", "(", ")", "as", "ss", ":", "\n", "            ", "return", "ss", ".", "n_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence._check_margin": [[28, 59], ["isinstance", "ValueError", "ValueError", "ValueError", "psg_utils.errors.MarginError", "psg_utils.errors.MarginError", "type"], "function", ["None"], ["", "", "", "def", "_check_margin", "(", "n_periods", ",", "margin", ",", "at_idx", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Helper function for sampling batches with BatchSequence(margin > 0).\n\n    Args:\n        n_periods:\n        margin:\n        at_idx:\n\n    Returns:\n\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "margin", ",", "int", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Margin must be an integer. Got '{}'\"", ".", "format", "(", "type", "(", "margin", ")", ")", ")", "\n", "", "if", "margin", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Margin must be a non-negative integer, got {}\"", ".", "format", "(", "margin", ")", ")", "\n", "# Check margin is not too large", "\n", "", "if", "margin", ">", "(", "n_periods", "-", "1", ")", "//", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Margin too large for dataset length.\"", ")", "\n", "", "if", "at_idx", "is", "not", "None", ":", "\n", "        ", "if", "margin", ">", "at_idx", ":", "\n", "            ", "raise", "MarginError", "(", "\"Margin of {} too large at period idx {} (extends\"", "\n", "\" to negative indices)\"", ".", "format", "(", "margin", ",", "at_idx", ")", ",", "\n", "shift", "=", "margin", "-", "at_idx", ")", "\n", "", "if", "margin", "+", "at_idx", ">=", "n_periods", ":", "\n", "            ", "raise", "MarginError", "(", "\"Margin of {} too large at period idx {} (extends\"", "\n", "\" to index >= to total number of periods\"", "\n", "\" ({}))\"", ".", "format", "(", "margin", ",", "at_idx", ",", "n_periods", ")", ",", "\n", "shift", "=", "n_periods", "-", "(", "margin", "+", "at_idx", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.__init__": [[21, 51], ["utime.sequences.BatchSequence.__init__", "random_batch_sequence.RandomBatchSequence.log"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log"], ["def", "__init__", "(", "self", ",", "\n", "dataset_queue", ",", "\n", "batch_size", ",", "\n", "data_per_period", ",", "\n", "n_classes", ",", "\n", "n_channels", ",", "\n", "margin", "=", "0", ",", "\n", "augmenters", "=", "None", ",", "\n", "batch_scaler", "=", "None", ",", "\n", "no_log", "=", "False", ",", "\n", "identifier", "=", "\"\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        See BatchSequence docstring for argument descriptions\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "dataset_queue", "=", "dataset_queue", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "data_per_period", "=", "data_per_period", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "n_channels", "=", "n_channels", ",", "\n", "margin", "=", "margin", ",", "\n", "augmenters", "=", "augmenters", ",", "\n", "batch_scaler", "=", "batch_scaler", ",", "\n", "no_log", "=", "True", ",", "\n", "scale_assertion", "=", "True", ",", "\n", "identifier", "=", "identifier", ",", "\n", "require_all_loaded", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.log": [[52, 55], ["logger.info", "type", "len", "bool"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "\"\"\" Log basic information on this object \"\"\"", "\n", "logger", ".", "info", "(", "f\"\\n[*] RandomBatchSequence initialized{' ({})'.format(self.identifier) if self.identifier else ''}:\\n\"", "\n", "f\"    Data queue type: {type(self.dataset_queue)}\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.__getitem__": [[65, 73], ["random_batch_sequence.RandomBatchSequence.seed", "random_batch_sequence.RandomBatchSequence.get_random_batch"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.seed", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.get_random_batch"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Return a random batch of data\n        See self.get_random_batch for docstring\n        \"\"\"", "\n", "# If multiprocessing, set unique seed for this particular process", "\n", "self", ".", "seed", "(", ")", "\n", "return", "self", ".", "get_random_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.get_random_period": [[74, 93], ["random_batch_sequence.RandomBatchSequence.dataset_queue.get_random_study", "int", "random_batch_sequence.RandomBatchSequence.get_period", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_period"], ["", "def", "get_random_period", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sample a random 'period/epoch/segment' of data from a (uniformly)\n        random SleepStudy object in self.pairs.\n\n        With self.margin > 0 multiple, connected periods is returned in a\n        single call.\n\n        Returns:\n            X, ndarray of shape [margin*2+1, data_per_period, n_channels]\n            y, ndarray of shape [margin*2+1, 1] class labels\n        \"\"\"", "\n", "with", "self", ".", "dataset_queue", ".", "get_random_study", "(", ")", "as", "sleep_study", ":", "\n", "# Get random period idx", "\n", "            ", "n_periods", "=", "sleep_study", ".", "n_periods", "\n", "period_idx", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "n_periods", ",", "1", ")", ")", "\n", "return", "self", ".", "get_period", "(", "sleep_study", "=", "sleep_study", ",", "\n", "period_idx", "=", "period_idx", ",", "\n", "allow_shift_at_border", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.get_random_batch": [[94, 112], ["random_batch_sequence.RandomBatchSequence.get_empty_batch_arrays", "range", "random_batch_sequence.RandomBatchSequence.process_batch", "random_batch_sequence.RandomBatchSequence.get_random_period"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence._BaseSequence.get_empty_batch_arrays", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.process_batch", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.random_batch_sequence.RandomBatchSequence.get_random_period"], ["", "", "def", "get_random_batch", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a batch of data sampled randomly across SleepStudy pairs.\n\n        Returns:\n            X, float32 ndarray, batch of input data,\n               shape [batch_size, data_per_prediction, n_channels] if margin=0\n               else [batch_size, margin*2+1, data_per_prediction, n_channels]\n            y, uint8 ndarray, batch of integer target values,\n               shape [batch_size, 1] if margin=0\n               else [batch_size, margin*2+1, 1]\n        \"\"\"", "\n", "X", ",", "y", "=", "self", ".", "get_empty_batch_arrays", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_size", ")", ":", "\n", "            ", "xx", ",", "yy", "=", "self", ".", "get_random_period", "(", ")", "\n", "X", "[", "i", "]", "=", "xx", "\n", "y", "[", "i", "]", "=", "yy", "\n", "", "return", "self", ".", "process_batch", "(", "X", ",", "y", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.batch_wrapper": [[10, 29], ["numpy.empty", "numpy.empty", "enumerate", "x_batch[].copy", "y_batch[].copy", "np.empty.copy", "np.empty.copy"], "function", ["None"], ["def", "create_folders", "(", "folders", ",", "create_deep", "=", "False", ")", ":", "\n", "    ", "def", "safe_make", "(", "path", ",", "make_func", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "make_func", "(", "path", ")", "\n", "", "except", "FileExistsError", ":", "\n", "# If running many jobs in parallel this may occur", "\n", "            ", "pass", "\n", "", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f", ")", ":", "\n", "                ", "safe_make", "(", "f", ",", "make_func", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_sequence_class": [[31, 56], ["ValueError"], "function", ["None"], ["    ", "for", "list_", "in", "list_of_lists", ":", "\n", "        ", "if", "isinstance", "(", "list_", ",", "Iterable", ")", "and", "not", "isinstance", "(", "list_", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n", "\n", "", "", "", "def", "highlighted", "(", "string", ")", ":", "\n", "    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n", "\n", "", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "if", "isinstance", "(", "pids", ",", "str", ")", ":", "\n", "        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n", "\n", "", "", "def", "wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.infer_dpe_and_chans": [[58, 61], ["dataset_queue.get_random_study"], "function", ["None"], ["        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pid", "=", "int", "(", "pid", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_batch_sequence": [[63, 100], ["utils.infer_dpe_and_chans", "utils.get_sequence_class", "get_sequence_class."], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.infer_dpe_and_chans", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_sequence_class"], ["            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n", "", "", "_wait_for", "(", "pid", ",", "check_every", ")", "\n", "\n", "\n", "", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "still_running", "=", "True", "\n", "logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "try", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "(", "\"grep\"", ",", "f\"{pid}\"", ")", ",", "stdin", "=", "ps", ".", "stdout", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "output", "=", "False", "\n", "", "ps", ".", "wait", "(", ")", "\n", "still_running", "=", "bool", "(", "output", ")", "\n", "if", "still_running", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Process {pid} still running... (sleeping {check_every} seconds)\"", ")", "\n", "time", ".", "sleep", "(", "check_every", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.get_argparser": [[25, 91], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Prepare a data folder for a\"", "\n", "\"CV experiment setup.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to data directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--subject_dir_pattern\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Glob-like pattern used to select subject folders\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--CV\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Number of splits (default=5)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"views\"", ",", "\n", "help", "=", "\"Directory to store CV subfolders \"", "\n", "\"(default=views\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--copy\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Copy files to CV-subfolders instead of \"", "\n", "\"symlinking (not recommended)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_list\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Create text files with paths pointing to the \"", "\n", "\"files needed under each split instead of \"", "\n", "\"symlink/copying. This is usefull on systems \"", "\n", "\"were symlink is not supported, but the dataset \"", "\n", "\"size is too large to store in copies. \"", "\n", "\"NOTE: Only one of --copy and --file_list \"", "\n", "\"flags must be set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation_fraction\"", ",", "type", "=", "float", ",", "\n", "default", "=", "_DEFAULT_VAL_FRACTION", ",", "\n", "help", "=", "\"Fraction of OVERALL data size used for \"", "\n", "\"validation in each split. In a 5-CV setting with\"", "\n", "\" N=100 and val_frac=0.20, each split will have \"", "\n", "\"N_train=60, N_val=20 and N_test=20 \"", "\n", "\"subjects/records (default={})\"", ".", "format", "(", "_DEFAULT_VAL_FRACTION", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_validation_subjects\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "\"(Optional) specify a maximum number of subjects\"", "\n", "\" to use for validation. That is, only up to \"", "\n", "\"'max_validation_subjects' number of subjects \"", "\n", "\"will be used, even if 'validation_fraction' \"", "\n", "\"dictates a larger number should be used.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_fraction\"", ",", "type", "=", "float", ",", "\n", "default", "=", "_DEFAULT_TEST_FRACTION", ",", "\n", "help", "=", "\"Fraction of data size used for test if CV=1. \"", "\n", "\"(default={})\"", ".", "format", "(", "_DEFAULT_TEST_FRACTION", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_test_subjects\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "\"(Optional) specify a maximum number of subjects\"", "\n", "\" to use for testing. That is, only up to \"", "\n", "\"'max_test_subjects' number of subjects \"", "\n", "\"will be used, even if 'test_fraction' \"", "\n", "\"dictates a larger number should be used.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--subject_matching_regex\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"If specified, files of identical sub-strings as \"", "\n", "\"matched by the regular expression \"", "\n", "\"'subject_matching_regex' will be considered a \"", "\n", "\"single entry when splitting. This is useful for \"", "\n", "\"splitting multiple studies on the same subject \"", "\n", "\"as together.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite existing log files (see --log_file). \"", "\n", "\"This flag does NOT tell the script to overwrite an existing folder \"", "\n", "\"at --out_dir, such folder must be manually deleted if intended.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.assert_dir_structure": [[93, 99], ["os.path.exists", "os.path.exists", "OSError", "OSError"], "function", ["None"], ["", "def", "assert_dir_structure", "(", "data_dir", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\" Asserts that the data_dir exists and the out_dir does not \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_dir", ")", ":", "\n", "        ", "raise", "OSError", "(", "\"Invalid data directory '%s'. Does not exist.\"", "%", "data_dir", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "raise", "OSError", "(", "\"Output directory at '%s' already exists.\"", "%", "out_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.create_view_folders": [[101, 114], ["os.path.exists", "logger.info", "os.makedirs", "range", "os.path.join", "logger.info", "os.mkdir"], "function", ["None"], ["", "", "def", "create_view_folders", "(", "out_dir", ",", "n_splits", ")", ":", "\n", "    ", "\"\"\"\n    Helper function that creates a set of 'split_0', 'split_1'..., folders\n    within a directory 'out_dir'. If n_splits == 1, only creates the out_dir.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating directory at %s\"", "%", "out_dir", ")", "\n", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "if", "n_splits", ">", "1", ":", "\n", "        ", "for", "i", "in", "range", "(", "n_splits", ")", ":", "\n", "            ", "split_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"split_%i\"", "%", "i", ")", "\n", "logger", ".", "info", "(", "\"Creating directory at %s\"", "%", "split_dir", ")", "\n", "os", ".", "mkdir", "(", "split_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.add_files": [[116, 139], ["isinstance", "os.path.relpath", "link_func", "os.path.split", "str"], "function", ["None"], ["", "", "", "def", "add_files", "(", "file_paths", ",", "out_folder", ",", "link_func", "=", "os", ".", "symlink", ")", ":", "\n", "    ", "\"\"\"\n    Add all files pointed to by paths in list 'file_paths' to folder\n    'out_folder' using the linking/copy function 'link_func'.\n\n    Args:\n        file_paths: A list of file paths\n        out_folder: A path to a directory that should store the linked files\n        link_func:  A function to apply on relative file paths in 'file_paths'\n                    and absolute paths in 'file_paths'.\n                    Typically one of os.symlink, os.copy or\n                    _add_to_file_list_fallback.\n    \"\"\"", "\n", "n_records", "=", "0", "\n", "for", "file_path", "in", "file_paths", ":", "\n", "        ", "if", "not", "isinstance", "(", "file_path", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "file_path", "=", "(", "file_path", ",", ")", "\n", "", "for", "path", "in", "file_path", ":", "\n", "            ", "file_name", "=", "os", ".", "path", ".", "split", "(", "str", "(", "path", ")", ")", "[", "-", "1", "]", "\n", "rel_path", "=", "os", ".", "path", ".", "relpath", "(", "path", ",", "out_folder", ")", "\n", "link_func", "(", "rel_path", ",", "out_folder", "+", "\"/%s\"", "%", "file_name", ")", "\n", "n_records", "+=", "1", "\n", "", "", "return", "n_records", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split._add_to_file_list_fallback": [[141, 172], ["os.chdir", "os.path.abspath", "os.path.join", "os.path.split", "open", "out_f.write"], "function", ["None"], ["", "def", "_add_to_file_list_fallback", "(", "rel_file_path", ",", "\n", "file_path", ",", "\n", "fname", "=", "\"LIST_OF_FILES.txt\"", ")", ":", "\n", "\n", "    ", "\"\"\"\n    On some system symlinks are not supported, if --files_list flag is set,\n    uses this function to add each absolute file path to a list at the final\n    subfolder that is supposed to store symlinks or actual files (--copy)\n\n    At run-time, these files must be loaded by reading the path from this\n    file instead.\n\n    Args:\n        rel_file_path: (string) Relative path pointing to the file from the\n                                current working directory.\n        file_path:     (string) Absolute path to the file\n        fname:         (string) Filename of the file to store the paths\n    \"\"\"", "\n", "# Get folder where list of files should be stored", "\n", "folder", "=", "os", ".", "path", ".", "split", "(", "file_path", ")", "[", "0", "]", "\n", "\n", "# Get absolute path to file", "\n", "# We change dir to get the correct abs path from the relative", "\n", "os", ".", "chdir", "(", "folder", ")", "\n", "abs_file_path", "=", "os", ".", "path", ".", "abspath", "(", "rel_file_path", ")", "\n", "\n", "# Get path to the list of files", "\n", "list_file_path", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "fname", ")", "\n", "\n", "with", "open", "(", "list_file_path", ",", "\"a\"", ")", "as", "out_f", ":", "\n", "        ", "out_f", ".", "write", "(", "abs_file_path", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.pair_by_names": [[174, 216], ["re.compile", "defaultdict", "enumerate", "defaultdict.values", "inds[].append", "tuple", "re.findall", "names.append", "os.path.split", "len", "ValueError", "os.path.splitext", "numpy.array", "len", "os.path.split"], "function", ["None"], ["", "", "def", "pair_by_names", "(", "files", ",", "subject_matching_regex", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Takes a list of file names and returns a list of tuples of file names in\n    the list that share substrings matches by the regular expression\n    'subject_matching_regex'. The regex should match to 1 group in each file.\n\n    That is, a list of files ['FILE_1_1', 'FILE_1_2', 'FILE_2_1'] and\n    subject_matching_regex \".*?_(\\d+).*\" will result in:\n\n       [ ('FILE_1_1', 'FILE_1_2') , ('FILE_2_1',) ]\n\n    Args:\n        files:                  (list) A list of filenames\n        subject_matching_regex: (str)  A regex string that that matches exactly\n                                       one group (sub-string) within all file\n                                       names in 'files'. Paring will be made\n                                       based on these sub-strings.\n\n    Returns:\n        A list of tuples of paired filenames\n    \"\"\"", "\n", "from", "collections", "import", "defaultdict", "\n", "regex", "=", "re", ".", "compile", "(", "subject_matching_regex", ")", "\n", "if", "subject_matching_regex", "is", "not", "None", ":", "\n", "        ", "names", "=", "[", "]", "\n", "for", "f_path", "in", "files", ":", "\n", "            ", "f_path", "=", "os", ".", "path", ".", "split", "(", "f_path", ")", "[", "-", "1", "]", "# Split just in case full paths", "\n", "matches", "=", "re", ".", "findall", "(", "regex", ",", "f_path", ")", "\n", "if", "len", "(", "matches", ")", "!=", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"'subject_matching_regex' of {} matched {} \"", "\n", "\"substrings ({}) within filename {}, \"", "\n", "\"expected 1.\"", ".", "format", "(", "subject_matching_regex", ",", "\n", "len", "(", "matches", ")", ",", "\n", "matches", ",", "f_path", ")", ")", "\n", "", "names", ".", "append", "(", "matches", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "names", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "i", ")", "[", "-", "1", "]", ")", "[", "0", "]", "for", "i", "in", "files", "]", "\n", "", "inds", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "names", ")", ":", "\n", "        ", "inds", "[", "item", "]", ".", "append", "(", "i", ")", "\n", "", "pairs", "=", "inds", ".", "values", "(", ")", "\n", "return", "[", "tuple", "(", "np", ".", "array", "(", "files", ")", "[", "i", "]", ")", "for", "i", "in", "pairs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.get_split_sizes": [[218, 251], ["len", "int", "int", "int", "min", "numpy.ceil", "min", "ValueError", "numpy.ceil", "numpy.ceil"], "function", ["None"], ["", "def", "get_split_sizes", "(", "subject_dirs", ",", "n_splits", ",", "args", ")", ":", "\n", "    ", "\"\"\"\n    Returns the number of samples to include in the training, validation and\n    testing sub-sets in each split given the parsed arguments (see argparser)\n\n    Also prints the results to screen.\n\n    Args:\n        subject_dirs: (list)   List of all subject dirs in the dataset\n        n_splits:     (int)    Number of splits to perform\n        args:         (tuple)  Arguments passed, see argparser.\n        desc:         (string) A string describing whether each entity in\n                               'subject_dirs' is a 'subject' or 'record'.\n\n    Returns:\n        3 ints, number of training-, validation- and testing samples for each\n        split.\n    \"\"\"", "\n", "n_total", "=", "len", "(", "subject_dirs", ")", "\n", "if", "n_splits", ">", "1", ":", "\n", "        ", "n_test", "=", "int", "(", "np", ".", "ceil", "(", "n_total", "/", "n_splits", ")", ")", "\n", "", "else", ":", "\n", "        ", "n_test", "=", "int", "(", "np", ".", "ceil", "(", "n_total", "*", "args", ".", "test_fraction", ")", ")", "\n", "", "if", "args", ".", "max_test_subjects", ":", "\n", "        ", "n_test", "=", "min", "(", "n_test", ",", "args", ".", "max_test_subjects", ")", "\n", "", "n_val", "=", "int", "(", "np", ".", "ceil", "(", "n_total", "*", "args", ".", "validation_fraction", ")", ")", "\n", "if", "args", ".", "max_validation_subjects", ":", "\n", "        ", "n_val", "=", "min", "(", "n_val", ",", "args", ".", "max_validation_subjects", ")", "\n", "", "if", "n_val", "+", "n_test", ">=", "n_total", ":", "\n", "        ", "raise", "ValueError", "(", "\"Too large test/validation_fraction - \"", "\n", "\"No training samples left!\"", ")", "\n", "", "n_train", "=", "n_total", "-", "n_test", "-", "n_val", "\n", "return", "n_train", ",", "n_val", ",", "n_test", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.run_on_split": [[253, 301], ["os.path.join", "os.path.join", "utime.utils.create_folders", "random.shuffle", "cv_split.add_files", "cv_split.add_files", "os.path.join", "cv_split.add_files"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.create_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.add_files", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.add_files", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.add_files"], ["", "def", "run_on_split", "(", "split_path", ",", "test_split", ",", "train_val_data", ",", "n_val", ",", "args", ")", ":", "\n", "    ", "\"\"\"\n    Add the train/val/test files of a single split to the split directories\n\n    Depending on the arguments parsed (--copy, --file_list etc.) either copies,\n    symlinks or creates a LIST_OF_FILES.txt file of absolute paths in each\n    split sub-directory.\n\n    Args:\n        split_path:      (string) Path to the split directory\n        test_split:      (list)   List of paths pointing to split test data\n        train_val_data:  (list)   List of paths pointing to the remaining data\n        n_val:           (int)    Number of samples in 'train_val_data' to use\n                                  for validation - rest is used for training.\n        args:            (tuple)  Parsed arguments, see argparser.\n    \"\"\"", "\n", "# Define train, val and test sub-dirs", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "split_path", ",", "\"train\"", ")", "\n", "val_path", "=", "os", ".", "path", ".", "join", "(", "split_path", ",", "\"val\"", ")", "if", "n_val", "else", "None", "\n", "test_path", "=", "os", ".", "path", ".", "join", "(", "split_path", ",", "\"test\"", ")", "\n", "\n", "# Create folders if not existing", "\n", "create_folders", "(", "[", "train_path", ",", "val_path", ",", "test_path", "]", ")", "\n", "\n", "# Copy or symlink?", "\n", "if", "args", ".", "copy", ":", "\n", "        ", "from", "shutil", "import", "copyfile", "\n", "move_func", "=", "copyfile", "\n", "", "elif", "args", ".", "file_list", ":", "\n", "        ", "move_func", "=", "_add_to_file_list_fallback", "\n", "", "else", ":", "\n", "        ", "move_func", "=", "os", ".", "symlink", "\n", "\n", "# Extract validation data from the remaining", "\n", "", "random", ".", "shuffle", "(", "train_val_data", ")", "\n", "validation", "=", "train_val_data", "[", ":", "n_val", "]", "\n", "training", "=", "train_val_data", "[", "n_val", ":", "]", "\n", "\n", "# Add training", "\n", "train_records", "=", "add_files", "(", "training", ",", "train_path", ",", "move_func", ")", "\n", "# Add test data", "\n", "test_records", "=", "add_files", "(", "test_split", ",", "test_path", ",", "move_func", ")", "\n", "if", "n_val", ":", "\n", "# Add validation", "\n", "        ", "val_records", "=", "add_files", "(", "validation", ",", "val_path", ",", "move_func", ")", "\n", "", "else", ":", "\n", "        ", "val_records", "=", "0", "\n", "", "return", "train_records", ",", "val_records", ",", "test_records", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.run": [[303, 398], ["os.path.abspath", "int", "cv_split.assert_dir_structure", "glob.glob", "cv_split.create_view_folders", "cv_split.get_split_sizes", "random.shuffle", "numpy.array_split", "pandas.DataFrame", "enumerate", "numpy.sum", "logger.info", "os.path.join", "os.path.join", "ValueError", "ValueError", "ValueError", "os.path.join", "logger.info", "cv_split.pair_by_names", "len", "ValueError", "zip", "print", "cv_split.run_on_split", "len", "os.path.join", "len", "numpy.sum", "numpy.sum", "range", "enumerate", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.assert_dir_structure", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.create_view_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.get_split_sizes", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.pair_by_names", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.run_on_split"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run the script according to 'args' - Please refer to the argparser.\n    \"\"\"", "\n", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "data_dir", ")", "\n", "n_splits", "=", "int", "(", "args", ".", "CV", ")", "\n", "if", "n_splits", ">", "1", ":", "\n", "        ", "out_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "args", ".", "out_dir", ",", "\"%i_CV\"", "%", "n_splits", ")", "\n", "", "else", ":", "\n", "        ", "out_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "args", ".", "out_dir", ",", "\"fixed_split\"", ")", "\n", "\n", "", "if", "n_splits", "==", "1", "and", "not", "args", ".", "test_fraction", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must specify --test_fraction with --CV=1.\"", ")", "\n", "", "if", "args", ".", "copy", "and", "args", ".", "file_list", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only one of --copy and --file_list \"", "\n", "\"flags must be set.\"", ")", "\n", "", "if", "(", "args", ".", "test_fraction", "!=", "_DEFAULT_TEST_FRACTION", ")", "and", "(", "args", ".", "CV", ">", "1", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Should not set --test_fraction with --CV > 1\"", ")", "\n", "\n", "# Assert suitable folders", "\n", "", "assert_dir_structure", "(", "data_dir", ",", "out_dir", ")", "\n", "\n", "# Get subject dirs", "\n", "subject_dirs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "args", ".", "subject_dir_pattern", ")", ")", "\n", "\n", "# Create sub-folders", "\n", "create_view_folders", "(", "out_dir", ",", "n_splits", ")", "\n", "\n", "if", "args", ".", "subject_matching_regex", ":", "\n", "        ", "logger", ".", "info", "(", "f\"OBS: Pairing files based on regex {args.subject_matching_regex}\"", ")", "\n", "subject_dirs", "=", "pair_by_names", "(", "subject_dirs", ",", "args", ".", "subject_matching_regex", ")", "\n", "\n", "", "if", "n_splits", ">", "len", "(", "subject_dirs", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"CV ({n_splits}) cannot be larger than number of \"", "\n", "f\"subjects ({len(subject_dirs)})\"", ")", "\n", "\n", "# Get train/val/test sizes", "\n", "", "n_train", ",", "n_val", ",", "n_test", "=", "get_split_sizes", "(", "subject_dirs", ",", "n_splits", ",", "args", ")", "\n", "\n", "# Shuffle and split the files into CV parts", "\n", "random", ".", "shuffle", "(", "subject_dirs", ")", "\n", "splits", "=", "np", ".", "array_split", "(", "subject_dirs", ",", "n_splits", ")", "\n", "\n", "# Prepare dataframe to store counts", "\n", "col_names", "=", "[", "'split_{}'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "n_splits", ")", "]", "if", "n_splits", "!=", "1", "else", "[", "'fixed_split'", "]", "\n", "counts_df", "=", "pd", ".", "DataFrame", "(", "index", "=", "[", "'train_records'", ",", "'train_subjects'", ",", "\n", "'val_records'", ",", "'val_subjects'", ",", "\n", "'test_records'", ",", "'test_subjects'", ",", "\n", "'total_records'", ",", "'total_subjects'", "]", ",", "\n", "columns", "=", "col_names", ")", "\n", "\n", "# Symlink / copy files", "\n", "for", "split_index", ",", "(", "test_split", ",", "col_name", ")", "in", "enumerate", "(", "zip", "(", "splits", ",", "\n", "col_names", ")", ")", ":", "\n", "        ", "print", "(", "\"  Split %i/%i\"", "%", "(", "split_index", "+", "1", ",", "n_splits", ")", ",", "\n", "end", "=", "\"\\r\"", ",", "flush", "=", "True", ")", "\n", "\n", "# Set root path to split folder", "\n", "if", "n_splits", ">", "1", ":", "\n", "            ", "split_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"split_%i\"", "%", "split_index", ")", "\n", "", "else", ":", "\n", "            ", "split_path", "=", "out_dir", "\n", "# Here we kind of hacky force the following code to work with CV=1", "\n", "# Define a test set and overwrite the current split", "\n", "# add the data, as splits was never split with n_splits=1", "\n", "test_split", "=", "splits", "[", "0", "]", "[", ":", "n_test", "]", "\n", "\n", "# Overwrite the splits variable to a length 2 array with the", "\n", "# remaining data which will be used as val+train. The loop still", "\n", "# refers to the old split and thus will only execute once", "\n", "splits", "=", "[", "test_split", ",", "splits", "[", "0", "]", "[", "n_test", ":", "]", "]", "\n", "\n", "# make flat list of remaining splits (train+val)", "\n", "", "train_val_data", "=", "[", "x", "for", "ind", ",", "x", "in", "enumerate", "(", "splits", ")", "if", "ind", "!=", "split_index", "]", "\n", "train_val_data", "=", "[", "item", "for", "sublist", "in", "train_val_data", "for", "item", "in", "sublist", "]", "\n", "\n", "# Add/copy/symlink the files to the split directories", "\n", "train_records", ",", "val_records", ",", "test_records", "=", "run_on_split", "(", "\n", "split_path", "=", "split_path", ",", "\n", "test_split", "=", "test_split", ",", "\n", "train_val_data", "=", "train_val_data", ",", "\n", "n_val", "=", "n_val", ",", "\n", "args", "=", "args", "\n", ")", "\n", "train_subjects", "=", "len", "(", "train_val_data", ")", "-", "n_val", "# n_val is exact", "\n", "val_subjects", "=", "n_val", "\n", "test_subjects", "=", "len", "(", "test_split", ")", "\n", "counts_col", "=", "[", "train_records", ",", "train_subjects", ",", "val_records", ",", "val_subjects", ",", "\n", "test_records", ",", "test_subjects", ",", "\n", "np", ".", "sum", "(", "[", "train_records", ",", "val_records", ",", "test_records", "]", ")", ",", "\n", "np", ".", "sum", "(", "[", "train_subjects", ",", "val_subjects", ",", "test_subjects", "]", ")", "]", "\n", "counts_df", "[", "col_name", "]", "=", "counts_col", "\n", "", "counts_df", "[", "\"sum\"", "]", "=", "np", ".", "sum", "(", "counts_df", ",", "axis", "=", "1", ")", "\n", "logger", ".", "info", "(", "f\"\\n{counts_df.T}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.entry_func": [[400, 405], ["cv_split.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "cv_split.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.group.get_argparser": [[17, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Group files into sub-folders '", "\n", "'according to file name similarities'", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./\"", ",", "\n", "help", "=", "'The directory in which files to be grouped are '", "\n", "'stored'", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Optional directory in which new sub-folders \"", "\n", "\"will be created (defaults ot --data_dir)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_regex\"", ",", "type", "=", "str", ",", "default", "=", "'.*'", ",", "required", "=", "False", ",", "\n", "help", "=", "'A regex pattern (note: not glob) that should '", "\n", "'match the all files that are to be considered '", "\n", "'for grouping.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--common_prefix_length\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Consider only the first N characters of the \"", "\n", "\"filenames when grouping.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.group.move_files": [[46, 66], ["os.path.join", "os.path.exists", "os.mkdir", "os.path.join", "shutil.move", "os.path.split"], "function", ["None"], ["", "def", "move_files", "(", "pairs", ",", "out_dir", ",", "subject_dir_name", ")", ":", "\n", "    ", "\"\"\"\n    Move files in tuple/list 'pairs' to 'out_dir' under a sub-directory of name\n    'subject_dir_name'.\n\n    OBS: files are moved. Uses shutil.move.\n\n    Args:\n        pairs:             Tuple/list of files to move\n        out_dir:           Path pointing to folder that should store the\n                           subject dir\n                           which in turn stores the individual files\n        subject_dir_name:  Name of sub-dir to store individual files.\n    \"\"\"", "\n", "subject_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "subject_dir_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "subject_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "subject_dir", ")", "\n", "", "for", "f", "in", "pairs", ":", "\n", "        ", "out_p", "=", "os", ".", "path", ".", "join", "(", "subject_dir", ",", "os", ".", "path", ".", "split", "(", "f", ")", "[", "-", "1", "]", ")", "\n", "shutil", ".", "move", "(", "f", ",", "out_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.group.run": [[68, 89], ["os.path.abspath", "os.path.abspath", "psg_utils.dataset.utils.filter_by_regex", "utime.bin.cv_split.pair_by_names", "logger.info", "os.path.exists", "OSError", "os.listdir", "input().lower", "print", "group.move_files", "len", "len", "input", "os.path.splitext", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_split.pair_by_names", "home.repos.pwc.inspect_result.perslev_U-Time.bin.group.move_files"], ["", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\" Run script with the specified args. See argparser for details. \"\"\"", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "raise", "OSError", "(", "f\"'out_dir' {out_dir} does not exist\"", ")", "\n", "\n", "# Get all files", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "data_dir", ")", "\n", "files", "=", "filter_by_regex", "(", "os", ".", "listdir", "(", "data_dir", ")", ",", "args", ".", "file_regex", ")", "\n", "pairs", "=", "pair_by_names", "(", "files", ",", "args", ".", "common_prefix_length", ")", "\n", "logger", ".", "info", "(", "f\"Found {len(files)} files\\n\"", "\n", "f\"Found {len(pairs)} pairs\\n\"", "\n", "f\"Moving to: {out_dir}\"", ")", "\n", "if", "input", "(", "\"Move? (y/N) \"", ")", ".", "lower", "(", ")", "==", "\"y\"", ":", "\n", "        ", "print", "(", "\"Moving...\"", ")", "\n", "for", "p", "in", "pairs", ":", "\n", "            ", "if", "args", ".", "common_prefix_length", "is", "None", ":", "\n", "                ", "subject_dir_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "p", "[", "0", "]", ")", "[", "-", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "subject_dir_name", "=", "os", ".", "path", ".", "split", "(", "p", "[", "0", "]", ")", "[", "-", "1", "]", "[", ":", "args", ".", "common_prefix_length", "]", "\n", "", "move_files", "(", "p", ",", "out_dir", ",", "subject_dir_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.group.entry_func": [[91, 97], ["group.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "group.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.get_parser": [[15, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "os.path.split", "os.path.abspath", "os.listdir"], "function", ["None"], ["def", "get_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Create a new project folder'", ")", "\n", "\n", "# Define groups", "\n", "defaults", "=", "os", ".", "path", ".", "split", "(", "__file__", ")", "[", "0", "]", "+", "\"/defaults\"", "\n", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'the name of the project folder'", ")", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "type", "=", "str", ",", "default", "=", "os", ".", "path", ".", "abspath", "(", "\"./\"", ")", ",", "\n", "help", "=", "'a path to the root folder in '", "\n", "'which the project will be initialized '", "\n", "'(default=./)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "default", "=", "\"utime\"", ",", "\n", "help", "=", "f\"Specify a model type parameter file. One of: \"", "\n", "f\"{','.join(os.listdir(defaults))} (default 'utime')\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Optional specification of path to dir \"", "\n", "\"storing data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite existing projects and/or log files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.copy_yaml_and_set_data_dirs": [[46, 72], ["YAMLHParams", "YAMLHParams.save_current", "os.path.join", "YAMLHParams.get", "YAMLHParams.set_group", "hparams[].get"], "function", ["None"], ["", "def", "copy_yaml_and_set_data_dirs", "(", "in_path", ",", "out_path", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a YAMLHParams object from a in_path (a hyperparameter .yaml file),\n    inserts the 'data_dir' argument into data_dir fileds in the .yaml file\n    (if present) and saves the hyperparameter file to out_path.\n\n    Note: If data_dir is set, it is assumed that the folder contains data in\n          sub-folders 'train', 'val' and 'test' (not required to exist).\n\n    args:\n        in_path:  (string) Path to a .yaml file storing the hyperparameters\n        out_path: (string) Path to save the hyperparameters to\n        data_dir: (string) Optional path to a directory storing data to use\n                           for this project.\n    \"\"\"", "\n", "from", "utime", ".", "hyperparameters", "import", "YAMLHParams", "\n", "hparams", "=", "YAMLHParams", "(", "in_path", ",", "no_version_control", "=", "True", ")", "\n", "\n", "# Set values in parameter file and save to new location", "\n", "data_ids", "=", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ")", "\n", "for", "dataset", "in", "data_ids", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset", ")", "if", "data_dir", "else", "\"Null\"", "\n", "dataset", "=", "dataset", "+", "\"_data\"", "\n", "if", "hparams", ".", "get", "(", "dataset", ")", "and", "not", "hparams", "[", "dataset", "]", ".", "get", "(", "\"data_dir\"", ")", ":", "\n", "            ", "hparams", ".", "set_group", "(", "f\"/{dataset}/data_dir\"", ",", "path", ",", "missing_parents_ok", "=", "True", ",", "overwrite", "=", "True", ")", "\n", "", "", "hparams", ".", "save_current", "(", "out_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.init_project_folder": [[74, 103], ["logger.info", "os.path.join", "utime.Defaults.get_hparams_dir", "utime.Defaults.get_model_dir", "utime.utils.create_folders", "os.walk", "os.path.join", "os.path.join", "dir_path.replace().strip", "os.path.join", "init.copy_yaml_and_set_data_dirs", "os.path.exists", "os.mkdir", "dir_path.replace"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_model_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.create_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.copy_yaml_and_set_data_dirs"], ["", "def", "init_project_folder", "(", "default_folder", ",", "preset", ",", "out_folder", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Create and populate a new project folder with default hyperparameter files.\n\n    Args:\n        default_folder: (string) Path to the utime.bin.defaults folder\n        preset:         (string) Name of the model/preset directory to use\n        out_folder:     (string) Path to the project directory to create and\n                                 populate\n        data_dir:       (string) Optional path to a directory storing data to\n                                 use for this project.\n    \"\"\"", "\n", "logger", ".", "info", "(", "f\"Initializing project in project folder: {out_folder} (model preset: '{preset}')\"", ")", "\n", "# Copy files and folders to project dir, set data_dirs if specified", "\n", "hparams_in_dir", "=", "os", ".", "path", ".", "join", "(", "default_folder", ",", "preset", ")", "\n", "# Create hyperparameters folder", "\n", "hparams_out_dir", "=", "Defaults", ".", "get_hparams_dir", "(", "out_folder", ")", "\n", "model_dir", "=", "Defaults", ".", "get_model_dir", "(", "out_folder", ")", "\n", "create_folders", "(", "[", "out_folder", ",", "hparams_out_dir", ",", "model_dir", "]", ")", "\n", "for", "dir_path", ",", "dir_names", ",", "file_names", "in", "os", ".", "walk", "(", "hparams_in_dir", ")", ":", "\n", "        ", "for", "dir_name", "in", "dir_names", ":", "\n", "            ", "p_", "=", "os", ".", "path", ".", "join", "(", "hparams_out_dir", ",", "dir_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "p_", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "p_", ")", "\n", "", "", "for", "file_name", "in", "file_names", ":", "\n", "            ", "in_file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "file_name", ")", "\n", "sub_dir", "=", "dir_path", ".", "replace", "(", "hparams_in_dir", ",", "\"\"", ")", ".", "strip", "(", "\"/\"", ")", "\n", "out_file_path", "=", "os", ".", "path", ".", "join", "(", "hparams_out_dir", ",", "sub_dir", ",", "file_name", ")", "\n", "copy_yaml_and_set_data_dirs", "(", "in_file_path", ",", "out_file_path", ",", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.run": [[105, 128], ["utime.utils.scriptutils.add_logging_file_handler", "os.path.abspath", "os.path.exists", "OSError", "os.path.abspath", "os.path.exists", "OSError", "os.path.join", "init.init_project_folder", "os.path.split", "os.path.exists", "OSError", "os.path.abspath"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.init_project_folder"], ["", "", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run this script with the specified args. See argparser for details.\n    \"\"\"", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "default_folder", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "[", "0", "]", "+", "\"/defaults\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "default_folder", ")", ":", "\n", "        ", "raise", "OSError", "(", "f\"Default path not found at {default_folder}\"", ")", "\n", "", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "root", ")", "\n", "data_dir", "=", "args", ".", "data_dir", "\n", "if", "data_dir", ":", "\n", "        ", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "data_dir", ")", "\n", "\n", "# Validate project path and create folder", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "root_path", ")", ":", "\n", "        ", "raise", "OSError", "(", "f\"root path '{args.root}' does not exist.\"", ")", "\n", "", "else", ":", "\n", "        ", "out_folder", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "args", ".", "name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_folder", ")", "and", "not", "args", ".", "overwrite", ":", "\n", "            ", "raise", "OSError", "(", "f\"Folder at '{out_folder}' already exists and --overwrite flag was not set. \"", "\n", "f\"Note that running this script with --overwrite will only replace \"", "\n", "f\"hyperparameter file data.\"", ")", "\n", "", "init_project_folder", "(", "default_folder", ",", "args", ".", "model", ",", "out_folder", ",", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.entry_func": [[130, 134], ["init.get_parser", "init.run", "get_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.get_parser", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Parse arguments", "\n", "    ", "parser", "=", "get_parser", "(", ")", "\n", "run", "(", "parser", ".", "parse_args", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.channels.get_argparser": [[17, 30], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'Print the channels of files '", "\n", "'matching a glob pattern.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--subject_dir_pattern\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--psg_regex\"", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.channels.run": [[32, 48], ["glob.glob", "len", "logger.info", "logger.info", "psg_utils.dataset.SleepStudy", "psg_utils.io.header.extract_header", "logger.info", "os.path.isfile", "os.path.split"], "function", ["None"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "files", "=", "glob", "(", "args", ".", "subject_dir_pattern", ")", "\n", "if", "len", "(", "files", ")", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "f\"No subject dirs match pattern {args.subject_dir_pattern}\"", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Channels:\"", ")", "\n", "for", "subject_dir", "in", "files", ":", "\n", "            ", "psg_regex", "=", "args", ".", "psg_regex", "or", "None", "\n", "if", "not", "psg_regex", "and", "os", ".", "path", ".", "isfile", "(", "subject_dir", ")", ":", "\n", "                ", "subject_dir", ",", "psg_regex", "=", "os", ".", "path", ".", "split", "(", "subject_dir", ")", "\n", "", "ss", "=", "SleepStudy", "(", "subject_dir", "=", "subject_dir", ",", "\n", "psg_regex", "=", "psg_regex", ",", "\n", "no_hypnogram", "=", "True", ",", "\n", "period_length_sec", "=", "30", ")", "\n", "header", "=", "extract_header", "(", "ss", ".", "psg_file_path", ")", "\n", "logger", ".", "info", "(", "header", "[", "'channel_names'", "]", ",", "header", "[", "'sample_rate'", "]", ",", "\" Hz\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.channels.entry_func": [[50, 56], ["channels.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "channels.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.get_argparser": [[23, 56], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Summary over U-Time project'", "\n", "' evaluations csv file(s).'", ")", "\n", "parser", ".", "add_argument", "(", "\"--csv_pattern\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"split_*/predictions/test_dataset/*dice*csv\"", ",", "\n", "help", "=", "\"Glob pattern used to match evaluation files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_rows\"", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "\"Grand mean\"", ",", "\n", "help", "=", "\"A series of row names to drop from each csv \"", "\n", "\"file before merging. For instance, specify \"", "\n", "\"{--drop_rows Grand mean some_row} to drop \"", "\n", "\"rows 'Grand mean' and 'some_row' \"", "\n", "\"(defaults to 'Grand mean')\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_cols\"", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "\"mean\"", ",", "\n", "help", "=", "\"Same as --drop_rows, but for column names. \"", "\n", "\"(defaults to 'mean')\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--print_all\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Print in addition the entire, merged data frame \"", "\n", "\"from which mean scores are computed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--round\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"Round float numbers. (defaults to 4)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.print_reduced_mean": [[58, 91], ["summary.print_reduced_mean.make_df"], "function", ["None"], ["", "def", "print_reduced_mean", "(", "df", ",", "print_all", "=", "False", ",", "round_", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Takes a DataFrame 'df' of per-subject (rows) of a metric on all classes\n    (columns), computes summary statistics over the subjects and prints the\n    results to screen. With print_all=True, the per-subject scores are also\n    printed.\n\n    Args:\n        df:         (DataFrame) Dataframe of shape NxK (N subjects, K classes)\n                                of metric values.\n        print_all:  (bool)      Print the 'df' to screen as well as the summary\n                                statics over 'df'\n        round_:     (int)       Rounding precision for printing.\n    \"\"\"", "\n", "def", "make_df", "(", "df", ",", "axis", ")", ":", "\n", "        ", "\"\"\" Create summary statistics DataFrame \"\"\"", "\n", "mean", "=", "df", ".", "mean", "(", "axis", "=", "axis", ")", "\n", "std", "=", "df", ".", "std", "(", "axis", "=", "axis", ")", "\n", "min_", "=", "df", ".", "min", "(", "axis", "=", "axis", ")", "\n", "max_", "=", "df", ".", "max", "(", "axis", "=", "axis", ")", "\n", "return", "pd", ".", "DataFrame", "(", "{", "\"mean\"", ":", "mean", ",", "\n", "\"std\"", ":", "std", ",", "\n", "\"min\"", ":", "min_", ",", "\n", "\"max\"", ":", "max_", "}", ",", "index", "=", "mean", ".", "index", ")", "\n", "\n", "", "df", "=", "make_df", "(", "df", ",", "axis", "=", "0", ")", "\n", "logger", ".", "info", "(", "\"\\nSUMMARY RESULT\\n\"", "+", "\n", "\"--------------\\n\"", "+", "\n", "(", "\"\\nMerged evaluation files:\\n\"", "+", "\n", "f\"{df.round(round_)}\\n\"", "if", "print_all", "else", "\"\"", ")", "+", "\n", "\"\\nMean over axis 0 (rows):\\n\"", "+", "\n", "f\"{df.round(round_)}\\n\"", "+", "\n", "f\"Mean of means: {round(df['mean'].mean(), round_)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.parse_and_add": [[93, 127], ["pandas.read_csv", "pandas.concat", "df.drop.drop", "len", "logger.error", "exit"], "function", ["None"], ["", "def", "parse_and_add", "(", "file_", ",", "results", ",", "drop_rows", ",", "drop_cols", ")", ":", "\n", "    ", "\"\"\"\n    Load a CSV file, drop rows and/or columns as specified and merge the data\n    with the pandas.DataFrame 'results'.\n\n    Concatenates the DataFrames over axis 0 (on rows)\n\n    Args:\n        file_:      (string)    Path to a CSV file to load and add\n        results:    (DataFrame) DataFrame storing other data (or empty)\n        drop_rows:  (list)      A list of string row names to drop from each\n                                csv file before merging.\n        drop_cols:  (list)      A list of string col names to drop from each\n                                csv file before merging.\n\n    Returns:\n        A DataFrame that stores all data from 'results' merged with data from\n        CSV file 'file_'.\n    \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "file_", ",", "index_col", "=", "0", ")", "\n", "try", ":", "\n", "        ", "df", "=", "df", ".", "drop", "(", "index", "=", "drop_rows", ",", "columns", "=", "drop_cols", ")", "\n", "", "except", "KeyError", ":", "\n", "        ", "from", "sys", "import", "exit", "\n", "logger", ".", "error", "(", "\"[PARSE ERROR] Invalid row or column in {drop_rows} or {drop_cols} respectively.\\n\"", "\n", "\"One or more of these were not found in file:\\n{file_}\\n\\n\"", "\n", "\"This file has the following:\\n\"", "\n", "\"Rows:    {list(df.index)}\\n\"", "\n", "\"Columns: {list(df.columns)}\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "        ", "return", "df", "\n", "", "o", "=", "pd", ".", "concat", "(", "(", "df", ",", "results", ")", ",", "axis", "=", "0", ",", "sort", "=", "True", ")", "\n", "return", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.parse_results": [[129, 153], ["pandas.DataFrame", "summary.print_reduced_mean", "summary.parse_and_add"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.print_reduced_mean", "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.parse_and_add"], ["", "def", "parse_results", "(", "csv_files", ",", "drop_rows", ",", "drop_cols", ",", "print_all", ",", "round_", ")", ":", "\n", "    ", "\"\"\"\n    Load, merge and print metrics from one or more CSV files.\n\n    Args:\n        csv_files:    (list) A list of paths to .csv files storing per-subject\n                             metrics.\n        drop_rows:    (list) A list of string row names to drop from each csv\n                             file before merging.\n        drop_cols:    (list) A list of string col names to drop from each csv\n                             file before merging.\n        print_all:    (bool) Print the entire, merged data frame from which\n                             mean scores are computed.\n        round_:       (int)  Rounding precision\n    \"\"\"", "\n", "results", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "file_", "in", "csv_files", ":", "\n", "        ", "results", "=", "parse_and_add", "(", "file_", "=", "file_", ",", "\n", "results", "=", "results", ",", "\n", "drop_rows", "=", "drop_rows", ",", "\n", "drop_cols", "=", "drop_cols", ")", "\n", "", "print_reduced_mean", "(", "results", ",", "\n", "print_all", "=", "print_all", ",", "\n", "round_", "=", "round_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.run": [[155, 173], ["logger.info", "glob.glob", "logger.info", "glob.glob.sort", "logger.info", "input", "sys.exit", "input.lower", "summary.parse_results", "map", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.parse_results"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\" Run this script with passed args - see argparser for details \"\"\"", "\n", "# Get folder/folders - 3 levels possible", "\n", "logger", ".", "info", "(", "\"... Looking for files matching pattern\"", ")", "\n", "pattern", "=", "args", ".", "csv_pattern", "\n", "csv_files", "=", "glob", "(", "pattern", ",", "recursive", "=", "False", ")", "\n", "logger", ".", "info", "(", "f\"Found {len(csv_files)} files matching pattern '{pattern}'\"", ")", "\n", "if", "not", "csv_files", ":", "\n", "        ", "sys", ".", "exit", "(", "0", ")", "\n", "", "csv_files", ".", "sort", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", ".", "join", "(", "map", "(", "os", ".", "path", ".", "abspath", ",", "csv_files", ")", ")", ")", "\n", "in_", "=", "input", "(", "\"\\nCorrect? (Y/n) \"", ")", "\n", "if", "in_", ".", "lower", "(", ")", "not", "in", "(", "\"n\"", ",", "\"no\"", ")", ":", "\n", "        ", "parse_results", "(", "csv_files", "=", "csv_files", ",", "\n", "drop_rows", "=", "args", ".", "drop_rows", ",", "\n", "drop_cols", "=", "args", ".", "drop_cols", ",", "\n", "print_all", "=", "args", ".", "print_all", ",", "\n", "round_", "=", "args", ".", "round", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.summary.entry_func": [[175, 180], ["summary.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "summary.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_parser": [[17, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\n", "\"Run a CV experiment. First, split a dataset folder using the 'ut cv_split' command. \"", "+", "\"This command may then be used to invoke a set of specified commands (usually 'ut <command>' commands) on \"", "+", "\"each split. By default the commands that should be run on each split must be specified in a file named 'script' (otherwise \"", "+", "\"specify a different path via the --script_prototype flag). The current working directory must be a project folder as created by \"", "+", "\"'ut init' or contain a subfolder at path '--hparams_prototype_dir <path>' storing the hyperparameters to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cv_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Directory storing split subfolders as output by\"", "\n", "\" cv_split.py\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./splits\"", ",", "\n", "help", "=", "\"Folder in which experiments will be run and \"", "\n", "\"results stored.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of GPUs to use per process. This also \"", "\n", "\"defines the number of parallel jobs to run.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--force_gpus\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"A list of one or more GPU IDs \"", "\n", "\"(comma separated) from which GPU resources \"", "\n", "\"will supplied to each split, independent of\"", "\n", "\" the current memory usage of the GPUs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ignore_gpus\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"A list of one or more GPU IDs \"", "\n", "\"(comma separated) that will not be considered.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_jobs\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"OBS: Only in effect when --num_gpus=0. Sets\"", "\n", "\" the number of jobs to run in parallel when no\"", "\n", "\" GPUs are attached to each job.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--run_on_split\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Only run a specific split\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--script_prototype\"", ",", "type", "=", "str", ",", "default", "=", "\"./script\"", ",", "\n", "help", "=", "\"Path to text file listing commands and \"", "\n", "\"arguments to execute under each sub-exp folder.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hparams_prototype_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"./model_prototype\"", ",", "\n", "help", "=", "\"Prototype directory storing all hyperparameter \"", "\n", "\"yaml files from which sub-CV models will be run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_hparams\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do not move a hyperparameter yaml file into \"", "\n", "\"each split dir (one must be already there).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--start_from\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Start from CV split<start_from>. Default 0.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wait_for\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Waiting for pid to terminate before starting \"", "\n", "\"training process.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--monitor_gpus_every\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"If specified, start a background process which\"", "\n", "\" monitors every 'monitor_gpus_every' seconds \"", "\n", "\"whether new GPUs have become available than may\"", "\n", "\" be included in the CV experiment GPU resource \"", "\n", "\"pool.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "\"cv_experiment_log\"", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is 'cv_experiment_log'\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_cv_folders": [[78, 81], ["int", "os.path.join", "sorted", "x.split", "os.listdir"], "function", ["None"], ["", "def", "get_cv_folders", "(", "dir_", ")", ":", "\n", "    ", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "\n", "return", "[", "os", ".", "path", ".", "join", "(", "dir_", ",", "p", ")", "for", "p", "in", "sorted", "(", "os", ".", "listdir", "(", "dir_", ")", ",", "key", "=", "key", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._get_gpu_sets": [[83, 86], ["list", "map", "range", "len"], "function", ["None"], ["", "def", "_get_gpu_sets", "(", "free_gpus", ",", "num_gpus", ")", ":", "\n", "    ", "free_gpus", "=", "list", "(", "map", "(", "str", ",", "free_gpus", ")", ")", "\n", "return", "[", "\",\"", ".", "join", "(", "free_gpus", "[", "x", ":", "x", "+", "num_gpus", "]", ")", "for", "x", "in", "range", "(", "0", ",", "len", "(", "free_gpus", ")", ",", "num_gpus", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_free_gpu_sets": [[88, 101], ["utime.utils.system.gpu_string_to_list", "sorted", "list", "len", "utime.utils.system.get_free_gpus", "filter", "cv_experiment._get_gpu_sets", "ValueError"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.gpu_string_to_list", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.get_free_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._get_gpu_sets"], ["", "def", "get_free_gpu_sets", "(", "num_gpus", ",", "ignore_gpus", "=", "None", ")", ":", "\n", "    ", "ignore_gpus", "=", "gpu_string_to_list", "(", "ignore_gpus", "or", "\"\"", ",", "as_int", "=", "True", ")", "\n", "free_gpus", "=", "sorted", "(", "get_free_gpus", "(", ")", ")", "\n", "free_gpus", "=", "list", "(", "filter", "(", "lambda", "gpu", ":", "gpu", "not", "in", "ignore_gpus", ",", "free_gpus", ")", ")", "\n", "total_gpus", "=", "len", "(", "free_gpus", ")", "\n", "if", "total_gpus", "%", "num_gpus", "or", "not", "free_gpus", ":", "\n", "        ", "if", "total_gpus", "<", "num_gpus", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid number of GPUs per process '{num_gpus}' for total \"", "\n", "f\"GPU count of '{total_gpus}' - must be evenly divisible.\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "        ", "return", "_get_gpu_sets", "(", "free_gpus", ",", "num_gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.monitor_gpus": [[103, 124], ["stop_event.is_set", "sublist.split", "cv_experiment.get_free_gpu_sets", "time.sleep", "any", "gpu_queue.put", "gpu_set.split", "gpu_set.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_free_gpu_sets"], ["", "", "def", "monitor_gpus", "(", "every", ",", "gpu_queue", ",", "num_gpus", ",", "ignore_gpus", ",", "current_pool", ",", "stop_event", ")", ":", "\n", "# Make flat version of the list of gpu sets", "\n", "    ", "current_pool", "=", "[", "gpu", "for", "sublist", "in", "current_pool", "for", "gpu", "in", "sublist", ".", "split", "(", "\",\"", ")", "]", "\n", "while", "not", "stop_event", ".", "is_set", "(", ")", ":", "\n", "# Get available GPU sets. Will raise ValueError if no full set is", "\n", "# available", "\n", "        ", "try", ":", "\n", "            ", "gpu_sets", "=", "get_free_gpu_sets", "(", "num_gpus", ",", "ignore_gpus", ")", "\n", "for", "gpu_set", "in", "gpu_sets", ":", "\n", "                ", "if", "any", "(", "[", "g", "in", "current_pool", "for", "g", "in", "gpu_set", ".", "split", "(", "\",\"", ")", "]", ")", ":", "\n", "# If one or more GPUs are already in use - this may happen", "\n", "# initially as preprocessing occurs in a process before GPU", "\n", "# memory has been allocated - ignore the set", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "gpu_queue", ".", "put", "(", "gpu_set", ")", "\n", "current_pool", "+=", "gpu_set", ".", "split", "(", "\",\"", ")", "\n", "", "", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "", "finally", ":", "\n", "            ", "time", ".", "sleep", "(", "every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.parse_script": [[126, 141], ["open", "line.strip.strip", "list", "commands.append", "line.strip.split", "filter", "list.append", "line.strip.split", "x.lower"], "function", ["None"], ["", "", "", "def", "parse_script", "(", "script", ",", "gpus", ")", ":", "\n", "    ", "commands", "=", "[", "]", "\n", "with", "open", "(", "script", ")", "as", "in_file", ":", "\n", "        ", "for", "line", "in", "in_file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", "\" \\n\"", ")", "\n", "if", "not", "line", "or", "line", "[", "0", "]", "==", "\"#\"", ":", "\n", "                ", "continue", "\n", "# Split out in-line comments", "\n", "", "line", "=", "line", ".", "split", "(", "\"#\"", ")", "[", "0", "]", "\n", "# Get all arguments, remove if concerning GPU (controlled here)", "\n", "cmd", "=", "list", "(", "filter", "(", "lambda", "x", ":", "\"gpu\"", "not", "in", "x", ".", "lower", "(", ")", ",", "line", ".", "split", "(", ")", ")", ")", "\n", "if", "\"python\"", "in", "line", "or", "line", "[", ":", "2", "]", "==", "\"mp\"", "or", "line", "[", ":", "2", "]", "==", "\"ds\"", ":", "\n", "                ", "cmd", ".", "append", "(", "f\"--force_gpus={gpus}\"", ")", "\n", "", "commands", ".", "append", "(", "cmd", ")", "\n", "", "", "return", "commands", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.run_sub_experiment": [[143, 200], ["os.path.join", "utime.utils.create_folders", "cv_experiment.parse_script", "os.chdir", "lock.acquire", "logger.info", "lock.release", "gpu_queue.put", "os.path.split", "os.path.split", "utime.bin.init.init_project_folder", "len", "lock.acquire", "logger.info", "lock.release", "subprocess.Popen", "subprocess.Popen.communicate", "lock.acquire", "lock.release", "logger.error", "logger.info", "err.decode", "enumerate"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.create_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.parse_script", "home.repos.pwc.inspect_result.perslev_U-Time.bin.init.init_project_folder"], ["", "def", "run_sub_experiment", "(", "split_dir", ",", "out_dir", ",", "script", ",", "hparams_dir", ",", "no_hparams", ",", "gpus", ",", "gpu_queue", ",", "lock", ")", ":", "\n", "# Create sub-directory", "\n", "    ", "split", "=", "os", ".", "path", ".", "split", "(", "split_dir", ")", "[", "-", "1", "]", "\n", "out_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "split", ")", "\n", "create_folders", "(", "out_dir", ")", "\n", "\n", "# Get list of commands", "\n", "commands", "=", "parse_script", "(", "script", ",", "gpus", ")", "\n", "\n", "# Move hparams and script files into folder", "\n", "if", "not", "no_hparams", ":", "\n", "        ", "dir_", ",", "name", "=", "os", ".", "path", ".", "split", "(", "hparams_dir", ")", "\n", "init_project_folder", "(", "default_folder", "=", "dir_", ",", "\n", "preset", "=", "name", ",", "\n", "out_folder", "=", "out_dir", ",", "\n", "data_dir", "=", "split_dir", ")", "\n", "\n", "# Change directory and file permissions", "\n", "", "os", ".", "chdir", "(", "out_dir", ")", "\n", "\n", "# Log", "\n", "lock", ".", "acquire", "(", ")", "\n", "s", "=", "f\"[*] Running experiment: {split}\"", "\n", "delim", "=", "'-'", "*", "len", "(", "s", ")", "\n", "logger", ".", "info", "(", "f\"\\n{delim}\\n\"", "+", "\n", "f\"{s}\\n\"", "+", "\n", "f\"Data dir:   {split_dir}\\n\"", "+", "\n", "f\"Out dir:    {out_dir}\\n\"", "+", "\n", "f\"Using GPUs: {gpus}\\n\"", "+", "\n", "f\"Running commands:\\n\"", "+", "\n", "\"\\n\"", ".", "join", "(", "[", "f\" ({i+1}) {' '.join(command)}\"", "for", "i", ",", "command", "in", "enumerate", "(", "commands", ")", "]", ")", "+", "f\"\\n{delim}\"", ")", "\n", "lock", ".", "release", "(", ")", "\n", "\n", "# Run the commands", "\n", "run_next_command", "=", "True", "\n", "for", "command", "in", "commands", ":", "\n", "        ", "if", "not", "run_next_command", ":", "\n", "            ", "break", "\n", "", "str_command", "=", "' '", ".", "join", "(", "command", ")", "\n", "lock", ".", "acquire", "(", ")", "\n", "logger", ".", "info", "(", "f\"[{split} - STARTING] {str_command}\"", ")", "\n", "lock", ".", "release", "(", ")", "\n", "p", "=", "subprocess", ".", "Popen", "(", "command", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "_", ",", "err", "=", "p", ".", "communicate", "(", ")", "\n", "rc", "=", "p", ".", "returncode", "\n", "lock", ".", "acquire", "(", ")", "\n", "if", "rc", "!=", "0", ":", "\n", "            ", "logger", ".", "error", "(", "f\"[{split} - ERROR - Exit code {rc}] {str_command}\\n\\n\"", "\n", "f\"----- START error message -----\\n{err.decode('utf-8')}\\n\"", "\n", "\"----- END error message -----\\n\"", ")", "\n", "run_next_command", "=", "False", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"[{split} - FINISHED] {str_command}\"", ")", "\n", "", "lock", ".", "release", "(", ")", "\n", "\n", "# Add the GPUs back into the queue", "\n", "", "gpu_queue", ".", "put", "(", "gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.start_gpu_monitor_process": [[202, 219], ["logger.info", "multiprocessing.Event", "multiprocessing.Process", "multiprocessing.Process.start", "procs.append"], "function", ["None"], ["", "def", "start_gpu_monitor_process", "(", "args", ",", "gpu_queue", ",", "gpu_sets", ")", ":", "\n", "    ", "procs", "=", "[", "]", "\n", "if", "args", ".", "monitor_gpus_every", "is", "not", "None", "and", "args", ".", "monitor_gpus_every", ":", "\n", "        ", "logger", ".", "info", "(", "f\"\\nOBS: Monitoring GPU pool every {args.monitor_gpus_every} seconds\\n\"", ")", "\n", "# Start a process monitoring new GPU availability over time", "\n", "stop_event", "=", "Event", "(", ")", "\n", "t", "=", "Process", "(", "target", "=", "monitor_gpus", ",", "args", "=", "(", "args", ".", "monitor_gpus_every", ",", "\n", "gpu_queue", ",", "\n", "args", ".", "num_gpus", ",", "\n", "args", ".", "ignore_gpus", ",", "\n", "gpu_sets", ",", "\n", "stop_event", ")", ")", "\n", "t", ".", "start", "(", ")", "\n", "procs", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "        ", "stop_event", "=", "None", "\n", "", "return", "procs", ",", "stop_event", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._assert_run_split": [[221, 227], ["ValueError", "ValueError"], "function", ["None"], ["", "def", "_assert_run_split", "(", "monitor_gpus_every", ",", "num_jobs", ")", ":", "\n", "    ", "if", "monitor_gpus_every", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"--monitor_gpus_every is not a valid argument\"", "\n", "\" to use with --run_on_split.\"", ")", "\n", "", "if", "num_jobs", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"--num_jobs is not a valid argument to use with\"", "\n", "\" --run_on_split.\"", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._assert_force_and_ignore_gpus": [[230, 238], ["utime.utils.system.gpu_string_to_list", "utime.utils.system.gpu_string_to_list", "set", "set", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.system.gpu_string_to_list", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.gpu_string_to_list"], ["", "", "def", "_assert_force_and_ignore_gpus", "(", "force_gpus", ",", "ignore_gpu", ")", ":", "\n", "    ", "force_gpus", "=", "gpu_string_to_list", "(", "force_gpus", ")", "\n", "ignore_gpu", "=", "gpu_string_to_list", "(", "ignore_gpu", ")", "\n", "overlap", "=", "set", "(", "force_gpus", ")", "&", "set", "(", "ignore_gpu", ")", "\n", "if", "overlap", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Cannot both force and ignore GPU(s) {}. \"", "\n", "\"Got forced GPUs {} and ignored GPUs {}\"", ".", "format", "(", "\n", "overlap", ",", "force_gpus", ",", "ignore_gpu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.prepare_hparams_dir": [[241, 255], ["os.path.exists", "os.path.exists", "os.mkdir", "utime.hyperparameters.YAMLHParams", "hparams[].items", "shutil.move", "RuntimeError", "os.path.join", "os.makedirs", "shutil.move", "os.path.dirname"], "function", ["None"], ["", "", "def", "prepare_hparams_dir", "(", "hparams_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "hparams_dir", ")", ":", "\n", "# Check local hparams.yaml file, move into hparams_dir", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "\"hparams.yaml\"", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "hparams_dir", ")", "\n", "hparams", "=", "YAMLHParams", "(", "\"hparams.yaml\"", ",", "no_version_control", "=", "True", ")", "\n", "for", "dataset", ",", "path", "in", "hparams", "[", "'datasets'", "]", ".", "items", "(", ")", ":", "\n", "                ", "destination", "=", "os", ".", "path", ".", "join", "(", "hparams_dir", ",", "path", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "destination", ")", ",", "exist_ok", "=", "True", ")", "\n", "shutil", ".", "move", "(", "path", ",", "destination", ")", "\n", "", "shutil", ".", "move", "(", "\"hparams.yaml\"", ",", "hparams_dir", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Must specifiy hyperparameters in a folder at path --hparams_prototype_dir <path> OR \"", "+", "\"have a hparams.yaml file at the current working directory (i.e. project folder)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.assert_args": [[257, 271], ["cv_experiment._assert_force_and_ignore_gpus", "cv_experiment._assert_run_split", "RuntimeError", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._assert_force_and_ignore_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment._assert_run_split"], ["", "", "", "def", "assert_args", "(", "args", ",", "n_splits", ")", ":", "\n", "# User input assertions", "\n", "    ", "_assert_force_and_ignore_gpus", "(", "args", ".", "force_gpus", ",", "args", ".", "ignore_gpus", ")", "\n", "if", "args", ".", "run_on_split", ":", "\n", "        ", "_assert_run_split", "(", "args", ".", "monitor_gpus_every", ",", "\n", "args", ".", "num_jobs", ")", "\n", "if", "args", ".", "start_from", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Should not use both --run_on_split and \"", "\n", "\"--start_from arguments.\"", ")", "\n", "", "", "first_split", "=", "args", ".", "run_on_split", "or", "args", ".", "start_from", "\n", "if", "first_split", "<", "0", "or", "first_split", ">", "(", "n_splits", "-", "1", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"--run_on_split or --start_from is out of range\"", "\n", "\" [0-{}] with value {}\"", ".", "format", "(", "n_splits", "-", "1", ",", "\n", "first_split", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.run": [[273, 335], ["os.path.abspath", "cv_experiment.get_cv_folders", "cv_experiment.assert_args", "os.path.abspath", "os.path.abspath", "cv_experiment.prepare_hparams_dir", "utime.utils.create_folders", "multiprocessing.Lock", "multiprocessing.Queue", "os.path.abspath", "cv_experiment.start_gpu_monitor_process", "await_pids", "set_gpu", "multiprocessing.Queue.put", "stop_event.set", "multiprocessing.Process.join", "len", "cv_experiment.get_free_gpu_sets", "ValueError", "multiprocessing.Queue.get", "multiprocessing.Process", "multiprocessing.Process.start", "running_processes.append", "len", "multiprocessing.Process.terminate", "multiprocessing.Process.is_alive", "multiprocessing.Process.join"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_cv_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.assert_args", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.prepare_hparams_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.create_folders", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.start_gpu_monitor_process", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.await_pids", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.set_gpu", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.get_free_gpu_sets"], ["", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "cv_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "cv_dir", ")", "\n", "# Get list of folders of CV data to run on", "\n", "cv_folders", "=", "get_cv_folders", "(", "cv_dir", ")", "\n", "assert_args", "(", "args", ",", "n_splits", "=", "len", "(", "cv_folders", ")", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "out_dir", ")", "\n", "hparams_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "hparams_prototype_dir", ")", "\n", "prepare_hparams_dir", "(", "hparams_dir", ")", "\n", "create_folders", "(", "out_dir", ")", "\n", "\n", "if", "args", ".", "wait_for", ":", "\n", "# Wait for pid before proceeding", "\n", "        ", "from", "utime", ".", "utils", "import", "await_pids", "\n", "await_pids", "(", "args", ".", "wait_for", ")", "\n", "", "if", "args", ".", "run_on_split", "is", "not", "None", ":", "\n", "# Run on a single split", "\n", "        ", "cv_folders", "=", "[", "cv_folders", "[", "args", ".", "run_on_split", "]", "]", "\n", "", "if", "args", ".", "force_gpus", ":", "\n", "# Only these GPUs fill be chosen from", "\n", "        ", "from", "utime", ".", "utils", "import", "set_gpu", "\n", "set_gpu", "(", "args", ".", "force_gpus", ")", "\n", "", "if", "args", ".", "num_gpus", ":", "\n", "# Get GPU sets (up to the number of splits)", "\n", "        ", "gpu_sets", "=", "get_free_gpu_sets", "(", "args", ".", "num_gpus", ",", "\n", "args", ".", "ignore_gpus", ")", "[", ":", "len", "(", "cv_folders", ")", "]", "\n", "", "elif", "not", "args", ".", "num_jobs", "or", "args", ".", "num_jobs", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Should specify a number of jobs to run in parallel \"", "\n", "\"with the --num_jobs flag when using 0 GPUs pr. \"", "\n", "\"process (--num_gpus=0 was set).\"", ")", "\n", "", "else", ":", "\n", "        ", "gpu_sets", "=", "[", "\"''\"", "]", "*", "args", ".", "num_jobs", "\n", "\n", "# Get process pool, lock and GPU queue objects", "\n", "", "lock", "=", "Lock", "(", ")", "\n", "gpu_queue", "=", "Queue", "(", ")", "\n", "for", "gpu", "in", "gpu_sets", ":", "\n", "        ", "gpu_queue", ".", "put", "(", "gpu", ")", "\n", "\n", "# Get file paths", "\n", "", "script", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "script_prototype", ")", "\n", "\n", "# Get GPU monitor process", "\n", "running_processes", ",", "stop_event", "=", "start_gpu_monitor_process", "(", "args", ",", "gpu_queue", ",", "gpu_sets", ")", "\n", "\n", "try", ":", "\n", "        ", "for", "cv_folder", "in", "cv_folders", "[", "args", ".", "start_from", ":", "]", ":", "\n", "            ", "gpus", "=", "gpu_queue", ".", "get", "(", ")", "\n", "t", "=", "Process", "(", "target", "=", "run_sub_experiment", ",", "\n", "args", "=", "(", "cv_folder", ",", "out_dir", ",", "script", ",", "hparams_dir", ",", "\n", "args", ".", "no_hparams", ",", "gpus", ",", "gpu_queue", ",", "lock", ")", ")", "\n", "t", ".", "start", "(", ")", "\n", "running_processes", ".", "append", "(", "t", ")", "\n", "for", "t", "in", "running_processes", ":", "\n", "                ", "if", "not", "t", ".", "is_alive", "(", ")", ":", "\n", "                    ", "t", ".", "join", "(", ")", "\n", "", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "for", "t", "in", "running_processes", ":", "\n", "            ", "t", ".", "terminate", "(", ")", "\n", "", "", "if", "stop_event", "is", "not", "None", ":", "\n", "        ", "stop_event", ".", "set", "(", ")", "\n", "", "for", "t", "in", "running_processes", ":", "\n", "        ", "t", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cv_experiment.entry_func": [[337, 343], ["cv_experiment.get_parser", "get_parser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "cv_experiment.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.get_parser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get parser", "\n", "    ", "parser", "=", "get_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"a\"", ")", "# Append mode for if --run_on_split support", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_argparser": [[25, 89], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["\n", "pred", "=", "[", "]", "\n", "end_of_data", "=", "False", "\n", "while", "not", "end_of_data", ":", "\n", "        ", "try", ":", "\n", "            ", "X_batch", ",", "_", "=", "next", "(", "generator", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "end_of_data", "=", "True", "\n", "", "else", ":", "\n", "# Predict", "\n", "            ", "pred_batch", "=", "model", ".", "predict_on_batch", "(", "X_batch", ")", "\n", "if", "argmax", ":", "\n", "                ", "pred_batch", "=", "pred_batch", ".", "argmax", "(", "-", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "pred", ".", "append", "(", "pred_batch", ")", "\n", "", "", "return", "np", ".", "vstack", "(", "pred", ")", "\n", "\n", "\n", "", "def", "predict_by_id", "(", "model", ",", "sequencer", ",", "study_id", ",", "argmax", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a tf.keras model and predicts on all batches of data in a SleepStudy\n    object.\n\n    Args:\n        model:      A tf.keras model instance. Should accept batches of data\n                    as output by the 'sequence' Sequence object.\n        sequencer:  A Sequence object which stores at least the passed\n                    SleepStudy object of 'sleep_study'.\n        study_id:   The identifier string of a SleepStudy object in 'sequence'.\n        argmax:     See predict_on_generator docstring.\n\n    Returns:\n        Predictions of 'model' on all batches of data in a SleepStudy\n        Please refer to the 'predict_on_generator' docstring.\n    \"\"\"", "\n", "# Get generator", "\n", "gen", "=", "sequencer", ".", "to_batch_generator", "(", "study_id", "=", "study_id", ")", "\n", "return", "predict_on_generator", "(", "model", ",", "gen", ",", "argmax", ")", "\n", "\n", "\n", "", "def", "sequence_predict_generator", "(", "model", ",", "total_seq_length", ",", "generator", ",", "\n", "argmax", "=", "False", ",", "overlapping", "=", "True", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Takes a tf.keras model and predicts on segments of data from a generator.\n    This function takes a few additional values needed to derive an\n    understanding of the data produced by 'generator', see below:\n\n    Args:\n        model:             A tf.keras model to predict with. Should accept data\n                           as output by the generator.\n        total_seq_length:  The total number of 'segments/epochs/stages' in the\n                           generator. This is needed to initialize the\n                           predictions array.\n        generator:         A generator which produces batches of data\n        argmax:            Whether to return argmax values or model output values\n        overlapping:       Specifies whether the sequences output of 'generator'\n                           represent overlapping segments or contagious data.\n        verbose:           If True, prints the prediction progess to screen.\n\n    Returns:\n        An array of shape [total_seq_length, n_classes] or\n        [total_seq_length, -1, n_classes] if data_per_prediction != input_dims.\n        If argmax = True axis -1 (now shape 1) is squeezed.\n    \"\"\"", "\n", "n_classes", "=", "model", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.assert_args": [[91, 94], ["None"], "function", ["None"], ["pred", "=", "np", ".", "zeros", "(", "shape", "=", "[", "total_seq_length", "]", "+", "s", "[", "2", ":", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "cur_pos", "=", "0", "\n", "for", "X", ",", "_", ",", "_", "in", "generator", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.set_new_strip_func": [[96, 100], ["None"], "function", ["None"], ["            ", "print", "(", "\"  pos: {}/{}\"", ".", "format", "(", "cur_pos", "+", "1", ",", "total_seq_length", ")", ",", "\n", "end", "=", "\"\\r\"", ",", "flush", "=", "True", ")", "\n", "", "batch_pred", "=", "model", ".", "predict_on_batch", "(", "X", ")", "\n", "if", "overlapping", ":", "\n", "            ", "for", "p", "in", "batch_pred", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_prediction_channel_sets": [[102, 135], ["dataset.misc.get", "hasattr", "psg_utils.io.channels.filter_non_available_channels", "product", "NotImplementedError"], "function", ["None"], ["cur_pos", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "batch_pred", "=", "batch_pred", ".", "reshape", "(", "-", "1", ",", "n_classes", ")", "\n", "n_vals", "=", "batch_pred", ".", "shape", "[", "0", "]", "\n", "pred", "[", "cur_pos", ":", "cur_pos", "+", "n_vals", "]", "+=", "batch_pred", "\n", "cur_pos", "+=", "n_vals", "\n", "", "", "if", "argmax", ":", "\n", "        ", "pred", "=", "pred", ".", "argmax", "(", "-", "1", ")", "\n", "", "print", "(", ")", "\n", "return", "pred", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_datasets": [[137, 180], ["get_all_dataset_hparams", "get_all_dataset_hparams.items", "dataset_hparams.get", "get_all_dataset_hparams.items", "predict.set_new_strip_func", "list", "len", "RuntimeError", "get_all_dataset_hparams.values", "get_dataset_from_regex_pattern", "datasets.append", "get_dataset_splits_from_hparams", "list", "get_all_dataset_hparams.keys"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_all_dataset_hparams", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.set_new_strip_func", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_from_regex_pattern", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_dataset_splits_from_hparams"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.predict_study": [[182, 198], ["callable", "sleep_study_pair.loaded_in_context", "utime.bin.evaluate.predict_on", "getattr", "pred.argmax.numpy", "pred.argmax.reshape", "y.reshape", "pred.argmax.argmax"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.predict_on"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_save_path": [[200, 208], ["os.path.join", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.save_file": [[210, 218], ["os.path.abspath", "os.makedirs", "logger.info", "numpy.save", "os.path.split", "arr.argmax.argmax"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_updated_majority_voted": [[220, 226], ["pred.copy"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred_on_channels": [[228, 240], ["predict.predict_study", "len", "numpy.repeat"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.predict_study"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred_on_pair": [[242, 285], ["predict.get_save_path", "predict.get_save_path", "enumerate", "predict.get_save_path", "predict.run_pred_on_channels", "predict.get_updated_majority_voted", "predict.save_file", "os.path.exists", "logger.info", "predict.get_updated_majority_voted", "logger.info", "predict.save_file", "predict.save_file", "logger.info", "numpy.load", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_save_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_save_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_save_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred_on_channels", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_updated_majority_voted", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.save_file", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_updated_majority_voted", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.save_file", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.save_file"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred": [[287, 329], ["logger.info", "utime.bin.evaluate.get_sequencer", "enumerate", "logger.info", "predict.get_prediction_channel_sets", "len", "logger.info", "len", "logger.info", "predict.run_pred_on_pair", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_sequencer", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.get_prediction_channel_sets", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred_on_pair"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run": [[332, 389], ["predict.assert_args", "logger.info", "os.path.abspath", "assert_project_folder", "utime.bin.evaluate.prepare_output_dir", "YAMLHParams", "utime.utils.system.find_and_set_gpus", "predict.get_datasets", "utime.bin.evaluate.get_out_dir", "utime.Defaults.get_hparams_path", "logger.info", "utime.utils.scriptutils.with_logging_level_wrapper", "utime.bin.evaluate.get_and_load_model", "logger.info", "predict.run_pred", "utime.bin.evaluate.get_and_load_one_shot_model", "os.path.join", "vars", "os.path.exists", "os.mkdir", "dataset.identifier.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.train.assert_args", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.prepare_output_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.find_and_set_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_datasets", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_out_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.with_logging_level_wrapper", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_model", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.run_pred", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_one_shot_model"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict.entry_func": [[391, 397], ["predict.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "predict.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], []], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_argparser": [[25, 79], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Evaluate a U-Time model.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"predictions\"", ",", "\n", "help", "=", "\"Output folder to store results\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of GPUs to use for this job\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_test_time_augment\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Number of prediction passes over each sleep \"", "\n", "\"study with augmentation enabled.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--channels\"", ",", "nargs", "=", "'*'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"A list of channels to use instead of those \"", "\n", "\"specified in the parameter file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--one_shot\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Segment each SleepStudy in one forward-pass \"", "\n", "\"instead of using (GPU memory-efficient) sliding \"", "\n", "\"window predictions.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_save\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do not save prediction files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_save_true\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Save the true hypnogram in addition to the \"", "\n", "\"predicted hypnogram. Ignored with --no_save.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_eval\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Perform no evaluation of the prediction performance. \"", "\n", "\"No label files loaded when this flag applies.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--force_gpus\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_split\"", ",", "type", "=", "str", ",", "default", "=", "\"test_data\"", ",", "\n", "help", "=", "\"Which split of data of those stored in the \"", "\n", "\"hparams file should the evaluation be performed \"", "\n", "\"on.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--plot_hypnograms\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Add plots comparing the predicted versus true\"", "\n", "\" hypnograms to folder [out_dir]/plots/hypnograms.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--plot_CMs\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Add plots showing per-sample confusion matrices.\"", "\n", "\" The plots will be stored in folder \"", "\n", "\"[out_dir]/plots/CMs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weights_file_name\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Specify the exact name of the weights file \"", "\n", "\"(located in <project_dir>/model/) to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wake_trim_min\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Only evaluate on within wake_trim_min of wake \"", "\n", "\"before and after sleep, as determined by true \"", "\n", "\"labels\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite previous results at the output folder and previous log files'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "\"evaluation_log\"", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is 'evaluation_log'\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.assert_args": [[81, 84], ["None"], "function", ["None"], ["", "def", "assert_args", "(", "args", ")", ":", "\n", "    ", "\"\"\" Not yet implemented \"\"\"", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_out_dir": [[86, 91], ["os.path.abspath", "os.path.join"], "function", ["None"], ["", "def", "get_out_dir", "(", "out_dir", ",", "dataset", ")", ":", "\n", "    ", "\"\"\" Returns a new, dataset-specific, out_dir under 'out_dir' \"\"\"", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "out_dir", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "dataset", ")", "\n", "return", "out_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.prepare_output_dir": [[93, 108], ["os.path.abspath", "os.path.exists", "os.makedirs", "os.listdir", "OSError"], "function", ["None"], ["", "def", "prepare_output_dir", "(", "out_dir", ",", "overwrite", ")", ":", "\n", "    ", "\"\"\"\n    Checks if the 'out_dir' exists, and if not, creates it\n    Otherwise, an error is raised, unless overwrite=True, in which case nothing\n    is done.\n    \"\"\"", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "elif", "not", "overwrite", ":", "\n", "        ", "files", "=", "os", ".", "listdir", "(", "out_dir", ")", "\n", "if", "files", ":", "\n", "            ", "raise", "OSError", "(", "\"out_dir {} is not empty and --overwrite=False. Folder\"", "\n", "\" contains the following files: {}\"", ".", "format", "(", "out_dir", ",", "\n", "files", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_model": [[110, 141], ["init_and_load_best_model", "os.path.join", "init_and_load_model", "os.path.join"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_and_load_best_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_and_load_model"], ["", "", "", "def", "get_and_load_model", "(", "project_dir", ",", "hparams", ",", "weights_file_name", "=", "None", ",", "clear_previous", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Initializes a model in project_dir according to hparams and loads weights\n    in .h5 file at path 'weights_file_name' or automatically determined from\n    the 'model' sub-folder under 'project_dir' if not specified.\n\n    Args:\n        project_dir:        Path to project folder\n        hparams:            A YAMLHParams object storing hyperparameters\n        weights_file_name:  Optional path to .h5 parameter file\n        clear_previous:     Clear previous keras session before initializing new model graph.\n\n    Returns:\n        Parameter-initialized model\n    \"\"\"", "\n", "if", "not", "weights_file_name", ":", "\n", "        ", "from", "utime", ".", "models", ".", "model_init", "import", "init_and_load_best_model", "\n", "model", ",", "_", "=", "init_and_load_best_model", "(", "\n", "hparams", "=", "hparams", ",", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "project_dir", ",", "\"model\"", ")", ",", "\n", "clear_previous", "=", "clear_previous", ",", "\n", "by_name", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "        ", "from", "utime", ".", "models", ".", "model_init", "import", "init_and_load_model", "\n", "weights_file_name", "=", "os", ".", "path", ".", "join", "(", "project_dir", ",", "\"model\"", ",", "weights_file_name", ")", "\n", "model", "=", "init_and_load_model", "(", "hparams", "=", "hparams", ",", "\n", "weights_file", "=", "weights_file_name", ",", "\n", "clear_previous", "=", "clear_previous", ",", "\n", "by_name", "=", "True", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_one_shot_model": [[143, 170], ["evaluate.get_and_load_model"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_model"], ["", "def", "get_and_load_one_shot_model", "(", "n_periods", ",", "project_dir", ",", "hparams", ",", "weights_file_name", "=", "None", ",", "clear_previous", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Returns a model according to 'hparams', potentially initialized from\n    parameters in a .h5 file 'weights_file_name'.\n\n    Independent of the settings in 'hparams', the returned model will be\n    configured in 'one shot' mode - that is the model will predict on an entire\n    PSG input in one forward pass. The 'full_hypnogram' array is used to\n    determine the corresponding number of segments.\n\n    Args:\n        n_periods:          Number of epochs that the model should score in 1 forward pass\n        project_dir:        Path to project directory\n        hparams:            YAMLHparams object\n        weights_file_name:  Optional path to .h5 parameter file\n        clear_previous:     Clear previous keras session before initializing new model graph.\n\n    Returns:\n        Initialized model\n    \"\"\"", "\n", "# Set seguence length", "\n", "hparams", "[", "\"build\"", "]", "[", "\"batch_shape\"", "]", "[", "1", "]", "=", "n_periods", "\n", "hparams", "[", "\"build\"", "]", "[", "\"batch_shape\"", "]", "[", "0", "]", "=", "1", "# Should not matter", "\n", "return", "get_and_load_model", "(", "project_dir", ",", "\n", "hparams", "=", "hparams", ",", "\n", "weights_file_name", "=", "weights_file_name", ",", "\n", "clear_previous", "=", "clear_previous", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.plot_hypnogram": [[172, 182], ["os.path.join", "plot_and_save_hypnogram", "os.path.join"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_and_save_hypnogram"], ["", "def", "plot_hypnogram", "(", "out_dir", ",", "pred", ",", "id_", ",", "true", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper around hypnogram plotting function\n    \"\"\"", "\n", "from", "utime", ".", "evaluation", ".", "plotting", "import", "plot_and_save_hypnogram", "\n", "hyp_plot_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"plots\"", ",", "\"hypnograms\"", ")", "\n", "plot_and_save_hypnogram", "(", "out_path", "=", "os", ".", "path", ".", "join", "(", "hyp_plot_dir", ",", "id_", "+", "\".png\"", ")", ",", "\n", "y_pred", "=", "pred", ",", "\n", "y_true", "=", "true", ",", "\n", "id_", "=", "id_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.plot_cm": [[184, 198], ["os.path.join", "plot_and_save_cm", "os.path.join"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_and_save_cm"], ["", "def", "plot_cm", "(", "out_dir", ",", "pred", ",", "true", ",", "n_classes", ",", "id_", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper around confusion matrix plotting function\n    \"\"\"", "\n", "from", "utime", ".", "evaluation", ".", "plotting", "import", "plot_and_save_cm", "\n", "cm_plot_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"plots\"", ",", "\"CMs\"", ")", "\n", "\n", "# Compute and plot CM", "\n", "plot_and_save_cm", "(", "out_path", "=", "os", ".", "path", ".", "join", "(", "cm_plot_dir", ",", "id_", "+", "\".png\"", ")", ",", "\n", "pred", "=", "pred", ",", "\n", "true", "=", "true", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "id_", "=", "id_", ",", "\n", "normalized", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save": [[200, 209], ["os.path.split", "numpy.savez", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "save", "(", "arr", ",", "fname", ")", ":", "\n", "    ", "\"\"\"\n    Helper func to save an array (.npz) to disk in a potentially non-existing\n    tree of sub-dirs\n    \"\"\"", "\n", "d", ",", "_", "=", "os", ".", "path", ".", "split", "(", "fname", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "d", ")", "\n", "", "np", ".", "savez", "(", "fname", ",", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate._predict_sequence": [[211, 236], ["seq.single_study_seq_generator", "sequence_predict_generator"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.single_study_seq_generator", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.sequence_predict_generator"], ["", "def", "_predict_sequence", "(", "study_pair", ",", "seq", ",", "model", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Predict on 'study_pair' wrapped by 'seq' using 'model'\n    Predicts in batches of size seq.batch_size (set in hparams file)\n\n    Args:\n        study_pair: A SleepStudyPair object to predict on\n        seq:        A BatchSequence object that stores 'study_pair'\n        model:      An initialized and loaded model to predict with\n        verbose:    Verbose level (True/False)\n\n    Returns:\n        An array of predicted sleep stages for all periods in 'study_pair'\n        Shape [n_periods, n_classes]\n    \"\"\"", "\n", "from", "utime", ".", "utils", ".", "scriptutils", ".", "predict", "import", "sequence_predict_generator", "\n", "gen", "=", "seq", ".", "single_study_seq_generator", "(", "study_id", "=", "study_pair", ".", "identifier", ",", "\n", "overlapping", "=", "True", ")", "\n", "pred", "=", "sequence_predict_generator", "(", "model", "=", "model", ",", "\n", "total_seq_length", "=", "study_pair", ".", "n_periods", ",", "\n", "generator", "=", "gen", ",", "\n", "argmax", "=", "False", ",", "\n", "overlapping", "=", "True", ",", "\n", "verbose", "=", "verbose", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate._predict_sequence_one_shot": [[238, 259], ["seq.get_single_study_full_seq", "numpy.expand_dims", "model.predict_on_batch"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_single_study_full_seq"], ["", "def", "_predict_sequence_one_shot", "(", "study_pair", ",", "seq", ",", "model", ")", ":", "\n", "    ", "\"\"\"\n    Predict on 'study_pair' wrapped by 'seq' using 'model'\n    Assumes len(PSG) (number of periods in PSG) is equal to the number of\n    periods output by 'model' in a single pass (one-shot segmentation).\n\n    Used with get_and_load_one_shot_model function (--one_shot set in args)\n\n    Args:\n        study_pair: A SleepStudyPair object to predict on\n        seq:        A BatchSequence object that stores 'study_pair'\n        model:      An initialized and loaded model to predict with\n\n    Returns:\n        An array of predicted sleep stages for all periods in 'study_pair'\n        Shape [n_periods, n_classes]\n    \"\"\"", "\n", "X", ",", "_", "=", "seq", ".", "get_single_study_full_seq", "(", "study_pair", ".", "identifier", ")", "\n", "if", "X", ".", "ndim", "==", "3", ":", "\n", "        ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "0", ")", "\n", "", "return", "model", ".", "predict_on_batch", "(", "X", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.predict_on": [[261, 326], ["study_pair.get_full_hypnogram", "callable", "bool", "bool", "RuntimeError", "callable", "seq.single_study_batch_generator", "predict_on_generator", "pred_func", "getattr", "pred.argmax.numpy", "pred.argmax.argmax", "NotImplementedError", "NotImplementedError", "evaluate.run.model_func", "range", "print", "print", "pred_func"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.single_study_batch_generator", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.predict.predict_on_generator"], ["", "def", "predict_on", "(", "study_pair", ",", "seq", ",", "model", "=", "None", ",", "model_func", "=", "None", ",", "n_aug", "=", "None", ",", "\n", "argmax", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    High-level function for predicting on a single SleepStudyPair\n    ('study_pair')object as wrapped by a BatchSequence ('seq') object using a\n    model returned when calling 'model_func'.\n\n    Arguments 'model' and 'model_func' are exclusive, exactly one must be set\n\n    Args:\n        study_pair:  A SleepStudyPair object to predict on\n        seq:         A BatchSequence object that stores 'study_pair'\n        model:       An initialized and loaded model to predict with\n        model_func:  A callable which returns an intialized model\n        n_aug:       Number of times to predict on study_pair with random\n                     augmentation enabled\n        argmax:      If true, returns [n_periods, 1] sleep stage labels,\n                     otherwise returns [n_periods, n_classes] softmax scores.\n\n    Returns:\n        An array of predicted sleep stage scores for 'study_pair'.\n        Shape [n_periods, 1] if argmax=True, otherwise [n_periods, n_classes]\n    \"\"\"", "\n", "if", "bool", "(", "model", ")", "==", "bool", "(", "model_func", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Must specify either model or model_func, \"", "\n", "\"got both or neither.\"", ")", "\n", "", "y", "=", "study_pair", ".", "get_full_hypnogram", "(", ")", "\n", "if", "not", "seq", ".", "margin", ":", "\n", "# Not a sequence model (no margin on center sleep segment)", "\n", "        ", "if", "callable", "(", "model_func", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Got callable for 'model_func' \"", "\n", "\"parameter, but did not receive a \"", "\n", "\"sequence object with margin > 0.\"", ")", "\n", "", "from", "utime", ".", "utils", ".", "scriptutils", ".", "predict", "import", "predict_on_generator", "\n", "if", "n_aug", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Test-time augmentation currently not\"", "\n", "\" supported for non-sequence models.\"", ")", "\n", "", "gen", "=", "seq", ".", "single_study_batch_generator", "(", "study_id", "=", "study_pair", ".", "identifier", ")", "\n", "pred", "=", "predict_on_generator", "(", "model", "=", "model", ",", "\n", "generator", "=", "gen", ",", "\n", "argmax", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_func", ":", "\n", "# One-shot sequencing", "\n", "            ", "pred_func", "=", "_predict_sequence_one_shot", "\n", "# Get one-shot model of input shape matching the hypnogram", "\n", "model", "=", "model_func", "(", "study_pair", ".", "n_periods", ")", "\n", "", "else", ":", "\n", "# Batch-wise sequencing with pre-loaded model", "\n", "            ", "pred_func", "=", "_predict_sequence", "\n", "# Get prediction", "\n", "", "pred", "=", "pred_func", "(", "study_pair", ",", "seq", ",", "model", ")", "\n", "if", "n_aug", ":", "\n", "# Predict additional times with augmentation enabled", "\n", "            ", "seq", ".", "augmentation_enabled", "=", "True", "\n", "for", "i", "in", "range", "(", "n_aug", ")", ":", "\n", "                ", "print", "(", "\"-- With aug: {}/{}\"", ".", "format", "(", "i", "+", "1", ",", "n_aug", ")", ",", "end", "=", "\"\\r\"", ",", "flush", "=", "True", ")", "\n", "pred", "+=", "pred_func", "(", "study_pair", ",", "seq", ",", "model", ")", "/", "n_aug", "\n", "", "seq", ".", "augmentation_enabled", "=", "False", "\n", "print", "(", ")", "\n", "", "", "if", "callable", "(", "getattr", "(", "pred", ",", "\"numpy\"", ",", "None", ")", ")", ":", "\n", "        ", "pred", "=", "pred", ".", "numpy", "(", ")", "\n", "", "if", "argmax", ":", "\n", "        ", "pred", "=", "pred", ".", "argmax", "(", "-", "1", ")", "\n", "", "return", "y", ",", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_sequencer": [[328, 360], ["psg_utils.dataset.queue.LazyQueue", "get_batch_sequence", "hparams.get_group", "hparams.get_group"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.utils.get_batch_sequence"], ["", "def", "get_sequencer", "(", "dataset", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"\n    Returns a BatchSequence object (see utime.seqeunces)\n\n    OBS: Initializes the BatchSequence with scale_assertion,\n    augmentation_enabled and requires_all_loaded flags all set to False.\n\n    args:\n        dataset: (SleepStudyDataset) A SleepStudyDataset storing data to\n                                     predict on\n        hparams: (YAMLHparams)       Hyperparameters to use for the prediction\n\n    Returns:\n        A BatchSequence object\n    \"\"\"", "\n", "# Wrap dataset in LazyQueue object", "\n", "dataset_queue", "=", "LazyQueue", "(", "dataset", ")", "\n", "\n", "from", "utime", ".", "sequences", "import", "get_batch_sequence", "\n", "if", "'fit'", "not", "in", "hparams", ":", "\n", "        ", "hparams", "[", "'fit'", "]", "=", "{", "}", "\n", "", "hparams", "[", "\"fit\"", "]", "[", "\"balanced_sampling\"", "]", "=", "False", "\n", "seq", "=", "get_batch_sequence", "(", "dataset_queue", "=", "dataset_queue", ",", "\n", "random_batches", "=", "False", ",", "\n", "augmenters", "=", "hparams", ".", "get_group", "(", "\"augmenters\"", ")", ",", "\n", "n_classes", "=", "hparams", ".", "get_group", "(", "'/build/n_classes'", ")", ",", "\n", "**", "hparams", "[", "\"fit\"", "]", ",", "\n", "no_log", "=", "True", ",", "\n", "scale_assertion", "=", "False", ",", "\n", "require_all_loaded", "=", "False", ")", "\n", "seq", ".", "augmentation_enabled", "=", "False", "\n", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.run_pred_and_eval": [[362, 443], ["logger.info", "evaluate.get_sequencer", "utime.evaluation.dataframe.get_eval_df", "utime.evaluation.dataframe.get_eval_df", "enumerate", "utime.evaluation.dataframe.with_grand_mean_col", "utime.evaluation.dataframe.log_eval_df", "utime.evaluation.dataframe.with_grand_mean_col", "utime.evaluation.dataframe.log_eval_df", "logger.info", "sklearn.metrics.f1_score", "logger.info", "utime.evaluation.dataframe.add_to_eval_df", "utime.evaluation.metrics.class_wise_kappa", "logger.info", "utime.evaluation.dataframe.add_to_eval_df", "sleep_study_pair.loaded_in_context", "evaluate.predict_on", "os.path.join", "evaluate.save", "evaluate.plot_hypnogram", "evaluate.plot_cm", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "wake_trim", "evaluate.save", "y.ravel", "pred.ravel", "list", "len", "os.path.join", "range", "numpy.round", "numpy.round", "os.path.join"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_sequencer", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.get_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.get_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.with_grand_mean_col", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.with_grand_mean_col", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.add_to_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.metrics.class_wise_kappa", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.add_to_eval_df", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.predict_on", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.plot_hypnogram", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.plot_cm", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.wake_trim", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save"], ["", "def", "run_pred_and_eval", "(", "dataset", ",", "\n", "out_dir", ",", "\n", "model", ",", "\n", "model_func", ",", "\n", "hparams", ",", "\n", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run evaluation (predict + evaluate) on a all entries of a SleepStudyDataset\n\n    Args:\n        dataset:     A SleepStudyDataset object storing one or more SleepStudy\n                     objects\n        out_dir:     Path to directory that will store predictions and\n                     evaluation results\n        model:       An initialized model used for prediction\n        model_func:  A callable that returns an initialized model for pred.\n        hparams:     An YAMLHparams object storing all hyperparameters\n        args:        Passed command-line arguments\n    \"\"\"", "\n", "logger", ".", "info", "(", "f\"\\nPREDICTING ON {len(dataset.pairs)} STUDIES\"", ")", "\n", "seq", "=", "get_sequencer", "(", "dataset", ",", "hparams", ")", "\n", "\n", "# Prepare evaluation data frames", "\n", "dice_eval_df", "=", "get_eval_df", "(", "seq", ")", "\n", "kappa_eval_df", "=", "get_eval_df", "(", "seq", ")", "\n", "\n", "# Predict on all samples", "\n", "for", "i", ",", "sleep_study_pair", "in", "enumerate", "(", "dataset", ")", ":", "\n", "        ", "id_", "=", "sleep_study_pair", ".", "identifier", "\n", "logger", ".", "info", "(", "f\"[{i+1}/{len(dataset)}] Predicting on SleepStudy: {id_}\"", ")", "\n", "\n", "# Predict", "\n", "with", "sleep_study_pair", ".", "loaded_in_context", "(", ")", ":", "\n", "            ", "y", ",", "pred", "=", "predict_on", "(", "study_pair", "=", "sleep_study_pair", ",", "\n", "seq", "=", "seq", ",", "\n", "model", "=", "model", ",", "\n", "model_func", "=", "model_func", ",", "\n", "n_aug", "=", "args", ".", "num_test_time_augment", ")", "\n", "\n", "", "if", "args", ".", "wake_trim_min", ":", "\n", "# Trim long periods of wake in start/end of true & prediction", "\n", "            ", "from", "utime", ".", "bin", ".", "cm", "import", "wake_trim", "\n", "y", ",", "pred", "=", "wake_trim", "(", "pairs", "=", "[", "[", "y", ",", "pred", "]", "]", ",", "\n", "wake_trim_min", "=", "args", ".", "wake_trim_min", ",", "\n", "period_length_sec", "=", "dataset", ".", "period_length_sec", ")", "[", "0", "]", "\n", "", "if", "not", "args", ".", "no_save", ":", "\n", "# Save the output", "\n", "            ", "save_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"files/{}\"", ".", "format", "(", "id_", ")", ")", "\n", "save", "(", "pred", ",", "fname", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"pred.npz\"", ")", ")", "\n", "if", "not", "args", ".", "no_save_true", ":", "\n", "                ", "save", "(", "y", ",", "fname", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"true.npz\"", ")", ")", "\n", "\n", "# Evaluate: dice scores", "\n", "", "", "dice_pr_class", "=", "f1_score", "(", "y_true", "=", "y", ".", "ravel", "(", ")", ",", "\n", "y_pred", "=", "pred", ".", "ravel", "(", ")", ",", "\n", "labels", "=", "list", "(", "range", "(", "seq", ".", "n_classes", ")", ")", ",", "\n", "average", "=", "None", ",", "\n", "zero_division", "=", "1", ")", "\n", "logger", ".", "info", "(", "f\"-- Dice scores:  {np.round(dice_pr_class, 4)}\"", ")", "\n", "add_to_eval_df", "(", "dice_eval_df", ",", "id_", ",", "values", "=", "dice_pr_class", ")", "\n", "\n", "# Evaluate: kappa", "\n", "kappa_pr_class", "=", "class_wise_kappa", "(", "y", ",", "pred", ",", "n_classes", "=", "seq", ".", "n_classes", ")", "\n", "logger", ".", "info", "(", "f\"-- Kappa scores: {np.round(kappa_pr_class, 4)}\"", ")", "\n", "add_to_eval_df", "(", "kappa_eval_df", ",", "id_", ",", "values", "=", "kappa_pr_class", ")", "\n", "\n", "# Flag dependent evaluations:", "\n", "if", "args", ".", "plot_hypnograms", ":", "\n", "            ", "plot_hypnogram", "(", "out_dir", ",", "pred", ",", "id_", ",", "true", "=", "y", ")", "\n", "", "if", "args", ".", "plot_CMs", ":", "\n", "            ", "plot_cm", "(", "out_dir", ",", "pred", ",", "y", ",", "seq", ".", "n_classes", ",", "id_", ")", "\n", "\n", "# Log eval to file and screen", "\n", "", "", "dice_eval_df", "=", "with_grand_mean_col", "(", "dice_eval_df", ")", "\n", "log_eval_df", "(", "dice_eval_df", ".", "T", ",", "\n", "out_csv_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"evaluation_dice.csv\"", ")", ",", "\n", "out_txt_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"evaluation_dice.txt\"", ")", ",", "round", "=", "4", ",", "txt", "=", "\"EVALUATION DICE SCORES\"", ")", "\n", "kappa_eval_df", "=", "with_grand_mean_col", "(", "kappa_eval_df", ")", "\n", "log_eval_df", "(", "kappa_eval_df", ".", "T", ",", "\n", "out_csv_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"evaluation_kappa.csv\"", ")", ",", "\n", "out_txt_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"evaluation_kappa.txt\"", ")", ",", "round", "=", "4", ",", "txt", "=", "\"EVALUATION KAPPA SCORES\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.cross_dataset_eval": [[445, 448], ["None"], "function", ["None"], ["", "def", "cross_dataset_eval", "(", "dataset_eval_dirs", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\" Not implemented yet \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.run": [[450, 506], ["evaluate.assert_args", "logger.info", "os.path.abspath", "utime.utils.scriptutils.assert_project_folder", "evaluate.get_out_dir", "evaluate.prepare_output_dir", "YAMLHParams", "utime.utils.system.find_and_set_gpus", "utime.utils.scriptutils.get_splits_from_all_datasets", "utime.Defaults.get_hparams_path", "logger.info", "utime.utils.scriptutils.with_logging_level_wrapper", "evaluate.get_and_load_model", "logger.info", "evaluate.run_pred_and_eval", "len", "evaluate.cross_dataset_eval", "evaluate.get_and_load_one_shot_model", "os.path.join", "eval_dirs.append", "vars", "os.path.exists", "os.mkdir", "dataset.identifier.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.train.assert_args", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_out_dir", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.prepare_output_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.find_and_set_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_splits_from_all_datasets", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.with_logging_level_wrapper", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_model", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.run_pred_and_eval", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.cross_dataset_eval", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_one_shot_model"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run the script according to args - Please refer to the argparser.\n    \"\"\"", "\n", "assert_args", "(", "args", ")", "\n", "logger", ".", "info", "(", "f\"Args dump: \\n{vars(args)}\"", ")", "\n", "project_dir", "=", "os", ".", "path", ".", "abspath", "(", "Defaults", ".", "PROJECT_DIRECTORY", ")", "\n", "assert_project_folder", "(", "project_dir", ",", "evaluation", "=", "True", ")", "\n", "\n", "# Prepare output dir", "\n", "out_dir", "=", "get_out_dir", "(", "args", ".", "out_dir", ",", "args", ".", "data_split", ")", "\n", "prepare_output_dir", "(", "out_dir", ",", "args", ".", "overwrite", ")", "\n", "\n", "# Get hyperparameters and init all described datasets", "\n", "from", "utime", ".", "hyperparameters", "import", "YAMLHParams", "\n", "hparams", "=", "YAMLHParams", "(", "Defaults", ".", "get_hparams_path", "(", "project_dir", ")", ")", "\n", "if", "args", ".", "channels", ":", "\n", "        ", "hparams", "[", "\"select_channels\"", "]", "=", "args", ".", "channels", "\n", "hparams", "[", "\"channel_sampling_groups\"", "]", "=", "None", "\n", "logger", ".", "info", "(", "f\"Evaluating using channels {args.channels}\"", ")", "\n", "\n", "# Get model", "\n", "", "find_and_set_gpus", "(", "args", ".", "num_gpus", ",", "args", ".", "force_gpus", ")", "\n", "model", ",", "model_func", "=", "None", ",", "None", "\n", "if", "args", ".", "one_shot", ":", "\n", "# Model is initialized for each sleep study later", "\n", "        ", "def", "model_func", "(", "n_periods", ")", ":", "\n", "            ", "return", "get_and_load_one_shot_model", "(", "n_periods", ",", "project_dir", ",", "hparams", ",", "args", ".", "weights_file_name", ")", "\n", "", "model_func", "=", "with_logging_level_wrapper", "(", "model_func", ",", "logging", ".", "ERROR", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "get_and_load_model", "(", "project_dir", ",", "hparams", ",", "args", ".", "weights_file_name", ")", "\n", "\n", "# Run predictions on all datasets", "\n", "", "datasets", "=", "get_splits_from_all_datasets", "(", "hparams", "=", "hparams", ",", "splits_to_load", "=", "(", "args", ".", "data_split", ",", ")", ")", "\n", "eval_dirs", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "dataset", "=", "dataset", "[", "0", "]", "\n", "if", "\"/\"", "in", "dataset", ".", "identifier", ":", "\n", "# Multiple datasets, separate results into sub-folders", "\n", "            ", "ds_out_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\n", "dataset", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "ds_out_dir", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "ds_out_dir", ")", "\n", "", "eval_dirs", ".", "append", "(", "ds_out_dir", ")", "\n", "", "else", ":", "\n", "            ", "ds_out_dir", "=", "out_dir", "\n", "", "logger", ".", "info", "(", "f\"\\n[*] Running eval on dataset {dataset}\\n\"", "\n", "f\"    Out dir: {ds_out_dir}\"", ")", "\n", "run_pred_and_eval", "(", "dataset", "=", "dataset", ",", "\n", "out_dir", "=", "ds_out_dir", ",", "\n", "model", "=", "model", ",", "\n", "model_func", "=", "model_func", ",", "\n", "hparams", "=", "hparams", ",", "\n", "args", "=", "args", ")", "\n", "", "if", "len", "(", "eval_dirs", ")", ">", "1", ":", "\n", "        ", "cross_dataset_eval", "(", "eval_dirs", ",", "out_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.entry_func": [[508, 514], ["evaluate.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "evaluate.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Parse command line arguments", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.get_argparser": [[21, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Output a confusion matrix computed '", "\n", "'over one or more true/pred .npz '", "\n", "'files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--true_pattern\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"split*/predictions/test_data/dataset_1/files/*/true.npz\"", ",", "\n", "help", "=", "'Glob-like pattern to one or more .npz files '", "\n", "'storing the true labels'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pred_pattern\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"split*/predictions/test_data/dataset_1/files/*/pred.npz\"", ",", "\n", "help", "=", "'Glob-like pattern to one or more .npz files '", "\n", "'storing the true labels'", ")", "\n", "parser", ".", "add_argument", "(", "\"--normalized\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Normalize the CM to show fraction of total trues\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--show_pairs\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Show the paired files (for debugging)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--group_non_rem\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Group all non-rem stages (N1, N2, N3) into one.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--round\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Round float numbers, only applicable \"", "\n", "\"with --normalized.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wake_trim_min\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Only evaluate on within wake_trim_min of wake \"", "\n", "\"before and after sleep, as determined by true \"", "\n", "\"labels\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--period_length_sec\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"Used with --wake_trim_min to determine number of\"", "\n", "\" periods to trim\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ignore_classes\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Optional space separated list of class integers to ignore.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.wake_trim": [[64, 90], ["int", "max", "trimmed_pairs.append", "numpy.where"], "function", ["None"], ["", "def", "wake_trim", "(", "pairs", ",", "wake_trim_min", ",", "period_length_sec", ")", ":", "\n", "    ", "\"\"\"\n    Trim the pred/true pairs to remove long stretches of 'wake' in either end.\n    Trims to a maximum of 'wake_trim_min' of uninterrupted 'wake' in either\n    end, determined by the >TRUE< labels.\n\n    args:\n        pairs:            (list) A list of (true, prediction) pairs to trim\n        wake_trim_min:    (int)  Maximum number of minutes of uninterrupted wake\n                                 sleep stage (integer value '0') to allow\n                                 according to TRUE values.\n        period_length_sec (int)  The length in seconds of 1 period/epoch/segment\n\n    Returns:\n        List of trimmed (true, prediction) pairs\n    \"\"\"", "\n", "trim", "=", "int", "(", "(", "60", "/", "period_length_sec", ")", "*", "wake_trim_min", ")", "\n", "trimmed_pairs", "=", "[", "]", "\n", "for", "true", ",", "pred", "in", "pairs", ":", "\n", "        ", "inds", "=", "np", ".", "where", "(", "true", "!=", "0", ")", "[", "0", "]", "\n", "start", "=", "max", "(", "0", ",", "inds", "[", "0", "]", "-", "trim", ")", "\n", "end", "=", "inds", "[", "-", "1", "]", "+", "trim", "\n", "trimmed_pairs", ".", "append", "(", "[", "\n", "true", "[", "start", ":", "end", "]", ",", "pred", "[", "start", ":", "end", "]", "\n", "]", ")", "\n", "", "return", "trimmed_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.trim": [[92, 104], ["len", "len", "len", "len"], "function", ["None"], ["", "def", "trim", "(", "p1", ",", "p2", ")", ":", "\n", "    ", "\"\"\"\n    Trims a pair of label arrays (true/pred normally) to equal length by\n    removing elements from the tail of the longest array.\n    This assumes that the arrays are aligned to the first element.\n    \"\"\"", "\n", "diff", "=", "len", "(", "p1", ")", "-", "len", "(", "p2", ")", "\n", "if", "diff", ">", "0", ":", "\n", "        ", "p1", "=", "p1", "[", ":", "len", "(", "p2", ")", "]", "\n", "", "else", ":", "\n", "        ", "p2", "=", "p2", "[", ":", "len", "(", "p1", ")", "]", "\n", "", "return", "p1", ",", "p2", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.run": [[106, 187], ["logger.info", "sorted", "sorted", "list", "logger.info", "list", "enumerate", "map", "sklearn.metrics.confusion_matrix", "len", "pandas.DataFrame", "logger.info", "utime.evaluation.f1_scores_from_cm", "utime.evaluation.precision_scores_from_cm", "utime.evaluation.recall_scores_from_cm", "pandas.DataFrame", "pd.DataFrame.mean", "logger.info", "glob.glob", "glob.glob", "OSError", "OSError", "len", "len", "OSError", "len", "len", "ValueError", "len", "len", "ValueError", "zip", "logger.info", "map", "logger.info", "cm.wake_trim", "utime.evaluation.concatenate_true_pred_pairs", "logger.info", "list", "numpy.ones_like", "numpy.where", "numpy.where", "list.pop", "list.pop", "cm.astype.astype", "cm.astype.sum", "set", "set", "len", "len", "len", "logger.warning", "cm.trim", "x.astype().reshape", "numpy.isin", "numpy.isin", "list.index", "list.index", "len", "len", "numpy.load", "set", "str", "str", "numpy.load", "x.astype", "set", "set", "range", "range", "cm.astype.round", "range", "numpy.round", "os.path.splitext", "numpy.unique", "numpy.unique", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.f1_scores_from_cm", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.precision_scores_from_cm", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.recall_scores_from_cm", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.wake_trim", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.concatenate_true_pred_pairs", "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.trim"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run the script according to 'args' - Please refer to the argparser.\n    \"\"\"", "\n", "logger", ".", "info", "(", "\"Looking for files...\"", ")", "\n", "true", "=", "sorted", "(", "glob", "(", "args", ".", "true_pattern", ")", ")", "\n", "pred", "=", "sorted", "(", "glob", "(", "args", ".", "pred_pattern", ")", ")", "\n", "if", "not", "true", ":", "\n", "        ", "raise", "OSError", "(", "\"Did not find any 'true' files matching \"", "\n", "\"pattern {}\"", ".", "format", "(", "args", ".", "true_pattern", ")", ")", "\n", "", "if", "not", "pred", ":", "\n", "        ", "raise", "OSError", "(", "\"Did not find any 'true' files matching \"", "\n", "\"pattern {}\"", ".", "format", "(", "args", ".", "pred_pattern", ")", ")", "\n", "", "if", "len", "(", "true", ")", "!=", "len", "(", "pred", ")", ":", "\n", "        ", "raise", "OSError", "(", "\"Did not find a matching number \"", "\n", "\"of true and pred files ({} and {})\"", "\n", "\"\"", ".", "format", "(", "len", "(", "true", ")", ",", "len", "(", "pred", ")", ")", ")", "\n", "", "if", "len", "(", "true", ")", "!=", "len", "(", "set", "(", "true", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Two or more identical file names in the set \"", "\n", "\"of 'true' files. Cannot uniquely match true/pred \"", "\n", "\"files\"", ")", "\n", "", "if", "len", "(", "pred", ")", "!=", "len", "(", "set", "(", "pred", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Two or more identical file names in the set \"", "\n", "\"of 'pred' files. Cannot uniquely match true/pred \"", "\n", "\"files\"", ")", "\n", "\n", "", "pairs", "=", "list", "(", "zip", "(", "true", ",", "pred", ")", ")", "\n", "if", "args", ".", "show_pairs", ":", "\n", "        ", "logger", ".", "info", "(", "\"PAIRS:\\n{}\"", ".", "format", "(", "pairs", ")", ")", "\n", "# Load the pairs", "\n", "", "logger", ".", "info", "(", "\"Loading {} pairs...\"", ".", "format", "(", "len", "(", "pairs", ")", ")", ")", "\n", "l", "=", "lambda", "x", ":", "[", "np", ".", "load", "(", "f", ")", "[", "\"arr_0\"", "]", "if", "os", ".", "path", ".", "splitext", "(", "f", ")", "[", "-", "1", "]", "==", "\".npz\"", "else", "np", ".", "load", "(", "f", ")", "for", "f", "in", "x", "]", "\n", "np_pairs", "=", "list", "(", "map", "(", "l", ",", "pairs", ")", ")", "\n", "for", "i", ",", "(", "p1", ",", "p2", ")", "in", "enumerate", "(", "np_pairs", ")", ":", "\n", "        ", "if", "len", "(", "p1", ")", "!=", "len", "(", "p2", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Not equal lengths: {pairs[i]} {f'{len(p1)}/{len(p2)}'}. Trimming...\"", ")", "\n", "np_pairs", "[", "i", "]", "=", "trim", "(", "p1", ",", "p2", ")", "\n", "", "", "if", "args", ".", "wake_trim_min", ":", "\n", "        ", "logger", ".", "info", "(", "\"OBS: Wake trimming of {} minutes (period length {} sec)\"", "\n", "\"\"", ".", "format", "(", "args", ".", "wake_trim_min", ",", "args", ".", "period_length_sec", ")", ")", "\n", "np_pairs", "=", "wake_trim", "(", "np_pairs", ",", "\n", "args", ".", "wake_trim_min", ",", "\n", "args", ".", "period_length_sec", ")", "\n", "", "true", ",", "pred", "=", "map", "(", "lambda", "x", ":", "x", ".", "astype", "(", "np", ".", "uint8", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "concatenate_true_pred_pairs", "(", "pairs", "=", "np_pairs", ")", ")", "\n", "labels", "=", "None", "\n", "if", "args", ".", "ignore_classes", ":", "\n", "        ", "logger", ".", "info", "(", "\"OBS: Ignoring class(es): {}\"", ".", "format", "(", "args", ".", "ignore_classes", ")", ")", "\n", "labels", "=", "list", "(", "(", "set", "(", "np", ".", "unique", "(", "true", ")", ")", "|", "set", "(", "np", ".", "unique", "(", "pred", ")", ")", ")", "-", "set", "(", "args", ".", "ignore_classes", ")", ")", "\n", "\n", "", "if", "args", ".", "group_non_rem", ":", "\n", "        ", "ones", "=", "np", ".", "ones_like", "(", "true", ")", "\n", "true", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "true", ",", "[", "1", ",", "2", ",", "3", "]", ")", ",", "ones", ",", "true", ")", "\n", "pred", "=", "np", ".", "where", "(", "np", ".", "isin", "(", "pred", ",", "[", "1", ",", "2", ",", "3", "]", ")", ",", "ones", ",", "pred", ")", "\n", "labels", ".", "pop", "(", "labels", ".", "index", "(", "2", ")", ")", "\n", "labels", ".", "pop", "(", "labels", ".", "index", "(", "3", ")", ")", "\n", "\n", "", "cm", "=", "confusion_matrix", "(", "true", ",", "pred", ",", "labels", "=", "labels", ")", "\n", "if", "args", ".", "normalized", ":", "\n", "        ", "cm", "=", "cm", ".", "astype", "(", "np", ".", "float64", ")", "\n", "cm", "/=", "cm", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "# Pretty print", "\n", "", "classes", "=", "len", "(", "cm", ")", "\n", "cm", "=", "pd", ".", "DataFrame", "(", "data", "=", "cm", ",", "\n", "index", "=", "[", "\"True {}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "classes", ")", "]", ",", "\n", "columns", "=", "[", "\"Pred {}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "classes", ")", "]", ")", "\n", "p", "=", "\"Raw\"", "if", "not", "args", ".", "normalized", "else", "\"Normed\"", "\n", "logger", ".", "info", "(", "f\"\\n\\n{p} Confusion Matrix:\\n\"", "+", "str", "(", "cm", ".", "round", "(", "args", ".", "round", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "# Print metrics", "\n", "f1", "=", "f1_scores_from_cm", "(", "cm", ")", "\n", "prec", "=", "precision_scores_from_cm", "(", "cm", ")", "\n", "recall", "=", "recall_scores_from_cm", "(", "cm", ")", "\n", "metrics", "=", "pd", ".", "DataFrame", "(", "{", "\n", "\"F1\"", ":", "f1", ",", "\n", "\"Precision\"", ":", "prec", ",", "\n", "\"Recall/Sens.\"", ":", "recall", "\n", "}", ",", "index", "=", "[", "\"Class {}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "classes", ")", "]", ")", "\n", "metrics", "=", "metrics", ".", "T", "\n", "metrics", "[", "\"mean\"", "]", "=", "metrics", ".", "mean", "(", "axis", "=", "1", ")", "\n", "logger", ".", "info", "(", "f\"\\n\\n{p} Metrics:\\n\"", "+", "str", "(", "np", ".", "round", "(", "metrics", ".", "T", ",", "args", ".", "round", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.cm.entry_func": [[189, 195], ["cm.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "cm.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.get_argparser": [[14, 41], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'Extract hypnograms from various'", "\n", "' file formats.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_regex\"", ",", "type", "=", "str", ",", "\n", "help", "=", "'A glob statement matching all files to extract '", "\n", "'from'", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory in which extracted files will be \"", "\n", "\"stored\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fill_blanks\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"A stage string value to insert into the hypnogram when gaps \"", "\n", "\"occour, e.g. 'UNKNOWN' or 'Not Scored', etc.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--extract_func\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Name of hyp extraction function. If not specified, the file extension defines the \"", "\n", "\"function to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--remove_offset\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Remove potential offsets so that the first sleep stage always starts at init sec 0.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--correct_zero_durations\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "\"Optionally change any stage with duration \"", "\n", "\"0 seconds to some other duration. E.g., --correct_zero_durations 30 will set those events to 30 seconds.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite existing files of identical name and log files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "\"hyp_extraction_log\"", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is 'hyp_extraction_log'\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.to_ids": [[43, 47], ["open", "zip", "out_f.write", "int", "int"], "function", ["None"], ["", "def", "to_ids", "(", "start", ",", "durs", ",", "stage", ",", "out", ")", ":", "\n", "    ", "with", "open", "(", "out", ",", "\"w\"", ")", "as", "out_f", ":", "\n", "        ", "for", "i", ",", "d", ",", "s", "in", "zip", "(", "start", ",", "durs", ",", "stage", ")", ":", "\n", "            ", "out_f", ".", "write", "(", "\"{},{},{}\\n\"", ".", "format", "(", "int", "(", "i", ")", ",", "int", "(", "d", ")", ",", "s", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.remove_offset": [[49, 61], ["range", "len", "numpy.round", "ValueError"], "function", ["None"], ["", "", "", "def", "remove_offset", "(", "inits", ")", ":", "\n", "    ", "offset", "=", "inits", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inits", ")", ")", ":", "\n", "        ", "new_init", "=", "inits", "[", "i", "]", "-", "offset", "\n", "rounded_new_init", "=", "np", ".", "round", "(", "new_init", ")", "\n", "if", "new_init", "-", "rounded_new_init", ">", "1e-6", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpectedly large difference of {new_init - rounded_new_init} between new_init of \"", "\n", "f\"{new_init} and round(new_init) of {rounded_new_init} when \"", "\n", "\"removing offset. The implementation expects inits to land on whole-seconds, not \"", "\n", "\"fractions.\"", ")", "\n", "", "inits", "[", "i", "]", "=", "new_init", "\n", "", "return", "inits", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.run": [[63, 105], ["logger.info", "glob.glob", "pathlib.Path().absolute", "Path().absolute.mkdir", "len", "logger.info", "logger.info", "enumerate", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "logger.info", "os.path.exists", "psg_utils.io.hypnogram.extract_ids_from_hyp_file", "extract_hypno.to_ids", "pathlib.Path", "[].split", "os.path.split", "os.path.exists", "os.mkdir", "os.remove", "psg_utils.hypnogram.utils.fill_hyp_gaps", "vars", "extract_hypno.remove_offset", "os.path.split", "shutil.move", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.to_ids", "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.remove_offset"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "f\"Args dump: {vars(args)}\"", ")", "\n", "files", "=", "glob", "(", "args", ".", "file_regex", ")", "\n", "out_dir", "=", "Path", "(", "args", ".", "out_dir", ")", ".", "absolute", "(", ")", "\n", "out_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "n_files", "=", "len", "(", "files", ")", "\n", "logger", ".", "info", "(", "f\"Found {n_files} files matching glob statement\"", ")", "\n", "if", "n_files", "==", "0", ":", "\n", "        ", "return", "\n", "", "logger", ".", "info", "(", "f\"Saving .ids files to '{out_dir}'\"", ")", "\n", "if", "n_files", "==", "0", ":", "\n", "        ", "return", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "for", "i", ",", "file_", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "file_name", "=", "os", ".", "path", ".", "split", "(", "file_", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ",", "1", ")", "[", "0", "]", "\n", "folder_name", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "split", "(", "file_", ")", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "out_dir_subject", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "folder_name", ")", "\n", "out", "=", "os", ".", "path", ".", "join", "(", "out_dir_subject", ",", "file_name", "+", "\".ids\"", ")", "\n", "logger", ".", "info", "(", "f\"{i+1}/{n_files} Processing {file_name}\\n\"", "\n", "f\"-- In path    {file_}\\n\"", "\n", "f\"-- Out path   {out}\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir_subject", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "out_dir_subject", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "out", ")", ":", "\n", "            ", "if", "not", "args", ".", "overwrite", ":", "\n", "                ", "continue", "\n", "", "os", ".", "remove", "(", "out", ")", "\n", "", "inits", ",", "durs", ",", "stages", "=", "extract_ids_from_hyp_file", "(", "file_", ",", "\n", "period_length_sec", "=", "30", ",", "\n", "extract_func", "=", "args", ".", "extract_func", ",", "\n", "replace_zero_durations", "=", "args", ".", "correct_zero_durations", ")", "\n", "if", "args", ".", "remove_offset", ":", "\n", "            ", "try", ":", "\n", "                ", "inits", "=", "remove_offset", "(", "inits", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "import", "shutil", "\n", "shutil", ".", "move", "(", "file_", ",", "\"missing_labels\"", ")", "\n", "", "", "if", "args", ".", "fill_blanks", ":", "\n", "            ", "inits", ",", "durs", ",", "stages", "=", "fill_hyp_gaps", "(", "inits", ",", "durs", ",", "stages", ",", "args", ".", "fill_blanks", ")", "\n", "", "to_ids", "(", "inits", ",", "durs", ",", "stages", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract_hypno.entry_func": [[107, 113], ["extract_hypno.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "extract_hypno.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.get_argparser": [[35, 123], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["            ", "os", ".", "remove", "(", "p", ")", "\n", "\n", "\n", "", "", "", "def", "init_default_project_structure", "(", "project_folder", ",", "required_folders", "=", "(", "'logs'", ",", "'model'", ")", ")", ":", "\n", "    ", "for", "folder", "in", "required_folders", ":", "\n", "        ", "folder", "=", "os", ".", "path", ".", "join", "(", "project_folder", ",", "folder", ")", "\n", "os", ".", "mkdir", "(", "folder", ")", "\n", "\n", "\n", "", "", "def", "get_train_and_val_datasets", "(", "hparams", ",", "no_val", ",", "train_on_val", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return all pairs of (train, validation) SleepStudyDatasets as described in\n    the YAMLHParams object 'hparams'. A list is returned, as more than 1\n    dataset may be described in the parameter file.\n\n    Also returns an updated version of 'no_val', see below. Specifically, if\n    'train_on_val' is True, then no_val will be set to true no matter its\n    initial value.\n\n    Args:\n        hparams:      (YAMLHParams) A hyperparameter object to load dataset\n                                    configurations from.\n        no_val:       (bool)        Do not load validation data\n        train_on_val: (bool)        Load validation data, but merge it into\n                                    the training data. Then return only the\n                                    'trainin' (train+val) dataset.\n        dataset_ids (None, list)    Only load datasets with IDs in 'dataset_ids'.\n                                    If None, load all datasets.\n\n    Returns:\n        A list of training SleepStudyDataset objects\n        A list of validation SleepStudyDataset objects, or [] if not val.\n    \"\"\"", "\n", "if", "no_val", ":", "\n", "        ", "load", "=", "(", "\"train_data\"", ",", ")", "\n", "if", "train_on_val", ":", "\n", "            ", "raise", "ValueError", "(", "\"Should not specify --no_val with --train_on_val\"", ")", "\n", "", "", "else", ":", "\n", "        ", "load", "=", "(", "\"train_data\"", ",", "\"val_data\"", ")", "\n", "", "datasets", "=", "[", "*", "get_splits_from_all_datasets", "(", "hparams", ",", "load", ",", "dataset_ids", "=", "dataset_ids", ")", "]", "\n", "if", "train_on_val", ":", "\n", "        ", "if", "any", "(", "[", "len", "(", "ds", ")", "!=", "2", "for", "ds", "in", "datasets", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Did not find a validation set for one or more \"", "\n", "\"pairs in {}\"", ".", "format", "(", "datasets", ")", ")", "\n", "", "logger", ".", "info", "(", "\"[OBS] Merging training and validation sets\"", ")", "\n", "datasets", "=", "[", "merge_train_and_val", "(", "*", "ds", ")", "for", "ds", "in", "datasets", "]", "\n", "no_val", "=", "True", "\n", "", "if", "not", "no_val", ":", "\n", "        ", "train_datasets", ",", "val_datasets", "=", "zip", "(", "*", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "train_datasets", "=", "[", "d", "[", "0", "]", "for", "d", "in", "datasets", "]", "\n", "val_datasets", "=", "[", "]", "\n", "", "return", "train_datasets", ",", "val_datasets", "\n", "\n", "\n", "", "def", "get_h5_train_and_val_datasets", "(", "hparams", ",", "no_val", ",", "train_on_val", ",", "dataset_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        hparams:      (YAMLHParams) A hyperparameter object to load dataset\n                                    configurations from.\n        no_val:       (bool)        Do not load validation data\n        train_on_val: (bool)        Load validation data, but merge it into\n                                    the training data. Then return only the\n                                    'trainin' (train+val) dataset.\n        dataset_ids (None, list)    Only load datasets with IDs in 'dataset_ids'.\n                                    If None, load all datasets.\n\n    Returns:\n        A list of training SleepStudyDataset objects\n        A list of validation SleepStudyDataset objects, or [] if not val.\n    \"\"\"", "\n", "def", "_get_dataset", "(", "h5_dataset", ",", "regex", ",", "hparams", ")", ":", "\n", "        ", "\"\"\"\n        Helper for returning a dataset from a H5Dataset object according to\n        regex and a hyperparameter set for a single dataset.\n        \"\"\"", "\n", "h5_path", "=", "hparams", "[", "'data_dir'", "]", "\n", "if", "os", ".", "path", ".", "abspath", "(", "h5_path", ")", "!=", "os", ".", "path", ".", "abspath", "(", "h5_dataset", ".", "h5_path", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently all data must be stored in a single \"", "\n", "\".h5 file. Found two or more different files.\"", ")", "\n", "", "dataset", "=", "h5_dataset", ".", "get_datasets", "(", "\n", "load_match_regex", "=", "regex", ",", "\n", "period_length_sec", "=", "hparams", ".", "get", "(", "'period_length_sec'", ")", ",", "\n", "annotation_dict", "=", "hparams", ".", "get", "(", "'sleep_stage_annotations'", ")", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "1", "\n", "return", "dataset", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.assert_args": [[125, 134], ["ValueError", "ValueError", "ValueError"], "function", ["None"], ["", "if", "train_on_val", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Training on validation data is not yet \"", "\n", "\"implemented for preprocessed H5 datasets.\"", ")", "\n", "", "data_hparams", "=", "get_all_dataset_hparams", "(", "hparams", ",", "dataset_ids", "=", "dataset_ids", ")", "\n", "h5_dataset", "=", "None", "\n", "train_datasets", ",", "val_datasets", "=", "[", "]", ",", "[", "]", "\n", "for", "dataset_id", ",", "hparams", "in", "data_hparams", ".", "items", "(", ")", ":", "\n", "        ", "if", "h5_dataset", "is", "None", ":", "\n", "            ", "h5_dataset", "=", "SingleH5Dataset", "(", "hparams", "[", "'train_data'", "]", "[", "'data_dir'", "]", ")", "\n", "", "train", "=", "_get_dataset", "(", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.update_hparams_with_command_line_arguments": [[136, 160], ["hparams.save_current", "isinstance", "hparams.set_group", "utime.utils.scriptutils.train.get_all_dataset_hparams().items", "dataset_hparams.set_group", "dataset_hparams.delete_group", "dataset_hparams.save_current", "utime.utils.scriptutils.train.get_all_dataset_hparams"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_all_dataset_hparams"], ["regex", "=", "f'/{dataset_id}/TRAIN'", ",", "\n", "hparams", "=", "hparams", "[", "'train_data'", "]", "\n", ")", "\n", "train_datasets", ".", "append", "(", "train", ")", "\n", "ds", "=", "[", "train", "]", "\n", "if", "not", "no_val", ":", "\n", "            ", "val", "=", "_get_dataset", "(", "\n", "h5_dataset", "=", "h5_dataset", ",", "\n", "regex", "=", "f'/{dataset_id}/VAL'", ",", "\n", "hparams", "=", "hparams", "[", "'val_data'", "]", "\n", ")", "\n", "ds", ".", "append", "(", "val", ")", "\n", "val_datasets", ".", "append", "(", "val", ")", "\n", "", "select_sample_strip_scale_quality", "(", "*", "ds", ",", "hparams", "=", "hparams", ")", "\n", "", "return", "train_datasets", ",", "val_datasets", "\n", "\n", "\n", "", "def", "get_generators", "(", "train_datasets_queues", ",", "hparams", ",", "val_dataset_queues", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.keep_n_random": [[162, 176], ["logger.info", "numpy.random.choice", "dataset.update_id_to_study_dict"], "function", ["None"], ["\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.run": [[178, 298], ["train.assert_args", "os.path.abspath", "utime.utils.scriptutils.assert_project_folder", "utime.utils.scriptutils.add_logging_file_handler", "logger.info", "utime.hyperparameters.YAMLHParams", "train.update_hparams_with_command_line_arguments", "dataset_func", "psg_utils.dataset.queue.utils.get_data_queues", "utime.utils.scriptutils.train.get_generators", "utime.hyperparameters.YAMLHParams.set_group", "utime.hyperparameters.YAMLHParams.set_group", "utime.hyperparameters.YAMLHParams.save_current", "utime.utils.system.find_and_set_gpus", "logger.info", "utime.utils.scriptutils.train.get_samples_per_epoch", "utime.utils.scriptutils.train.remove_previous_session", "utime.utils.scriptutils.train.init_default_project_structure", "utime.Defaults.get_pre_processed_hparams_path", "utime.Defaults.get_hparams_path", "train.keep_n_random", "psg_utils.dataset.queue.utils.get_data_queues", "utime.models.model_init.prepare_for_continued_training", "g.name.replace", "len", "tensorflow.distribute.MirroredStrategy", "tensorflow.distribute.OneDeviceStrategy", "strategy.scope", "utime.models.model_init.init_model", "utime.train.Trainer", "utime.train.Trainer.compile_model", "utime.train.Trainer.fit", "utime.utils.scriptutils.train.save_final_weights", "OSError", "tensorflow.config.list_physical_devices", "utime.models.model_init.load_from_file", "train_study_loader.stop", "val_study_loader.stop", "vars", "hparams[].get"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.train.assert_args", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.update_hparams_with_command_line_arguments", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_generators", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.find_and_set_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_samples_per_epoch", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.remove_previous_session", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.init_default_project_structure", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.keep_n_random", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.prepare_for_continued_training", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.compile_model", "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.fit", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.save_final_weights", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.load_from_file"], ["train_seqs", "=", "[", "get_batch_sequence", "(", "dataset_queue", "=", "d", ",", "\n", "random_batches", "=", "True", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "augmenters", "=", "hparams", ".", "get", "(", "\"augmenters\"", ")", ",", "\n", "**", "hparams", "[", "\"fit\"", "]", ")", "for", "d", "in", "train_datasets_queues", "]", "\n", "val_seq", "=", "None", "\n", "if", "val_dataset_queues", ":", "\n", "        ", "val_seq", "=", "[", "get_batch_sequence", "(", "dataset_queue", "=", "d", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "hparams", "[", "'fit'", "]", ")", "for", "d", "in", "val_dataset_queues", "]", "\n", "", "if", "len", "(", "train_seqs", ")", ">", "1", ":", "\n", "# Wrap sequencers in MultiSequence object which creates batches by sampling", "\n", "# across its stores individual sequencers", "\n", "        ", "train_seq", "=", "MultiSequence", "(", "train_seqs", ",", "hparams", "[", "'fit'", "]", "[", "'batch_size'", "]", ")", "\n", "", "else", ":", "\n", "        ", "train_seq", "=", "train_seqs", "[", "0", "]", "\n", "", "if", "val_seq", ":", "\n", "        ", "assert", "len", "(", "val_seq", ")", "==", "len", "(", "train_seqs", ")", "\n", "val_seq", "=", "ValidationMultiSequence", "(", "val_seq", ")", "\n", "", "return", "train_seq", ",", "val_seq", "\n", "\n", "\n", "", "def", "merge_train_and_val", "(", "train", ",", "val", ")", ":", "\n", "    ", "\"\"\"\n    Takes two SleepStudyDataset objects 'train' and 'val' and merges them by\n    adding all stored SleepStudy pairs of 'val' to the list of pairs in 'train'\n    Then changes the 'identifier' attribute of the 'train' sequencer to reflect\n    the changes and returns the, now merged, 'train' dataset only (in a list).\n\n    Args:\n        train: A SleepStudyDataset object\n        val:   A SleepStudyDataset object\n\n    Returns:\n        A list of 1 SleepStudyDataset object storing data from both 'train'\n        and 'val'\n    \"\"\"", "\n", "train", ".", "add_pairs", "(", "val", ".", "pairs", ")", "\n", "train", ".", "_identifier", "=", "train", ".", "identifier", "+", "\"_\"", "+", "val", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "train", ".", "log", "(", ")", "\n", "return", "[", "train", "]", "\n", "\n", "\n", "", "def", "get_samples_per_epoch", "(", "train_seq", ",", "max_train_samples_per_epoch", ")", ":", "\n", "    ", "\"\"\"\n    Returns the number of samples to take from the training sequence objects\n    for 1 epoch to be considered finished.\n\n    Specifically, the specified number of training 'samples' in args\n    (number of sleep 'epochs'/'segments'/'periods') will be divided by the\n    total number of such segments that the model takes as input in each pass\n    I.e. if train_samples_per_epoch is set to 100 for a model which considers\n    10 epochs at a time, this function will return 100/10 = 10 steps per train\n    epoch.\n\n    Note: The (non-standardized) training samples is upper bounded by the\n    total number of samples in the dataset.\n\n    Args:\n        train_seq:                  (Sequence) The training Sequence or\n                                               MultiSequence object\n        max_train_samples_per_epoch (int)      Maximum number of samples for\n                                               training. The actual number will\n                                               be the lesser of this value and\n                                               the total number of samples.\n\n    Returns:\n        Number of samples to take in training and validation\n    \"\"\"", "\n", "try", ":", "\n", "        ", "total_periods", "=", "train_seq", ".", "total_periods", "\n", "", "except", "(", "NotLoadedError", ",", "TypeError", ")", ":", "\n", "# train_seq.total_period is not available (not all samples loaded or limitation queue). Use estimate.", "\n", "        ", "n_studies", "=", "train_seq", ".", "num_pairs", "\n", "total_periods", "=", "2000", "*", "n_studies", "\n", "logger", ".", "warning", "(", "f\"Property 'total_periods' not available on sequence {train_seq}. \"", "\n", "f\"Using (over)estimate total periods of {total_periods} based on dataset length of {n_studies}.\"", ")", "\n", "", "train_samples_per_epoch", "=", "min", "(", "total_periods", ",", "max_train_samples_per_epoch", ")", "\n", "if", "train_seq", ".", "margin", ":", "\n", "# For sequence models, we only sample a number of batches to cover", "\n", "# all data in once (in expectation).", "\n", "        ", "m", "=", "train_seq", ".", "margin", "*", "2", "+", "1", "\n", "train_samples_per_epoch", "=", "int", "(", "train_samples_per_epoch", "/", "m", ")", "\n", "", "return", "train_samples_per_epoch", "\n", "\n", "\n", "", "def", "get_lr_at_epoch", "(", "epoch", ",", "log_dir", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training.csv\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_path", ")", ":", "\n", "        ", "print", "(", "\"No training.csv file found at %s. Continuing with default \"", "\n", "\"learning rate found in parameter file.\"", "%", "log_dir", ")", "\n", "return", "None", ",", "None", "\n", "", "df", "=", "pd", ".", "read_csv", "(", "log_path", ")", "\n", "possible_names", "=", "(", "\"lr\"", ",", "\"LR\"", ",", "\"learning_rate\"", ",", "\"LearningRate\"", ")", "\n", "try", ":", "\n", "        ", "in_df", "=", "[", "l", "in", "df", ".", "columns", "for", "l", "in", "possible_names", "]", ".", "index", "(", "True", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "col_name", "=", "possible_names", "[", "in_df", "]", "\n", "return", "float", "(", "df", "[", "col_name", "]", "[", "int", "(", "epoch", ")", "]", ")", ",", "col_name", "\n", "\n", "\n", "", "def", "clear_csv_after_epoch", "(", "epoch", ",", "csv_file", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "csv_file", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "csv_file", ")", "\n", "", "except", "pd", ".", "errors", ".", "EmptyDataError", ":", "\n", "# Remove the file", "\n", "            ", "os", ".", "remove", "(", "csv_file", ")", "\n", "return", "\n", "# Remove any trailing runs and remove after 'epoch'", "\n", "", "try", ":", "\n", "            ", "df", "=", "df", "[", "np", ".", "flatnonzero", "(", "df", "[", "\"epoch\"", "]", "==", "0", ")", "[", "-", "1", "]", ":", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "pass", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.train.entry_func": [[300, 308], ["train.get_argparser", "get_argparser.parse_args", "train.run", "tables.file._open_files.close_all"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["# Save again", "\n", "with", "open", "(", "csv_file", ",", "\"w\"", ")", "as", "out_f", ":", "\n", "            ", "out_f", ".", "write", "(", "df", ".", "to_csv", "(", "index", "=", "False", ")", ")", "\n", "\n", "\n", "", "", "", "def", "get_last_epoch", "(", "csv_file", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.get_parser": [[22, 60], ["pkgutil.iter_modules", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "len", "os.path.split", "isinstance", "choices.append", "os.path.abspath"], "function", ["None"], ["def", "get_parser", "(", ")", ":", "\n", "    ", "mods", "=", "pkgutil", ".", "iter_modules", "(", "bin", ".", "__path__", ")", "\n", "\n", "ids", "=", "f\"U-Time ({__version__})\"", "\n", "sep", "=", "\"-\"", "*", "len", "(", "ids", ")", "\n", "usage", "=", "(", "f\"ut [--help] script [script args]... [--seed]\\n\\n\"", "\n", "f\"{ids}\\n\"", "\n", "f\"{sep}\\n\"", "\n", "f\"Available scripts:\\n\"", ")", "\n", "\n", "choices", "=", "[", "]", "\n", "file_name", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "[", "-", "1", "]", "\n", "for", "m", "in", "mods", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "tuple", ")", ":", "\n", "            ", "name", ",", "ispkg", "=", "m", "[", "1", "]", ",", "m", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "name", ",", "ispkg", "=", "m", ".", "name", ",", "m", ".", "ispkg", "\n", "", "if", "name", "==", "file_name", "[", ":", "-", "3", "]", "or", "ispkg", ":", "\n", "            ", "continue", "\n", "", "usage", "+=", "\"- \"", "+", "name", "+", "\"\\n\"", "\n", "choices", ".", "append", "(", "name", ")", "\n", "\n", "# Top level parser", "\n", "", "parser", "=", "argparse", ".", "ArgumentParser", "(", "usage", "=", "usage", ")", "\n", "parser", ".", "add_argument", "(", "\"script\"", ",", "help", "=", "\"Name of the ut script to run.\"", ",", "\n", "choices", "=", "choices", ")", "\n", "parser", ".", "add_argument", "(", "\"--project_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./\"", ",", "\n", "help", "=", "'Path to U-Time project folder. '", "\n", "'Default is \"./\" (current working directory)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_dir\"", ",", "default", "=", "\"logs\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to directory that should store logs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_level\"", ",", "default", "=", "\"INFO\"", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'DEBUG'", ",", "'INFO'", ",", "'WARNING'", ",", "'WARN'", ",", "'ERROR'", ",", "'FATAL'", ",", "'CRITICAL'", "]", ",", "\n", "help", "=", "\"Set the logging level for this script. Default 'INFO'.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Run this script with numpy, random and tensorflow RNGs seeded \"", "\n", "\"from integer --seed.\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.split_help_from_args": [[62, 70], ["help_args.append", "other_args.append"], "function", ["None"], ["", "def", "split_help_from_args", "(", "args", ")", ":", "\n", "    ", "other_args", ",", "help_args", "=", "[", "]", ",", "[", "]", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "arg", "==", "\"-h\"", "or", "arg", "==", "\"--help\"", ":", "\n", "            ", "help_args", ".", "append", "(", "\"--help\"", ")", "\n", "", "else", ":", "\n", "            ", "other_args", ".", "append", "(", "arg", ")", "\n", "", "", "return", "other_args", ",", "help_args", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.entry_func": [[72, 104], ["ut.split_help_from_args", "get_parser().parse_known_args", "os.path.abspath", "utime.Defaults.init_package_level_loggers", "logger.info", "utime.Defaults.set_project_directory", "logging.getLogger().setLevel", "importlib.import_module", "importlib.import_module.entry_func", "utime.Defaults.set_global_seed", "ut.get_parser", "logging.getLogger", "vars"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.split_help_from_args", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.init_package_level_loggers", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_project_directory", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.entry_func", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.set_global_seed", "home.repos.pwc.inspect_result.perslev_U-Time.bin.ut.get_parser"], ["", "def", "entry_func", "(", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "args", ",", "help_agrs", "=", "split_help_from_args", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", "\n", "parsed", ",", "script_args", "=", "get_parser", "(", ")", ".", "parse_known_args", "(", "args", "or", "help_agrs", ")", "\n", "\n", "# Set logging output dir on Defaults object", "\n", "# OBS we do not create the folder yet.", "\n", "# Handled in add_logging_file_handler of individual script where overwriting is also checked.", "\n", "Defaults", ".", "LOG_DIR", "=", "os", ".", "path", ".", "abspath", "(", "parsed", ".", "log_dir", ")", "\n", "\n", "# Init both the utime and psg_utils package-level loggers to share formatter and handlers", "\n", "Defaults", ".", "init_package_level_loggers", "(", "parsed", ".", "log_level", ",", "package_names", "=", "(", "Defaults", ".", "PACKAGE_NAME", ",", "\n", "psg_utils", ".", "__name__", ")", ")", "\n", "logger", ".", "info", "(", "f\"Entry script args dump: {vars(parsed)}\"", ")", "\n", "\n", "# Set project directory for the script", "\n", "Defaults", ".", "set_project_directory", "(", "parsed", ".", "project_dir", ")", "\n", "\n", "# Set Tensorflow logging level to ERROR or higher.", "\n", "# This omits a range of (usually....) unimportant warning message.", "\n", "os", ".", "environ", "[", "'TF_CPP_MIN_LOG_LEVEL'", "]", "=", "'2'", "\n", "logging", ".", "getLogger", "(", "\"tensorflow\"", ")", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "\n", "script", "=", "parsed", ".", "script", "\n", "if", "parsed", ".", "seed", "is", "not", "None", ":", "\n", "        ", "Defaults", ".", "set_global_seed", "(", "parsed", ".", "seed", ")", "\n", "\n", "# Import the script", "\n", "", "mod", "=", "importlib", ".", "import_module", "(", "\"utime.bin.\"", "+", "script", ")", "\n", "\n", "# Call entry function with remaining arguments", "\n", "mod", ".", "entry_func", "(", "script_args", "+", "help_agrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.get_argparser": [[33, 55], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'TODO'", ")", "# TODO", "\n", "parser", ".", "add_argument", "(", "\"--out_path\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to output h5 archive\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_splits\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "'*'", ",", "\n", "help", "=", "\"Dataset splits (e.g. train_data) to preprocess \"", "\n", "\"and save; space-separated list.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite previous pre-processed data'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_threads\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of threads to use for loading and \"", "\n", "\"writing. Note: HDF5 must be compiled in \"", "\n", "\"thread-safe mode!\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "\"preprocessing\"", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is 'preprocessing'\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.copy_dataset_hparams": [[57, 67], ["hparams.save_current.save_current", "list", "hparams.save_current.save_current", "hparams.save_current.keys", "hparams.save_current.delete_group"], "function", ["None"], ["", "def", "copy_dataset_hparams", "(", "hparams", ",", "hparams_out_path", ")", ":", "\n", "    ", "groups_to_save", "=", "(", "'select_channels'", ",", "\n", "'alternative_select_channels'", ",", "\n", "'channel_sampling_groups'", ")", "\n", "hparams", "=", "hparams", ".", "save_current", "(", "hparams_out_path", ",", "return_copy", "=", "True", ")", "\n", "groups", "=", "list", "(", "hparams", ".", "keys", "(", ")", ")", "\n", "for", "group", "in", "groups", ":", "\n", "        ", "if", "group", "not", "in", "groups_to_save", ":", "\n", "            ", "hparams", ".", "delete_group", "(", "group", ")", "\n", "", "", "hparams", ".", "save_current", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.add_dataset_entry": [[69, 77], ["open", "out_f.write", "split_identifier.upper"], "function", ["None"], ["", "def", "add_dataset_entry", "(", "hparams_out_path", ",", "h5_path", ",", "\n", "split_identifier", ",", "period_length_sec", ")", ":", "\n", "    ", "field", "=", "f\"{split_identifier}_data:\\n\"", "+", "f\"  data_dir: {h5_path}\\n\"", "+", "f\"  period_length_sec: {period_length_sec}\\n\"", "+", "f\"  identifier: {split_identifier.upper()}\\n\\n\"", "\n", "with", "open", "(", "hparams_out_path", ",", "\"a\"", ")", "as", "out_f", ":", "\n", "        ", "out_f", ".", "write", "(", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.preprocess_study": [[79, 114], ["h5_file_group.create_group", "h5_file_group.create_group.create_group", "study.loaded_in_context", "study.get_all_periods", "enumerate", "h5_file_group.create_group.create_dataset", "h5_file_group.create_group.create_group", "study_group.create_group.create_dataset", "numpy.dtype", "numpy.dtype", "[].astype", "study_group.create_group.create_dataset", "len", "str", "numpy.where"], "function", ["None"], ["", "", "def", "preprocess_study", "(", "h5_file_group", ",", "study", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        h5_file_group:\n        study:\n\n    Returns:\n        None\n    \"\"\"", "\n", "# Create groups", "\n", "study_group", "=", "h5_file_group", ".", "create_group", "(", "study", ".", "identifier", ")", "\n", "psg_group", "=", "study_group", ".", "create_group", "(", "\"PSG\"", ")", "\n", "with", "study", ".", "loaded_in_context", "(", "allow_missing_channels", "=", "True", ")", ":", "\n", "        ", "X", ",", "y", "=", "study", ".", "get_all_periods", "(", ")", "\n", "for", "chan_ind", ",", "channel_name", "in", "enumerate", "(", "study", ".", "select_channels", ")", ":", "\n", "# Create PSG channel datasets", "\n", "            ", "psg_group", ".", "create_dataset", "(", "channel_name", ".", "original_name", ",", "\n", "data", "=", "X", "[", "...", ",", "chan_ind", "]", ")", "\n", "# Create hypnogram dataset", "\n", "", "study_group", ".", "create_dataset", "(", "\"hypnogram\"", ",", "data", "=", "y", ")", "\n", "\n", "# Create class --> index lookup groups", "\n", "cls_to_indx_group", "=", "study_group", ".", "create_group", "(", "'class_to_index'", ")", "\n", "dtype", "=", "np", ".", "dtype", "(", "'uint16'", ")", "if", "len", "(", "y", ")", "<=", "65535", "else", "np", ".", "dtype", "(", "'uint32'", ")", "\n", "classes", "=", "study", ".", "hypnogram", ".", "classes", "\n", "for", "class_", "in", "classes", ":", "\n", "            ", "inds", "=", "np", ".", "where", "(", "y", "==", "class_", ")", "[", "0", "]", ".", "astype", "(", "dtype", ")", "\n", "cls_to_indx_group", ".", "create_dataset", "(", "\n", "str", "(", "class_", ")", ",", "data", "=", "inds", "\n", ")", "\n", "\n", "# Set attributes, currently only sample rate is (/may be) used", "\n", "", "study_group", ".", "attrs", "[", "'sample_rate'", "]", "=", "study", ".", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.run": [[116, 200], ["os.path.abspath", "utime.utils.scriptutils.assert_project_folder", "logger.info", "utime.hyperparameters.YAMLHParams", "utime.utils.scriptutils.get_splits_from_all_datasets", "os.path.exists", "utime.Defaults.get_pre_processed_data_configurations_dir", "utime.Defaults.get_hparams_path", "os.path.exists", "os.mkdir", "concurrent.futures.ThreadPoolExecutor", "os.remove", "logger.info", "exit", "h5py.File", "vars", "os.path.join", "preprocess.copy_dataset_hparams", "utime.hyperparameters.YAMLHParams.set_group", "utime.hyperparameters.YAMLHParams.save_current", "dataset[].identifier.split", "utime.Defaults.get_pre_processed_hparams_path", "preprocess.add_dataset_entry", "dataset_hparams.get", "h5_file.create_group", "functools.partial", "logger.info", "len", "enumerate", "print", "[].lower", "list", "logger.info", "split.set_channel_sampling_groups", "split.set_select_channels", "pool.map", "print", "set", "utime.utils.flatten_lists_recursively", "split.identifier.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.get_splits_from_all_datasets", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_data_configurations_dir", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.copy_dataset_hparams", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_pre_processed_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.add_dataset_entry", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.flatten_lists_recursively"], ["", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Run the script according to args - Please refer to the argparser.\n\n    args:\n        args:    (Namespace)  command-line arguments\n    \"\"\"", "\n", "project_dir", "=", "os", ".", "path", ".", "abspath", "(", "\"./\"", ")", "\n", "assert_project_folder", "(", "project_dir", ")", "\n", "logger", ".", "info", "(", "f\"Args dump: {vars(args)}\"", ")", "\n", "\n", "# Load hparams", "\n", "hparams", "=", "YAMLHParams", "(", "Defaults", ".", "get_hparams_path", "(", "project_dir", ")", ",", "no_version_control", "=", "True", ")", "\n", "\n", "# Initialize and load (potentially multiple) datasets", "\n", "datasets", "=", "get_splits_from_all_datasets", "(", "hparams", ",", "\n", "splits_to_load", "=", "args", ".", "dataset_splits", ",", "\n", "return_data_hparams", "=", "True", ")", "\n", "\n", "# Check if file exists, and overwrite if specified", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "out_path", ")", ":", "\n", "        ", "if", "args", ".", "overwrite", ":", "\n", "            ", "os", ".", "remove", "(", "args", ".", "out_path", ")", "\n", "", "else", ":", "\n", "            ", "from", "sys", "import", "exit", "\n", "logger", ".", "info", "(", "f\"Out file at {args.out_path} exists, and --overwrite was not set\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "# Create dataset hparams output directory", "\n", "", "", "out_dir", "=", "Defaults", ".", "get_pre_processed_data_configurations_dir", "(", "project_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "", "with", "ThreadPoolExecutor", "(", "args", ".", "num_threads", ")", "as", "pool", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "args", ".", "out_path", ",", "\"w\"", ")", "as", "h5_file", ":", "\n", "            ", "for", "dataset", ",", "dataset_hparams", "in", "datasets", ":", "\n", "# Create a new version of the dataset-specific hyperparameters", "\n", "# that contain only the fields needed for pre-processed data", "\n", "                ", "name", "=", "dataset", "[", "0", "]", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "hparams_out_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "name", "+", "\".yaml\"", ")", "\n", "copy_dataset_hparams", "(", "dataset_hparams", ",", "hparams_out_path", ")", "\n", "\n", "# Update paths to dataset hparams in main hparams file", "\n", "hparams", ".", "set_group", "(", "f\"/datasets/{name}\"", ",", "\n", "value", "=", "hparams_out_path", ",", "\n", "overwrite", "=", "True", ")", "\n", "\n", "# Save the hyperparameters to the pre-processed main hparams", "\n", "hparams", ".", "save_current", "(", "Defaults", ".", "get_pre_processed_hparams_path", "(", "\n", "project_dir", "\n", ")", ")", "\n", "\n", "# Process each dataset", "\n", "for", "split", "in", "dataset", ":", "\n", "# Add this split to the dataset-specific hparams", "\n", "                    ", "add_dataset_entry", "(", "hparams_out_path", ",", "\n", "args", ".", "out_path", ",", "\n", "split", ".", "identifier", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "lower", "(", ")", ",", "\n", "split", ".", "period_length_sec", ")", "\n", "\n", "# Overwrite potential load time channel sampler to None", "\n", "channel_sampling_groups", "=", "dataset_hparams", ".", "get", "(", "'channel_sampling_groups'", ")", "\n", "if", "channel_sampling_groups", ":", "\n", "                        ", "unique_channels", "=", "list", "(", "set", "(", "flatten_lists_recursively", "(", "\n", "channel_sampling_groups", "\n", ")", ")", ")", "\n", "logger", ".", "info", "(", "f\"Found channel sampling groups '{channel_sampling_groups}'. \"", "\n", "f\"Saving unique channels {unique_channels}.\"", ")", "\n", "split", ".", "set_channel_sampling_groups", "(", "None", ")", "\n", "split", ".", "set_select_channels", "(", "unique_channels", ")", "\n", "\n", "# Create dataset group", "\n", "", "split_group", "=", "h5_file", ".", "create_group", "(", "split", ".", "identifier", ")", "\n", "\n", "# Run the preprocessing", "\n", "process_func", "=", "partial", "(", "preprocess_study", ",", "split_group", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Preprocessing dataset: {split}\"", ")", "\n", "n_pairs", "=", "len", "(", "split", ".", "pairs", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "pool", ".", "map", "(", "process_func", ",", "\n", "split", ".", "pairs", ")", ")", ":", "\n", "                        ", "print", "(", "\"  {}/{}\"", ".", "format", "(", "i", "+", "1", ",", "n_pairs", ")", ",", "\n", "end", "=", "'\\r'", ",", "flush", "=", "True", ")", "\n", "", "print", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.preprocess.entry_func": [[202, 208], ["preprocess.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "preprocess.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "", "", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.get_argparser": [[21, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "\"Download and preprocess a sleep \"", "\n", "\"staging (PSG) dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the dataset to download. \"", "\n", "f\"Must be one of: {', '.join(DATASETS)}\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to a directory that should store the data.\"", "\n", "\" If the directory does not exist, it will be \"", "\n", "\"created.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--N_first\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Download only the N first samples \"", "\n", "\"(default: download all)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_preprocessing\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do not apply preprocessing on the downloaded \"", "\n", "\"data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite existing log files (see --log_file). \"", "\n", "\"Note that fetch data is only overwritten if the file has invalid SHA256 values. \"", "\n", "\"Otherwise, with valid SHA256, existing files on disk are always skipped. \"", "\n", "\"I.e., the --overwrite flag does not stored influence data for this script.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.validate_dataset": [[53, 59], ["logger.info", "sys.exit"], "function", ["None"], ["", "def", "validate_dataset", "(", "dataset", ")", ":", "\n", "    ", "\"\"\" Asserts that the specified dataset is supported \"\"\"", "\n", "if", "dataset", "not", "in", "DATASETS", ":", "\n", "        ", "datasets_str", "=", "'\\n- '", ".", "join", "(", "DATASETS", ")", "\n", "logger", ".", "info", "(", "f\"Dataset {dataset} is invalid, must be one of:\\n- {datasets_str}\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.validate_and_create_out_dir": [[61, 68], ["os.path.exists", "logger.info", "os.makedirs"], "function", ["None"], ["", "", "def", "validate_and_create_out_dir", "(", "out_dir", ")", ":", "\n", "    ", "\"\"\"\n    Creates directory/directories if not existing\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating output directory {}\"", ".", "format", "(", "out_dir", ")", ")", "\n", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.run": [[70, 78], ["utime.utils.scriptutils.add_logging_file_handler", "os.path.abspath", "fetch.validate_dataset", "fetch.validate_and_create_out_dir", "psg_utils.downloads.download_dataset", "psg_utils.downloads.preprocess_dataset"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.validate_dataset", "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.validate_and_create_out_dir"], ["", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "out_dir", ")", "\n", "validate_dataset", "(", "args", ".", "dataset", ")", "\n", "validate_and_create_out_dir", "(", "out_dir", ")", "\n", "download_dataset", "(", "args", ".", "dataset", ",", "out_dir", ",", "args", ".", "N_first", ")", "\n", "if", "not", "args", ".", "no_preprocessing", ":", "\n", "        ", "preprocess_dataset", "(", "args", ".", "dataset", ",", "out_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.fetch.entry_func": [[80, 84], ["fetch.get_argparser", "fetch.run", "get_argparser.parse_args"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "run", "(", "parser", ".", "parse_args", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_argparser": [[12, 33], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Majority vote across a set of channels.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to folder storing predictions for each dataset. '", "\n", "'The specified folder must store sub-folders for each given dataset. '", "\n", "'Each dataset folder must store results from each channel combination each '", "\n", "'in a sub-folder named according to the channel combination.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--soft\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If using NxC shaped probability-like arrays, use this option to sum arrays \"", "\n", "\"instead of computing mode.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing output files and log files.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is None (no log file)\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_datasets": [[35, 41], ["glob.glob", "os.path.split", "os.path.isdir"], "function", ["None"], ["", "def", "get_datasets", "(", "folder", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary of dataset-ID: dataset directory paths\n    \"\"\"", "\n", "paths", "=", "glob", "(", "f\"{folder}/*\"", ")", "\n", "return", "{", "os", ".", "path", ".", "split", "(", "p", ")", "[", "-", "1", "]", ":", "p", "for", "p", "in", "paths", "if", "os", ".", "path", ".", "isdir", "(", "p", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_true_paths": [[43, 50], ["glob.glob", "[].split", "os.path.split"], "function", ["None"], ["", "def", "get_true_paths", "(", "dataset_dir", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary of study-ID: true/target vector paths\n    \"\"\"", "\n", "true_paths", "=", "glob", "(", "f'{dataset_dir}/*TRUE.np*'", ")", "\n", "return", "{", "\n", "os", ".", "path", ".", "split", "(", "p", ")", "[", "-", "1", "]", ".", "split", "(", "\"_TRUE\"", ")", "[", "0", "]", ":", "p", "for", "p", "in", "true_paths", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_prediction_paths": [[53, 60], ["glob.glob", "[].split", "os.path.split"], "function", ["None"], ["", "def", "get_prediction_paths", "(", "pred_dir", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary of study-ID: predicted vector paths\n    \"\"\"", "\n", "pred_paths", "=", "glob", "(", "f'{pred_dir}/*PRED.np*'", ")", "\n", "return", "{", "\n", "os", ".", "path", ".", "split", "(", "p", ")", "[", "-", "1", "]", ".", "split", "(", "\"_PRED\"", ")", "[", "0", "]", ":", "p", "for", "p", "in", "pred_paths", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_input_channel_combinations": [[63, 69], ["glob.glob"], "function", ["None"], ["", "def", "get_input_channel_combinations", "(", "dataset_dir", ",", "study_id", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary of channel-combination string IDs: dir paths\n    \"\"\"", "\n", "# Find all directories in the dataset directory", "\n", "return", "glob", "(", "f'{dataset_dir}/*/*{study_id}_PRED.np*'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_arrays": [[71, 80], ["numpy.stack", "loaded.append", "numpy.load"], "function", ["None"], ["", "def", "get_arrays", "(", "paths", ")", ":", "\n", "    ", "\"\"\"\n    Takes a dictionary of study-ID: numpy npy/npz file path and returns\n    a dictionary of study-ID: loaded numpy arrays\n    \"\"\"", "\n", "loaded", "=", "[", "]", "\n", "for", "arr_path", "in", "paths", ":", "\n", "        ", "loaded", ".", "append", "(", "np", ".", "load", "(", "arr_path", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "loaded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.run": [[82, 112], ["majority_vote.get_datasets", "get_datasets.items", "logger.info", "set", "logger.info", "os.path.exists", "os.mkdir", "logger.info", "majority_vote.get_input_channel_combinations", "majority_vote.get_arrays", "numpy.save", "numpy.mean().squeeze", "[].squeeze", "os.path.exists", "OSError", "[].split", "glob.glob", "len", "numpy.mean", "scipy.stats.mode", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_datasets", "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_input_channel_combinations", "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.get_arrays", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "dataset_dirs", "=", "get_datasets", "(", "folder", "=", "args", ".", "folder", ")", "\n", "\n", "for", "dataset", ",", "dataset_dir_path", "in", "dataset_dirs", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Processing dataset '{dataset}'\"", ")", "\n", "\n", "# Create majority vote folder", "\n", "out_dir", "=", "f'{dataset_dir_path}/majority'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "# Get all study IDs", "\n", "", "study_ids", "=", "set", "(", "[", "os", ".", "path", ".", "split", "(", "s", ")", "[", "-", "1", "]", ".", "split", "(", "\"_PRED\"", ")", "[", "0", "]", "for", "s", "in", "glob", "(", "dataset_dir_path", "+", "\"/**/*PRED.npy\"", ")", "]", ")", "\n", "logger", ".", "info", "(", "f\"Found {len(study_ids)} paths to study IDs\"", ")", "\n", "\n", "for", "study_id", "in", "study_ids", ":", "\n", "            ", "logger", ".", "info", "(", "dataset", ",", "study_id", ")", "\n", "channels", "=", "get_input_channel_combinations", "(", "dataset_dir_path", ",", "study_id", ")", "\n", "channel_arrs", "=", "get_arrays", "(", "channels", ")", "\n", "\n", "# Compute MJ vote", "\n", "if", "args", ".", "soft", ":", "\n", "                ", "mj", "=", "np", ".", "mean", "(", "channel_arrs", ",", "axis", "=", "0", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                ", "mj", "=", "stats", ".", "mode", "(", "channel_arrs", ",", "axis", "=", "0", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "", "out_path", "=", "f'{out_dir}/{study_id}_PRED'", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_path", ")", "and", "not", "args", ".", "overwrite", ":", "\n", "                ", "raise", "OSError", "(", "f\"Output file at {out_path} exists and the --overwrite flag was not set.\"", ")", "\n", "", "np", ".", "save", "(", "out_path", ",", "mj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.majority_vote.entry_func": [[114, 120], ["majority_vote.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "majority_vote.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Parse command line arguments", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.get_argparser": [[27, 74], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Extract a set of channels from a set '", "\n", "'of PSG files, various formats '", "\n", "'supported. The extracted data will be'", "\n", "' saved to .h5 files with minimal '", "\n", "'header information attributes.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_regex\"", ",", "type", "=", "str", ",", "\n", "help", "=", "'A glob statement matching all files to extract '", "\n", "'from'", ")", "\n", "parser", ".", "add_argument", "(", "\"--out_dir\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory in which extracted files will be \"", "\n", "\"stored\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--channels\"", ",", "nargs", "=", "\"+\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Space-separated list of CHAN1-CHAN2 format of\"", "\n", "\"referenced channel montages to extract. A \"", "\n", "\"montage will be created if the referenced \"", "\n", "\"channel is not already available in the file. If\"", "\n", "\" the channel does not already exist and if \"", "\n", "\"CHAN1 or CHAN2 is not available, an error is \"", "\n", "\"raised.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rename_channels\"", ",", "nargs", "=", "\"+\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Space-separated list of channel names to save\"", "\n", "\" as instead of the originally extracted names. \"", "\n", "\"Must match in length --channels.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resample'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Re-sample the selected channels before storage.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_dir_names\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Each PSG file will be saved as '", "\n", "'<parent directory>.h5 instead of <file_name>.h5'", ")", "\n", "parser", ".", "add_argument", "(", "\"--trim_leading_seconds_dict\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Path to .pickle dictionary of format ['filename' (without extension): float 'seconds'] \"", "\n", "\"where 'seconds' is the number of seconds to trim from the start of file 'filename' before \"", "\n", "\"saving to newly extracted file. Note that 'filename' is the dictionary name if the \"", "\n", "\"--use_dir_names flag is also set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite existing files of identical name and log files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--continue_\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Skip already existing files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_file\"", ",", "type", "=", "str", ",", "default", "=", "\"extraction_log\"", ",", "\n", "help", "=", "\"Relative path (from Defaults.LOG_DIR as specified by ut --log_dir flag) of \"", "\n", "\"output log file for this script. \"", "\n", "\"Set to an empty string to not save any logs to file for this run. \"", "\n", "\"Default is 'extraction_log'\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.filter_channels": [[76, 82], ["enumerate", "enumerate"], "function", ["None"], ["", "def", "filter_channels", "(", "renamed_channels", ",", "selected_original_channels", ",", "\n", "original_channels", ")", ":", "\n", "    ", "inds_selected", "=", "[", "i", "for", "i", ",", "chan", "in", "enumerate", "(", "original_channels", ")", "\n", "if", "chan", "in", "selected_original_channels", "]", "\n", "return", "[", "chan", "for", "i", ",", "chan", "in", "enumerate", "(", "renamed_channels", ")", "\n", "if", "i", "in", "inds_selected", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract._extract": [[84, 151], ["psg_utils.io.channels.ChannelMontageCreator", "logger.info", "psg_utils.io.channels.ChannelMontageCreator.create_montages", "logger.info", "logger.info", "psg_utils.io.to_h5_file", "psg_utils.io.header.extract_header", "psg_utils.io.high_level_file_loaders.load_psg", "int", "logger.info", "logger.info", "logger.info", "psg_utils.preprocessing.psg_sampling.set_psg_sample_rate", "logger.info", "extract.filter_channels", "logger.info", "os.rmdir", "numpy.isnan", "numpy.isclose", "logger.warning", "int", "os.path.split", "len", "str", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.filter_channels"], ["", "def", "_extract", "(", "file_", ",", "\n", "out_path", ",", "\n", "channels", ",", "\n", "renamed_channels", ",", "\n", "trim_leading_sec", ",", "\n", "args", ")", ":", "\n", "    ", "channels_in_file", "=", "extract_header", "(", "file_", ")", "[", "\"channel_names\"", "]", "\n", "chan_creator", "=", "ChannelMontageCreator", "(", "existing_channels", "=", "channels_in_file", ",", "\n", "channels_required", "=", "channels", ",", "\n", "allow_missing", "=", "True", ")", "\n", "logger", ".", "info", "(", "f\"\\n[*] Channels in file: {', '.join(chan_creator.existing_channels.names)}\\n\"", "\n", "f\"[*] Output channels: {', '.join(chan_creator.output_channels.names)}\\n\"", "\n", "f\"[*] Channels to load: {', '.join(chan_creator.channels_to_load.names)}\"", ")", "\n", "try", ":", "\n", "        ", "psg", ",", "header", "=", "load_psg", "(", "file_", ",", "\n", "load_channels", "=", "chan_creator", ".", "channels_to_load", ",", "\n", "allow_missing_channels", "=", "True", ")", "\n", "", "except", "ChannelNotFoundError", "as", "e", ":", "\n", "        ", "logger", ".", "info", "(", "f\"\\n-----\\n\"", "\n", "f\"CHANNEL ERROR ON FILE {file_}\\n\"", "\n", "f\"{str(e)}\\n\"", "\n", "f\"-----\"", ")", "\n", "os", ".", "rmdir", "(", "os", ".", "path", ".", "split", "(", "out_path", ")", "[", "0", "]", ")", "\n", "return", "\n", "\n", "# create montages", "\n", "", "psg", ",", "channels", "=", "chan_creator", ".", "create_montages", "(", "psg", ")", "\n", "header", "[", "'channel_names'", "]", "=", "channels", "\n", "logger", ".", "info", "(", "f\"[*] Original PSG shape: {psg.shape}\"", ")", "\n", "\n", "# Trim if needed", "\n", "if", "trim_leading_sec", "and", "not", "np", ".", "isnan", "(", "trim_leading_sec", ")", ":", "\n", "        ", "n_trim", "=", "trim_leading_sec", "*", "header", "[", "'sample_rate'", "]", "\n", "if", "not", "np", ".", "isclose", "(", "n_trim", ",", "int", "(", "n_trim", ")", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"The number of trim seconds {trim_leading_sec} does not give a \"", "\n", "f\"whole number of datapoints to remove ({n_trim}) given sample rate \"", "\n", "f\"{header['sample_rate']}. Skipping file!\"", ")", "\n", "return", "\n", "", "n_trim", "=", "int", "(", "n_trim", ")", "\n", "psg", "=", "psg", "[", "n_trim", ":", "]", "\n", "logger", ".", "info", "(", "f\"[*] PSG shape after trimming (leading, seconds={trim_leading_sec}, sr={header['sample_rate']}, \"", "\n", "f\"N trim={n_trim}): {psg.shape}\"", ")", "\n", "\n", "", "if", "psg", ".", "shape", "[", "0", "]", "%", "header", "[", "'sample_rate'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"--- OBS: Length {len(psg)} not divisible by sample rate! \"", "\n", "f\"Trimming N items from end {len(psg) % header['sample_rate']}.\"", ")", "\n", "psg", "=", "psg", "[", ":", "-", "(", "psg", ".", "shape", "[", "0", "]", "%", "header", "[", "'sample_rate'", "]", ")", "]", "\n", "logger", ".", "info", "(", "f\"--- New PSG shape: {psg.shape}\"", ")", "\n", "\n", "# Resample", "\n", "", "if", "args", ".", "resample", ":", "\n", "        ", "psg", "=", "set_psg_sample_rate", "(", "psg", ",", "\n", "new_sample_rate", "=", "args", ".", "resample", ",", "\n", "old_sample_rate", "=", "header", "[", "'sample_rate'", "]", ")", "\n", "header", "[", "'sample_rate'", "]", "=", "args", ".", "resample", "\n", "logger", ".", "info", "(", "f\"[*] PSG shape after re-sampling: {psg.shape}\"", ")", "\n", "\n", "# Rename channels", "\n", "", "if", "renamed_channels", ":", "\n", "        ", "org_names", "=", "header", "[", "'channel_names'", "]", ".", "original_names", "\n", "header", "[", "'channel_names'", "]", "=", "filter_channels", "(", "renamed_channels", ",", "\n", "org_names", ",", "\n", "args", ".", "channels", ")", "\n", "", "else", ":", "\n", "        ", "header", "[", "'channel_names'", "]", "=", "header", "[", "'channel_names'", "]", ".", "original_names", "\n", "", "logger", ".", "info", "(", "f\"[*] Extracted {psg.shape[1]} channels: {header['channel_names']}\"", ")", "\n", "to_h5_file", "(", "out_path", ",", "psg", ",", "**", "header", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.extract": [[153, 191], ["enumerate", "os.path.exists", "os.makedirs", "logger.info", "os.path.join", "os.path.join", "os.path.exists", "extract._extract", "os.path.exists", "os.mkdir", "os.path.split", "os.path.splitext", "logger.info", "ValueError", "len", "OSError", "os.remove", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.extract._extract"], ["", "def", "extract", "(", "files", ",", "out_dir", ",", "channels", ",", "renamed_channels", ",", "trim_leading_seconds_dict", ",", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "for", "i", ",", "file_", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "if", "args", ".", "use_dir_names", ":", "\n", "            ", "name", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "split", "(", "file_", ")", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "file_", ")", "[", "-", "1", "]", ")", "[", "0", "]", "\n", "", "logger", ".", "info", "(", "\"\\n------------------\\n\"", "\n", "f\"[*] {i+1}/{len(files)} Processing {name}\"", ")", "\n", "out_dir_subject", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir_subject", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "out_dir_subject", ")", "\n", "", "out_path", "=", "os", ".", "path", ".", "join", "(", "out_dir_subject", ",", "name", "+", "\".h5\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_path", ")", ":", "\n", "            ", "if", "args", ".", "continue_", ":", "\n", "                ", "logger", ".", "info", "(", "\"-- Skipping (already exists, overwrite=False)\"", ")", "\n", "continue", "\n", "", "elif", "not", "args", ".", "overwrite", ":", "\n", "                ", "raise", "OSError", "(", "f\"File already exists at '{out_path}' abd neither --overwrite nor --continue was set.\"", ")", "\n", "", "else", ":", "\n", "                ", "os", ".", "remove", "(", "out_path", ")", "\n", "", "", "trim_leading_secs", "=", "0.0", "\n", "if", "trim_leading_seconds_dict", ":", "\n", "            ", "if", "name", "not", "in", "trim_leading_seconds_dict", ":", "\n", "                ", "raise", "ValueError", "(", "f\"The filename '{name}' does not exist as a key in dictioanry \"", "\n", "f\"'trim_leading_seconds_dict'. All files to extract must be represented in the trim \"", "\n", "f\"dictionary. If you do not want to trim this particular file, enter the filename \"", "\n", "f\"anyway into the dictionary with key:value pair ({name}: 0.0) to effectively apply \"", "\n", "f\"no trimming.\"", ")", "\n", "", "trim_leading_secs", "=", "trim_leading_seconds_dict", "[", "name", "]", "\n", "", "_extract", "(", "\n", "file_", "=", "file_", ",", "\n", "out_path", "=", "out_path", ",", "\n", "channels", "=", "channels", ",", "\n", "renamed_channels", "=", "renamed_channels", ",", "\n", "trim_leading_sec", "=", "trim_leading_secs", ",", "\n", "args", "=", "args", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.get_trim_dict": [[194, 203], ["os.path.exists", "OSError", "open", "pickle.load", "isinstance", "ValueError", "type"], "function", ["None"], ["", "", "def", "get_trim_dict", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "raise", "OSError", "(", "f\"No trim dict exists at path {path}\"", ")", "\n", "", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "in_f", ":", "\n", "        ", "trim_dict", "=", "pickle", ".", "load", "(", "in_f", ")", "\n", "", "if", "not", "isinstance", "(", "trim_dict", ",", "dict", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"The trim dict at path {path} with has an unexpected type ({type(trim_dict)}) \"", "\n", "f\"- expected {dict}\"", ")", "\n", "", "return", "trim_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.run": [[205, 241], ["logger.info", "glob.glob", "os.path.abspath", "logger.info", "psg_utils.io.channels.ChannelMontageTuple", "logger.info", "extract.extract", "os.path.exists", "os.mkdir", "RuntimeError", "len", "ValueError", "extract.get_trim_dict", "len", "len", "vars", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.extract", "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.get_trim_dict"], ["", "def", "run", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "f\"Args dump: {vars(args)}\"", ")", "\n", "files", "=", "glob", "(", "args", ".", "file_regex", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "", "if", "args", ".", "overwrite", "and", "args", ".", "continue_", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Only one of the flags '--continue' and '--overwrite' may be used.\"", ")", "\n", "", "logger", ".", "info", "(", "f\"Found {len(files)} files matching glob statement\"", ")", "\n", "if", "len", "(", "files", ")", "==", "0", ":", "\n", "        ", "return", "\n", "", "channels", "=", "ChannelMontageTuple", "(", "args", ".", "channels", ",", "relax", "=", "True", ")", "\n", "renamed_channels", "=", "args", ".", "rename_channels", "\n", "if", "renamed_channels", "and", "(", "len", "(", "renamed_channels", ")", "!=", "len", "(", "channels", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"--rename_channels argument must have the same number\"", "\n", "\" of elements as --channels. Got {} and {}.\"", ".", "format", "(", "\n", "len", "(", "channels", ")", ",", "len", "(", "renamed_channels", ")", "\n", ")", ")", "\n", "\n", "", "trim_leading_seconds_dict", "=", "None", "\n", "if", "args", ".", "trim_leading_seconds_dict", ":", "\n", "        ", "trim_leading_seconds_dict", "=", "get_trim_dict", "(", "args", ".", "trim_leading_seconds_dict", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Extracting channels {channels.names}\\n\"", "+", "\n", "(", "f\"Saving channels under names {renamed_channels}\\n\"", "if", "renamed_channels", "else", "\"\"", ")", "+", "\n", "f\"Saving .h5 files to '{out_dir}'\\n\"", "+", "\n", "f\"Re-sampling: {args.resample}\\n\"", "+", "\n", "(", "f\"Using (leading) trim dict at path '{args.trim_leading_seconds_dict}'\\n\"", "if", "trim_leading_seconds_dict", "else", "\"\"", ")", "+", "\n", "\"-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\"", ")", "\n", "extract", "(", "\n", "files", "=", "files", ",", "\n", "out_dir", "=", "out_dir", ",", "\n", "channels", "=", "channels", ",", "\n", "renamed_channels", "=", "renamed_channels", ",", "\n", "trim_leading_seconds_dict", "=", "trim_leading_seconds_dict", ",", "\n", "args", "=", "args", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.extract.entry_func": [[244, 250], ["extract.get_argparser", "get_argparser.parse_args", "utime.utils.scriptutils.add_logging_file_handler", "extract.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Get the script to execute, parse only first input", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "add_logging_file_handler", "(", "args", ".", "log_file", ",", "args", ".", "overwrite", ",", "mode", "=", "\"w\"", "if", "not", "args", ".", "continue_", "else", "\"a\"", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser": [[19, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_argparser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser for this script\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "'Predict using a U-Time model.'", ")", "\n", "parser", ".", "add_argument", "(", "\"-f\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to file to predict on.'", ")", "\n", "parser", ".", "add_argument", "(", "\"-o\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output path for storing predictions. \"", "\n", "\"Valid extensions are '.hyp' (text file with 1 stage (string) per line), \"", "\n", "\"'.ids' (init-duration-stage (string) format text file) and '.npy' (numpy array \"", "\n", "\"of shape [N, 1] storing stages (ints)). \"", "\n", "\"If any other or no extension is specified, '.npy' is assumed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--header_file_name\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Optional header file name. Header must be in the same folder of the input file, see -f.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--logging_out_path\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Optional path to store prediction log. If not set, <out_folder>/<file_name>.log is used.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--channels\"", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"A list of channels to use for prediction. \"", "\n", "\"To predict on multiple channel groups, pass a string where \"", "\n", "\"each channel in each channel group is separated by '++' and different groups are \"", "\n", "\"separated by space or '&&'. E.g. to predict on {EEG1, EOG1} and {EEG2, EOG2}, pass \"", "\n", "\"'EEG1++EOG1' 'EEG2++EOG2'. Each group will be used for prediction once, and the final \"", "\n", "\"results will be a majority vote across all. \"", "\n", "\"You may also specify a list of individual channels and use the --auto_channel_grouping to\"", "\n", "\" predict on all channel group combinations possible by channel types. \"", "\n", "\"You may optionally also specify channel types using general channel declarations \"", "\n", "\"['EEG', 'EOG', 'EMG'] which will be considered when using the --auto_channel_grouping \"", "\n", "\"flag. Use '<channel_name>==<channel_type>', e.g. 'C3-A2==EEG' 'EOGl==EOG'.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_channel_grouping\"", ",", "nargs", "=", "\"+\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Attempt to automatically group all channels specified with --channels into channel \"", "\n", "\"groups by types. Pass a string of format '<type_1> <type_2>' (optional && separaters) \"", "\n", "\"using the general channel types declarations ['EEG', 'EOG', 'EMG']. \"", "\n", "\"E.g. to predict on all available channel groups with 1 EEG and 1 EOG channel \"", "\n", "\"(in that order), pass '--auto_channel_grouping=EEG EOG' and all channels to consider \"", "\n", "\"with the --channels argument. Channel types may be passed with --channels (see above), \"", "\n", "\"otherwise, channel types are automatically inferred from the channel names. \"", "\n", "\"Note that not all models are designed to work with all types, e.g. U-Sleep V1.0 \"", "\n", "\"does not need EMG inputs and should not be passed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_reference_types\"", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Attempt to automatically reference channels to MASTOID typed channels. Pass channel \"", "\n", "\"types in ['EEG', 'EOG'] for which this feature should be active. E.g., with \"", "\n", "\"--channels C3 C4 A1 A2 passed and --auto_reference_types EEG set, the referenced \"", "\n", "\"channels C3-A2 and C4-A1 will be used instead.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--strip_func\"", ",", "type", "=", "str", ",", "default", "=", "'trim_psg_trailing'", ",", "\n", "help", "=", "\"Strip function to use, default = 'trim_psg_trailing'.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Specify a model by string identifier of format <model_name>:<model_version> \"", "\n", "\"available in the U-Sleep package. OBS: The U-Sleep package must be installed or an \"", "\n", "\"error is raised. Cannot specify both --model and --project_dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_per_prediction\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Number of samples that should make up each sleep'", "\n", "' stage scoring. Defaults to sample_rate*30, '", "\n", "'giving 1 segmentation per 30 seconds of signal. '", "\n", "'Set this to 1 to score every data point in the '", "\n", "'signal.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of GPUs to use for this job\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--force_gpus\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_argmax\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Do not argmax prediction volume prior to save.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weights_file_name\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Specify the exact name of the weights file \"", "\n", "\"(located in <project_dir>/model/) to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Overwrite existing output files and log files.'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_processed_args": [[89, 155], ["vars().items", "argparse.Namespace", "assert_project_folder", "os.path.abspath", "os.path.isdir", "isinstance", "logger.info", "argparse.Namespace.model.split", "usleep.get_model_path", "os.path.abspath", "ValueError", "os.path.join", "os.path.isdir", "vars", "os.path.exists", "os.path.splitext", "os.path.join", "len", "split_list.extend", "RuntimeError", "os.path.join", "map", "os.path.splitext", "os.path.split", "item.split", "os.path.split", "s.strip", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.assert_project_folder"], ["", "def", "get_processed_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Validate and prepare args.\n    Returns a new set of args with potential modifications.\n\n    Returns:\n         Path to a validated project directory as per --project_dir.\n    \"\"\"", "\n", "modified_args", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "# Allow list-like arguments to be passed either space-separated as normally,", "\n", "# or using '&&' delimiters. This is useful e.g. when using Docker.", "\n", "            ", "split_list", "=", "[", "]", "\n", "for", "item", "in", "value", ":", "\n", "                ", "split_list", ".", "extend", "(", "map", "(", "lambda", "s", ":", "s", ".", "strip", "(", ")", ",", "item", ".", "split", "(", "\"&&\"", ")", ")", ")", "\n", "", "value", "=", "split_list", "\n", "", "modified_args", "[", "key", "]", "=", "value", "\n", "", "args", "=", "Namespace", "(", "**", "modified_args", ")", "\n", "assert", "args", ".", "num_gpus", ">=", "0", ",", "\"--num_gpus must be positive or 0.\"", "\n", "\n", "if", "args", ".", "model", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Using the --model flag. \"", "\n", "f\"Models (if any) at project directory path {Defaults.PROJECT_DIRECTORY} (if set) \"", "\n", "f\"will not be considered.\"", ")", "\n", "try", ":", "\n", "            ", "import", "usleep", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Cannot use the --model flag when the U-Sleep package is \"", "\n", "\"not installed.\"", ")", "from", "e", "\n", "", "model_name", ",", "model_version", "=", "args", ".", "model", ".", "split", "(", "\":\"", ")", "\n", "project_dir", "=", "usleep", ".", "get_model_path", "(", "model_name", ",", "model_version", ")", "\n", "", "else", ":", "\n", "        ", "project_dir", "=", "os", ".", "path", ".", "abspath", "(", "Defaults", ".", "PROJECT_DIRECTORY", ")", "\n", "\n", "# Check project folder is valid", "\n", "", "from", "utime", ".", "utils", ".", "scriptutils", ".", "scriptutils", "import", "assert_project_folder", "\n", "assert_project_folder", "(", "project_dir", ",", "evaluation", "=", "True", ")", "\n", "args", ".", "project_dir", "=", "project_dir", "\n", "\n", "# Set absolute input file path", "\n", "args", ".", "f", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "f", ")", "\n", "\n", "# Check header exists if specified", "\n", "if", "args", ".", "header_file_name", "and", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "args", ".", "f", ")", "[", "0", "]", ",", "args", ".", "header_file_name", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Could not find header file with name {args.header_file_path} in the \"", "\n", "f\"folder where input file {args.f} is stored.\"", ")", "\n", "\n", "# Set output file path", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "args", ".", "o", ")", ":", "\n", "        ", "args", ".", "o", "=", "os", ".", "path", ".", "join", "(", "args", ".", "o", ",", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "args", ".", "f", ")", "[", "-", "1", "]", ")", "[", "0", "]", "+", "\".npy\"", ")", "\n", "\n", "# Set logging out path", "\n", "", "default_log_file_path", "=", "os", ".", "path", ".", "splitext", "(", "args", ".", "o", ")", "[", "0", "]", "+", "\".log\"", "\n", "if", "args", ".", "logging_out_path", "is", "None", ":", "\n", "        ", "args", ".", "logging_out_path", "=", "default_log_file_path", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "args", ".", "logging_out_path", ")", ":", "\n", "        ", "args", ".", "logging_out_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logging_out_path", ",", "os", ".", "path", ".", "split", "(", "default_log_file_path", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "args", ".", "auto_channel_grouping", "is", "not", "None", ":", "\n", "# Check if --auto_channel_grouping has correct format and at least 2 groups", "\n", "        ", "assert", "len", "(", "args", ".", "auto_channel_grouping", ")", ">", "1", ",", "\"Should specify at least 2 channel type groups \"", "\"with parameter --auto_channel_grouping, \"", "f\"e.g. 'EEG' 'EOG', but got {args.auto_channel_grouping}\"", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.predict_study": [[157, 178], ["numpy.expand_dims", "model.predict_on_batch.reshape", "study.get_all_periods", "logger.info", "hasattr", "callable", "model.predict_on_batch.numpy", "numpy.expand_dims", "model.predict_on_batch", "model.predict_on_batch", "model.predict_on_batch.argmax", "tuple"], "function", ["None"], ["", "def", "predict_study", "(", "study", ",", "model", ",", "channel_groups", ",", "no_argmax", ")", ":", "\n", "    ", "psg", "=", "np", ".", "expand_dims", "(", "study", ".", "get_all_periods", "(", ")", ",", "0", ")", "\n", "pred", "=", "None", "\n", "for", "channel_group", "in", "channel_groups", ":", "\n", "# Get PSG for particular group", "\n", "        ", "psg_subset", "=", "psg", "[", "...", ",", "tuple", "(", "channel_group", ".", "channel_indices", ")", "]", "\n", "logger", ".", "info", "(", "f\"\\n--- Channel names: {channel_group.channel_names}\\n\"", "\n", "f\"--- Channel inds: {channel_group.channel_indices}\\n\"", "\n", "f\"--- Extracted PSG shape: {psg_subset.shape}\"", ")", "\n", "if", "pred", "is", "None", ":", "\n", "            ", "pred", "=", "model", ".", "predict_on_batch", "(", "psg_subset", ")", "\n", "", "else", ":", "\n", "# Sum into if using multiple channel groups", "\n", "            ", "pred", "+=", "model", ".", "predict_on_batch", "(", "psg_subset", ")", "\n", "", "", "if", "hasattr", "(", "pred", ",", "\"numpy\"", ")", "and", "callable", "(", "pred", ".", "numpy", ")", ":", "\n", "        ", "pred", "=", "pred", ".", "numpy", "(", ")", "\n", "", "pred", "=", "pred", ".", "reshape", "(", "-", "1", ",", "pred", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "no_argmax", ":", "\n", "        ", "return", "pred", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "expand_dims", "(", "pred", ".", "argmax", "(", "-", "1", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.save_hyp": [[180, 188], ["numpy.vectorize", "pred.ravel", "open", "out_f.write", "utime.Defaults.get_class_int_to_stage_string"], "function", ["None"], ["", "", "def", "save_hyp", "(", "path", ",", "pred", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Save predictions as stage strings with 1 stage (segment) per line in a plain text file.\n    \"\"\"", "\n", "# Map integer outputs to string stages", "\n", "stage_strings", "=", "np", ".", "vectorize", "(", "Defaults", ".", "get_class_int_to_stage_string", "(", ")", ".", "get", ")", "(", "pred", ".", "ravel", "(", ")", ")", "\n", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "out_f", ":", "\n", "        ", "out_f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "stage_strings", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.save_ids": [[190, 200], ["psg_utils.hypnogram.utils.dense_to_sparse", "numpy.vectorize", "pred.ravel", "open", "out_f.write", "utime.Defaults.get_class_int_to_stage_string"], "function", ["None"], ["", "", "def", "save_ids", "(", "path", ",", "pred", ",", "period_length_sec", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Save predictions as stage strings in init-duration-stage format in a plain text file.\n    \"\"\"", "\n", "# Map integer outputs to string stages", "\n", "stage_strings", "=", "np", ".", "vectorize", "(", "Defaults", ".", "get_class_int_to_stage_string", "(", ")", ".", "get", ")", "(", "pred", ".", "ravel", "(", ")", ")", "\n", "ids", "=", "dense_to_sparse", "(", "stage_strings", ",", "period_length_sec", ",", "allow_trim", "=", "True", ")", "\n", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "out_f", ":", "\n", "        ", "for", "i", ",", "d", ",", "s", "in", "ids", ":", "\n", "            ", "out_f", ".", "write", "(", "f\"{i},{d},{s}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.save_npy": [[202, 207], ["numpy.save", "pred.reshape", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.save"], ["", "", "", "def", "save_npy", "(", "path", ",", "pred", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Save predictions as a numpy file storing a [N, 1] array of integer stages\n    \"\"\"", "\n", "np", ".", "save", "(", "path", ",", "pred", ".", "reshape", "(", "len", "(", "pred", ")", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.save_prediction": [[209, 232], ["os.path.split", "os.path.splitext", "logger.info", "logger.info", "save_func", "os.makedirs", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_prediction", "(", "pred", ",", "out_path", ",", "period_length_sec", ",", "no_argmax", ")", ":", "\n", "    ", "dir_", ",", "fname", "=", "os", ".", "path", ".", "split", "(", "out_path", ")", "\n", "if", "dir_", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir_", ",", "exist_ok", "=", "True", ")", "\n", "", "basename", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "fname", ")", "\n", "if", "ext", "==", "\".hyp\"", ":", "\n", "# Save as plain text of 1 stage per line", "\n", "        ", "out_path", "=", "os", ".", "path", ".", "join", "(", "dir_", ",", "basename", "+", "ext", ")", "\n", "save_func", "=", "save_hyp", "\n", "assert", "not", "no_argmax", ",", "\"Cannot save to .hyp format with the --no_argmax flag. Please use .npy.\"", "\n", "", "elif", "ext", "==", "\".ids\"", ":", "\n", "# Save as plain text in IDS format", "\n", "        ", "out_path", "=", "os", ".", "path", ".", "join", "(", "dir_", ",", "basename", "+", "ext", ")", "\n", "save_func", "=", "save_ids", "\n", "assert", "not", "no_argmax", ",", "\"Cannot save to .ids format with the --no_argmax flag. Please use .npy.\"", "\n", "", "else", ":", "\n", "# Save as npy", "\n", "        ", "out_path", "=", "os", ".", "path", ".", "join", "(", "dir_", ",", "basename", "+", "\".npy\"", ")", "\n", "save_func", "=", "save_npy", "\n", "# Save pred to disk", "\n", "", "logger", ".", "info", "(", "f\"Saving prediction array of shape {pred.shape} to {out_path}\"", ")", "\n", "logger", ".", "info", "(", "f\"Using save function: {save_func.__name__}\"", ")", "\n", "save_func", "(", "out_path", ",", "pred", ",", "period_length_sec", "=", "period_length_sec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.split_channel_types": [[234, 257], ["types.append", "stripped.append", "channel.split", "type_.strip().upper.strip().upper", "ValueError", "type_.strip().upper.strip"], "function", ["None"], ["", "def", "split_channel_types", "(", "channels", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        channels: list of channel names\n\n    Returns:\n        stripped channels\n        channel_types\n    \"\"\"", "\n", "stripped", ",", "types", "=", "[", "]", ",", "[", "]", "\n", "for", "channel", "in", "channels", ":", "\n", "        ", "type_", "=", "None", "\n", "if", "\"==\"", "in", "channel", ":", "\n", "            ", "channel", ",", "type_", "=", "channel", ".", "split", "(", "\"==\"", ")", "\n", "type_", "=", "type_", ".", "strip", "(", ")", ".", "upper", "(", ")", "\n", "if", "type_", "not", "in", "VALID_CHANNEL_TYPES", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Invalid channel type '{type_}' specified for channel '{channel}'. \"", "\n", "f\"Valid are: {VALID_CHANNEL_TYPES}\"", ")", "\n", "", "", "types", ".", "append", "(", "type_", ")", "\n", "stripped", ".", "append", "(", "channel", ")", "\n", "", "return", "stripped", ",", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.unpack_channel_groups": [[259, 281], ["map", "all", "list", "channel.split", "list.extend", "channel_groups.append", "OrderedDict.fromkeys", "any", "ValueError"], "function", ["None"], ["", "def", "unpack_channel_groups", "(", "channels", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "channels_to_load", ",", "channel_groups", "=", "[", "]", ",", "[", "]", "\n", "grouped", "=", "map", "(", "lambda", "chan", ":", "\"++\"", "in", "chan", ",", "channels", ")", "\n", "if", "all", "(", "grouped", ")", ":", "\n", "        ", "for", "channel", "in", "channels", ":", "\n", "            ", "group", "=", "channel", ".", "split", "(", "\"++\"", ")", "\n", "channels_to_load", ".", "extend", "(", "group", ")", "\n", "channel_groups", ".", "append", "(", "group", ")", "\n", "# Remove duplicated while preserving order", "\n", "", "from", "collections", "import", "OrderedDict", "\n", "channels_to_load", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "channels_to_load", ")", ")", "\n", "", "elif", "not", "any", "(", "grouped", ")", ":", "\n", "        ", "channels_to_load", "=", "channels", "\n", "channel_groups", "=", "[", "channels", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must specify either a list of channels \"", "\n", "\"or a list of channel groups, got a mix: {}\"", ".", "format", "(", "channels", ")", ")", "\n", "\n", "", "return", "channels_to_load", ",", "channel_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.strip_and_infer_channel_types": [[283, 306], ["predict_one.split_channel_types", "psg_utils.io.channels.infer_channel_types", "enumerate", "zip", "predict_one.split_channel_types"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.split_channel_types", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.split_channel_types"], ["", "def", "strip_and_infer_channel_types", "(", "channels_to_load", ",", "channel_groups", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        channels_to_load:\n        channel_groups:\n\n    Returns:\n\n    \"\"\"", "\n", "# Infer and strip potential channel types", "\n", "channels_to_load", ",", "channel_types", "=", "split_channel_types", "(", "channels_to_load", ")", "\n", "channel_groups", "=", "[", "split_channel_types", "(", "group", ")", "[", "0", "]", "for", "group", "in", "channel_groups", "]", "\n", "\n", "# Infer channel types, may not be specified by user", "\n", "# If user did not specify all channels, use inferred for those missing", "\n", "inferred_channel_types", "=", "infer_channel_types", "(", "channels_to_load", ")", "\n", "for", "i", ",", "(", "inferred", ",", "passed", ")", "in", "enumerate", "(", "zip", "(", "inferred_channel_types", ",", "channel_types", ")", ")", ":", "\n", "        ", "if", "passed", "is", "None", ":", "\n", "            ", "channel_types", "[", "i", "]", "=", "inferred", "\n", "\n", "", "", "return", "channels_to_load", ",", "channel_groups", ",", "channel_types", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_channel_groups": [[308, 323], ["list", "list", "any", "zip", "list", "s.strip().upper", "map", "map", "ValueError", "channels_by_group[].append", "product", "range", "s.strip", "len", "list.index"], "function", ["None"], ["", "def", "get_channel_groups", "(", "channels", ",", "channel_types", ",", "channel_group_spec", ")", ":", "\n", "    ", "def", "upper_stripped", "(", "s", ")", ":", "\n", "        ", "return", "s", ".", "strip", "(", ")", ".", "upper", "(", ")", "\n", "", "channel_types", "=", "list", "(", "map", "(", "upper_stripped", ",", "channel_types", ")", ")", "\n", "channel_group_spec", "=", "list", "(", "map", "(", "upper_stripped", ",", "channel_group_spec", ")", ")", "\n", "if", "any", "(", "[", "c", "not", "in", "channel_group_spec", "for", "c", "in", "channel_types", "]", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Cannot get channel groups for spec {channel_group_spec} with channels \"", "\n", "f\"{channels} and types {channel_types}: One or more types are not in the requested \"", "\n", "f\"channel group spec.\"", ")", "\n", "", "channels_by_group", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "channel_group_spec", ")", ")", "]", "\n", "for", "channel", ",", "type_", "in", "zip", "(", "channels", ",", "channel_types", ")", ":", "\n", "        ", "channels_by_group", "[", "channel_group_spec", ".", "index", "(", "type_", ")", "]", ".", "append", "(", "channel", ")", "\n", "# Return all combinations", "\n", "", "from", "itertools", "import", "product", "\n", "return", "list", "(", "product", "(", "*", "channels_by_group", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_load_and_group_channels": [[325, 366], ["logger.info", "predict_one.unpack_channel_groups", "predict_one.strip_and_infer_channel_types", "logger.info", "isinstance", "isinstance", "collections.namedtuple", "enumerate", "psg_utils.io.channels.auto_infer_referencing", "logger.warning", "predict_one.get_channel_groups", "logger.warning", "collections.namedtuple.", "len", "channels_to_load.index"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.unpack_channel_groups", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.strip_and_infer_channel_types", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_channel_groups"], ["", "def", "get_load_and_group_channels", "(", "channels", ",", "auto_channel_grouping", ",", "auto_reference_types", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n\n    Args:\n        channels:\n        auto_channel_grouping:\n        auto_reference_types:\n\n    Returns:\n\n    \"\"\"", "\n", "logger", ".", "info", "(", "f\"Processing input channels: {channels}\"", ")", "\n", "channels_to_load", ",", "channel_groups", "=", "unpack_channel_groups", "(", "channels", ")", "\n", "channels_to_load", ",", "channel_groups", ",", "channel_types", "=", "strip_and_infer_channel_types", "(", "channels_to_load", ",", "\n", "channel_groups", ")", "\n", "logger", ".", "info", "(", "f\"\\nFound:\\n\"", "\n", "f\"-- Load channels: {channels_to_load}\\n\"", "\n", "f\"-- Groups: {channel_groups}\\n\"", "\n", "f\"-- Types: {channel_types}\"", ")", "\n", "if", "isinstance", "(", "auto_reference_types", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "channel_groups", ")", "==", "1", ",", "\"Cannot use channel groups with --auto_reference_types.\"", "\n", "channels_to_load", ",", "channel_types", "=", "infer_channel_refs", "(", "channel_names", "=", "channels_to_load", ",", "\n", "channel_types", "=", "channel_types", ",", "\n", "types", "=", "auto_reference_types", ",", "\n", "on_already_ref", "=", "\"warn\"", ")", "\n", "channel_groups", "=", "[", "channels_to_load", "]", "\n", "logger", ".", "warning", "(", "f\"OBS: Auto referencing returned channels: {channels_to_load}\"", ")", "\n", "", "if", "isinstance", "(", "auto_channel_grouping", ",", "list", ")", ":", "\n", "        ", "channel_groups", "=", "get_channel_groups", "(", "channels_to_load", ",", "channel_types", ",", "auto_channel_grouping", ")", "\n", "logger", ".", "warning", "(", "f\"OBS: Auto channel grouping returned groups: {channel_groups}\"", ")", "\n", "\n", "# Add channel inds to groups", "\n", "", "channel_set", "=", "namedtuple", "(", "\"ChannelSet\"", ",", "[", "\"channel_names\"", ",", "\"channel_indices\"", "]", ")", "\n", "for", "i", ",", "group", "in", "enumerate", "(", "channel_groups", ")", ":", "\n", "        ", "channel_groups", "[", "i", "]", "=", "channel_set", "(", "\n", "channel_names", "=", "group", ",", "\n", "channel_indices", "=", "[", "channels_to_load", ".", "index", "(", "channel", ")", "for", "channel", "in", "group", "]", "\n", ")", "\n", "\n", "", "return", "channels_to_load", ",", "channel_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_sleep_study": [[368, 406], ["params.get", "logger.info", "os.path.split", "psg_utils.dataset.sleep_study.SleepStudy", "predict_one.get_load_and_group_channels", "logger.info", "psg_utils.dataset.sleep_study.SleepStudy.set_strip_func", "psg_utils.dataset.sleep_study.SleepStudy.set_quality_control_func", "psg_utils.dataset.sleep_study.SleepStudy.load", "logger.info", "NotImplementedError", "os.path.abspath", "params.get", "pprint.pformat", "psg_utils.dataset.sleep_study.SleepStudy.get_psg_shape"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_load_and_group_channels"], ["", "def", "get_sleep_study", "(", "psg_path", ",", "\n", "channels", ",", "\n", "header_file_name", "=", "None", ",", "\n", "auto_channel_grouping", "=", "False", ",", "\n", "auto_reference_types", "=", "False", ",", "\n", "**", "params", ")", ":", "\n", "    ", "\"\"\"\n    Loads a specified sleep study object with no labels\n    Sets scaler and quality control function\n\n    Returns:\n        A loaded SleepStudy object\n    \"\"\"", "\n", "if", "params", ".", "get", "(", "'batch_wise_scaling'", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Batch-wise scaling is currently not \"", "\n", "\"supported. Use ut predict/evaluate instead\"", ")", "\n", "", "logger", ".", "info", "(", "f\"Evaluating using parameters:\\n{pformat(params)}\"", ")", "\n", "dir_", ",", "regex", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "psg_path", ")", ")", "\n", "study", "=", "SleepStudy", "(", "subject_dir", "=", "dir_", ",", "psg_regex", "=", "regex", ",", "\n", "header_regex", "=", "header_file_name", ",", "\n", "no_hypnogram", "=", "True", ",", "\n", "period_length_sec", "=", "params", ".", "get", "(", "'period_length_sec'", ",", "30", ")", ")", "\n", "\n", "channels_to_load", ",", "channel_groups", "=", "get_load_and_group_channels", "(", "channels", ",", "\n", "auto_channel_grouping", ",", "\n", "auto_reference_types", ")", "\n", "\n", "logger", ".", "info", "(", "f\"\\nLoading channels: {channels_to_load}\\n\"", "\n", "f\"Channel groups: {channel_groups}\"", ")", "\n", "study", ".", "set_strip_func", "(", "**", "params", "[", "'strip_func'", "]", ")", "\n", "study", ".", "select_channels", "=", "channels_to_load", "\n", "study", ".", "sample_rate", "=", "params", "[", "'set_sample_rate'", "]", "\n", "study", ".", "scaler", "=", "params", "[", "'scaler'", "]", "\n", "study", ".", "set_quality_control_func", "(", "**", "params", "[", "'quality_control_func'", "]", ")", "\n", "study", ".", "load", "(", ")", "\n", "logger", ".", "info", "(", "f\"\\nStudy loaded with shape: {study.get_psg_shape()}\\n\"", "\n", "f\"Channels: {study.select_channels} (org names: {study.select_channels.original_names})\"", ")", "\n", "return", "study", ",", "channel_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run": [[408, 454], ["predict_one.get_processed_args", "os.path.split", "utime.utils.scriptutils.add_logging_file_handler", "YAMLHParams", "logger.info", "predict_one.get_sleep_study", "utime.utils.system.find_and_set_gpus", "logger.info", "utime.bin.evaluate.get_and_load_one_shot_model", "logger.info", "predict_one.predict_study", "logger.info", "logger.info", "utime.Defaults.get_hparams_path", "predict_one.save_prediction", "YAMLHParams.get", "YAMLHParams.get", "vars"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_processed_args", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.scriptutils.add_logging_file_handler", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_sleep_study", "home.repos.pwc.inspect_result.perslev_U-Time.utils.system.find_and_set_gpus", "home.repos.pwc.inspect_result.perslev_U-Time.bin.evaluate.get_and_load_one_shot_model", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.predict_study", "home.repos.pwc.inspect_result.perslev_U-Time.utime._defaults._Defaults.get_hparams_path", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.save_prediction"], ["", "def", "run", "(", "args", ",", "return_prediction", "=", "False", ",", "dump_args", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run the script according to args - Please refer to the argparser.\n    \"\"\"", "\n", "args", "=", "get_processed_args", "(", "args", ")", "\n", "\n", "# Get a logger", "\n", "log_dir", ",", "log_file_name", "=", "os", ".", "path", ".", "split", "(", "args", ".", "logging_out_path", ")", "\n", "add_logging_file_handler", "(", "log_file_name", ",", "args", ".", "overwrite", ",", "log_dir", "=", "log_dir", ",", "mode", "=", "\"w\"", ")", "\n", "if", "dump_args", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Args dump: {vars(args)}\"", ")", "\n", "\n", "# Get hyperparameters and init all described datasets", "\n", "", "from", "utime", ".", "hyperparameters", "import", "YAMLHParams", "\n", "hparams", "=", "YAMLHParams", "(", "Defaults", ".", "get_hparams_path", "(", "args", ".", "project_dir", ")", ",", "no_version_control", "=", "True", ")", "\n", "\n", "# Get the sleep study", "\n", "logger", ".", "info", "(", "\"Loading and pre-processing PSG file...\"", ")", "\n", "hparams", "[", "'prediction_params'", "]", "[", "'channels'", "]", "=", "args", ".", "channels", "\n", "hparams", "[", "'prediction_params'", "]", "[", "'strip_func'", "]", "[", "'strip_func_str'", "]", "=", "args", ".", "strip_func", "\n", "study", ",", "channel_groups", "=", "get_sleep_study", "(", "psg_path", "=", "args", ".", "f", ",", "\n", "header_file_name", "=", "args", ".", "header_file_name", ",", "\n", "auto_channel_grouping", "=", "args", ".", "auto_channel_grouping", ",", "\n", "auto_reference_types", "=", "args", ".", "auto_reference_types", ",", "\n", "**", "hparams", "[", "'prediction_params'", "]", ")", "\n", "\n", "# Set GPU and get model", "\n", "find_and_set_gpus", "(", "args", ".", "num_gpus", ",", "args", ".", "force_gpus", ")", "\n", "hparams", "[", "\"build\"", "]", "[", "\"data_per_prediction\"", "]", "=", "args", ".", "data_per_prediction", "\n", "logger", ".", "info", "(", "f\"Predicting with {args.data_per_prediction} data per prediction\"", ")", "\n", "model", "=", "get_and_load_one_shot_model", "(", "\n", "n_periods", "=", "study", ".", "n_periods", ",", "\n", "project_dir", "=", "args", ".", "project_dir", ",", "\n", "hparams", "=", "hparams", ",", "\n", "weights_file_name", "=", "hparams", ".", "get", "(", "'weights_file_name'", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Predicting...\"", ")", "\n", "pred", "=", "predict_study", "(", "study", ",", "model", ",", "channel_groups", ",", "args", ".", "no_argmax", ")", "\n", "logger", ".", "info", "(", "f\"Predicted shape: {pred.shape}\"", ")", "\n", "if", "return_prediction", ":", "\n", "        ", "return", "pred", "\n", "", "else", ":", "\n", "        ", "save_prediction", "(", "pred", "=", "pred", ",", "\n", "out_path", "=", "args", ".", "o", ",", "\n", "period_length_sec", "=", "hparams", ".", "get", "(", "'period_length_sec'", ",", "30", ")", ",", "\n", "no_argmax", "=", "args", ".", "no_argmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.entry_func": [[456, 461], ["predict_one.get_argparser", "get_argparser.parse_args", "predict_one.run"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.get_argparser", "home.repos.pwc.inspect_result.perslev_U-Time.bin.predict_one.run"], ["", "", "def", "entry_func", "(", "args", "=", "None", ")", ":", "\n", "# Parse command line arguments", "\n", "    ", "parser", "=", "get_argparser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "run", "(", "args", ",", "dump_args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.elastic_deformation.elastic_transform": [[9, 69], ["range", "numpy.reshape", "numpy.empty", "enumerate", "np.expand_dims.reshape", "lab_intrp().astype.reshape", "numpy.arange", "intrps.append", "scipy.ndimage.filters.gaussian_filter", "intrp().astype", "scipy.interpolate.RegularGridInterpolator", "scipy.interpolate.RegularGridInterpolator.astype", "np.expand_dims.reshape", "lab_intrp().astype.reshape", "numpy.expand_dims", "scipy.interpolate.RegularGridInterpolator", "len", "len", "intrp", "scipy.interpolate.RegularGridInterpolator.", "numpy.random.rand"], "function", ["None"], ["def", "elastic_transform", "(", "signal", ",", "labels", ",", "alpha", ",", "sigma", ",", "bg_value", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"\n    Elastic deformation for 1D signals, modified from:\n    [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n    Convolutional Neural Networks applied to Visual Document Analysis\", in\n    Proc. of the International Conference on Document Analysis and\n    Recognition, 2003.\n\n    Modified from:\n    https://gist.github.com/chsasank/4d8f68caf01f041a6453e67fb30f8f5a\n\n    Deforms both the signal and labels if len(labels) == len(signal)\n    Signal linearly interpolated\n    Labels nearest neighbour interpolated\n    \"\"\"", "\n", "assert", "signal", ".", "ndim", "in", "(", "1", ",", "2", ",", "3", ")", "\n", "org_sig_shape", "=", "signal", ".", "shape", "\n", "org_lab_shape", "=", "labels", ".", "shape", "\n", "if", "signal", ".", "ndim", "==", "3", ":", "\n", "        ", "signal", "=", "signal", ".", "reshape", "(", "-", "1", ",", "signal", ".", "shape", "[", "-", "1", "]", ")", "\n", "labels", "=", "labels", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "elif", "signal", ".", "ndim", "==", "1", ":", "\n", "        ", "signal", "=", "np", ".", "expand_dims", "(", "signal", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "seg_length", "=", "signal", ".", "shape", "[", "0", "]", "\n", "channels", "=", "signal", ".", "shape", "[", "1", "]", "\n", "dtype", "=", "signal", ".", "dtype", "\n", "\n", "# Define coordinate system", "\n", "coords", "=", "(", "np", ".", "arange", "(", "seg_length", ")", ",", ")", "\n", "\n", "# Initialize interpolators", "\n", "intrps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "channels", ")", ":", "\n", "        ", "intrps", ".", "append", "(", "RegularGridInterpolator", "(", "coords", ",", "signal", "[", ":", ",", "i", "]", ",", "\n", "method", "=", "\"linear\"", ",", "\n", "bounds_error", "=", "False", ",", "\n", "fill_value", "=", "bg_value", ")", ")", "\n", "\n", "# Get random elastic deformations", "\n", "", "dx", "=", "gaussian_filter", "(", "(", "np", ".", "random", ".", "rand", "(", "seg_length", ")", "*", "2", "-", "1", ")", ",", "sigma", ",", "\n", "mode", "=", "\"constant\"", ",", "cval", "=", "0.", ")", "*", "alpha", "\n", "\n", "# Define sample points", "\n", "indices", "=", "np", ".", "reshape", "(", "coords", "[", "0", "]", "+", "dx", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "# Interpolate all signal channels", "\n", "signal", "=", "np", ".", "empty", "(", "shape", "=", "signal", ".", "shape", ",", "dtype", "=", "dtype", ")", "\n", "for", "i", ",", "intrp", "in", "enumerate", "(", "intrps", ")", ":", "\n", "        ", "signal", "[", ":", ",", "i", "]", "=", "intrp", "(", "indices", ")", ".", "astype", "(", "dtype", ")", "\n", "\n", "# Interpolate labels if passed, only if same shape as input", "\n", "", "if", "labels", "is", "not", "None", "and", "len", "(", "labels", ")", "==", "len", "(", "signal", ")", ":", "\n", "        ", "lab_intrp", "=", "RegularGridInterpolator", "(", "coords", ",", "labels", ",", "\n", "method", "=", "\"nearest\"", ",", "\n", "bounds_error", "=", "False", ",", "\n", "fill_value", "=", "0", ")", "\n", "labels", "=", "lab_intrp", "(", "indices", ")", ".", "astype", "(", "labels", ".", "dtype", ")", "\n", "\n", "", "return", "signal", ".", "reshape", "(", "org_sig_shape", ")", ",", "labels", ".", "reshape", "(", "org_lab_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.__init__": [[20, 36], ["callable"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transform_func", ",", "apply_prob", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            transform_func: A callable function accepting parameters\n                            (X, y, **kwargs) that modifies X in-place\n            apply_prob:     A [0-1] float giving the probabilty that\n                            transform_func is applied to an element of a batch\n            aug_weight:     Multiplicative factor applied to elements in\n                            (optional) list batch_w passed to transform_func.\n                            batch_w is a list of sample weights for each\n                            element in the batch.\n        \"\"\"", "\n", "assert", "callable", "(", "transform_func", ")", "\n", "self", ".", "transform_func", "=", "transform_func", "\n", "self", ".", "apply_prob", "=", "apply_prob", "\n", "self", ".", "aug_weight", "=", "aug_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.__repr__": [[37, 39], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"<{}>\"", ".", "format", "(", "self", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.apply_prob": [[44, 50], ["ValueError"], "methods", ["None"], ["", "@", "apply_prob", ".", "setter", "\n", "def", "apply_prob", "(", "self", ",", "apply_prob", ")", ":", "\n", "        ", "if", "apply_prob", ">", "1", "or", "apply_prob", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Apply probability is invalid with value %3.f\"", "%", "apply_prob", ")", "\n", "", "self", ".", "_apply_prob", "=", "apply_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.aug_weight": [[55, 60], ["ValueError"], "methods", ["None"], ["", "@", "aug_weight", ".", "setter", "\n", "def", "aug_weight", "(", "self", ",", "aug_weight", ")", ":", "\n", "        ", "if", "aug_weight", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"aug_weight must be >= 0 (got %3.f)\"", "%", "aug_weight", ")", "\n", "", "self", ".", "_aug_weight", "=", "aug_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.separate_global_and_position_wise_kwargs": [[61, 87], ["kwargs.items", "isinstance", "pos_keys.append", "glob_keys.append", "range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "separate_global_and_position_wise_kwargs", "(", "kwargs", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Separates arguments passed with **kwargs to the self.transform_func\n        into two sets:\n          - Global arguments that should be passed to all self.trans_func calls\n          - Position wise arguments that should be passed only for certain\n            entities in batch_x and batch-y\n\n        Specifically, list or tuple parameters of length == batch_size are\n        considered position-wise arguments.\n\n        Args:\n            kwargs:   A dictionary of parameters, global and position-wise\n            batch_size: Number of elements in the batch\n\n        Returns:\n            Dict of global arguments and dict of position-wise arguments\n        \"\"\"", "\n", "pos_keys", ",", "glob_keys", "=", "[", "]", ",", "[", "]", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "is_pos", "=", "isinstance", "(", "v", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "v", ")", "==", "batch_size", "\n", "pos_keys", ".", "append", "(", "k", ")", "if", "is_pos", "else", "glob_keys", ".", "append", "(", "k", ")", "\n", "", "glob", "=", "{", "k", ":", "kwargs", "[", "k", "]", "for", "k", "in", "glob_keys", "}", "\n", "pos", "=", "[", "{", "k", ":", "kwargs", "[", "k", "]", "[", "i", "]", "for", "k", "in", "pos_keys", "}", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "return", "glob", ",", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.__call__": [[88, 91], ["augmenters.Augmenter.augment"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.augment"], ["", "def", "__call__", "(", "self", ",", "batch_x", ",", "batch_y", ",", "batch_w", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Augment a batch of data \"\"\"", "\n", "return", "self", ".", "augment", "(", "batch_x", ",", "batch_y", ",", "batch_w", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.augment": [[92, 127], ["augmenters.Augmenter.separate_global_and_position_wise_kwargs", "enumerate", "numpy.random.rand", "len", "augmenters.Augmenter.transform_func", "len"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.separate_global_and_position_wise_kwargs"], ["", "def", "augment", "(", "self", ",", "batch_x", ",", "batch_y", ",", "batch_w", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Applies self.transform_func to elements of batch_x and batch_y with\n        element-wise probability self.apply_prob\n\n        Assumes len(batch_x) == len(batch_y) (== len(batch_w))\n\n        List/tuples of len(batch_x) passed as kwargs will be passed with their\n        position equivalents of batch_x and batch_y to the transform func. All\n        other items in kwargs will be passed to all calls made to\n        self.trans_func\n\n        Args:\n            batch_x:  A batch of data\n            batch_y:  A batch of labels\n            batch_w:  An optional batch of sample-weights\n            **kwargs: Parameters passed to the transform functon\n        \"\"\"", "\n", "# Only augment some of the images (determined by apply_prob)", "\n", "augment_mask", "=", "np", ".", "random", ".", "rand", "(", "len", "(", "batch_x", ")", ")", "<=", "self", ".", "apply_prob", "\n", "\n", "# Get arguments that should be passed to all self.trans_func calls", "\n", "# (glob) and for only specific position-wise entities in batch_x and", "\n", "# batch_y", "\n", "glob", ",", "pos", "=", "self", ".", "separate_global_and_position_wise_kwargs", "(", "kwargs", ",", "\n", "len", "(", "batch_x", ")", ")", "\n", "\n", "for", "i", ",", "augment", "in", "enumerate", "(", "augment_mask", ")", ":", "\n", "            ", "if", "not", "augment", ":", "\n", "                ", "continue", "\n", "", "x_aug", ",", "y_aug", "=", "self", ".", "transform_func", "(", "batch_x", "[", "i", "]", ",", "batch_y", "[", "i", "]", ",", "\n", "**", "glob", ",", "**", "pos", "[", "i", "]", ")", "\n", "batch_x", "[", "i", "]", ",", "batch_y", "[", "i", "]", "=", "x_aug", ",", "y_aug", "\n", "if", "batch_w", "is", "not", "None", ":", "\n", "                ", "batch_w", "[", "i", "]", "*=", "self", ".", "aug_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.__init__": [[136, 149], ["augmenters.Augmenter.__init__", "float", "float", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "transform_func", ",", "min_fraction", ",", "max_fraction", ",", "apply_prob", ",", "\n", "log_sample", ",", "aug_weight", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "transform_func", ",", "apply_prob", ",", "aug_weight", ")", "\n", "\n", "self", ".", "log_sample", "=", "log_sample", "\n", "self", ".", "min_fraction", "=", "float", "(", "min_fraction", ")", "\n", "self", ".", "max_fraction", "=", "float", "(", "max_fraction", ")", "\n", "if", "self", ".", "min_fraction", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Minimum fraction must be > 0, got \"", "\n", "\"{}\"", ".", "format", "(", "self", ".", "min_fraction", ")", ")", "\n", "", "if", "self", ".", "max_fraction", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Maximum fraction must be <= 1, \"", "\n", "\"got {}\"", ".", "format", "(", "self", ".", "max_fraction", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.reshape_x": [[150, 158], ["x.reshape.reshape.reshape"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "reshape_x", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Reshapes a signal to shape [-1, n_channels]\n        \"\"\"", "\n", "org_shape", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "return", "x", ",", "org_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_aug_length": [[159, 175], ["numpy.log10", "numpy.log10", "numpy.power", "int", "int", "int", "int", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["None"], ["", "def", "get_aug_length", "(", "self", ",", "x_length", ")", ":", "\n", "        ", "\"\"\"\n        Giving a signal of length x_length, sample a length of signal\n        (number of samples) to augment according to properties\n        self.log_sample, self.min_fraction, self.max_fraction\n        \"\"\"", "\n", "if", "self", ".", "log_sample", ":", "\n", "            ", "min_f", "=", "np", ".", "log10", "(", "self", ".", "min_fraction", ")", "\n", "max_f", "=", "np", ".", "log10", "(", "self", ".", "max_fraction", ")", "\n", "frac", "=", "np", ".", "power", "(", "10", ",", "np", ".", "random", ".", "uniform", "(", "min_f", ",", "max_f", ",", "1", ")", "[", "0", "]", ")", "\n", "length", "=", "int", "(", "frac", "*", "x_length", ")", "\n", "", "else", ":", "\n", "            ", "min_", "=", "int", "(", "self", ".", "min_fraction", "*", "x_length", ")", "\n", "max_", "=", "int", "(", "self", ".", "max_fraction", "*", "x_length", ")", "\n", "length", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "min_", ",", "max_", ",", "1", ")", "[", "0", "]", ")", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_start_point": [[176, 181], ["numpy.random.randint"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_start_point", "(", "x_length", ")", ":", "\n", "        ", "\"\"\" Sample a random start position within a x_length long signal \"\"\"", "\n", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "x_length", ",", "1", ")", "[", "0", "]", "\n", "return", "start", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter._augment_with_transform": [[182, 197], ["transform_func", "transform_func", "transform_func"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_augment_with_transform", "(", "x", ",", "y", ",", "start", ",", "transform_func", ",", "x_length", ",", "aug_length", ")", ":", "\n", "        ", "\"\"\"\n        Augment region with a function that applies (in-place) to the region\n        \"\"\"", "\n", "wrap", "=", "start", "+", "aug_length", "-", "x_length", "\n", "if", "wrap", ">", "0", ":", "\n", "            ", "r1", "=", "x", "[", "start", ":", "start", "+", "aug_length", "-", "wrap", "]", "\n", "r2", "=", "x", "[", "0", ":", "wrap", "]", "\n", "r1", "[", ":", "]", "=", "transform_func", "(", "r1", ")", "\n", "r2", "[", ":", "]", "=", "transform_func", "(", "r2", ")", "\n", "", "else", ":", "\n", "            ", "r", "=", "x", "[", "start", ":", "start", "+", "aug_length", "]", "\n", "r", "[", ":", "]", "=", "transform_func", "(", "r", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter._augment_with_insert": [[198, 211], ["len", "insert[].copy", "insert[].copy", "insert.copy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_augment_with_insert", "(", "x", ",", "y", ",", "start", ",", "insert", ",", "x_length", ")", ":", "\n", "        ", "\"\"\"\n        Augment region by replacing/inserting an array of data in the region\n        \"\"\"", "\n", "aug_length", "=", "len", "(", "insert", ")", "\n", "wrap", "=", "start", "+", "aug_length", "-", "x_length", "\n", "if", "wrap", ">", "0", ":", "\n", "            ", "x", "[", "start", ":", "start", "+", "aug_length", "-", "wrap", "]", "=", "insert", "[", ":", "-", "wrap", "]", ".", "copy", "(", ")", "\n", "x", "[", "0", ":", "wrap", "]", "=", "insert", "[", "-", "wrap", ":", "]", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "            ", "x", "[", "start", ":", "start", "+", "aug_length", "]", "=", "insert", ".", "copy", "(", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.augment_region": [[212, 245], ["augmenters.RegionalAugmenter.reshape_x", "len", "psg_utils.utils.exactly_one_specified", "ValueError", "augmenters.RegionalAugmenter.get_start_point", "augmenters.RegionalAugmenter.get_aug_length", "augmenters.RegionalAugmenter._augment_with_transform", "augmenters.RegionalAugmenter._augment_with_insert", "x.reshape"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.reshape_x", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_start_point", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_aug_length", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter._augment_with_transform", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter._augment_with_insert"], ["", "def", "augment_region", "(", "self", ",", "x", ",", "y", ",", "start", "=", "None", ",", "transform_func", "=", "None", ",", "insert", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Augment a region/sub-sequence of a signal 'x'\n\n        Args:\n            x:                A sample from a batch, array, [..., n_channels]\n            y:                A label value from a batch, int\n            start:            Aug. region start position within x, int\n            transform_func:   Function to apply to values within aug region\n            insert:           Array to insert/replace at aug region\n\n        Returns:\n            x (augmented in-place), y\n        \"\"\"", "\n", "if", "not", "exactly_one_specified", "(", "transform_func", ",", "insert", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"'augment_region' expected one of \"", "\n", "\"'transform_func' and 'insert', got one or both.\"", ")", "\n", "", "x", ",", "org_shape", "=", "self", ".", "reshape_x", "(", "x", ")", "\n", "x_length", "=", "len", "(", "x", ")", "\n", "start", "=", "start", "or", "self", ".", "get_start_point", "(", "x_length", ")", "\n", "if", "transform_func", "is", "not", "None", ":", "\n", "            ", "aug_length", "=", "self", ".", "get_aug_length", "(", "x_length", ")", "\n", "x", ",", "y", "=", "self", ".", "_augment_with_transform", "(", "x", ",", "y", ",", "\n", "start", "=", "start", ",", "\n", "transform_func", "=", "transform_func", ",", "\n", "x_length", "=", "x_length", ",", "\n", "aug_length", "=", "aug_length", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "y", "=", "self", ".", "_augment_with_insert", "(", "x", ",", "y", ",", "\n", "start", "=", "start", ",", "\n", "insert", "=", "insert", ",", "\n", "x_length", "=", "x_length", ")", "\n", "", "return", "x", ".", "reshape", "(", "org_shape", ")", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalElasticDeformations.__init__": [[251, 285], ["augmenters.Augmenter.__init__", "isinstance", "isinstance", "len", "ValueError", "ValueError", "len", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "alpha", ",", "sigma", ",", "apply_prob", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            alpha: A number of tuple/list of two numbers specifying a range\n                   of alpha values to sample from in each augmentation call\n                   The alpha value determines the strength of the deformation\n            sigma: A number of tuple/list of two numbers specifying a range\n                   of sigma values to sample from in each augmentation call\n                   The sigma value determines the smoothness of the deformation\n            apply_prob: Apply the transformation only with some probability\n                        Otherwise, return the image untransformed\n            aug_weight: If a list of weights of len(batch_x) elements is passed\n                        the aug_weight will multiply with the passed weight at\n                        index i of batch_x if i in batch_x is transformed.\n        \"\"\"", "\n", "self", ".", "__name__", "=", "\"GlobalElasticDeformations\"", "\n", "# Initialize base", "\n", "super", "(", ")", ".", "__init__", "(", "elastic_transform", ",", "apply_prob", ",", "aug_weight", ")", "\n", "\n", "if", "isinstance", "(", "alpha", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "alpha", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid list of alphas specified '%s'. \"", "\n", "\"Should be 2 numbers.\"", "%", "alpha", ")", "\n", "", "if", "alpha", "[", "1", "]", "<=", "alpha", "[", "0", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"alpha upper is smaller than sigma lower (%s)\"", "%", "alpha", ")", "\n", "", "", "if", "isinstance", "(", "sigma", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "sigma", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid list of sigmas specified '%s'. \"", "\n", "\"Should be 2 numbers.\"", "%", "sigma", ")", "\n", "", "if", "sigma", "[", "1", "]", "<=", "sigma", "[", "0", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"Sigma upper is smaller than sigma lower (%s)\"", "%", "sigma", ")", "\n", "\n", "", "", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalElasticDeformations.alpha": [[286, 296], ["isinstance", "numpy.random.uniform"], "methods", ["None"], ["", "@", "property", "\n", "def", "alpha", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a randomly sampled alpha value in the range [alpha[0], alpha[1]]\n        or return the integer/float alpha if alpha is not a list\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "_alpha", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "np", ".", "random", ".", "uniform", "(", "self", ".", "_alpha", "[", "0", "]", ",", "self", ".", "_alpha", "[", "1", "]", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalElasticDeformations.sigma": [[297, 307], ["isinstance", "numpy.random.uniform"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "sigma", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a randomly sampled sigma value in the range [sigma[0], sigma[1]]\n        or return the integer/float sigma if sigma is not a list\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "_sigma", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "np", ".", "random", ".", "uniform", "(", "self", ".", "_sigma", "[", "0", "]", ",", "self", ".", "_sigma", "[", "1", "]", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalElasticDeformations.__call__": [[308, 313], ["augmenters.GlobalElasticDeformations.augment", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.Augmenter.augment"], ["", "", "def", "__call__", "(", "self", ",", "batch_x", ",", "batch_y", ",", "batch_w", ",", "bg_values", "=", "0.0", ")", ":", "\n", "        ", "return", "self", ".", "augment", "(", "batch_x", ",", "batch_y", ",", "batch_w", ",", "\n", "bg_value", "=", "bg_values", ",", "\n", "sigma", "=", "[", "self", ".", "sigma", "for", "_", "in", "range", "(", "len", "(", "batch_x", ")", ")", "]", ",", "\n", "alpha", "=", "[", "self", ".", "alpha", "for", "_", "in", "range", "(", "len", "(", "batch_x", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalElasticDeformations.__str__": [[314, 317], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"%s(alpha=%s, sigma=%s, apply_prob=%.3f)\"", "%", "(", "\n", "self", ".", "__name__", ",", "self", ".", "_alpha", ",", "self", ".", "_sigma", ",", "self", ".", "apply_prob", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalAmplitude.__init__": [[325, 334], ["augmenters.Augmenter.__init__", "float", "float", "ValueError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_scaling", ",", "max_scaling", ",", "apply_prob", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"GlobalAmplitude\"", "\n", "# Initialize base", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "scale", ",", "apply_prob", ",", "aug_weight", ")", "\n", "\n", "self", ".", "min_scaling", "=", "float", "(", "min_scaling", ")", "\n", "self", ".", "max_scaling", "=", "float", "(", "max_scaling", ")", "\n", "if", "self", ".", "max_scaling", "<=", "self", ".", "min_scaling", ":", "\n", "            ", "raise", "ValueError", "(", "\"Max scaling must be greater than min. scaling.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalAmplitude.scale": [[335, 338], ["numpy.random.uniform"], "methods", ["None"], ["", "", "def", "scale", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "scale", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "min_scaling", ",", "self", ".", "max_scaling", ",", "1", ")", "\n", "return", "x", "*", "scale", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalShift.__init__": [[344, 353], ["augmenters.Augmenter.__init__", "float", "float", "ValueError"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_shift", ",", "max_shift", ",", "apply_prob", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"GlobalShift\"", "\n", "# Initialize base", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "shift", ",", "apply_prob", ",", "aug_weight", ")", "\n", "\n", "self", ".", "min_shift", "=", "float", "(", "min_shift", ")", "\n", "self", ".", "max_shift", "=", "float", "(", "max_shift", ")", "\n", "if", "self", ".", "max_shift", "<=", "self", ".", "min_shift", ":", "\n", "            ", "raise", "ValueError", "(", "\"Max shift must be greater than min. shift.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalShift.shift": [[354, 357], ["numpy.random.uniform"], "methods", ["None"], ["", "", "def", "shift", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "shift", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "min_shift", ",", "self", ".", "max_shift", ",", "1", ")", "\n", "return", "x", "+", "shift", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalGaussianNoise.__init__": [[364, 371], ["augmenters.Augmenter.__init__", "float", "float"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "sigma", ",", "apply_prob", ",", "mean", "=", "0", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"GlobalGaussianNoise\"", "\n", "# Initialize base", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "apply_noise", ",", "apply_prob", ",", "aug_weight", ")", "\n", "\n", "self", ".", "mean", "=", "float", "(", "mean", ")", "\n", "self", ".", "sigma", "=", "float", "(", "sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.GlobalGaussianNoise.apply_noise": [[372, 375], ["numpy.random.normal"], "methods", ["None"], ["", "def", "apply_noise", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "noise", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "self", ".", "mean", ",", "scale", "=", "self", ".", "sigma", ",", "size", "=", "x", ".", "shape", ")", "\n", "return", "x", "+", "noise", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.ChannelDropout.__init__": [[382, 386], ["augmenters.Augmenter.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "drop_fraction", ",", "apply_prob", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"ChannelDropout\"", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "drop_channels", ",", "apply_prob", ",", "aug_weight", ")", "\n", "self", ".", "drop_fraction", "=", "drop_fraction", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.ChannelDropout.drop_channels": [[387, 401], ["max", "numpy.random.choice", "int", "ValueError", "numpy.arange", "numpy.random.normal", "numpy.mean"], "methods", ["None"], ["", "def", "drop_channels", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "n_channels", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "n_to_drop", "=", "max", "(", "int", "(", "n_channels", "*", "self", ".", "drop_fraction", ")", ",", "1", ")", "\n", "if", "n_to_drop", ">=", "n_channels", ":", "\n", "            ", "raise", "ValueError", "(", "\"Attempted to drop {} channels from 'x' with {}\"", "\n", "\" channels (shape {})\"", ".", "format", "(", "n_to_drop", ",", "\n", "n_channels", ",", "\n", "x", ".", "shape", ")", ")", "\n", "", "to_drop", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "n_channels", ")", ",", "n_to_drop", ",", "False", ")", "\n", "for", "i", "in", "to_drop", ":", "\n", "            ", "x", "[", "...", ",", "i", "]", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "np", ".", "mean", "(", "x", "[", "...", ",", "i", "]", ")", ",", "\n", "scale", "=", "0.01", ",", "\n", "size", "=", "x", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalGaussianNoise.__init__": [[408, 418], ["augmenters.RegionalAugmenter.__init__", "float", "float"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "mean", "=", "0", ",", "sigma", "=", "0.1", ",", "log_sample", "=", "True", ",", "\n", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"RegionalGaussianNoise\"", "\n", "# Initialize base", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "apply_noise", ",", "min_region_fraction", ",", "\n", "max_region_fraction", ",", "apply_prob", ",", "log_sample", ",", "\n", "aug_weight", ")", "\n", "self", ".", "mean", "=", "float", "(", "mean", ")", "\n", "self", ".", "sigma", "=", "float", "(", "sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalGaussianNoise._noise_func": [[419, 423], ["numpy.random.normal"], "methods", ["None"], ["", "def", "_noise_func", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "+", "np", ".", "random", ".", "normal", "(", "loc", "=", "self", ".", "mean", ",", "\n", "scale", "=", "self", ".", "sigma", ",", "\n", "size", "=", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalGaussianNoise.apply_noise": [[424, 427], ["augmenters.RegionalGaussianNoise.augment_region"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.augment_region"], ["", "def", "apply_noise", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "x", ",", "y", "=", "self", ".", "augment_region", "(", "x", ",", "y", ",", "transform_func", "=", "self", ".", "_noise_func", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalErase.__init__": [[434, 440], ["augmenters.RegionalAugmenter.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "log_sample", "=", "True", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"RegionalErase\"", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "random_erase", ",", "min_region_fraction", ",", "\n", "max_region_fraction", ",", "apply_prob", ",", "log_sample", ",", "\n", "aug_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalErase.random_erase": [[441, 451], ["augmenters.RegionalErase.reshape_x", "len", "augmenters.RegionalErase.get_start_point", "augmenters.RegionalErase.get_aug_length", "numpy.random.normal", "augmenters.RegionalErase.augment_region", "x.reshape", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.reshape_x", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_start_point", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_aug_length", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.augment_region"], ["", "def", "random_erase", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "x", ",", "org_shape", "=", "self", ".", "reshape_x", "(", "x", ")", "\n", "x_length", "=", "len", "(", "x", ")", "\n", "erase_start", "=", "self", ".", "get_start_point", "(", "x_length", ")", "\n", "erase_len", "=", "self", ".", "get_aug_length", "(", "x_length", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "np", ".", "mean", "(", "x", ")", ",", "\n", "scale", "=", "0.01", ",", "\n", "size", "=", "[", "erase_len", ",", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "x", ",", "y", "=", "self", ".", "augment_region", "(", "x", ",", "y", ",", "start", "=", "erase_start", ",", "insert", "=", "noise", ")", "\n", "return", "x", ".", "reshape", "(", "org_shape", ")", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalSignalMix.__init__": [[458, 464], ["augmenters.RegionalAugmenter.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "log_sample", "=", "True", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"RegionalSignalMix\"", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "random_mix", ",", "\n", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "log_sample", ",", "aug_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalSignalMix.random_mix": [[465, 481], ["augmenters.RegionalSignalMix.reshape_x", "len", "augmenters.RegionalSignalMix.get_start_point", "augmenters.RegionalSignalMix.get_start_point", "augmenters.RegionalSignalMix.get_aug_length", "numpy.arange", "x.take().reshape", "numpy.arange", "x.take().reshape", "augmenters.RegionalSignalMix.augment_region", "x.reshape", "x.take", "x.take"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.reshape_x", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_start_point", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_start_point", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.get_aug_length", "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.augment_region"], ["", "def", "random_mix", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "x", ",", "org_shape", "=", "self", ".", "reshape_x", "(", "x", ")", "\n", "x_length", "=", "len", "(", "x", ")", "\n", "insert_start", "=", "self", ".", "get_start_point", "(", "x_length", ")", "\n", "take_start", "=", "self", ".", "get_start_point", "(", "x_length", ")", "\n", "mix_len", "=", "self", ".", "get_aug_length", "(", "x_length", ")", "\n", "\n", "# Get signal to insert into 'insert_start' position", "\n", "take_inds", "=", "np", ".", "arange", "(", "take_start", ",", "take_start", "+", "mix_len", ")", "\n", "take_sig", "=", "x", ".", "take", "(", "take_inds", ",", "mode", "=", "\"wrap\"", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "insert_inds", "=", "np", ".", "arange", "(", "insert_start", ",", "insert_start", "+", "mix_len", ")", "\n", "insert_sig", "=", "x", ".", "take", "(", "insert_inds", ",", "mode", "=", "\"wrap\"", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "insert", "=", "(", "take_sig", "+", "insert_sig", ")", "/", "2", "\n", "\n", "x", ",", "y", "=", "self", ".", "augment_region", "(", "x", ",", "y", ",", "start", "=", "insert_start", ",", "insert", "=", "insert", ")", "\n", "return", "x", ".", "reshape", "(", "org_shape", ")", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalSignFlip.__init__": [[487, 493], ["augmenters.RegionalAugmenter.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "log_sample", "=", "True", ",", "aug_weight", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "__name__", "=", "\"RegionalSignFlip\"", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "sign_flip", ",", "\n", "min_region_fraction", ",", "max_region_fraction", ",", "\n", "apply_prob", ",", "log_sample", ",", "aug_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalSignFlip.sign_flip": [[494, 496], ["augmenters.RegionalSignFlip.augment_region"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.augmentation.augmenters.RegionalAugmenter.augment_region"], ["", "def", "sign_flip", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "return", "self", ".", "augment_region", "(", "x", ",", "y", ",", "transform_func", "=", "lambda", "x", ":", "-", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation.__init__": [[35, 48], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "val_sequence", ",", "max_val_studies_per_dataset", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            val_sequence: A deepsleep ValidationMultiSequence object\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sequences", "=", "val_sequence", ".", "sequences", "\n", "self", ".", "max_studies", "=", "max_val_studies_per_dataset", "\n", "self", ".", "n_classes", "=", "val_sequence", ".", "n_classes", "\n", "self", ".", "IDs", "=", "val_sequence", ".", "IDs", "\n", "self", ".", "print_round", "=", "3", "\n", "self", ".", "log_round", "=", "4", "\n", "self", ".", "_supports_tf_logs", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._compute_counts": [[49, 71], ["pred.argmax().ravel.argmax().ravel.argmax().ravel", "true.ravel.ravel.ravel", "numpy.where().astype", "[].astype", "numpy.bincount().astype", "numpy.bincount().astype", "pred.argmax().ravel.argmax().ravel.argmax", "numpy.where", "numpy.bincount", "numpy.bincount", "numpy.logical_and", "numpy.ones_like", "numpy.zeros_like", "numpy.bincount", "numpy.greater_equal", "numpy.less", "numpy.where"], "methods", ["None"], ["", "def", "_compute_counts", "(", "self", ",", "pred", ",", "true", ")", ":", "\n", "# Argmax and CM elements", "\n", "        ", "pred", "=", "pred", ".", "argmax", "(", "-", "1", ")", ".", "ravel", "(", ")", "\n", "true", "=", "true", ".", "ravel", "(", ")", "\n", "\n", "# True array may include negative or non-negative integers larger than n_classes, e.g. int class 5 \"UNKNOWN\"", "\n", "# Here we mask out any out-of-range values any evaluate only on in-range classes.", "\n", "mask", "=", "np", ".", "where", "(", "np", ".", "logical_and", "(", "\n", "np", ".", "greater_equal", "(", "true", ",", "0", ")", ",", "\n", "np", ".", "less", "(", "true", ",", "self", ".", "n_classes", ")", "\n", ")", ",", "np", ".", "ones_like", "(", "true", ")", ",", "np", ".", "zeros_like", "(", "true", ")", ")", ".", "astype", "(", "bool", ")", "\n", "pred", "=", "pred", "[", "mask", "]", "\n", "true", "=", "true", "[", "mask", "]", "\n", "\n", "# Compute relevant CM elements", "\n", "# We select the number following the largest class integer when", "\n", "# y != pred, then bincount and remove the added dummy class", "\n", "tps", "=", "np", ".", "bincount", "(", "np", ".", "where", "(", "true", "==", "pred", ",", "true", ",", "self", ".", "n_classes", ")", ",", "\n", "minlength", "=", "self", ".", "n_classes", "+", "1", ")", "[", ":", "-", "1", "]", ".", "astype", "(", "np", ".", "uint64", ")", "\n", "rel", "=", "np", ".", "bincount", "(", "true", ",", "minlength", "=", "self", ".", "n_classes", ")", ".", "astype", "(", "np", ".", "uint64", ")", "\n", "sel", "=", "np", ".", "bincount", "(", "pred", ",", "minlength", "=", "self", ".", "n_classes", ")", ".", "astype", "(", "np", ".", "uint64", ")", "\n", "return", "tps", ",", "rel", ",", "sel", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation.predict": [[72, 133], ["list", "callbacks.Validation.model.reset_metrics", "zip", "getattr", "filter", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "sequence.dataset_queue.get_study_iterator", "collections.defaultdict", "enumerate", "zip", "callbacks.Validation.model.reset_metrics", "len", "print", "hasattr", "callbacks.Validation._compute_counts", "zip", "numpy.mean", "sequence.get_single_study_full_seq", "callbacks.Validation.model.predict_on_batch", "callbacks.Validation.numpy", "tensorflow.reduce_mean", "hasattr", "per_study_metrics[].append", "getattr", "metric", "res.numpy.numpy.numpy", "hasattr", "type", "metric.reset_states", "metric.reset_state"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._compute_counts", "home.repos.pwc.inspect_result.perslev_U-Time.sequences.batch_sequence.BatchSequence.get_single_study_full_seq"], ["", "def", "predict", "(", "self", ")", ":", "\n", "# Get tensors to run and their names", "\n", "        ", "metrics", "=", "getattr", "(", "self", ".", "model", ",", "\"loss_functions\"", ",", "self", ".", "model", ".", "losses", ")", "or", "self", ".", "model", ".", "loss", "+", "self", ".", "model", ".", "metrics", "\n", "metrics", "=", "list", "(", "filter", "(", "lambda", "m", ":", "not", "type", "(", "m", ")", "is", "tf", ".", "keras", ".", "metrics", ".", "Mean", ",", "metrics", ")", ")", "\n", "metrics_names", "=", "self", ".", "model", ".", "metrics_names", "\n", "self", ".", "model", ".", "reset_metrics", "(", ")", "\n", "assert", "len", "(", "metrics_names", ")", "==", "len", "(", "metrics", ")", "\n", "\n", "# Prepare arrays for CM summary stats", "\n", "true_pos", ",", "relevant", ",", "selected", ",", "metrics_results", "=", "{", "}", ",", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "for", "id_", ",", "sequence", "in", "zip", "(", "self", ".", "IDs", ",", "self", ".", "sequences", ")", ":", "\n", "# Add count arrays to the result dictionaries", "\n", "            ", "true_pos", "[", "id_", "]", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_classes", ",", ")", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "relevant", "[", "id_", "]", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_classes", ",", ")", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "selected", "[", "id_", "]", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_classes", ",", ")", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "\n", "# Get validation sleep study loader", "\n", "n_val", "=", "min", "(", "len", "(", "sequence", ".", "dataset_queue", ")", ",", "self", ".", "max_studies", ")", "\n", "study_iterator", "=", "sequence", ".", "dataset_queue", ".", "get_study_iterator", "(", "n_val", ")", "\n", "\n", "# Predict and evaluate on all studies", "\n", "per_study_metrics", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "sleep_study_context", "in", "enumerate", "(", "study_iterator", ")", ":", "\n", "                ", "s", "=", "\"   {}Validation subject: {}/{}\"", ".", "format", "(", "f\"[{id_}] \"", "\n", "if", "id_", "else", "\"\"", ",", "\n", "i", "+", "1", ",", "\n", "n_val", ")", "\n", "print", "(", "s", ",", "end", "=", "\"\\r\"", ",", "flush", "=", "True", ")", "\n", "\n", "with", "sleep_study_context", "as", "ss", ":", "\n", "                    ", "x", ",", "y", "=", "sequence", ".", "get_single_study_full_seq", "(", "ss", ".", "identifier", ",", "reshape", "=", "True", ")", "\n", "pred", "=", "self", ".", "model", ".", "predict_on_batch", "(", "x", ")", "\n", "\n", "# Compute counts", "\n", "", "if", "hasattr", "(", "pred", ",", "\"numpy\"", ")", ":", "\n", "                    ", "pred_numpy", "=", "pred", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "pred_numpy", "=", "pred", "\n", "", "tps", ",", "rel", ",", "sel", "=", "self", ".", "_compute_counts", "(", "pred", "=", "pred_numpy", ",", "true", "=", "y", ")", "\n", "true_pos", "[", "id_", "]", "+=", "tps", "\n", "relevant", "[", "id_", "]", "+=", "rel", "\n", "selected", "[", "id_", "]", "+=", "sel", "\n", "\n", "# Run all metrics", "\n", "for", "metric", ",", "name", "in", "zip", "(", "metrics", ",", "metrics_names", ")", ":", "\n", "                    ", "res", "=", "tf", ".", "reduce_mean", "(", "metric", "(", "y", ",", "pred", ")", ")", "\n", "if", "hasattr", "(", "pred", ",", "\"numpy\"", ")", ":", "\n", "                        ", "res", "=", "res", ".", "numpy", "(", ")", "\n", "", "per_study_metrics", "[", "name", "]", ".", "append", "(", "res", ")", "\n", "if", "getattr", "(", "metric", ",", "\"stateful\"", ",", "False", ")", ":", "\n", "                        ", "if", "hasattr", "(", "metric", ",", "\"reset_states\"", ")", ":", "\n", "                            ", "metric", ".", "reset_states", "(", ")", "\n", "", "else", ":", "\n", "                            ", "metric", ".", "reset_state", "(", ")", "\n", "\n", "# Compute mean metrics for the dataset", "\n", "", "", "", "", "metrics_results", "[", "id_", "]", "=", "{", "}", "\n", "for", "metric", ",", "name", "in", "zip", "(", "metrics", ",", "metrics_names", ")", ":", "\n", "                ", "metrics_results", "[", "id_", "]", "[", "name", "]", "=", "np", ".", "mean", "(", "per_study_metrics", "[", "name", "]", ")", "\n", "", "self", ".", "model", ".", "reset_metrics", "(", ")", "\n", "", "return", "true_pos", ",", "relevant", ",", "selected", ",", "metrics_results", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._compute_dice": [[134, 157], ["numpy.zeros", "numpy.zeros_like", "numpy.zeros_like"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_dice", "(", "tp", ",", "rel", ",", "sel", ")", ":", "\n", "# Get data masks (to avoid div. by zero warnings)", "\n", "# We set precision, recall, dice to 0 in for those particular cls.", "\n", "        ", "sel_mask", "=", "sel", ">", "0", "\n", "rel_mask", "=", "rel", ">", "0", "\n", "\n", "# prepare arrays", "\n", "precisions", "=", "np", ".", "zeros", "(", "shape", "=", "tp", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "recalls", "=", "np", ".", "zeros_like", "(", "precisions", ")", "\n", "dices", "=", "np", ".", "zeros_like", "(", "precisions", ")", "\n", "\n", "# Compute precisions, recalls", "\n", "precisions", "[", "sel_mask", "]", "=", "tp", "[", "sel_mask", "]", "/", "sel", "[", "sel_mask", "]", "\n", "recalls", "[", "rel_mask", "]", "=", "tp", "[", "rel_mask", "]", "/", "rel", "[", "rel_mask", "]", "\n", "\n", "# Compute dice", "\n", "intrs", "=", "(", "2", "*", "precisions", "*", "recalls", ")", "\n", "union", "=", "(", "precisions", "+", "recalls", ")", "\n", "dice_mask", "=", "union", ">", "0", "\n", "dices", "[", "dice_mask", "]", "=", "intrs", "[", "dice_mask", "]", "/", "union", "[", "dice_mask", "]", "\n", "\n", "return", "precisions", ",", "recalls", ",", "dices", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._log_val_results": [[158, 188], ["map", "numpy.empty", "value_dict.update", "list", "list.insert", "val_results.round().to_string", "logger.info", "list", "list.pop", "zip", "len", "pandas.DataFrame", "precisions.mean", "recalls.mean", "dices.mean", "list.index", "val_results.round", "val_results.round().to_string.replace", "metrics.items", "utime.utils.highlighted().lstrip", "utime.utils.highlighted"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.highlighted"], ["", "def", "_log_val_results", "(", "self", ",", "precisions", ",", "recalls", ",", "dices", ",", "metrics", ",", "epoch", ",", "\n", "name", ",", "classes", ")", ":", "\n", "# Log the results", "\n", "# We add them to a pd dataframe just for the pretty print output", "\n", "        ", "index", "=", "[", "\"cls %i\"", "%", "i", "for", "i", "in", "classes", "]", "\n", "metric_keys", ",", "metric_vals", "=", "map", "(", "list", ",", "list", "(", "zip", "(", "*", "metrics", ".", "items", "(", ")", ")", ")", ")", "\n", "col_order", "=", "metric_keys", "+", "[", "\"precision\"", ",", "\"recall\"", ",", "\"dice\"", "]", "\n", "nan_arr", "=", "np", ".", "empty", "(", "shape", "=", "len", "(", "precisions", ")", ")", "\n", "nan_arr", "[", ":", "]", "=", "np", ".", "nan", "\n", "value_dict", "=", "{", "\"precision\"", ":", "precisions", ",", "\n", "\"recall\"", ":", "recalls", ",", "\n", "\"dice\"", ":", "dices", "}", "\n", "value_dict", ".", "update", "(", "{", "key", ":", "nan_arr", "for", "key", "in", "metrics", "}", ")", "\n", "val_results", "=", "pd", ".", "DataFrame", "(", "value_dict", ",", "\n", "index", "=", "index", ")", ".", "loc", "[", ":", ",", "col_order", "]", "# ensure order", "\n", "# Transpose the results to have metrics in rows", "\n", "val_results", "=", "val_results", ".", "T", "\n", "# Add mean and set in first row", "\n", "means", "=", "metric_vals", "+", "[", "precisions", ".", "mean", "(", ")", ",", "recalls", ".", "mean", "(", ")", ",", "dices", ".", "mean", "(", ")", "]", "\n", "val_results", "[", "\"mean\"", "]", "=", "means", "\n", "cols", "=", "list", "(", "val_results", ".", "columns", ")", "\n", "cols", ".", "insert", "(", "0", ",", "cols", ".", "pop", "(", "cols", ".", "index", "(", "'mean'", ")", ")", ")", "\n", "val_results", "=", "val_results", ".", "loc", "[", ":", ",", "cols", "]", "\n", "\n", "# Print the df to screen", "\n", "print_string", "=", "val_results", ".", "round", "(", "self", ".", "print_round", ")", ".", "to_string", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\\n\"", "+", "\n", "highlighted", "(", "f\"[{name}] Validation Results for Epoch {epoch}\"", ")", ".", "lstrip", "(", "\" \"", ")", "+", "\n", "\"\\n\"", "+", "\n", "print_string", ".", "replace", "(", "\"NaN\"", ",", "\"---\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation.on_epoch_end": [[189, 227], ["callbacks.Validation.predict", "callbacks.Validation._compute_dice", "numpy.arange", "dices.mean().round", "precisions.mean().round", "recalls.mean().round", "metrics[].items", "callbacks.Validation._log_val_results", "len", "logger.info", "tuple", "pandas.DataFrame", "logger.info", "len", "value.round", "utime.utils.highlighted", "numpy.mean", "numpy.mean.round", "len", "dices.mean", "precisions.mean", "recalls.mean", "list", "str", "f.split", "pandas.DataFrame.round"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation.predict", "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._compute_dice", "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.Validation._log_val_results", "home.repos.pwc.inspect_result.perslev_U-Time.utils.utils.highlighted"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "# Predict and get CM", "\n", "        ", "TPs", ",", "relevant", ",", "selected", ",", "metrics", "=", "self", ".", "predict", "(", ")", "\n", "for", "id_", "in", "self", ".", "IDs", ":", "\n", "            ", "tp", ",", "rel", ",", "sel", "=", "TPs", "[", "id_", "]", ",", "relevant", "[", "id_", "]", ",", "selected", "[", "id_", "]", "\n", "precisions", ",", "recalls", ",", "dices", "=", "self", ".", "_compute_dice", "(", "tp", "=", "tp", ",", "sel", "=", "sel", ",", "rel", "=", "rel", ")", "\n", "classes", "=", "np", ".", "arange", "(", "len", "(", "dices", ")", ")", "\n", "\n", "# Add to log", "\n", "n", "=", "(", "id_", "+", "\"_\"", ")", "if", "len", "(", "self", ".", "IDs", ")", ">", "1", "else", "\"\"", "\n", "logs", "[", "f\"{n}val_dice\"", "]", "=", "dices", ".", "mean", "(", ")", ".", "round", "(", "self", ".", "log_round", ")", "\n", "logs", "[", "f\"{n}val_precision\"", "]", "=", "precisions", ".", "mean", "(", ")", ".", "round", "(", "self", ".", "log_round", ")", "\n", "logs", "[", "f\"{n}val_recall\"", "]", "=", "recalls", ".", "mean", "(", ")", ".", "round", "(", "self", ".", "log_round", ")", "\n", "for", "m_name", ",", "value", "in", "metrics", "[", "id_", "]", ".", "items", "(", ")", ":", "\n", "                ", "logs", "[", "f\"{n}val_{m_name}\"", "]", "=", "value", ".", "round", "(", "self", ".", "log_round", ")", "\n", "\n", "", "self", ".", "_log_val_results", "(", "precisions", "=", "precisions", ",", "\n", "recalls", "=", "recalls", ",", "\n", "dices", "=", "dices", ",", "\n", "metrics", "=", "metrics", "[", "id_", "]", ",", "\n", "epoch", "=", "epoch", ",", "\n", "name", "=", "id_", ",", "\n", "classes", "=", "classes", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "IDs", ")", ">", "1", ":", "\n", "# Print cross-dataset mean values", "\n", "            ", "logger", ".", "info", "(", "highlighted", "(", "f\"[ALL DATASETS] Means Across Classes for Epoch {epoch}\"", ")", ")", "\n", "fetch", "=", "(", "\"val_dice\"", ",", "\"val_precision\"", ",", "\"val_recall\"", ")", "\n", "m_fetch", "=", "tuple", "(", "[", "\"val_\"", "+", "s", "for", "s", "in", "self", ".", "model", ".", "metrics_names", "]", ")", "\n", "to_print", "=", "{", "}", "\n", "for", "f", "in", "fetch", "+", "m_fetch", ":", "\n", "                ", "scores", "=", "[", "logs", "[", "\"%s_%s\"", "%", "(", "name", ",", "f", ")", "]", "for", "name", "in", "self", ".", "IDs", "]", "\n", "res", "=", "np", ".", "mean", "(", "scores", ")", "\n", "logs", "[", "f", "]", "=", "res", ".", "round", "(", "self", ".", "log_round", ")", "# Add to log file", "\n", "to_print", "[", "f", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "]", "=", "list", "(", "scores", ")", "+", "[", "res", "]", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "to_print", ")", "\n", "df", ".", "index", "=", "self", ".", "IDs", "+", "[", "\"mean\"", "]", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "str", "(", "df", ".", "round", "(", "self", ".", "print_round", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption.__init__": [[230, 240], ["tensorflow.keras.callbacks.Callback.__init__", "resource.getrlimit", "resource.setrlimit", "logger.info", "callbacks.MemoryConsumption._gib_to_bytes"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption._gib_to_bytes"], ["    ", "def", "__init__", "(", "self", ",", "max_gib", "=", "None", ",", "round_", "=", "2", ",", "set_limit", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_gib", "=", "max_gib", "\n", "self", ".", "round_", "=", "round_", "\n", "if", "set_limit", ":", "\n", "            ", "import", "resource", "\n", "_", ",", "hard", "=", "resource", ".", "getrlimit", "(", "resource", ".", "RLIMIT_AS", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_AS", ",", "\n", "(", "self", ".", "_gib_to_bytes", "(", "max_gib", ")", ",", "hard", ")", ")", "\n", "logger", ".", "info", "(", "f\"Setting memory limit to {max_gib} GiB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption._gib_to_bytes": [[241, 244], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_gib_to_bytes", "(", "gib", ")", ":", "\n", "        ", "return", "gib", "*", "(", "1024", "**", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption._bytes_to_gib": [[245, 248], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_bytes_to_gib", "(", "bytes", ")", ":", "\n", "        ", "return", "bytes", "/", "(", "1024", "**", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption.on_epoch_end": [[249, 258], ["psg_utils.utils.get_memory_usage", "round", "callbacks.MemoryConsumption._bytes_to_gib", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MemoryConsumption._bytes_to_gib"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "mem_bytes", "=", "get_memory_usage", "(", ")", "\n", "mem_gib", "=", "round", "(", "self", ".", "_bytes_to_gib", "(", "mem_bytes", ")", ",", "self", ".", "round_", ")", "\n", "logs", "[", "'memory_usage_gib'", "]", "=", "mem_gib", "\n", "if", "self", ".", "max_gib", "and", "mem_gib", ">=", "self", ".", "max_gib", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Stopping training from callback 'MemoryConsumption'! \"", "\n", "f\"Total memory consumption of {mem_gib} GiB exceeds limitation\"", "\n", "f\" (self.max_gib = {self.max_gib})\"", ")", "\n", "self", ".", "model", ".", "stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MaxTrainingTime.__init__": [[261, 269], ["tensorflow.keras.callbacks.Callback.__init__", "int"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "max_minutes", ",", "log_name", "=", "'train_time_total'", ")", ":", "\n", "        ", "\"\"\"\n        TODO\n        Args:\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_minutes", "=", "int", "(", "max_minutes", ")", "\n", "self", ".", "log_name", "=", "log_name", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MaxTrainingTime.on_epoch_end": [[270, 296], ["logs.get", "logger.warning", "datetime.datetime.timedelta().total_seconds", "logger.warning", "datetime.datetime.timedelta", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epochs", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"\n        TODO\n\n        Args:\n            epochs:\n            logs:\n\n        Returns:\n\n        \"\"\"", "\n", "train_time_str", "=", "logs", ".", "get", "(", "self", ".", "log_name", ",", "None", ")", "\n", "if", "not", "train_time_str", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Did not find log entry '{self.log_name}' (needed in callback 'MaxTrainingTime')\"", ")", "\n", "return", "\n", "", "train_time_m", "=", "timedelta", "(", "\n", "days", "=", "int", "(", "train_time_str", "[", ":", "2", "]", ")", ",", "\n", "hours", "=", "int", "(", "train_time_str", "[", "4", ":", "6", "]", ")", ",", "\n", "minutes", "=", "int", "(", "train_time_str", "[", "8", ":", "10", "]", ")", ",", "\n", "seconds", "=", "int", "(", "train_time_str", "[", "12", ":", "14", "]", ")", "\n", ")", ".", "total_seconds", "(", ")", "/", "60", "\n", "if", "train_time_m", ">=", "self", ".", "max_minutes", ":", "\n", "# Stop training", "\n", "            ", "logger", ".", "warning", "(", "f\"Stopping training from callback 'MaxTrainingTime'! \"", "\n", "f\"Total training length of {self.max_minutes} minutes exceeded (now {train_time_m})\"", ")", "\n", "self", ".", "model", ".", "stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.CarbonUsageTracking.__init__": [[303, 321], ["tensorflow.keras.callbacks.Callback.__init__", "bool", "callbacks.CarbonUsageTracking.parameters.update"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "epochs", ",", "add_to_logs", "=", "True", ",", "monitor_epochs", "=", "-", "1", ",", "\n", "epochs_before_pred", "=", "-", "1", ",", "devices_by_pid", "=", "True", ",", "**", "additional_tracker_kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Accepts parameters as per CarbonTracker.__init__\n        Sets other default values for key parameters.\n\n        Args:\n            add_to_logs: bool, Add total_energy_kwh and total_co2_g to the keras logs after each epoch\n            For other arguments, please refer to CarbonTracker.__init__\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tracker", "=", "None", "\n", "self", ".", "add_to_logs", "=", "bool", "(", "add_to_logs", ")", "\n", "self", ".", "parameters", "=", "{", "\"epochs\"", ":", "epochs", ",", "\n", "\"monitor_epochs\"", ":", "monitor_epochs", ",", "\n", "\"epochs_before_pred\"", ":", "epochs_before_pred", ",", "\n", "\"devices_by_pid\"", ":", "devices_by_pid", "}", "\n", "self", ".", "parameters", ".", "update", "(", "additional_tracker_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.CarbonUsageTracking.on_train_end": [[322, 325], ["callbacks.CarbonUsageTracking.tracker.stop"], "methods", ["None"], ["", "def", "on_train_end", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "        ", "\"\"\" Ensure actual consumption is reported \"\"\"", "\n", "self", ".", "tracker", ".", "stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.CarbonUsageTracking.on_epoch_begin": [[326, 332], ["callbacks.CarbonUsageTracking.tracker.epoch_start", "carbontracker.tracker.CarbonTracker"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "\"\"\" Start tracking this epoch \"\"\"", "\n", "if", "self", ".", "tracker", "is", "None", ":", "\n", "# At this point all CPUs should be discoverable", "\n", "            ", "self", ".", "tracker", "=", "CarbonTracker", "(", "**", "self", ".", "parameters", ")", "\n", "", "self", ".", "tracker", ".", "epoch_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.CarbonUsageTracking.on_epoch_end": [[333, 341], ["callbacks.CarbonUsageTracking.tracker.epoch_end", "callbacks.CarbonUsageTracking.tracker.tracker.total_energy_per_epoch().sum", "callbacks.CarbonUsageTracking.tracker._co2eq", "round", "round", "callbacks.CarbonUsageTracking.tracker.tracker.total_energy_per_epoch"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" End tracking this epoch \"\"\"", "\n", "self", ".", "tracker", ".", "epoch_end", "(", ")", "\n", "if", "self", ".", "add_to_logs", ":", "\n", "            ", "energy_kwh", "=", "self", ".", "tracker", ".", "tracker", ".", "total_energy_per_epoch", "(", ")", ".", "sum", "(", ")", "\n", "co2eq_g", "=", "self", ".", "tracker", ".", "_co2eq", "(", "energy_kwh", ")", "\n", "logs", "[", "\"total_energy_kwh\"", "]", "=", "round", "(", "energy_kwh", ",", "6", ")", "\n", "logs", "[", "\"total_co2_g\"", "]", "=", "round", "(", "co2eq_g", ",", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.LearningCurve.__init__": [[353, 369], ["tensorflow.keras.callbacks.Callback.__init__", "os.path.abspath", "os.path.join", "os.path.join", "os.path.exists", "os.makedirs", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "log_dir", "=", "\"logs\"", ",", "out_dir", "=", "\"logs\"", ",", "fname", "=", "\"curve.png\"", ",", "\n", "csv_regex", "=", "\"*training.csv\"", ",", "**", "plot_kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            log_dir: Relative path from the\n            out_dir:\n            fname:\n            csv_regex:\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_dir", "=", "os", ".", "path", ".", "abspath", "(", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "self", ".", "csv_regex", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "log_dir", ")", ",", "csv_regex", ")", "\n", "self", ".", "save_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "fname", ")", "\n", "self", ".", "plot_kwargs", "=", "plot_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.LearningCurve.on_epoch_end": [[370, 378], ["utime.utils.plotting.plot_all_training_curves", "logger.error"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.utils.plotting.plot_all_training_curves"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "plot_all_training_curves", "(", "self", ".", "csv_regex", ",", "\n", "self", ".", "save_path", ",", "\n", "logy", "=", "True", ",", "\n", "**", "self", ".", "plot_kwargs", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logger", ".", "error", "(", "f\"Could not plot one or more training curves. Reason: {e}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.DelayedCallback.__init__": [[385, 394], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "callback", ",", "start_from", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            callback:   A tf.keras callback\n            start_from: Delay the activity of 'callback' until this epoch\n                        'start_from'\n        \"\"\"", "\n", "self", ".", "callback", "=", "callback", "\n", "self", ".", "start_from", "=", "start_from", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.DelayedCallback.__getattr__": [[395, 397], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "callback", ",", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.DelayedCallback.on_epoch_end": [[398, 403], ["callbacks.DelayedCallback.callback.on_epoch_end", "logger.info"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.PrintDividerLine.on_epoch_end"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "epoch", ">=", "self", ".", "start_from", "-", "1", ":", "\n", "            ", "self", ".", "callback", ".", "on_epoch_end", "(", "epoch", ",", "logs", "=", "logs", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"[{self.callback.__class__.__name__}] \"", "\n", "f\"Not active at epoch {epoch+1} - will be at {self.start_from}\"", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.TrainTimer.__init__": [[412, 420], ["tensorflow.keras.callbacks.Callback.__init__", "bool", "int"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "max_minutes", "=", "None", ",", "verbose", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_minutes", "=", "int", "(", "max_minutes", ")", "if", "max_minutes", "else", "None", "\n", "self", ".", "verbose", "=", "bool", "(", "verbose", ")", "\n", "\n", "# Timing attributes", "\n", "self", ".", "train_begin_time", "=", "None", "\n", "self", ".", "prev_epoch_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.TrainTimer.on_train_begin": [[421, 423], ["datetime.datetime.datetime.now"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "train_begin_time", "=", "datetime", ".", "now", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.TrainTimer.on_epoch_begin": [[424, 426], ["datetime.datetime.datetime.now"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "prev_epoch_time", "=", "datetime", ".", "now", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.TrainTimer.on_epoch_end": [[427, 450], ["datetime.datetime.datetime.now", "round", "round", "logger.info", "logger.info", "train_time.total_seconds", "epoch_time.total_seconds"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "# Compute epoch execution time", "\n", "        ", "end_time", "=", "datetime", ".", "now", "(", ")", "\n", "epoch_time", "=", "end_time", "-", "self", ".", "prev_epoch_time", "\n", "train_time", "=", "end_time", "-", "self", ".", "train_begin_time", "\n", "\n", "# Update attributes", "\n", "self", ".", "prev_epoch_time", "=", "end_time", "\n", "\n", "# Add to logs", "\n", "train_hours", "=", "round", "(", "train_time", ".", "total_seconds", "(", ")", "/", "3600", ",", "4", ")", "\n", "epoch_minutes", "=", "round", "(", "epoch_time", ".", "total_seconds", "(", ")", "/", "60", ",", "4", ")", "\n", "logs", "[", "\"epoch_minutes\"", "]", "=", "epoch_minutes", "\n", "logs", "[", "\"train_hours\"", "]", "=", "train_hours", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "f\"[TrainTimer] Epoch time: {epoch_minutes:.2f} minutes \"", "\n", "f\"- Total train time: {train_hours:.2f} hours\"", ")", "\n", "", "if", "self", ".", "max_minutes", "and", "train_hours", "*", "60", ">", "self", ".", "max_minutes", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Stopping training. Training ran for {train_hours*60} minutes, \"", "\n", "f\"max_minutes of {self.max_minutes} was specified on the \"", "\n", "f\"TrainTimer callback.\"", ")", "\n", "self", ".", "model", ".", "stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MeanReduceLogArrays.__init__": [[457, 459], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.MeanReduceLogArrays.on_epoch_end": [[460, 464], ["logs.items", "isinstance", "numpy.mean"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "logs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "(", "np", ".", "ndarray", ",", "list", ")", ")", ":", "\n", "                ", "logs", "[", "key", "]", "=", "np", ".", "mean", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.PrintDividerLine.__init__": [[470, 472], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.callbacks.PrintDividerLine.on_epoch_end": [[473, 475], ["print"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "print", "(", "\"\\n\"", "+", "\"-\"", "*", "45", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.utils.init_callback_objects": [[9, 50], ["enumerate", "cb_objs.append", "logger.info", "isinstance", "callback.get", "utime.callbacks.DelayedCallback.", "logger.info", "utime.callbacks.DelayedCallback", "getattr", "getattr", "ValueError"], "function", ["None"], ["\n", "def", "create_folders", "(", "folders", ",", "create_deep", "=", "False", ")", ":", "\n", "    ", "def", "safe_make", "(", "path", ",", "make_func", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "make_func", "(", "path", ")", "\n", "", "except", "FileExistsError", ":", "\n", "# If running many jobs in parallel this may occur", "\n", "            ", "pass", "\n", "", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f", ")", ":", "\n", "                ", "safe_make", "(", "f", ",", "make_func", ")", "\n", "\n", "\n", "", "", "", "", "def", "flatten_lists_recursively", "(", "list_of_lists", ")", ":", "\n", "    ", "for", "list_", "in", "list_of_lists", ":", "\n", "        ", "if", "isinstance", "(", "list_", ",", "Iterable", ")", "and", "not", "isinstance", "(", "list_", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n", "\n", "", "", "", "def", "highlighted", "(", "string", ")", ":", "\n", "    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n", "\n", "", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "if", "isinstance", "(", "pids", ",", "str", ")", ":", "\n", "        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.utils.remove_validation_callbacks": [[52, 72], ["enumerate", "callback[].values", "any", "val_dependent_params.append", "logger.info", "tensorflow.keras.callbacks.pop", "str().lower", "str"], "function", ["None"], ["", "", "def", "wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n", "if", "not", "pid", ":", "\n", "        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pid", "=", "int", "(", "pid", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n", "", "", "_wait_for", "(", "pid", ",", "check_every", ")", "\n", "\n", "\n", "", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "still_running", "=", "True", "\n", "logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "try", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet.__init__": [[23, 55], ["super().__init__", "utime.models.utils.standardize_batch_shape", "tensorflow.name_scope", "super().__init__", "deep_sleep_net.DeepFeatureNet.log", "deep_sleep_net.DeepFeatureNet.init_model"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.standardize_batch_shape", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model"], ["def", "__init__", "(", "self", ",", "\n", "batch_shape", ",", "\n", "n_classes", ",", "\n", "padding", "=", "\"valid\"", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "use_dropout", "=", "True", ",", "\n", "use_bn", "=", "True", ",", "\n", "classify", "=", "True", ",", "\n", "flatten", "=", "True", ",", "\n", "l2_reg", "=", "0.0", ",", "\n", "log", "=", "True", ",", "\n", "build", "=", "True", ",", "\n", "**", "unused", ")", ":", "\n", "        ", "super", "(", "DeepFeatureNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_shape", "=", "standardize_batch_shape", "(", "batch_shape", ")", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "use_dropout", "=", "use_dropout", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "use_bn", "=", "use_bn", "\n", "self", ".", "classify", "=", "classify", "\n", "self", ".", "flatten", "=", "flatten", "\n", "self", ".", "l2_reg", "=", "l2_reg", "\n", "self", ".", "reg", "=", "None", "\n", "self", ".", "model_name", "=", "\"DeepFeatureNet\"", "\n", "\n", "# Build model and init base keras Model class", "\n", "if", "build", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "self", ".", "model_name", ")", ":", "\n", "                ", "super", "(", "DeepFeatureNet", ",", "self", ")", ".", "__init__", "(", "*", "self", ".", "init_model", "(", ")", ")", "\n", "", "if", "log", ":", "\n", "                ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet.log": [[56, 58], ["logger.info", "deep_sleep_net.DeepFeatureNet.count_params"], "methods", ["None"], ["", "", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"\\nDeepFeatureNet Model Summary\\n\"", "\n", "\"----------------------------\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet._build_encoder": [[68, 100], ["range", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.MaxPooling1D", "tensorflow.keras.layers.MaxPooling1D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.BatchNormalization"], "methods", ["None"], ["", "def", "_build_encoder", "(", "self", ",", "inputs", ",", "n_filters_input", ",", "filter_size_input", ",", "\n", "stride_input", ",", "pool_size_input", ",", "n_filters_lower", ",", "\n", "filter_size_lower", ",", "stride_lower", ",", "pool_size_lower", ",", "kr", ",", "\n", "name", ")", ":", "\n", "        ", "inputs", "=", "Conv1D", "(", "filters", "=", "n_filters_input", ",", "\n", "kernel_size", "=", "filter_size_input", ",", "\n", "strides", "=", "stride_input", ",", "\n", "kernel_regularizer", "=", "kr", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "name", "=", "f\"{name}_conv_input\"", ")", "(", "inputs", ")", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "inputs", "=", "BatchNormalization", "(", "name", "=", "f\"{name}_BN_input\"", ")", "(", "inputs", ")", "\n", "", "inputs", "=", "MaxPooling1D", "(", "pool_size", "=", "pool_size_input", ",", "\n", "name", "=", "f\"{name}_MP_input\"", ")", "(", "inputs", ")", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "inputs", "=", "Dropout", "(", "0.5", ",", "name", "=", "f\"{name}_DO_input\"", ")", "(", "inputs", ")", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "inputs", "=", "Conv1D", "(", "filters", "=", "n_filters_lower", ",", "\n", "kernel_size", "=", "filter_size_lower", ",", "\n", "strides", "=", "stride_lower", ",", "\n", "kernel_regularizer", "=", "kr", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "name", "=", "f\"{name}_conv_lower{i}\"", ")", "(", "inputs", ")", "\n", "if", "self", ".", "use_bn", ":", "\n", "                ", "inputs", "=", "BatchNormalization", "(", "name", "=", "f\"{name}BN_lower_{i}\"", ")", "(", "inputs", ")", "\n", "", "", "inputs", "=", "MaxPooling1D", "(", "pool_size", "=", "pool_size_lower", ",", "\n", "name", "=", "f\"{name}_MP_lower\"", ")", "(", "inputs", ")", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "inputs", "=", "Dropout", "(", "0.5", ",", "name", "=", "f\"{name}_DO_lower\"", ")", "(", "inputs", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet.init_model": [[101, 141], ["tensorflow.keras.layers.Input", "tensorflow.keras.regularizers.l2", "tensorflow.name_scope", "deep_sleep_net.DeepFeatureNet._build_encoder", "tensorflow.name_scope", "deep_sleep_net.DeepFeatureNet._build_encoder", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Concatenate"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet._build_encoder", "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepFeatureNet._build_encoder"], ["", "def", "init_model", "(", "self", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "Input", "(", "shape", "=", "self", ".", "batch_shape", ",", "name", "=", "\"input\"", ")", "\n", "\n", "# Apply regularization if not None or 0", "\n", "", "self", ".", "reg", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "self", ".", "l2_reg", ")", "if", "self", ".", "l2_reg", "else", "None", "\n", "\n", "# Build two encoders", "\n", "with", "tf", ".", "name_scope", "(", "\"small_filter_encoder\"", ")", ":", "\n", "            ", "enc1", "=", "self", ".", "_build_encoder", "(", "inputs", "=", "inputs", ",", "\n", "n_filters_input", "=", "64", ",", "\n", "filter_size_input", "=", "50", ",", "\n", "stride_input", "=", "6", ",", "\n", "pool_size_input", "=", "8", ",", "\n", "n_filters_lower", "=", "128", ",", "\n", "filter_size_lower", "=", "8", ",", "\n", "stride_lower", "=", "1", ",", "\n", "pool_size_lower", "=", "4", ",", "\n", "kr", "=", "self", ".", "reg", ",", "name", "=", "\"SFE\"", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"large_filter_encoder\"", ")", ":", "\n", "            ", "enc2", "=", "self", ".", "_build_encoder", "(", "inputs", "=", "inputs", ",", "\n", "n_filters_input", "=", "64", ",", "\n", "filter_size_input", "=", "400", ",", "\n", "stride_input", "=", "50", ",", "\n", "pool_size_input", "=", "4", ",", "\n", "n_filters_lower", "=", "128", ",", "\n", "filter_size_lower", "=", "6", ",", "\n", "stride_lower", "=", "1", ",", "\n", "pool_size_lower", "=", "2", ",", "\n", "kr", "=", "self", ".", "reg", ",", "name", "=", "\"LFE\"", ")", "\n", "", "if", "self", ".", "flatten", ":", "\n", "            ", "enc1", "=", "Flatten", "(", "name", "=", "\"flatten_small_filters\"", ")", "(", "enc1", ")", "\n", "enc2", "=", "Flatten", "(", "name", "=", "\"flatten_large_filters\"", ")", "(", "enc2", ")", "\n", "", "if", "self", ".", "classify", ":", "\n", "            ", "outputs", "=", "Concatenate", "(", "name", "=", "\"concat_features\"", ")", "(", "[", "enc1", ",", "enc2", "]", ")", "\n", "outputs", "=", "Dense", "(", "self", ".", "n_classes", ",", "activation", "=", "\"softmax\"", ",", "\n", "name", "=", "\"classifier\"", ")", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "Concatenate", "(", "name", "=", "\"concat\"", ")", "(", "[", "enc1", ",", "enc2", "]", ")", "\n", "", "return", "[", "inputs", "]", ",", "[", "outputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepSleepNet.__init__": [[147, 184], ["deep_sleep_net.DeepFeatureNet.__init__", "len", "tensorflow.name_scope", "deep_sleep_net.DeepFeatureNet.__init__", "deep_sleep_net.DeepSleepNet.log", "deep_sleep_net.DeepSleepNet.init_model"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model"], ["def", "__init__", "(", "self", ",", "\n", "batch_shape", ",", "\n", "n_classes", ",", "\n", "n_rnn_layers", "=", "2", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "use_dropout", "=", "True", ",", "\n", "use_bn", "=", "True", ",", "\n", "l2_reg", "=", "0.0", ",", "\n", "l2_reg_feature_net", "=", "None", ",", "\n", "log", "=", "True", ",", "\n", "name", "=", "\"DeepSleepNet\"", ",", "\n", "**", "unused", ")", ":", "\n", "        ", "super", "(", "DeepSleepNet", ",", "self", ")", ".", "__init__", "(", "\n", "batch_shape", "=", "[", "None", ",", "None", "]", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "activation", ",", "\n", "use_dropout", "=", "use_dropout", ",", "\n", "use_bn", "=", "use_bn", ",", "\n", "classify", "=", "False", ",", "\n", "l2_reg", "=", "l2_reg_feature_net", "or", "l2_reg", ",", "\n", "log", "=", "False", ",", "\n", "build", "=", "False", "\n", ")", "\n", "assert", "len", "(", "batch_shape", ")", "==", "4", "\n", "self", ".", "n_periods", "=", "batch_shape", "[", "1", "]", "\n", "self", ".", "input_dims", "=", "batch_shape", "[", "2", "]", "\n", "self", ".", "n_channels", "=", "batch_shape", "[", "3", "]", "\n", "self", ".", "n_rnn_layers", "=", "n_rnn_layers", "\n", "self", ".", "model_name", "=", "name", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "model_name", ")", ":", "\n", "            ", "super", "(", "DeepFeatureNet", ",", "self", ")", ".", "__init__", "(", "\n", "*", "self", ".", "init_model", "(", ")", "\n", ")", "\n", "", "if", "log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepSleepNet.log": [[185, 187], ["logger.info", "deep_sleep_net.DeepSleepNet.count_params"], "methods", ["None"], ["", "", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"DeepSleepNet Model Summary\\n\"", "\n", "\"-------------------------\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepSleepNet._reshape": [[199, 201], ["tensorflow.keras.backend.reshape"], "methods", ["None"], ["", "def", "_reshape", "(", "self", ",", "layer", ",", "shape", ")", ":", "\n", "        ", "return", "tf", ".", "keras", ".", "backend", ".", "reshape", "(", "layer", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.deep_sleep_net.DeepSleepNet.init_model": [[202, 250], ["tensorflow.keras.layers.Input", "deep_sleep_net.DeepFeatureNet.init_model", "tensorflow.keras.layers.Lambda", "tensorflow.name_scope", "outputs.append", "tensorflow.name_scope", "range", "outputs.append", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Add", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Bidirectional", "tensorflow.keras.layers.Dropout", "features.get_shape", "tensorflow.keras.layers.LSTM", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model"], ["", "def", "init_model", "(", "self", ",", "inputs", "=", "None", ")", ":", "\n", "        ", "inputs", "=", "Input", "(", "shape", "=", "[", "self", ".", "n_periods", ",", "self", ".", "input_dims", ",", "self", ".", "n_channels", "]", ")", "\n", "\n", "# Reshape and build DeepFeatureNet", "\n", "s", "=", "[", "-", "1", ",", "self", ".", "input_dims", ",", "self", ".", "n_channels", "]", "\n", "feature_ins", "=", "Lambda", "(", "self", ".", "_reshape", ",", "arguments", "=", "{", "\"shape\"", ":", "s", "}", ")", "(", "inputs", ")", "\n", "_", ",", "features", "=", "super", "(", "DeepSleepNet", ",", "self", ")", ".", "init_model", "(", "inputs", "=", "feature_ins", ")", "\n", "features", "=", "features", "[", "0", "]", "\n", "\n", "outputs", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"fc_skip_conn\"", ")", ":", "\n", "# Fully connected skip-conn", "\n", "            ", "skip_con", "=", "Dense", "(", "units", "=", "1024", ",", "activation", "=", "\"relu\"", ",", "\n", "name", "=", "\"skip_conn_FC\"", ",", "\n", "kernel_regularizer", "=", "self", ".", "reg", ")", "(", "features", ")", "\n", "outputs", ".", "append", "(", "BatchNormalization", "(", "name", "=", "\"skip_conn_BN\"", ")", "(", "skip_con", ")", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"bidirect_LSTMs\"", ")", ":", "\n", "# Reshape to sequence and feed to Bidirectional LSTMs", "\n", "            ", "s", "=", "[", "-", "1", ",", "self", ".", "n_periods", ",", "features", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "]", "\n", "seq", "=", "Lambda", "(", "self", ".", "_reshape", ",", "arguments", "=", "{", "\"shape\"", ":", "s", "}", ",", "\n", "name", "=", "\"LSTM_input_reshape\"", ")", "(", "features", ")", "\n", "do", "=", "0.5", "if", "self", ".", "use_dropout", "else", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "n_rnn_layers", ")", ":", "\n", "                ", "seq", "=", "Bidirectional", "(", "LSTM", "(", "units", "=", "512", ",", "dropout", "=", "do", ",", "\n", "recurrent_dropout", "=", "0", ",", "\n", "return_sequences", "=", "True", ",", "\n", "kernel_regularizer", "=", "self", ".", "reg", ",", "\n", "name", "=", "f\"LSTM_{i}\"", ")", ",", "\n", "name", "=", "f\"bidirect_{i}\"", ")", "(", "seq", ")", "\n", "if", "self", ".", "use_bn", ":", "\n", "                    ", "seq", "=", "BatchNormalization", "(", "name", "=", "f\"LSTM_bn_{i}\"", ")", "(", "seq", ")", "\n", "", "", "s", "=", "[", "-", "1", ",", "1024", "]", "\n", "seq", "=", "Lambda", "(", "self", ".", "_reshape", ",", "arguments", "=", "{", "\"shape\"", ":", "s", "}", ",", "\n", "name", "=", "\"LSTM_output_reshape\"", ")", "(", "seq", ")", "\n", "outputs", ".", "append", "(", "seq", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"LSTM_and_skip_add\"", ")", ":", "\n", "# Add skip and LSTM outputs", "\n", "            ", "outputs", "=", "Add", "(", "name", "=", "\"add_LSTM_and_skip\"", ")", "(", "outputs", ")", "\n", "if", "self", ".", "use_dropout", ":", "\n", "                ", "outputs", "=", "Dropout", "(", "0.5", ")", "(", "outputs", ")", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"classifier\"", ")", ":", "\n", "# Classify", "\n", "            ", "outputs", "=", "Dense", "(", "units", "=", "self", ".", "n_classes", ",", "activation", "=", "\"softmax\"", ",", "\n", "name", "=", "\"deep_sleep_net_classifier\"", ")", "(", "outputs", ")", "\n", "s", "=", "[", "-", "1", ",", "self", ".", "n_periods", ",", "self", ".", "n_classes", "]", "\n", "outputs", "=", "Lambda", "(", "self", ".", "_reshape", ",", "arguments", "=", "{", "\"shape\"", ":", "s", "}", ",", "\n", "name", "=", "\"output_reshape\"", ")", "(", "outputs", ")", "\n", "", "return", "[", "inputs", "]", ",", "[", "outputs", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.__init__": [[33, 126], ["int", "int", "numpy.sqrt", "int", "padding.lower", "tensorflow.keras.models.Model.__init__", "utime.UTime.log", "len", "len", "ValueError", "ValueError", "isinstance", "TypeError", "ValueError", "isinstance", "utime.UTime.init_model", "utime.utils.conv_arithmetics.compute_receptive_fields"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.compute_receptive_fields"], ["def", "__init__", "(", "self", ",", "\n", "n_classes", ",", "\n", "batch_shape", ",", "\n", "depth", "=", "4", ",", "\n", "dilation", "=", "2", ",", "\n", "activation", "=", "\"elu\"", ",", "\n", "dense_classifier_activation", "=", "\"tanh\"", ",", "\n", "kernel_size", "=", "5", ",", "\n", "transition_window", "=", "1", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "init_filters", "=", "16", ",", "\n", "complexity_factor", "=", "2", ",", "\n", "l2_reg", "=", "None", ",", "\n", "pools", "=", "(", "10", ",", "8", ",", "6", ",", "4", ")", ",", "\n", "data_per_prediction", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        n_classes (int):\n            The number of classes to model, gives the number of filters in the\n            final 1x1 conv layer.\n        batch_shape (list): Giving the shape of one one batch of data,\n                            potentially omitting the zeroth axis (the batch\n                            size dim)\n        depth (int):\n            Number of conv blocks in encoding layer (number of 2x2 max pools)\n            Note: each block doubles the filter count while halving the spatial\n            dimensions of the features.\n        dilation (int):\n            TODO\n        activation (string):\n            Activation function for convolution layers\n        dense_classifier_activation (string):\n            TODO\n        kernel_size (int):\n            Kernel size for convolution layers\n        transition_window (int):\n            TODO\n        padding (string):\n            Padding type ('same' or 'valid')\n        complexity_factor (int/float):\n            Use int(N * sqrt(complexity_factor)) number of filters in each\n            convolution layer instead of default N.\n        l2_reg (float in [0, 1])\n            L2 regularization on conv weights\n        pools (int or list of ints):\n            TODO\n        data_per_prediction (int):\n            TODO\n        build (bool):\n            TODO\n        \"\"\"", "\n", "# Set various attributes", "\n", "assert", "len", "(", "batch_shape", ")", "==", "4", "\n", "self", ".", "n_periods", "=", "batch_shape", "[", "1", "]", "\n", "self", ".", "input_dims", "=", "batch_shape", "[", "2", "]", "\n", "self", ".", "n_channels", "=", "batch_shape", "[", "3", "]", "\n", "self", ".", "n_classes", "=", "int", "(", "n_classes", ")", "\n", "self", ".", "dilation", "=", "int", "(", "dilation", ")", "\n", "self", ".", "cf", "=", "np", ".", "sqrt", "(", "complexity_factor", ")", "\n", "self", ".", "init_filters", "=", "init_filters", "\n", "self", ".", "kernel_size", "=", "int", "(", "kernel_size", ")", "\n", "self", ".", "transition_window", "=", "transition_window", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "l2_reg", "=", "l2_reg", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "n_crops", "=", "0", "\n", "self", ".", "pools", "=", "[", "pools", "]", "*", "self", ".", "depth", "if", "not", "isinstance", "(", "pools", ",", "(", "list", ",", "tuple", ")", ")", "else", "pools", "\n", "if", "len", "(", "self", ".", "pools", ")", "!=", "self", ".", "depth", ":", "\n", "            ", "raise", "ValueError", "(", "\"Argument 'pools' must be a single integer or a \"", "\n", "\"list of values of length equal to 'depth'.\"", ")", "\n", "", "self", ".", "padding", "=", "padding", ".", "lower", "(", ")", "\n", "if", "self", ".", "padding", "!=", "\"same\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently, must use 'same' padding.\"", ")", "\n", "\n", "", "self", ".", "dense_classifier_activation", "=", "dense_classifier_activation", "\n", "self", ".", "data_per_prediction", "=", "data_per_prediction", "or", "self", ".", "input_dims", "\n", "if", "not", "isinstance", "(", "self", ".", "data_per_prediction", ",", "(", "int", ",", "np", ".", "integer", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"data_per_prediction must be an integer value\"", ")", "\n", "", "if", "self", ".", "input_dims", "%", "self", ".", "data_per_prediction", ":", "\n", "            ", "raise", "ValueError", "(", "\"'input_dims' ({}) must be evenly divisible by \"", "\n", "\"'data_per_prediction' ({})\"", ".", "format", "(", "self", ".", "input_dims", ",", "\n", "self", ".", "data_per_prediction", ")", ")", "\n", "\n", "# Build model and init base keras Model class", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "self", ".", "init_model", "(", ")", ")", "\n", "\n", "# Compute receptive field", "\n", "ind", "=", "[", "x", ".", "__class__", ".", "__name__", "for", "x", "in", "self", ".", "layers", "]", ".", "index", "(", "\"UpSampling2D\"", ")", "\n", "self", ".", "receptive_field", "=", "compute_receptive_fields", "(", "self", ".", "layers", "[", ":", "ind", "]", ")", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "# Log the model definition", "\n", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.create_encoder": [[127, 183], ["range", "residual_connections.append", "int", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.MaxPooling2D", "int", "int", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_encoder", "(", "in_", ",", "\n", "depth", ",", "\n", "pools", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "activation", ",", "\n", "dilation", ",", "\n", "padding", ",", "\n", "complexity_factor", ",", "\n", "regularizer", "=", "None", ",", "\n", "name", "=", "\"encoder\"", ",", "\n", "name_prefix", "=", "\"\"", ")", ":", "\n", "        ", "name", "=", "\"{}{}\"", ".", "format", "(", "name_prefix", ",", "name", ")", "\n", "residual_connections", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "l_name", "=", "name", "+", "\"_L%i\"", "%", "i", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "dilation", ",", "\n", "name", "=", "l_name", "+", "\"_conv1\"", ")", "(", "in_", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "dilation", ",", "\n", "name", "=", "l_name", "+", "\"_conv2\"", ")", "(", "bn", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN2\"", ")", "(", "conv", ")", "\n", "in_", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "pools", "[", "i", "]", ",", "1", ")", ",", "\n", "name", "=", "l_name", "+", "\"_pool\"", ")", "(", "bn", ")", "\n", "\n", "# add bn layer to list for residual conn.", "\n", "residual_connections", ".", "append", "(", "bn", ")", "\n", "filters", "=", "int", "(", "filters", "*", "2", ")", "\n", "\n", "# Bottom", "\n", "", "name", "=", "\"{}bottom\"", ".", "format", "(", "name_prefix", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "1", ",", "\n", "name", "=", "name", "+", "\"_conv1\"", ")", "(", "in_", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "1", ",", "\n", "name", "=", "name", "+", "\"_conv2\"", ")", "(", "bn", ")", "\n", "encoded", "=", "BatchNormalization", "(", "name", "=", "name", "+", "\"_BN2\"", ")", "(", "conv", ")", "\n", "\n", "return", "encoded", ",", "residual_connections", ",", "filters", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.create_upsample": [[184, 234], ["range", "int", "utime.UTime.crop_nodes_to_match", "tensorflow.keras.layers.UpSampling2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.crop_nodes_to_match"], ["", "def", "create_upsample", "(", "self", ",", "\n", "in_", ",", "\n", "res_conns", ",", "\n", "depth", ",", "\n", "pools", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "activation", ",", "\n", "dilation", ",", "# NOT USED", "\n", "padding", ",", "\n", "complexity_factor", ",", "\n", "regularizer", "=", "None", ",", "\n", "name", "=", "\"upsample\"", ",", "\n", "name_prefix", "=", "\"\"", ")", ":", "\n", "        ", "name", "=", "\"{}{}\"", ".", "format", "(", "name_prefix", ",", "name", ")", "\n", "residual_connections", "=", "res_conns", "[", ":", ":", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "filters", "=", "int", "(", "filters", "/", "2", ")", "\n", "l_name", "=", "name", "+", "\"_L%i\"", "%", "i", "\n", "\n", "# Up-sampling block", "\n", "fs", "=", "pools", "[", ":", ":", "-", "1", "]", "[", "i", "]", "\n", "up", "=", "UpSampling2D", "(", "size", "=", "(", "fs", ",", "1", ")", ",", "\n", "name", "=", "l_name", "+", "\"_up\"", ")", "(", "in_", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "fs", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "\n", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "name", "=", "l_name", "+", "\"_conv1\"", ")", "(", "up", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "\n", "# Crop and concatenate", "\n", "cropped_res", "=", "self", ".", "crop_nodes_to_match", "(", "residual_connections", "[", "i", "]", ",", "bn", ")", "\n", "# cropped_res = residual_connections[i]", "\n", "merge", "=", "Concatenate", "(", "axis", "=", "-", "1", ",", "\n", "name", "=", "l_name", "+", "\"_concat\"", ")", "(", "[", "cropped_res", ",", "bn", "]", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "name", "=", "l_name", "+", "\"_conv2\"", ")", "(", "merge", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN2\"", ")", "(", "conv", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "name", "=", "l_name", "+", "\"_conv3\"", ")", "(", "bn", ")", "\n", "in_", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN3\"", ")", "(", "conv", ")", "\n", "", "return", "in_", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.create_dense_modeling": [[235, 256], ["utime.UTime.crop_nodes_to_match", "tensorflow.keras.layers.Conv2D", "cls.get_shape().as_list", "int", "tensorflow.keras.layers.ZeroPadding2D", "cls.get_shape"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.crop_nodes_to_match"], ["", "def", "create_dense_modeling", "(", "self", ",", "\n", "in_", ",", "\n", "in_reshaped", ",", "\n", "filters", ",", "\n", "dense_classifier_activation", ",", "\n", "regularizer", ",", "\n", "complexity_factor", ",", "\n", "name_prefix", "=", "\"\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "cls", "=", "Conv2D", "(", "filters", "=", "int", "(", "filters", "*", "complexity_factor", ")", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "activation", "=", "dense_classifier_activation", ",", "\n", "name", "=", "\"{}dense_classifier_out\"", ".", "format", "(", "name_prefix", ")", ")", "(", "in_", ")", "\n", "s", "=", "(", "self", ".", "n_periods", "*", "self", ".", "input_dims", ")", "-", "cls", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "out", "=", "self", ".", "crop_nodes_to_match", "(", "\n", "node1", "=", "ZeroPadding2D", "(", "padding", "=", "[", "[", "s", "//", "2", ",", "s", "//", "2", "+", "s", "%", "2", "]", ",", "[", "0", ",", "0", "]", "]", ")", "(", "cls", ")", ",", "\n", "node2", "=", "in_reshaped", "\n", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.create_seq_modeling": [[257, 289], ["tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "s.pop", "tensorflow.keras.layers.Lambda", "tensorflow.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_seq_modeling", "(", "in_", ",", "\n", "input_dims", ",", "\n", "data_per_period", ",", "\n", "n_periods", ",", "\n", "n_classes", ",", "\n", "transition_window", ",", "\n", "activation", ",", "\n", "regularizer", "=", "None", ",", "\n", "name_prefix", "=", "\"\"", ")", ":", "\n", "        ", "cls", "=", "AveragePooling2D", "(", "(", "data_per_period", ",", "1", ")", ",", "\n", "name", "=", "\"{}average_pool\"", ".", "format", "(", "name_prefix", ")", ")", "(", "in_", ")", "\n", "out", "=", "Conv2D", "(", "filters", "=", "n_classes", ",", "\n", "kernel_size", "=", "(", "transition_window", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"{}sequence_conv_out_1\"", ".", "format", "(", "name_prefix", ")", ")", "(", "cls", ")", "\n", "out", "=", "Conv2D", "(", "filters", "=", "n_classes", ",", "\n", "kernel_size", "=", "(", "transition_window", ",", "1", ")", ",", "\n", "activation", "=", "\"softmax\"", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"{}sequence_conv_out_2\"", ".", "format", "(", "name_prefix", ")", ")", "(", "out", ")", "\n", "s", "=", "[", "-", "1", ",", "n_periods", ",", "input_dims", "//", "data_per_period", ",", "n_classes", "]", "\n", "if", "s", "[", "2", "]", "==", "1", ":", "\n", "            ", "s", ".", "pop", "(", "2", ")", "# Squeeze the dim", "\n", "", "out", "=", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reshape", "(", "x", ",", "s", ")", ",", "\n", "name", "=", "\"{}sequence_classification_reshaped\"", ".", "format", "(", "name_prefix", ")", ")", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.init_model": [[290, 357], ["utime.train.utils.get_activation_function", "utime.UTime.create_encoder", "utime.UTime.create_upsample", "utime.UTime.create_dense_modeling", "utime.UTime.create_seq_modeling", "tensorflow.keras.layers.Input", "tensorflow.keras.layers.Lambda", "tensorflow.keras.regularizers.l2", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils.get_activation_function", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_encoder", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_upsample", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_dense_modeling", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_seq_modeling"], ["", "def", "init_model", "(", "self", ",", "inputs", "=", "None", ",", "name_prefix", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Build the UNet model with the specified input image shape.\n        \"\"\"", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "Input", "(", "shape", "=", "[", "self", ".", "n_periods", ",", "\n", "self", ".", "input_dims", ",", "\n", "self", ".", "n_channels", "]", ")", "\n", "", "reshaped", "=", "[", "-", "1", ",", "self", ".", "n_periods", "*", "self", ".", "input_dims", ",", "1", ",", "self", ".", "n_channels", "]", "\n", "in_reshaped", "=", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reshape", "(", "x", ",", "reshaped", ")", ")", "(", "inputs", ")", "\n", "\n", "# Apply regularization if not None or 0", "\n", "regularizer", "=", "regularizers", ".", "l2", "(", "self", ".", "l2_reg", ")", "if", "self", ".", "l2_reg", "else", "None", "\n", "\n", "# Get activation func from tf or tfa", "\n", "activation", "=", "get_activation_function", "(", "activation_string", "=", "self", ".", "activation", ")", "\n", "\n", "settings", "=", "{", "\n", "\"depth\"", ":", "self", ".", "depth", ",", "\n", "\"pools\"", ":", "self", ".", "pools", ",", "\n", "\"filters\"", ":", "self", ".", "init_filters", ",", "\n", "\"kernel_size\"", ":", "self", ".", "kernel_size", ",", "\n", "\"activation\"", ":", "activation", ",", "\n", "\"dilation\"", ":", "self", ".", "dilation", ",", "\n", "\"padding\"", ":", "self", ".", "padding", ",", "\n", "\"regularizer\"", ":", "regularizer", ",", "\n", "\"name_prefix\"", ":", "name_prefix", ",", "\n", "\"complexity_factor\"", ":", "self", ".", "cf", "\n", "}", "\n", "\n", "\"\"\"\n        Encoding path\n        \"\"\"", "\n", "enc", ",", "residual_cons", ",", "filters", "=", "self", ".", "create_encoder", "(", "in_", "=", "in_reshaped", ",", "\n", "**", "settings", ")", "\n", "\n", "\"\"\"\n        Decoding path\n        \"\"\"", "\n", "settings", "[", "\"filters\"", "]", "=", "filters", "\n", "up", "=", "self", ".", "create_upsample", "(", "enc", ",", "residual_cons", ",", "**", "settings", ")", "\n", "\n", "\"\"\"\n        Dense class modeling layers\n        \"\"\"", "\n", "cls", "=", "self", ".", "create_dense_modeling", "(", "in_", "=", "up", ",", "\n", "in_reshaped", "=", "in_reshaped", ",", "\n", "filters", "=", "self", ".", "n_classes", ",", "\n", "dense_classifier_activation", "=", "self", ".", "dense_classifier_activation", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "complexity_factor", "=", "self", ".", "cf", ",", "\n", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "\"\"\"\n        Sequence modeling\n        \"\"\"", "\n", "out", "=", "self", ".", "create_seq_modeling", "(", "in_", "=", "cls", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "data_per_period", "=", "self", ".", "data_per_prediction", ",", "\n", "n_periods", "=", "self", ".", "n_periods", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "transition_window", "=", "self", ".", "transition_window", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "return", "[", "inputs", "]", ",", "[", "out", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.crop_nodes_to_match": [[358, 374], ["numpy.any", "numpy.array", "numpy.array", "numpy.array().flatten", "node1.get_shape().as_list", "node2.get_shape().as_list", "tensorflow.keras.layers.Cropping2D", "numpy.array", "node1.get_shape", "node2.get_shape", "list"], "methods", ["None"], ["", "def", "crop_nodes_to_match", "(", "self", ",", "node1", ",", "node2", ")", ":", "\n", "        ", "\"\"\"\n        If necessary, applies Cropping2D layer to node1 to match shape of node2\n        \"\"\"", "\n", "s1", "=", "np", ".", "array", "(", "node1", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "[", "1", ":", "-", "2", "]", "\n", "s2", "=", "np", ".", "array", "(", "node2", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "[", "1", ":", "-", "2", "]", "\n", "\n", "if", "np", ".", "any", "(", "s1", "!=", "s2", ")", ":", "\n", "            ", "self", ".", "n_crops", "+=", "1", "\n", "c", "=", "(", "s1", "-", "s2", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "cr", "=", "np", ".", "array", "(", "[", "c", "//", "2", ",", "c", "//", "2", "]", ")", ".", "flatten", "(", ")", "\n", "cr", "[", "self", ".", "n_crops", "%", "2", "]", "+=", "c", "%", "2", "\n", "cropped_node1", "=", "Cropping2D", "(", "[", "list", "(", "cr", ")", ",", "[", "0", ",", "0", "]", "]", ")", "(", "node1", ")", "\n", "", "else", ":", "\n", "            ", "cropped_node1", "=", "node1", "\n", "", "return", "cropped_node1", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utime.UTime.log": [[375, 377], ["logger.info", "utime.UTime.count_params"], "methods", ["None"], ["", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"\\nUTime Model Summary\\n\"", "\n", "\"-------------------\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.InputReshape.__init__": [[32, 36], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "seq_length", ",", "n_channels", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "InputReshape", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "self", ".", "seq_length", "=", "seq_length", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.InputReshape.get_config": [[37, 44], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.OutputReshape.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "\"seq_length\"", ":", "self", ".", "seq_length", ",", "\n", "\"n_channels\"", ":", "self", ".", "n_channels", ",", "\n", "}", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.InputReshape.call": [[45, 49], ["usleep.shape_safe", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "shape", "=", "shape_safe", "(", "inputs", ")", "\n", "inputs_reshaped", "=", "tf", ".", "reshape", "(", "inputs", ",", "shape", "=", "[", "shape", "[", "0", "]", ",", "self", ".", "seq_length", "or", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", ",", "1", ",", "self", ".", "n_channels", "]", ")", "\n", "return", "inputs_reshaped", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.OutputReshape.__init__": [[52, 55], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_periods", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OutputReshape", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "self", ".", "n_periods", "=", "n_periods", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.OutputReshape.get_config": [[56, 62], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.OutputReshape.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "\"n_periods\"", ":", "self", ".", "n_periods", "\n", "}", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.OutputReshape.call": [[63, 70], ["usleep.shape_safe", "int", "tensorflow.reshape", "shape_safe.pop"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "shape", "=", "shape_safe", "(", "inputs", ")", "\n", "n_pred", "=", "int", "(", "shape", "[", "1", "]", "//", "self", ".", "n_periods", ")", "\n", "shape", "=", "[", "shape", "[", "0", "]", ",", "self", ".", "n_periods", "or", "shape", "[", "1", "]", ",", "n_pred", ",", "inputs", ".", "shape", "[", "-", "1", "]", "]", "\n", "if", "n_pred", "==", "1", ":", "\n", "            ", "shape", ".", "pop", "(", "2", ")", "\n", "", "return", "tf", ".", "reshape", "(", "inputs", ",", "shape", "=", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.PadEndToEvenLength.__init__": [[73, 75], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PadEndToEvenLength", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.PadEndToEvenLength.call": [[76, 79], ["tensorflow.pad", "usleep.shape_safe"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "tf", ".", "pad", "(", "inputs", ",", "\n", "paddings", "=", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "shape_safe", "(", "inputs", ",", "1", ")", "%", "2", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.PadToMatch.__init__": [[82, 84], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PadToMatch", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.PadToMatch.call": [[85, 89], ["tensorflow.maximum", "tensorflow.pad", "usleep.shape_safe", "usleep.shape_safe"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "s", "=", "tf", ".", "maximum", "(", "0", ",", "shape_safe", "(", "inputs", "[", "1", "]", ",", "1", ")", "-", "shape_safe", "(", "inputs", "[", "0", "]", ",", "1", ")", ")", "\n", "return", "tf", ".", "pad", "(", "inputs", "[", "0", "]", ",", "\n", "paddings", "=", "[", "[", "0", ",", "0", "]", ",", "[", "s", "//", "2", ",", "s", "//", "2", "+", "(", "s", "%", "2", ")", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.CropToMatch.__init__": [[92, 94], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CropToMatch", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.CropToMatch.call": [[95, 99], ["tensorflow.maximum", "usleep.shape_safe", "usleep.shape_safe", "usleep.shape_safe"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "diff", "=", "tf", ".", "maximum", "(", "0", ",", "shape_safe", "(", "inputs", "[", "0", "]", ",", "1", ")", "-", "shape_safe", "(", "inputs", "[", "1", "]", ",", "1", ")", ")", "\n", "start", "=", "diff", "//", "2", "+", "diff", "%", "2", "\n", "return", "inputs", "[", "0", "]", "[", ":", ",", "start", ":", "start", "+", "shape_safe", "(", "inputs", "[", "1", "]", ",", "1", ")", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.__init__": [[110, 201], ["tensorflow.keras.initializers.glorot_uniform", "tensorflow.keras.initializers.zeros", "int", "int", "numpy.sqrt", "int", "padding.lower", "tensorflow.keras.models.Model.__init__", "len", "ValueError", "isinstance", "TypeError", "ValueError", "usleep.USleep.log", "usleep.USleep.init_model", "utime.utils.conv_arithmetics.compute_receptive_fields"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.utils.conv_arithmetics.compute_receptive_fields"], ["def", "__init__", "(", "self", ",", "\n", "n_classes", ",", "\n", "batch_shape", ",", "\n", "depth", "=", "12", ",", "\n", "dilation", "=", "1", ",", "\n", "activation", "=", "\"elu\"", ",", "\n", "dense_classifier_activation", "=", "\"tanh\"", ",", "\n", "kernel_size", "=", "9", ",", "\n", "transition_window", "=", "1", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "init_filters", "=", "5", ",", "\n", "complexity_factor", "=", "2", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_uniform", "(", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "zeros", "(", ")", ",", "\n", "l2_reg", "=", "None", ",", "\n", "data_per_prediction", "=", "None", ",", "\n", "no_log", "=", "False", ",", "\n", "name", "=", "\"\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        n_classes (int):\n            The number of classes to model, gives the number of filters in the\n            final 1x1 conv layer.\n        batch_shape (list): Giving the shape of one one batch of data,\n                            potentially omitting the zeroth axis (the batch\n                            size dim)\n        depth (int):\n            Number of conv blocks in encoding layer (number of 2x2 max pools)\n            Note: each block doubles the filter count while halving the spatial\n            dimensions of the features.\n        dilation (int):\n            TODO\n        activation (string):\n            Activation function for convolution layers\n        dense_classifier_activation (string):\n            TODO\n        kernel_size (int):\n            Kernel size for convolution layers\n        transition_window (int):\n            TODO\n        padding (string):\n            Padding type ('same' or 'valid')\n        complexity_factor (int/float):\n            Use int(N * sqrt(complexity_factor)) number of filters in each\n            convolution layer instead of default N.\n        l2_reg (float in [0, 1])\n            L2 regularization on conv weights\n        data_per_prediction (int):\n            TODO\n        build (bool):\n            TODO\n        \"\"\"", "\n", "# Set various attributes", "\n", "assert", "len", "(", "batch_shape", ")", "==", "4", "\n", "self", ".", "n_periods", "=", "batch_shape", "[", "1", "]", "\n", "self", ".", "input_dims", "=", "batch_shape", "[", "2", "]", "\n", "self", ".", "n_channels", "=", "batch_shape", "[", "3", "]", "\n", "self", ".", "n_classes", "=", "int", "(", "n_classes", ")", "\n", "self", ".", "dilation", "=", "int", "(", "dilation", ")", "\n", "self", ".", "cf", "=", "np", ".", "sqrt", "(", "complexity_factor", ")", "\n", "self", ".", "init_filters", "=", "init_filters", "\n", "self", ".", "kernel_size", "=", "int", "(", "kernel_size", ")", "\n", "self", ".", "transition_window", "=", "transition_window", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "kernel_initializer", "=", "kernel_initializer", "\n", "self", ".", "bias_initializer", "=", "bias_initializer", "\n", "self", ".", "l2_reg", "=", "l2_reg", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "padding", "=", "padding", ".", "lower", "(", ")", "\n", "if", "self", ".", "padding", "!=", "\"same\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently, must use 'same' padding.\"", ")", "\n", "\n", "", "self", ".", "dense_classifier_activation", "=", "dense_classifier_activation", "\n", "self", ".", "data_per_prediction", "=", "data_per_prediction", "or", "self", ".", "input_dims", "\n", "if", "not", "isinstance", "(", "self", ".", "data_per_prediction", ",", "(", "int", ",", "np", ".", "integer", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"data_per_prediction must be an integer value\"", ")", "\n", "", "if", "self", ".", "input_dims", "%", "self", ".", "data_per_prediction", ":", "\n", "            ", "raise", "ValueError", "(", "\"'input_dims' ({}) must be evenly divisible by \"", "\n", "\"'data_per_prediction' ({})\"", ".", "format", "(", "self", ".", "input_dims", ",", "\n", "self", ".", "data_per_prediction", ")", ")", "\n", "\n", "# Build model and init base keras Model class", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "self", ".", "init_model", "(", "name_prefix", "=", "name", ")", ")", "\n", "\n", "# Compute receptive field", "\n", "ind", "=", "[", "x", ".", "__class__", ".", "__name__", "for", "x", "in", "self", ".", "layers", "]", ".", "index", "(", "\"UpSampling2D\"", ")", "\n", "self", ".", "receptive_field", "=", "compute_receptive_fields", "(", "self", ".", "layers", "[", ":", "ind", "]", ")", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "# Log the model definition", "\n", "if", "not", "no_log", ":", "\n", "            ", "self", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_encoder": [[202, 243], ["range", "residual_connections.append", "int", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "usleep.PadEndToEvenLength", "tensorflow.keras.layers.MaxPooling2D", "int", "int", "numpy.sqrt"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "create_encoder", "(", "in_", ",", "\n", "depth", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "activation", ",", "\n", "dilation", ",", "\n", "padding", ",", "\n", "complexity_factor", ",", "\n", "regularizer", "=", "None", ",", "\n", "name", "=", "\"encoder\"", ",", "\n", "name_prefix", "=", "\"\"", ",", "\n", "**", "other_conv_params", ")", ":", "\n", "        ", "name", "=", "\"{}{}\"", ".", "format", "(", "name_prefix", ",", "name", ")", "\n", "residual_connections", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "l_name", "=", "name", "+", "\"_L%i\"", "%", "i", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "dilation", ",", "\n", "name", "=", "l_name", "+", "\"_conv1\"", ",", "**", "other_conv_params", ")", "(", "in_", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "bn", "=", "PadEndToEvenLength", "(", "name", "=", "l_name", "+", "\"_padding\"", ")", "(", "bn", ")", "\n", "in_", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "1", ")", ",", "name", "=", "l_name", "+", "\"_pool\"", ")", "(", "bn", ")", "\n", "\n", "# add bn layer to list for residual conn.", "\n", "residual_connections", ".", "append", "(", "bn", ")", "\n", "filters", "=", "int", "(", "filters", "*", "np", ".", "sqrt", "(", "2", ")", ")", "\n", "\n", "# Bottom", "\n", "", "name", "=", "\"{}bottom\"", ".", "format", "(", "name_prefix", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "dilation_rate", "=", "1", ",", "\n", "name", "=", "name", "+", "\"_conv1\"", ",", "**", "other_conv_params", ")", "(", "in_", ")", "\n", "encoded", "=", "BatchNormalization", "(", "name", "=", "name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "return", "encoded", ",", "residual_connections", ",", "filters", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_upsample": [[244, 285], ["range", "int", "numpy.ceil", "tensorflow.keras.layers.UpSampling2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "usleep.CropToMatch", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "int", "int", "numpy.sqrt"], "methods", ["None"], ["", "def", "create_upsample", "(", "self", ",", "\n", "in_", ",", "\n", "res_conns", ",", "\n", "depth", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "activation", ",", "\n", "dilation", ",", "# NOT USED", "\n", "padding", ",", "\n", "complexity_factor", ",", "\n", "regularizer", "=", "None", ",", "\n", "name", "=", "\"upsample\"", ",", "\n", "name_prefix", "=", "\"\"", ",", "\n", "**", "other_conv_params", ")", ":", "\n", "        ", "name", "=", "\"{}{}\"", ".", "format", "(", "name_prefix", ",", "name", ")", "\n", "residual_connections", "=", "res_conns", "[", ":", ":", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "filters", "=", "int", "(", "np", ".", "ceil", "(", "filters", "/", "np", ".", "sqrt", "(", "2", ")", ")", ")", "\n", "l_name", "=", "name", "+", "\"_L%i\"", "%", "i", "\n", "\n", "# Up-sampling block", "\n", "up", "=", "UpSampling2D", "(", "size", "=", "(", "2", ",", "1", ")", ",", "name", "=", "l_name", "+", "\"_up\"", ")", "(", "in_", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "2", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "\n", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "name", "=", "l_name", "+", "\"_conv1\"", ",", "**", "other_conv_params", ")", "(", "up", ")", "\n", "bn", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN1\"", ")", "(", "conv", ")", "\n", "\n", "# Crop and concatenate", "\n", "res_con", "=", "residual_connections", "[", "i", "]", "\n", "cropped_bn", "=", "CropToMatch", "(", "name", "=", "l_name", "+", "\"_crop\"", ")", "(", "[", "bn", ",", "res_con", "]", ")", "\n", "merge", "=", "Concatenate", "(", "axis", "=", "-", "1", ",", "name", "=", "l_name", "+", "\"_concat\"", ")", "(", "[", "res_con", ",", "cropped_bn", "]", ")", "\n", "conv", "=", "Conv2D", "(", "int", "(", "filters", "*", "complexity_factor", ")", ",", "(", "kernel_size", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "padding", "=", "padding", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "name", "=", "l_name", "+", "\"_conv2\"", ",", "**", "other_conv_params", ")", "(", "merge", ")", "\n", "in_", "=", "BatchNormalization", "(", "name", "=", "l_name", "+", "\"_BN2\"", ")", "(", "conv", ")", "\n", "", "return", "in_", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_dense_modeling": [[286, 305], ["tensorflow.keras.layers.Conv2D", "usleep.PadToMatch", "usleep.CropToMatch", "int"], "methods", ["None"], ["", "def", "create_dense_modeling", "(", "self", ",", "\n", "in_", ",", "\n", "in_reshaped", ",", "\n", "filters", ",", "\n", "dense_classifier_activation", ",", "\n", "regularizer", ",", "\n", "complexity_factor", ",", "\n", "name_prefix", "=", "\"\"", ",", "\n", "**", "other_conv_params", ")", ":", "\n", "        ", "cls", "=", "Conv2D", "(", "filters", "=", "int", "(", "filters", "*", "complexity_factor", ")", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "activation", "=", "dense_classifier_activation", ",", "\n", "name", "=", "\"{}dense_classifier_out\"", ".", "format", "(", "name_prefix", ")", ",", "\n", "**", "other_conv_params", ")", "(", "in_", ")", "\n", "cls", "=", "PadToMatch", "(", "name", "=", "\"{}dense_classifier_out_pad\"", ".", "format", "(", "name_prefix", ")", ")", "(", "[", "cls", ",", "in_reshaped", "]", ")", "\n", "cls", "=", "CropToMatch", "(", "name", "=", "\"{}dense_classifier_out_crop\"", ".", "format", "(", "name_prefix", ")", ")", "(", "[", "cls", ",", "in_reshaped", "]", ")", "\n", "return", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_seq_modeling": [[306, 337], ["tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "usleep.OutputReshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_seq_modeling", "(", "in_", ",", "\n", "input_dims", ",", "\n", "data_per_period", ",", "\n", "n_periods", ",", "\n", "n_classes", ",", "\n", "transition_window", ",", "\n", "activation", ",", "\n", "regularizer", "=", "None", ",", "\n", "name_prefix", "=", "\"\"", ",", "\n", "**", "other_conv_params", ")", ":", "\n", "        ", "cls", "=", "AveragePooling2D", "(", "(", "data_per_period", ",", "1", ")", ",", "\n", "name", "=", "\"{}average_pool\"", ".", "format", "(", "name_prefix", ")", ")", "(", "in_", ")", "\n", "out", "=", "Conv2D", "(", "filters", "=", "n_classes", ",", "\n", "kernel_size", "=", "(", "transition_window", ",", "1", ")", ",", "\n", "activation", "=", "activation", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"{}sequence_conv_out_1\"", ".", "format", "(", "name_prefix", ")", ",", "\n", "**", "other_conv_params", ")", "(", "cls", ")", "\n", "out", "=", "Conv2D", "(", "filters", "=", "n_classes", ",", "\n", "kernel_size", "=", "(", "transition_window", ",", "1", ")", ",", "\n", "activation", "=", "\"softmax\"", ",", "\n", "kernel_regularizer", "=", "regularizer", ",", "\n", "bias_regularizer", "=", "regularizer", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"{}sequence_conv_out_2\"", ".", "format", "(", "name_prefix", ")", ",", "\n", "**", "other_conv_params", ")", "(", "out", ")", "\n", "out", "=", "OutputReshape", "(", "n_periods", "=", "n_periods", ",", "name", "=", "\"{}output_reshape\"", ".", "format", "(", "name_prefix", ")", ")", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.init_model": [[338, 404], ["utime.train.utils.get_activation_function", "usleep.USleep.create_encoder", "usleep.USleep.create_upsample", "usleep.USleep.create_dense_modeling", "usleep.USleep.create_seq_modeling", "tensorflow.keras.layers.Input", "usleep.InputReshape", "tensorflow.keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils.get_activation_function", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_encoder", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_upsample", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_dense_modeling", "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.create_seq_modeling"], ["", "def", "init_model", "(", "self", ",", "inputs", "=", "None", ",", "name_prefix", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Build the UNet model with the specified input image shape.\n        \"\"\"", "\n", "seq_length", "=", "self", ".", "n_periods", "*", "self", ".", "input_dims", "if", "self", ".", "n_periods", "else", "None", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "Input", "(", "shape", "=", "[", "self", ".", "n_periods", ",", "self", ".", "input_dims", ",", "self", ".", "n_channels", "]", ")", "\n", "", "inputs_reshaped", "=", "InputReshape", "(", "seq_length", ",", "self", ".", "n_channels", ")", "(", "inputs", ")", "\n", "\n", "# Apply regularization if not None or 0", "\n", "regularizer", "=", "regularizers", ".", "l2", "(", "self", ".", "l2_reg", ")", "if", "self", ".", "l2_reg", "else", "None", "\n", "\n", "# Get activation func from tf or tfa", "\n", "activation", "=", "get_activation_function", "(", "activation_string", "=", "self", ".", "activation", ")", "\n", "\n", "settings", "=", "{", "\n", "\"depth\"", ":", "self", ".", "depth", ",", "\n", "\"filters\"", ":", "self", ".", "init_filters", ",", "\n", "\"kernel_size\"", ":", "self", ".", "kernel_size", ",", "\n", "\"activation\"", ":", "activation", ",", "\n", "\"dilation\"", ":", "self", ".", "dilation", ",", "\n", "\"padding\"", ":", "self", ".", "padding", ",", "\n", "\"regularizer\"", ":", "regularizer", ",", "\n", "\"kernel_initializer\"", ":", "self", ".", "kernel_initializer", ",", "\n", "\"bias_initializer\"", ":", "self", ".", "bias_initializer", ",", "\n", "\"name_prefix\"", ":", "name_prefix", ",", "\n", "\"complexity_factor\"", ":", "self", ".", "cf", "\n", "}", "\n", "\n", "\"\"\"\n        Encoding path\n        \"\"\"", "\n", "enc", ",", "residual_cons", ",", "filters", "=", "self", ".", "create_encoder", "(", "in_", "=", "inputs_reshaped", ",", "\n", "**", "settings", ")", "\n", "\n", "\"\"\"\n        Decoding path\n        \"\"\"", "\n", "settings", "[", "\"filters\"", "]", "=", "filters", "\n", "up", "=", "self", ".", "create_upsample", "(", "enc", ",", "residual_cons", ",", "**", "settings", ")", "\n", "\n", "\"\"\"\n        Dense class modeling layers\n        \"\"\"", "\n", "cls", "=", "self", ".", "create_dense_modeling", "(", "in_", "=", "up", ",", "\n", "in_reshaped", "=", "inputs_reshaped", ",", "\n", "filters", "=", "self", ".", "n_classes", ",", "\n", "dense_classifier_activation", "=", "self", ".", "dense_classifier_activation", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "complexity_factor", "=", "self", ".", "cf", ",", "\n", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "\"\"\"\n        Sequence modeling\n        \"\"\"", "\n", "out", "=", "self", ".", "create_seq_modeling", "(", "in_", "=", "cls", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "data_per_period", "=", "self", ".", "data_per_prediction", ",", "\n", "n_periods", "=", "self", ".", "n_periods", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "transition_window", "=", "self", ".", "transition_window", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "name_prefix", "=", "name_prefix", ")", "\n", "\n", "return", "[", "inputs", "]", ",", "[", "out", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.USleep.log": [[405, 407], ["logger.info", "usleep.USleep.count_params"], "methods", ["None"], ["", "def", "log", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"\\nUSleep Model Summary\\n\"", "\n", "\"--------------------\\n\"", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe": [[24, 29], ["usleep.shape_safe", "tensorflow.shape", "range", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.usleep.shape_safe"], ["def", "shape_safe", "(", "input", ",", "dim", "=", "None", ")", ":", "\n", "    ", "if", "dim", "is", "not", "None", ":", "\n", "        ", "return", "input", ".", "shape", "[", "dim", "]", "or", "tf", ".", "shape", "(", "input", ")", "[", "dim", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "shape_safe", "(", "input", ",", "d", ")", "for", "d", "in", "range", "(", "len", "(", "input", ".", "shape", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model": [[17, 38], ["logger.info", "tensorflow.keras.backend.clear_session"], "function", ["None"], ["def", "init_model", "(", "build_hparams", ",", "clear_previous", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    From a set of hyperparameters 'build_hparams' (dict) initializes the\n    model specified under build_hparams['model_class_name'].\n\n    Typically, this function is not called directly, but used by the\n    higher-level 'initialize_model' function.\n\n    Args:\n        build_hparams:  A dictionary of model build hyperparameters\n        clear_previous: Clear previous tf sessions\n\n    Returns:\n        A tf.keras Model instance\n    \"\"\"", "\n", "if", "clear_previous", ":", "\n", "        ", "tf", ".", "keras", ".", "backend", ".", "clear_session", "(", ")", "\n", "# Build new model of the specified type", "\n", "", "cls_name", "=", "build_hparams", "[", "\"model_class_name\"", "]", "\n", "logger", ".", "info", "(", "f\"Creating new model of type '{cls_name}'\"", ")", "\n", "return", "models", ".", "__dict__", "[", "cls_name", "]", "(", "**", "build_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.load_from_file": [[40, 51], ["model.load_weights", "logger.info"], "function", ["None"], ["", "def", "load_from_file", "(", "model", ",", "file_path", ",", "by_name", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Load parameters from file 'file_path' into model 'model'.\n\n    Args:\n        model:      A tf.keras Model instance\n        file_path:  A path to a parameter file (h5 format typically)\n        by_name:    Load parameters by layer names instead of order (default).\n    \"\"\"", "\n", "model", ".", "load_weights", "(", "file_path", ",", "by_name", "=", "by_name", ")", "\n", "logger", ".", "info", "(", "f\"Loading parameters from: {file_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_and_load_model": [[53, 70], ["model_init.init_model", "model_init.load_from_file"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.load_from_file"], ["", "def", "init_and_load_model", "(", "hparams", ",", "weights_file", ",", "clear_previous", "=", "False", ",", "by_name", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Initializes a model according to hparams. Then sets its parameters from\n    the parameters in h5 file 'weights_file'.\n\n    Args:\n        hparams:        A YAMLHparams object of hyperparameters\n        weights_file:   A path to a h5 parameter file to load\n        clear_previous: Clear previous keras session before initializing new model graph.\n        by_name:        Load parameters by layer names instead of order (default).\n\n    Returns:\n        A tf.keras Model instance\n    \"\"\"", "\n", "model", "=", "init_model", "(", "build_hparams", "=", "hparams", "[", "\"build\"", "]", ",", "clear_previous", "=", "clear_previous", ")", "\n", "load_from_file", "(", "model", ",", "weights_file", ",", "by_name", "=", "by_name", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_and_load_best_model": [[72, 92], ["model_init.init_model", "utime.models.utils.get_best_model", "model_init.load_from_file", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.get_best_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.load_from_file"], ["", "def", "init_and_load_best_model", "(", "hparams", ",", "model_dir", ",", "clear_previous", "=", "False", ",", "by_name", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Initializes a model according to hparams. Then finds the best model in\n    model_dir and loads it (see utime.utils.get_best_model).\n\n    Args:\n        hparams:        A YAMLHparams object of hyperparameters\n        model_dir:      A path to the directory that stores model param files\n        clear_previous: Clear previous keras session before initializing new model graph.\n        by_name:        Load parameters by layer names instead of order (default).\n\n    Returns:\n        A tf.keras Model instance\n        The file name of the parameter file that was loaded\n    \"\"\"", "\n", "model", "=", "init_model", "(", "hparams", "[", "\"build\"", "]", ",", "clear_previous", "=", "clear_previous", ")", "\n", "model_path", "=", "get_best_model", "(", "model_dir", ")", "\n", "load_from_file", "(", "model", ",", "model_path", ",", "by_name", "=", "by_name", ")", "\n", "model_file_name", "=", "os", ".", "path", ".", "split", "(", "model_path", ")", "[", "-", "1", "]", "\n", "return", "model", ",", "model_file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_and_load_latest_model": [[94, 118], ["model_init.init_model", "utime.models.utils.get_last_model", "model_init.load_from_file", "OSError", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.init_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.get_last_model", "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.load_from_file"], ["", "def", "init_and_load_latest_model", "(", "hparams", ",", "model_dir", ",", "clear_previous", "=", "False", ",", "by_name", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Initializes a model according to hparams. Then finds the latest model in\n    model_dir and loads it (see utime.utils.get_latest_model).\n\n    Args:\n        hparams:        A YAMLHparams object of hyperparameters\n        model_dir:      A path to the directory that stores model param files\n        clear_previous: Clear previous keras session before initializing new model graph.\n        by_name:        Load parameters by layer names instead of order (default).\n\n    Returns:\n        A tf.keras Model instance\n        The file name of the parameter file that was loaded\n        The epoch of training that the file corresponds to\n    \"\"\"", "\n", "model", "=", "init_model", "(", "hparams", "[", "\"build\"", "]", ",", "clear_previous", "=", "clear_previous", ")", "\n", "model_path", ",", "epoch", "=", "get_last_model", "(", "model_dir", ")", "\n", "if", "model_path", "is", "None", ":", "\n", "        ", "raise", "OSError", "(", "\"Did not find any model files in \"", "\n", "\"directory {}\"", ".", "format", "(", "model_dir", ")", ")", "\n", "", "load_from_file", "(", "model", ",", "model_path", ",", "by_name", "=", "by_name", ")", "\n", "model_file_name", "=", "os", ".", "path", ".", "split", "(", "model_path", ")", "[", "-", "1", "]", "\n", "return", "model", ",", "model_file_name", ",", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.model_init.prepare_for_continued_training": [[120, 169], ["utime.models.utils.get_last_model", "os.path.join", "utime.utils.scriptutils.train.get_lr_at_epoch", "logger.info", "os.path.join", "utime.utils.scriptutils.train.get_last_epoch", "utime.utils.scriptutils.train.clear_csv_after_epoch", "os.path.join", "os.path.split"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.models.utils.get_last_model", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_lr_at_epoch", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.get_last_epoch", "home.repos.pwc.inspect_result.perslev_U-Time.scriptutils.train.clear_csv_after_epoch"], ["", "def", "prepare_for_continued_training", "(", "hparams", ",", "project_dir", ")", ":", "\n", "    ", "\"\"\"\n    Prepares the hyperparameter set and project directory for continued\n    training.\n\n    Will find the latest model (highest epoch number) of parameter files in\n    the 'model' subdir of 'project_dir' and base the continued training on this\n    file. If no file is found, training will start from scratch as\n    normally (note: no error is raised, but None is returned instead of a path\n    to a parameter file).\n\n    The hparams['fit']['init_epoch'] parameter will be set to match the found\n    parameter file or to 0 if no file was found. Note that if init_epoch is set\n    to 0 all rows in the training.csv file will be deleted.\n\n    The hparams['fit']['optimizer_kwargs']['learning_rate'] parameter will\n    be set according to the value stored in the project_dir/logs/training.csv\n    file at the corresponding epoch (left default if no init_epoch was found)\n\n    Args:\n        hparams:      (YAMLHParams) The hyperparameters to use for training\n        project_dir:  (string)      The path to the current project directory\n\n    Returns:\n        A path to the model weight files to use for continued training.\n        Will be None if no model files were found\n    \"\"\"", "\n", "model_path", ",", "epoch", "=", "get_last_model", "(", "os", ".", "path", ".", "join", "(", "project_dir", ",", "\"model\"", ")", ")", "\n", "if", "model_path", ":", "\n", "        ", "model_name", "=", "os", ".", "path", ".", "split", "(", "model_path", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "model_name", "=", "None", "\n", "", "csv_path", "=", "os", ".", "path", ".", "join", "(", "project_dir", ",", "\"logs\"", ",", "\"training.csv\"", ")", "\n", "if", "epoch", "==", "0", ":", "\n", "        ", "epoch", "=", "get_last_epoch", "(", "csv_path", ")", "\n", "", "else", ":", "\n", "        ", "if", "epoch", "is", "None", ":", "\n", "            ", "epoch", "=", "0", "\n", "", "clear_csv_after_epoch", "(", "epoch", ",", "csv_path", ")", "\n", "", "hparams", "[", "\"fit\"", "]", "[", "\"init_epoch\"", "]", "=", "epoch", "+", "1", "\n", "# Get the LR at the continued epoch", "\n", "lr", ",", "name", "=", "get_lr_at_epoch", "(", "epoch", ",", "os", ".", "path", ".", "join", "(", "project_dir", ",", "\"logs\"", ")", ")", "\n", "if", "lr", ":", "\n", "        ", "hparams", "[", "\"fit\"", "]", "[", "\"optimizer_kwargs\"", "]", "[", "name", "]", "=", "lr", "\n", "", "logger", ".", "info", "(", "f\"[NOTICE] Training continues from:\\n\"", "\n", "f\"Model: {model_name or '<No model found - Starting for scratch!>'}\\n\"", "\n", "f\"Epoch: {epoch}\\n\"", "\n", "f\"LR:    {lr}\"", ")", "\n", "return", "model_path", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.standardize_batch_shape": [[12, 24], ["list", "len", "len", "len", "len", "ValueError"], "function", ["None"], ["        ", "try", ":", "\n", "            ", "make_func", "(", "path", ")", "\n", "", "except", "FileExistsError", ":", "\n", "# If running many jobs in parallel this may occur", "\n", "            ", "pass", "\n", "", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.get_best_model": [[28, 51], ["os.path.abspath", "len", "OSError", "glob.glob", "os.path.join", "os.path.exists", "OSError", "os.listdir", "os.path.join", "os.path.abspath", "scores.append", "float", "select_func", "re.findall", "numpy.array"], "function", ["None"], ["\n", "\n", "", "", "", "", "def", "flatten_lists_recursively", "(", "list_of_lists", ")", ":", "\n", "    ", "for", "list_", "in", "list_of_lists", ":", "\n", "        ", "if", "isinstance", "(", "list_", ",", "Iterable", ")", "and", "not", "isinstance", "(", "list_", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n", "\n", "", "", "", "def", "highlighted", "(", "string", ")", ":", "\n", "    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n", "\n", "", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "if", "isinstance", "(", "pids", ",", "str", ")", ":", "\n", "        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.get_last_model": [[53, 71], ["glob.glob", "os.path.join", "epochs.append", "numpy.argmax", "os.path.join", "os.path.exists", "int", "os.path.abspath", "int", "re.findall", "int"], "function", ["None"], ["    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n", "if", "not", "pid", ":", "\n", "        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pid", "=", "int", "(", "pid", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n", "", "", "_wait_for", "(", "pid", ",", "check_every", ")", "\n", "\n", "\n", "", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "still_running", "=", "True", "\n", "logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.models.utils.save_frozen_model": [[73, 83], ["tensorflow.function", "tensorflow.python.framework.convert_to_constants.convert_variables_to_constants_v2", "tensorflow.io.write_graph", "len", "len", "tf.function.get_concrete_function", "tensorflow.TensorSpec"], "function", ["None"], ["            ", "output", "=", "subprocess", ".", "check_output", "(", "(", "\"grep\"", ",", "f\"{pid}\"", ")", ",", "stdin", "=", "ps", ".", "stdout", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "output", "=", "False", "\n", "", "ps", ".", "wait", "(", ")", "\n", "still_running", "=", "bool", "(", "output", ")", "\n", "if", "still_running", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Process {pid} still running... (sleeping {check_every} seconds)\"", ")", "\n", "time", ".", "sleep", "(", "check_every", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__.YAMLHParams.__init__": [[83, 88], ["yamlhparams.YAMLHParams.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], []], "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_channel_sampling_group_renaming": [[9, 25], ["hparams.get", "logger.warning", "hparams.delete_group", "hparams.set_group", "hparams.save_current"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_metrics_renaming": [[27, 53], ["hparams.get_group", "enumerate", "psg_utils.utils.ensure_list_or_tuple", "hparams.set_group", "hparams.save_current", "logger.warning"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_version_format_changes": [[55, 65], ["hparams.get", "logger.warning"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__.check_deprecated_params": [[72, 76], ["__init__._handle_channel_sampling_group_renaming", "__init__._handle_metrics_renaming", "__init__._handle_version_format_changes"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_channel_sampling_group_renaming", "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_metrics_renaming", "home.repos.pwc.inspect_result.perslev_U-Time.hyperparameters.__init__._handle_version_format_changes"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.__init__": [[23, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model:      (tf.keras Model) Initialized model to train\n        \"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.compile_model": [[30, 69], ["psg_utils.utils.ensure_list_or_tuple", "psg_utils.utils.ensure_list_or_tuple", "utime.train.utils.init_optimizer", "utime.train.utils.init_losses", "utime.train.utils.init_metrics", "trainer.Trainer.model.compile", "logger.info", "utime.train.utils.ensure_sparse"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_optimizer", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_losses", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_metrics", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.ensure_sparse"], ["", "def", "compile_model", "(", "self", ",", "optimizer", ",", "loss", ",", "metrics", ",", "reduction", ",", "\n", "ignore_out_of_bounds_classes", "=", "False", ",", "check_sparse", "=", "False", ",", "\n", "optimizer_kwargs", "=", "{", "}", ",", "loss_kwargs", "=", "{", "}", ",", "metric_kwargs", "=", "{", "}", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compile the stored tf.keras Model instance stored in self.model\n        Sets the loss function, optimizer and metrics\n\n        Args:\n            optimizer:        (string) The name of a tf.keras.optimizers Optimizer\n            loss:             (string) The name of a tf.keras.losses or\n            metrics:          (list)   List of tf.keras.metrics or\n                                       MultiPlanarUNet metrics.\n            reduction:                          TODO\n            check_sparse:                       TODO\n            ignore_out_of_bounds_classes (bool) TODO\n            optimizer_kwargs: (dict)   Key-word arguments passed to the Optimizer\n            loss_kwargs:      (dict)   Key-word arguments passed to all Loss functions\n            metric_kwargs:    (dict)   Key-word arguments passed to all Metrics functions\n                                       MultiPlanarUnet loss function\n            **kwargs:         (dict)   Key-word arguments passed to losses\n                                       and/or metrics that accept such.\n        \"\"\"", "\n", "# Make sure sparse metrics and loss are specified as sparse", "\n", "metrics", "=", "ensure_list_or_tuple", "(", "metrics", ")", "\n", "losses", "=", "ensure_list_or_tuple", "(", "loss", ")", "\n", "if", "check_sparse", ":", "\n", "            ", "ensure_sparse", "(", "metrics", "+", "losses", ")", "\n", "\n", "# Initialize optimizer, loss(es) and metric(s) from tf.keras, tf addons or utime.evaluation", "\n", "", "optimizer", "=", "init_optimizer", "(", "optimizer", ",", "**", "optimizer_kwargs", ")", "\n", "losses", "=", "init_losses", "(", "losses", ",", "reduction", ",", "ignore_out_of_bounds_classes", ",", "**", "loss_kwargs", ")", "\n", "metrics", "=", "init_metrics", "(", "metrics", ",", "ignore_out_of_bounds_classes", ",", "**", "metric_kwargs", ")", "\n", "\n", "# Compile the model", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "losses", ",", "metrics", "=", "metrics", ")", "\n", "logger", ".", "info", "(", "f\"\\nOptimizer:   {optimizer}\\n\"", "\n", "f\"Loss funcs:  {losses}\\n\"", "\n", "f\"Metrics:     {metrics}\"", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.fit": [[70, 105], ["logger.info", "trainer.Trainer._fit", "logger.error", "logger.exception", "logger.error", "str"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer._fit"], ["", "def", "fit", "(", "self", ",", "batch_size", ",", "**", "fit_kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Fit the stored tf.keras Model (self.model) on a set of data.\n\n        The 'fit' method is a wrapper around the hidden '_fit' method. It\n        handles KeyboardInterrupts (--> stopping training prematurely), TF\n        GPU memory errors (--> batch_size is reduced by 2 and training\n        restarted), and other exceptions (--> error logged and training\n        terminated).\n\n        Please refer to the self._fit method for 'fit_kwargs' argument details.\n\n        Args:\n            batch_size: (int)  The initial batch size to run training with\n            fit_kwargs: (dict) Keyword arguments passed to self._fit\n        \"\"\"", "\n", "fitting", "=", "True", "\n", "while", "fitting", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_fit", "(", "batch_size", "=", "batch_size", ",", "**", "fit_kwargs", ")", "\n", "fitting", "=", "False", "\n", "", "except", "(", "ResourceExhaustedError", ",", "InternalError", ")", ":", "\n", "# Reduce batch size", "\n", "                ", "batch_size", "-=", "2", "\n", "logger", ".", "error", "(", "f\"[MEMORY ERROR] Reducing batch size by 2 (now {batch_size})\"", ")", "\n", "if", "batch_size", "<", "1", ":", "\n", "                    ", "logger", ".", "error", "(", "\"[ERROR] Batch size negative or zero! Stopping training.\"", ")", "\n", "fitting", "=", "False", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "fitting", "=", "False", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "logger", ".", "exception", "(", "str", "(", "e", ")", ",", "exc_info", "=", "e", ")", "\n", "raise", "e", "\n", "", "", "logger", ".", "info", "(", "\"Training stopped.\"", ")", "\n", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer._fit": [[106, 175], ["utime.train.utils.get_steps", "logger.info", "callbacks.append", "utime.callbacks.init_callback_objects", "list", "tensorflow.data.Dataset.from_generator", "tensorflow.data.Options", "train.with_options.with_options.with_options", "trainer.Trainer.model.fit", "utime.callbacks.remove_validation_callbacks", "utime.callbacks.LearningCurve", "zip", "utime.callbacks.PrintDividerLine", "utime.callbacks.Validation", "utime.callbacks.MeanReduceLogArrays", "utime.callbacks.PrintDividerLine", "map"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils.get_steps", "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.utils.init_callback_objects", "home.repos.pwc.inspect_result.perslev_U-Time.train.trainer.Trainer.fit", "home.repos.pwc.inspect_result.perslev_U-Time.callbacks.utils.remove_validation_callbacks"], ["", "def", "_fit", "(", "self", ",", "\n", "train", ",", "\n", "val", ",", "\n", "batch_size", ",", "\n", "n_epochs", ",", "\n", "callbacks", ",", "\n", "train_samples_per_epoch", ",", "\n", "max_val_studies_per_dataset", ",", "\n", "verbose", "=", "1", ",", "\n", "init_epoch", "=", "0", ",", "\n", "**", "unused", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            train: (Sequence)       The training Sequence object\n            val    (Sequence, None) The validation Sequence object or None if no\n                                    validation is to be performed\n            batch_size: (int)       The batch size to use for training\n            n_epochs: (int)         Number of epochs to train for\n            callbacks: (list)       List of uninitialized callback kwargs.\n            train_samples_per_epoch: (int) Number of training samples to sample\n                                           before an epoch is determined over.\n            verbose: (int/bool)     Verbosity level passed to keras.fit_generator\n            init_epoch: (int)       The initial epoch\n            use_multiprocessing: (bool) Whether to use multiprocessing instead\n                                        of multithreading.\n        \"\"\"", "\n", "train", ".", "batch_size", "=", "batch_size", "\n", "train_steps", "=", "get_steps", "(", "train_samples_per_epoch", ",", "train", ")", "\n", "logger", ".", "info", "(", "f\"Using {train_steps} steps per train epoch\"", ")", "\n", "\n", "if", "val", "is", "None", ":", "\n", "# No validation to be performed, remove callbacks that might need", "\n", "# validation data to function properly", "\n", "            ", "remove_validation_callbacks", "(", "callbacks", ")", "\n", "", "else", ":", "\n", "            ", "val", ".", "batch_size", "=", "batch_size", "\n", "# Add validation callback", "\n", "# Important: Should be first in callbacks list as other CBs may", "\n", "# depend on the validation metrics/loss", "\n", "callbacks", "=", "[", "Validation", "(", "val", ",", "max_val_studies_per_dataset", ")", ",", "MeanReduceLogArrays", "(", ")", "]", "+", "callbacks", "\n", "\n", "# Add various callbacks for plotting learning curves etc.", "\n", "", "callbacks", ".", "append", "(", "LearningCurve", "(", ")", ")", "\n", "# callbacks.append(MemoryConsumption(max_gib=45))", "\n", "# callbacks.append(CarbonUsageTracking(epochs=n_epochs, add_to_logs=False))", "\n", "\n", "# Get initialized callback objects", "\n", "callbacks", "=", "[", "PrintDividerLine", "(", ")", "]", "+", "callbacks", "+", "[", "PrintDividerLine", "(", ")", "]", "\n", "callbacks", ",", "cb_dict", "=", "init_callback_objects", "(", "callbacks", ")", "\n", "\n", "# Wrap generator in TF Dataset and disable auto shard", "\n", "dtypes", ",", "shapes", "=", "list", "(", "zip", "(", "*", "map", "(", "lambda", "x", ":", "(", "x", ".", "dtype", ",", "x", ".", "shape", ")", ",", "train", "[", "0", "]", ")", ")", ")", "\n", "train", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "train", ",", "dtypes", ",", "shapes", ")", "\n", "options", "=", "tf", ".", "data", ".", "Options", "(", ")", "\n", "options", ".", "experimental_distribute", ".", "auto_shard_policy", "=", "tf", ".", "data", ".", "experimental", ".", "AutoShardPolicy", ".", "OFF", "\n", "train", "=", "train", ".", "with_options", "(", "options", ")", "\n", "\n", "# Fit the model", "\n", "self", ".", "model", ".", "fit", "(", "\n", "train", ",", "\n", "steps_per_epoch", "=", "train_steps", ",", "\n", "epochs", "=", "n_epochs", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "initial_epoch", "=", "init_epoch", ",", "\n", "use_multiprocessing", "=", "False", ",", "\n", "workers", "=", "3", ",", "\n", "max_queue_size", "=", "10", ",", "\n", "shuffle", "=", "False", ",", "# Determined by the chosen Sequence class", "\n", "verbose", "=", "verbose", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.ensure_sparse": [[17, 27], ["enumerate", "m.lower", "utime.errors.NotSparseError"], "function", ["None"], ["", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f", ")", ":", "\n", "                ", "safe_make", "(", "f", ",", "make_func", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._get_classes_or_funcs": [[33, 63], ["psg_utils.utils.ensure_list_or_tuple", "psg_utils.utils.ensure_list_or_tuple", "getattr", "AttributeError", "logger.info", "functions_or_classes.append"], "function", ["None"], ["            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n", "\n", "", "", "", "def", "highlighted", "(", "string", ")", ":", "\n", "    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n", "\n", "", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "if", "isinstance", "(", "pids", ",", "str", ")", ":", "\n", "        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n", "\n", "", "", "def", "wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n", "if", "not", "pid", ":", "\n", "        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pid", "=", "int", "(", "pid", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._assert_all_classes": [[65, 74], ["psg_utils.utils.ensure_list_or_tuple", "TypeError", "isinstance", "issubclass", "tensorflow_addons.losses", "tensorflow_addons.metrics"], "function", ["None"], ["\n", "\n", "", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "still_running", "=", "True", "\n", "logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "try", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "(", "\"grep\"", ",", "f\"{pid}\"", ")", ",", "stdin", "=", "ps", ".", "stdout", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._init_losses_or_metrics": [[82, 115], ["enumerate", "utime.evaluation.utils.ignore_out_of_bounds_classes_wrapper.", "utime.evaluation.utils.ignore_out_of_bounds_classes_wrapper", "setattr", "utime.evaluation.utils.ignore_out_of_bounds_classes_wrapper", "str", "TypeError", "hasattr", "AttributeError", "getattr", "tensorflow_addons.losses", "tensorflow_addons.metrics"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.ignore_out_of_bounds_classes_wrapper", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.ignore_out_of_bounds_classes_wrapper"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_losses": [[117, 149], ["utils._get_classes_or_funcs", "utils._assert_all_classes", "utils._init_losses_or_metrics"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils._get_classes_or_funcs", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._assert_all_classes", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._init_losses_or_metrics"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_metrics": [[151, 164], ["utils._get_classes_or_funcs", "utils._assert_all_classes", "utils._init_losses_or_metrics"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils._get_classes_or_funcs", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._assert_all_classes", "home.repos.pwc.inspect_result.perslev_U-Time.train.utils._init_losses_or_metrics"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.init_optimizer": [[166, 177], ["utils._get_classes_or_funcs", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils._get_classes_or_funcs"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.get_activation_function": [[179, 190], ["utils._get_classes_or_funcs", "len", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.train.utils._get_classes_or_funcs"], []], "home.repos.pwc.inspect_result.perslev_U-Time.train.utils.get_steps": [[192, 216], ["int", "len", "numpy.ceil"], "function", ["None"], []], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.get_eval_df": [[8, 12], ["pandas.DataFrame", "sequencer.get_pairs", "range"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.sequences.base_sequence.BaseSequence.get_pairs"], ["def", "get_eval_df", "(", "sequencer", ")", ":", "\n", "    ", "ids", "=", "[", "ss", ".", "identifier", "for", "ss", "in", "sequencer", ".", "get_pairs", "(", ")", "]", "\n", "classes", "=", "[", "\"mean\"", "]", "+", "[", "\"cls {}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "sequencer", ".", "n_classes", ")", "]", "\n", "return", "pd", ".", "DataFrame", "(", "columns", "=", "ids", ",", "index", "=", "classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.add_to_eval_df": [[14, 18], ["numpy.nanmean", "list"], "function", ["None"], ["", "def", "add_to_eval_df", "(", "eval_dict", ",", "id_", ",", "values", ")", ":", "\n", "    ", "mean", "=", "np", ".", "nanmean", "(", "values", ")", "\n", "values", "=", "[", "mean", "]", "+", "list", "(", "values", ")", "\n", "eval_dict", "[", "id_", "]", "=", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.with_grand_mean_col": [[20, 26], ["numpy.mean", "list", "list.append", "list.pop", "list.index"], "function", ["None"], ["", "def", "with_grand_mean_col", "(", "eval_dict", ",", "col_name", "=", "\"Grand mean\"", ")", ":", "\n", "    ", "means", "=", "np", ".", "mean", "(", "eval_dict", ",", "axis", "=", "1", ")", "\n", "eval_dict", "[", "col_name", "]", "=", "means", "\n", "cols", "=", "list", "(", "eval_dict", ".", "columns", ")", "\n", "cols", ".", "append", "(", "cols", ".", "pop", "(", "cols", ".", "index", "(", "col_name", ")", ")", ")", "\n", "return", "eval_dict", ".", "loc", "[", ":", ",", "cols", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df_to_screen": [[28, 32], ["logger.info", "len", "str", "eval_dict.round", "len"], "function", ["None"], ["", "def", "log_eval_df_to_screen", "(", "eval_dict", ",", "round", "=", "4", ",", "txt", "=", "None", ")", ":", "\n", "    ", "log", "=", "f\"\\n[*] {txt or 'EVALUATION RESULTS'}\"", "\n", "logger", ".", "info", "(", "\n", "log", "+", "\"\\n\"", "+", "\"-\"", "*", "len", "(", "log", ")", "+", "\"\\n\"", "+", "str", "(", "eval_dict", ".", "round", "(", "round", ")", ")", "+", "\"\\n\"", "+", "\"-\"", "*", "len", "(", "log", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df_to_file": [[35, 42], ["open", "out_csv.write", "open", "out_txt.write", "eval_dict.to_csv", "eval_dict.round().to_string", "eval_dict.round"], "function", ["None"], ["", "def", "log_eval_df_to_file", "(", "eval_dict", ",", "out_csv_file", "=", "None", ",", "out_txt_file", "=", "None", ",", "round", "=", "4", ")", ":", "\n", "    ", "if", "out_csv_file", ":", "\n", "        ", "with", "open", "(", "out_csv_file", ",", "\"w+\"", ")", "as", "out_csv", ":", "\n", "            ", "out_csv", ".", "write", "(", "eval_dict", ".", "to_csv", "(", ")", ")", "\n", "", "", "if", "out_txt_file", ":", "\n", "        ", "with", "open", "(", "out_txt_file", ",", "\"w+\"", ")", "as", "out_txt", ":", "\n", "            ", "out_txt", ".", "write", "(", "eval_dict", ".", "round", "(", "round", ")", ".", "to_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df": [[44, 47], ["dataframe.log_eval_df_to_screen", "dataframe.log_eval_df_to_file"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df_to_screen", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.dataframe.log_eval_df_to_file"], ["", "", "", "def", "log_eval_df", "(", "eval_dict", ",", "out_csv_file", "=", "None", ",", "out_txt_file", "=", "None", ",", "round", "=", "4", ",", "txt", "=", "None", ")", ":", "\n", "    ", "log_eval_df_to_screen", "(", "eval_dict", ",", "round", ",", "txt", ")", "\n", "log_eval_df_to_file", "(", "eval_dict", ",", "out_csv_file", ",", "out_txt_file", ",", "round", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.get_hypnogram": [[9, 36], ["numpy.arange", "plt.figure.suptitle", "fig.add_subplot.step", "plotting.get_hypnogram.format_ax"], "function", ["None"], ["\n", "\n", "def", "plot_all_training_curves", "(", "glob_path", ",", "out_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "paths", "=", "glob", "(", "glob_path", ")", "\n", "if", "not", "paths", ":", "\n", "        ", "raise", "OSError", "(", "f\"File pattern {glob_path} gave no matches matches '({paths})'\"", ")", "\n", "", "out_folder", "=", "os", ".", "path", ".", "split", "(", "out_path", ")", "[", "0", "]", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "len", "(", "paths", ")", ">", "1", ":", "\n", "# Set unique names", "\n", "            ", "uniq", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "p", ")", "[", "-", "1", "]", ")", "[", "0", "]", "\n", "f_name", "=", "uniq", "+", "\"_\"", "+", "os", ".", "path", ".", "split", "(", "out_path", ")", "[", "-", "1", "]", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "out_folder", ",", "f_name", ")", "\n", "", "else", ":", "\n", "            ", "save_path", "=", "out_path", "\n", "", "plot_training_curves", "(", "p", ",", "save_path", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "def", "plot_training_curves", "(", "csv_path", ",", "save_path", ",", "logy", "=", "False", ",", "\n", "exclude", "=", "(", "\"learning_rate\"", ",", "\"epoch\"", ",", "\"loss\"", ",", "\n", "\"epoch_minutes\"", ",", "\"train_hours\"", ",", "\n", "'memory_usage_gib'", ")", ",", "\n", "include_regex", "=", "None", ")", ":", "\n", "# Read CSV file", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "# Prepare plot", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "12", ")", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_and_save_hypnogram": [[38, 45], ["plotting.get_hypnogram", "outs[].savefig", "matplotlib.close", "os.path.split", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.get_hypnogram"], ["\n", "# Get epoch, training and validation loss vectors", "\n", "epochs", "=", "df", "[", "\"epoch\"", "]", "+", "1", "\n", "train_loss", "=", "df", "[", "\"loss\"", "]", "\n", "val_loss", "=", "df", ".", "get", "(", "\"val_loss\"", ")", "\n", "\n", "if", "logy", ":", "\n", "        ", "train_loss", "=", "np", ".", "log10", "(", "train_loss", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_confusion_matrix": [[47, 101], ["numpy.arange", "confusion_matrix", "matplotlib.subplots", "ax.imshow", "ax.figure.colorbar", "ax.set", "matplotlib.setp", "range", "fig.tight_layout", "ax.get_xticklabels", "confusion_matrix.max", "range", "unique_labels", "confusion_matrix.astype", "Defaults.get_class_int_to_stage_string", "matplotlib.get_cmap", "numpy.arange", "numpy.arange", "ax.text", "confusion_matrix.sum", "format"], "function", ["None"], ["            ", "val_loss", "=", "np", ".", "log10", "(", "val_loss", ")", "\n", "\n", "# Plot", "\n", "", "", "ax1", ".", "plot", "(", "epochs", ",", "train_loss", ",", "lw", "=", "3", ",", "color", "=", "\"darkblue\"", ",", "label", "=", "\"Training loss\"", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "        ", "ax1", ".", "plot", "(", "epochs", ",", "val_loss", ",", "lw", "=", "3", ",", "color", "=", "\"darkred\"", ",", "label", "=", "\"Validation loss\"", ")", "\n", "\n", "# Add legend, labels and title", "\n", "", "leg", "=", "ax1", ".", "legend", "(", "loc", "=", "0", ")", "\n", "leg", ".", "get_frame", "(", ")", ".", "set_linewidth", "(", "0", ")", "\n", "ax1", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax1", ".", "set_ylabel", "(", "\"Loss\"", "if", "not", "logy", "else", "\"$\\log_{10}$(Loss)\"", ",", "size", "=", "16", ")", "\n", "ax1", ".", "set_title", "(", "\"Training %sloss\"", "%", "(", "\"and validation \"", "if", "val_loss", "is", "not", "None", "else", "\"\"", ")", ",", "size", "=", "20", ")", "\n", "\n", "# Make second plot", "\n", "ax2", "=", "fig", ".", "add_subplot", "(", "312", ")", "\n", "\n", "# Get all other columns, optionally only if matching 'include_regex'", "\n", "import", "re", "\n", "include_regex", "=", "re", ".", "compile", "(", "include_regex", "or", "\".*\"", ")", "\n", "\n", "plotted", "=", "0", "\n", "for", "col", "in", "df", ".", "columns", ":", "\n", "        ", "if", "any", "(", "[", "s", "in", "col", "for", "s", "in", "exclude", "[", "1", ":", "]", "]", ")", "or", "col", "==", "\"lr\"", ":", "\n", "            ", "continue", "\n", "", "elif", "not", "re", ".", "match", "(", "include_regex", ",", "col", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "plotted", "+=", "1", "\n", "ax2", ".", "plot", "(", "epochs", ",", "df", "[", "col", "]", ",", "label", "=", "col", ",", "lw", "=", "2", ")", "\n", "\n", "# Add legend, labels and title", "\n", "", "", "if", "plotted", "<=", "8", ":", "\n", "# Otherwise it takes up all the space", "\n", "        ", "leg", "=", "ax2", ".", "legend", "(", "loc", "=", "0", ",", "ncol", "=", "int", "(", "np", ".", "ceil", "(", "plotted", "/", "5", ")", ")", ")", "\n", "leg", ".", "get_frame", "(", ")", ".", "set_linewidth", "(", "0", ")", "\n", "", "ax2", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax2", ".", "set_ylabel", "(", "\"Metric\"", ",", "size", "=", "16", ")", "\n", "ax2", ".", "set_title", "(", "\"Training and validation metrics\"", ",", "size", "=", "20", ")", "\n", "\n", "# Plot learning rate", "\n", "lr", "=", "df", ".", "get", "(", "\"lr\"", ")", "\n", "if", "lr", "is", "None", ":", "\n", "        ", "lr", "=", "df", ".", "get", "(", "\"learning_rate\"", ")", "\n", "", "if", "lr", "is", "not", "None", ":", "\n", "        ", "ax3", "=", "fig", ".", "add_subplot", "(", "313", ")", "\n", "ax3", ".", "step", "(", "epochs", ",", "lr", ")", "\n", "ax3", ".", "set_xlabel", "(", "\"Epoch\"", ",", "size", "=", "16", ")", "\n", "ax3", ".", "set_ylabel", "(", "\"Learning Rate\"", ",", "size", "=", "16", ")", "\n", "ax3", ".", "set_title", "(", "\"Learning Rate\"", ",", "size", "=", "20", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "save_path", ")", "\n", "plt", ".", "close", "(", "fig", ".", "number", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_and_save_cm": [[103, 110], ["plotting.plot_confusion_matrix", "fig.savefig", "matplotlib.close", "os.path.split", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.plotting.plot_confusion_matrix"], []], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.metrics.class_wise_kappa": [[5, 18], ["numpy.empty", "np.empty.fill", "enumerate", "numpy.unique", "numpy.arange", "max", "numpy.any", "numpy.any", "sklearn.metrics.cohen_kappa_score"], "function", ["None"], ["def", "class_wise_kappa", "(", "true", ",", "pred", ",", "n_classes", "=", "None", ")", ":", "\n", "    ", "if", "n_classes", "is", "None", ":", "\n", "        ", "classes", "=", "np", ".", "unique", "(", "true", ")", "\n", "", "else", ":", "\n", "        ", "classes", "=", "np", ".", "arange", "(", "max", "(", "2", ",", "n_classes", ")", ")", "\n", "", "kappa_scores", "=", "np", ".", "empty", "(", "shape", "=", "classes", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "kappa_scores", ".", "fill", "(", "np", ".", "nan", ")", "\n", "for", "idx", ",", "_class", "in", "enumerate", "(", "classes", ")", ":", "\n", "        ", "s1", "=", "true", "==", "_class", "\n", "s2", "=", "pred", "==", "_class", "\n", "if", "np", ".", "any", "(", "s1", ")", "or", "np", ".", "any", "(", "s2", ")", ":", "\n", "            ", "kappa_scores", "[", "idx", "]", "=", "cohen_kappa_score", "(", "s1", ",", "s2", ")", "\n", "", "", "return", "kappa_scores", "\n", "", ""]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__": [[36, 46], ["tensorflow.python.keras.losses.LossFunctionWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.SparseDiceLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "reduction", ",", "\n", "smooth", "=", "1", ",", "\n", "name", "=", "'sparse_dice_loss'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SparseDiceLoss", ",", "self", ")", ".", "__init__", "(", "\n", "sparse_dice_loss", ",", "\n", "name", "=", "name", ",", "\n", "reduction", "=", "reduction", ",", "\n", "smooth", "=", "smooth", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions._get_shapes_and_one_hot": [[5, 13], ["y_pred.get_shape", "tensorflow.cond", "tensorflow.reshape", "tensorflow.one_hot", "tensorflow.equal", "tensorflow.cast", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["def", "_get_shapes_and_one_hot", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "shape", "=", "y_pred", ".", "get_shape", "(", ")", "\n", "n_classes", "=", "shape", "[", "-", "1", "]", "\n", "# Squeeze dim -1 if it is == 1, otherwise leave it", "\n", "dims", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "y_true", ".", "shape", "[", "-", "1", "]", "or", "-", "1", ",", "1", ")", ",", "lambda", ":", "tf", ".", "shape", "(", "y_true", ")", "[", ":", "-", "1", "]", ",", "lambda", ":", "tf", ".", "shape", "(", "y_true", ")", ")", "\n", "y_true", "=", "tf", ".", "reshape", "(", "y_true", ",", "dims", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "tf", ".", "cast", "(", "y_true", ",", "tf", ".", "uint8", ")", ",", "depth", "=", "n_classes", ")", "\n", "return", "y_true", ",", "shape", ",", "n_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions.sparse_dice_loss": [[15, 32], ["loss_functions._get_shapes_and_one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "range", "tensorflow.reduce_mean", "len"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.loss_functions._get_shapes_and_one_hot"], ["", "def", "sparse_dice_loss", "(", "y_true", ",", "y_pred", ",", "smooth", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Approximates the class-wise dice coefficient computed per-batch element\n    across spatial image dimensions. Returns the 1 - mean(per_class_dice) for\n    each batch element.\n    :param y_true:\n    :param y_pred:\n    :param smooth:\n    :return:\n    \"\"\"", "\n", "y_true", ",", "shape", ",", "n_classes", "=", "_get_shapes_and_one_hot", "(", "y_true", ",", "y_pred", ")", "\n", "reduction_dims", "=", "range", "(", "len", "(", "shape", ")", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "intersection", "=", "tf", ".", "reduce_sum", "(", "y_true", "*", "y_pred", ",", "axis", "=", "reduction_dims", ")", "\n", "union", "=", "tf", ".", "reduce_sum", "(", "y_true", "+", "y_pred", ",", "axis", "=", "reduction_dims", ")", "\n", "dice", "=", "(", "2", "*", "intersection", "+", "smooth", ")", "/", "(", "union", "+", "smooth", ")", "\n", "return", "1.0", "-", "tf", ".", "reduce_mean", "(", "dice", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.ignore_out_of_bounds_classes_wrapper": [[9, 37], ["functools.wraps", "logger.info", "tf.boolean_mask.set_shape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.where", "tensorflow.cast", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "func", "tf.boolean_mask.get_shape", "tensorflow.logical_and", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.greater_equal", "tensorflow.less", "tf.boolean_mask.get_shape"], "function", ["None"], ["\n", "def", "create_folders", "(", "folders", ",", "create_deep", "=", "False", ")", ":", "\n", "    ", "def", "safe_make", "(", "path", ",", "make_func", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "make_func", "(", "path", ")", "\n", "", "except", "FileExistsError", ":", "\n", "# If running many jobs in parallel this may occur", "\n", "            ", "pass", "\n", "", "", "make_func", "=", "os", ".", "mkdir", "if", "not", "create_deep", "else", "os", ".", "makedirs", "\n", "if", "isinstance", "(", "folders", ",", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folders", ")", ":", "\n", "            ", "safe_make", "(", "folders", ",", "make_func", ")", "\n", "", "", "else", ":", "\n", "        ", "folders", "=", "list", "(", "folders", ")", "\n", "for", "f", "in", "folders", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f", ")", ":", "\n", "                ", "safe_make", "(", "f", ",", "make_func", ")", "\n", "\n", "\n", "", "", "", "", "def", "flatten_lists_recursively", "(", "list_of_lists", ")", ":", "\n", "    ", "for", "list_", "in", "list_of_lists", ":", "\n", "        ", "if", "isinstance", "(", "list_", ",", "Iterable", ")", "and", "not", "isinstance", "(", "list_", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "flatten_lists_recursively", "(", "list_", ")", "\n", "", "else", ":", "\n", "            ", "yield", "list_", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils._get_tp_rel_sel_from_cm": [[39, 44], ["numpy.diagonal", "numpy.sum", "numpy.sum"], "function", ["None"], ["    ", "length", "=", "len", "(", "string", ")", "if", "\"\\n\"", "not", "in", "string", "else", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "string", ".", "split", "(", "\"\\n\"", ")", "]", ")", "\n", "border", "=", "\"-\"", "*", "length", "\n", "return", "\"%s\\n%s\\n%s\"", "%", "(", "border", ",", "string", ",", "border", ")", "\n", "\n", "\n", "", "def", "await_pids", "(", "pids", ",", "check_every", "=", "120", ")", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.f1_scores_from_cm": [[46, 59], ["utils.precision_scores_from_cm", "utils.recall_scores_from_cm", "numpy.zeros_like"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.precision_scores_from_cm", "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.recall_scores_from_cm"], ["        ", "for", "pid", "in", "pids", ".", "split", "(", "\",\"", ")", ":", "\n", "            ", "wait_for", "(", "int", "(", "pid", ")", ",", "check_every", "=", "check_every", ")", "\n", "", "", "else", ":", "\n", "        ", "wait_for", "(", "pids", ",", "check_every", "=", "check_every", ")", "\n", "\n", "\n", "", "", "def", "wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n", "    ", "\"\"\"\n    Check for a running process with pid 'pid' and only return when the process\n    is no longer running. Checks the process list every 'check_every' seconds.\n    \"\"\"", "\n", "if", "not", "pid", ":", "\n", "        ", "return", "\n", "", "if", "not", "isinstance", "(", "pid", ",", "int", ")", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.precision_scores_from_cm": [[61, 67], ["utils._get_tp_rel_sel_from_cm", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils._get_tp_rel_sel_from_cm"], ["            ", "pid", "=", "int", "(", "pid", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot wait for pid '{pid}', must be an integer\"", ")", "from", "e", "\n", "", "", "_wait_for", "(", "pid", ",", "check_every", ")", "\n", "\n", "\n", "", "def", "_wait_for", "(", "pid", ",", "check_every", "=", "120", ")", ":", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.recall_scores_from_cm": [[69, 75], ["utils._get_tp_rel_sel_from_cm", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils._get_tp_rel_sel_from_cm"], ["logging", ".", "info", "(", "f\"\\n[*] Waiting for process pid={pid} to terminate...\"", ")", "\n", "while", "still_running", ":", "\n", "        ", "ps", "=", "subprocess", ".", "Popen", "(", "(", "\"ps\"", ",", "\"-p\"", ",", "f\"{pid}\"", ")", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "try", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "(", "\"grep\"", ",", "f\"{pid}\"", ")", ",", "stdin", "=", "ps", ".", "stdout", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "output", "=", "False", "\n"]], "home.repos.pwc.inspect_result.perslev_U-Time.evaluation.utils.concatenate_true_pred_pairs": [[77, 84], ["ValueError", "zip", "numpy.concatenate", "numpy.concatenate", "list", "list"], "function", ["None"], ["still_running", "=", "bool", "(", "output", ")", "\n", "if", "still_running", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Process {pid} still running... (sleeping {check_every} seconds)\"", ")", "\n", "time", ".", "sleep", "(", "check_every", ")", "\n", "", "", "", ""]]}