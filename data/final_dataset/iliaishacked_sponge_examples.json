{"home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.__init__": [[31, 42], ["ga.GeneticAlgorithm._initialise_population"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm._initialise_population"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", ",", "input_shape", ",", "clip_min", "=", "0", ",", "clip_max", "=", "1", ",", "\n", "noise_scale", "=", "0.1", ",", "cv", "=", "False", ")", ":", "\n", "        ", "self", ".", "pool_size", "=", "pool_size", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "clip_min", "=", "clip_min", "\n", "self", ".", "clip_max", "=", "clip_max", "\n", "self", ".", "noise_scale", "=", "noise_scale", "\n", "\n", "# flag for computer vision", "\n", "self", ".", "cv", "=", "cv", "\n", "self", ".", "_initialise_population", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.scaled_random_noise": [[43, 48], ["noise.astype", "numpy.random.rand"], "methods", ["None"], ["", "def", "scaled_random_noise", "(", "self", ",", "shape", ",", "scale", ",", "dtype", ")", ":", "\n", "        ", "noise", "=", "np", ".", "random", ".", "rand", "(", "*", "self", ".", "input_shape", ")", "*", "scale", "\n", "noise", "*=", "self", ".", "clip_max", "-", "self", ".", "clip_min", "\n", "noise", "+=", "self", ".", "clip_min", "\n", "return", "noise", ".", "astype", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm._initialise_population": [[49, 56], ["range", "numpy.random.rand", "ga.GeneticAlgorithm.population.append"], "methods", ["None"], ["", "def", "_initialise_population", "(", "self", ")", ":", "\n", "        ", "self", ".", "population", "=", "[", "]", "\n", "for", "p", "in", "range", "(", "self", ".", "pool_size", ")", ":", "\n", "            ", "samp", "=", "np", ".", "random", ".", "rand", "(", "*", "self", ".", "input_shape", ")", "\n", "samp", "*=", "self", ".", "clip_max", "-", "self", ".", "clip_min", "\n", "samp", "+=", "self", ".", "clip_min", "\n", "self", ".", "population", ".", "append", "(", "samp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm._random_pick": [[57, 60], ["numpy.random.choice"], "methods", ["None"], ["", "", "def", "_random_pick", "(", "self", ",", "x", ",", "axis", ",", "p", "=", "None", ")", ":", "\n", "        ", "axis_index", "=", "np", ".", "random", ".", "choice", "(", "x", ".", "shape", "[", "axis", "]", ",", "p", "=", "p", ")", "\n", "return", "x", "[", "axis_index", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.selection": [[61, 127], ["sorted", "numpy.dstack", "numpy.dstack", "int", "numpy.array", "numpy.array", "numpy.random.shuffle", "numpy.array", "collections.defaultdict", "enumerate", "numpy.array.sum", "len", "len", "x.tolist", "len", "ga.GeneticAlgorithm._random_pick", "ga.GeneticAlgorithm._random_pick", "sorted", "sorted", "len", "zip", "numpy.array.append", "numpy.array.append", "population.append", "ga.GeneticAlgorithm.crossover", "ga.GeneticAlgorithm.crossover", "ga.GeneticAlgorithm.mutate", "ga.GeneticAlgorithm.clip", "ga.GeneticAlgorithm.tolist", "zip", "pop_list.append", "population.append"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm._random_pick", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm._random_pick", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.crossover", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.crossover", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.mutate", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.clip"], ["", "def", "selection", "(", "self", ",", "fitness_scores", ",", "best_class", "=", "None", ",", "perc", "=", "None", ",", "\n", "transform", "=", "None", ",", "rescale", "=", "None", ",", "rotate", "=", "None", ")", ":", "\n", "\n", "# top 10% picked", "\n", "        ", "fitness_sorted", "=", "[", "x", "for", "_", ",", "x", "in", "sorted", "(", "zip", "(", "fitness_scores", ",", "\n", "self", ".", "population", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "scores_sorted", "=", "sorted", "(", "fitness_scores", ")", "\n", "\n", "self", ".", "best", "=", "np", ".", "dstack", "(", "fitness_sorted", "[", "-", "10", ":", "]", ")", "\n", "self", ".", "worst", "=", "np", ".", "dstack", "(", "fitness_sorted", "[", ":", "10", "]", ")", "\n", "\n", "percentile90", "=", "int", "(", "len", "(", "fitness_sorted", ")", "*", "0.1", ")", "\n", "\n", "top10", "=", "fitness_sorted", "[", "-", "percentile90", ":", "]", "\n", "p", "=", "scores_sorted", "[", "-", "percentile90", ":", "]", "\n", "\n", "if", "self", ".", "cv", ":", "\n", "            ", "population", "=", "[", "]", "\n", "", "else", ":", "\n", "#population = top10[:]", "\n", "            ", "population", "=", "top10", "[", ":", "]", "\n", "\n", "", "parents", "=", "top10", "[", ":", "]", "\n", "\n", "if", "best_class", "is", "not", "None", ":", "\n", "            ", "best_class", "=", "np", ".", "array", "(", "best_class", ")", "\n", "best", "=", "defaultdict", "(", "lambda", ":", "(", "0", ",", "0", ")", ")", "\n", "for", "i", ",", "(", "cl", ",", "sc", ")", "in", "enumerate", "(", "zip", "(", "best_class", ",", "fitness_scores", ")", ")", ":", "\n", "                ", "if", "best", "[", "cl", "]", "[", "0", "]", "<", "sc", ":", "\n", "                    ", "best", "[", "cl", "]", "=", "(", "sc", ",", "i", ")", "\n", "\n", "", "", "for", "key", "in", "best", ":", "\n", "                ", "parents", ".", "append", "(", "self", ".", "population", "[", "best", "[", "key", "]", "[", "1", "]", "]", ")", "\n", "p", ".", "append", "(", "best", "[", "key", "]", "[", "0", "]", ")", "\n", "\n", "population", ".", "append", "(", "self", ".", "population", "[", "best", "[", "key", "]", "[", "1", "]", "]", ")", "\n", "\n", "", "", "parents", "=", "np", ".", "array", "(", "parents", ")", "\n", "p", "=", "np", ".", "array", "(", "p", ")", "\n", "p", "=", "p", "/", "p", ".", "sum", "(", ")", "\n", "\n", "assert", "len", "(", "p", ")", "==", "len", "(", "parents", ")", "\n", "pop_list", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "population", "]", "\n", "\n", "while", "(", "len", "(", "population", ")", "<", "self", ".", "pool_size", ")", ":", "\n", "# heuristic, pure cross over", "\n", "            ", "parent_a", "=", "self", ".", "_random_pick", "(", "parents", ",", "axis", "=", "0", ",", "p", "=", "p", ")", "\n", "parent_b", "=", "self", ".", "_random_pick", "(", "parents", ",", "axis", "=", "0", ",", "p", "=", "p", ")", "\n", "mutated", "=", "[", "\n", "self", ".", "crossover", "(", "parent_a", ",", "parent_b", ")", ",", "\n", "self", ".", "crossover", "(", "parent_b", ",", "parent_a", ")", "\n", "]", "\n", "\n", "for", "mut", "in", "mutated", ":", "\n", "                ", "mut", "=", "self", ".", "mutate", "(", "mut", ",", "perc", "=", "perc", ")", "\n", "mut", "=", "self", ".", "clip", "(", "mut", ")", "\n", "mutated_list", "=", "mut", ".", "tolist", "(", ")", "\n", "if", "mutated_list", "not", "in", "pop_list", ":", "\n", "                    ", "pop_list", ".", "append", "(", "mutated_list", ")", "\n", "population", ".", "append", "(", "mut", ")", "\n", "\n", "", "", "", "del", "pop_list", "\n", "del", "self", ".", "population", "\n", "np", ".", "random", ".", "shuffle", "(", "population", ")", "\n", "self", ".", "population", "=", "population", "\n", "self", ".", "top10", "=", "sorted", "(", "fitness_scores", ")", "[", "-", "percentile90", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.mutate": [[128, 190], ["scipy.ndimage.rotate", "range", "ga.GeneticAlgorithm.scaled_random_noise", "numpy.flip.flatten", "numpy.put", "numpy.flip.reshape", "ga.GeneticAlgorithm.scaled_random_noise", "numpy.random.random", "max", "max", "scipy.ndimage.zoom", "numpy.pad", "len", "numpy.random.random", "numpy.transpose", "numpy.random.random", "numpy.random.random", "numpy.random.random", "numpy.random.random", "numpy.roll", "numpy.random.rand", "numpy.flip", "numpy.random.rand", "numpy.flip", "float", "numpy.random.random", "numpy.random.randint", "int"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.scaled_random_noise", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.scaled_random_noise"], ["", "def", "mutate", "(", "self", ",", "a", ",", "perc", "=", "None", ",", "transform", "=", "None", ",", "rescale", "=", "None", ",", "\n", "rotate", "=", "None", ")", ":", "\n", "\n", "        ", "a_shape", "=", "a", ".", "shape", "\n", "\n", "if", "rotate", "is", "not", "None", ":", "\n", "            ", "a_rot", "=", "ndimage", ".", "rotate", "(", "a", ",", "np", ".", "random", ".", "random", "(", ")", "*", "360", ",", "axes", "=", "(", "2", ",", "3", ")", ",", "reshape", "=", "False", ")", "\n", "a", "+=", "a_rot", "\n", "\n", "", "if", "rescale", "is", "not", "None", ":", "\n", "            ", "if", "np", ".", "random", ".", "random", "(", ")", "<", "rescale", ":", "\n", "                ", "new_width", "=", "max", "(", "0.1", ",", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "new_height", "=", "max", "(", "0.1", ",", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "\n", "a_original", "=", "a", "\n", "a", "=", "zoom", "(", "a", ",", "(", "1", ",", "1", ",", "\n", "new_width", ",", "new_height", ",", ")", ")", "\n", "\n", "a", "=", "np", ".", "pad", "(", "a", ",", "\n", "(", "\n", "(", "0", ",", "0", ")", ",", "\n", "(", "0", ",", "0", ")", ",", "\n", "(", "0", ",", "a_shape", "[", "2", "]", "-", "a", ".", "shape", "[", "2", "]", ")", ",", "\n", "(", "0", ",", "a_shape", "[", "3", "]", "-", "a", ".", "shape", "[", "3", "]", ")", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "constant_values", "=", "(", "self", ".", "clip_min", ",", ")", ",", "\n", ")", "\n", "#a += a_original", "\n", "\n", "", "", "if", "transform", "is", "not", "None", ":", "\n", "            ", "for", "ax", "in", "range", "(", "1", ",", "len", "(", "a_shape", ")", ")", ":", "\n", "                ", "if", "np", ".", "random", ".", "random", "(", ")", "<", "transform", ":", "\n", "                    ", "a", "=", "np", ".", "roll", "(", "a", ",", "shift", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "a_shape", "[", "ax", "]", ")", ",", "axis", "=", "ax", ")", "\n", "\n", "", "", "if", "np", ".", "random", ".", "random", "(", ")", "<", "transform", ":", "\n", "                ", "a", "=", "np", ".", "transpose", "(", "a", ",", "(", "0", ",", "1", ",", "3", ",", "2", ")", ")", "\n", "\n", "", "", "if", "perc", "is", "not", "None", ":", "\n", "\n", "            ", "rperc", "=", "perc", "#np.random.rand() * perc", "\n", "\n", "indx", "=", "(", "np", ".", "random", ".", "random", "(", "size", "=", "int", "(", "rperc", "*", "a", ".", "size", ")", ")", "*", "\n", "a", ".", "size", ")", ".", "astype", "(", "int", ")", "\n", "values", "=", "self", ".", "scaled_random_noise", "(", "indx", ".", "shape", ",", "\n", "scale", "=", "self", ".", "noise_scale", ",", "dtype", "=", "a", ".", "dtype", ")", "\n", "a", "=", "a", ".", "flatten", "(", ")", "\n", "\n", "if", "not", "self", ".", "cv", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "                    ", "a", "=", "np", ".", "flip", "(", "a", ")", "\n", "\n", "", "", "np", ".", "put", "(", "a", ",", "indx", ",", "values", ")", "\n", "a", "=", "a", ".", "reshape", "(", "a_shape", ")", "\n", "return", "a", "\n", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "cv", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "                    ", "a", "=", "np", ".", "flip", "(", "a", ")", "\n", "\n", "", "", "noise", "=", "self", ".", "scaled_random_noise", "(", "a", ".", "shape", ",", "\n", "scale", "=", "self", ".", "noise_scale", ",", "dtype", "=", "a", ".", "dtype", ")", "\n", "noise", "-=", "self", ".", "noise_scale", "*", "float", "(", "self", ".", "clip_max", "-", "self", ".", "clip_min", ")", "/", "2", "\n", "return", "a", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.crossover": [[191, 213], ["numpy.concatenate.reshape", "a.flatten", "b.flatten", "len", "numpy.concatenate", "numpy.random.rand"], "methods", ["None"], ["", "", "def", "crossover", "(", "self", ",", "a", ",", "b", ",", "concat", "=", "False", ")", ":", "\n", "        ", "a_shape", "=", "a", ".", "shape", "\n", "flat_a", ",", "flat_b", "=", "a", ".", "flatten", "(", ")", ",", "b", ".", "flatten", "(", ")", "\n", "mid_point", "=", "len", "(", "flat_a", ")", "//", "2", "\n", "\n", "#offspring = sbx(", "\n", "#        flat_a, flat_b,", "\n", "#        -2.8, 2.8,", "\n", "#        eta=1", "\n", "#        )", "\n", "#offspring = offspring.reshape(a_shape)", "\n", "#return offspring", "\n", "\n", "if", "concat", ":", "\n", "            ", "left", "=", "flat_a", "[", ":", "mid_point", "]", "\n", "right", "=", "flat_b", "[", "mid_point", ":", "]", "\n", "offspring", "=", "np", ".", "concatenate", "(", "(", "left", ",", "right", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "masked", "=", "np", ".", "random", ".", "rand", "(", "*", "flat_a", ".", "shape", ")", "\n", "offspring", "=", "(", "flat_a", "*", "masked", "+", "flat_b", "*", "(", "1", "-", "masked", ")", ")", "\n", "", "offspring", "=", "offspring", ".", "reshape", "(", "a_shape", ")", "\n", "return", "offspring", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.clip": [[214, 216], ["numpy.clip"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.clip"], ["", "def", "clip", "(", "self", ",", "a", ")", ":", "\n", "        ", "return", "np", ".", "clip", "(", "a", ",", "self", ".", "clip_min", ",", "self", ".", "clip_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string": [[6, 10], ["min", "int", "len", "len"], "function", ["None"], ["def", "to_string", "(", "dist", ",", "dictionary", ")", ":", "\n", "    ", "word", "=", "\" \"", ".", "join", "(", "[", "dictionary", "[", "min", "(", "int", "(", "x", "*", "len", "(", "dictionary", ")", ")", ",", "len", "(", "dictionary", ")", "-", "1", ")", "]", "\n", "for", "x", "in", "dist", "]", ")", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga._read_sysfs_file": [[11, 14], ["open", "f.read().strip", "f.read"], "function", ["None"], ["", "def", "_read_sysfs_file", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.get_cpu_reading": [[15, 22], ["sum", "int", "int", "ga._read_sysfs_file", "ga._read_sysfs_file"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga._read_sysfs_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga._read_sysfs_file"], ["", "", "def", "get_cpu_reading", "(", ")", ":", "\n", "#return int(_read_sysfs_file(\"/sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj\"))", "\n", "    ", "files", "=", "[", "\n", "int", "(", "_read_sysfs_file", "(", "\"/sys/class/powercap/intel-rapl:0/energy_uj\"", ")", ")", ",", "\n", "int", "(", "_read_sysfs_file", "(", "\"/sys/class/powercap/intel-rapl:1/energy_uj\"", ")", ")", ",", "\n", "]", "\n", "return", "sum", "(", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.get_cpu_temp": [[23, 29], ["sum", "int", "int", "ga._read_sysfs_file", "ga._read_sysfs_file"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga._read_sysfs_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga._read_sysfs_file"], ["", "def", "get_cpu_temp", "(", ")", ":", "\n", "    ", "files", "=", "[", "\n", "int", "(", "_read_sysfs_file", "(", "\"/sys/class/thermal/thermal_zone0/temp\"", ")", ")", ",", "\n", "int", "(", "_read_sysfs_file", "(", "\"/sys/class/thermal/thermal_zone1/temp\"", ")", ")", ",", "\n", "]", "\n", "return", "sum", "(", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.test": [[217, 224], ["ga.GeneticAlgorithm", "print", "ga.GeneticAlgorithm.selection", "print", "list", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.selection"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "pool_size", "=", "100", "\n", "input_shape", "=", "(", "32", ",", "32", ",", "3", ")", "\n", "ga", "=", "GeneticAlgorithm", "(", "pool_size", ",", "input_shape", ")", "\n", "print", "(", "ga", ".", "population", ")", "\n", "ga", ".", "selection", "(", "list", "(", "np", ".", "random", ".", "rand", "(", "pool_size", ")", ")", ")", "\n", "print", "(", "ga", ".", "population", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.sbx": [[227, 271], ["x.copy", "numpy.random.random", "numpy.random.random", "range", "len", "len", "len", "abs", "min", "max", "min", "min", "max", "max"], "function", ["None"], ["", "def", "sbx", "(", "x", ",", "y", ",", "_min", ",", "_max", ",", "eta", ")", ":", "\n", "    ", "'''\n    SBX (cf Deb 2001, p 113) Simulated Binary Crossover\n    A large value ef eta gives a higher probablitity for\n    creating a `near-parent' solutions and a small value allows\n    distant solutions to be selected as offspring.\n    '''", "\n", "xl", "=", "_min", "\n", "xu", "=", "_max", "\n", "z", "=", "x", ".", "copy", "(", ")", "\n", "r1", "=", "np", ".", "random", ".", "random", "(", "size", "=", "len", "(", "x", ")", ")", "\n", "r2", "=", "np", ".", "random", ".", "random", "(", "size", "=", "len", "(", "x", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "x", ")", ")", ":", "\n", "        ", "if", "abs", "(", "x", "[", "i", "]", "-", "y", "[", "i", "]", ")", ">", "1e-15", ":", "\n", "            ", "x1", "=", "min", "(", "x", "[", "i", "]", ",", "y", "[", "i", "]", ")", "\n", "x2", "=", "max", "(", "x", "[", "i", "]", ",", "y", "[", "i", "]", ")", "\n", "\n", "beta", "=", "1.0", "+", "(", "2.0", "*", "(", "x1", "-", "xl", ")", "/", "(", "x2", "-", "x1", ")", ")", "\n", "alpha", "=", "2.0", "-", "beta", "**", "-", "(", "eta", "+", "1", ")", "\n", "rand", "=", "r1", "[", "i", "]", "\n", "if", "rand", "<=", "1.0", "/", "alpha", ":", "\n", "                ", "beta_q", "=", "(", "rand", "*", "alpha", ")", "**", "(", "1.0", "/", "(", "eta", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "beta_q", "=", "(", "1.0", "/", "(", "2.0", "-", "rand", "*", "alpha", ")", ")", "**", "(", "1.0", "/", "(", "eta", "+", "1", ")", ")", "\n", "\n", "", "c1", "=", "0.5", "*", "(", "x1", "+", "x2", "-", "beta_q", "*", "(", "x2", "-", "x1", ")", ")", "\n", "\n", "beta", "=", "1.0", "+", "(", "2.0", "*", "(", "xu", "-", "x2", ")", "/", "(", "x2", "-", "x1", ")", ")", "\n", "alpha", "=", "2.0", "-", "beta", "**", "-", "(", "eta", "+", "1", ")", "\n", "if", "rand", "<=", "1.0", "/", "alpha", ":", "\n", "                ", "beta_q", "=", "(", "rand", "*", "alpha", ")", "**", "(", "1.0", "/", "(", "eta", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "beta_q", "=", "(", "1.0", "/", "(", "2.0", "-", "rand", "*", "alpha", ")", ")", "**", "(", "1.0", "/", "(", "eta", "+", "1", ")", ")", "\n", "", "c2", "=", "0.5", "*", "(", "x1", "+", "x2", "+", "beta_q", "*", "(", "x2", "-", "x1", ")", ")", "\n", "\n", "c1", "=", "min", "(", "max", "(", "c1", ",", "xl", ")", ",", "xu", ")", "\n", "c2", "=", "min", "(", "max", "(", "c2", ",", "xl", ")", ",", "xu", ")", "\n", "\n", "if", "r2", "[", "i", "]", "<=", "0.5", ":", "\n", "                ", "z", "[", "i", "]", "=", "c2", "\n", "", "else", ":", "\n", "                ", "z", "[", "i", "]", "=", "c1", "\n", "", "", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.cli": [[16, 20], ["click.group", "click.version_option", "run.run", "run.analyse", "run.azure"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.run", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.analyse", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.azure"], ["@", "click", ".", "group", "(", ")", "\n", "@", "click", ".", "version_option", "(", ")", "\n", "def", "cli", "(", ")", ":", "\n", "    ", "\"\"\" Salo -- energy attacks against DNNs \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.analyse": [[21, 148], ["click.command", "click.argument", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "ga.GeneticAlgorithm", "energy_estimator.HardwareModel", "language_models.utils.get_characters", "language_models.utils.get_file", "pynvml.nvmlInit", "pynvml.nvmlDeviceGetHandleByIndex", "energy_estimator.StatsRecorder", "language_models.utils.get_task", "language_models.utils.get_inference", "range", "language_models.utils.get_file.close", "language_models.utils.get_naturals", "all_simuls.append", "all_energies.append", "all_times.append", "language_models.utils.write_to_file", "enumerate", "ga.GeneticAlgorithm.selection", "language_models.utils.write_to_file", "all_simuls.append", "all_energies.append", "all_times.append", "print", "print", "print", "print", "open", "pickle.dump", "click.Choice", "torch.no_grad", "range", "torch.no_grad", "enumerate", "ga.to_string", "ga.to_string", "ga.to_string", "language_models.utils.eval_pass", "language_models.utils.hook_up", "language_models.utils.eval_pass", "language_models.utils.hook_down", "simuls.append", "energies.append", "times.append", "scores.append", "torch.no_grad", "language_models.utils.eval_pass", "simuls.append", "energies.append", "times.append", "print", "language_models.utils.get_inference.", "energy_estimator.get_energy_estimate", "language_models.utils.hook_up", "language_models.utils.eval_pass", "language_models.utils.hook_down", "scores.append", "numpy.mean", "numpy.max", "numpy.mean", "numpy.max", "numpy.mean", "numpy.max", "energy_estimator.get_energy_estimate", "scores.append", "scores.append"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_characters", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_task", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_inference", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_naturals", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.write_to_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.selection", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.write_to_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_up", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_down", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_up", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_down", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate"], ["", "@", "click", ".", "command", "(", "help", "=", "\"Command to run the analysis\"", ")", "\n", "@", "click", ".", "argument", "(", "'task'", ")", "\n", "@", "click", ".", "option", "(", "'pool_size'", ",", "'--pool_size'", ",", "default", "=", "50", ")", "\n", "@", "click", ".", "option", "(", "'input_size'", ",", "'--input_size'", ",", "default", "=", "6", ")", "\n", "@", "click", ".", "option", "(", "'epochs'", ",", "'--epochs'", ",", "default", "=", "50", ")", "\n", "@", "click", ".", "option", "(", "'out'", ",", "'--out'", ",", "default", "=", "\"test\"", ")", "\n", "@", "click", ".", "option", "(", "'hot_start'", ",", "'--hot_start'", ",", "is_flag", "=", "True", ")", "\n", "@", "click", ".", "option", "(", "'natural'", ",", "'--natural'", ",", "is_flag", "=", "True", ")", "\n", "@", "click", ".", "option", "(", "'cost_type'", ",", "'--cost_type'", ",", "default", "=", "\"simul\"", ",", "\n", "type", "=", "click", ".", "Choice", "(", "[", "'simul'", ",", "'time'", ",", "'energy'", "]", ")", ")", "\n", "@", "click", ".", "option", "(", "'nointereng'", ",", "'--nointereng'", ",", "is_flag", "=", "True", ")", "\n", "def", "analyse", "(", "task", ",", "pool_size", ",", "input_size", ",", "epochs", ",", "out", ",", "\n", "hot_start", ",", "natural", ",", "cost_type", ",", "nointereng", ")", ":", "\n", "    ", "ga", "=", "GeneticAlgorithm", "(", "pool_size", ",", "(", "input_size", ",", ")", ",", "noise_scale", "=", "1.0", ")", "\n", "hardware", "=", "simul", ".", "HardwareModel", "(", "optim", "=", "True", ")", "\n", "\n", "dictionary", "=", "get_characters", "(", ")", "\n", "_f", "=", "get_file", "(", "out", ")", "\n", "\n", "pynvml", ".", "nvmlInit", "(", ")", "\n", "handle", "=", "pynvml", ".", "nvmlDeviceGetHandleByIndex", "(", "0", ")", "\n", "stats", "=", "simul", ".", "StatsRecorder", "(", ")", "\n", "\n", "model", "=", "get_task", "(", "task", ")", "\n", "inference", "=", "get_inference", "(", "model", ",", "task", ")", "\n", "\n", "if", "hot_start", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "30", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "inference", "(", "\"JAJJAJAJAJJAJAJAJAJJ\"", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "", "all_scores", ",", "all_energies", ",", "all_simuls", ",", "all_times", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "if", "natural", ":", "\n", "        ", "natural_samples", "=", "get_naturals", "(", "pool_size", ",", "task", ",", "input_size", ")", "\n", "scores", ",", "energies", ",", "times", ",", "simuls", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "word", "in", "enumerate", "(", "natural_samples", ")", ":", "\n", "                ", "energy_delta", ",", "time_delta", ",", "prediction", "=", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ")", "\n", "\n", "stat_hooks", "=", "hook_up", "(", "model", ",", "stats", ",", "task", ")", "\n", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ")", "\n", "hook_down", "(", "stat_hooks", ")", "\n", "\n", "if", "energy_delta", "==", "0", ":", "\n", "                    ", "energy_est", "=", "0", "\n", "", "else", ":", "\n", "                    ", "energy_est", "=", "simul", ".", "get_energy_estimate", "(", "stats", ",", "hardware", ")", "\n", "\n", "", "simuls", ".", "append", "(", "energy_est", ")", "\n", "energies", ".", "append", "(", "energy_delta", ")", "\n", "times", ".", "append", "(", "time_delta", ")", "\n", "scores", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "", "all_simuls", ".", "append", "(", "simuls", ")", "\n", "all_energies", ".", "append", "(", "energies", ")", "\n", "all_times", ".", "append", "(", "times", ")", "\n", "\n", "write_to_file", "(", "_f", ",", "-", "1", ",", "simuls", ",", "energies", ",", "times", ",", "ga", ")", "\n", "del", "natural_samples", "\n", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "scores", ",", "energies", ",", "simuls", ",", "times", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "ga", ".", "population", ")", ":", "\n", "            ", "word", "=", "to_string", "(", "sample", ",", "dictionary", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "energy_delta", ",", "time_delta", ",", "prediction", "=", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ")", "\n", "\n", "if", "not", "nointereng", "or", "(", "epoch", "==", "epochs", "-", "1", ")", ":", "\n", "                    ", "stat_hooks", "=", "hook_up", "(", "model", ",", "stats", ",", "task", ")", "\n", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ")", "\n", "hook_down", "(", "stat_hooks", ")", "\n", "\n", "", "if", "energy_delta", "==", "0", ":", "\n", "                    ", "energy_est", "=", "0", "\n", "", "else", ":", "\n", "                    ", "if", "nointereng", "and", "(", "epoch", "!=", "epochs", "-", "1", ")", ":", "\n", "                        ", "energy_est", "=", "-", "2", "\n", "", "else", ":", "\n", "                        ", "energy_est", "=", "simul", ".", "get_energy_estimate", "(", "stats", ",", "hardware", ")", "\n", "\n", "", "", "if", "cost_type", "==", "\"energy\"", ":", "\n", "                    ", "scores", ".", "append", "(", "energy_delta", ")", "\n", "", "elif", "cost_type", "==", "\"time\"", ":", "\n", "                    ", "scores", ".", "append", "(", "time_delta", ")", "\n", "", "elif", "cost_type", "==", "\"simul\"", ":", "\n", "                    ", "scores", ".", "append", "(", "energy_est", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\"Unsupported cost type {cost_type}\"", "\n", "\n", "", "simuls", ".", "append", "(", "energy_est", ")", "\n", "energies", ".", "append", "(", "energy_delta", ")", "\n", "times", ".", "append", "(", "time_delta", ")", "\n", "\n", "print", "(", "f\"{word} -> {prediction} : Simul: {energy_est:.4f} Time:\"", "\n", "f\" {time_delta:.4f} NVML: {energy_delta:.4f}\"", ",", "end", "=", "\"\\r\"", ")", "\n", "\n", "", "", "ga", ".", "selection", "(", "scores", ",", "perc", "=", "0.1", ")", "\n", "write_to_file", "(", "_f", ",", "epoch", ",", "scores", ",", "energies", ",", "times", ",", "ga", ")", "\n", "\n", "all_simuls", ".", "append", "(", "simuls", ")", "\n", "all_energies", ".", "append", "(", "energies", ")", "\n", "all_times", ".", "append", "(", "times", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Best:\"", ",", "to_string", "(", "ga", ".", "best", "[", "0", "]", "[", ":", ",", "-", "1", "]", ",", "dictionary", ")", ")", "\n", "print", "(", "\"Worst:\"", ",", "to_string", "(", "ga", ".", "worst", "[", "0", "]", "[", ":", ",", "-", "1", "]", ",", "dictionary", ")", ")", "\n", "print", "(", "f\"Epoch: {epoch}/{epochs}: \"", "\n", "f\"Mean simul: {np.mean(simuls)} {np.max(simuls)} \"", "\n", "f\"Mean nvml: {np.mean(energies)} {np.max(energies)} \"", "\n", "f\"Mean time: {np.mean(times)} {np.max(times)}\"", ")", "\n", "#del scores, energies, times", "\n", "del", "ga", ".", "top10", "\n", "\n", "", "_f", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "out", "+", "\".pkl\"", ",", "\"wb\"", ")", "as", "_f", ":", "\n", "        ", "pickle", ".", "dump", "(", "[", "\n", "task", ",", "cost_type", ",", "ga", ".", "population", ",", "\n", "all_simuls", ",", "all_energies", ",", "all_times", "]", ",", "_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.run": [[149, 219], ["click.command", "click.argument", "click.option", "click.option", "click.option", "click.option", "pickle.load", "pynvml.nvmlInit", "pynvml.nvmlDeviceGetHandleByIndex", "energy_estimator.StatsRecorder", "energy_estimator.HardwareModel", "language_models.utils.get_task", "language_models.utils.get_characters", "language_models.utils.get_inference", "open", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "enumerate", "open", "pickle.dump", "model.cuda.to", "model.cuda.cuda", "language_models.utils.get_naturals", "numpy.random.shuffle", "ga.to_string", "torch.no_grad", "language_models.utils.eval_pass", "language_models.utils.hook_up", "language_models.utils.eval_pass", "language_models.utils.hook_down", "simuls[].append", "energies[].append", "times[].append", "print", "len", "type", "energy_estimator.get_energy_estimate"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_task", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_characters", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_inference", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_naturals", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_up", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_down", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate"], ["", "", "@", "click", ".", "command", "(", "help", "=", "\"Command to run the analysis\"", ")", "\n", "@", "click", ".", "argument", "(", "'task'", ")", "\n", "@", "click", ".", "option", "(", "'infile'", ",", "'--infile'", ",", "required", "=", "True", ")", "\n", "@", "click", ".", "option", "(", "'out'", ",", "'--out'", ",", "default", "=", "\"test\"", ")", "\n", "@", "click", ".", "option", "(", "'natural'", ",", "'--natural'", ",", "is_flag", "=", "True", ")", "\n", "@", "click", ".", "option", "(", "'natural_size'", ",", "'--natural_size'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "def", "run", "(", "task", ",", "infile", ",", "out", ",", "natural", ",", "natural_size", ")", ":", "\n", "\n", "    ", "inf", "=", "pickle", ".", "load", "(", "open", "(", "infile", ",", "\"rb\"", ")", ")", "\n", "\n", "pynvml", ".", "nvmlInit", "(", ")", "\n", "handle", "=", "pynvml", ".", "nvmlDeviceGetHandleByIndex", "(", "0", ")", "\n", "stats", "=", "simul", ".", "StatsRecorder", "(", ")", "\n", "hardware", "=", "simul", ".", "HardwareModel", "(", "optim", "=", "True", ")", "\n", "\n", "model", "=", "get_task", "(", "task", ")", "\n", "dictionary", "=", "get_characters", "(", ")", "\n", "\n", "inference", "=", "get_inference", "(", "model", ",", "task", ")", "\n", "\n", "energies", ",", "times", ",", "simuls", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "for", "dev", "in", "[", "\"cpu\"", ",", "\"gpu\"", "]", ":", "\n", "\n", "        ", "if", "dev", "==", "\"cpu\"", ":", "\n", "            ", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "model", ".", "cuda", "(", "0", ")", "\n", "\n", "", "if", "natural", ":", "\n", "            ", "samples", "=", "get_naturals", "(", "100", ",", "task", ",", "natural_size", ")", "\n", "", "else", ":", "\n", "            ", "if", "(", "len", "(", "inf", ")", "==", "6", ")", "and", "(", "type", "(", "inf", "[", "0", "]", ")", "==", "str", ")", ":", "\n", "                ", "samples", "=", "inf", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "samples", "=", "inf", "\n", "", "np", ".", "random", ".", "shuffle", "(", "samples", ")", "\n", "#samples = samples[::-1]", "\n", "\n", "", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "if", "i", "==", "100", ":", "\n", "                ", "break", "\n", "", "if", "natural", ":", "\n", "                ", "word", "=", "sample", "\n", "", "else", ":", "\n", "                ", "word", "=", "to_string", "(", "sample", ",", "dictionary", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "energy_delta", ",", "time_delta", ",", "prediction", "=", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ",", "dev", "=", "dev", ")", "\n", "\n", "stat_hooks", "=", "hook_up", "(", "model", ",", "stats", ",", "task", ")", "\n", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ")", "\n", "hook_down", "(", "stat_hooks", ")", "\n", "\n", "if", "energy_delta", "==", "0", ":", "\n", "                    ", "energy_est", "=", "0", "\n", "", "else", ":", "\n", "                    ", "energy_est", "=", "simul", ".", "get_energy_estimate", "(", "stats", ",", "hardware", ")", "\n", "\n", "", "simuls", "[", "dev", "]", ".", "append", "(", "energy_est", ")", "\n", "energies", "[", "dev", "]", ".", "append", "(", "energy_delta", ")", "\n", "times", "[", "dev", "]", ".", "append", "(", "time_delta", ")", "\n", "\n", "print", "(", "f\"{word} -> {prediction} : Simul: {energy_est:.4f} Time:\"", "\n", "f\" {time_delta:.4f} NVML: {energy_delta:.4f}\"", ",", "end", "=", "\"\\r\"", ")", "\n", "\n", "", "", "", "with", "open", "(", "out", "+", "\".pkl\"", ",", "\"wb\"", ")", "as", "_f", ":", "\n", "        ", "pickle", ".", "dump", "(", "[", "\n", "task", ",", "inf", ",", "\n", "simuls", ",", "energies", ",", "times", "]", ",", "_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.run.azure": [[222, 299], ["click.command", "click.argument", "click.option", "click.option", "click.option", "click.option", "ga.GeneticAlgorithm", "energy_estimator.HardwareModel", "language_models.utils.get_characters", "language_models.utils.get_file", "range", "enumerate", "ga.GeneticAlgorithm.selection", "all_scores.append", "print", "print", "print", "print", "open", "pickle.dump", "ga.to_string", "requests.post", "requests.post.elapsed.total_seconds", "requests.post.json", "scores.append", "ga.to_string", "ga.to_string", "print", "print", "numpy.mean", "numpy.percentile", "numpy.max"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_characters", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_file", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.GeneticAlgorithm.selection", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.to_string"], ["", "", "@", "click", ".", "command", "(", "help", "=", "\"Command to run the azure exps\"", ")", "\n", "@", "click", ".", "argument", "(", "'task'", ")", "\n", "@", "click", ".", "option", "(", "'pool_size'", ",", "'--pool_size'", ",", "default", "=", "50", ")", "\n", "@", "click", ".", "option", "(", "'input_size'", ",", "'--input_size'", ",", "default", "=", "6", ")", "\n", "@", "click", ".", "option", "(", "'epochs'", ",", "'--epochs'", ",", "default", "=", "50", ")", "\n", "@", "click", ".", "option", "(", "'out'", ",", "'--out'", ",", "default", "=", "\"test\"", ")", "\n", "def", "azure", "(", "task", ",", "pool_size", ",", "input_size", ",", "epochs", ",", "out", ")", ":", "\n", "    ", "ga", "=", "GeneticAlgorithm", "(", "pool_size", ",", "(", "input_size", ",", ")", ",", "noise_scale", "=", "1.0", ")", "\n", "hardware", "=", "simul", ".", "HardwareModel", "(", "optim", "=", "True", ")", "\n", "\n", "dictionary", "=", "get_characters", "(", ")", "\n", "_f", "=", "get_file", "(", "out", ")", "\n", "\n", "subscription_key", "=", "\"\"", "\n", "endpoint", "=", "\"https://somethingsomething.cognitiveservices.azure.com/\"", "\n", "\n", "if", "task", "==", "\"translate\"", ":", "\n", "        ", "subscription_key", "=", "\"\"", "\n", "endpoint", "=", "\"https://api.cognitive.microsofttranslator.com/\"", "\n", "\n", "", "if", "task", "==", "\"language_detection\"", ":", "\n", "        ", "language_api_url", "=", "endpoint", "+", "\"/text/analytics/v3.0/languages\"", "\n", "", "elif", "task", "==", "\"sentiment\"", ":", "\n", "        ", "language_api_url", "=", "endpoint", "+", "\"/text/analytics/v3.0/sentiment\"", "\n", "", "elif", "task", "==", "\"keyphrase\"", ":", "\n", "        ", "language_api_url", "=", "endpoint", "+", "\"/text/analytics/v3.0/keyPhrases\"", "\n", "", "elif", "task", "==", "\"indetities\"", ":", "\n", "        ", "language_api_url", "=", "endpoint", "+", "\"/text/analytics/v3.0/entities/recognition/general\"", "\n", "", "elif", "task", "==", "\"translate\"", ":", "\n", "        ", "language_api_url", "=", "endpoint", "+", "\"/translate?api-version=3.0\"", "\n", "", "else", ":", "\n", "        ", "raise", "\"I do not know such a task\"", "\n", "\n", "", "all_scores", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "scores", "=", "[", "]", "\n", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "ga", ".", "population", ")", ":", "\n", "            ", "word", "=", "to_string", "(", "sample", ",", "dictionary", ")", "\n", "documents", "=", "{", "\"documents\"", ":", "[", "{", "\"id\"", ":", "\"1\"", ",", "\"language\"", ":", "\"en\"", ",", "\"text\"", ":", "word", "}", "]", "}", "\n", "\n", "if", "task", "==", "\"translate\"", ":", "\n", "                ", "documents", "=", "[", "{", "\"Text\"", ":", "word", "}", "]", "\n", "\n", "headers", "=", "{", "\n", "\"Ocp-Apim-Subscription-Key\"", ":", "subscription_key", ",", "\n", "\"Ocp-Apim-Subscription-Region\"", ":", "\"westeurope\"", ",", "\n", "}", "\n", "", "else", ":", "\n", "                ", "headers", "=", "{", "\"Ocp-Apim-Subscription-Key\"", ":", "subscription_key", "}", "\n", "\n", "", "response", "=", "requests", ".", "post", "(", "language_api_url", "+", "\"&to=fr\"", ",", "headers", "=", "headers", ",", "json", "=", "documents", ")", "\n", "timedelta", "=", "response", ".", "elapsed", ".", "total_seconds", "(", ")", "\n", "languages", "=", "response", ".", "json", "(", ")", "\n", "\n", "scores", ".", "append", "(", "timedelta", ")", "\n", "\n", "if", "'documents'", "not", "in", "languages", ":", "\n", "                ", "print", "(", "f\"{word[:10]} -> ERROR ({languages}) : {timedelta:.3f}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "else", ":", "\n", "#print(f\"{word[:10]} -> {languages['documents'][0]} : {timedelta:.3f}\", end='\\r')", "\n", "                ", "print", "(", "f\"{word[:10]} -> {timedelta:.3f}\"", ",", "end", "=", "'\\r'", ")", "\n", "\n", "", "", "ga", ".", "selection", "(", "scores", ",", "perc", "=", "0.1", ")", "\n", "all_scores", ".", "append", "(", "scores", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Best:\"", ",", "to_string", "(", "ga", ".", "best", "[", "0", "]", "[", ":", ",", "-", "1", "]", ",", "dictionary", ")", ")", "\n", "print", "(", "\"Worst:\"", ",", "to_string", "(", "ga", ".", "worst", "[", "0", "]", "[", ":", ",", "-", "1", "]", ",", "dictionary", ")", ")", "\n", "print", "(", "f\"Epoch: {epoch}/{epochs}: \"", "\n", "f\"Mean time: {np.mean(scores)} 90perc: {np.percentile(scores, 90)} max {np.max(scores)}\"", ")", "\n", "#del scores, energies, times", "\n", "del", "ga", ".", "top10", "\n", "\n", "", "with", "open", "(", "out", "+", "\".pkl\"", ",", "\"wb\"", ")", "as", "_f", ":", "\n", "        ", "pickle", ".", "dump", "(", "[", "\n", "task", ",", "ga", ".", "population", ",", "all_scores", ",", "scores", "]", ",", "_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_characters": [[29, 34], ["chr", "range"], "function", ["None"], ["def", "get_characters", "(", ")", ":", "\n", "#return string.ascii_lowercase + string.ascii_uppercase +\\", "\n", "#\" 0123456789!@\u00a3$%^&*(){}[]\\,./+-)(:\"", "\n", "#return [chr(x) for x in range(128*10)]", "\n", "    ", "return", "[", "chr", "(", "x", ")", "for", "x", "in", "range", "(", "2048", "*", "20", ")", "]", "\n", "#return [chr(x) for x in range(2048, 2048+1024)]", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_file": [[36, 41], ["open", "open.write"], "function", ["None"], ["", "def", "get_file", "(", "outfile", ")", ":", "\n", "    ", "global", "file_headers", "\n", "final", "=", "open", "(", "outfile", ",", "\"w\"", ")", "\n", "final", ".", "write", "(", "\",\"", ".", "join", "(", "file_headers", ")", "+", "\"\\n\"", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_task": [[43, 75], ["torch.hub.load.cuda", "torch.hub.load.eval", "torch.hub.load", "fairseq.models.roberta.RobertaModel.from_pretrained", "fairseq.models.transformer.TransformerModel.from_pretrained", "fairseq.models.transformer.TransformerModel.from_pretrained", "torch.hub.load"], "function", ["None"], ["", "def", "get_task", "(", "task", ")", ":", "\n", "    ", "global", "userdir", "\n", "\n", "if", "task", "in", "[", "\"wsc\"", ",", "\"mnli\"", "]", ":", "\n", "        ", "model", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq'", ",", "f'roberta.large.{task}'", ",", "\n", "user_dir", "=", "f\"{userdir}\"", ")", "\n", "", "elif", "task", "==", "\"cola\"", ":", "\n", "        ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "\n", "'language_models/checkpoints/'", ",", "\n", "checkpoint_file", "=", "'checkpoint_best.pt'", ",", "\n", "data_name_or_path", "=", "'language_models/CoLA-bin'", "\n", ")", "\n", "", "elif", "task", "==", "\"wmt18\"", ":", "\n", "        ", "model", "=", "TransformerModel", ".", "from_pretrained", "(", "f'{userdir}/wmt18ensemble/'", ",", "\n", "checkpoint_file", "=", "'wmt18.model1.pt:wmt18.model2.pt:wmt18.model3.pt:wmt18.model4.pt'", ",", "\n", "tokenizer", "=", "'moses'", ",", "bpe", "=", "'fastbpe'", ")", "\n", "", "elif", "task", "==", "\"wmt19\"", ":", "\n", "        ", "model", "=", "TransformerModel", ".", "from_pretrained", "(", "f'{userdir}/wmt19.en-ru.ensemble/'", ",", "\n", "checkpoint_file", "=", "'model1.pt:model2.pt:model3.pt:model4.pt'", ",", "\n", "tokenizer", "=", "'moses'", ",", "bpe", "=", "'fastbpe'", ")", "\n", "", "elif", "task", "in", "[", "\"wmt14\"", ",", "\"wmt16\"", "]", ":", "\n", "        ", "if", "task", "==", "\"wmt16\"", ":", "lang", "=", "\"en-de\"", "\n", "elif", "task", "==", "\"wmt14\"", ":", "lang", "=", "\"en-fr\"", "\n", "\n", "model", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq'", ",", "f'transformer.{task}.{lang}'", ",", "tokenizer", "=", "'moses'", ",", "bpe", "=", "'subword_nmt'", ",", "force_reload", "=", "False", ",", "user_dir", "=", "userdir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "f\"I dont task: {task}\"", "\n", "\n", "", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.write_to_file": [[76, 116], ["a", "a", "a", "sorted", "_f.write", "_f.flush", "numpy.array", "sorted", "sorted", "float", "int", "zip", "int", "zip", "int", "f", "f", "f", "f", "f", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.median", "numpy.std", "numpy.mean", "numpy.std", "len", "len", "len"], "function", ["None"], ["", "def", "write_to_file", "(", "_f", ",", "epoch", ",", "scores", ",", "energies", ",", "times", ",", "ga", ")", ":", "\n", "\n", "    ", "a", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ")", "\n", "\n", "scores", "=", "a", "(", "scores", ")", "\n", "energies", "=", "a", "(", "energies", ")", "\n", "times", "=", "a", "(", "times", ")", "\n", "\n", "mask", "=", "(", "scores", "!=", "0", ")", "\n", "\n", "scores", "=", "scores", "[", "mask", "]", "\n", "energies", "=", "energies", "[", "mask", "]", "\n", "times", "=", "times", "[", "mask", "]", "\n", "\n", "scores_sorted", "=", "sorted", "(", "scores", ")", "\n", "scores_sorted", "=", "scores_sorted", "[", "-", "int", "(", "0.1", "*", "len", "(", "mask", ")", ")", ":", "]", "\n", "\n", "eng_sorted", "=", "[", "x", "for", "_", ",", "x", "in", "sorted", "(", "zip", "(", "scores", ",", "\n", "energies", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "eng_sorted", "=", "eng_sorted", "[", "-", "int", "(", "0.1", "*", "len", "(", "mask", ")", ")", ":", "]", "\n", "\n", "times_sorted", "=", "[", "x", "for", "_", ",", "x", "in", "sorted", "(", "zip", "(", "scores", ",", "\n", "times", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "times_sorted", "=", "times_sorted", "[", "-", "int", "(", "0.1", "*", "len", "(", "mask", ")", ")", ":", "]", "\n", "\n", "\n", "f", "=", "lambda", "x", ":", "(", "float", "(", "x", ")", "/", "1.0e+9", ")", "\n", "\n", "_f", ".", "write", "(", "\n", "f\"{epoch}, {f(np.mean(scores))}, {f(np.median(scores))},\"", "\n", "f\"{f(np.std(scores))}, {f(np.mean(scores_sorted))},\"", "\n", "f\"{f(np.std(scores_sorted))}, \"", "\n", "\n", "f\"{np.mean(energies)}, \"", "\n", "f\"{np.mean(eng_sorted)}, \"", "\n", "\n", "f\"{np.mean(times)}, \"", "\n", "f\"{np.mean(times_sorted)}\\n\"", "\n", ")", "\n", "_f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_inference": [[117, 130], ["model.disambiguate_pronoun", "model.predict().argmax().item", "model.predict().argmax().item", "model.predict().argmax", "model.translate", "model.predict().argmax", "model.predict", "utils.mnli_sent_split", "model.predict", "model.encode"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.disambiguate_pronoun", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.mnli_sent_split"], ["", "def", "get_inference", "(", "model", ",", "task", ")", ":", "\n", "    ", "if", "task", "==", "\"wsc\"", ":", "\n", "        ", "return", "lambda", "x", ":", "model", ".", "disambiguate_pronoun", "(", "x", "+", "\" [they] \"", ")", "\n", "", "elif", "task", "==", "\"mnli\"", ":", "\n", "        ", "return", "lambda", "x", ":", "model", ".", "predict", "(", "'mnli'", ",", "\n", "mnli_sent_split", "(", "model", ",", "x", ")", ")", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "", "elif", "task", "==", "\"cola\"", ":", "\n", "        ", "return", "lambda", "x", ":", "model", ".", "predict", "(", "'sentence_classification_head'", ",", "\n", "model", ".", "encode", "(", "x", ")", ")", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "", "elif", "task", "in", "[", "\"wmt14\"", ",", "\"wmt16\"", ",", "\"wmt19\"", ",", "\"wmt18\"", "]", ":", "\n", "        ", "return", "lambda", "x", ":", "model", ".", "translate", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "raise", "f\"Unknown inference task: {task}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.mnli_sent_split": [[131, 139], ["model.encode", "type", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "mnli_sent_split", "(", "model", ",", "word", ")", ":", "\n", "    ", "if", "type", "(", "word", ")", "==", "tuple", ":", "\n", "        ", "sent1", ",", "sent2", "=", "word", "[", "0", "]", ",", "word", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "half1", ",", "half2", "=", "word", "[", ":", "len", "(", "word", ")", "//", "2", "]", ",", "word", "[", "len", "(", "word", ")", "//", "2", ":", "]", "\n", "sent1", ",", "sent2", "=", "half1", "[", ":", "len", "(", "half1", ")", "//", "2", "]", "+", "half2", "[", ":", "len", "(", "half2", ")", "//", "2", "]", ",", "half1", "[", "len", "(", "half1", ")", "//", "2", ":", "]", "+", "half2", "[", "len", "(", "half2", ")", "//", "2", ":", "]", "\n", "", "tokens", "=", "model", ".", "encode", "(", "sent1", ",", "sent2", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.get_naturals": [[141, 193], ["wsc.wsc_utils.jsonl_iterator", "sentence.index", "sentences.append", "len", "open", "fin.readline", "enumerate", "task.startswith", "line.strip().split", "sentences.append", "open", "fin.readline", "len", "line.strip().split", "sentences.append", "open", "line.strip", "len", "line.strip", "numpy.random.randint", "sentences.append", "line.strip", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.jsonl_iterator"], ["", "def", "get_naturals", "(", "pool_size", ",", "task", ",", "input_size", ")", ":", "\n", "    ", "global", "userdir", "\n", "\n", "sentences", "=", "[", "]", "\n", "if", "task", "==", "\"wsc\"", ":", "\n", "        ", "for", "sentence", ",", "label", "in", "wsc_utils", ".", "jsonl_iterator", "(", "f'{userdir}/WSC/val.jsonl'", ",", "eval", "=", "True", ")", ":", "\n", "\n", "#sentences.append(sentence)", "\n", "            ", "inx_e", "=", "sentence", ".", "index", "(", "\"]\"", ")", "\n", "sentences", ".", "append", "(", "sentence", "[", "inx_e", "-", "input_size", ":", "inx_e", "+", "1", "]", ")", "\n", "\n", "if", "len", "(", "sentences", ")", "==", "pool_size", ":", "\n", "                ", "break", "\n", "", "", "", "elif", "task", "==", "\"mnli\"", ":", "\n", "        ", "with", "open", "(", "f'{userdir}/glue_data/MNLI/dev_matched.tsv'", ")", "as", "fin", ":", "\n", "            ", "fin", ".", "readline", "(", ")", "\n", "for", "index", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "                ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sent1", ",", "sent2", ",", "target", "=", "tokens", "[", "8", "]", ",", "tokens", "[", "9", "]", ",", "tokens", "[", "-", "1", "]", "\n", "\n", "sentences", ".", "append", "(", "(", "sent1", "[", ":", "input_size", "//", "2", "]", ",", "sent2", "[", ":", "input_size", "//", "2", "]", ")", ")", "\n", "\n", "if", "len", "(", "sentences", ")", "==", "pool_size", ":", "\n", "                    ", "break", "\n", "", "", "", "", "elif", "task", "==", "\"cola\"", ":", "\n", "        ", "with", "open", "(", "f'{userdir}/glue_data/CoLA/dev.tsv'", ")", "as", "fin", ":", "\n", "            ", "fin", ".", "readline", "(", ")", "\n", "for", "line", "in", "fin", ":", "\n", "                ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sent", "=", "tokens", "[", "-", "1", "]", "\n", "\n", "sentences", ".", "append", "(", "sent", "[", ":", "input_size", "]", ")", "\n", "\n", "if", "len", "(", "sentences", ")", "==", "pool_size", ":", "\n", "                    ", "break", "\n", "", "", "", "", "elif", "task", ".", "startswith", "(", "\"wmt\"", ")", ":", "\n", "        ", "with", "open", "(", "f'{userdir}/wmt14data/newsdev2014.en'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "sent", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "sent", ")", "<", "input_size", ":", "\n", "                    ", "continue", "\n", "\n", "", "rnd", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "sent", ")", "-", "input_size", ")", "\n", "\n", "sentences", ".", "append", "(", "sent", "[", "rnd", ":", "rnd", "+", "input_size", "]", ")", "\n", "\n", "if", "len", "(", "sentences", ")", "==", "pool_size", ":", "\n", "                    ", "break", "\n", "", "", "", "", "else", ":", "\n", "        ", "raise", "f\"I cant find naturals for task {task}\"", "\n", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.eval_pass": [[195, 223], ["stats.__reset__", "time.time", "time.time", "pynvml.nvmlDeviceGetTotalEnergyConsumption", "ga.get_cpu_reading", "inference", "pynvml.nvmlDeviceGetTotalEnergyConsumption", "ga.get_cpu_reading", "print"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.StatsRecorder.__reset__", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.get_cpu_reading", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.ga.get_cpu_reading"], ["", "def", "eval_pass", "(", "inference", ",", "word", ",", "stats", ",", "handle", ",", "dev", "=", "\"gpu\"", ")", ":", "\n", "    ", "stats", ".", "__reset__", "(", ")", "\n", "\n", "\n", "if", "dev", "==", "\"gpu\"", ":", "\n", "        ", "before_energy", "=", "pynvml", ".", "nvmlDeviceGetTotalEnergyConsumption", "(", "handle", ")", "\n", "", "else", ":", "\n", "        ", "before_energy", "=", "get_cpu_reading", "(", ")", "\n", "\n", "", "before_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "prediction", "=", "inference", "(", "word", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "e", ")", "\n", "#Misaligned pronoun here and ValueError", "\n", "return", "0", ",", "0", ",", "None", "\n", "\n", "", "after_time", "=", "time", ".", "time", "(", ")", "\n", "if", "dev", "==", "\"gpu\"", ":", "\n", "        ", "after_energy", "=", "pynvml", ".", "nvmlDeviceGetTotalEnergyConsumption", "(", "handle", ")", "\n", "", "else", ":", "\n", "        ", "after_energy", "=", "get_cpu_reading", "(", ")", "\n", "\n", "", "time_delta", "=", "after_time", "-", "before_time", "\n", "energy_delta", "=", "after_energy", "-", "before_energy", "\n", "\n", "return", "energy_delta", ",", "time_delta", ",", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_up": [[225, 233], ["energy_estimator.add_hooks", "task.startswith", "energy_estimator.add_hooks"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.add_hooks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.add_hooks"], ["", "def", "hook_up", "(", "model", ",", "stats", ",", "task", ")", ":", "\n", "    ", "if", "task", "in", "[", "\"wsc\"", ",", "\"cola\"", ",", "\"mnli\"", "]", ":", "\n", "        ", "stat_hooks", "=", "simul", ".", "add_hooks", "(", "model", ".", "model", ",", "stats", ")", "\n", "", "elif", "task", ".", "startswith", "(", "\"wmt\"", ")", ":", "\n", "        ", "stat_hooks", "=", "simul", ".", "add_hooks", "(", "model", ".", "models", "[", "0", "]", ",", "stats", ")", "\n", "", "else", ":", "\n", "        ", "raise", "\"Not sure how to hook up the model\"", "\n", "", "return", "stat_hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.language_models.utils.hook_down": [[234, 236], ["energy_estimator.remove_hooks"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.remove_hooks"], ["", "def", "hook_down", "(", "stat_hooks", ")", ":", "\n", "    ", "simul", ".", "remove_hooks", "(", "stat_hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.Net.__init__": [[17, 27], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Dropout2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_outputs", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ic", ",", "ih", ",", "iw", "=", "input_shape", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "ic", ",", "256", ",", "3", ",", "1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "1", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "1", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout2d", "(", "0.5", ")", "\n", "self", ".", "pool", "=", "torch", ".", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "256", ",", "128", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "128", ",", "num_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.Net.forward": [[28, 41], ["images_energy_estimator.Net.conv1", "torch.nn.functional.relu", "images_energy_estimator.Net.conv2", "torch.nn.functional.relu", "images_energy_estimator.Net.conv3", "torch.nn.functional.relu", "images_energy_estimator.Net.pool", "torch.flatten", "images_energy_estimator.Net.fc1", "torch.nn.functional.relu", "images_energy_estimator.Net.dropout1", "images_energy_estimator.Net.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "return", "self", ".", "fc2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.get_trainable_image": [[43, 48], ["torch.from_numpy().float", "torch.nn.Parameter", "torch.from_numpy"], "function", ["None"], ["", "", "def", "get_trainable_image", "(", "image", ")", ":", "\n", "# take original image in numpy format, this image should have been preprocessed", "\n", "    ", "tensor_image", "=", "torch", ".", "from_numpy", "(", "image", ")", ".", "float", "(", ")", "\n", "tensor_image", "=", "torch", ".", "nn", ".", "Parameter", "(", "tensor_image", ",", "requires_grad", "=", "True", ")", "\n", "return", "tensor_image", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.compute_loss": [[50, 52], ["torch.sum", "torch.abs"], "function", ["None"], ["", "def", "compute_loss", "(", "output", ",", "target", ")", ":", "\n", "    ", "return", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "output", "-", "target", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.compute_loss_no_abs": [[54, 56], ["torch.sum"], "function", ["None"], ["", "def", "compute_loss_no_abs", "(", "output", ",", "target", ")", ":", "\n", "    ", "return", "torch", ".", "sum", "(", "output", "-", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.renorm": [[58, 60], ["torch.clamp"], "function", ["None"], ["", "def", "renorm", "(", "image", ",", "min_value", "=", "0.0", ",", "max_value", "=", "1.0", ")", ":", "\n", "    ", "return", "torch", ".", "clamp", "(", "image", ",", "min_value", ",", "max_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.score_me": [[61, 80], ["energy_estimator.add_hooks", "enumerate", "print", "energy_estimator.remove_hooks", "stats.__reset__", "model", "energy_estimator.get_energy_estimate", "energy_estimator.get_energy_estimate", "reses.append", "print", "dat.unsqueeze"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.add_hooks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.remove_hooks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.StatsRecorder.__reset__", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate"], ["", "def", "score_me", "(", "datas", ",", "model", ",", "hardware", ",", "hardware_worst", ",", "stats", ")", ":", "\n", "\n", "    ", "reses", "=", "[", "]", "\n", "\n", "hooks", "=", "simul", ".", "add_hooks", "(", "model", ",", "stats", ")", "\n", "\n", "for", "i", ",", "dat", "in", "enumerate", "(", "datas", ")", ":", "\n", "        ", "stats", ".", "__reset__", "(", ")", "\n", "_", "=", "model", "(", "dat", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", "\n", "energy_est", "=", "simul", ".", "get_energy_estimate", "(", "stats", ",", "hardware", ")", "\n", "energy_est_worst", "=", "simul", ".", "get_energy_estimate", "(", "stats", ",", "hardware_worst", ")", "\n", "rs", "=", "energy_est", "/", "energy_est_worst", "\n", "reses", ".", "append", "(", "rs", ")", "\n", "print", "(", "f\"{i} {rs}\"", ",", "end", "=", "\"\\r\"", ")", "\n", "", "print", "(", ")", "\n", "\n", "simul", ".", "remove_hooks", "(", "hooks", ")", "\n", "\n", "return", "reses", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.build_dataset": [[81, 126], ["torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "energy_estimator.HardwareModel", "energy_estimator.HardwareModel", "energy_estimator.StatsRecorder", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "train_data_x.to.to", "train_data_x.to.to", "print", "torch.Tensor", "torch.Tensor", "print", "pickle.dump", "torch.no_grad", "images_energy_estimator.score_me", "images_energy_estimator.score_me", "open"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.score_me", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.score_me"], ["", "def", "build_dataset", "(", "\n", "train_data_x", "=", "None", ",", "train_data_y", "=", "None", ",", "\n", "test_data_x", "=", "None", ",", "test_data_y", "=", "None", ",", "random", "=", "False", ",", "model", "=", "None", ",", "\n", "random_shape", "=", "(", "1", ",", "28", ",", "28", ")", ",", "savename", "=", "None", ",", "gpu", "=", "None", ")", ":", "\n", "# better provide train_data_x and test_data_x as post-transformation images", "\n", "\n", "    ", "if", "random", ":", "\n", "        ", "hardware", "=", "simul", ".", "HardwareModel", "(", "optim", "=", "True", ")", "\n", "hardware_worst", "=", "simul", ".", "HardwareModel", "(", "optim", "=", "False", ")", "\n", "stats", "=", "simul", ".", "StatsRecorder", "(", ")", "\n", "\n", "train_data_x", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "rand", "(", "5000", ",", "*", "random_shape", ")", ")", "\n", "test_data_x", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "rand", "(", "100", ",", "*", "random_shape", ")", ")", "\n", "\n", "train_data_y", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "rand", "(", "5000", ",", "1", ")", ")", "\n", "test_data_y", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ")", ")", "\n", "\n", "if", "gpu", "is", "not", "None", ":", "\n", "            ", "train_data_x", "=", "train_data_x", ".", "to", "(", "gpu", ")", "\n", "test_data_x", "=", "train_data_x", ".", "to", "(", "gpu", ")", "\n", "\n", "", "if", "model", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "train_data_y", "=", "score_me", "(", "train_data_x", ",", "model", ",", "hardware", ",", "\n", "hardware_worst", ",", "stats", ")", "\n", "test_data_y", "=", "score_me", "(", "test_data_x", ",", "model", ",", "hardware", ",", "\n", "hardware_worst", ",", "stats", ")", "\n", "", "print", "(", ")", "\n", "\n", "train_data_y", "=", "torch", ".", "Tensor", "(", "train_data_y", ")", "\n", "test_data_y", "=", "torch", ".", "Tensor", "(", "test_data_y", ")", "\n", "\n", "", "if", "savename", "is", "not", "None", ":", "\n", "            ", "print", "(", "f\"Saving to {savename} ... \"", ")", "\n", "pickle", ".", "dump", "(", "[", "train_data_x", ",", "train_data_y", ",", "test_data_x", ",", "test_data_y", "]", ",", "\n", "open", "(", "savename", ",", "\"wb\"", ")", ")", "\n", "\n", "# train loader", "\n", "", "", "dataset", "=", "data", ".", "TensorDataset", "(", "train_data_x", ",", "train_data_y", ")", "\n", "train_dataloader", "=", "data", ".", "DataLoader", "(", "dataset", ")", "\n", "\n", "# test loader", "\n", "dataset", "=", "data", ".", "TensorDataset", "(", "test_data_x", ",", "test_data_y", ")", "\n", "test_dataloader", "=", "data", ".", "DataLoader", "(", "dataset", ")", "\n", "return", "(", "train_dataloader", ",", "test_dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.build_adversarial_image": [[128, 148], ["model.eval", "range", "numpy.random.rand", "torch.Tensor", "images_energy_estimator.get_trainable_image", "model", "images_energy_estimator.compute_loss_no_abs", "compute_loss_no_abs.backward", "images_energy_estimator.renorm", "renorm.detach().numpy", "numpy.random.rand", "renorm.detach"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.get_trainable_image", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.compute_loss_no_abs", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.renorm"], ["", "def", "build_adversarial_image", "(", "\n", "image", ",", "label", ",", "model", ",", "iterations", "=", "10", ",", "alpha", "=", "0.01", ",", "random", "=", "False", ")", ":", "\n", "    ", "if", "random", ":", "\n", "        ", "image", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "label", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "rand", "(", "1", ")", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "numpy_image", "=", "image", "\n", "for", "i", "in", "range", "(", "iterations", ")", ":", "\n", "        ", "tensor_image", "=", "get_trainable_image", "(", "numpy_image", ")", "\n", "tensor_image", ".", "grad", "=", "None", "\n", "pred", "=", "model", "(", "tensor_image", ")", "\n", "loss_with_sign", "=", "compute_loss_no_abs", "(", "pred", ",", "label", ")", "\n", "loss_with_sign", ".", "backward", "(", ")", "\n", "# ascending on gradients", "\n", "adv_noise", "=", "alpha", "*", "tensor_image", ".", "grad", ".", "data", "\n", "tensor_image", "=", "tensor_image", "-", "adv_noise", "\n", "# renorm input", "\n", "tensor_image", "=", "renorm", "(", "tensor_image", ")", "\n", "numpy_image", "=", "tensor_image", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "image", ",", "tensor_image", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.train": [[151, 165], ["model.train", "enumerate", "print", "optimizer.zero_grad", "model", "images_energy_estimator.compute_loss", "compute_loss.backward", "optimizer.step", "torch.utils.data.to", "target.to", "print", "len", "compute_loss.item", "len", "len"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.train", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.compute_loss"], ["", "def", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "compute_loss", "(", "output", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "batch_idx", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "len", "(", "data", ")", ",", "len", "(", "train_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "batch_idx", "/", "len", "(", "train_loader", ")", ",", "loss", ".", "item", "(", ")", ")", ",", "end", "=", "\"\\r\"", ")", "\n", "", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.test": [[167, 179], ["model.eval", "len", "print", "torch.no_grad", "model", "compute_loss().item", "torch.utils.data.to", "target.to", "images_energy_estimator.compute_loss"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.compute_loss"], ["", "def", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "test_loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "test_loss", "+=", "compute_loss", "(", "output", ",", "target", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "\n", "", "", "test_loss", "/=", "len", "(", "test_loader", ".", "dataset", ")", "\n", "print", "(", "'\\nTest set: Average loss: {:.4f} \\n'", ".", "format", "(", "test_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.main": [[181, 237], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.device", "Net().to", "torch.optim.Adadelta", "images_energy_estimator.build_dataset", "torch.optim.lr_scheduler.StepLR", "range", "images_energy_estimator.build_adversarial_image", "Net().to.eval", "time.time", "Net().to.", "time.time", "torch.cuda.is_available", "Net().to.parameters", "images_energy_estimator.train", "images_energy_estimator.test", "torch.optim.lr_scheduler.StepLR.step", "torch.save", "images_energy_estimator.Net", "Net().to.state_dict"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.build_dataset", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.build_adversarial_image", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.train", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.images_energy_estimator.test"], ["", "def", "main", "(", ")", ":", "\n", "# Training settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Energy Estimator'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for training (default: 64)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-batch-size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of epochs to train (default: 14)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'learning rate (default: 1.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'Learning rate step gamma (default: 0.7)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disables CUDA training'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'S'", ",", "\n", "help", "=", "'random seed (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'how many batches to wait before logging training status'", ")", "\n", "parser", ".", "add_argument", "(", "'--load-model'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'For Loading the current Model'", ")", "\n", "parser", ".", "add_argument", "(", "'--save-model'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'For Saving the current Model'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "use_cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "\n", "\n", "model", "=", "Net", "(", "\n", "(", "1", ",", "28", ",", "28", ")", ",", "\n", "1", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "optim", ".", "Adadelta", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "train_loader", ",", "test_loader", "=", "build_dataset", "(", "random", "=", "True", ",", "model", "=", "model", ")", "\n", "\n", "scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "1", ",", "gamma", "=", "args", ".", "gamma", ")", "\n", "# testing enabled", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# testing enabled", "\n", "", "org_image", ",", "adv_image", "=", "build_adversarial_image", "(", "None", ",", "None", ",", "model", ",", "random", "=", "True", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "res", "=", "model", "(", "org_image", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "args", ".", "save_model", ":", "\n", "        ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"checkpoints/image_energy_est.pt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.HardwareModel.__init__": [[19, 38], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optim", "=", "True", ")", ":", "\n", "# Cost of a single memory access in pJ.", "\n", "# ASSUMPTION: DRAM costs dominate (on-chip caches are negligible).", "\n", "# ASSUMPTION: reads and writes cost the same.", "\n", "        ", "self", ".", "memory_cost", "=", "1950.0", "\n", "\n", "# Cost of a single computation (e.g. multiply) in pJ.", "\n", "# ASSUMPTION: all computations cost the same amount.", "\n", "self", ".", "compute_cost", "=", "3.7", "\n", "\n", "# Is the hardware able to optimise memory access for sparse data?", "\n", "# ASSUMPTION: there is no overhead to (de)compression.", "\n", "self", ".", "compress_sparse_weights", "=", "optim", "\n", "self", ".", "compress_sparse_activations", "=", "optim", "\n", "\n", "# Is the hardware able to skip computations when one input is zero?", "\n", "# ASSUMPTION: zeros are uniformly distributed throughout the data.", "\n", "self", ".", "compute_skip_zero_weights", "=", "optim", "\n", "self", ".", "compute_skip_zero_activations", "=", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.StatsRecorder.__init__": [[104, 118], ["float", "len", "x.abs"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "bitwidth", "=", "32", ")", ":", "\n", "        ", "self", ".", "total_input_activations", "=", "0.0", "\n", "self", ".", "non_zero_input_activations", "=", "0.0", "\n", "self", ".", "total_output_activations", "=", "0.0", "\n", "self", ".", "non_zero_output_activations", "=", "0.0", "\n", "self", ".", "total_parameters", "=", "0.0", "\n", "self", ".", "non_zero_parameters", "=", "0.0", "\n", "self", ".", "computations", "=", "0.0", "\n", "\n", "if", "bitwidth", "not", "in", "bitwidth_to_minvalue", ":", "\n", "            ", "raise", "\"Passed bitwidth is not supported\"", "\n", "", "self", ".", "min_value", "=", "bitwidth_to_minvalue", "[", "bitwidth", "]", "\n", "self", ".", "nonzero_func", "=", "lambda", "x", ":", "float", "(", "len", "(", "(", "x", ".", "abs", "(", ")", ">", "self", ".", "min_value", ")", ".", "nonzero", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.StatsRecorder.__reset__": [[119, 124], ["analyse.StatsRecorder.__init__"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__init__"], ["", "def", "__reset__", "(", "self", ")", ":", "\n", "        ", "del", "self", ".", "total_input_activations", ",", "self", ".", "non_zero_input_activations", "\n", "del", "self", ".", "total_output_activations", ",", "self", ".", "non_zero_output_activations", "\n", "del", "self", ".", "total_parameters", ",", "self", ".", "non_zero_parameters", ",", "self", ".", "computations", "\n", "self", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.analyse": [[40, 65], ["analyse.HardwareModel", "analyse.StatsRecorder", "analyse.add_hooks", "model", "analyse.remove_hooks", "analyse.get_energy_estimate", "print"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.add_hooks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.remove_hooks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate"], ["", "", "def", "analyse", "(", "model", ",", "input_data", ",", "hardware", "=", "HardwareModel", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n    Estimate how much energy will be consumed by applying a given model to the\n    given data.\n\n    :param model: a torch.nn.Module to be analysed.\n    :param input_data: a torch.Tensor to be passed through the model.\n    :param hardware: a HardwareModel representing the processor on which the\n                     model will be executed.\n    :return: the estimated number of picojoules consumed.\n    \"\"\"", "\n", "stats", "=", "StatsRecorder", "(", ")", "\n", "\n", "# Prepare the model for analysis.", "\n", "hooks", "=", "add_hooks", "(", "model", ",", "stats", ")", "\n", "\n", "# Send the data through the model.", "\n", "_", "=", "model", "(", "input_data", ")", "\n", "\n", "# Clean up.", "\n", "remove_hooks", "(", "hooks", ")", "\n", "\n", "energy", "=", "get_energy_estimate", "(", "stats", ",", "hardware", ")", "\n", "print", "(", "energy", ",", "\"pJ\"", ")", "\n", "return", "energy", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.add_hooks": [[67, 91], ["analyse.record_stats", "module.register_forward_hook", "hooks.append", "model.modules", "len", "list", "module.children"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.record_stats"], ["", "def", "add_hooks", "(", "model", ",", "stats", ")", ":", "\n", "    ", "\"\"\"\n    Prepare a model for analysis.\n\n    Intercept computation in each leaf node of the network, and collect data\n    on the amount of data accessed and computation performed.\n\n    ASSUMPTION: nothing significant happens in modules which contain other\n    modules. Only leaf modules are analysed.\n\n    :param model: a torch.nn.Module to be analysed.\n    :param stats: a StatsRecorder into which the results will be stored.\n    \"\"\"", "\n", "hooks", "=", "[", "]", "\n", "\n", "leaf_nodes", "=", "[", "module", "for", "module", "in", "model", ".", "modules", "(", ")", "\n", "if", "len", "(", "list", "(", "module", ".", "children", "(", ")", ")", ")", "==", "0", "]", "\n", "\n", "stat_fn", "=", "record_stats", "(", "stats", ")", "\n", "for", "module", "in", "leaf_nodes", ":", "\n", "        ", "hook", "=", "module", ".", "register_forward_hook", "(", "stat_fn", ")", "\n", "hooks", ".", "append", "(", "hook", ")", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.remove_hooks": [[93, 101], ["hook.remove"], "function", ["None"], ["", "def", "remove_hooks", "(", "hooks", ")", ":", "\n", "    ", "\"\"\"\n    Remove hooks from a model.\n\n    :param hooks: an Iterable containing hooks to be removed.\n    \"\"\"", "\n", "for", "hook", "in", "hooks", ":", "\n", "        ", "hook", ".", "remove", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.get_energy_estimate": [[125, 164], ["None"], "function", ["None"], ["", "", "def", "get_energy_estimate", "(", "stats", ",", "hw", ")", ":", "\n", "    ", "\"\"\"\n    Estimate the energy consumption in picojoules of a given computation on\n    given hardware.\n\n    ASSUMPTIONS:\n    * Weights are read from DRAM exactly once.\n    * Input activations are read from DRAM exactly once.\n    * Output activations are written to DRAM exactly once.\n\n    :param stats: a StatsRecorder containing details of the computation.\n    :param hw: a HardwareModel containing details of the processor.\n    \"\"\"", "\n", "total", "=", "0.0", "\n", "\n", "if", "hw", ".", "compress_sparse_weights", ":", "\n", "        ", "total", "+=", "hw", ".", "memory_cost", "*", "stats", ".", "non_zero_parameters", "\n", "", "else", ":", "\n", "        ", "total", "+=", "hw", ".", "memory_cost", "*", "stats", ".", "total_parameters", "\n", "\n", "", "if", "hw", ".", "compress_sparse_activations", ":", "\n", "        ", "total", "+=", "hw", ".", "memory_cost", "*", "(", "stats", ".", "non_zero_input_activations", "+", "\n", "stats", ".", "non_zero_output_activations", ")", "\n", "", "else", ":", "\n", "        ", "total", "+=", "hw", ".", "memory_cost", "*", "(", "stats", ".", "total_input_activations", "+", "\n", "stats", ".", "total_output_activations", ")", "\n", "\n", "", "compute_fraction", "=", "1.0", "\n", "\n", "if", "hw", ".", "compute_skip_zero_weights", ":", "\n", "        ", "compute_fraction", "*=", "(", "stats", ".", "non_zero_parameters", "/", "stats", ".", "total_parameters", ")", "\n", "\n", "", "if", "hw", ".", "compute_skip_zero_activations", ":", "\n", "        ", "compute_fraction", "*=", "(", "stats", ".", "non_zero_input_activations", "/", "\n", "stats", ".", "total_input_activations", ")", "\n", "\n", "", "total", "+=", "compute_fraction", "*", "stats", ".", "computations", "*", "hw", ".", "compute_cost", "\n", "\n", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.energy_estimator.analyse.record_stats": [[165, 287], ["isinstance", "isinstance", "module.buffers", "module.parameters", "isinstance", "analyse.record_stats.hook_fn"], "function", ["None"], ["", "def", "record_stats", "(", "stats", ")", ":", "\n", "    ", "\"\"\"\n    Create a forward hook function which will record information about a layer's\n    execution.\n\n    For all module parameters/buffers, in_data and out_data, record:\n    * Number of values\n    * Number of non-zeros\n    Also estimate amount of computation (depends on layer type).\n\n    :param stats: a StatsRecorder to store results in.\n    :return: forward hook function.\n    \"\"\"", "\n", "\n", "def", "hook_fn", "(", "nonzero_func", ",", "module", ",", "in_data", ",", "out_data", ")", ":", "\n", "# Activations are sometimes Tensors, and sometimes tuples of Tensors.", "\n", "# Ensure we're always dealing with tuples.", "\n", "        ", "if", "isinstance", "(", "in_data", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "in_data", "=", "(", "in_data", ",", ")", "\n", "", "if", "isinstance", "(", "out_data", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "out_data", "=", "(", "out_data", ",", ")", "\n", "\n", "# Collect memory statistics.", "\n", "", "for", "tensor", "in", "in_data", ":", "\n", "            ", "stats", ".", "total_input_activations", "+=", "tensor", ".", "numel", "(", ")", "\n", "stats", ".", "non_zero_input_activations", "+=", "nonzero_func", "(", "tensor", ")", "\n", "\n", "", "for", "tensor", "in", "out_data", ":", "\n", "            ", "stats", ".", "total_output_activations", "+=", "tensor", ".", "numel", "(", ")", "\n", "stats", ".", "non_zero_output_activations", "+=", "nonzero_func", "(", "tensor", ")", "\n", "\n", "", "for", "tensor", "in", "module", ".", "buffers", "(", ")", ":", "\n", "            ", "stats", ".", "total_parameters", "+=", "tensor", ".", "numel", "(", ")", "\n", "stats", ".", "non_zero_parameters", "+=", "nonzero_func", "(", "tensor", ")", "\n", "\n", "", "for", "tensor", "in", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "stats", ".", "total_parameters", "+=", "tensor", ".", "numel", "(", ")", "\n", "stats", ".", "non_zero_parameters", "+=", "nonzero_func", "(", "tensor", ")", "\n", "\n", "# Collect computation statistics.", "\n", "", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "AdaptiveAvgPool2d", ")", ":", "\n", "# One computation per input pixel - window size is chosen adaptively", "\n", "# and windows never overlap (?).", "\n", "            ", "assert", "len", "(", "in_data", ")", "==", "1", "\n", "input_size", "=", "in_data", "[", "0", "]", ".", "numel", "(", ")", "\n", "stats", ".", "computations", "+=", "input_size", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Embedding", ")", ":", "\n", "            ", "stats", ".", "total_parameters", "+=", "module", ".", "embedding_dim", "*", "in_data", "[", "0", "]", ".", "numel", "(", ")", "\n", "stats", ".", "non_zero_parameters", "+=", "nonzero_func", "(", "out_data", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "fairseq", ".", "modules", ".", "sinusoidal_positional_embedding", ".", "SinusoidalPositionalEmbedding", ")", ":", "\n", "#stats.total_parameters += module.embedding_dim * in_data[0].numel()", "\n", "#stats.non_zero_parameters += len(out_data[0].nonzero())", "\n", "            ", "pass", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "AvgPool2d", ")", "or", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "MaxPool2d", ")", ":", "\n", "# Each output pixel requires computations on a 2D window of input.", "\n", "            ", "if", "type", "(", "module", ".", "kernel_size", ")", "==", "int", ":", "\n", "# Kernel size here can be either a single int for square kernel", "\n", "# or a tuple (see", "\n", "# https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d )", "\n", "                ", "window_size", "=", "module", ".", "kernel_size", "**", "2", "\n", "", "else", ":", "\n", "                ", "window_size", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "\n", "\n", "# Not sure which output tensor to use if there are multiple of them.", "\n", "", "assert", "len", "(", "out_data", ")", "==", "1", "\n", "output_size", "=", "out_data", "[", "0", "]", ".", "numel", "(", ")", "\n", "stats", ".", "computations", "+=", "output_size", "*", "window_size", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Conv2d", ")", ":", "\n", "# Each output pixel requires computations on a 3D window of input.", "\n", "# Not sure which input tensor to use if there are multiple of them.", "\n", "            ", "assert", "len", "(", "in_data", ")", "==", "1", "\n", "_", ",", "channels", ",", "_", ",", "_", "=", "in_data", "[", "0", "]", ".", "size", "(", ")", "\n", "window_size", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "*", "channels", "\n", "\n", "# Not sure which output tensor to use if there are multiple of them.", "\n", "assert", "len", "(", "out_data", ")", "==", "1", "\n", "output_size", "=", "out_data", "[", "0", "]", ".", "numel", "(", ")", "\n", "\n", "stats", ".", "computations", "+=", "output_size", "*", "window_size", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Dropout2d", ")", "or", "isinstance", "(", "module", ",", "\n", "torch", ".", "nn", ".", "modules", ".", "dropout", ".", "Dropout", ")", ":", "\n", "# Do nothing - dropout has no effect during inference.", "\n", "            ", "pass", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "# One computation per weight, for each batch element.", "\n", "\n", "# Not sure which input tensor to use if there are multiple of them.", "\n", "            ", "assert", "len", "(", "in_data", ")", "==", "1", "\n", "batch", "=", "in_data", "[", "0", "]", ".", "numel", "(", ")", "/", "in_data", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "stats", ".", "computations", "+=", "module", ".", "weight", ".", "numel", "(", ")", "*", "batch", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "activation", ".", "ReLU", ")", "or", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "activation", ".", "ReLU6", ")", ":", "\n", "# ReLU does a single negation check", "\n", "            ", "pass", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "LayerNorm", ")", ":", "\n", "# You first compute", "\n", "            ", "pass", "\n", "\n", "", "elif", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm2d", ")", ":", "\n", "\n", "# Accesses to E[x] and Var[x] (all channel size)", "\n", "\n", "            ", "stats", ".", "total_parameters", "+=", "2", "*", "module", ".", "num_features", "\n", "stats", ".", "non_zero_parameters", "+=", "nonzero_func", "(", "module", ".", "running_mean", ")", "+", "nonzero_func", "(", "module", ".", "running_var", ")", "\n", "\n", "# (x-running_mean)/running variance", "\n", "# multiply by gamma and beta addition", "\n", "stats", ".", "computations", "+=", "4", "*", "in_data", "[", "0", "]", ".", "numel", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Unsupported module type for energy analysis:\"", ",", "type", "(", "module", ")", ")", "\n", "\n", "", "", "return", "lambda", "*", "x", ":", "hook_fn", "(", "stats", ".", "nonzero_func", ",", "*", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.add_args": [[36, 43], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "'data'", ",", "metavar", "=", "'DIR'", ",", "\n", "help", "=", "'path to data directory; we load <split>.jsonl'", ")", "\n", "parser", ".", "add_argument", "(", "'--init-token'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'add token at the beginning of each batch item'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.__init__": [[44, 59], ["fairseq.tasks.FairseqTask.__init__", "vocab.add_symbol", "fairseq.data.encoders.build_bpe", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "vocab", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "mask", "=", "vocab", ".", "add_symbol", "(", "'<mask>'", ")", "\n", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "\n", "# hack to handle GPT-2 BPE, which includes leading spaces", "\n", "if", "args", ".", "bpe", "==", "'gpt2'", ":", "\n", "            ", "self", ".", "leading_space", "=", "True", "\n", "self", ".", "trailing_space", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "leading_space", "=", "False", "\n", "self", ".", "trailing_space", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.load_dictionary": [[60, 70], ["fairseq.data.Dictionary.load", "fairseq.data.Dictionary.load.add_symbol"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "filename", ")", "\n", "dictionary", ".", "add_symbol", "(", "'<mask>'", ")", "\n", "return", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.setup_task": [[71, 80], ["cls.load_dictionary", "print", "cls", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.load_dictionary"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "args", ".", "criterion", "==", "'wsc'", ",", "'Must set --criterion=wsc'", "\n", "\n", "# load data and label dictionaries", "\n", "vocab", "=", "cls", ".", "load_dictionary", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "'dict.txt'", ")", ")", "\n", "print", "(", "'| dictionary: {} types'", ".", "format", "(", "len", "(", "vocab", ")", ")", ")", "\n", "\n", "return", "cls", "(", "args", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize": [[81, 92], ["wsc_task.WSCTask.vocab.encode_line().long", "wsc_task.WSCTask.tokenizer.encode", "wsc_task.WSCTask.bpe.encode", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "wsc_task.WSCTask.vocab.encode_line", "torch.cat.new", "torch.cat.new"], "methods", ["None"], ["", "def", "binarize", "(", "self", ",", "s", ":", "str", ",", "append_eos", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "s", "=", "self", ".", "tokenizer", ".", "encode", "(", "s", ")", "\n", "", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "s", "=", "self", ".", "bpe", ".", "encode", "(", "s", ")", "\n", "", "tokens", "=", "self", ".", "vocab", ".", "encode_line", "(", "\n", "s", ",", "append_eos", "=", "append_eos", ",", "add_if_not_exist", "=", "False", ",", "\n", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "args", ".", "init_token", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "torch", ".", "cat", "(", "[", "tokens", ".", "new", "(", "[", "self", ".", "args", ".", "init_token", "]", ")", ",", "tokens", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize_with_mask": [[93, 103], ["wsc_task.WSCTask.binarize", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "len", "len", "wsc_task.WSCTask.binarize", "wsc_task.WSCTask.binarize"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize"], ["", "def", "binarize_with_mask", "(", "self", ",", "txt", ",", "prefix", ",", "suffix", ",", "leading_space", ",", "trailing_space", ")", ":", "\n", "        ", "toks", "=", "self", ".", "binarize", "(", "\n", "prefix", "+", "leading_space", "+", "txt", "+", "trailing_space", "+", "suffix", ",", "\n", "append_eos", "=", "True", ",", "\n", ")", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "toks", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "mask_start", "=", "len", "(", "self", ".", "binarize", "(", "prefix", ")", ")", "\n", "mask_size", "=", "len", "(", "self", ".", "binarize", "(", "leading_space", "+", "txt", ")", ")", "\n", "mask", "[", "mask_start", ":", "mask_start", "+", "mask_size", "]", "=", "1", "\n", "return", "toks", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.load_dataset": [[104, 210], ["wsc_utils.jsonl_iterator", "numpy.array", "fairseq.data.ListDataset", "fairseq.data.ListDataset", "numpy.array", "fairseq.data.ListDataset", "fairseq.data.ListDataset", "fairseq.data.ListDataset", "fairseq.data.NestedDictionaryDataset", "fairseq.data.SortDataset", "os.path.join", "os.path.exists", "FileNotFoundError", "wsc_utils.filter_noun_chunks", "fairseq.data.ListDataset.append", "fairseq.data.ListDataset.append", "numpy.array.append", "fairseq.data.data_utils.collate_tokens", "fairseq.data.data_utils.collate_tokens", "fairseq.data.ListDataset.append", "fairseq.data.ListDataset.append", "numpy.array.append", "fairseq.data.ListDataset.append", "fairseq.data.IdDataset", "fairseq.data.NumSamplesDataset", "fairseq.data.NumelDataset", "fairseq.data.data_utils.numpy_seed", "numpy.random.permutation", "sentence[].text_with_ws.endswith", "pronoun_span.text_with_ws.endswith", "wsc_utils.extended_noun_chunks", "wsc_task.WSCTask.binarize_with_mask", "len", "wsc_task.WSCTask.binarize_with_mask", "fairseq.data.data_utils.collate_tokens.append", "fairseq.data.data_utils.collate_tokens.append", "fairseq.data.data_utils.collate_tokens.size", "fairseq.data.data_utils.collate_tokens.size", "fairseq.data.data_utils.collate_tokens.size", "len", "len", "wsc_task.WSCTask.vocab.pad"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.jsonl_iterator", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.filter_noun_chunks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.extended_noun_chunks", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize_with_mask", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.binarize_with_mask"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "data_path", "=", "None", ",", "return_only", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "if", "data_path", "is", "None", ":", "\n", "            ", "data_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "split", "+", "'.jsonl'", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "data_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "'Cannot find data: {}'", ".", "format", "(", "data_path", ")", ")", "\n", "\n", "", "query_tokens", "=", "[", "]", "\n", "query_masks", "=", "[", "]", "\n", "query_lengths", "=", "[", "]", "\n", "candidate_tokens", "=", "[", "]", "\n", "candidate_masks", "=", "[", "]", "\n", "candidate_lengths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "for", "sentence", ",", "pronoun_span", ",", "query", ",", "label", "in", "wsc_utils", ".", "jsonl_iterator", "(", "data_path", ")", ":", "\n", "            ", "prefix", "=", "sentence", "[", ":", "pronoun_span", ".", "start", "]", ".", "text", "\n", "suffix", "=", "sentence", "[", "pronoun_span", ".", "end", ":", "]", ".", "text_with_ws", "\n", "\n", "# spaCy spans include trailing spaces, but we need to know about", "\n", "# leading spaces for the GPT-2 BPE", "\n", "leading_space", "=", "' '", "if", "sentence", "[", ":", "pronoun_span", ".", "start", "]", ".", "text_with_ws", ".", "endswith", "(", "' '", ")", "else", "''", "\n", "trailing_space", "=", "' '", "if", "pronoun_span", ".", "text_with_ws", ".", "endswith", "(", "' '", ")", "else", "''", "\n", "\n", "# get noun phrases, excluding pronouns and anything overlapping with the query", "\n", "cand_spans", "=", "wsc_utils", ".", "filter_noun_chunks", "(", "\n", "wsc_utils", ".", "extended_noun_chunks", "(", "sentence", ")", ",", "\n", "exclude_pronouns", "=", "True", ",", "\n", "exclude_query", "=", "query", ",", "\n", "exact_match", "=", "False", ",", "\n", ")", "\n", "\n", "if", "query", "is", "not", "None", ":", "\n", "                ", "query_toks", ",", "query_mask", "=", "self", ".", "binarize_with_mask", "(", "\n", "query", ",", "prefix", ",", "suffix", ",", "leading_space", ",", "trailing_space", "\n", ")", "\n", "query_len", "=", "len", "(", "query_toks", ")", "\n", "", "else", ":", "\n", "                ", "query_toks", ",", "query_mask", ",", "query_len", "=", "None", ",", "None", ",", "0", "\n", "\n", "", "query_tokens", ".", "append", "(", "query_toks", ")", "\n", "query_masks", ".", "append", "(", "query_mask", ")", "\n", "query_lengths", ".", "append", "(", "query_len", ")", "\n", "\n", "cand_toks", ",", "cand_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "cand_span", "in", "cand_spans", ":", "\n", "                ", "toks", ",", "mask", "=", "self", ".", "binarize_with_mask", "(", "\n", "cand_span", ".", "text", ",", "prefix", ",", "suffix", ",", "leading_space", ",", "trailing_space", ",", "\n", ")", "\n", "cand_toks", ".", "append", "(", "toks", ")", "\n", "cand_masks", ".", "append", "(", "mask", ")", "\n", "\n", "# collate candidates", "\n", "", "cand_toks", "=", "data_utils", ".", "collate_tokens", "(", "cand_toks", ",", "pad_idx", "=", "self", ".", "vocab", ".", "pad", "(", ")", ")", "\n", "cand_masks", "=", "data_utils", ".", "collate_tokens", "(", "cand_masks", ",", "pad_idx", "=", "0", ")", "\n", "assert", "cand_toks", ".", "size", "(", ")", "==", "cand_masks", ".", "size", "(", ")", "\n", "\n", "candidate_tokens", ".", "append", "(", "cand_toks", ")", "\n", "candidate_masks", ".", "append", "(", "cand_masks", ")", "\n", "candidate_lengths", ".", "append", "(", "cand_toks", ".", "size", "(", "1", ")", ")", "\n", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "query_lengths", "=", "np", ".", "array", "(", "query_lengths", ")", "\n", "query_tokens", "=", "ListDataset", "(", "query_tokens", ",", "query_lengths", ")", "\n", "query_masks", "=", "ListDataset", "(", "query_masks", ",", "query_lengths", ")", "\n", "\n", "candidate_lengths", "=", "np", ".", "array", "(", "candidate_lengths", ")", "\n", "candidate_tokens", "=", "ListDataset", "(", "candidate_tokens", ",", "candidate_lengths", ")", "\n", "candidate_masks", "=", "ListDataset", "(", "candidate_masks", ",", "candidate_lengths", ")", "\n", "\n", "labels", "=", "ListDataset", "(", "labels", ",", "[", "1", "]", "*", "len", "(", "labels", ")", ")", "\n", "\n", "dataset", "=", "{", "\n", "'id'", ":", "IdDataset", "(", ")", ",", "\n", "'query_tokens'", ":", "query_tokens", ",", "\n", "'query_masks'", ":", "query_masks", ",", "\n", "'candidate_tokens'", ":", "candidate_tokens", ",", "\n", "'candidate_masks'", ":", "candidate_masks", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'nsentences'", ":", "NumSamplesDataset", "(", ")", ",", "\n", "'ntokens'", ":", "NumelDataset", "(", "query_tokens", ",", "reduce", "=", "True", ")", ",", "\n", "}", "\n", "\n", "nested_dataset", "=", "NestedDictionaryDataset", "(", "\n", "dataset", ",", "\n", "sizes", "=", "[", "query_lengths", "]", ",", "\n", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "query_tokens", ")", ")", "\n", "", "dataset", "=", "SortDataset", "(", "\n", "nested_dataset", ",", "\n", "# shuffle", "\n", "sort_order", "=", "[", "shuffle", "]", ",", "\n", ")", "\n", "\n", "if", "return_only", ":", "\n", "            ", "return", "dataset", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "dataset", "\n", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.build_dataset_for_inference": [[211, 220], ["tempfile.NamedTemporaryFile", "h.write", "wsc_task.WSCTask.load_dataset", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WinograndeTask.load_dataset"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "sample_json", ")", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "buffering", "=", "0", ")", "as", "h", ":", "\n", "            ", "h", ".", "write", "(", "(", "json", ".", "dumps", "(", "sample_json", ")", "+", "'\\n'", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "dataset", "=", "self", ".", "load_dataset", "(", "\n", "'disambiguate_pronoun'", ",", "\n", "data_path", "=", "h", ".", "name", ",", "\n", "return_only", "=", "True", ",", "\n", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.disambiguate_pronoun": [[221, 257], ["wsc_utils.convert_sentence_to_json", "wsc_task.WSCTask.build_dataset_for_inference", "wsc_task.WSCTask.collater", "wsc_task.WSCTask.disambiguate_pronoun.get_lprobs"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.convert_sentence_to_json", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.build_dataset_for_inference", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs"], ["", "def", "disambiguate_pronoun", "(", "self", ",", "model", ",", "sentence", ",", "use_cuda", "=", "False", ")", ":", "\n", "        ", "sample_json", "=", "wsc_utils", ".", "convert_sentence_to_json", "(", "sentence", ")", "\n", "dataset", "=", "self", ".", "build_dataset_for_inference", "(", "sample_json", ")", "\n", "sample", "=", "dataset", ".", "collater", "(", "[", "dataset", "[", "0", "]", "]", ")", "\n", "if", "use_cuda", ":", "\n", "            ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "\n", "\n", "", "def", "get_masked_input", "(", "tokens", ",", "mask", ")", ":", "\n", "            ", "masked_tokens", "=", "tokens", ".", "clone", "(", ")", "\n", "masked_tokens", "[", "mask", ".", "bool", "(", ")", "]", "=", "self", ".", "mask", "\n", "return", "masked_tokens", "\n", "\n", "", "def", "get_lprobs", "(", "tokens", ",", "mask", ")", ":", "\n", "            ", "logits", ",", "_", "=", "model", "(", "src_tokens", "=", "get_masked_input", "(", "tokens", ",", "mask", ")", ")", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "scores", "=", "lprobs", ".", "gather", "(", "2", ",", "tokens", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "mask", "=", "mask", ".", "type_as", "(", "scores", ")", "\n", "scores", "=", "(", "scores", "*", "mask", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "return", "scores", "\n", "\n", "", "cand_lprobs", "=", "get_lprobs", "(", "\n", "sample", "[", "'candidate_tokens'", "]", "[", "0", "]", ",", "\n", "sample", "[", "'candidate_masks'", "]", "[", "0", "]", ",", "\n", ")", "\n", "if", "sample", "[", "'query_tokens'", "]", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "query_lprobs", "=", "get_lprobs", "(", "\n", "sample", "[", "'query_tokens'", "]", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "sample", "[", "'query_masks'", "]", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", ")", "\n", "return", "(", "query_lprobs", ">=", "cand_lprobs", ")", ".", "all", "(", ")", ".", "item", "(", ")", "==", "1", "\n", "", "else", ":", "\n", "            ", "best_idx", "=", "cand_lprobs", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "full_cand", "=", "sample", "[", "'candidate_tokens'", "]", "[", "0", "]", "[", "best_idx", "]", "\n", "mask", "=", "sample", "[", "'candidate_masks'", "]", "[", "0", "]", "[", "best_idx", "]", "\n", "toks", "=", "full_cand", "[", "mask", ".", "bool", "(", ")", "]", "\n", "return", "self", ".", "bpe", ".", "decode", "(", "self", ".", "source_dictionary", ".", "string", "(", "toks", ")", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.source_dictionary": [[258, 261], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.target_dictionary": [[262, 265], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WinograndeTask.setup_task": [[274, 283], ["cls.load_dictionary", "print", "cls", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WSCTask.load_dictionary"], ["@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "args", ".", "criterion", "==", "'winogrande'", ",", "'Must set --criterion=winogrande'", "\n", "\n", "# load data and label dictionaries", "\n", "vocab", "=", "cls", ".", "load_dictionary", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "'dict.txt'", ")", ")", "\n", "print", "(", "'| dictionary: {} types'", ".", "format", "(", "len", "(", "vocab", ")", ")", ")", "\n", "\n", "return", "cls", "(", "args", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_task.WinograndeTask.load_dataset": [[284, 376], ["wsc_utils.winogrande_jsonl_iterator", "numpy.array", "wsc_task.WinograndeTask.load_dataset.get_pad_dataset_fn"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.winogrande_jsonl_iterator"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "data_path", "=", "None", ",", "return_only", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "if", "data_path", "is", "None", ":", "\n", "            ", "data_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "split", "+", "'.jsonl'", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "data_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "'Cannot find data: {}'", ".", "format", "(", "data_path", ")", ")", "\n", "\n", "", "query_tokens", "=", "[", "]", "\n", "query_masks", "=", "[", "]", "\n", "query_lengths", "=", "[", "]", "\n", "candidate_tokens", "=", "[", "]", "\n", "candidate_masks", "=", "[", "]", "\n", "candidate_lengths", "=", "[", "]", "\n", "\n", "itr", "=", "wsc_utils", ".", "winogrande_jsonl_iterator", "(", "data_path", ",", "eval", "=", "(", "split", "==", "'test'", ")", ")", "\n", "\n", "for", "sample", "in", "itr", ":", "\n", "            ", "sentence", ",", "pronoun_span", ",", "query", ",", "cand_text", "=", "sample", "\n", "prefix", "=", "sentence", "[", ":", "pronoun_span", "[", "0", "]", "]", ".", "rstrip", "(", ")", "\n", "suffix", "=", "sentence", "[", "pronoun_span", "[", "1", "]", ":", "]", "\n", "\n", "leading_space", "=", "' '", "if", "sentence", "[", ":", "pronoun_span", "[", "0", "]", "]", ".", "endswith", "(", "' '", ")", "else", "''", "\n", "trailing_space", "=", "''", "\n", "\n", "if", "query", "is", "not", "None", ":", "\n", "                ", "query_toks", ",", "query_mask", "=", "self", ".", "binarize_with_mask", "(", "\n", "query", ",", "prefix", ",", "suffix", ",", "leading_space", ",", "trailing_space", ",", "\n", ")", "\n", "query_len", "=", "len", "(", "query_toks", ")", "\n", "", "else", ":", "\n", "                ", "query_toks", ",", "query_mask", ",", "query_len", "=", "None", ",", "None", ",", "0", "\n", "\n", "", "query_tokens", ".", "append", "(", "query_toks", ")", "\n", "query_masks", ".", "append", "(", "query_mask", ")", "\n", "query_lengths", ".", "append", "(", "query_len", ")", "\n", "\n", "cand_toks", ",", "cand_mask", "=", "self", ".", "binarize_with_mask", "(", "\n", "cand_text", ",", "prefix", ",", "suffix", ",", "leading_space", ",", "trailing_space", ",", "\n", ")", "\n", "\n", "candidate_tokens", ".", "append", "(", "cand_toks", ")", "\n", "candidate_masks", ".", "append", "(", "cand_mask", ")", "\n", "candidate_lengths", ".", "append", "(", "cand_toks", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "query_lengths", "=", "np", ".", "array", "(", "query_lengths", ")", "\n", "\n", "def", "get_pad_dataset_fn", "(", "tokens", ",", "length", ",", "pad_idx", ")", ":", "\n", "            ", "return", "PadDataset", "(", "\n", "ListDataset", "(", "tokens", ",", "length", ")", ",", "\n", "pad_idx", "=", "pad_idx", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", "\n", "\n", "", "query_tokens", "=", "get_pad_dataset_fn", "(", "query_tokens", ",", "query_lengths", ",", "self", ".", "vocab", ".", "pad", "(", ")", ")", "\n", "query_masks", "=", "get_pad_dataset_fn", "(", "query_masks", ",", "query_lengths", ",", "0", ")", "\n", "\n", "candidate_lengths", "=", "np", ".", "array", "(", "candidate_lengths", ")", "\n", "candidate_tokens", "=", "get_pad_dataset_fn", "(", "candidate_tokens", ",", "candidate_lengths", ",", "self", ".", "vocab", ".", "pad", "(", ")", ")", "\n", "candidate_masks", "=", "get_pad_dataset_fn", "(", "candidate_masks", ",", "candidate_lengths", ",", "0", ")", "\n", "\n", "dataset", "=", "{", "\n", "'id'", ":", "IdDataset", "(", ")", ",", "\n", "'query_tokens'", ":", "query_tokens", ",", "\n", "'query_masks'", ":", "query_masks", ",", "\n", "'candidate_tokens'", ":", "candidate_tokens", ",", "\n", "'candidate_masks'", ":", "candidate_masks", ",", "\n", "'nsentences'", ":", "NumSamplesDataset", "(", ")", ",", "\n", "'ntokens'", ":", "NumelDataset", "(", "query_tokens", ",", "reduce", "=", "True", ")", ",", "\n", "}", "\n", "\n", "nested_dataset", "=", "NestedDictionaryDataset", "(", "\n", "dataset", ",", "\n", "sizes", "=", "[", "query_lengths", "]", ",", "\n", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "query_tokens", ")", ")", "\n", "", "dataset", "=", "SortDataset", "(", "\n", "nested_dataset", ",", "\n", "# shuffle", "\n", "sort_order", "=", "[", "shuffle", "]", ",", "\n", ")", "\n", "\n", "if", "return_only", ":", "\n", "            ", "return", "dataset", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "dataset", "\n", "return", "self", ".", "datasets", "[", "split", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.convert_sentence_to_json": [[10, 32], ["sentence.replace().replace().replace.split", "rest.split", "len", "sentence.replace().replace().replace.replace().replace().replace", "sentence.replace().replace().replace.split", "rest.split", "len", "prefix.rstrip().split", "prefix.rstrip().split", "sentence.replace().replace().replace.replace().replace", "prefix.rstrip", "prefix.rstrip", "sentence.replace().replace().replace.replace"], "function", ["None"], ["def", "convert_sentence_to_json", "(", "sentence", ")", ":", "\n", "    ", "if", "'_'", "in", "sentence", ":", "\n", "        ", "prefix", ",", "rest", "=", "sentence", ".", "split", "(", "'_'", ",", "1", ")", "\n", "query", ",", "rest", "=", "rest", ".", "split", "(", "'_'", ",", "1", ")", "\n", "query_index", "=", "len", "(", "prefix", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "else", ":", "\n", "        ", "query", ",", "query_index", "=", "None", ",", "None", "\n", "\n", "", "prefix", ",", "rest", "=", "sentence", ".", "split", "(", "'['", ",", "1", ")", "\n", "pronoun", ",", "rest", "=", "rest", ".", "split", "(", "']'", ",", "1", ")", "\n", "pronoun_index", "=", "len", "(", "prefix", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", ")", "\n", "\n", "sentence", "=", "sentence", ".", "replace", "(", "'_'", ",", "''", ")", ".", "replace", "(", "'['", ",", "''", ")", ".", "replace", "(", "']'", ",", "''", ")", "\n", "\n", "return", "{", "\n", "'idx'", ":", "0", ",", "\n", "'text'", ":", "sentence", ",", "\n", "'target'", ":", "{", "\n", "'span1_index'", ":", "query_index", ",", "\n", "'span1_text'", ":", "query", ",", "\n", "'span2_index'", ":", "pronoun_index", ",", "\n", "'span2_text'", ":", "pronoun", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.extended_noun_chunks": [[36, 50], ["enumerate", "noun_chunks.add", "sorted", "noun_chunks.add", "len"], "function", ["None"], ["", "def", "extended_noun_chunks", "(", "sentence", ")", ":", "\n", "    ", "noun_chunks", "=", "{", "(", "np", ".", "start", ",", "np", ".", "end", ")", "for", "np", "in", "sentence", ".", "noun_chunks", "}", "\n", "np_start", ",", "cur_np", "=", "0", ",", "'NONE'", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "sentence", ")", ":", "\n", "        ", "np_type", "=", "token", ".", "pos_", "if", "token", ".", "pos_", "in", "{", "'NOUN'", ",", "'PROPN'", "}", "else", "'NONE'", "\n", "if", "np_type", "!=", "cur_np", ":", "\n", "            ", "if", "cur_np", "!=", "'NONE'", ":", "\n", "                ", "noun_chunks", ".", "add", "(", "(", "np_start", ",", "i", ")", ")", "\n", "", "if", "np_type", "!=", "'NONE'", ":", "\n", "                ", "np_start", "=", "i", "\n", "", "cur_np", "=", "np_type", "\n", "", "", "if", "cur_np", "!=", "'NONE'", ":", "\n", "        ", "noun_chunks", ".", "add", "(", "(", "np_start", ",", "len", "(", "sentence", ")", ")", ")", "\n", "", "return", "[", "sentence", "[", "s", ":", "e", "]", "for", "(", "s", ",", "e", ")", "in", "sorted", "(", "noun_chunks", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.find_token": [[52, 59], ["None"], "function", ["None"], ["", "def", "find_token", "(", "sentence", ",", "start_pos", ")", ":", "\n", "    ", "found_tok", "=", "None", "\n", "for", "tok", "in", "sentence", ":", "\n", "        ", "if", "tok", ".", "idx", "==", "start_pos", ":", "\n", "            ", "found_tok", "=", "tok", "\n", "break", "\n", "", "", "return", "found_tok", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.find_span": [[61, 74], ["search_text.lower.lower", "sentence[].text.lower", "sentence[].text.lower.startswith", "len", "len"], "function", ["None"], ["", "def", "find_span", "(", "sentence", ",", "search_text", ",", "start", "=", "0", ")", ":", "\n", "    ", "search_text", "=", "search_text", ".", "lower", "(", ")", "\n", "for", "tok", "in", "sentence", "[", "start", ":", "]", ":", "\n", "        ", "remainder", "=", "sentence", "[", "tok", ".", "i", ":", "]", ".", "text", ".", "lower", "(", ")", "\n", "if", "remainder", ".", "startswith", "(", "search_text", ")", ":", "\n", "            ", "len_to_consume", "=", "len", "(", "search_text", ")", "\n", "start_idx", "=", "tok", ".", "idx", "\n", "for", "next_tok", "in", "sentence", "[", "tok", ".", "i", ":", "]", ":", "\n", "                ", "end_idx", "=", "next_tok", ".", "idx", "+", "len", "(", "next_tok", ".", "text", ")", "\n", "if", "end_idx", "-", "start_idx", "==", "len_to_consume", ":", "\n", "                    ", "span", "=", "sentence", "[", "tok", ".", "i", ":", "next_tok", ".", "i", "+", "1", "]", "\n", "return", "span", "\n", "", "", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.get_detokenizer": [[76, 81], ["functools.lru_cache", "MosesDetokenizer"], "function", ["None"], ["", "@", "lru_cache", "(", "maxsize", "=", "1", ")", "\n", "def", "get_detokenizer", "(", ")", ":", "\n", "    ", "from", "sacremoses", "import", "MosesDetokenizer", "\n", "detok", "=", "MosesDetokenizer", "(", "lang", "=", "'en'", ")", "\n", "return", "detok", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.get_spacy_nlp": [[83, 88], ["functools.lru_cache", "en_core_web_lg.load"], "function", ["None"], ["", "@", "lru_cache", "(", "maxsize", "=", "1", ")", "\n", "def", "get_spacy_nlp", "(", ")", ":", "\n", "    ", "import", "en_core_web_lg", "\n", "nlp", "=", "en_core_web_lg", ".", "load", "(", ")", "\n", "return", "nlp", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.jsonl_iterator": [[90, 191], ["wsc_utils.get_detokenizer", "wsc_utils.get_spacy_nlp", "open", "json.loads", "sample[].split", "wsc_utils.jsonl_iterator.strip_pronoun"], "function", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.get_detokenizer", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.get_spacy_nlp"], ["", "def", "jsonl_iterator", "(", "input_fname", ",", "positive_only", "=", "False", ",", "ngram_order", "=", "3", ",", "eval", "=", "False", ")", ":", "\n", "    ", "detok", "=", "get_detokenizer", "(", ")", "\n", "nlp", "=", "get_spacy_nlp", "(", ")", "\n", "\n", "with", "open", "(", "input_fname", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "sample", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "if", "positive_only", "and", "'label'", "in", "sample", "and", "not", "sample", "[", "'label'", "]", ":", "\n", "# only consider examples where the query is correct", "\n", "                ", "continue", "\n", "\n", "", "target", "=", "sample", "[", "'target'", "]", "\n", "\n", "# clean up the query", "\n", "query", "=", "target", "[", "'span1_text'", "]", "\n", "if", "query", "is", "not", "None", ":", "\n", "                ", "if", "'\\n'", "in", "query", ":", "\n", "                    ", "continue", "\n", "", "if", "query", ".", "endswith", "(", "'.'", ")", "or", "query", ".", "endswith", "(", "','", ")", ":", "\n", "                    ", "query", "=", "query", "[", ":", "-", "1", "]", "\n", "\n", "# split tokens", "\n", "", "", "tokens", "=", "sample", "[", "'text'", "]", ".", "split", "(", "' '", ")", "\n", "\n", "def", "strip_pronoun", "(", "x", ")", ":", "\n", "                ", "return", "x", ".", "rstrip", "(", "'.,\"'", ")", "\n", "\n", "# find the pronoun", "\n", "", "pronoun_idx", "=", "target", "[", "'span2_index'", "]", "\n", "pronoun", "=", "strip_pronoun", "(", "target", "[", "'span2_text'", "]", ")", "\n", "if", "strip_pronoun", "(", "tokens", "[", "pronoun_idx", "]", ")", "!=", "pronoun", ":", "\n", "# hack: sometimes the index is misaligned", "\n", "                ", "if", "strip_pronoun", "(", "tokens", "[", "pronoun_idx", "+", "1", "]", ")", "==", "pronoun", ":", "\n", "                    ", "pronoun_idx", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Misaligned pronoun!'", ")", "\n", "", "", "assert", "strip_pronoun", "(", "tokens", "[", "pronoun_idx", "]", ")", "==", "pronoun", "\n", "\n", "# split tokens before and after the pronoun", "\n", "before", "=", "tokens", "[", ":", "pronoun_idx", "]", "\n", "after", "=", "tokens", "[", "pronoun_idx", "+", "1", ":", "]", "\n", "\n", "# the GPT BPE attaches leading spaces to tokens, so we keep track", "\n", "# of whether we need spaces before or after the pronoun", "\n", "leading_space", "=", "' '", "if", "pronoun_idx", ">", "0", "else", "''", "\n", "trailing_space", "=", "' '", "if", "len", "(", "after", ")", ">", "0", "else", "''", "\n", "\n", "# detokenize", "\n", "before", "=", "detok", ".", "detokenize", "(", "before", ",", "return_str", "=", "True", ")", "\n", "pronoun", "=", "detok", ".", "detokenize", "(", "[", "pronoun", "]", ",", "return_str", "=", "True", ")", "\n", "after", "=", "detok", ".", "detokenize", "(", "after", ",", "return_str", "=", "True", ")", "\n", "\n", "# hack: when the pronoun ends in a period (or comma), move the", "\n", "# punctuation to the \"after\" part", "\n", "if", "pronoun", ".", "endswith", "(", "'.'", ")", "or", "pronoun", ".", "endswith", "(", "','", ")", ":", "\n", "                ", "after", "=", "pronoun", "[", "-", "1", "]", "+", "trailing_space", "+", "after", "\n", "pronoun", "=", "pronoun", "[", ":", "-", "1", "]", "\n", "\n", "# hack: when the \"after\" part begins with a comma or period, remove", "\n", "# the trailing space", "\n", "", "if", "after", ".", "startswith", "(", "'.'", ")", "or", "after", ".", "startswith", "(", "','", ")", ":", "\n", "                ", "trailing_space", "=", "''", "\n", "\n", "# parse sentence with spacy", "\n", "", "sentence", "=", "nlp", "(", "before", "+", "leading_space", "+", "pronoun", "+", "trailing_space", "+", "after", ")", "\n", "\n", "# find pronoun span", "\n", "start", "=", "len", "(", "before", "+", "leading_space", ")", "\n", "first_pronoun_tok", "=", "find_token", "(", "sentence", ",", "start_pos", "=", "start", ")", "\n", "pronoun_span", "=", "find_span", "(", "sentence", ",", "pronoun", ",", "start", "=", "first_pronoun_tok", ".", "i", ")", "\n", "assert", "pronoun_span", ".", "text", "==", "pronoun", "\n", "\n", "if", "eval", ":", "\n", "# convert to format where pronoun is surrounded by \"[]\" and", "\n", "# query is surrounded by \"_\"", "\n", "                ", "query_span", "=", "find_span", "(", "sentence", ",", "query", ")", "\n", "query_with_ws", "=", "'_{}_{}'", ".", "format", "(", "\n", "query_span", ".", "text", ",", "\n", "(", "' '", "if", "query_span", ".", "text_with_ws", ".", "endswith", "(", "' '", ")", "else", "''", ")", "\n", ")", "\n", "pronoun_with_ws", "=", "'[{}]{}'", ".", "format", "(", "\n", "pronoun_span", ".", "text", ",", "\n", "(", "' '", "if", "pronoun_span", ".", "text_with_ws", ".", "endswith", "(", "' '", ")", "else", "''", ")", "\n", ")", "\n", "if", "query_span", ".", "start", "<", "pronoun_span", ".", "start", ":", "\n", "                    ", "first", "=", "(", "query_span", ",", "query_with_ws", ")", "\n", "second", "=", "(", "pronoun_span", ",", "pronoun_with_ws", ")", "\n", "", "else", ":", "\n", "                    ", "first", "=", "(", "pronoun_span", ",", "pronoun_with_ws", ")", "\n", "second", "=", "(", "query_span", ",", "query_with_ws", ")", "\n", "", "sentence", "=", "(", "\n", "sentence", "[", ":", "first", "[", "0", "]", ".", "start", "]", ".", "text_with_ws", "\n", "+", "first", "[", "1", "]", "\n", "+", "sentence", "[", "first", "[", "0", "]", ".", "end", ":", "second", "[", "0", "]", ".", "start", "]", ".", "text_with_ws", "\n", "+", "second", "[", "1", "]", "\n", "+", "sentence", "[", "second", "[", "0", "]", ".", "end", ":", "]", ".", "text", "\n", ")", "\n", "yield", "sentence", ",", "sample", ".", "get", "(", "'label'", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "yield", "sentence", ",", "pronoun_span", ",", "query", ",", "sample", ".", "get", "(", "'label'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.winogrande_jsonl_iterator": [[193, 208], ["open", "json.loads", "line.strip", "sentence.index", "sentence.index"], "function", ["None"], ["", "", "", "", "def", "winogrande_jsonl_iterator", "(", "input_fname", ",", "eval", "=", "False", ")", ":", "\n", "    ", "with", "open", "(", "input_fname", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "sample", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "sentence", ",", "option1", ",", "option2", "=", "sample", "[", "'sentence'", "]", ",", "sample", "[", "'option1'", "]", ",", "sample", "[", "'option2'", "]", "\n", "\n", "pronoun_span", "=", "(", "sentence", ".", "index", "(", "'_'", ")", ",", "sentence", ".", "index", "(", "'_'", ")", "+", "1", ")", "\n", "\n", "if", "eval", ":", "\n", "                ", "query", ",", "cand", "=", "option1", ",", "option2", "\n", "", "else", ":", "\n", "                ", "query", "=", "option1", "if", "sample", "[", "'answer'", "]", "==", "'1'", "else", "option2", "\n", "cand", "=", "option2", "if", "sample", "[", "'answer'", "]", "==", "'1'", "else", "option1", "\n", "", "yield", "sentence", ",", "pronoun_span", ",", "query", ",", "cand", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_utils.filter_noun_chunks": [[210, 237], ["exclude_query.lower", "chunk.text.lower", "filtered_chunks.append", "all"], "function", ["None"], ["", "", "", "def", "filter_noun_chunks", "(", "chunks", ",", "exclude_pronouns", "=", "False", ",", "exclude_query", "=", "None", ",", "exact_match", "=", "False", ")", ":", "\n", "    ", "if", "exclude_pronouns", ":", "\n", "        ", "chunks", "=", "[", "\n", "np", "for", "np", "in", "chunks", "if", "(", "\n", "np", ".", "lemma_", "!=", "'-PRON-'", "\n", "and", "not", "all", "(", "tok", ".", "pos_", "==", "'PRON'", "for", "tok", "in", "np", ")", "\n", ")", "\n", "]", "\n", "\n", "", "if", "exclude_query", "is", "not", "None", ":", "\n", "        ", "excl_txt", "=", "[", "exclude_query", ".", "lower", "(", ")", "]", "\n", "filtered_chunks", "=", "[", "]", "\n", "for", "chunk", "in", "chunks", ":", "\n", "            ", "lower_chunk", "=", "chunk", ".", "text", ".", "lower", "(", ")", "\n", "found", "=", "False", "\n", "for", "excl", "in", "excl_txt", ":", "\n", "                ", "if", "(", "\n", "(", "not", "exact_match", "and", "(", "lower_chunk", "in", "excl", "or", "excl", "in", "lower_chunk", ")", ")", "\n", "or", "lower_chunk", "==", "excl", "\n", ")", ":", "\n", "                    ", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "                ", "filtered_chunks", ".", "append", "(", "chunk", ")", "\n", "", "", "chunks", "=", "filtered_chunks", "\n", "\n", "", "return", "chunks", "\n", "", ""]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__init__": [[19, 27], ["fairseq.criterions.FairseqCriterion.__init__", "fairseq.data.encoders.build_bpe", "fairseq.data.encoders.build_tokenizer", "open"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "task", ")", "\n", "if", "self", ".", "args", ".", "save_predictions", "is", "not", "None", ":", "\n", "            ", "self", ".", "prediction_h", "=", "open", "(", "self", ".", "args", ".", "save_predictions", ",", "'w'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "prediction_h", "=", "None", "\n", "", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.__del__": [[28, 31], ["wsc_criterion.WSCCriterion.prediction_h.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "prediction_h", "is", "not", "None", ":", "\n", "            ", "self", ".", "prediction_h", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.add_args": [[32, 41], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "'--wsc-margin-alpha'", ",", "type", "=", "float", ",", "metavar", "=", "'A'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--wsc-margin-beta'", ",", "type", "=", "float", ",", "metavar", "=", "'B'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--wsc-cross-entropy'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use cross entropy formulation instead of margin loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--save-predictions'", ",", "metavar", "=", "'FILE'", ",", "\n", "help", "=", "'file to save predictions to'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_masked_input": [[42, 46], ["tokens.clone"], "methods", ["None"], ["", "def", "get_masked_input", "(", "self", ",", "tokens", ",", "mask", ")", ":", "\n", "        ", "masked_tokens", "=", "tokens", ".", "clone", "(", ")", "\n", "masked_tokens", "[", "mask", "]", "=", "self", ".", "task", ".", "mask", "\n", "return", "masked_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs": [[47, 54], ["model", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather().squeeze", "mask.type_as.type_as.type_as", "mask.type_as.type_as.sum", "wsc_criterion.WSCCriterion.get_masked_input", "torch.log_softmax.gather", "tokens.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_masked_input"], ["", "def", "get_lprobs", "(", "self", ",", "model", ",", "tokens", ",", "mask", ")", ":", "\n", "        ", "logits", ",", "_", "=", "model", "(", "src_tokens", "=", "self", ".", "get_masked_input", "(", "tokens", ",", "mask", ")", ")", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "scores", "=", "lprobs", ".", "gather", "(", "2", ",", "tokens", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "mask", "=", "mask", ".", "type_as", "(", "scores", ")", "\n", "scores", "=", "(", "scores", "*", "mask", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_loss": [[55, 67], ["torch.cross_entropy", "torch.cross_entropy", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "query_lprobs.new().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "query_lprobs.new"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "query_lprobs", ",", "cand_lprobs", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "wsc_cross_entropy", ":", "\n", "            ", "return", "F", ".", "cross_entropy", "(", "\n", "torch", ".", "cat", "(", "[", "query_lprobs", ",", "cand_lprobs", "]", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "query_lprobs", ".", "new", "(", "[", "0", "]", ")", ".", "long", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "-", "query_lprobs", "\n", "+", "self", ".", "args", ".", "wsc_margin_alpha", "*", "(", "\n", "cand_lprobs", "-", "query_lprobs", "+", "self", ".", "args", ".", "wsc_margin_beta", "\n", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", ")", ".", "sum", "(", ")", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.forward": [[69, 115], ["enumerate", "wsc_criterion.WSCCriterion.get_lprobs", "wsc_criterion.WSCCriterion.get_lprobs", "[].item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "[].unsqueeze", "[].unsqueeze", "wsc_criterion.WSCCriterion.get_loss", "print", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_loss"], ["", "", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "# compute loss and accuracy", "\n", "        ", "loss", ",", "nloss", "=", "0.", ",", "0", "\n", "ncorrect", ",", "nqueries", "=", "0", ",", "0", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "sample", "[", "'labels'", "]", ")", ":", "\n", "            ", "query_lprobs", "=", "self", ".", "get_lprobs", "(", "\n", "model", ",", "\n", "sample", "[", "'query_tokens'", "]", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "sample", "[", "'query_masks'", "]", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", ")", "\n", "cand_lprobs", "=", "self", ".", "get_lprobs", "(", "\n", "model", ",", "\n", "sample", "[", "'candidate_tokens'", "]", "[", "i", "]", ",", "\n", "sample", "[", "'candidate_masks'", "]", "[", "i", "]", ",", "\n", ")", "\n", "\n", "pred", "=", "(", "query_lprobs", ">=", "cand_lprobs", ")", ".", "all", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "label", "is", "not", "None", ":", "\n", "                ", "label", "=", "1", "if", "label", "else", "0", "\n", "ncorrect", "+=", "1", "if", "pred", "==", "label", "else", "0", "\n", "nqueries", "+=", "1", "\n", "\n", "", "if", "label", ":", "\n", "# only compute a loss for positive instances", "\n", "                ", "nloss", "+=", "1", "\n", "loss", "+=", "self", ".", "get_loss", "(", "query_lprobs", ",", "cand_lprobs", ")", "\n", "\n", "", "id", "=", "sample", "[", "'id'", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "if", "self", ".", "prediction_h", "is", "not", "None", ":", "\n", "                ", "print", "(", "'{}\\t{}\\t{}'", ".", "format", "(", "id", ",", "pred", ",", "label", ")", ",", "file", "=", "self", ".", "prediction_h", ")", "\n", "\n", "", "", "if", "nloss", "==", "0", ":", "\n", "            ", "loss", "=", "torch", ".", "tensor", "(", "0.0", ",", "requires_grad", "=", "True", ")", "\n", "\n", "", "sample_size", "=", "nqueries", "if", "nqueries", ">", "0", "else", "1", "\n", "logging_output", "=", "{", "\n", "'loss'", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "'ntokens'", ":", "sample", "[", "'ntokens'", "]", ",", "\n", "'nsentences'", ":", "sample", "[", "'nsentences'", "]", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "'ncorrect'", ":", "ncorrect", ",", "\n", "'nqueries'", ":", "nqueries", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.aggregate_logging_outputs": [[116, 137], ["sum", "sum", "sum", "sum", "sum", "sum", "log.get", "log.get", "log.get", "log.get", "math.log", "log.get", "log.get", "float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "'loss'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "'ntokens'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "'nsentences'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "'sample_size'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "agg_output", "=", "{", "\n", "'loss'", ":", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "\n", "'ntokens'", ":", "ntokens", ",", "\n", "'nsentences'", ":", "nsentences", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "ncorrect", "=", "sum", "(", "log", ".", "get", "(", "'ncorrect'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nqueries", "=", "sum", "(", "log", ".", "get", "(", "'nqueries'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "if", "nqueries", ">", "0", ":", "\n", "            ", "agg_output", "[", "'accuracy'", "]", "=", "ncorrect", "/", "float", "(", "nqueries", ")", "\n", "\n", "", "return", "agg_output", "\n", "\n"]], "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WinograndeCriterion.forward": [[141, 167], ["wsc_criterion.WinograndeCriterion.get_lprobs", "wsc_criterion.WinograndeCriterion.get_lprobs", "wsc_criterion.WinograndeCriterion.get_loss", "sample[].size", "pred.sum().item", "pred.sum", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_lprobs", "home.repos.pwc.inspect_result.iliaishacked_sponge_examples.wsc.wsc_criterion.WSCCriterion.get_loss"], ["    ", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "# compute loss and accuracy", "\n", "        ", "query_lprobs", "=", "self", ".", "get_lprobs", "(", "\n", "model", ",", "\n", "sample", "[", "'query_tokens'", "]", ",", "\n", "sample", "[", "'query_masks'", "]", ",", "\n", ")", "\n", "cand_lprobs", "=", "self", ".", "get_lprobs", "(", "\n", "model", ",", "\n", "sample", "[", "'candidate_tokens'", "]", ",", "\n", "sample", "[", "'candidate_masks'", "]", ",", "\n", ")", "\n", "pred", "=", "query_lprobs", ">=", "cand_lprobs", "\n", "loss", "=", "self", ".", "get_loss", "(", "query_lprobs", ",", "cand_lprobs", ")", "\n", "\n", "sample_size", "=", "sample", "[", "'query_tokens'", "]", ".", "size", "(", "0", ")", "\n", "ncorrect", "=", "pred", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "logging_output", "=", "{", "\n", "'loss'", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "'ntokens'", ":", "sample", "[", "'ntokens'", "]", ",", "\n", "'nsentences'", ":", "sample", "[", "'nsentences'", "]", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "'ncorrect'", ":", "ncorrect", ",", "\n", "'nqueries'", ":", "sample_size", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "", "", ""]]}