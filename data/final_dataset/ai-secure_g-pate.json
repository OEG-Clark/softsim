{"home.repos.pwc.inspect_result.ai-secure_g-pate.None.dp_pca.ComputeDPPrincipalProjection": [[26, 61], ["sklearn.preprocessing.normalize", "numpy.matmul", "rdp_utils.gaussian_rdp", "numpy.linalg.eig", "numpy.reshape", "numpy.transpose", "np.matmul.reshape", "gaussian_noise.reshape", "numpy.transpose", "numpy.transpose", "eigvals.argsort", "numpy.take", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gaussian_rdp"], ["def", "ComputeDPPrincipalProjection", "(", "data", ",", "projection_dims", ",", "orders", ",", "sigma", ")", ":", "\n", "  ", "\"\"\"Compute differentially private projection.\n\n  Args:\n    data: the input data, each row is a data vector.\n    projection_dims: the projection dimension.\n    sigma: sigma for gaussian noise\n  Returns:\n    A projection matrix with projection_dims columns.\n  \"\"\"", "\n", "\n", "# Normalize each row.", "\n", "normalized_data", "=", "normalize", "(", "data", ",", "norm", "=", "'l2'", ",", "axis", "=", "1", ")", "\n", "covar", "=", "np", ".", "matmul", "(", "np", ".", "transpose", "(", "normalized_data", ")", ",", "normalized_data", ")", "\n", "\n", "# Since the data is already normalized, there is no need to clip", "\n", "# the covariance matrix.", "\n", "\n", "gaussian_noise", ",", "rdp_budget", "=", "gaussian_rdp", "(", "covar", ".", "reshape", "(", "[", "1", ",", "-", "1", "]", ")", ",", "1.0", ",", "orders", ",", "sigma", ")", "\n", "\n", "saned_covar", "=", "covar", "+", "gaussian_noise", ".", "reshape", "(", "covar", ".", "shape", ")", "\n", "\n", "# Symmetrize saned_covar. This also reduces the noise variance.", "\n", "saned_covar", "=", "0.5", "*", "(", "saned_covar", "+", "np", ".", "transpose", "(", "saned_covar", ")", ")", "\n", "\n", "# Compute the eigen decomposition of the covariance matrix, and", "\n", "# return the top projection_dims eigen vectors, represented as columns of", "\n", "# the projection matrix.", "\n", "eigvals", ",", "eigvecs", "=", "np", ".", "linalg", ".", "eig", "(", "saned_covar", ")", "\n", "\n", "topk_indices", "=", "eigvals", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "projection_dims", "]", "\n", "topk_indices", "=", "np", ".", "reshape", "(", "topk_indices", ",", "[", "projection_dims", "]", ")", "\n", "\n", "# Gather and return the corresponding eigenvectors.", "\n", "return", "np", ".", "transpose", "(", "np", ".", "take", "(", "np", ".", "transpose", "(", "eigvecs", ")", ",", "topk_indices", ",", "axis", "=", "0", ")", ")", ",", "rdp_budget", "", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.input.create_dir_if_needed": [[35, 58], ["tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Exists", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "sys.stdout.write", "sys.stdout.flush", "float", "float"], "function", ["None"], ["def", "create_dir_if_needed", "(", "dest_directory", ")", ":", "\n", "    ", "\"\"\"\n    Create directory if doesn't exist\n    :param dest_directory:\n    :return: True if everything went well\n    \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "dest_directory", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dest_directory", ")", "\n", "\n", "", "return", "True", "\n", "\n", "# Test if file already exists", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "filepath", ")", ":", "\n", "        ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "filename", ",", "\n", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "file_url", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.input.image_whitening": [[60, 89], ["numpy.mean", "numpy.ones", "six.moves.xrange", "numpy.maximum", "six.moves.xrange", "print", "len", "len", "numpy.std", "len", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.ones", "math.sqrt", "numpy.shape", "numpy.shape", "len"], "function", ["None"], ["", "def", "image_whitening", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Subtracts mean of image and divides by adjusted standard variance (for\n    stability). Operations are per image but performed for the entire array.\n    :param image: 4D array (ID, Height, Weight, Channel)\n    :return: 4D array (ID, Height, Weight, Channel)\n    \"\"\"", "\n", "assert", "len", "(", "np", ".", "shape", "(", "data", ")", ")", "==", "4", "\n", "\n", "# Compute number of pixels in image", "\n", "nb_pixels", "=", "np", ".", "shape", "(", "data", ")", "[", "1", "]", "*", "np", ".", "shape", "(", "data", ")", "[", "2", "]", "*", "np", ".", "shape", "(", "data", ")", "[", "3", "]", "\n", "\n", "# Subtract mean", "\n", "mean", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "\n", "ones", "=", "np", ".", "ones", "(", "np", ".", "shape", "(", "data", ")", "[", "1", ":", "4", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "xrange", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "data", "[", "i", ",", ":", ",", ":", ",", ":", "]", "-=", "mean", "[", "i", "]", "*", "ones", "\n", "\n", "# Compute adjusted standard variance", "\n", "", "adj_std_var", "=", "np", ".", "maximum", "(", "np", ".", "ones", "(", "len", "(", "data", ")", ",", "dtype", "=", "np", ".", "float32", ")", "/", "math", ".", "sqrt", "(", "nb_pixels", ")", ",", "np", ".", "std", "(", "data", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ")", ")", "#NOLINT(long-line)", "\n", "\n", "# Divide image", "\n", "for", "i", "in", "xrange", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "data", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "data", "[", "i", ",", ":", ",", ":", ",", ":", "]", "/", "adj_std_var", "[", "i", "]", "\n", "\n", "", "print", "(", "np", ".", "shape", "(", "data", ")", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.input.ld_mnist": [[90, 127], ["os.path.join", "open", "numpy.fromfile", "loaded[].reshape().astype", "open", "numpy.fromfile", "loaded[].reshape().astype", "open", "numpy.fromfile", "loaded[].reshape().astype", "open", "numpy.fromfile", "loaded[].reshape().astype", "numpy.asarray", "numpy.asarray", "numpy.concatenate", "numpy.concatenate().astype", "numpy.random.seed", "numpy.random.shuffle", "numpy.random.seed", "numpy.random.shuffle", "numpy.zeros", "enumerate", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "loaded[].reshape", "loaded[].reshape", "loaded[].reshape", "loaded[].reshape", "numpy.concatenate", "len"], "function", ["None"], ["", "def", "ld_mnist", "(", "data_dir", ",", "dataset_name", ")", ":", "\n", "\n", "    ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", ")", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-images-idx3-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "trX", "=", "loaded", "[", "16", ":", "]", ".", "reshape", "(", "(", "60000", ",", "28", ",", "28", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-labels-idx1-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "trY", "=", "loaded", "[", "8", ":", "]", ".", "reshape", "(", "(", "60000", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'t10k-images-idx3-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "teX", "=", "loaded", "[", "16", ":", "]", ".", "reshape", "(", "(", "10000", ",", "28", ",", "28", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'t10k-labels-idx1-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "teY", "=", "loaded", "[", "8", ":", "]", ".", "reshape", "(", "(", "10000", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "trY", "=", "np", ".", "asarray", "(", "trY", ")", "\n", "teY", "=", "np", ".", "asarray", "(", "teY", ")", "\n", "\n", "X", "=", "np", ".", "concatenate", "(", "(", "trX", ",", "teX", ")", ",", "axis", "=", "0", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "(", "trY", ",", "teY", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "seed", "=", "547", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "y", ")", "\n", "\n", "y_vec", "=", "np", ".", "zeros", "(", "(", "len", "(", "y", ")", ",", "self", ".", "y_dim", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y", ")", ":", "\n", "      ", "y_vec", "[", "i", ",", "y", "[", "i", "]", "]", "=", "1.0", "\n", "\n", "", "return", "X", "/", "255.", ",", "y_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.input.partition_dataset": [[129, 157], ["int", "len", "len", "int", "int", "len"], "function", ["None"], ["", "def", "partition_dataset", "(", "data", ",", "labels", ",", "nb_teachers", ",", "teacher_id", ")", ":", "\n", "    ", "\"\"\"\n    Simple partitioning algorithm that returns the right portion of the data\n    needed by a given teacher out of a certain nb of teachers\n    :param data: input data to be partitioned\n    :param labels: output data to be partitioned\n    :param nb_teachers: number of teachers in the ensemble (affects size of each\n                       partition)\n    :param teacher_id: id of partition to retrieve\n    :return:\n    \"\"\"", "\n", "\n", "# Sanity check", "\n", "assert", "(", "len", "(", "data", ")", "==", "len", "(", "labels", ")", ")", "\n", "assert", "(", "int", "(", "teacher_id", ")", "<", "int", "(", "nb_teachers", ")", ")", "\n", "\n", "# This will floor the possible number of batches", "\n", "batch_len", "=", "int", "(", "len", "(", "data", ")", "/", "nb_teachers", ")", "\n", "\n", "# Compute start, end indices of partition", "\n", "start", "=", "teacher_id", "*", "batch_len", "\n", "end", "=", "(", "teacher_id", "+", "1", ")", "*", "batch_len", "\n", "\n", "# Slice partition off", "\n", "partition_data", "=", "data", "[", "start", ":", "end", "]", "\n", "partition_labels", "=", "labels", "[", "start", ":", "end", "]", "\n", "\n", "return", "partition_data", ",", "partition_labels", "\n", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.batch_norm.__init__": [[30, 36], ["tensorflow.variable_scope"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.9", ",", "name", "=", "\"batch_norm\"", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "      ", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "bn", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.batch_norm.__call__": [[37, 45], ["tensorflow.contrib.layers.batch_norm"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "x", ",", "train", "=", "True", ")", ":", "\n", "    ", "return", "tf", ".", "contrib", ".", "layers", ".", "batch_norm", "(", "x", ",", "\n", "decay", "=", "self", ".", "momentum", ",", "\n", "updates_collections", "=", "None", ",", "\n", "epsilon", "=", "self", ".", "epsilon", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "train", ",", "\n", "scope", "=", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv_cond_concat": [[46, 52], ["x.get_shape", "y.get_shape", "concat", "tensorflow.ones"], "function", ["None"], ["", "", "def", "conv_cond_concat", "(", "x", ",", "y", ")", ":", "\n", "  ", "\"\"\"Concatenate conditioning vector on feature map axis.\"\"\"", "\n", "x_shapes", "=", "x", ".", "get_shape", "(", ")", "\n", "y_shapes", "=", "y", ".", "get_shape", "(", ")", "\n", "return", "concat", "(", "[", "\n", "x", ",", "y", "*", "tf", ".", "ones", "(", "[", "x_shapes", "[", "0", "]", ",", "x_shapes", "[", "1", "]", ",", "x_shapes", "[", "2", "]", ",", "y_shapes", "[", "3", "]", "]", ")", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv2d": [[53, 65], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.nn.bias_add", "tf.reshape.get_shape", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "input_.get_shape"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv2d"], ["", "def", "conv2d", "(", "input_", ",", "output_dim", ",", "\n", "k_h", "=", "5", ",", "k_w", "=", "5", ",", "d_h", "=", "2", ",", "d_w", "=", "2", ",", "stddev", "=", "0.02", ",", "\n", "name", "=", "\"conv2d\"", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "    ", "w", "=", "tf", ".", "get_variable", "(", "'w'", ",", "[", "k_h", ",", "k_w", ",", "input_", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "output_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "input_", ",", "w", ",", "strides", "=", "[", "1", ",", "d_h", ",", "d_w", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "biases", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "[", "output_dim", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "conv", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ")", ",", "conv", ".", "get_shape", "(", ")", ")", "\n", "\n", "return", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d": [[66, 90], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.nn.conv2d_transpose", "tensorflow.nn.bias_add", "tf.nn.deconv2d.get_shape", "tensorflow.random_normal_initializer", "tensorflow.nn.deconv2d", "tensorflow.constant_initializer", "input_.get_shape"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d"], ["", "", "def", "deconv2d", "(", "input_", ",", "output_shape", ",", "\n", "k_h", "=", "5", ",", "k_w", "=", "5", ",", "d_h", "=", "2", ",", "d_w", "=", "2", ",", "stddev", "=", "0.02", ",", "\n", "name", "=", "\"deconv2d\"", ",", "with_w", "=", "False", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "# filter : [height, width, output_channels, in_channels]", "\n", "    ", "w", "=", "tf", ".", "get_variable", "(", "'w'", ",", "[", "k_h", ",", "k_w", ",", "output_shape", "[", "-", "1", "]", ",", "input_", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "try", ":", "\n", "      ", "deconv", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "input_", ",", "w", ",", "output_shape", "=", "output_shape", ",", "\n", "strides", "=", "[", "1", ",", "d_h", ",", "d_w", ",", "1", "]", ")", "\n", "\n", "# Support for verisons of TensorFlow before 0.7.0", "\n", "", "except", "AttributeError", ":", "\n", "      ", "deconv", "=", "tf", ".", "nn", ".", "deconv2d", "(", "input_", ",", "w", ",", "output_shape", "=", "output_shape", ",", "\n", "strides", "=", "[", "1", ",", "d_h", ",", "d_w", ",", "1", "]", ")", "\n", "\n", "", "biases", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "[", "output_shape", "[", "-", "1", "]", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "deconv", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "bias_add", "(", "deconv", ",", "biases", ")", ",", "deconv", ".", "get_shape", "(", ")", ")", "\n", "\n", "if", "with_w", ":", "\n", "      ", "return", "deconv", ",", "w", ",", "biases", "\n", "", "else", ":", "\n", "      ", "return", "deconv", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu": [[91, 93], ["tensorflow.maximum"], "function", ["None"], ["", "", "", "def", "lrelu", "(", "x", ",", "leak", "=", "0.2", ",", "name", "=", "\"lrelu\"", ")", ":", "\n", "  ", "return", "tf", ".", "maximum", "(", "x", ",", "leak", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear": [[94, 111], ["input_.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.get_variable", "input_.get_shape", "tensorflow.get_variable", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.matmul", "tensorflow.matmul"], "function", ["None"], ["", "def", "linear", "(", "input_", ",", "output_size", ",", "scope", "=", "None", ",", "stddev", "=", "0.02", ",", "bias_start", "=", "0.0", ",", "with_w", "=", "False", ")", ":", "\n", "  ", "shape", "=", "input_", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"Linear\"", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "matrix", "=", "tf", ".", "get_variable", "(", "\"Matrix\"", ",", "[", "shape", "[", "1", "]", ",", "output_size", "]", ",", "tf", ".", "float32", ",", "\n", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "", "except", "ValueError", "as", "err", ":", "\n", "        ", "msg", "=", "\"NOTE: Usually, this is due to an issue with the image dimensions.  Did you correctly set '--crop' or '--input_height' or '--output_height'?\"", "\n", "err", ".", "args", "=", "err", ".", "args", "+", "(", "msg", ",", ")", "\n", "raise", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "output_size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "bias_start", ")", ")", "\n", "if", "with_w", ":", "\n", "      ", "return", "tf", ".", "matmul", "(", "input_", ",", "matrix", ")", "+", "bias", ",", "matrix", ",", "bias", "\n", "", "else", ":", "\n", "      ", "return", "tf", ".", "matmul", "(", "input_", ",", "matrix", ")", "+", "bias", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.main.main": [[74, 152], ["utils.pp.pprint", "tensorflow.ConfigProto", "flags.FLAGS.flag_values_dict", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "tensorflow.Session", "model.DCGAN", "utils.show_all_variables", "os.path.join", "os.path.join", "model.DCGAN.gen_data", "joblib.dump", "model.DCGAN.train_together", "os.path.exists", "os.makedirs", "os.path.join", "Exception", "model.DCGAN.load"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.show_all_variables", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.gen_data", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.train_together", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "main", "(", "_", ")", ":", "\n", "    ", "pp", ".", "pprint", "(", "flags", ".", "FLAGS", ".", "flag_values_dict", "(", ")", ")", "\n", "\n", "# if FLAGS.input_width is None:", "\n", "#   FLAGS.input_width = FLAGS.input_height", "\n", "# if FLAGS.output_width is None:", "\n", "#   FLAGS.output_width = FLAGS.output_height", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "checkpoint_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "FLAGS", ".", "checkpoint_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "sample_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "FLAGS", ".", "sample_dir", ")", "\n", "\n", "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)", "\n", "", "run_config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "run_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "if", "FLAGS", ".", "thresh", "==", "0", ":", "\n", "        ", "thresh", "=", "None", "\n", "", "else", ":", "\n", "        ", "thresh", "=", "FLAGS", ".", "thresh", "\n", "\n", "", "if", "FLAGS", ".", "wgan", ":", "\n", "        ", "FLAGS", ".", "learning_rate", "=", "5e-5", "\n", "FLAGS", ".", "step_size", "=", "5e-4", "\n", "\n", "", "with", "tf", ".", "Session", "(", "config", "=", "run_config", ")", "as", "sess", ":", "\n", "\n", "        ", "dcgan", "=", "DCGAN", "(", "\n", "sess", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "sample_num", "=", "FLAGS", ".", "batch_size", ",", "\n", "y_dim", "=", "FLAGS", ".", "y_dim", ",", "\n", "z_dim", "=", "FLAGS", ".", "z_dim", ",", "\n", "dataset_name", "=", "FLAGS", ".", "dataset", ",", "\n", "crop", "=", "FLAGS", ".", "crop", ",", "\n", "checkpoint_dir", "=", "FLAGS", ".", "checkpoint_dir", ",", "\n", "sample_dir", "=", "FLAGS", ".", "sample_dir", ",", "\n", "data_dir", "=", "FLAGS", ".", "data_dir", ",", "\n", "# parameters to tune", "\n", "batch_teachers", "=", "FLAGS", ".", "batch_teachers", ",", "\n", "pca", "=", "FLAGS", ".", "pca", ",", "\n", "random_proj", "=", "FLAGS", ".", "random_proj", ",", "\n", "thresh", "=", "thresh", ",", "\n", "dp_delta", "=", "FLAGS", ".", "delta", ",", "\n", "pca_dim", "=", "FLAGS", ".", "pca_dim", ",", "\n", "teachers_batch", "=", "FLAGS", ".", "teachers_batch", ",", "\n", "teacher_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "checkpoint_dir", ",", "FLAGS", ".", "teacher_dir", ")", ",", "\n", "generator_dir", "=", "FLAGS", ".", "generator_dir", ",", "\n", "non_private", "=", "FLAGS", ".", "non_private", ",", "\n", "input_height", "=", "FLAGS", ".", "input_height", ",", "\n", "input_width", "=", "FLAGS", ".", "input_width", ",", "\n", "output_height", "=", "FLAGS", ".", "output_height", ",", "\n", "output_width", "=", "FLAGS", ".", "output_width", ",", "\n", "wgan", "=", "FLAGS", ".", "wgan", ",", "\n", "small", "=", "FLAGS", ".", "small", ",", "\n", "config", "=", "FLAGS", "\n", ")", "\n", "\n", "show_all_variables", "(", ")", "\n", "\n", "if", "FLAGS", ".", "train", ":", "\n", "            ", "epsilon", ",", "delta", "=", "dcgan", ".", "train_together", "(", "FLAGS", ")", "\n", "filename", "=", "'%.2fepsilon-%.2fdelta.data'", "%", "(", "epsilon", ",", "delta", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "dcgan", ".", "load", "(", "FLAGS", ".", "checkpoint_dir", ",", "FLAGS", ".", "checkpoint_name", ")", "[", "0", "]", ":", "\n", "                ", "raise", "Exception", "(", "\"[!] Train a model first, then run test mode\"", ")", "\n", "", "filename", "=", "'private.data'", "\n", "\n", "", "outpath", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "checkpoint_dir", ",", "FLAGS", ".", "sample_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "outpath", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "outpath", ")", "\n", "\n", "", "outfile", "=", "os", ".", "path", ".", "join", "(", "outpath", ",", "filename", ")", "\n", "n_batch", "=", "100000", "//", "FLAGS", ".", "batch_size", "+", "1", "\n", "data", "=", "dcgan", ".", "gen_data", "(", "n_batch", ")", "\n", "data", "=", "data", "[", ":", "100000", "]", "\n", "import", "joblib", "\n", "joblib", ".", "dump", "(", "data", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.dp_utils.BatchClipByL2norm": [[26, 55], ["tensorflow.name_scope", "tensorflow.shape", "tensorflow.slice", "tensorflow.reshape", "tensorflow.fill", "tensorflow.rsqrt", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.concat", "tensorflow.slice", "tensorflow.constant", "tensorflow.minimum", "tensorflow.diag", "tensorflow.reduce_sum"], "function", ["None"], ["def", "BatchClipByL2norm", "(", "t", ",", "upper_bound", ",", "name", "=", "None", ")", ":", "\n", "  ", "\"\"\"Clip an array of tensors by L2 norm.\n\n  Shrink each dimension-0 slice of tensor (for matrix it is each row) such\n  that the l2 norm is at most upper_bound. Here we clip each row as it\n  corresponds to each example in the batch.\n\n  Args:\n    t: the input tensor.\n    upper_bound: the upperbound of the L2 norm.\n    name: optional name.\n  Returns:\n    the clipped tensor.\n  \"\"\"", "\n", "\n", "assert", "upper_bound", ">", "0", "\n", "with", "tf", ".", "name_scope", "(", "values", "=", "[", "t", ",", "upper_bound", "]", ",", "name", "=", "name", ",", "\n", "default_name", "=", "\"batch_clip_by_l2norm\"", ")", "as", "name", ":", "\n", "    ", "saved_shape", "=", "tf", ".", "shape", "(", "t", ")", "\n", "batch_size", "=", "tf", ".", "slice", "(", "saved_shape", ",", "[", "0", "]", ",", "[", "1", "]", ")", "\n", "t2", "=", "tf", ".", "reshape", "(", "t", ",", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "[", "batch_size", ",", "[", "-", "1", "]", "]", ")", ")", "\n", "upper_bound_inv", "=", "tf", ".", "fill", "(", "tf", ".", "slice", "(", "saved_shape", ",", "[", "0", "]", ",", "[", "1", "]", ")", ",", "\n", "tf", ".", "constant", "(", "1.0", "/", "upper_bound", ")", ")", "\n", "# Add a small number to avoid divide by 0", "\n", "l2norm_inv", "=", "tf", ".", "rsqrt", "(", "tf", ".", "reduce_sum", "(", "t2", "*", "t2", ",", "[", "1", "]", ")", "+", "0.000001", ")", "\n", "scale", "=", "tf", ".", "minimum", "(", "l2norm_inv", ",", "upper_bound_inv", ")", "*", "upper_bound", "\n", "clipped_t", "=", "tf", ".", "matmul", "(", "tf", ".", "diag", "(", "scale", ")", ",", "t2", ")", "\n", "clipped_t", "=", "tf", ".", "reshape", "(", "clipped_t", ",", "saved_shape", ",", "name", "=", "name", ")", "\n", "", "return", "clipped_t", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.dp_utils.AddGaussianNoise": [[57, 72], ["tensorflow.name_scope", "tensorflow.random_normal", "tensorflow.shape"], "function", ["None"], ["", "def", "AddGaussianNoise", "(", "t", ",", "sigma", ",", "name", "=", "None", ")", ":", "\n", "  ", "\"\"\"Add i.i.d. Gaussian noise (0, sigma^2) to every entry of t.\n\n  Args:\n    t: the input tensor.\n    sigma: the stddev of the Gaussian noise.\n    name: optional name.\n  Returns:\n    the noisy tensor.\n  \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "values", "=", "[", "t", ",", "sigma", "]", ",", "name", "=", "name", ",", "\n", "default_name", "=", "\"add_gaussian_noise\"", ")", "as", "name", ":", "\n", "    ", "noisy_t", "=", "t", "+", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "t", ")", ",", "stddev", "=", "sigma", ")", "\n", "", "return", "noisy_t", "\n", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_thresh_aggregator": [[13, 28], ["pate_core.compute_logpr_answered", "pate_core.compute_rdp_threshold", "numpy.random.normal", "pate_core.compute_logq_gaussian", "numpy.argmax", "pate_core.rdp_gaussian", "numpy.max", "numpy.random.normal"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logpr_answered", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_threshold", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logq_gaussian", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_gaussian"], ["def", "gnmax_thresh_aggregator", "(", "counts", ",", "thresh_cnt", ",", "sigma_thresh", ",", "sigma", ",", "orders", ")", ":", "\n", "    ", "log_pr_answered", "=", "compute_logpr_answered", "(", "thresh_cnt", ",", "sigma_thresh", ",", "counts", ")", "\n", "rdp_budget", "=", "compute_rdp_threshold", "(", "log_pr_answered", ",", "sigma_thresh", ",", "orders", ")", "\n", "# print(\"Threshold budget:\" + str(rdp_budget))", "\n", "\n", "if", "np", ".", "random", ".", "normal", "(", "np", ".", "max", "(", "counts", ")", ",", "sigma_thresh", ")", ">=", "thresh_cnt", ":", "\n", "        ", "logq", "=", "compute_logq_gaussian", "(", "counts", ",", "sigma", ")", "\n", "res", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "normal", "(", "counts", ",", "sigma", ")", ")", "\n", "g_rdp_budget", "=", "rdp_gaussian", "(", "logq", ",", "sigma", ",", "orders", ")", "\n", "rdp_budget", "+=", "g_rdp_budget", "\n", "", "else", ":", "\n", "# do not return result if teacher models do not agree", "\n", "        ", "res", "=", "-", "1", "\n", "\n", "", "return", "res", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_aggregator": [[30, 35], ["pate_core.compute_logq_gaussian", "numpy.argmax", "pate_core.rdp_gaussian", "numpy.random.normal"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logq_gaussian", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_gaussian"], ["", "def", "gnmax_aggregator", "(", "counts", ",", "sigma", ",", "orders", ")", ":", "\n", "    ", "logq", "=", "compute_logq_gaussian", "(", "counts", ",", "sigma", ")", "\n", "dir_index", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "normal", "(", "counts", ",", "sigma", ")", ")", "\n", "rdp_budget", "=", "rdp_gaussian", "(", "logq", ",", "sigma", ",", "orders", ")", "\n", "return", "dir_index", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.rdp_percentile": [[37, 87], ["len", "numpy.vstack", "numpy.sort", "arr_ordered.clip.clip", "numpy.vstack", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "range", "numpy.random.uniform", "output_q.reshape.reshape", "diff.clip.clip", "numpy.min", "print", "exit", "numpy.random.choice", "numpy.multiply", "arr.reshape", "numpy.exp", "numpy.sum", "numpy.log", "numpy.ones", "numpy.ones", "numpy.abs", "abs", "numpy.multiply", "numpy.multiply", "numpy.divide", "numpy.exp", "numpy.divide", "numpy.exp"], "function", ["None"], ["", "def", "rdp_percentile", "(", "arr_list", ",", "q", ",", "orders", ",", "vmin", ",", "vmax", ",", "lmbd", ",", "axis", "=", "0", ")", ":", "\n", "    ", "arr_length", "=", "len", "(", "arr_list", ")", "\n", "arr_size", "=", "arr_list", "[", "0", "]", ".", "size", "\n", "input_shape", "=", "arr_list", "[", "0", "]", ".", "shape", "\n", "arr_reshaped", "=", "np", ".", "vstack", "(", "[", "arr", ".", "reshape", "(", "[", "1", ",", "arr_size", "]", ")", "for", "arr", "in", "arr_list", "]", ")", "\n", "\n", "arr_ordered", "=", "np", ".", "sort", "(", "arr_reshaped", ",", "axis", "=", "0", ")", "\n", "arr_ordered", "=", "arr_ordered", ".", "clip", "(", "min", "=", "vmin", ",", "max", "=", "vmax", ")", "\n", "\n", "arr_ordered_new", "=", "np", ".", "vstack", "(", "[", "np", ".", "ones", "(", "[", "1", ",", "arr_size", "]", ")", "*", "vmin", ",", "arr_ordered", ",", "np", ".", "ones", "(", "[", "1", ",", "arr_size", "]", ")", "*", "vmax", "]", ")", "\n", "arr_ordered_new", "[", "np", ".", "abs", "(", "arr_ordered_new", ")", "<", "sys", ".", "float_info", ".", "epsilon", "]", "=", "0", "\n", "\n", "n_teachers", ",", "n_feature", "=", "arr_reshaped", ".", "shape", "\n", "arr_prob", "=", "np", ".", "zeros", "(", "[", "n_teachers", "+", "1", ",", "n_feature", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "arr_length", "+", "1", ")", ":", "\n", "        ", "diff", "=", "arr_ordered_new", "[", "i", "+", "1", ",", ":", "]", "-", "arr_ordered_new", "[", "i", ",", ":", "]", "\n", "diff", "=", "diff", ".", "clip", "(", "min", "=", "0", ")", "\n", "arr_prob", "[", "i", "]", "=", "diff", "*", "np", ".", "exp", "(", "-", "0.5", "/", "lmbd", "*", "abs", "(", "i", "-", "q", "/", "100", "*", "arr_length", ")", ")", "\n", "# arr_prob[i] = np.exp(np.log(diff) - 0.5/lmbd * abs(i - q/100 * arr_length))", "\n", "\n", "# arr_prob = normalize(arr_prob, norm='l1', axis=0)", "\n", "\n", "", "if", "np", ".", "min", "(", "arr_prob", ")", "<", "0", ":", "\n", "        ", "print", "(", "arr_prob", ")", "\n", "exit", "(", ")", "\n", "\n", "", "low", "=", "np", ".", "zeros", "(", "[", "1", ",", "arr_size", "]", ")", "\n", "high", "=", "np", ".", "zeros", "(", "[", "1", ",", "arr_size", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "arr_size", ")", ":", "\n", "        ", "prob", "=", "arr_prob", "[", ":", ",", "i", "]", "/", "np", ".", "sum", "(", "arr_prob", "[", ":", ",", "i", "]", ")", "\n", "rindex", "=", "np", ".", "random", ".", "choice", "(", "arr_length", "+", "1", ",", "p", "=", "prob", ")", "\n", "# print(rindex)", "\n", "\n", "low", "[", "0", ",", "i", "]", "=", "arr_ordered_new", "[", "rindex", ",", "i", "]", "\n", "high", "[", "0", ",", "i", "]", "=", "arr_ordered_new", "[", "rindex", "+", "1", ",", "i", "]", "\n", "\n", "", "output_q", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "[", "1", ",", "arr_size", "]", ")", "\n", "output_q", "=", "output_q", ".", "reshape", "(", "input_shape", ")", "\n", "\n", "rdp_budget", "=", "arr_size", "*", "np", ".", "multiply", "(", "\n", "1", "/", "(", "orders", "-", "1", ")", ",", "\n", "np", ".", "log", "(", "\n", "np", ".", "multiply", "(", "np", ".", "divide", "(", "orders", ",", "2", "*", "orders", "-", "1", ")", ",", "np", ".", "exp", "(", "(", "orders", "-", "1", ")", "/", "lmbd", ")", ")", "+", "np", ".", "multiply", "(", "np", ".", "divide", "(", "orders", "-", "1", ",", "2", "*", "orders", "-", "1", ")", ",", "np", ".", "exp", "(", "-", "orders", "/", "lmbd", ")", ")", "\n", ")", "\n", ")", "\n", "\n", "return", "output_q", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.rdp_winsorized_mean": [[89, 132], ["numpy.asarray", "rdp_utils.rdp_percentile", "rdp_utils.rdp_percentile", "numpy.mean", "numpy.nonzero", "numpy.linalg.norm", "rdp_utils.gaussian_rdp", "arr_mean[].clip", "numpy.matmul", "np.matmul.clip", "numpy.logical_and", "numpy.matmul", "np.matmul.reshape", "arr.flatten", "len", "numpy.transpose", "numpy.sign", "numpy.sign", "numpy.sign", "numpy.sign"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.rdp_percentile", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.rdp_percentile", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gaussian_rdp"], ["", "def", "rdp_winsorized_mean", "(", "arr_list", ",", "step_size", ",", "sigma_mean", ",", "sigma_percentile", ",", "orders", ",", "pca_mat", "=", "None", ")", ":", "\n", "    ", "vmin", "=", "-", "step_size", "\n", "vmax", "=", "step_size", "\n", "\n", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "arr_list", "]", ")", "\n", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project to principal components", "\n", "        ", "flatten_arr", "=", "np", ".", "matmul", "(", "flatten_arr", ",", "pca_mat", ")", "\n", "n_features", "=", "flatten_arr", ".", "shape", "[", "1", "]", "\n", "\n", "", "q25", ",", "q25_budget", "=", "rdp_percentile", "(", "flatten_arr", ",", "25", ",", "orders", ",", "vmin", "=", "vmin", ",", "vmax", "=", "vmax", ",", "lmbd", "=", "sigma_percentile", ")", "\n", "q75", ",", "q75_budget", "=", "rdp_percentile", "(", "flatten_arr", ",", "75", ",", "orders", ",", "vmin", "=", "vmin", ",", "vmax", "=", "vmax", ",", "lmbd", "=", "sigma_percentile", ")", "\n", "\n", "arr_mean", "=", "np", ".", "mean", "(", "flatten_arr", ".", "clip", "(", "min", "=", "q25", ",", "max", "=", "q75", ")", ",", "axis", "=", "0", ")", "\n", "\n", "arr_mean", "[", "np", ".", "sign", "(", "q75", ")", "!=", "np", ".", "sign", "(", "q25", ")", "]", "=", "0", "\n", "\n", "# when 75 percentile is smaller, update the model with the average of 75 and 25 percentile", "\n", "# quantile_mean = (q75 + q25) / 2", "\n", "arr_mean", "[", "q75", "<", "q25", "]", "=", "0", "\n", "\n", "update_index", "=", "np", ".", "nonzero", "(", "np", ".", "logical_and", "(", "np", ".", "sign", "(", "q75", ")", "==", "np", ".", "sign", "(", "q25", ")", ",", "q75", ">", "q25", ")", ")", "\n", "q_range", "=", "q75", "-", "q25", "\n", "\n", "sensitivity", "=", "LA", ".", "norm", "(", "q_range", "[", "update_index", "]", "/", "len", "(", "arr_list", ")", ")", "\n", "\n", "gaussian_noise", ",", "mean_budget", "=", "gaussian_rdp", "(", "arr_mean", "[", "update_index", "]", ",", "sensitivity", ",", "orders", ",", "sigma_mean", ")", "\n", "arr_mean", "[", "update_index", "]", "+=", "gaussian_noise", "\n", "arr_mean", "[", "update_index", "]", "=", "arr_mean", "[", "update_index", "]", ".", "clip", "(", "min", "=", "q25", "[", "update_index", "]", ",", "max", "=", "q75", "[", "update_index", "]", ")", "\n", "\n", "# for testing only", "\n", "# update_ratio = gaussian_noise.size / arr_mean.size", "\n", "# print(\"Update ratio: %.8f, norm: %.8f\" % (update_ratio, sensitivity))", "\n", "\n", "rdp_budget", "=", "q25_budget", "+", "q75_budget", "+", "mean_budget", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project res direction back to original axis", "\n", "        ", "arr_mean", "=", "np", ".", "matmul", "(", "arr_mean", ",", "np", ".", "transpose", "(", "pca_mat", ")", ")", "\n", "\n", "", "return", "arr_mean", ".", "reshape", "(", "arr_list", "[", "0", "]", ".", "shape", ")", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_nonprivate": [[134, 151], ["len", "numpy.asarray", "flatten_arr.clip.clip", "numpy.arange", "numpy.hstack", "numpy.zeros", "range", "np.zeros.reshape", "numpy.histogram", "numpy.argmax", "arr.flatten"], "function", ["None"], ["", "def", "gradient_voting_nonprivate", "(", "output_list", ",", "step_size", ",", "nbins", "=", "10", ")", ":", "\n", "    ", "n", "=", "len", "(", "output_list", ")", "\n", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ")", "\n", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "\n", "flatten_arr", "=", "flatten_arr", ".", "clip", "(", "min", "=", "-", "step_size", ",", "max", "=", "step_size", ")", "\n", "\n", "bins", "=", "np", ".", "arange", "(", "-", "step_size", ",", "step_size", ",", "(", "step_size", "*", "2", "/", "nbins", ")", ")", "\n", "bins", "=", "np", ".", "hstack", "(", "[", "bins", ",", "step_size", "]", ")", "\n", "result", "=", "np", ".", "zeros", "(", "[", "1", ",", "n_features", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_features", ")", ":", "\n", "        ", "votes_arr", ",", "_", "=", "np", ".", "histogram", "(", "flatten_arr", "[", ":", ",", "i", "]", ",", "bins", ")", "\n", "res_idx", "=", "np", ".", "argmax", "(", "votes_arr", ")", "\n", "result", "[", ":", ",", "i", "]", "=", "(", "bins", "[", "res_idx", "]", "+", "bins", "[", "res_idx", "+", "1", "]", ")", "/", "2", "\n", "\n", "", "return", "result", ".", "reshape", "(", "output_list", "[", "0", "]", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp": [[153, 200], ["time.time", "len", "np.matmul.clip", "numpy.arange", "numpy.hstack", "numpy.zeros", "range", "print", "torch.tensor", "numpy.asarray", "numpy.histogram", "print", "rdp_utils.gnmax_thresh_aggregator", "numpy.matmul", "np.matmul.reshape", "torch.from_numpy().float().to", "torch.matmul", "np.matmul.cpu().numpy", "numpy.matmul", "numpy.transpose", "arr.flatten", "arr.flatten", "torch.from_numpy().float", "np.matmul.cpu", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_thresh_aggregator"], ["", "def", "gradient_voting_rdp", "(", "output_list", ",", "step_size", ",", "sigma", ",", "sigma_thresh", ",", "orders", ",", "pca_mat", "=", "None", ",", "nbins", "=", "10", ",", "thresh", "=", "0.9", ")", ":", "\n", "    ", "import", "time", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "n", "=", "len", "(", "output_list", ")", "\n", "use_gpu", "=", "False", "# turn it on if you are running a huge matrix and the bottleneck lies on CPU matmul", "\n", "if", "use_gpu", ":", "\n", "# have to use torch==1.2.0 and torchvision==0.4.0 to run tensorflow-gpu==1.4.0", "\n", "        ", "import", "torch", "\n", "flatten_arr", "=", "torch", ".", "tensor", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ",", "device", "=", "'cuda:0'", ")", "\n", "", "else", ":", "\n", "        ", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ")", "\n", "", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project to principal components", "\n", "        ", "if", "use_gpu", ":", "\n", "            ", "pca_mat_tensor", "=", "torch", ".", "from_numpy", "(", "pca_mat", ")", ".", "float", "(", ")", ".", "to", "(", "'cuda:0'", ")", "\n", "flatten_arr", "=", "torch", ".", "matmul", "(", "flatten_arr", ",", "pca_mat_tensor", ")", "\n", "flatten_arr", "=", "flatten_arr", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "flatten_arr", "=", "np", ".", "matmul", "(", "flatten_arr", ",", "pca_mat", ")", "\n", "", "n_features", "=", "flatten_arr", ".", "shape", "[", "1", "]", "\n", "\n", "", "flatten_arr", "=", "flatten_arr", ".", "clip", "(", "min", "=", "-", "step_size", ",", "max", "=", "step_size", ")", "\n", "\n", "bins", "=", "np", ".", "arange", "(", "-", "step_size", ",", "step_size", ",", "(", "step_size", "*", "2", "/", "nbins", ")", ")", "\n", "bins", "=", "np", ".", "hstack", "(", "[", "bins", ",", "step_size", "]", ")", "\n", "result", "=", "np", ".", "zeros", "(", "[", "1", ",", "n_features", "]", ")", "\n", "\n", "rdp_budget", "=", "0", "\n", "skipped_cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "n_features", ")", ":", "\n", "        ", "votes_arr", ",", "_", "=", "np", ".", "histogram", "(", "flatten_arr", "[", ":", ",", "i", "]", ",", "bins", ")", "\n", "print", "(", "votes_arr", ")", "\n", "res_idx", ",", "cur_budget", "=", "gnmax_thresh_aggregator", "(", "votes_arr", ",", "thresh", "*", "n_teachers", ",", "sigma_thresh", ",", "sigma", ",", "orders", ")", "\n", "rdp_budget", "+=", "cur_budget", "\n", "if", "res_idx", "<", "0", ":", "\n", "            ", "skipped_cnt", "+=", "1", "\n", "", "else", ":", "\n", "            ", "result", "[", ":", ",", "i", "]", "=", "(", "bins", "[", "res_idx", "]", "+", "bins", "[", "res_idx", "+", "1", "]", ")", "/", "2", "\n", "", "", "print", "(", "\"Skipped %d feaatures out of %d\"", "%", "(", "skipped_cnt", ",", "n_features", ")", ")", "\n", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project res direction back to original axis", "\n", "        ", "result", "=", "np", ".", "matmul", "(", "result", ",", "np", ".", "transpose", "(", "pca_mat", ")", ")", "\n", "", "return", "result", ".", "reshape", "(", "output_list", "[", "0", "]", ".", "shape", ")", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp_multiproj": [[202, 248], ["len", "numpy.asarray", "print", "np.concatenate.clip", "numpy.arange", "numpy.hstack", "numpy.zeros", "range", "print", "numpy.split", "zip", "numpy.concatenate", "numpy.histogram", "print", "rdp_utils.gnmax_thresh_aggregator", "numpy.split", "zip", "numpy.concatenate", "np.concatenate.reshape", "np.matmul.flatten", "len", "print", "print", "numpy.matmul", "reduced_flatten_arr.append", "len", "np.concatenate.append", "numpy.matmul", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_thresh_aggregator"], ["", "def", "gradient_voting_rdp_multiproj", "(", "output_list", ",", "step_size", ",", "sigma", ",", "sigma_thresh", ",", "orders", ",", "pca_mats", "=", "None", ",", "nbins", "=", "10", ",", "thresh", "=", "0.9", ")", ":", "\n", "    ", "n", "=", "len", "(", "output_list", ")", "\n", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ")", "\n", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "print", "(", "\"flatten arr shape\"", ",", "flatten_arr", ".", "shape", ")", "\n", "\n", "if", "pca_mats", "is", "not", "None", ":", "\n", "# project to principal components", "\n", "        ", "split_flatten_arr", "=", "np", ".", "split", "(", "flatten_arr", ",", "len", "(", "pca_mats", ")", ",", "axis", "=", "1", ")", "\n", "reduced_flatten_arr", "=", "[", "]", "\n", "for", "pca_mat", ",", "arr", "in", "zip", "(", "pca_mats", ",", "split_flatten_arr", ")", ":", "\n", "            ", "print", "(", "\"arr shape\"", ",", "arr", ".", "shape", ")", "\n", "print", "(", "\"pca shape\"", ",", "pca_mat", ".", "shape", ")", "\n", "arr", "=", "np", ".", "matmul", "(", "arr", ",", "pca_mat", ")", "\n", "reduced_flatten_arr", ".", "append", "(", "arr", ")", "\n", "", "flatten_arr", "=", "np", ".", "concatenate", "(", "reduced_flatten_arr", ",", "axis", "=", "1", ")", "\n", "n_features", "=", "flatten_arr", ".", "shape", "[", "1", "]", "\n", "\n", "", "flatten_arr", "=", "flatten_arr", ".", "clip", "(", "min", "=", "-", "step_size", ",", "max", "=", "step_size", ")", "\n", "\n", "bins", "=", "np", ".", "arange", "(", "-", "step_size", ",", "step_size", ",", "(", "step_size", "*", "2", "/", "nbins", ")", ")", "\n", "bins", "=", "np", ".", "hstack", "(", "[", "bins", ",", "step_size", "]", ")", "\n", "result", "=", "np", ".", "zeros", "(", "[", "1", ",", "n_features", "]", ")", "\n", "\n", "rdp_budget", "=", "0", "\n", "skipped_cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "n_features", ")", ":", "\n", "        ", "votes_arr", ",", "_", "=", "np", ".", "histogram", "(", "flatten_arr", "[", ":", ",", "i", "]", ",", "bins", ")", "\n", "print", "(", "votes_arr", ")", "\n", "res_idx", ",", "cur_budget", "=", "gnmax_thresh_aggregator", "(", "votes_arr", ",", "thresh", "*", "n_teachers", ",", "sigma_thresh", ",", "sigma", ",", "orders", ")", "\n", "rdp_budget", "+=", "cur_budget", "\n", "if", "res_idx", "<", "0", ":", "\n", "            ", "skipped_cnt", "+=", "1", "\n", "", "else", ":", "\n", "            ", "result", "[", ":", ",", "i", "]", "=", "(", "bins", "[", "res_idx", "]", "+", "bins", "[", "res_idx", "+", "1", "]", ")", "/", "2", "\n", "\n", "", "", "print", "(", "\"Skipped %d feaatures out of %d\"", "%", "(", "skipped_cnt", ",", "n_features", ")", ")", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project res direction back to original axis", "\n", "        ", "split_results", "=", "np", ".", "split", "(", "result", ",", "len", "(", "pca_mats", ")", ",", "axis", "=", "1", ")", "\n", "final_results", "=", "[", "]", "\n", "for", "split_result", ",", "pca_mat", "in", "zip", "(", "split_results", ",", "pca_mats", ")", ":", "\n", "            ", "final_results", ".", "append", "(", "np", ".", "matmul", "(", "split_result", ",", "np", ".", "transpose", "(", "pca_mat", ")", ")", ")", "\n", "", "final_results", "=", "np", ".", "concatenate", "(", "final_results", ",", "axis", "=", "1", ")", "\n", "", "return", "final_results", ".", "reshape", "(", "output_list", "[", "0", "]", ".", "shape", ")", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_sign_rdp": [[250, 290], ["len", "numpy.asarray", "numpy.zeros", "numpy.sign", "numpy.sum", "numpy.zeros", "range", "print", "numpy.matmul", "numpy.sum", "rdp_utils.gnmax_thresh_aggregator", "numpy.matmul", "np.matmul.reshape", "arr.flatten", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_thresh_aggregator"], ["", "def", "gradient_sign_rdp", "(", "output_list", ",", "step_size", ",", "sigma", ",", "sigma_thresh", ",", "orders", ",", "pca_mat", "=", "None", ",", "thresh", "=", "0.9", ")", ":", "\n", "    ", "n", "=", "len", "(", "output_list", ")", "\n", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ")", "\n", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project to principal components", "\n", "        ", "flatten_arr", "=", "np", ".", "matmul", "(", "flatten_arr", ",", "pca_mat", ")", "\n", "n_features", "=", "flatten_arr", ".", "shape", "[", "1", "]", "\n", "\n", "# first line for positive votes, second line for negative votes", "\n", "", "votes_arr", "=", "np", ".", "zeros", "(", "[", "2", ",", "n_features", "]", ")", "\n", "votes_sign", "=", "np", ".", "sign", "(", "flatten_arr", ")", "\n", "# counts for positive votes", "\n", "votes_arr", "[", "0", ",", ":", "]", "=", "np", ".", "sum", "(", "votes_sign", "[", "votes_sign", ">", "0", "]", ",", "axis", "=", "0", ")", "\n", "# counts for negative votes ", "\n", "votes_arr", "[", "1", ",", ":", "]", "=", "-", "np", ".", "sum", "(", "votes_sign", "[", "votes_sign", "<", "0", "]", ",", "axis", "=", "0", ")", "\n", "\n", "res_dir", "=", "np", ".", "zeros", "(", "[", "1", ",", "n_features", "]", ")", "\n", "\n", "rdp_budget", "=", "0", "\n", "skipped_cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "n_features", ")", ":", "\n", "        ", "dir_index", ",", "cur_budget", "=", "gnmax_thresh_aggregator", "(", "votes_arr", "[", ":", ",", "i", "]", ",", "thresh", "*", "n_teachers", ",", "sigma_thresh", ",", "sigma", ",", "\n", "orders", ")", "\n", "if", "dir_index", "==", "0", ":", "\n", "            ", "res_dir", "[", "0", ",", "i", "]", "=", "step_size", "\n", "", "elif", "dir_index", "==", "1", ":", "\n", "            ", "res_dir", "[", "0", ",", "i", "]", "=", "-", "step_size", "\n", "", "else", ":", "\n", "            ", "skipped_cnt", "+=", "1", "\n", "", "rdp_budget", "+=", "cur_budget", "\n", "\n", "", "print", "(", "\"Skipped %d feaatures out of %d\"", "%", "(", "skipped_cnt", ",", "n_features", ")", ")", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project res direction back to original axis", "\n", "        ", "res_dir", "=", "np", ".", "matmul", "(", "res_dir", ",", "np", ".", "transpose", "(", "pca_mat", ")", ")", "\n", "\n", "", "return", "res_dir", ".", "reshape", "(", "output_list", "[", "0", "]", ".", "shape", ")", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_rdp": [[292, 337], ["len", "numpy.asarray", "numpy.zeros", "numpy.argmax", "range", "numpy.sum", "numpy.max", "numpy.zeros", "numpy.matmul", "numpy.abs", "rdp_utils.gnmax_aggregator", "rdp_utils.gnmax_thresh_aggregator", "numpy.matmul", "np.matmul.reshape", "arr.flatten", "print", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_aggregator", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gnmax_thresh_aggregator"], ["", "def", "gradient_rdp", "(", "output_list", ",", "step_size", ",", "sigma", ",", "orders", ",", "pca_mat", "=", "None", ",", "thresh", "=", "None", ",", "sigma_thresh", "=", "1", ")", ":", "\n", "    ", "n", "=", "len", "(", "output_list", ")", "\n", "flatten_arr", "=", "np", ".", "asarray", "(", "[", "arr", ".", "flatten", "(", ")", "for", "arr", "in", "output_list", "]", ")", "\n", "n_teachers", ",", "n_features", "=", "flatten_arr", ".", "shape", "\n", "\n", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project to principal components", "\n", "        ", "flatten_arr", "=", "np", ".", "matmul", "(", "flatten_arr", ",", "pca_mat", ")", "\n", "n_features", "=", "flatten_arr", ".", "shape", "[", "1", "]", "\n", "\n", "# first half votes for positive direction, second half votes for negative direction", "\n", "", "votes_arr", "=", "np", ".", "zeros", "(", "[", "n_teachers", ",", "n_features", "*", "2", "]", ")", "\n", "max_index", "=", "np", ".", "argmax", "(", "np", ".", "abs", "(", "flatten_arr", ")", ",", "axis", "=", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_teachers", ")", ":", "\n", "        ", "if", "flatten_arr", "[", "i", ",", "max_index", "[", "i", "]", "]", ">", "0", ":", "\n", "            ", "votes_arr", "[", "i", ",", "max_index", "[", "i", "]", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "votes_arr", "[", "i", ",", "max_index", "[", "i", "]", "+", "n_features", "]", "=", "1", "\n", "\n", "", "", "votes_count", "=", "np", ".", "sum", "(", "votes_arr", ",", "axis", "=", "0", ")", "\n", "\n", "if", "thresh", "is", "None", ":", "\n", "        ", "dir_index", ",", "rdp_budget", "=", "gnmax_aggregator", "(", "votes_count", ",", "sigma", ",", "orders", ")", "\n", "", "else", ":", "\n", "        ", "dir_index", ",", "rdp_budget", "=", "gnmax_thresh_aggregator", "(", "votes_count", ",", "thresh", "*", "n_teachers", ",", "sigma_thresh", ",", "sigma", ",", "orders", ")", "\n", "\n", "", "max_votes", "=", "np", ".", "max", "(", "votes_count", ")", "\n", "selected_votes", "=", "votes_count", "[", "dir_index", "]", "\n", "# print(\"Max cnt: %d, selected cnt: %d\" % (max_votes, selected_votes))", "\n", "\n", "res_dir", "=", "np", ".", "zeros", "(", "[", "1", ",", "n_features", "]", ")", "\n", "\n", "if", "dir_index", "<", "n_features", "and", "dir_index", ">=", "0", ":", "\n", "        ", "res_dir", "[", "0", ",", "dir_index", "]", "=", "step_size", "\n", "", "elif", "dir_index", ">=", "n_features", ":", "\n", "        ", "res_dir", "[", "0", ",", "dir_index", "-", "n_features", "]", "=", "-", "step_size", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Teachers don't agree. Skip...\"", ")", "\n", "\n", "", "if", "pca_mat", "is", "not", "None", ":", "\n", "# project res direction back to original axis", "\n", "        ", "res_dir", "=", "np", ".", "matmul", "(", "res_dir", ",", "np", ".", "transpose", "(", "pca_mat", ")", ")", "\n", "\n", "", "return", "res_dir", ".", "reshape", "(", "output_list", "[", "0", "]", ".", "shape", ")", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gaussian_rdp": [[339, 346], ["numpy.random.normal", "numpy.zeros"], "function", ["None"], ["", "def", "gaussian_rdp", "(", "arr", ",", "sensitivity", ",", "orders", ",", "sigma", ")", ":", "\n", "    ", "gaussian_noise", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "np", ".", "zeros", "(", "arr", ".", "shape", ")", ",", "scale", "=", "sigma", "*", "sensitivity", ",", "size", "=", "arr", ".", "shape", ")", "\n", "\n", "# Table 2 @ https://arxiv.org/pdf/1702.07476.pdf", "\n", "rdp_budget", "=", "[", "o", "/", "(", "(", "2", "*", "sigma", ")", "**", "2", ")", "for", "o", "in", "orders", "]", "\n", "\n", "return", "gaussian_noise", ",", "rdp_budget", "\n", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.download": [[27, 53], ["os.path.join", "six.moves.urllib.request.urlopen", "open", "int", "print", "open.close", "url.split", "urllib.request.urlopen.read", "len", "open.write", "print", "sys.stdout.flush", "print", "print", "str", "int", "float"], "function", ["None"], ["def", "download", "(", "url", ",", "dirpath", ")", ":", "\n", "  ", "filename", "=", "url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dirpath", ",", "filename", ")", "\n", "u", "=", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "\n", "f", "=", "open", "(", "filepath", ",", "'wb'", ")", "\n", "filesize", "=", "int", "(", "u", ".", "headers", "[", "\"Content-Length\"", "]", ")", "\n", "print", "(", "\"Downloading: %s Bytes: %s\"", "%", "(", "filename", ",", "filesize", ")", ")", "\n", "\n", "downloaded", "=", "0", "\n", "block_sz", "=", "8192", "\n", "status_width", "=", "70", "\n", "while", "True", ":", "\n", "    ", "buf", "=", "u", ".", "read", "(", "block_sz", ")", "\n", "if", "not", "buf", ":", "\n", "      ", "print", "(", "''", ")", "\n", "break", "\n", "", "else", ":", "\n", "      ", "print", "(", "''", ",", "end", "=", "'\\r'", ")", "\n", "", "downloaded", "+=", "len", "(", "buf", ")", "\n", "f", ".", "write", "(", "buf", ")", "\n", "status", "=", "(", "(", "\"[%-\"", "+", "str", "(", "status_width", "+", "1", ")", "+", "\"s] %3.2f%%\"", ")", "%", "\n", "(", "'='", "*", "int", "(", "float", "(", "downloaded", ")", "/", "filesize", "*", "status_width", ")", "+", "'>'", ",", "downloaded", "*", "100.", "/", "filesize", ")", ")", "\n", "print", "(", "status", ",", "end", "=", "''", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.download_file_from_google_drive": [[54, 66], ["requests.Session", "requests.Session.get", "download.get_confirm_token", "download.save_response_content", "requests.Session.get"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.get_confirm_token", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.save_response_content"], ["", "def", "download_file_from_google_drive", "(", "id", ",", "destination", ")", ":", "\n", "  ", "URL", "=", "\"https://docs.google.com/uc?export=download\"", "\n", "session", "=", "requests", ".", "Session", "(", ")", "\n", "\n", "response", "=", "session", ".", "get", "(", "URL", ",", "params", "=", "{", "'id'", ":", "id", "}", ",", "stream", "=", "True", ")", "\n", "token", "=", "get_confirm_token", "(", "response", ")", "\n", "\n", "if", "token", ":", "\n", "    ", "params", "=", "{", "'id'", ":", "id", ",", "'confirm'", ":", "token", "}", "\n", "response", "=", "session", ".", "get", "(", "URL", ",", "params", "=", "params", ",", "stream", "=", "True", ")", "\n", "\n", "", "save_response_content", "(", "response", ",", "destination", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.get_confirm_token": [[67, 72], ["response.cookies.items", "key.startswith"], "function", ["None"], ["", "def", "get_confirm_token", "(", "response", ")", ":", "\n", "  ", "for", "key", ",", "value", "in", "response", ".", "cookies", ".", "items", "(", ")", ":", "\n", "    ", "if", "key", ".", "startswith", "(", "'download_warning'", ")", ":", "\n", "      ", "return", "value", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.save_response_content": [[73, 80], ["int", "response.headers.get", "open", "tqdm.tqdm", "response.iter_content", "f.write"], "function", ["None"], ["", "def", "save_response_content", "(", "response", ",", "destination", ",", "chunk_size", "=", "32", "*", "1024", ")", ":", "\n", "  ", "total_size", "=", "int", "(", "response", ".", "headers", ".", "get", "(", "'content-length'", ",", "0", ")", ")", "\n", "with", "open", "(", "destination", ",", "\"wb\"", ")", "as", "f", ":", "\n", "    ", "for", "chunk", "in", "tqdm", "(", "response", ".", "iter_content", "(", "chunk_size", ")", ",", "total", "=", "total_size", ",", "\n", "unit", "=", "'B'", ",", "unit_scale", "=", "True", ",", "desc", "=", "destination", ")", ":", "\n", "      ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "        ", "f", ".", "write", "(", "chunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.unzip": [[81, 87], ["print", "os.path.dirname", "os.remove", "zipfile.ZipFile", "zf.extractall"], "function", ["None"], ["", "", "", "", "def", "unzip", "(", "filepath", ")", ":", "\n", "  ", "print", "(", "\"Extracting: \"", "+", "filepath", ")", "\n", "dirpath", "=", "os", ".", "path", ".", "dirname", "(", "filepath", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "filepath", ")", "as", "zf", ":", "\n", "    ", "zf", ".", "extractall", "(", "dirpath", ")", "\n", "", "os", ".", "remove", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download._list_categories": [[89, 93], ["six.moves.urllib.request.urlopen", "json.loads", "urllib.request.urlopen.read"], "function", ["None"], ["", "def", "_list_categories", "(", "tag", ")", ":", "\n", "  ", "url", "=", "'http://lsun.cs.princeton.edu/htbin/list.cgi?tag='", "+", "tag", "\n", "f", "=", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download._download_lsun": [[94, 106], ["print", "os.path.join", "print", "subprocess.call", "locals", "locals"], "function", ["None"], ["", "def", "_download_lsun", "(", "out_dir", ",", "category", ",", "set_name", ",", "tag", ")", ":", "\n", "  ", "url", "=", "'http://lsun.cs.princeton.edu/htbin/download.cgi?tag={tag}'", "'&category={category}&set={set_name}'", ".", "format", "(", "**", "locals", "(", ")", ")", "\n", "print", "(", "url", ")", "\n", "if", "set_name", "==", "'test'", ":", "\n", "    ", "out_name", "=", "'test_lmdb.zip'", "\n", "", "else", ":", "\n", "    ", "out_name", "=", "'{category}_{set_name}_lmdb.zip'", ".", "format", "(", "**", "locals", "(", ")", ")", "\n", "", "out_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "out_name", ")", "\n", "cmd", "=", "[", "'curl'", ",", "url", ",", "'-o'", ",", "out_path", "]", "\n", "print", "(", "'Downloading'", ",", "category", ",", "set_name", ",", "'set'", ")", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.download_lsun": [[107, 123], ["os.path.join", "os.path.exists", "download._download_lsun", "print", "os.mkdir", "download._download_lsun", "download._download_lsun"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.download._download_lsun", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download._download_lsun", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download._download_lsun"], ["", "def", "download_lsun", "(", "dirpath", ")", ":", "\n", "  ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "dirpath", ",", "'lsun'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_dir", ")", ":", "\n", "    ", "print", "(", "'Found LSUN - skip'", ")", "\n", "return", "\n", "", "else", ":", "\n", "    ", "os", ".", "mkdir", "(", "data_dir", ")", "\n", "\n", "", "tag", "=", "'latest'", "\n", "#categories = _list_categories(tag)", "\n", "categories", "=", "[", "'bedroom'", "]", "\n", "\n", "for", "category", "in", "categories", ":", "\n", "    ", "_download_lsun", "(", "data_dir", ",", "category", ",", "'train'", ",", "tag", ")", "\n", "_download_lsun", "(", "data_dir", ",", "category", ",", "'val'", ",", "tag", ")", "\n", "", "_download_lsun", "(", "data_dir", ",", "''", ",", "'test'", ",", "tag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.download_fashion_mnist": [[124, 146], ["os.path.join", "os.path.exists", "print", "os.mkdir", "print", "os.path.join", "print", "subprocess.call", "print", "subprocess.call", "locals"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir"], ["", "def", "download_fashion_mnist", "(", "dirpath", ")", ":", "\n", "  ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "dirpath", ",", "'fashion_mnist'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_dir", ")", ":", "\n", "    ", "print", "(", "'Found MNIST - skip'", ")", "\n", "return", "\n", "", "else", ":", "\n", "    ", "os", ".", "mkdir", "(", "data_dir", ")", "\n", "", "url_base", "=", "'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'", "\n", "file_names", "=", "[", "'train-images-idx3-ubyte.gz'", ",", "\n", "'train-labels-idx1-ubyte.gz'", ",", "\n", "'t10k-images-idx3-ubyte.gz'", ",", "\n", "'t10k-labels-idx1-ubyte.gz'", "]", "\n", "for", "file_name", "in", "file_names", ":", "\n", "    ", "url", "=", "(", "url_base", "+", "file_name", ")", ".", "format", "(", "**", "locals", "(", ")", ")", "\n", "print", "(", "url", ")", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", "\n", "cmd", "=", "[", "'curl'", ",", "url", ",", "'-o'", ",", "out_path", "]", "\n", "print", "(", "'Downloading '", ",", "file_name", ")", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "cmd", "=", "[", "'gzip'", ",", "'-d'", ",", "out_path", "]", "\n", "print", "(", "'Decompressing '", ",", "file_name", ")", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.download_mnist": [[147, 169], ["os.path.join", "os.path.exists", "print", "os.mkdir", "print", "os.path.join", "print", "subprocess.call", "print", "subprocess.call", "locals"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir"], ["", "", "def", "download_mnist", "(", "dirpath", ")", ":", "\n", "  ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "dirpath", ",", "'mnist'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_dir", ")", ":", "\n", "    ", "print", "(", "'Found MNIST - skip'", ")", "\n", "return", "\n", "", "else", ":", "\n", "    ", "os", ".", "mkdir", "(", "data_dir", ")", "\n", "", "url_base", "=", "'http://yann.lecun.com/exdb/mnist/'", "\n", "file_names", "=", "[", "'train-images-idx3-ubyte.gz'", ",", "\n", "'train-labels-idx1-ubyte.gz'", ",", "\n", "'t10k-images-idx3-ubyte.gz'", ",", "\n", "'t10k-labels-idx1-ubyte.gz'", "]", "\n", "for", "file_name", "in", "file_names", ":", "\n", "    ", "url", "=", "(", "url_base", "+", "file_name", ")", ".", "format", "(", "**", "locals", "(", ")", ")", "\n", "print", "(", "url", ")", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", "\n", "cmd", "=", "[", "'curl'", ",", "url", ",", "'-o'", ",", "out_path", "]", "\n", "print", "(", "'Downloading '", ",", "file_name", ")", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "cmd", "=", "[", "'gzip'", ",", "'-d'", ",", "out_path", "]", "\n", "print", "(", "'Decompressing '", ",", "file_name", ")", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.download.prepare_data_dir": [[170, 173], ["os.path.exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir"], ["", "", "def", "prepare_data_dir", "(", "path", "=", "'./data'", ")", ":", "\n", "  ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._logaddexp": [[36, 40], ["max", "math.log", "sum", "numpy.exp"], "function", ["None"], ["def", "_logaddexp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Addition in the log space. Analogue of numpy.logaddexp for a list.\"\"\"", "\n", "m", "=", "max", "(", "x", ")", "\n", "return", "m", "+", "math", ".", "log", "(", "sum", "(", "np", ".", "exp", "(", "x", "-", "m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._log1mexp": [[42, 52], ["math.log1p", "math.log", "math.exp", "ValueError", "math.expm1"], "function", ["None"], ["", "def", "_log1mexp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Numerically stable computation of log(1-exp(x)).\"\"\"", "\n", "if", "x", "<", "-", "1", ":", "\n", "    ", "return", "math", ".", "log1p", "(", "-", "math", ".", "exp", "(", "x", ")", ")", "\n", "", "elif", "x", "<", "0", ":", "\n", "    ", "return", "math", ".", "log", "(", "-", "math", ".", "expm1", "(", "x", ")", ")", "\n", "", "elif", "x", "==", "0", ":", "\n", "    ", "return", "-", "np", ".", "inf", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Argument must be non-positive.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_eps_from_delta": [[54, 73], ["numpy.argmin", "len", "len", "ValueError", "numpy.array", "math.log", "numpy.array"], "function", ["None"], ["", "", "def", "compute_eps_from_delta", "(", "orders", ",", "rdp", ",", "delta", ")", ":", "\n", "  ", "\"\"\"Translates between RDP and (eps, delta)-DP.\n\n  Args:\n    orders: A list (or a scalar) of orders.\n    rdp: A list of RDP guarantees (of the same length as orders).\n    delta: Target delta.\n\n  Returns:\n    Pair of (eps, optimal_order).\n\n  Raises:\n    ValueError: If input is malformed.\n  \"\"\"", "\n", "if", "len", "(", "orders", ")", "!=", "len", "(", "rdp", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"Input lists must have the same length.\"", ")", "\n", "", "eps", "=", "np", ".", "array", "(", "rdp", ")", "-", "math", ".", "log", "(", "delta", ")", "/", "(", "np", ".", "array", "(", "orders", ")", "-", "1", ")", "\n", "idx_opt", "=", "np", ".", "argmin", "(", "eps", ")", "\n", "return", "eps", "[", "idx_opt", "]", ",", "orders", "[", "idx_opt", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logq_gaussian": [[80, 110], ["len", "numpy.argmax", "pate_core._logaddexp", "min", "scipy.stats.norm.logsf", "math.log", "numpy.arange", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._logaddexp"], ["", "def", "compute_logq_gaussian", "(", "counts", ",", "sigma", ")", ":", "\n", "  ", "\"\"\"Returns an upper bound on ln Pr[outcome != argmax] for GNMax.\n\n  Implementation of Proposition 7.\n\n  Args:\n    counts: A numpy array of scores.\n    sigma: The standard deviation of the Gaussian noise in the GNMax mechanism.\n\n  Returns:\n    logq: Natural log of the probability that outcome is different from argmax.\n  \"\"\"", "\n", "n", "=", "len", "(", "counts", ")", "\n", "variance", "=", "sigma", "**", "2", "\n", "idx_max", "=", "np", ".", "argmax", "(", "counts", ")", "\n", "counts_normalized", "=", "counts", "[", "idx_max", "]", "-", "counts", "\n", "counts_rest", "=", "counts_normalized", "[", "np", ".", "arange", "(", "n", ")", "!=", "idx_max", "]", "# exclude one index", "\n", "# Upper bound q via a union bound rather than a more precise calculation.", "\n", "logq", "=", "_logaddexp", "(", "\n", "scipy", ".", "stats", ".", "norm", ".", "logsf", "(", "counts_rest", ",", "scale", "=", "math", ".", "sqrt", "(", "2", "*", "variance", ")", ")", ")", "\n", "\n", "# A sketch of a more accurate estimate, which is currently disabled for two", "\n", "# reasons:", "\n", "# 1. Numerical instability;", "\n", "# 2. Not covered by smooth sensitivity analysis.", "\n", "# covariance = variance * (np.ones((n - 1, n - 1)) + np.identity(n - 1))", "\n", "# logq = np.log1p(-statsmodels.sandbox.distributions.extras.mvnormcdf(", "\n", "#     counts_rest, np.zeros(n - 1), covariance, maxpts=1e4))", "\n", "\n", "return", "min", "(", "logq", ",", "math", ".", "log", "(", "1", "-", "(", "1", "/", "n", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_data_independent_gaussian": [[112, 135], ["numpy.isscalar", "numpy.any", "ValueError", "numpy.atleast_1d"], "function", ["None"], ["", "def", "rdp_data_independent_gaussian", "(", "sigma", ",", "orders", ")", ":", "\n", "  ", "\"\"\"Computes a data-independent RDP curve for GNMax.\n\n  Implementation of Proposition 8.\n\n  Args:\n    sigma: Standard deviation of Gaussian noise.\n    orders: An array_like list of Renyi orders.\n\n  Returns:\n    Upper bound on RPD for all orders. A scalar if orders is a scalar.\n\n  Raises:\n    ValueError: If the input is malformed.\n  \"\"\"", "\n", "if", "sigma", "<", "0", "or", "np", ".", "any", "(", "orders", "<=", "1", ")", ":", "# not defined for alpha=1", "\n", "    ", "raise", "ValueError", "(", "\"Inputs are malformed.\"", ")", "\n", "\n", "", "variance", "=", "sigma", "**", "2", "\n", "if", "np", ".", "isscalar", "(", "orders", ")", ":", "\n", "    ", "return", "orders", "/", "variance", "\n", "", "else", ":", "\n", "    ", "return", "np", ".", "atleast_1d", "(", "orders", ")", "/", "variance", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_gaussian": [[137, 199], ["numpy.isneginf", "math.sqrt", "numpy.atleast_1d", "numpy.logical_and", "numpy.all", "numpy.isscalar", "numpy.any", "ValueError", "numpy.isscalar", "numpy.any", "pate_core._log1mexp", "numpy.logaddexp", "numpy.asscalar", "numpy.full_like", "numpy.minimum", "pate_core._log1mexp", "math.log", "math.log"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._log1mexp", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._log1mexp"], ["", "", "def", "rdp_gaussian", "(", "logq", ",", "sigma", ",", "orders", ")", ":", "\n", "  ", "\"\"\"Bounds RDP from above of GNMax given an upper bound on q (Theorem 6).\n\n  Args:\n    logq: Natural logarithm of the probability of a non-argmax outcome.\n    sigma: Standard deviation of Gaussian noise.\n    orders: An array_like list of Renyi orders.\n\n  Returns:\n    Upper bound on RPD for all orders. A scalar if orders is a scalar.\n\n  Raises:\n    ValueError: If the input is malformed.\n  \"\"\"", "\n", "if", "logq", ">", "0", "or", "sigma", "<", "0", "or", "np", ".", "any", "(", "orders", "<=", "1", ")", ":", "# not defined for alpha=1", "\n", "    ", "raise", "ValueError", "(", "\"Inputs are malformed.\"", ")", "\n", "\n", "", "if", "np", ".", "isneginf", "(", "logq", ")", ":", "# If the mechanism's output is fixed, it has 0-DP.", "\n", "    ", "if", "np", ".", "isscalar", "(", "orders", ")", ":", "\n", "      ", "return", "0.", "\n", "", "else", ":", "\n", "      ", "return", "np", ".", "full_like", "(", "orders", ",", "0.", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "", "variance", "=", "sigma", "**", "2", "\n", "\n", "# Use two different higher orders: mu_hi1 and mu_hi2 computed according to", "\n", "# Proposition 10.", "\n", "mu_hi2", "=", "math", ".", "sqrt", "(", "variance", "*", "-", "logq", ")", "\n", "mu_hi1", "=", "mu_hi2", "+", "1", "\n", "\n", "orders_vec", "=", "np", ".", "atleast_1d", "(", "orders", ")", "\n", "\n", "ret", "=", "orders_vec", "/", "variance", "# baseline: data-independent bound", "\n", "\n", "# Filter out entries where data-dependent bound does not apply.", "\n", "mask", "=", "np", ".", "logical_and", "(", "mu_hi1", ">", "orders_vec", ",", "mu_hi2", ">", "1", ")", "\n", "\n", "rdp_hi1", "=", "mu_hi1", "/", "variance", "\n", "rdp_hi2", "=", "mu_hi2", "/", "variance", "\n", "\n", "log_a2", "=", "(", "mu_hi2", "-", "1", ")", "*", "rdp_hi2", "\n", "\n", "# Make sure q is in the increasing wrt q range and A is positive.", "\n", "if", "(", "np", ".", "any", "(", "mask", ")", "and", "logq", "<=", "log_a2", "-", "mu_hi2", "*", "\n", "(", "math", ".", "log", "(", "1", "+", "1", "/", "(", "mu_hi1", "-", "1", ")", ")", "+", "math", ".", "log", "(", "1", "+", "1", "/", "(", "mu_hi2", "-", "1", ")", ")", ")", "and", "\n", "-", "logq", ">", "rdp_hi2", ")", ":", "\n", "# Use log1p(x) = log(1 + x) to avoid catastrophic cancellations when x ~ 0.", "\n", "    ", "log1q", "=", "_log1mexp", "(", "logq", ")", "# log1q = log(1-q)", "\n", "log_a", "=", "(", "orders", "-", "1", ")", "*", "(", "\n", "log1q", "-", "_log1mexp", "(", "(", "logq", "+", "rdp_hi2", ")", "*", "(", "1", "-", "1", "/", "mu_hi2", ")", ")", ")", "\n", "log_b", "=", "(", "orders", "-", "1", ")", "*", "(", "rdp_hi1", "-", "logq", "/", "(", "mu_hi1", "-", "1", ")", ")", "\n", "\n", "# Use logaddexp(x, y) = log(e^x + e^y) to avoid overflow for large x, y.", "\n", "log_s", "=", "np", ".", "logaddexp", "(", "log1q", "+", "log_a", ",", "logq", "+", "log_b", ")", "\n", "ret", "[", "mask", "]", "=", "np", ".", "minimum", "(", "ret", ",", "log_s", "/", "(", "orders", "-", "1", ")", ")", "[", "mask", "]", "\n", "\n", "", "assert", "np", ".", "all", "(", "ret", ">=", "0", ")", "\n", "\n", "if", "np", ".", "isscalar", "(", "orders", ")", ":", "\n", "    ", "return", "np", ".", "asscalar", "(", "ret", ")", "\n", "", "else", ":", "\n", "    ", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.is_data_independent_always_opt_gaussian": [[201, 222], ["numpy.array", "pate_core.compute_logq_gaussian", "pate_core.rdp_gaussian", "pate_core.rdp_data_independent_gaussian", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logq_gaussian", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_gaussian", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_data_independent_gaussian"], ["", "", "def", "is_data_independent_always_opt_gaussian", "(", "num_teachers", ",", "num_classes", ",", "sigma", ",", "\n", "orders", ")", ":", "\n", "  ", "\"\"\"Tests whether data-ind bound is always optimal for GNMax.\n\n  Args:\n    num_teachers: Number of teachers.\n    num_classes: Number of classes.\n    sigma: Standard deviation of the Gaussian noise.\n    orders: An array_like list of Renyi orders.\n\n  Returns:\n    Boolean array of length |orders| (a scalar if orders is a scalar). True if\n    the data-independent bound is always the same as the data-dependent bound.\n\n  \"\"\"", "\n", "unanimous", "=", "np", ".", "array", "(", "[", "num_teachers", "]", "+", "[", "0", "]", "*", "(", "num_classes", "-", "1", ")", ")", "\n", "logq", "=", "compute_logq_gaussian", "(", "unanimous", ",", "sigma", ")", "\n", "\n", "rdp_dep", "=", "rdp_gaussian", "(", "logq", ",", "sigma", ",", "orders", ")", "\n", "rdp_ind", "=", "rdp_data_independent_gaussian", "(", "sigma", ",", "orders", ")", "\n", "return", "np", ".", "isclose", "(", "rdp_dep", ",", "rdp_ind", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logpr_answered": [[229, 244], ["scipy.stats.norm.logsf", "round", "max"], "function", ["None"], ["", "def", "compute_logpr_answered", "(", "t", ",", "sigma", ",", "counts", ")", ":", "\n", "  ", "\"\"\"Computes log of the probability that a noisy threshold is crossed.\n\n  Args:\n    t: The threshold.\n    sigma: The stdev of the Gaussian noise added to the threshold.\n    counts: An array of votes.\n\n  Returns:\n    Natural log of the probability that max is larger than a noisy threshold.\n  \"\"\"", "\n", "# Compared to the paper, max(counts) is rounded to the nearest integer. This", "\n", "# is done to facilitate computation of smooth sensitivity for the case of", "\n", "# the interactive mechanism, where votes are not necessarily integer.", "\n", "return", "scipy", ".", "stats", ".", "norm", ".", "logsf", "(", "t", "-", "round", "(", "max", "(", "counts", ")", ")", ",", "scale", "=", "sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_data_independent_threshold": [[246, 250], ["pate_core.rdp_data_independent_gaussian"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_data_independent_gaussian"], ["", "def", "compute_rdp_data_independent_threshold", "(", "sigma", ",", "orders", ")", ":", "\n", "# The input to the threshold mechanism has stability 1, compared to", "\n", "# GNMax, which has stability = 2. Hence the sqrt(2) factor below.", "\n", "  ", "return", "rdp_data_independent_gaussian", "(", "2", "**", ".5", "*", "sigma", ",", "orders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_threshold": [[252, 257], ["min", "pate_core.rdp_gaussian", "pate_core._log1mexp"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_gaussian", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._log1mexp"], ["", "def", "compute_rdp_threshold", "(", "log_pr_answered", ",", "sigma", ",", "orders", ")", ":", "\n", "  ", "logq", "=", "min", "(", "log_pr_answered", ",", "_log1mexp", "(", "log_pr_answered", ")", ")", "\n", "# The input to the threshold mechanism has stability 1, compared to", "\n", "# GNMax, which has stability = 2. Hence the sqrt(2) factor below.", "\n", "return", "rdp_gaussian", "(", "logq", ",", "2", "**", ".5", "*", "sigma", ",", "orders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.is_data_independent_always_opt_threshold": [[259, 296], ["pate_core.compute_logpr_answered", "pate_core.compute_logpr_answered", "pate_core.compute_rdp_threshold", "pate_core.compute_rdp_threshold", "pate_core.compute_rdp_data_independent_threshold", "numpy.isclose", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logpr_answered", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logpr_answered", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_threshold", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_threshold", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_rdp_data_independent_threshold"], ["", "def", "is_data_independent_always_opt_threshold", "(", "num_teachers", ",", "threshold", ",", "sigma", ",", "\n", "orders", ")", ":", "\n", "  ", "\"\"\"Tests whether data-ind bound is always optimal for the threshold mechanism.\n\n  Args:\n    num_teachers: Number of teachers.\n    threshold: The cut-off threshold.\n    sigma: Standard deviation of the Gaussian noise.\n    orders: An array_like list of Renyi orders.\n\n  Returns:\n    Boolean array of length |orders| (a scalar if orders is a scalar). True if\n    the data-independent bound is always the same as the data-dependent bound.\n  \"\"\"", "\n", "\n", "# Since the data-dependent bound depends only on max(votes), it suffices to", "\n", "# check whether the data-dependent bounds are better than data-independent", "\n", "# bounds in the extreme cases when max(votes) is minimal or maximal.", "\n", "# For both Confident GNMax and Interactive GNMax it holds that", "\n", "#   0 <= max(votes) <= num_teachers.", "\n", "# The upper bound is trivial in both cases.", "\n", "# The lower bound is trivial for Confident GNMax (and a stronger one, based on", "\n", "# the pigeonhole principle, is possible).", "\n", "# For Interactive GNMax (Algorithm 2), the lower bound follows from the", "\n", "# following argument. Since the votes vector is the difference between the", "\n", "# actual teachers' votes and the student's baseline, we need to argue that", "\n", "# max(n_j - M * p_j) >= 0.", "\n", "# The bound holds because sum_j n_j = sum M * p_j = M. Thus,", "\n", "# sum_j (n_j - M * p_j) = 0, and max_j (n_j - M * p_j) >= 0 as needed.", "\n", "logq1", "=", "compute_logpr_answered", "(", "threshold", ",", "sigma", ",", "[", "0", "]", ")", "\n", "logq2", "=", "compute_logpr_answered", "(", "threshold", ",", "sigma", ",", "[", "num_teachers", "]", ")", "\n", "\n", "rdp_dep1", "=", "compute_rdp_threshold", "(", "logq1", ",", "sigma", ",", "orders", ")", "\n", "rdp_dep2", "=", "compute_rdp_threshold", "(", "logq2", ",", "sigma", ",", "orders", ")", "\n", "\n", "rdp_ind", "=", "compute_rdp_data_independent_threshold", "(", "sigma", ",", "orders", ")", "\n", "return", "np", ".", "isclose", "(", "rdp_dep1", ",", "rdp_ind", ")", "and", "np", ".", "isclose", "(", "rdp_dep2", ",", "rdp_ind", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_logq_laplace": [[303, 327], ["numpy.argmax", "numpy.array", "pate_core._logaddexp", "min", "math.log", "range", "numpy.log", "math.log", "len", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._logaddexp"], ["", "def", "compute_logq_laplace", "(", "counts", ",", "lmbd", ")", ":", "\n", "  ", "\"\"\"Computes an upper bound on log Pr[outcome != argmax] for LNMax.\n\n  Args:\n    counts: A list of scores.\n    lmbd: The lambda parameter of the Laplace distribution ~exp(-|x| / lambda).\n\n  Returns:\n    logq: Natural log of the probability that outcome is different from argmax.\n  \"\"\"", "\n", "# For noisy max, we only get an upper bound via the union bound. See Lemma 4", "\n", "# in https://arxiv.org/abs/1610.05755.", "\n", "#", "\n", "# Pr[ j beats i*] = (2+gap(j,i*))/ 4 exp(gap(j,i*)", "\n", "# proof at http://mathoverflow.net/questions/66763/", "\n", "\n", "idx_max", "=", "np", ".", "argmax", "(", "counts", ")", "\n", "counts_normalized", "=", "(", "counts", "-", "counts", "[", "idx_max", "]", ")", "/", "lmbd", "\n", "counts_rest", "=", "np", ".", "array", "(", "\n", "[", "counts_normalized", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "counts", ")", ")", "if", "i", "!=", "idx_max", "]", ")", "\n", "\n", "logq", "=", "_logaddexp", "(", "np", ".", "log", "(", "2", "-", "counts_rest", ")", "+", "math", ".", "log", "(", ".25", ")", "+", "counts_rest", ")", "\n", "\n", "return", "min", "(", "logq", ",", "math", ".", "log", "(", "1", "-", "(", "1", "/", "len", "(", "counts", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.rdp_pure_eps": [[329, 366], ["numpy.atleast_1d", "math.exp", "numpy.full_like", "numpy.minimum", "numpy.isscalar", "numpy.logaddexp", "numpy.minimum", "numpy.asscalar", "math.log1p", "math.exp", "math.log1p", "pate_core._log1mexp"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core._log1mexp"], ["", "def", "rdp_pure_eps", "(", "logq", ",", "pure_eps", ",", "orders", ")", ":", "\n", "  ", "\"\"\"Computes the RDP value given logq and pure privacy eps.\n\n  Implementation of https://arxiv.org/abs/1610.05755, Theorem 3.\n\n  The bound used is the min of three terms. The first term is from\n  https://arxiv.org/pdf/1605.02065.pdf.\n  The second term is based on the fact that when event has probability (1-q) for\n  q close to zero, q can only change by exp(eps), which corresponds to a\n  much smaller multiplicative change in (1-q)\n  The third term comes directly from the privacy guarantee.\n\n  Args:\n    logq: Natural logarithm of the probability of a non-optimal outcome.\n    pure_eps: eps parameter for DP\n    orders: array_like list of moments to compute.\n\n  Returns:\n    Array of upper bounds on rdp (a scalar if orders is a scalar).\n  \"\"\"", "\n", "orders_vec", "=", "np", ".", "atleast_1d", "(", "orders", ")", "\n", "q", "=", "math", ".", "exp", "(", "logq", ")", "\n", "log_t", "=", "np", ".", "full_like", "(", "orders_vec", ",", "np", ".", "inf", ")", "\n", "if", "q", "<=", "1", "/", "(", "math", ".", "exp", "(", "pure_eps", ")", "+", "1", ")", ":", "\n", "    ", "logt_one", "=", "math", ".", "log1p", "(", "-", "q", ")", "+", "(", "\n", "math", ".", "log1p", "(", "-", "q", ")", "-", "_log1mexp", "(", "pure_eps", "+", "logq", ")", ")", "*", "(", "\n", "orders_vec", "-", "1", ")", "\n", "logt_two", "=", "logq", "+", "pure_eps", "*", "(", "orders_vec", "-", "1", ")", "\n", "log_t", "=", "np", ".", "logaddexp", "(", "logt_one", ",", "logt_two", ")", "\n", "\n", "", "ret", "=", "np", ".", "minimum", "(", "\n", "np", ".", "minimum", "(", "0.5", "*", "pure_eps", "*", "pure_eps", "*", "orders_vec", ",", "\n", "log_t", "/", "(", "orders_vec", "-", "1", ")", ")", ",", "pure_eps", ")", "\n", "if", "np", ".", "isscalar", "(", "orders", ")", ":", "\n", "    ", "return", "np", ".", "asscalar", "(", "ret", ")", "\n", "", "else", ":", "\n", "    ", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.main": [[368, 370], ["None"], "function", ["None"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "# Unused.", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.__init__": [[74, 290], ["ops.batch_norm", "ops.batch_norm", "ops.batch_norm", "ops.batch_norm", "ops.batch_norm", "ops.batch_norm", "ops.batch_norm", "numpy.zeros", "defaultdict", "range", "len", "model.DCGAN.build_model", "numpy.asarray", "numpy.hstack", "model.DCGAN.load_mnist", "shuffle", "model.partition_dataset", "model.DCGAN.train_data_list.append", "model.DCGAN.train_label_list.append", "print", "model.DCGAN.load_fashion_mnist", "numpy.arange", "numpy.random.shuffle", "model.DCGAN.load_cifar", "model.DCGAN.load_small_celebA_gender", "model.DCGAN.dataset_name.split", "numpy.random.shuffle", "model.DCGAN.load_celebA_hair", "model.DCGAN.dataset_name.split", "numpy.random.shuffle", "model.DCGAN.load_celebA_gender", "model.DCGAN.dataset_name.split", "numpy.random.shuffle", "model.DCGAN.load_cinic", "model.DCGAN.slt", "print", "model.DCGAN.load_isolet", "model.DCGAN.load_fire_data", "model.DCGAN.load_census_data", "Exception"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.build_model", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_mnist", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.partition_dataset", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_fashion_mnist", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_cifar", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_small_celebA_gender", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_celebA_hair", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_celebA_gender", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_cinic", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.slt", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_isolet", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_fire_data", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_census_data"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "input_height", "=", "32", ",", "input_width", "=", "32", ",", "crop", "=", "False", ",", "\n", "batch_size", "=", "64", ",", "sample_num", "=", "64", ",", "output_height", "=", "32", ",", "output_width", "=", "32", ",", "\n", "y_dim", "=", "10", ",", "z_dim", "=", "100", ",", "gf_dim", "=", "64", ",", "df_dim", "=", "32", ",", "sample_step", "=", "800", ",", "\n", "gfc_dim", "=", "1024", ",", "dfc_dim", "=", "256", ",", "c_dim", "=", "3", ",", "dataset_name", "=", "'default'", ",", "\n", "input_fname_pattern", "=", "'*.jpg'", ",", "checkpoint_dir", "=", "None", ",", "teacher_dir", "=", "None", ",", "generator_dir", "=", "None", ",", "\n", "sample_dir", "=", "None", ",", "data_dir", "=", "'./data'", ",", "batch_teachers", "=", "10", ",", "teachers_batch", "=", "2", ",", "\n", "orders", "=", "None", ",", "\n", "thresh", "=", "None", ",", "dp_delta", "=", "1e-5", ",", "pca", "=", "False", ",", "pca_dim", "=", "5", ",", "non_private", "=", "False", ",", "random_proj", "=", "False", ",", "wgan", "=", "False", ",", "\n", "wgan_scale", "=", "10", ",", "small", "=", "False", ",", "config", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          sess: TensorFlow session\n          batch_size: The size of batch. Should be specified before training.\n          z_dim: (optional) Dimension of dim for Z. [100]\n          gf_dim: (optional) Dimension of gen filters in first conv layer. [64]\n          df_dim: (optional) Dimension of discrim filters in first conv layer. [64]\n          gfc_dim: (optional) Dimension of gen units for for fully connected layer. [1024]\n          dfc_dim: (optional) Dimension of discrim units for fully connected layer. [1024]\n          c_dim: (optional) Dimension of image color. For grayscale input, set to 1. [3]\n          batch_teachers:  Number of teacher models in one batch. Default 10.\n          teachers_batch:  Batches of training teacher models. Default 1.\n        \"\"\"", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "small", "=", "small", "\n", "self", ".", "wgan", "=", "wgan", "\n", "self", ".", "wgan_scale", "=", "wgan_scale", "\n", "\n", "self", ".", "sample_step", "=", "sample_step", "\n", "self", ".", "pca", "=", "pca", "\n", "self", ".", "pca_dim", "=", "pca_dim", "\n", "self", ".", "random_proj", "=", "random_proj", "\n", "\n", "self", ".", "dp_eps_list", "=", "[", "]", "\n", "self", ".", "rdp_eps_list", "=", "[", "]", "\n", "self", ".", "rdp_order_list", "=", "[", "]", "\n", "self", ".", "thresh", "=", "thresh", "\n", "self", ".", "dp_delta", "=", "dp_delta", "\n", "self", ".", "sample_dir", "=", "sample_dir", "\n", "self", ".", "dataset", "=", "dataset_name", "\n", "self", ".", "batch_teachers", "=", "batch_teachers", "\n", "self", ".", "teachers_batch", "=", "teachers_batch", "\n", "self", ".", "overall_teachers", "=", "batch_teachers", "*", "teachers_batch", "\n", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "crop", "=", "crop", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "sample_num", "=", "sample_num", "\n", "\n", "self", ".", "input_height", "=", "input_height", "\n", "self", ".", "input_width", "=", "input_width", "\n", "self", ".", "output_height", "=", "output_height", "\n", "self", ".", "output_width", "=", "output_width", "\n", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "y_dim", "=", "y_dim", "\n", "\n", "self", ".", "gf_dim", "=", "gf_dim", "\n", "self", ".", "df_dim", "=", "df_dim", "\n", "\n", "self", ".", "gfc_dim", "=", "gfc_dim", "\n", "self", ".", "dfc_dim", "=", "dfc_dim", "\n", "\n", "# batch normalization : deals with poor initialization helps gradient flow", "\n", "self", ".", "d_bn1", "=", "batch_norm", "(", "name", "=", "'d_bn1'", ")", "\n", "self", ".", "d_bn2", "=", "batch_norm", "(", "name", "=", "'d_bn2'", ")", "\n", "self", ".", "d_bn3", "=", "batch_norm", "(", "name", "=", "'d_bn3'", ")", "\n", "\n", "self", ".", "g_bn0", "=", "batch_norm", "(", "name", "=", "'g_bn0'", ")", "\n", "self", ".", "g_bn1", "=", "batch_norm", "(", "name", "=", "'g_bn1'", ")", "\n", "self", ".", "g_bn2", "=", "batch_norm", "(", "name", "=", "'g_bn2'", ")", "\n", "self", ".", "g_bn3", "=", "batch_norm", "(", "name", "=", "'g_bn3'", ")", "\n", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "input_fname_pattern", "=", "input_fname_pattern", "\n", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "self", ".", "teacher_dir", "=", "teacher_dir", "\n", "self", ".", "generator_dir", "=", "generator_dir", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "\n", "if", "orders", "is", "not", "None", ":", "\n", "            ", "self", ".", "orders", "=", "np", ".", "asarray", "(", "orders", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "orders", "=", "np", ".", "hstack", "(", "[", "1.1", ",", "np", ".", "arange", "(", "2", ",", "config", ".", "orders", ")", "]", ")", "\n", "\n", "", "self", ".", "rdp_counter", "=", "np", ".", "zeros", "(", "self", ".", "orders", ".", "shape", ")", "\n", "\n", "# Load the dataset, ignore test data for now", "\n", "if", "self", ".", "dataset_name", "==", "'mnist'", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_mnist", "(", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "1", ")", "\n", "self", ".", "input_height", "=", "self", ".", "input_width", "=", "28", "\n", "self", ".", "output_height", "=", "self", ".", "output_width", "=", "28", "\n", "\n", "", "elif", "self", ".", "dataset_name", "==", "'fashion_mnist'", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_fashion_mnist", "(", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "# = (self.c_dim == 1)", "\n", "self", ".", "input_height", "=", "self", ".", "input_width", "=", "28", "\n", "self", ".", "output_height", "=", "self", ".", "output_width", "=", "28", "\n", "if", "self", ".", "config", ".", "random_label", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "data_y", ")", "\n", "\n", "", "", "elif", "self", ".", "dataset_name", "==", "'cifar'", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_cifar", "(", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "3", ")", "\n", "\n", "", "elif", "'small-celebA-gender'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "mode", "=", "self", ".", "dataset_name", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "self", ".", "y_dim", "=", "2", "\n", "self", ".", "input_size", "=", "self", ".", "input_height", "=", "self", ".", "input_width", "=", "32", "\n", "self", ".", "output_size", "=", "self", ".", "output_height", "=", "self", ".", "output_width", "=", "32", "\n", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_small_celebA_gender", "(", "mode", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "1", ")", "\n", "\n", "if", "self", ".", "config", ".", "random_label", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "data_y", ")", "\n", "\n", "", "", "elif", "'celebA-hair'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "mode", "=", "self", ".", "dataset_name", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "self", ".", "y_dim", "=", "3", "\n", "self", ".", "input_size", "=", "self", ".", "input_height", "=", "self", ".", "input_width", "=", "64", "\n", "self", ".", "output_size", "=", "self", ".", "output_height", "=", "self", ".", "output_width", "=", "64", "\n", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_celebA_hair", "(", "mode", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "1", ")", "\n", "\n", "if", "self", ".", "config", ".", "random_label", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "data_y", ")", "\n", "\n", "", "", "elif", "'celebA-gender'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "mode", "=", "self", ".", "dataset_name", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "self", ".", "y_dim", "=", "2", "\n", "self", ".", "input_size", "=", "self", ".", "input_height", "=", "self", ".", "input_width", "=", "64", "\n", "self", ".", "output_size", "=", "self", ".", "output_height", "=", "self", ".", "output_width", "=", "64", "\n", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_celebA_gender", "(", "mode", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "1", ")", "\n", "\n", "if", "self", ".", "config", ".", "random_label", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "data_y", ")", "\n", "\n", "", "", "elif", "self", ".", "dataset_name", "==", "'cinic'", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_cinic", "(", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "3", ")", "\n", "\n", "", "elif", "self", ".", "dataset_name", "==", "'slt'", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "slt", "(", ")", "\n", "self", ".", "c_dim", "=", "self", ".", "data_X", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "grayscale", "=", "(", "self", ".", "c_dim", "==", "3", ")", "\n", "print", "(", "self", ".", "data_X", ".", "shape", ")", "\n", "\n", "\n", "", "elif", "'isolet'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "self", ".", "load_isolet", "(", ")", "\n", "self", ".", "train_size", ",", "self", ".", "input_size", "=", "self", ".", "data_X", ".", "shape", "\n", "self", ".", "output_size", "=", "self", ".", "input_size", "\n", "# self.y_dim = None", "\n", "# self.crop = False", "\n", "if", "self", ".", "pca_dim", ">", "self", ".", "input_size", ":", "\n", "                ", "self", ".", "pca_dim", "=", "self", ".", "input_size", "\n", "\n", "", "", "elif", "'fire-small'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "self", ".", "data_X", "=", "self", ".", "load_fire_data", "(", ")", "\n", "self", ".", "data_y", "=", "None", "\n", "self", ".", "train_size", ",", "self", ".", "input_size", "=", "self", ".", "data_X", ".", "shape", "\n", "self", ".", "output_size", "=", "self", ".", "input_size", "\n", "self", ".", "y_dim", "=", "None", "\n", "self", ".", "crop", "=", "False", "\n", "if", "self", ".", "pca_dim", ">", "self", ".", "input_size", ":", "\n", "                ", "self", ".", "pca_dim", "=", "self", ".", "input_size", "\n", "", "", "elif", "'census'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "self", ".", "data_X", "=", "self", ".", "load_census_data", "(", ")", "\n", "self", ".", "data_y", "=", "None", "\n", "self", ".", "train_size", ",", "self", ".", "input_size", "=", "self", ".", "data_X", ".", "shape", "\n", "self", ".", "output_size", "=", "self", ".", "input_size", "\n", "self", ".", "y_dim", "=", "None", "\n", "self", ".", "crop", "=", "False", "\n", "if", "self", ".", "pca_dim", ">", "self", ".", "input_size", ":", "\n", "                ", "self", ".", "pca_dim", "=", "self", ".", "input_size", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Check value of dataset flag\"", ")", "\n", "\n", "", "self", ".", "train_data_list", "=", "[", "]", "\n", "self", ".", "train_label_list", "=", "[", "]", "\n", "\n", "# if non_private:", "\n", "#     for i in range(self.overall_teachers):", "\n", "#         partition_data, partition_labels = partition_dataset(self.data_X, self.data_y, 1, i)", "\n", "#         self.train_data_list.append(partition_data)", "\n", "#         self.train_label_list.append(partition_labels)", "\n", "# else:", "\n", "if", "config", ".", "shuffle", ":", "\n", "            ", "from", "sklearn", ".", "utils", "import", "shuffle", "\n", "self", ".", "data_X", ",", "self", ".", "data_y", "=", "shuffle", "(", "self", ".", "data_X", ",", "self", ".", "data_y", ")", "\n", "", "from", "collections", "import", "defaultdict", "\n", "self", ".", "save_dict", "=", "defaultdict", "(", "lambda", ":", "False", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "overall_teachers", ")", ":", "\n", "            ", "partition_data", ",", "partition_labels", "=", "partition_dataset", "(", "self", ".", "data_X", ",", "self", ".", "data_y", ",", "self", ".", "overall_teachers", ",", "i", ")", "\n", "self", ".", "train_data_list", ".", "append", "(", "partition_data", ")", "\n", "self", ".", "train_label_list", ".", "append", "(", "partition_labels", ")", "\n", "# print(self.train_label_list)", "\n", "", "self", ".", "train_size", "=", "len", "(", "self", ".", "train_data_list", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "train_size", "<", "self", ".", "batch_size", ":", "\n", "            ", "self", ".", "batch_size", "=", "self", ".", "train_size", "\n", "print", "(", "'adjusted batch size:'", ",", "self", ".", "batch_size", ")", "\n", "# raise Exception(\"[!] Entire dataset size (%d) is less than the configured batch_size (%d) \" % (", "\n", "# self.train_size, self.batch_size))", "\n", "\n", "", "self", ".", "build_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.aggregate_results": [[291, 352], ["rdp_utils.gradient_voting_rdp", "rdp_utils.gradient_voting_rdp", "min", "print", "print", "rdp_utils.gradient_voting_rdp_multiproj", "sklearn.random_projection.GaussianRandomProjection", "sklearn.random_projection.GaussianRandomProjection.fit", "numpy.transpose", "rdp_utils.gradient_voting_rdp", "sklearn.random_projection.GaussianRandomProjection", "sklearn.random_projection.GaussianRandomProjection.fit", "print", "numpy.transpose", "numpy.zeros", "range", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp_multiproj", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.rdp_utils.gradient_voting_rdp"], ["", "def", "aggregate_results", "(", "self", ",", "output_list", ",", "config", ",", "thresh", "=", "None", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "pca", ":", "\n", "            ", "res", ",", "rdp_budget", "=", "gradient_voting_rdp", "(", "\n", "output_list", ",", "\n", "config", ".", "step_size", ",", "\n", "config", ".", "sigma", ",", "\n", "config", ".", "sigma_thresh", ",", "\n", "self", ".", "orders", ",", "\n", "pca_mat", "=", "self", ".", "pca_components", ",", "\n", "thresh", "=", "thresh", "\n", ")", "\n", "", "elif", "self", ".", "random_proj", ":", "\n", "            ", "orig_dim", "=", "1", "\n", "for", "dd", "in", "self", ".", "image_dims", ":", "\n", "                ", "orig_dim", "=", "orig_dim", "*", "dd", "\n", "\n", "", "if", "epoch", "is", "not", "None", ":", "\n", "                ", "proj_dim", "=", "min", "(", "epoch", "+", "1", ",", "self", ".", "pca_dim", ")", "\n", "", "else", ":", "\n", "                ", "proj_dim", "=", "self", ".", "pca_dim", "\n", "\n", "", "n_data", "=", "output_list", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "if", "config", ".", "proj_mat", ">", "1", ":", "\n", "                ", "proj_dim_", "=", "proj_dim", "//", "config", ".", "proj_mat", "\n", "n_data_", "=", "n_data", "//", "config", ".", "proj_mat", "\n", "orig_dim_", "=", "orig_dim", "//", "config", ".", "proj_mat", "\n", "print", "(", "\"n_data:\"", ",", "n_data", ")", "\n", "print", "(", "\"orig_dim:\"", ",", "orig_dim", ")", "\n", "transformers", "=", "[", "GaussianRandomProjection", "(", "n_components", "=", "proj_dim_", ")", "for", "_", "in", "range", "(", "config", ".", "proj_mat", ")", "]", "\n", "for", "transformer", "in", "transformers", ":", "\n", "                    ", "transformer", ".", "fit", "(", "np", ".", "zeros", "(", "[", "n_data_", ",", "orig_dim_", "]", ")", ")", "\n", "print", "(", "transformer", ".", "components_", ".", "shape", ")", "\n", "", "proj_matrices", "=", "[", "np", ".", "transpose", "(", "transformer", ".", "components_", ")", "for", "transformer", "in", "transformers", "]", "\n", "res", ",", "rdp_budget", "=", "gradient_voting_rdp_multiproj", "(", "\n", "output_list", ",", "\n", "config", ".", "step_size", ",", "\n", "config", ".", "sigma", ",", "\n", "config", ".", "sigma_thresh", ",", "\n", "self", ".", "orders", ",", "\n", "pca_mats", "=", "proj_matrices", ",", "\n", "thresh", "=", "thresh", "\n", ")", "\n", "", "else", ":", "\n", "                ", "transformer", "=", "GaussianRandomProjection", "(", "n_components", "=", "proj_dim", ")", "\n", "transformer", ".", "fit", "(", "np", ".", "zeros", "(", "[", "n_data", ",", "orig_dim", "]", ")", ")", "# only the shape of output_list[0] is used", "\n", "proj_matrix", "=", "np", ".", "transpose", "(", "transformer", ".", "components_", ")", "\n", "\n", "# proj_matrix = np.random.normal(loc=np.zeros([orig_dim, proj_dim]), scale=1/float(proj_dim), size=[orig_dim, proj_dim])", "\n", "res", ",", "rdp_budget", "=", "gradient_voting_rdp", "(", "\n", "output_list", ",", "\n", "config", ".", "step_size", ",", "\n", "config", ".", "sigma", ",", "\n", "config", ".", "sigma_thresh", ",", "\n", "self", ".", "orders", ",", "\n", "pca_mat", "=", "proj_matrix", ",", "\n", "thresh", "=", "thresh", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ",", "rdp_budget", "=", "gradient_voting_rdp", "(", "output_list", ",", "config", ".", "step_size", ",", "config", ".", "sigma", ",", "config", ".", "sigma_thresh", ",", "\n", "self", ".", "orders", ",", "thresh", "=", "thresh", ")", "\n", "", "return", "res", ",", "rdp_budget", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.non_private_aggregation": [[353, 359], ["numpy.zeros", "len"], "methods", ["None"], ["", "def", "non_private_aggregation", "(", "self", ",", "output_list", ",", "config", ")", ":", "\n", "# TODO update nonprivate aggregation", "\n", "        ", "sum_arr", "=", "np", ".", "zeros", "(", "output_list", "[", "0", "]", ".", "shape", ")", "\n", "for", "arr", "in", "output_list", ":", "\n", "            ", "sum_arr", "+=", "arr", "\n", "", "return", "sum_arr", "/", "len", "(", "output_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_fire_data": [[360, 368], ["os.path.join", "numpy.loadtxt", "numpy.random.seed", "numpy.random.shuffle"], "methods", ["None"], ["", "def", "load_fire_data", "(", "self", ")", ":", "\n", "        ", "dataset_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", ")", "\n", "dataset_name", "+=", "'.csv'", "\n", "X", "=", "np", ".", "loadtxt", "(", "dataset_name", ")", "\n", "seed", "=", "307", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_census_data": [[369, 378], ["os.path.join", "numpy.random.seed", "numpy.random.shuffle", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "def", "load_census_data", "(", "self", ")", ":", "\n", "        ", "dataset_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", ")", "\n", "dataset_name", "+=", "'.pkl'", "\n", "with", "open", "(", "dataset_name", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "X", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "seed", "=", "37", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_isolet": [[379, 395], ["os.path.join", "numpy.loadtxt", "numpy.random.seed", "numpy.random.shuffle", "numpy.hsplit", "keras.utils.np_utils.to_categorical"], "methods", ["None"], ["", "def", "load_isolet", "(", "self", ")", ":", "\n", "        ", "dataset_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", ")", "\n", "dataset_name", "+=", "'.csv'", "\n", "X", "=", "np", ".", "loadtxt", "(", "dataset_name", ")", "\n", "# print(X.shape)", "\n", "seed", "=", "37", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "X", "=", "np", ".", "hsplit", "(", "X", ",", "[", "-", "1", "]", ")", "\n", "x", "=", "X", "[", "0", "]", "\n", "# print(X.shape)", "\n", "y", "=", "X", "[", "1", "]", "\n", "# print(y.shape)", "\n", "y", "=", "np_utils", ".", "to_categorical", "(", "y", ",", "2", ")", "\n", "# print(y.shape)", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_cifar": [[396, 404], ["keras.datasets.cifar10.load_data", "keras.utils.np_utils.to_categorical", "x_train.reshape.reshape.reshape", "x_train.reshape.reshape.astype"], "methods", ["None"], ["", "def", "load_cifar", "(", "self", ")", ":", "\n", "# dataset_name = os.path.join(self.data_dir, self.dataset_name)", "\n", "# dataset_name += '.csv'", "\n", "        ", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "cifar10", ".", "load_data", "(", ")", "\n", "y_train", "=", "np_utils", ".", "to_categorical", "(", "y_train", ",", "10", ")", "\n", "x_train", "=", "x_train", ".", "reshape", "(", "x_train", ".", "shape", "[", "0", "]", ",", "32", ",", "32", ",", "3", ")", "\n", "x_train", "=", "x_train", ".", "astype", "(", "'float32'", ")", "/", "255.", "\n", "return", "x_train", ",", "y_train", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.slt": [[405, 440], ["open", "numpy.fromfile", "numpy.reshape", "numpy.transpose", "numpy.zeros", "range", "numpy.random.randint", "keras.utils.np_utils.to_categorical", "print", "PIL.Image.fromarray", "numpy.array", "numpy.array.resize"], "methods", ["None"], ["", "def", "slt", "(", "self", ")", ":", "\n", "\n", "        ", "path_to_data", "=", "'../../data/stl10_binary/unlabeled_X.bin'", "\n", "with", "open", "(", "path_to_data", ",", "'rb'", ")", "as", "f", ":", "\n", "# read whole file in uint8 chunks", "\n", "            ", "everything", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "# We force the data into 3x96x96 chunks, since the", "\n", "# images are stored in \"column-major order\", meaning", "\n", "# that \"the first 96*96 values are the red channel,", "\n", "# the next 96*96 are green, and the last are blue.\"", "\n", "# The -1 is since the size of the pictures depends", "\n", "# on the input file, and this way numpy determines", "\n", "# the size on its own.", "\n", "\n", "images", "=", "np", ".", "reshape", "(", "everything", ",", "(", "-", "1", ",", "3", ",", "96", ",", "96", ")", ")", "\n", "\n", "# Now transpose the images into a standard image format", "\n", "# readable by, for example, matplotlib.imshow", "\n", "# You might want to comment this line or reverse the shuffle", "\n", "# if you will use a learning algorithm like CNN, since they like", "\n", "# their channels separated.", "\n", "images", "=", "np", ".", "transpose", "(", "images", ",", "(", "0", ",", "3", ",", "2", ",", "1", ")", ")", "\n", "X_resized", "=", "np", ".", "zeros", "(", "(", "100000", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "100000", ")", ":", "\n", "                ", "img", "=", "images", "[", "i", "]", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "img", "=", "np", ".", "array", "(", "img", ".", "resize", "(", "(", "32", ",", "32", ")", ",", "Image", ".", "BICUBIC", ")", ")", "# \u4fee\u6539\u5206\u8fa8\u7387\uff0c\u518d\u8f6c\u4e3aarray\u7c7b", "\n", "X_resized", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "img", "\n", "\n", "", "y", "=", "np", ".", "random", ".", "randint", "(", "10", ",", "size", "=", "(", "100000", ",", "1", ")", ")", "\n", "y", "=", "np_utils", ".", "to_categorical", "(", "y", ",", "10", ")", "\n", "X_resized", "/=", "255", "\n", "print", "(", "X_resized", ")", "\n", "return", "X_resized", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_cinic": [[441, 457], ["torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "enumerate", "numpy.asarray", "numpy.asarray", "numpy.reshape", "keras.utils.np_utils.to_categorical", "torchvision.ToTensor", "torchvision.ToTensor"], "methods", ["None"], ["", "", "def", "load_cinic", "(", "self", ")", ":", "\n", "        ", "cinic_directory", "=", "'../../data/cinic'", "\n", "# cinic_mean = [0.47889522, 0.47227842, 0.43047404]", "\n", "# cinic_std = [0.24205776, 0.23828046, 0.25874835]", "\n", "image_folder", "=", "torchvision", ".", "datasets", ".", "ImageFolder", "(", "cinic_directory", "+", "'/train/'", ",", "\n", "# transform=transforms.Compose([transforms.ToTensor(),", "\n", "# transforms.Normalize(mean=cinic_mean,std=cinic_std)])),", "\n", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "cinic_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "image_folder", ",", "batch_size", "=", "180000", ",", "shuffle", "=", "True", ")", "\n", "\n", "for", "batch_ndx", ",", "sample", "in", "enumerate", "(", "cinic_train", ")", ":", "\n", "            ", "x", "=", "np", ".", "asarray", "(", "sample", "[", "0", "]", ")", "\n", "y", "=", "np", ".", "asarray", "(", "sample", "[", "1", "]", ")", "\n", "x", "=", "np", ".", "reshape", "(", "x", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "y", "=", "np_utils", ".", "to_categorical", "(", "y", ",", "10", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_celebA_gender": [[458, 482], ["joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "numpy.vstack", "numpy.vstack", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "Exception"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "", "def", "load_celebA_gender", "(", "self", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "import", "joblib", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "train_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-x-lg-ups.pkl'", ")", "\n", "train_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-gender-lg-ups.pkl'", ")", "\n", "train_y", "=", "np_utils", ".", "to_categorical", "(", "train_y", ",", "2", ")", "\n", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-x-lg-ups.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-gender-lg-ups.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "2", ")", "\n", "return", "np", ".", "vstack", "(", "(", "train_x", ",", "val_x", ")", ")", ",", "np", ".", "vstack", "(", "(", "train_y", ",", "val_y", ")", ")", "\n", "", "elif", "mode", "==", "'val'", ":", "\n", "            ", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-x-lg-ups.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-gender-lg-ups.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "2", ")", "\n", "return", "val_x", ",", "val_y", "\n", "", "elif", "mode", "==", "'tst'", ":", "\n", "            ", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-x.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-gender.pkl'", ")", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "2", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Mode {} Not support\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_celebA_hair": [[484, 508], ["joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "numpy.vstack", "numpy.vstack", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "Exception"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "", "def", "load_celebA_hair", "(", "self", ",", "mode", "=", "'trn'", ")", ":", "\n", "        ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "import", "joblib", "\n", "\n", "if", "mode", "==", "'trn'", ":", "\n", "            ", "train_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-trn-ups-hair-x.pkl'", ")", "\n", "train_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-trn-ups-hair-y.pkl'", ")", "\n", "train_y", "=", "np_utils", ".", "to_categorical", "(", "train_y", ",", "3", ")", "\n", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-val-ups-hair-x.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-val-ups-hair-y.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "3", ")", "\n", "return", "np", ".", "vstack", "(", "(", "train_x", ",", "val_x", ")", ")", ",", "np", ".", "vstack", "(", "(", "train_y", ",", "val_y", ")", ")", "\n", "", "elif", "mode", "==", "'val'", ":", "\n", "            ", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-val-ups-hair-x.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-val-ups-hair-y.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "3", ")", "\n", "return", "val_x", ",", "val_y", "\n", "", "elif", "mode", "==", "'tst'", ":", "\n", "            ", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-tst-ups-hair-x.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-tst-ups-hair-y.pkl'", ")", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "3", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Mode {} Not support\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_small_celebA_gender": [[510, 534], ["joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "numpy.vstack", "numpy.vstack", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "joblib.load", "joblib.load", "keras.utils.np_utils.to_categorical", "Exception"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "", "def", "load_small_celebA_gender", "(", "self", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "import", "joblib", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "train_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-x-small-ups.pkl'", ")", "\n", "train_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-gender-ups.pkl'", ")", "\n", "train_y", "=", "np_utils", ".", "to_categorical", "(", "train_y", ",", "2", ")", "\n", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-x-small-ups.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-gender-ups.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "2", ")", "\n", "return", "np", ".", "vstack", "(", "(", "train_x", ",", "val_x", ")", ")", ",", "np", ".", "vstack", "(", "(", "train_y", ",", "val_y", ")", ")", "\n", "", "elif", "mode", "==", "'val'", ":", "\n", "            ", "val_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-x-small-ups.pkl'", ")", "\n", "val_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-val-gender-ups.pkl'", ")", "\n", "val_y", "=", "np_utils", ".", "to_categorical", "(", "val_y", ",", "2", ")", "\n", "return", "val_x", ",", "val_y", "\n", "", "elif", "mode", "==", "'tst'", ":", "\n", "            ", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-x-small.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-gender.pkl'", ")", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "2", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Mode {} Not support\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_fashion_mnist": [[536, 574], ["os.path.join", "open", "numpy.fromfile", "loaded[].reshape().astype", "open", "numpy.fromfile", "loaded[].reshape().astype", "numpy.asarray", "numpy.asarray.astype", "numpy.random.seed", "numpy.random.shuffle", "numpy.random.seed", "numpy.random.shuffle", "numpy.zeros", "enumerate", "os.path.join", "os.path.join", "loaded[].reshape", "loaded[].reshape", "len"], "methods", ["None"], ["", "", "def", "load_fashion_mnist", "(", "self", ")", ":", "\n", "        ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-images-idx3-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "trX", "=", "loaded", "[", "16", ":", "]", ".", "reshape", "(", "(", "60000", ",", "28", ",", "28", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-labels-idx1-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "trY", "=", "loaded", "[", "8", ":", "]", ".", "reshape", "(", "(", "60000", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# fd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))", "\n", "# loaded = np.fromfile(file=fd,dtype=np.uint8)", "\n", "# teX = loaded[16:].reshape((10000,28,28,1)).astype(np.float)", "\n", "\n", "# fd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))", "\n", "# loaded = np.fromfile(file=fd,dtype=np.uint8)", "\n", "# teY = loaded[8:].reshape((10000)).astype(np.int)", "\n", "\n", "trY", "=", "np", ".", "asarray", "(", "trY", ")", "\n", "# teY = np.asarray(teY)", "\n", "\n", "# X = np.concatenate((trX, teX), axis=0)", "\n", "# y = np.concatenate((trY, teY), axis=0).astype(np.int)", "\n", "X", "=", "trX", "\n", "y", "=", "trY", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "seed", "=", "307", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "y", ")", "\n", "\n", "y_vec", "=", "np", ".", "zeros", "(", "(", "len", "(", "y", ")", ",", "self", ".", "y_dim", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y", ")", ":", "\n", "            ", "y_vec", "[", "i", ",", "y", "[", "i", "]", "]", "=", "1.0", "\n", "\n", "", "return", "X", "/", "255.", ",", "y_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_mnist": [[575, 613], ["os.path.join", "open", "numpy.fromfile", "loaded[].reshape().astype", "open", "numpy.fromfile", "loaded[].reshape().astype", "numpy.asarray", "numpy.asarray.astype", "numpy.random.seed", "numpy.random.shuffle", "numpy.random.seed", "numpy.random.shuffle", "numpy.zeros", "enumerate", "os.path.join", "os.path.join", "loaded[].reshape", "loaded[].reshape", "len"], "methods", ["None"], ["", "def", "load_mnist", "(", "self", ")", ":", "\n", "        ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "self", ".", "dataset_name", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-images-idx3-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "trX", "=", "loaded", "[", "16", ":", "]", ".", "reshape", "(", "(", "60000", ",", "28", ",", "28", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train-labels-idx1-ubyte'", ")", ")", "\n", "loaded", "=", "np", ".", "fromfile", "(", "file", "=", "fd", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "trY", "=", "loaded", "[", "8", ":", "]", ".", "reshape", "(", "(", "60000", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# fd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))", "\n", "# loaded = np.fromfile(file=fd,dtype=np.uint8)", "\n", "# teX = loaded[16:].reshape((10000,28,28,1)).astype(np.float)", "\n", "\n", "# fd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))", "\n", "# loaded = np.fromfile(file=fd,dtype=np.uint8)", "\n", "# teY = loaded[8:].reshape((10000)).astype(np.int)", "\n", "\n", "trY", "=", "np", ".", "asarray", "(", "trY", ")", "\n", "# teY = np.asarray(teY)", "\n", "\n", "# X = np.concatenate((trX, teX), axis=0)", "\n", "# y = np.concatenate((trY, teY), axis=0).astype(np.int)", "\n", "X", "=", "trX", "\n", "y", "=", "trY", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "seed", "=", "307", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "y", ")", "\n", "\n", "y_vec", "=", "np", ".", "zeros", "(", "(", "len", "(", "y", ")", ",", "self", ".", "y_dim", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y", ")", ":", "\n", "            ", "y_vec", "[", "i", ",", "y", "[", "i", "]", "]", "=", "1.0", "\n", "\n", "", "return", "X", "/", "255.", ",", "y_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.build_model": [[614, 714], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "histogram_summary", "model.DCGAN.generator", "tensorflow.placeholder", "tensorflow.reduce_sum", "scalar_summary", "range", "tensorflow.trainable_variables", "tensorflow.global_variables", "range", "print", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.image.resize_image_with_crop_or_pad", "image_summary", "tensorflow.square", "teacher.update", "model.DCGAN.teachers_list.append", "model.DCGAN.d_vars.append", "tensorflow.variable_scope", "model.DCGAN.discriminator", "scope.reuse_variables", "model.DCGAN.discriminator", "image_summary", "model.DCGAN.discriminator", "tensorflow.sqrt", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "scalar_summary", "scalar_summary", "tensorflow.gradients", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.math.multiply", "tensorflow.math.multiply", "tensorflow.gradients", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "model.sigmoid_cross_entropy_with_logits", "tensorflow.constant", "tensorflow.constant", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "model.sigmoid_cross_entropy_with_logits", "model.sigmoid_cross_entropy_with_logits", "tensorflow.ones_like", "tensorflow.square", "tensorflow.ones_like", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.generator", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.discriminator", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.discriminator", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.discriminator", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "crop", ":", "\n", "            ", "image_dims", "=", "[", "self", ".", "output_height", ",", "self", ".", "output_width", ",", "self", ".", "c_dim", "]", "\n", "", "else", ":", "\n", "            ", "image_dims", "=", "[", "self", ".", "input_height", ",", "self", ".", "input_width", ",", "self", ".", "c_dim", "]", "\n", "\n", "", "self", ".", "inputs", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", "]", "+", "[", "self", ".", "input_height", ",", "self", ".", "input_width", ",", "self", ".", "c_dim", "]", ",", "name", "=", "'real_images'", ")", "\n", "self", ".", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", ",", "self", ".", "y_dim", "]", ",", "name", "=", "'y'", ")", "\n", "\n", "self", ".", "image_dims", "=", "image_dims", "\n", "\n", "inputs", "=", "self", ".", "inputs", "\n", "if", "self", ".", "crop", ":", "\n", "            ", "inputs", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "inputs", ",", "target_height", "=", "self", ".", "output_height", ",", "\n", "target_width", "=", "self", ".", "output_width", ")", "\n", "\n", "", "self", ".", "z", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", ",", "self", ".", "z_dim", "]", ",", "name", "=", "'z'", ")", "\n", "self", ".", "z_sum", "=", "histogram_summary", "(", "\"z\"", ",", "self", ".", "z", ")", "\n", "\n", "self", ".", "G", "=", "self", ".", "generator", "(", "self", ".", "z", ",", "self", ".", "y", ")", "\n", "if", "'slt'", "in", "self", ".", "dataset_name", "or", "'cifar'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "self", ".", "G_sum", "=", "image_summary", "(", "\"G\"", ",", "self", ".", "G", ",", "max_outputs", "=", "10", ")", "\n", "\n", "", "self", ".", "updated_img", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", "]", "+", "image_dims", ",", "name", "=", "'updated_img'", ")", "\n", "self", ".", "g_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "self", ".", "updated_img", "-", "self", ".", "G", ")", ")", "\n", "\n", "self", ".", "g_loss_sum", "=", "scalar_summary", "(", "\"g_loss\"", ",", "self", ".", "g_loss", ")", "\n", "\n", "self", ".", "teachers_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"teacher%d\"", "%", "i", ")", "as", "scope", ":", "\n", "                ", "D", ",", "D_logits", "=", "self", ".", "discriminator", "(", "inputs", ",", "self", ".", "y", ")", "\n", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "D_", ",", "D_logits_", "=", "self", ".", "discriminator", "(", "self", ".", "G", ",", "self", ".", "y", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "# Use WassersteinGAN loss with gradient penalty. Reference: https://github.com/jiamings/wgan/blob/master/wgan_v2.py", "\n", "# Calculate interpolation of real and fake image", "\n", "                    ", "if", "'mnist'", "in", "self", ".", "dataset_name", ":", "\n", "                        ", "alpha", "=", "tf", ".", "random_uniform", "(", "[", "self", ".", "batch_size", ",", "1", ",", "1", ",", "1", "]", ",", "0.0", ",", "1.0", ")", "\n", "alpha", "=", "tf", ".", "tile", "(", "alpha", ",", "tf", ".", "constant", "(", "[", "1", ",", "self", ".", "input_height", ",", "self", ".", "input_width", ",", "self", ".", "c_dim", "]", ")", ")", "\n", "", "else", ":", "\n", "                        ", "alpha", "=", "tf", ".", "random_uniform", "(", "[", "self", ".", "batch_size", ",", "1", "]", ",", "0.0", ",", "1.0", ")", "\n", "alpha", "=", "tf", ".", "tile", "(", "alpha", ",", "tf", ".", "constant", "(", "[", "1", ",", "self", ".", "input_size", "]", ")", ")", "\n", "\n", "", "x_hat", "=", "tf", ".", "math", ".", "multiply", "(", "alpha", ",", "inputs", ")", "+", "tf", ".", "math", ".", "multiply", "(", "(", "1", "-", "alpha", ")", ",", "self", ".", "G", ")", "\n", "_", ",", "d_hat", "=", "self", ".", "discriminator", "(", "x_hat", ",", "self", ".", "y", ")", "\n", "\n", "# Calculate gradient penalty for wgan", "\n", "ddx", "=", "tf", ".", "gradients", "(", "d_hat", ",", "x_hat", ")", "[", "0", "]", "\n", "ddx", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "ddx", ")", ",", "axis", "=", "1", ")", ")", "\n", "ddx", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "ddx", "-", "1.0", ")", "**", "2", "*", "self", ".", "wgan_scale", ")", "\n", "\n", "", "", "if", "self", ".", "wgan", ":", "\n", "                ", "teacher", "=", "{", "\n", "'d_loss'", ":", "tf", ".", "reduce_mean", "(", "D_logits_", ")", "-", "tf", ".", "reduce_mean", "(", "D_logits", ")", "+", "ddx", ",", "\n", "'g_loss'", ":", "-", "tf", ".", "reduce_mean", "(", "D_logits_", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                ", "teacher", "=", "{", "\n", "'d_loss'", ":", "tf", ".", "reduce_mean", "(", "sigmoid_cross_entropy_with_logits", "(", "D_logits", ",", "tf", ".", "ones_like", "(", "D", ")", ")", ")", "+", "tf", ".", "reduce_mean", "(", "sigmoid_cross_entropy_with_logits", "(", "D_logits_", ",", "tf", ".", "zeros_like", "(", "D_", ")", ")", ")", ",", "\n", "'g_loss'", ":", "tf", ".", "reduce_mean", "(", "sigmoid_cross_entropy_with_logits", "(", "D_logits_", ",", "tf", ".", "ones_like", "(", "D_", ")", ")", ")", ",", "\n", "}", "\n", "\n", "", "teacher", ".", "update", "(", "{", "\n", "'d_loss_sum'", ":", "scalar_summary", "(", "\"d_loss_%d\"", "%", "i", ",", "teacher", "[", "'d_loss'", "]", ")", ",", "\n", "'g_loss_sum'", ":", "scalar_summary", "(", "\"g_loss_%d\"", "%", "i", ",", "teacher", "[", "'g_loss'", "]", ")", ",", "\n", "}", ")", "\n", "\n", "# calculate the change in the images that would minimize generator loss", "\n", "teacher", "[", "'img_grads'", "]", "=", "-", "tf", ".", "gradients", "(", "teacher", "[", "'g_loss'", "]", ",", "self", ".", "G", ")", "[", "0", "]", "\n", "\n", "if", "'slt'", "in", "self", ".", "dataset_name", ":", "\n", "                ", "teacher", "[", "'img_grads_sum'", "]", "=", "image_summary", "(", "\"img_grads\"", ",", "teacher", "[", "'img_grads'", "]", ",", "max_outputs", "=", "10", ")", "\n", "\n", "", "self", ".", "teachers_list", ".", "append", "(", "teacher", ")", "\n", "\n", "", "t_vars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "g_list", "=", "tf", ".", "global_variables", "(", ")", "\n", "add_save", "=", "[", "g", "for", "g", "in", "g_list", "if", "\"moving_mean\"", "in", "g", ".", "name", "]", "\n", "add_save", "+=", "[", "g", "for", "g", "in", "g_list", "if", "\"moving_variance\"", "in", "g", ".", "name", "]", "\n", "\n", "self", ".", "save_vars", "=", "t_vars", "+", "add_save", "\n", "\n", "self", ".", "d_vars", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "            ", "self", ".", "d_vars", ".", "append", "(", "[", "var", "for", "var", "in", "t_vars", "if", "'teacher%d'", "%", "i", "in", "var", ".", "name", "]", ")", "\n", "", "self", ".", "g_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "'g_'", "in", "var", ".", "name", "]", "\n", "\n", "self", ".", "g_save_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "'g_'", "in", "var", ".", "name", "]", "\n", "self", ".", "d_save_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "'d_'", "in", "var", ".", "name", "]", "\n", "# print(self.d_save_vars)", "\n", "print", "(", "self", ".", "save_vars", ")", "\n", "# self.d_save_vars = {'k': v for k, v in zip(self.d_save_vars, self.d_save_vars)}", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ",", "var_list", "=", "self", ".", "save_vars", ")", "\n", "self", ".", "saver_g", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ",", "var_list", "=", "self", ".", "g_save_vars", ")", "\n", "self", ".", "saver_d", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "self", ".", "teachers_batch", ",", "var_list", "=", "self", ".", "d_save_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.get_random_labels": [[715, 724], ["numpy.zeros", "numpy.random.randint", "enumerate"], "methods", ["None"], ["", "def", "get_random_labels", "(", "self", ",", "batch_size", ")", ":", "\n", "# print(self.y_dim)", "\n", "        ", "y_vec", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "self", ".", "y_dim", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "y_dim", ",", "batch_size", ")", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y", ")", ":", "\n", "            ", "y_vec", "[", "i", ",", "y", "[", "i", "]", "]", "=", "1.0", "\n", "\n", "", "return", "y_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.train_together": [[725, 1068], ["print", "range", "tensorflow.train.AdamOptimizer().minimize", "range", "SummaryWriter", "numpy.random.uniform", "time.time", "model.DCGAN.save_d", "six.moves.xrange", "model.DCGAN.save", "numpy.savetxt", "numpy.savetxt", "numpy.savetxt", "print", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "open", "json.dump", "model.DCGAN.data_X.reshape", "dp_pca.ComputeDPPrincipalProjection", "d_optim_list.append", "model.DCGAN.load_pretrain", "merge_summary", "merge_summary", "os.path.join", "print", "print", "int", "print", "six.moves.xrange", "print", "model.DCGAN.save", "numpy.savetxt", "numpy.savetxt", "numpy.savetxt", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "str", "os.path.join", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.train.AdamOptimizer", "tensorflow.global_variables_initializer().run", "tensorflow.global_variables_initializer().run", "model.DCGAN.d_sum_list.append", "model.DCGAN.d_sum_list.append", "numpy.random.uniform().astype", "range", "range", "print", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "tensorflow.initialize_all_variables().run", "tensorflow.initialize_all_variables().run", "merge_summary", "merge_summary", "min", "model.DCGAN.load_d", "range", "model.DCGAN.save_d", "range", "numpy.asarray", "model.DCGAN.dp_eps_list.append", "model.DCGAN.rdp_order_list.append", "model.DCGAN.rdp_eps_list.append", "str", "math.floor", "os.path.join", "os.path.join", "copytree", "tensorflow.train.AdamOptimizer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "numpy.random.uniform", "print", "print", "model.DCGAN.load_d", "range", "range", "model.DCGAN.get_random_labels", "range", "model.DCGAN.sess.run", "range", "model.DCGAN.sess.run", "img_grads_agg_list.append", "pate_core.compute_eps_from_delta", "model.DCGAN.sess.run", "model.DCGAN.writer.add_summary", "model.DCGAN.g_loss.eval", "model.DCGAN.sess.run", "model.DCGAN.writer.add_summary", "model.DCGAN.g_loss.eval", "str", "tensorflow.initialize_all_variables", "tensorflow.initialize_all_variables", "print", "print", "model.DCGAN.load_d", "model.DCGAN.load_d", "range", "model.DCGAN.load_d", "range", "model.DCGAN.non_private_aggregation", "print", "model.DCGAN.save", "numpy.savetxt", "numpy.savetxt", "numpy.savetxt", "model.DCGAN.gen_data", "joblib.dump", "sys.exit", "str", "model.DCGAN.sess.run", "model.DCGAN.writer.add_summary", "[].eval", "model.DCGAN.sess.run", "model.DCGAN.writer.add_summary", "[].eval", "print", "print", "model.DCGAN.sess.run", "img_grads_list.append", "print", "print", "model.DCGAN.sess.run", "img_grads_list.append", "model.DCGAN.aggregate_results", "model.DCGAN.aggregate_results", "numpy.asarray", "numpy.asarray", "numpy.asarray", "time.time", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.dp_pca.ComputeDPPrincipalProjection", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_pretrain", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.get_random_labels", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.pate_core.compute_eps_from_delta", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.non_private_aggregation", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.gen_data", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.aggregate_results", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.aggregate_results"], ["", "def", "train_together", "(", "self", ",", "config", ")", ":", "\n", "        ", "print", "(", "\"Training teacher models and student model together...\"", ")", "\n", "\n", "if", "not", "config", ".", "non_private", ":", "\n", "            ", "assert", "len", "(", "self", ".", "train_data_list", ")", "==", "self", ".", "overall_teachers", "\n", "", "else", ":", "\n", "            ", "print", "(", "str", "(", "len", "(", "self", ".", "train_data_list", ")", ")", ")", "\n", "\n", "", "configs", "=", "{", "\n", "'sigma'", ":", "config", ".", "sigma", ",", "\n", "'sigma_thresh'", ":", "config", ".", "sigma_thresh", ",", "\n", "'pca'", ":", "self", ".", "pca", ",", "\n", "'pca_sigma'", ":", "config", ".", "pca_sigma", ",", "\n", "'step_size'", ":", "config", ".", "step_size", ",", "\n", "'batch_teachers'", ":", "self", ".", "batch_teachers", ",", "\n", "'g_step'", ":", "config", ".", "g_step", ",", "\n", "'pca_dim'", ":", "self", ".", "pca_dim", ",", "\n", "}", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "checkpoint_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "teacher_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "teacher_dir", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'configs.json'", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "configs", ",", "fp", ")", "\n", "\n", "", "if", "self", ".", "pca", ":", "\n", "            ", "data", "=", "self", ".", "data_X", ".", "reshape", "(", "[", "self", ".", "data_X", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "self", ".", "pca_components", ",", "rdp_budget", "=", "ComputeDPPrincipalProjection", "(", "\n", "data", ",", "\n", "self", ".", "pca_dim", ",", "\n", "self", ".", "orders", ",", "\n", "config", ".", "pca_sigma", ",", "\n", ")", "\n", "self", ".", "rdp_counter", "+=", "rdp_budget", "\n", "\n", "", "d_optim_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "            ", "d_optim_list", ".", "append", "(", "tf", ".", "train", ".", "AdamOptimizer", "(", "config", ".", "learning_rate", ",", "beta1", "=", "config", ".", "beta1", ")", ".", "minimize", "(", "\n", "self", ".", "teachers_list", "[", "i", "]", "[", "'d_loss'", "]", ",", "var_list", "=", "self", ".", "d_vars", "[", "i", "]", ")", ")", "\n", "\n", "", "g_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "config", ".", "learning_rate", ",", "beta1", "=", "config", ".", "beta1", ")", ".", "minimize", "(", "self", ".", "g_loss", ",", "\n", "var_list", "=", "self", ".", "g_vars", ")", "\n", "\n", "if", "not", "config", ".", "pretrain", ":", "\n", "            ", "try", ":", "\n", "                ", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "", "except", ":", "\n", "                ", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "", "except", ":", "\n", "                ", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "", "self", ".", "load_pretrain", "(", "config", ".", "checkpoint_dir", ")", "\n", "# data = self.gen_data(5000)", "\n", "# output_dir = os.path.join(self.checkpoint_dir, self.sample_dir)", "\n", "# if not os.path.exists(output_dir):", "\n", "#     os.makedirs(output_dir)", "\n", "# filename = 'private.data_epoch_' + str(-1) + '.pkl'", "\n", "# outfile = os.path.join(output_dir, filename)", "\n", "# mkdir(output_dir)", "\n", "# with open(outfile, 'wb') as f:", "\n", "#     pickle.dump(data, f)", "\n", "# current_scope = tf.contrib.framework.get_name_scope()", "\n", "# with tf.variable_scope(current_scope, reuse=True):", "\n", "#     biases = tf.get_variable(\"teacher0/d_h0_conv/biases\")", "\n", "#     biases = tf.Print(biases, [biases])", "\n", "#     self.sess.run(biases)", "\n", "\n", "", "if", "'slt'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "self", ".", "g_sum", "=", "merge_summary", "(", "[", "self", ".", "z_sum", ",", "self", ".", "G_sum", ",", "self", ".", "g_loss_sum", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "g_sum", "=", "merge_summary", "(", "[", "self", ".", "z_sum", ",", "self", ".", "g_loss_sum", "]", ")", "\n", "\n", "", "self", ".", "d_sum_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "            ", "teacher", "=", "self", ".", "teachers_list", "[", "i", "]", "\n", "if", "'slt'", "in", "self", ".", "dataset_name", ":", "\n", "                ", "self", ".", "d_sum_list", ".", "append", "(", "\n", "merge_summary", "(", "[", "teacher", "[", "'d_loss_sum'", "]", ",", "teacher", "[", "'g_loss_sum'", "]", ",", "teacher", "[", "'img_grads_sum'", "]", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "d_sum_list", ".", "append", "(", "merge_summary", "(", "[", "teacher", "[", "'d_loss_sum'", "]", ",", "teacher", "[", "'g_loss_sum'", "]", "]", ")", ")", "\n", "\n", "", "", "self", ".", "writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "\"logs\"", ")", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "sample_z", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "self", ".", "sample_num", ",", "self", ".", "z_dim", ")", ")", "\n", "\n", "counter", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "save_d", "(", "self", ".", "teacher_dir", ",", "0", ",", "-", "1", ")", "\n", "for", "epoch", "in", "xrange", "(", "config", ".", "epoch", ")", ":", "\n", "            ", "print", "(", "\"----------------epoch: %d --------------------\"", "%", "epoch", ")", "\n", "print", "(", "\"-------------------train-teachers----------------\"", ")", "\n", "batch_idxs", "=", "int", "(", "min", "(", "self", ".", "train_size", ",", "config", ".", "train_size", ")", "//", "self", ".", "batch_size", ")", "\n", "# The idex of each batch", "\n", "print", "(", "\"Train %d idxs\"", "%", "batch_idxs", ")", "\n", "for", "idx", "in", "xrange", "(", "0", ",", "batch_idxs", ")", ":", "\n", "\n", "                ", "batch_z", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "[", "self", ".", "batch_size", ",", "self", ".", "z_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "errD", "=", "0", "\n", "# train teacher models in batches, teachers_batch: how many batches of teacher", "\n", "for", "batch_num", "in", "range", "(", "self", ".", "teachers_batch", ")", ":", "\n", "                    ", "could_load", ",", "checkpoint_counter", "=", "self", ".", "load_d", "(", "self", ".", "teacher_dir", ",", "epoch", "=", "epoch", ",", "\n", "batch_num", "=", "batch_num", ")", "\n", "if", "could_load", ":", "\n", "                        ", "counter", "=", "checkpoint_counter", "\n", "print", "(", "\"load sucess_this_epoch\"", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'fail_1'", ")", "\n", "could_load", ",", "checkpoint_counter", "=", "self", ".", "load_d", "(", "self", ".", "teacher_dir", ",", "epoch", "=", "epoch", "-", "1", ",", "\n", "batch_num", "=", "batch_num", ")", "\n", "if", "could_load", ":", "\n", "                            ", "counter", "=", "checkpoint_counter", "\n", "print", "(", "\"load sucess_previous_epoch\"", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "'fail_2'", ")", "\n", "could_load", ",", "checkpoint_counter", "=", "self", ".", "load_d", "(", "self", ".", "teacher_dir", ",", "epoch", "=", "0", ",", "\n", "batch_num", "=", "-", "1", ")", "\n", "\n", "# train each teacher in this batch, batch_teachers: how many teacher in a batch", "\n", "", "", "for", "teacher_id", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "#print(\"Training teacher model %d\" % teacher_id)", "\n", "# data_X = self.data_X if config.non_private else self.train_data_list[teacher_id+batch_num*self.batch_teachers]", "\n", "                        ", "data_X", "=", "self", ".", "train_data_list", "[", "teacher_id", "+", "batch_num", "*", "self", ".", "batch_teachers", "]", "\n", "\n", "batch_idx", "=", "range", "(", "idx", "*", "self", ".", "batch_size", ",", "(", "idx", "+", "1", ")", "*", "self", ".", "batch_size", ")", "\n", "batch_images", "=", "data_X", "[", "batch_idx", "]", "\n", "\n", "for", "k", "in", "range", "(", "config", ".", "d_step", ")", ":", "\n", "                            ", "if", "self", ".", "y", "is", "not", "None", ":", "\n", "# data_y = self.data_y if config.non_private else self.train_label_list[teacher_id+batch_num*self.batch_teachers]", "\n", "                                ", "data_y", "=", "self", ".", "train_label_list", "[", "teacher_id", "+", "batch_num", "*", "self", ".", "batch_teachers", "]", "\n", "#print(data_y.shape)", "\n", "batch_labels", "=", "data_y", "[", "batch_idx", "]", "\n", "\n", "_", ",", "summary_str", "=", "self", ".", "sess", ".", "run", "(", "[", "d_optim_list", "[", "teacher_id", "]", ",", "self", ".", "d_sum_list", "[", "teacher_id", "]", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "batch_images", ",", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary_str", ",", "epoch", ")", "\n", "\n", "err", "=", "self", ".", "teachers_list", "[", "teacher_id", "]", "[", "'d_loss'", "]", ".", "eval", "(", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "inputs", ":", "batch_images", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "# print(str(batch_num*self.batch_teachers + teacher_id) + \"loss:\"+str(err))", "\n", "errD", "+=", "err", "\n", "", "else", ":", "\n", "                                ", "_", ",", "summary_str", "=", "self", ".", "sess", ".", "run", "(", "[", "d_optim_list", "[", "teacher_id", "]", ",", "self", ".", "d_sum_list", "[", "teacher_id", "]", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "inputs", ":", "batch_images", ",", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "}", ")", "\n", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary_str", ",", "epoch", ")", "\n", "\n", "err", "=", "self", ".", "teachers_list", "[", "teacher_id", "]", "[", "'d_loss'", "]", ".", "eval", "(", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "inputs", ":", "batch_images", ",", "\n", "}", ")", "\n", "# print(str(batch_num * self.batch_teachers + teacher_id) + \"d_loss:\" + str(err))", "\n", "errD", "+=", "err", "\n", "\n", "", "", "", "self", ".", "save_d", "(", "self", ".", "teacher_dir", ",", "epoch", ",", "batch_num", ")", "\n", "\n", "# print(\"------------------train-generator-------------------\")", "\n", "", "for", "k", "in", "range", "(", "config", ".", "g_step", ")", ":", "\n", "                    ", "errG", "=", "0", "\n", "img_grads_list", "=", "[", "]", "\n", "if", "self", ".", "y", "is", "not", "None", ":", "\n", "                        ", "batch_labels", "=", "self", ".", "get_random_labels", "(", "self", ".", "batch_size", ")", "\n", "for", "batch_num", "in", "range", "(", "self", ".", "teachers_batch", ")", ":", "\n", "                            ", "could_load", ",", "checkpoint_counter", "=", "self", ".", "load_d", "(", "self", ".", "teacher_dir", ",", "epoch", "=", "epoch", ",", "\n", "batch_num", "=", "batch_num", ")", "\n", "if", "could_load", ":", "\n", "                                ", "counter", "=", "checkpoint_counter", "\n", "print", "(", "\"load sucess\"", ")", "\n", "", "else", ":", "\n", "                                ", "print", "(", "'fail'", ")", "\n", "\n", "", "for", "teacher_id", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "                                ", "img_grads", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "teachers_list", "[", "teacher_id", "]", "[", "'img_grads'", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "img_grads_list", ".", "append", "(", "img_grads", ")", "\n", "\n", "", "", "old_img", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "G", ",", "feed_dict", "=", "{", "self", ".", "z", ":", "batch_z", ",", "self", ".", "y", ":", "batch_labels", "}", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "for", "batch_num", "in", "range", "(", "self", ".", "teachers_batch", ")", ":", "\n", "                            ", "could_load", ",", "checkpoint_counter", "=", "self", ".", "load_d", "(", "self", ".", "teacher_dir", ",", "epoch", "=", "epoch", ",", "\n", "batch_num", "=", "batch_num", ")", "\n", "if", "could_load", ":", "\n", "                                ", "counter", "=", "checkpoint_counter", "\n", "print", "(", "\"load sucess\"", ")", "\n", "", "else", ":", "\n", "                                ", "print", "(", "'fail'", ")", "\n", "\n", "", "for", "teacher_id", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "                                ", "img_grads", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "teachers_list", "[", "teacher_id", "]", "[", "'img_grads'", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "}", ")", "\n", "img_grads_list", ".", "append", "(", "img_grads", ")", "\n", "\n", "", "", "old_img", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "G", ",", "feed_dict", "=", "{", "self", ".", "z", ":", "batch_z", "}", ")", "\n", "\n", "", "img_grads_agg_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "batch_size", ")", ":", "\n", "                        ", "thresh", "=", "self", ".", "thresh", "\n", "\n", "if", "config", ".", "non_private", ":", "\n", "                            ", "img_grads_agg_tmp", "=", "self", ".", "non_private_aggregation", "(", "[", "grads", "[", "j", "]", "for", "grads", "in", "img_grads_list", "]", ",", "\n", "config", ")", "\n", "rdp_budget", "=", "0", "\n", "", "elif", "config", ".", "increasing_dim", ":", "\n", "                            ", "img_grads_agg_tmp", ",", "rdp_budget", "=", "self", ".", "aggregate_results", "(", "\n", "[", "grads", "[", "j", "]", "for", "grads", "in", "img_grads_list", "]", ",", "config", ",", "thresh", "=", "thresh", ",", "epoch", "=", "epoch", ")", "\n", "", "else", ":", "\n", "                            ", "img_grads_agg_tmp", ",", "rdp_budget", "=", "self", ".", "aggregate_results", "(", "\n", "[", "grads", "[", "j", "]", "for", "grads", "in", "img_grads_list", "]", ",", "config", ",", "thresh", "=", "thresh", ")", "\n", "\n", "", "img_grads_agg_list", ".", "append", "(", "img_grads_agg_tmp", ")", "\n", "self", ".", "rdp_counter", "+=", "rdp_budget", "\n", "\n", "", "img_grads_agg", "=", "np", ".", "asarray", "(", "img_grads_agg_list", ")", "\n", "updated_img", "=", "old_img", "+", "img_grads_agg", "\n", "\n", "if", "config", ".", "non_private", ":", "\n", "                        ", "eps", "=", "0", "\n", "order", "=", "0", "\n", "", "else", ":", "\n", "# calculate privacy budget and break if exceeds threshold", "\n", "                        ", "eps", ",", "order", "=", "compute_eps_from_delta", "(", "self", ".", "orders", ",", "self", ".", "rdp_counter", ",", "self", ".", "dp_delta", ")", "\n", "\n", "if", "eps", ">", "config", ".", "max_eps", ":", "\n", "                            ", "print", "(", "\"New budget (eps = %.2f) exceeds threshold of %.2f. Early break (eps = %.2f).\"", "%", "(", "\n", "eps", ",", "config", ".", "max_eps", ",", "self", ".", "dp_eps_list", "[", "-", "1", "]", ")", ")", "\n", "\n", "# save privacy budget", "\n", "self", ".", "save", "(", "config", ".", "checkpoint_dir", ",", "counter", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/dp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "dp_eps_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_eps_list", ")", ",", "\n", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_order.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_order_list", ")", ",", "\n", "delimiter", "=", "\",\"", ")", "\n", "\n", "gen_batch", "=", "100000", "//", "self", ".", "batch_size", "+", "1", "\n", "data", "=", "self", ".", "gen_data", "(", "gen_batch", ")", "\n", "data", "=", "data", "[", ":", "100000", "]", "\n", "import", "joblib", "\n", "joblib", ".", "dump", "(", "data", ",", "self", ".", "checkpoint_dir", "+", "'/eps-%.2f.data'", "%", "self", ".", "dp_eps_list", "[", "-", "1", "]", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "", "self", ".", "dp_eps_list", ".", "append", "(", "eps", ")", "\n", "self", ".", "rdp_order_list", ".", "append", "(", "order", ")", "\n", "self", ".", "rdp_eps_list", ".", "append", "(", "self", ".", "rdp_counter", ")", "\n", "\n", "# Update G network", "\n", "if", "self", ".", "y", "is", "not", "None", ":", "\n", "                        ", "_", ",", "summary_str", ",", "errG2", "=", "self", ".", "sess", ".", "run", "(", "[", "g_optim", ",", "self", ".", "g_sum", ",", "self", ".", "g_loss", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "updated_img", ":", "updated_img", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary_str", ",", "epoch", ")", "\n", "\n", "errG", "=", "self", ".", "g_loss", ".", "eval", "(", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "updated_img", ":", "updated_img", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "", "else", ":", "\n", "                        ", "_", ",", "summary_str", "=", "self", ".", "sess", ".", "run", "(", "[", "g_optim", ",", "self", ".", "g_sum", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "updated_img", ":", "updated_img", ",", "\n", "}", ")", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary_str", ",", "epoch", ")", "\n", "\n", "errG", "=", "self", ".", "g_loss", ".", "eval", "(", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "updated_img", ":", "updated_img", ",", "\n", "}", ")", "\n", "\n", "", "", "counter", "+=", "1", "\n", "print", "(", "\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f, g_loss_before: %.8f, dp_eps: %.8f, rdp_order: %d\"", "%", "(", "epoch", ",", "config", ".", "epoch", ",", "idx", ",", "batch_idxs", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "errD", ",", "errG", ",", "errG2", ",", "eps", ",", "order", ")", ")", "\n", "# filename = 'epoch'+str(epoch)+'_errD'+str(errD)+'_errG'+str(errG)+'_teachers'+str(self.batch_teachers)+'f.csv'", "\n", "# if epoch % 4 == 0:", "\n", "", "print", "(", "'----------------------generate sample----------------------'", ")", "\n", "# data = self.gen_data(500)", "\n", "# output_dir = os.path.join(self.checkpoint_dir, self.sample_dir)", "\n", "# if not os.path.exists(output_dir):", "\n", "#     os.makedirs(output_dir)", "\n", "# filename = 'private.data_epoch_' + str(epoch) + '.pkl'", "\n", "# outfile = os.path.join(output_dir, filename)", "\n", "# mkdir(output_dir)", "\n", "# with open(outfile,'wb') as f:", "\n", "#     pickle.dump(data, f)", "\n", "\n", "\n", "filename", "=", "'epoch'", "+", "str", "(", "epoch", ")", "+", "'_errD'", "+", "str", "(", "errD", ")", "+", "'_errG'", "+", "str", "(", "errG", ")", "+", "'_teachers'", "+", "str", "(", "\n", "self", ".", "batch_teachers", ")", "+", "'f.csv'", "\n", "\n", "# save each epoch", "\n", "self", ".", "save", "(", "config", ".", "checkpoint_dir", ",", "counter", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/dp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "dp_eps_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_order.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_order_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_eps_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "if", "config", ".", "save_epoch", ":", "\n", "                ", "floor_eps", "=", "math", ".", "floor", "(", "eps", "*", "10", ")", "/", "10.0", "\n", "if", "not", "self", ".", "save_dict", "[", "floor_eps", "]", ":", "\n", "# get a checkpoint of low eps", "\n", "                    ", "self", ".", "save_dict", "[", "floor_eps", "]", "=", "True", "\n", "from", "shutil", "import", "copytree", "\n", "src_dir", "=", "os", ".", "path", ".", "join", "(", "config", ".", "checkpoint_dir", ",", "self", ".", "model_dir", ")", "\n", "dst_dir", "=", "os", ".", "path", ".", "join", "(", "config", ".", "checkpoint_dir", ",", "str", "(", "floor_eps", ")", ")", "\n", "copytree", "(", "src_dir", ",", "dst_dir", ")", "\n", "\n", "#", "\n", "# save after training", "\n", "", "", "", "self", ".", "save", "(", "config", ".", "checkpoint_dir", ",", "counter", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/dp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "dp_eps_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_eps.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_eps_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "checkpoint_dir", "+", "\"/rdp_order.txt\"", ",", "np", ".", "asarray", "(", "self", ".", "rdp_order_list", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "return", "self", ".", "dp_eps_list", "[", "-", "1", "]", ",", "self", ".", "dp_delta", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.discriminator": [[1069, 1093], ["tensorflow.reshape", "ops.conv_cond_concat", "ops.lrelu", "ops.conv_cond_concat", "tensorflow.reshape", "concat", "concat", "ops.linear", "ops.conv2d", "ops.lrelu", "ops.lrelu", "ops.lrelu", "ops.lrelu", "tensorflow.nn.sigmoid", "ops.conv2d", "model.DCGAN.d_bn1", "ops.linear", "model.DCGAN.d_bn2", "ops.conv2d", "ops.linear"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv_cond_concat", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv_cond_concat", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.lrelu", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear"], ["", "def", "discriminator", "(", "self", ",", "image", ",", "y", ")", ":", "\n", "        ", "yb", "=", "tf", ".", "reshape", "(", "y", ",", "[", "self", ".", "batch_size", ",", "1", ",", "1", ",", "self", ".", "y_dim", "]", ")", "\n", "x", "=", "conv_cond_concat", "(", "image", ",", "yb", ")", "\n", "\n", "h0", "=", "lrelu", "(", "conv2d", "(", "x", ",", "self", ".", "c_dim", "+", "self", ".", "y_dim", ",", "name", "=", "'d_h0_conv'", ")", ")", "\n", "h0", "=", "conv_cond_concat", "(", "h0", ",", "yb", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "            ", "h1", "=", "lrelu", "(", "conv2d", "(", "h0", ",", "self", ".", "df_dim", "+", "self", ".", "y_dim", ",", "name", "=", "'d_h1_conv'", ")", ")", "\n", "", "else", ":", "\n", "            ", "h1", "=", "lrelu", "(", "self", ".", "d_bn1", "(", "conv2d", "(", "h0", ",", "self", ".", "df_dim", "+", "self", ".", "y_dim", ",", "name", "=", "'d_h1_conv'", ")", ")", ")", "\n", "\n", "", "h1", "=", "tf", ".", "reshape", "(", "h1", ",", "[", "self", ".", "batch_size", ",", "-", "1", "]", ")", "\n", "h1", "=", "concat", "(", "[", "h1", ",", "y", "]", ",", "1", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "            ", "h2", "=", "lrelu", "(", "linear", "(", "h1", ",", "self", ".", "dfc_dim", ",", "'d_h2_lin'", ")", ")", "\n", "", "else", ":", "\n", "            ", "h2", "=", "lrelu", "(", "self", ".", "d_bn2", "(", "linear", "(", "h1", ",", "self", ".", "dfc_dim", ",", "'d_h2_lin'", ")", ")", ")", "\n", "", "h2", "=", "concat", "(", "[", "h2", ",", "y", "]", ",", "1", ")", "\n", "\n", "h3", "=", "linear", "(", "h2", ",", "1", ",", "'d_h3_lin'", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "sigmoid", "(", "h3", ")", ",", "h3", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.generator": [[1094, 1129], ["tensorflow.variable_scope", "tensorflow.reshape", "concat", "concat", "tensorflow.reshape", "ops.conv_cond_concat", "ops.conv_cond_concat", "int", "int", "int", "int", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.sigmoid", "ops.linear", "model.DCGAN.g_bn0", "ops.linear", "model.DCGAN.g_bn1", "ops.deconv2d", "model.DCGAN.g_bn2", "ops.deconv2d", "ops.linear", "ops.linear", "ops.deconv2d", "tensorflow.nn.tanh", "ops.deconv2d"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv_cond_concat", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.conv_cond_concat", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.linear", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.ops.deconv2d"], ["", "def", "generator", "(", "self", ",", "z", ",", "y", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", "as", "scope", ":", "\n", "            ", "s_h", ",", "s_w", "=", "self", ".", "output_height", ",", "self", ".", "output_width", "\n", "s_h2", ",", "s_h4", "=", "int", "(", "s_h", "/", "2", ")", ",", "int", "(", "s_h", "/", "4", ")", "\n", "s_w2", ",", "s_w4", "=", "int", "(", "s_w", "/", "2", ")", ",", "int", "(", "s_w", "/", "4", ")", "\n", "\n", "# yb = tf.expand_dims(tf.expand_dims(y, 1),2)", "\n", "yb", "=", "tf", ".", "reshape", "(", "y", ",", "[", "self", ".", "batch_size", ",", "1", ",", "1", ",", "self", ".", "y_dim", "]", ")", "\n", "z", "=", "concat", "(", "[", "z", ",", "y", "]", ",", "1", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "                ", "h0", "=", "tf", ".", "nn", ".", "relu", "(", "linear", "(", "z", ",", "self", ".", "gfc_dim", ",", "'g_h0_lin'", ")", ")", "\n", "", "else", ":", "\n", "                ", "h0", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "g_bn0", "(", "linear", "(", "z", ",", "self", ".", "gfc_dim", ",", "'g_h0_lin'", ")", ")", ")", "\n", "", "h0", "=", "concat", "(", "[", "h0", ",", "y", "]", ",", "1", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "                ", "h1", "=", "tf", ".", "nn", ".", "relu", "(", "linear", "(", "h0", ",", "self", ".", "gf_dim", "*", "2", "*", "s_h4", "*", "s_w4", ",", "'g_h1_lin'", ")", ")", "\n", "", "else", ":", "\n", "                ", "h1", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "g_bn1", "(", "linear", "(", "h0", ",", "self", ".", "gf_dim", "*", "2", "*", "s_h4", "*", "s_w4", ",", "'g_h1_lin'", ")", ")", ")", "\n", "", "h1", "=", "tf", ".", "reshape", "(", "h1", ",", "[", "self", ".", "batch_size", ",", "s_h4", ",", "s_w4", ",", "self", ".", "gf_dim", "*", "2", "]", ")", "\n", "\n", "h1", "=", "conv_cond_concat", "(", "h1", ",", "yb", ")", "\n", "\n", "if", "self", ".", "wgan", ":", "\n", "                ", "h2", "=", "tf", ".", "nn", ".", "relu", "(", "deconv2d", "(", "h1", ",", "[", "self", ".", "batch_size", ",", "s_h2", ",", "s_w2", ",", "self", ".", "gf_dim", "*", "2", "]", ",", "name", "=", "'g_h2'", ")", ")", "\n", "", "else", ":", "\n", "                ", "h2", "=", "tf", ".", "nn", ".", "relu", "(", "\n", "self", ".", "g_bn2", "(", "deconv2d", "(", "h1", ",", "[", "self", ".", "batch_size", ",", "s_h2", ",", "s_w2", ",", "self", ".", "gf_dim", "*", "2", "]", ",", "name", "=", "'g_h2'", ")", ")", ")", "\n", "", "h2", "=", "conv_cond_concat", "(", "h2", ",", "yb", ")", "\n", "\n", "if", "self", ".", "config", ".", "tanh", ":", "\n", "                ", "return", "(", "1", "+", "tf", ".", "nn", ".", "tanh", "(", "deconv2d", "(", "h2", ",", "[", "self", ".", "batch_size", ",", "s_h", ",", "s_w", ",", "self", ".", "c_dim", "]", ",", "name", "=", "'g_h3'", ")", ")", ")", "/", "2.", "\n", "", "else", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "sigmoid", "(", "deconv2d", "(", "h2", ",", "[", "self", ".", "batch_size", ",", "s_h", ",", "s_w", ",", "self", ".", "c_dim", "]", ",", "name", "=", "'g_h3'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.gen_data": [[1131, 1162], ["range", "numpy.vstack", "numpy.random.uniform().astype", "output_list.append", "model.DCGAN.sess.run", "model.DCGAN.reshape", "numpy.hstack", "model.DCGAN.sess.run", "model.DCGAN.reshape", "numpy.random.uniform", "model.DCGAN.get_random_labels", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.get_random_labels"], ["", "", "", "def", "gen_data", "(", "self", ",", "n_batch", ",", "label", "=", "None", ")", ":", "\n", "        ", "output_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_batch", ")", ":", "\n", "            ", "batch_z", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "[", "self", ".", "batch_size", ",", "self", ".", "z_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "if", "self", ".", "y", "is", "not", "None", ":", "\n", "                ", "if", "label", "is", "None", ":", "\n", "                    ", "batch_labels", "=", "self", ".", "get_random_labels", "(", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "                    ", "batch_labels", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "y_dim", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "batch_labels", "[", ":", ",", "label", "]", "=", "1.0", "\n", "\n", "", "outputs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "G", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "self", ".", "y", ":", "batch_labels", ",", "\n", "}", ")", "\n", "outputsX", "=", "outputs", ".", "reshape", "(", "[", "self", ".", "batch_size", ",", "-", "1", "]", ")", "\n", "outputs", "=", "np", ".", "hstack", "(", "[", "outputsX", ",", "batch_labels", "[", ":", ",", "0", ":", "10", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "G", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "batch_z", ",", "\n", "}", ")", "\n", "outputsX", "=", "outputs", ".", "reshape", "(", "[", "self", ".", "batch_size", ",", "-", "1", "]", ")", "\n", "outputs", "=", "outputsX", "\n", "\n", "", "output_list", ".", "append", "(", "outputs", ")", "\n", "\n", "", "output_arr", "=", "np", ".", "vstack", "(", "output_list", ")", "\n", "return", "output_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.model_dir": [[1163, 1168], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_dir", "(", "self", ")", ":", "\n", "        ", "return", "\"{}_{}_{}_{}\"", ".", "format", "(", "\n", "self", ".", "dataset_name", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "output_height", ",", "self", ".", "output_width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.print_tensors_in_checkpoint": [[1169, 1175], ["os.path.join", "print_tensors_in_checkpoint_file"], "methods", ["None"], ["", "def", "print_tensors_in_checkpoint", "(", "self", ",", "checkpoint_dir", ",", "ckpt_name", ")", ":", "\n", "        ", "from", "tensorflow", ".", "python", ".", "tools", ".", "inspect_checkpoint", "import", "print_tensors_in_checkpoint_file", "\n", "import", "os", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "ckpt_name", ")", "\n", "# List ALL tensors example output: v0/Adam (DT_FLOAT) [3,3,1,80]", "\n", "print_tensors_in_checkpoint_file", "(", "file_name", "=", "checkpoint_path", ",", "tensor_name", "=", "''", ",", "all_tensors", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_pretrain": [[1176, 1209], ["print", "print", "tensorflow.train.Saver", "print", "tensorflow.train.Saver.restore", "int", "print", "os.path.join", "range", "next().group", "x.name.startswith", "print", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "re.sub", "os.path.join", "next", "x.name.startswith", "re.finditer"], "methods", ["None"], ["", "def", "load_pretrain", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "print", "(", "\" [*] Reading checkpoints...\"", ")", "\n", "print", "(", "checkpoint_dir", ")", "\n", "save_vars_dict", "=", "{", "x", ".", "name", "[", ":", "-", "2", "]", ":", "x", "for", "x", "in", "self", ".", "save_vars", "if", "x", ".", "name", ".", "startswith", "(", "'generator'", ")", "}", "\n", "pretrain_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ",", "var_list", "=", "save_vars_dict", ")", "\n", "print", "(", "self", ".", "dataset_name", ")", "\n", "if", "'cifar'", "in", "self", ".", "dataset_name", "or", "'cinic'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "ckpt_name", "=", "'DCGAN.model-100'", "\n", "", "elif", "'mnist'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "ckpt_name", "=", "'CIFAR.model-250'", "\n", "", "elif", "'celebA'", "in", "self", ".", "dataset_name", ":", "\n", "            ", "ckpt_name", "=", "'CIFAR.model-99'", "\n", "", "pretrain_saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "ckpt_name", ")", ")", "\n", "import", "re", "\n", "if", "self", ".", "config", ".", "load_d", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "batch_teachers", ")", ":", "\n", "                ", "print", "(", "'loading teacher {}'", ".", "format", "(", "i", ")", ")", "\n", "save_vars_dict", "=", "{", "re", ".", "sub", "(", "r'teacher[0-9]+'", ",", "'teacher0'", ",", "x", ".", "name", "[", ":", "-", "2", "]", ")", ":", "x", "for", "x", "in", "self", ".", "save_vars", "if", "x", ".", "name", ".", "startswith", "(", "'teacher{}/'", ".", "format", "(", "i", ")", ")", "}", "\n", "pretrain_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ",", "var_list", "=", "save_vars_dict", ")", "\n", "pretrain_saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "ckpt_name", ")", ")", "\n", "\n", "# save_vars_dict = {x.name: x for x in self.save_vars}", "\n", "# print(save_vars_dict.keys())", "\n", "", "", "counter", "=", "int", "(", "next", "(", "re", ".", "finditer", "(", "\"(\\d+)(?!.*\\d)\"", ",", "ckpt_name", ")", ")", ".", "group", "(", "0", ")", ")", "\n", "print", "(", "\" [*] Success to read {}\"", ".", "format", "(", "ckpt_name", ")", ")", "\n", "# current_scope = tf.contrib.framework.get_name_scope()", "\n", "# with tf.variable_scope(current_scope, reuse=True):", "\n", "#     biases = tf.get_variable(\"teacher0/d_h0_conv/biases\")", "\n", "#     biases2 = tf.get_variable(\"teacher12/d_h0_conv/biases\")", "\n", "#     biases3 = tf.get_variable(\"generator/g_h0_lin/Matrix\")", "\n", "#     biases = tf.Print(biases, [biases, biases2, biases3])", "\n", "#     self.sess.run(biases)", "\n", "return", "True", ",", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load": [[1210, 1219], ["print", "print", "print", "model.DCGAN.saver.restore", "int", "print", "os.path.join", "next().group", "next", "re.finditer"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "checkpoint_dir", ",", "ckpt_name", ")", ":", "\n", "        ", "import", "re", "\n", "print", "(", "\" [*] Reading checkpoints...\"", ")", "\n", "print", "(", "checkpoint_dir", ")", "\n", "print", "(", "ckpt_name", ")", "\n", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "ckpt_name", ")", ")", "\n", "counter", "=", "int", "(", "next", "(", "re", ".", "finditer", "(", "\"(\\d+)(?!.*\\d)\"", ",", "ckpt_name", ")", ")", ".", "group", "(", "0", ")", ")", "\n", "print", "(", "\" [*] Success to read {}\"", ".", "format", "(", "ckpt_name", ")", ")", "\n", "return", "True", ",", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load_d": [[1239, 1258], ["print", "os.path.join", "os.path.join", "print", "os.path.isfile", "str", "model.DCGAN.saver_d.restore", "int", "print", "print", "next().group", "str", "next", "re.finditer"], "methods", ["None"], ["", "def", "load_d", "(", "self", ",", "checkpoint_dir", ",", "batch_num", ",", "epoch", ")", ":", "\n", "        ", "import", "re", "\n", "print", "(", "\" [*] Reading checkpoints...\"", ")", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "self", ".", "model_dir", ")", "\n", "model_name", "=", "\"DCGAN_batch_\"", "+", "str", "(", "batch_num", ")", "+", "\"_epoch-\"", "+", "str", "(", "epoch", ")", "\n", "\n", "ckpt", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "model_name", ")", "\n", "print", "(", "ckpt", "+", "\".meta\"", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "ckpt", "+", "\".meta\"", ")", ":", "\n", "# model_name = \"DCGAN_batch_\" + str(batch_num) + \"_epoch_\" + str(epoch)", "\n", "# print(model_name)", "\n", "            ", "self", ".", "saver_d", ".", "restore", "(", "self", ".", "sess", ",", "ckpt", ")", "\n", "counter", "=", "int", "(", "next", "(", "re", ".", "finditer", "(", "\"(\\d+)(?!.*\\d)\"", ",", "model_name", ")", ")", ".", "group", "(", "0", ")", ")", "\n", "print", "(", "\" [*] Success to read {}\"", ".", "format", "(", "model_name", ")", ")", "\n", "return", "True", ",", "counter", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\" [*] Failed to find a checkpoint\"", ")", "\n", "return", "False", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save": [[1259, 1269], ["os.path.join", "model.DCGAN.saver.save", "os.path.exists", "os.makedirs", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save"], ["", "", "def", "save", "(", "self", ",", "checkpoint_dir", ",", "step", ")", ":", "\n", "        ", "model_name", "=", "\"CIFAR.model\"", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "self", ".", "model_dir", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "checkpoint_dir", ")", "\n", "\n", "", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "\n", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "model_name", ")", ",", "\n", "global_step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save_d": [[1270, 1281], ["os.path.join", "model.DCGAN.saver_d.save", "print", "os.path.exists", "os.makedirs", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save"], ["", "def", "save_d", "(", "self", ",", "checkpoint_dir", ",", "step", ",", "teacher_batch", ")", ":", "\n", "        ", "model_name", "=", "\"DCGAN_batch_\"", "+", "str", "(", "teacher_batch", ")", "+", "\"_epoch\"", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "self", ".", "model_dir", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "checkpoint_dir", ")", "\n", "\n", "", "self", ".", "saver_d", ".", "save", "(", "self", ".", "sess", ",", "\n", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "model_name", ")", ",", "\n", "global_step", "=", "step", ")", "\n", "print", "(", "\"-------------save-dis----------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save_g": [[1282, 1292], ["os.path.join", "model.DCGAN.saver_g.save", "os.path.exists", "os.makedirs", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.save"], ["", "def", "save_g", "(", "self", ",", "checkpoint_dir", ",", "step", ")", ":", "\n", "        ", "model_name", "=", "\"DCGAN.model\"", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "self", ".", "model_dir", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "checkpoint_dir", ")", "\n", "\n", "", "self", ".", "saver_g", ".", "save", "(", "self", ".", "sess", ",", "\n", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "model_name", ")", ",", "\n", "global_step", "=", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.partition_dataset": [[30, 60], ["int", "int", "int", "len"], "function", ["None"], ["def", "partition_dataset", "(", "data", ",", "labels", ",", "nb_teachers", ",", "teacher_id", ")", ":", "\n", "    ", "\"\"\"\n    Simple partitioning algorithm that returns the right portion of the data\n    needed by a given teacher out of a certain nb of teachers\n    :param data: input data to be partitioned\n    :param labels: output data to be partitioned\n    :param nb_teachers: number of teachers in the ensemble (affects size of each\n                       partition)\n    :param teacher_id: id of partition to retrieve\n    :return:\n    \"\"\"", "\n", "\n", "# Sanity check", "\n", "assert", "(", "int", "(", "teacher_id", ")", "<", "int", "(", "nb_teachers", ")", ")", "\n", "\n", "# This will floor the possible number of batches", "\n", "batch_len", "=", "int", "(", "len", "(", "data", ")", "/", "nb_teachers", ")", "\n", "\n", "# Compute start, end indices of partition", "\n", "start", "=", "teacher_id", "*", "batch_len", "\n", "end", "=", "(", "teacher_id", "+", "1", ")", "*", "batch_len", "\n", "\n", "# Slice partition off", "\n", "partition_data", "=", "data", "[", "start", ":", "end", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "        ", "partition_labels", "=", "labels", "[", "start", ":", "end", "]", "\n", "", "else", ":", "\n", "        ", "partition_labels", "=", "None", "\n", "\n", "", "return", "partition_data", ",", "partition_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.conv_out_size_same": [[62, 64], ["int", "math.ceil", "float", "float"], "function", ["None"], ["", "def", "conv_out_size_same", "(", "size", ",", "stride", ")", ":", "\n", "    ", "return", "int", "(", "math", ".", "ceil", "(", "float", "(", "size", ")", "/", "float", "(", "stride", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits": [[66, 71], ["tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.sigmoid_cross_entropy_with_logits"], ["", "def", "sigmoid_cross_entropy_with_logits", "(", "x", ",", "y", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "x", ",", "labels", "=", "y", ")", "\n", "", "except", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "x", ",", "targets", "=", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.gen_data.data2str": [[44, 69], ["range", "numpy.argmax", "str", "str", "float", "str", "str", "int", "round"], "function", ["None"], ["def", "data2str", "(", "ans", ",", "n_dim", "=", "29", ")", ":", "\n", "\t", "temp", "=", "\"\"", "\n", "for", "i", "in", "range", "(", "n_dim", ")", ":", "\n", "\t\t", "if", "(", "i", "==", "0", ")", ":", "\n", "\t\t\t", "tmp", "=", "ans", "[", ":", "x", "[", "i", "]", "]", "\n", "", "else", ":", "\n", "\t\t\t", "tmp", "=", "ans", "[", "x", "[", "i", "-", "1", "]", ":", "x", "[", "i", "]", "]", "\n", "", "_", "=", "np", ".", "argmax", "(", "tmp", ")", "\n", "if", "(", "i", "==", "0", ")", ":", "\n", "\t\t\t", "temp", "+=", "str", "(", "_", ")", "\n", "", "else", ":", "\n", "\t\t\t", "if", "(", "x", "[", "i", "]", "-", "x", "[", "i", "-", "1", "]", "==", "101", ")", ":", "\n", "\t\t\t\t", "if", "(", "_", "==", "100", ")", ":", "\n", "\t\t\t\t\t", "temp", "+=", "\",\"", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "step", "=", "float", "(", "y", "[", "i", "]", "[", "1", "]", "-", "y", "[", "i", "]", "[", "0", "]", ")", "/", "100", "\n", "value", "=", "y", "[", "i", "]", "[", "0", "]", "+", "(", "_", "+", "0.5", ")", "*", "step", "\n", "if", "(", "i", "!=", "23", "and", "i", "!=", "27", ")", ":", "\n", "\t\t\t\t\t\t", "temp", "+=", "\",\"", "+", "str", "(", "int", "(", "round", "(", "value", ")", ")", ")", "\n", "", "else", ":", "\n", "\n", "\t\t\t\t\t\t", "temp", "+=", "\",\"", "+", "str", "(", "value", ")", "\n", "", "", "", "else", ":", "\n", "\t\t\t\t", "temp", "+=", "\",\"", "+", "str", "(", "_", ")", "\n", "", "", "", "return", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.gen_data.batch2str": [[70, 83], ["open", "range", "open.write", "range", "open.close", "gen_data.data2str", "open.write"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.gen_data.data2str"], ["", "def", "batch2str", "(", "data", ",", "out_file", ",", "n_dim", "=", "29", ",", "n_features", "=", "20", ")", ":", "\n", "\t", "g", "=", "open", "(", "out_file", ",", "\"w+\"", ")", "\n", "temp", "=", "''", "\n", "for", "i", "in", "range", "(", "n_features", ")", ":", "\n", "\t\t", "if", "i", ">", "0", ":", "\n", "\t\t\t", "temp", "+=", "','", "\n", "", "temp", "+=", "FEATURES", "[", "i", "]", "\n", "", "g", ".", "write", "(", "temp", "+", "\"\\n\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "\t\t", "temp", "=", "data2str", "(", "data", "[", "i", ",", ":", "]", ",", "n_dim", "=", "n_dim", ")", "\n", "g", ".", "write", "(", "temp", "+", "\"\\n\"", ")", "\n", "", "g", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir": [[22, 33], ["dir_name.split", "os.path.join", "os.path.exists", "print", "os.mkdir", "print"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.mkdir"], ["def", "mkdir", "(", "dir_name", ")", ":", "\n", "    ", "dirs", "=", "dir_name", ".", "split", "(", "'/'", ")", "\n", "\n", "cur_dir", "=", "''", "\n", "for", "d", "in", "dirs", ":", "\n", "        ", "cur_dir", "=", "os", ".", "path", ".", "join", "(", "cur_dir", ",", "d", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cur_dir", ")", ":", "\n", "            ", "print", "(", "\"mkdir %s\"", "%", "cur_dir", ")", "\n", "os", ".", "mkdir", "(", "cur_dir", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"%s exists\"", "%", "cur_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.show_all_variables": [[34, 37], ["tensorflow.trainable_variables", "tensorflow.model_analyzer.analyze_vars"], "function", ["None"], ["", "", "", "def", "show_all_variables", "(", ")", ":", "\n", "  ", "model_vars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "slim", ".", "model_analyzer", ".", "analyze_vars", "(", "model_vars", ",", "print_info", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.get_image": [[38, 44], ["utils.imread", "utils.transform"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imread", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.transform"], ["", "def", "get_image", "(", "image_path", ",", "input_height", ",", "input_width", ",", "\n", "resize_height", "=", "64", ",", "resize_width", "=", "64", ",", "\n", "crop", "=", "True", ",", "grayscale", "=", "False", ")", ":", "\n", "  ", "image", "=", "imread", "(", "image_path", ",", "grayscale", ")", "\n", "return", "transform", "(", "image", ",", "input_height", ",", "input_width", ",", "\n", "resize_height", ",", "resize_width", ",", "crop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.save_images": [[45, 47], ["utils.imsave", "utils.inverse_transform"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imsave", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.inverse_transform"], ["", "def", "save_images", "(", "images", ",", "size", ",", "image_path", ")", ":", "\n", "  ", "return", "imsave", "(", "inverse_transform", "(", "images", ")", ",", "size", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imread": [[48, 53], ["scipy.misc.imread().astype", "scipy.misc.imread().astype", "scipy.misc.imread", "scipy.misc.imread"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imread", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imread"], ["", "def", "imread", "(", "path", ",", "grayscale", "=", "False", ")", ":", "\n", "  ", "if", "(", "grayscale", ")", ":", "\n", "    ", "return", "scipy", ".", "misc", ".", "imread", "(", "path", ",", "flatten", "=", "True", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "", "else", ":", "\n", "    ", "return", "scipy", ".", "misc", ".", "imread", "(", "path", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.merge_images": [[54, 56], ["utils.inverse_transform"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.inverse_transform"], ["", "", "def", "merge_images", "(", "images", ",", "size", ")", ":", "\n", "  ", "return", "inverse_transform", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.merge": [[57, 76], ["numpy.zeros", "enumerate", "numpy.zeros", "enumerate", "ValueError"], "function", ["None"], ["", "def", "merge", "(", "images", ",", "size", ")", ":", "\n", "  ", "h", ",", "w", "=", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", "\n", "if", "(", "images", ".", "shape", "[", "3", "]", "in", "(", "3", ",", "4", ")", ")", ":", "\n", "    ", "c", "=", "images", ".", "shape", "[", "3", "]", "\n", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "size", "[", "0", "]", ",", "w", "*", "size", "[", "1", "]", ",", "c", ")", ")", "\n", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "      ", "i", "=", "idx", "%", "size", "[", "1", "]", "\n", "j", "=", "idx", "//", "size", "[", "1", "]", "\n", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", ":", "]", "=", "image", "\n", "", "return", "img", "\n", "", "elif", "images", ".", "shape", "[", "3", "]", "==", "1", ":", "\n", "    ", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "size", "[", "0", "]", ",", "w", "*", "size", "[", "1", "]", ")", ")", "\n", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "      ", "i", "=", "idx", "%", "size", "[", "1", "]", "\n", "j", "=", "idx", "//", "size", "[", "1", "]", "\n", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", "]", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "", "return", "img", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'in merge(images,size) images parameter '", "\n", "'must have dimensions: HxW or HxWx3 or HxWx4'", ")", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imsave": [[78, 81], ["numpy.squeeze", "scipy.misc.imsave", "utils.merge"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.imsave", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.merge"], ["", "", "def", "imsave", "(", "images", ",", "size", ",", "path", ")", ":", "\n", "  ", "image", "=", "np", ".", "squeeze", "(", "merge", "(", "images", ",", "size", ")", ")", "\n", "return", "scipy", ".", "misc", ".", "imsave", "(", "path", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.center_crop": [[82, 91], ["int", "int", "scipy.misc.imresize", "round", "round"], "function", ["None"], ["", "def", "center_crop", "(", "x", ",", "crop_h", ",", "crop_w", ",", "\n", "resize_h", "=", "64", ",", "resize_w", "=", "64", ")", ":", "\n", "  ", "if", "crop_w", "is", "None", ":", "\n", "    ", "crop_w", "=", "crop_h", "\n", "", "h", ",", "w", "=", "x", ".", "shape", "[", ":", "2", "]", "\n", "j", "=", "int", "(", "round", "(", "(", "h", "-", "crop_h", ")", "/", "2.", ")", ")", "\n", "i", "=", "int", "(", "round", "(", "(", "w", "-", "crop_w", ")", "/", "2.", ")", ")", "\n", "return", "scipy", ".", "misc", ".", "imresize", "(", "\n", "x", "[", "j", ":", "j", "+", "crop_h", ",", "i", ":", "i", "+", "crop_w", "]", ",", "[", "resize_h", ",", "resize_w", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.transform": [[92, 101], ["utils.center_crop", "scipy.misc.imresize", "numpy.array"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.center_crop"], ["", "def", "transform", "(", "image", ",", "input_height", ",", "input_width", ",", "\n", "resize_height", "=", "64", ",", "resize_width", "=", "64", ",", "crop", "=", "True", ")", ":", "\n", "  ", "if", "crop", ":", "\n", "    ", "cropped_image", "=", "center_crop", "(", "\n", "image", ",", "input_height", ",", "input_width", ",", "\n", "resize_height", ",", "resize_width", ")", "\n", "", "else", ":", "\n", "    ", "cropped_image", "=", "scipy", ".", "misc", ".", "imresize", "(", "image", ",", "[", "resize_height", ",", "resize_width", "]", ")", "\n", "", "return", "np", ".", "array", "(", "cropped_image", ")", "/", "127.5", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.inverse_transform": [[102, 104], ["None"], "function", ["None"], ["", "def", "inverse_transform", "(", "images", ")", ":", "\n", "  ", "return", "(", "images", "+", "1.", ")", "/", "2.", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.to_json": [[105, 167], ["open", "layer_f.write", "b.eval", "[].split", "w.eval", "numpy.rollaxis", "bn.gamma.eval", "bn.beta.eval", "lines.replace().split", "w.eval", "fs.append", "fs.append", "list", "lines.replace", "w.name.split", "list", "list", "layer_idx.split", "int", "int", "list", "list", "w_.flatten"], "function", ["None"], ["", "def", "to_json", "(", "output_path", ",", "*", "layers", ")", ":", "\n", "  ", "with", "open", "(", "output_path", ",", "\"w\"", ")", "as", "layer_f", ":", "\n", "    ", "lines", "=", "\"\"", "\n", "for", "w", ",", "b", ",", "bn", "in", "layers", ":", "\n", "      ", "layer_idx", "=", "w", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", ".", "split", "(", "'h'", ")", "[", "1", "]", "\n", "\n", "B", "=", "b", ".", "eval", "(", ")", "\n", "\n", "if", "\"lin/\"", "in", "w", ".", "name", ":", "\n", "        ", "W", "=", "w", ".", "eval", "(", ")", "\n", "depth", "=", "W", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "W", "=", "np", ".", "rollaxis", "(", "w", ".", "eval", "(", ")", ",", "2", ",", "0", ")", "\n", "depth", "=", "W", ".", "shape", "[", "0", "]", "\n", "\n", "", "biases", "=", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "depth", ",", "\"w\"", ":", "[", "'%.2f'", "%", "elem", "for", "elem", "in", "list", "(", "B", ")", "]", "}", "\n", "if", "bn", "!=", "None", ":", "\n", "        ", "gamma", "=", "bn", ".", "gamma", ".", "eval", "(", ")", "\n", "beta", "=", "bn", ".", "beta", ".", "eval", "(", ")", "\n", "\n", "gamma", "=", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "depth", ",", "\"w\"", ":", "[", "'%.2f'", "%", "elem", "for", "elem", "in", "list", "(", "gamma", ")", "]", "}", "\n", "beta", "=", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "depth", ",", "\"w\"", ":", "[", "'%.2f'", "%", "elem", "for", "elem", "in", "list", "(", "beta", ")", "]", "}", "\n", "", "else", ":", "\n", "        ", "gamma", "=", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "0", ",", "\"w\"", ":", "[", "]", "}", "\n", "beta", "=", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "0", ",", "\"w\"", ":", "[", "]", "}", "\n", "\n", "", "if", "\"lin/\"", "in", "w", ".", "name", ":", "\n", "        ", "fs", "=", "[", "]", "\n", "for", "w", "in", "W", ".", "T", ":", "\n", "          ", "fs", ".", "append", "(", "{", "\"sy\"", ":", "1", ",", "\"sx\"", ":", "1", ",", "\"depth\"", ":", "W", ".", "shape", "[", "0", "]", ",", "\"w\"", ":", "[", "'%.2f'", "%", "elem", "for", "elem", "in", "list", "(", "w", ")", "]", "}", ")", "\n", "\n", "", "lines", "+=", "\"\"\"\n          var layer_%s = {\n            \"layer_type\": \"fc\", \n            \"sy\": 1, \"sx\": 1, \n            \"out_sx\": 1, \"out_sy\": 1,\n            \"stride\": 1, \"pad\": 0,\n            \"out_depth\": %s, \"in_depth\": %s,\n            \"biases\": %s,\n            \"gamma\": %s,\n            \"beta\": %s,\n            \"filters\": %s\n          };\"\"\"", "%", "(", "layer_idx", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "W", ".", "shape", "[", "1", "]", ",", "W", ".", "shape", "[", "0", "]", ",", "biases", ",", "gamma", ",", "beta", ",", "fs", ")", "\n", "", "else", ":", "\n", "        ", "fs", "=", "[", "]", "\n", "for", "w_", "in", "W", ":", "\n", "          ", "fs", ".", "append", "(", "{", "\"sy\"", ":", "5", ",", "\"sx\"", ":", "5", ",", "\"depth\"", ":", "W", ".", "shape", "[", "3", "]", ",", "\"w\"", ":", "[", "'%.2f'", "%", "elem", "for", "elem", "in", "list", "(", "w_", ".", "flatten", "(", ")", ")", "]", "}", ")", "\n", "\n", "", "lines", "+=", "\"\"\"\n          var layer_%s = {\n            \"layer_type\": \"deconv\", \n            \"sy\": 5, \"sx\": 5,\n            \"out_sx\": %s, \"out_sy\": %s,\n            \"stride\": 2, \"pad\": 1,\n            \"out_depth\": %s, \"in_depth\": %s,\n            \"biases\": %s,\n            \"gamma\": %s,\n            \"beta\": %s,\n            \"filters\": %s\n          };\"\"\"", "%", "(", "layer_idx", ",", "2", "**", "(", "int", "(", "layer_idx", ")", "+", "2", ")", ",", "2", "**", "(", "int", "(", "layer_idx", ")", "+", "2", ")", ",", "\n", "W", ".", "shape", "[", "0", "]", ",", "W", ".", "shape", "[", "3", "]", ",", "biases", ",", "gamma", ",", "beta", ",", "fs", ")", "\n", "", "", "layer_f", ".", "write", "(", "\" \"", ".", "join", "(", "lines", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ".", "split", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.make_gif": [[168, 184], ["mpy.VideoClip", "mpy.VideoClip.write_gif", "x.astype", "len", "int", "len"], "function", ["None"], ["", "", "def", "make_gif", "(", "images", ",", "fname", ",", "duration", "=", "2", ",", "true_image", "=", "False", ")", ":", "\n", "  ", "import", "moviepy", ".", "editor", "as", "mpy", "\n", "\n", "def", "make_frame", "(", "t", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "x", "=", "images", "[", "int", "(", "len", "(", "images", ")", "/", "duration", "*", "t", ")", "]", "\n", "", "except", ":", "\n", "      ", "x", "=", "images", "[", "-", "1", "]", "\n", "\n", "", "if", "true_image", ":", "\n", "      ", "return", "x", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "(", "x", "+", "1", ")", "/", "2", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "", "", "clip", "=", "mpy", ".", "VideoClip", "(", "make_frame", ",", "duration", "=", "duration", ")", "\n", "clip", ".", "write_gif", "(", "fname", ",", "fps", "=", "len", "(", "images", ")", "/", "duration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.visualize": [[185, 257], ["int", "math.ceil", "numpy.random.uniform", "sess.run", "utils.save_images", "numpy.arange", "six.moves.xrange", "time.strftime", "print", "numpy.random.uniform", "enumerate", "utils.save_images", "numpy.arange", "time.gmtime", "numpy.random.choice", "numpy.zeros", "sess.run", "sess.run", "random.randint", "print", "numpy.random.uniform", "numpy.tile", "enumerate", "numpy.arange", "six.moves.xrange", "six.moves.xrange", "numpy.random.choice", "numpy.zeros", "sess.run", "sess.run", "utils.make_gif", "print", "numpy.zeros", "enumerate", "sess.run", "utils.make_gif", "numpy.arange", "six.moves.xrange", "utils.make_gif", "utils.save_images", "print", "numpy.zeros", "enumerate", "image_set.append", "utils.make_gif", "utils.merge", "numpy.arange", "sess.run", "numpy.array", "numpy.arange", "time.strftime", "range", "range", "time.gmtime"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.save_images", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.save_images", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.make_gif", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.make_gif", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.make_gif", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.save_images", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.make_gif", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.merge"], ["", "def", "visualize", "(", "sess", ",", "dcgan", ",", "config", ",", "option", ")", ":", "\n", "  ", "image_frame_dim", "=", "int", "(", "math", ".", "ceil", "(", "config", ".", "batch_size", "**", ".5", ")", ")", "\n", "if", "option", "==", "0", ":", "\n", "    ", "z_sample", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.5", ",", "0.5", ",", "size", "=", "(", "config", ".", "batch_size", ",", "dcgan", ".", "z_dim", ")", ")", "\n", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", "}", ")", "\n", "save_images", "(", "samples", ",", "[", "image_frame_dim", ",", "image_frame_dim", "]", ",", "'./samples/test_%s.png'", "%", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "gmtime", "(", ")", ")", ")", "\n", "", "elif", "option", "==", "1", ":", "\n", "    ", "values", "=", "np", ".", "arange", "(", "0", ",", "1", ",", "1.", "/", "config", ".", "batch_size", ")", "\n", "for", "idx", "in", "xrange", "(", "dcgan", ".", "z_dim", ")", ":", "\n", "      ", "print", "(", "\" [*] %d\"", "%", "idx", ")", "\n", "z_sample", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "config", ".", "batch_size", ",", "dcgan", ".", "z_dim", ")", ")", "\n", "for", "kdx", ",", "z", "in", "enumerate", "(", "z_sample", ")", ":", "\n", "        ", "z", "[", "idx", "]", "=", "values", "[", "kdx", "]", "\n", "\n", "", "if", "config", ".", "dataset", "==", "\"mnist\"", ":", "\n", "        ", "y", "=", "np", ".", "random", ".", "choice", "(", "10", ",", "config", ".", "batch_size", ")", "\n", "y_one_hot", "=", "np", ".", "zeros", "(", "(", "config", ".", "batch_size", ",", "10", ")", ")", "\n", "y_one_hot", "[", "np", ".", "arange", "(", "config", ".", "batch_size", ")", ",", "y", "]", "=", "1", "\n", "\n", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", ",", "dcgan", ".", "y", ":", "y_one_hot", "}", ")", "\n", "", "else", ":", "\n", "        ", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", "}", ")", "\n", "\n", "", "save_images", "(", "samples", ",", "[", "image_frame_dim", ",", "image_frame_dim", "]", ",", "'./samples/test_arange_%s.png'", "%", "(", "idx", ")", ")", "\n", "", "", "elif", "option", "==", "2", ":", "\n", "    ", "values", "=", "np", ".", "arange", "(", "0", ",", "1", ",", "1.", "/", "config", ".", "batch_size", ")", "\n", "for", "idx", "in", "[", "random", ".", "randint", "(", "0", ",", "dcgan", ".", "z_dim", "-", "1", ")", "for", "_", "in", "xrange", "(", "dcgan", ".", "z_dim", ")", "]", ":", "\n", "      ", "print", "(", "\" [*] %d\"", "%", "idx", ")", "\n", "z", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.2", ",", "0.2", ",", "size", "=", "(", "dcgan", ".", "z_dim", ")", ")", "\n", "z_sample", "=", "np", ".", "tile", "(", "z", ",", "(", "config", ".", "batch_size", ",", "1", ")", ")", "\n", "#z_sample = np.zeros([config.batch_size, dcgan.z_dim])", "\n", "for", "kdx", ",", "z", "in", "enumerate", "(", "z_sample", ")", ":", "\n", "        ", "z", "[", "idx", "]", "=", "values", "[", "kdx", "]", "\n", "\n", "", "if", "config", ".", "dataset", "==", "\"mnist\"", ":", "\n", "        ", "y", "=", "np", ".", "random", ".", "choice", "(", "10", ",", "config", ".", "batch_size", ")", "\n", "y_one_hot", "=", "np", ".", "zeros", "(", "(", "config", ".", "batch_size", ",", "10", ")", ")", "\n", "y_one_hot", "[", "np", ".", "arange", "(", "config", ".", "batch_size", ")", ",", "y", "]", "=", "1", "\n", "\n", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", ",", "dcgan", ".", "y", ":", "y_one_hot", "}", ")", "\n", "", "else", ":", "\n", "        ", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", "}", ")", "\n", "\n", "", "try", ":", "\n", "        ", "make_gif", "(", "samples", ",", "'./samples/test_gif_%s.gif'", "%", "(", "idx", ")", ")", "\n", "", "except", ":", "\n", "        ", "save_images", "(", "samples", ",", "[", "image_frame_dim", ",", "image_frame_dim", "]", ",", "'./samples/test_%s.png'", "%", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "gmtime", "(", ")", ")", ")", "\n", "", "", "", "elif", "option", "==", "3", ":", "\n", "    ", "values", "=", "np", ".", "arange", "(", "0", ",", "1", ",", "1.", "/", "config", ".", "batch_size", ")", "\n", "for", "idx", "in", "xrange", "(", "dcgan", ".", "z_dim", ")", ":", "\n", "      ", "print", "(", "\" [*] %d\"", "%", "idx", ")", "\n", "z_sample", "=", "np", ".", "zeros", "(", "[", "config", ".", "batch_size", ",", "dcgan", ".", "z_dim", "]", ")", "\n", "for", "kdx", ",", "z", "in", "enumerate", "(", "z_sample", ")", ":", "\n", "        ", "z", "[", "idx", "]", "=", "values", "[", "kdx", "]", "\n", "\n", "", "samples", "=", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", "}", ")", "\n", "make_gif", "(", "samples", ",", "'./samples/test_gif_%s.gif'", "%", "(", "idx", ")", ")", "\n", "", "", "elif", "option", "==", "4", ":", "\n", "    ", "image_set", "=", "[", "]", "\n", "values", "=", "np", ".", "arange", "(", "0", ",", "1", ",", "1.", "/", "config", ".", "batch_size", ")", "\n", "\n", "for", "idx", "in", "xrange", "(", "dcgan", ".", "z_dim", ")", ":", "\n", "      ", "print", "(", "\" [*] %d\"", "%", "idx", ")", "\n", "z_sample", "=", "np", ".", "zeros", "(", "[", "config", ".", "batch_size", ",", "dcgan", ".", "z_dim", "]", ")", "\n", "for", "kdx", ",", "z", "in", "enumerate", "(", "z_sample", ")", ":", "z", "[", "idx", "]", "=", "values", "[", "kdx", "]", "\n", "\n", "image_set", ".", "append", "(", "sess", ".", "run", "(", "dcgan", ".", "sampler", ",", "feed_dict", "=", "{", "dcgan", ".", "z", ":", "z_sample", "}", ")", ")", "\n", "make_gif", "(", "image_set", "[", "-", "1", "]", ",", "'./samples/test_gif_%s.gif'", "%", "(", "idx", ")", ")", "\n", "\n", "", "new_image_set", "=", "[", "merge", "(", "np", ".", "array", "(", "[", "images", "[", "idx", "]", "for", "images", "in", "image_set", "]", ")", ",", "[", "10", ",", "10", "]", ")", "for", "idx", "in", "range", "(", "64", ")", "+", "range", "(", "63", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "make_gif", "(", "new_image_set", ",", "'./samples/test_gif_merged.gif'", ",", "duration", "=", "8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.None.utils.image_manifold_size": [[259, 264], ["int", "int", "numpy.floor", "numpy.ceil", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["", "", "def", "image_manifold_size", "(", "num_images", ")", ":", "\n", "  ", "manifold_h", "=", "int", "(", "np", ".", "floor", "(", "np", ".", "sqrt", "(", "num_images", ")", ")", ")", "\n", "manifold_w", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "num_images", ")", ")", ")", "\n", "assert", "manifold_h", "*", "manifold_w", "==", "num_images", "\n", "return", "manifold_h", ",", "manifold_w", "\n", "", ""]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-mnist.pipeline": [[18, 74], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "joblib.load", "print", "numpy.hsplit", "label.reshape.reshape", "x.reshape.reshape", "mnist.load_data", "np_utils.to_categorical", "np_utils.to_categorical", "x_train.reshape.reshape", "x_test.reshape.reshape", "Sequential", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "optimizers.sgd", "Sequential.compile", "print", "print", "print", "print", "Sequential.fit", "x_train.reshape.astype", "x_test.reshape.astype", "Conv2D", "MaxPooling2D", "Dropout", "Conv2D", "Dropout", "Flatten", "Dense", "Dense"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "pipeline", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train classifier and evaluate their accuracy'", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "help", "=", "'datafile name'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "import", "joblib", "\n", "data", "=", "joblib", ".", "load", "(", "args", ".", "data", ")", "\n", "print", "(", "args", ".", "data", ")", "\n", "x", ",", "label", "=", "np", ".", "hsplit", "(", "data", ",", "[", "-", "10", "]", ")", "\n", "nb_classes", "=", "10", "\n", "label", "=", "label", ".", "reshape", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "nb_classes", ")", ",", "order", "=", "'F'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "from", "keras", ".", "datasets", "import", "mnist", "\n", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "mnist", ".", "load_data", "(", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "y_train", "=", "np_utils", ".", "to_categorical", "(", "y_train", ",", "10", ")", "\n", "y_test", "=", "np_utils", ".", "to_categorical", "(", "y_test", ",", "10", ")", "\n", "x_train", "=", "x_train", ".", "reshape", "(", "x_train", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "x_train", "=", "x_train", ".", "astype", "(", "'float32'", ")", "/", "255.", "\n", "x_test", "=", "x_test", ".", "reshape", "(", "x_test", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "x_test", "=", "x_test", ".", "astype", "(", "'float32'", ")", "/", "255.", "\n", "\n", "from", "keras", ".", "models", "import", "Sequential", "\n", "from", "keras", ".", "layers", ".", "core", "import", "Dense", ",", "Dropout", ",", "Activation", ",", "Flatten", "\n", "from", "keras", ".", "layers", ".", "pooling", "import", "MaxPooling2D", "\n", "from", "keras", ".", "layers", ".", "convolutional", "import", "Convolution2D", ",", "Conv2D", "\n", "from", "keras", ".", "optimizers", "import", "Adam", "\n", "from", "keras", "import", "optimizers", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "32", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "28", ",", "28", ",", "1", ")", ",", "name", "=", "'Conv2D-1'", ")", ")", "\n", "model", ".", "add", "(", "MaxPooling2D", "(", "pool_size", "=", "2", ",", "name", "=", "'MaxPool'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ",", "name", "=", "'Dropout-1'", ")", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "64", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "name", "=", "'Conv2D-2'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ",", "name", "=", "'Dropout-2'", ")", ")", "\n", "model", ".", "add", "(", "Flatten", "(", "name", "=", "'flatten'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "name", "=", "'Dense'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'Output'", ")", ")", "\n", "sgd", "=", "optimizers", ".", "sgd", "(", "lr", "=", "1e-3", ")", "\n", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "sgd", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "label", ".", "shape", ")", "\n", "print", "(", "x_test", ".", "shape", ")", "\n", "print", "(", "y_test", ".", "shape", ")", "\n", "train_accs", "=", "[", "]", "\n", "eval_accs", "=", "[", "]", "\n", "#     for i in range(70):", "\n", "history", "=", "model", ".", "fit", "(", "x", ",", "label", ",", "batch_size", "=", "512", ",", "epochs", "=", "600", ",", "validation_data", "=", "(", "x_test", ",", "y_test", ")", ",", "shuffle", "=", "True", ")", "\n", "train_accs", "=", "history", ".", "history", "[", "'acc'", "]", "\n", "eval_accs", "=", "history", ".", "history", "[", "'val_acc'", "]", "\n", "return", "train_accs", ",", "eval_accs", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-small-celebA.load_celeb": [[27, 35], ["joblib.load", "joblib.load", "print", "np_utils.to_categorical", "np_utils.to_categorical.sum", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "load_celeb", "(", ")", ":", "\n", "    ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-x-small.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-gender.pkl'", ")", "\n", "print", "(", "tst_y", ".", "sum", "(", ")", ",", "len", "(", "tst_y", ")", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "2", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-small-celebA.pipeline": [[41, 78], ["print", "numpy.hsplit", "label.reshape.reshape", "x.reshape.reshape", "Sequential", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "optimizers.sgd", "Sequential.compile", "print", "print", "print", "print", "Sequential.fit", "Conv2D", "MaxPooling2D", "Dropout", "Conv2D", "Dropout", "Flatten", "Dense", "Dense"], "function", ["None"], ["def", "pipeline", "(", "data", ")", ":", "\n", "    ", "print", "(", "data", ".", "shape", ")", "\n", "x", ",", "label", "=", "np", ".", "hsplit", "(", "data", ",", "[", "-", "2", "]", ")", "\n", "nb_classes", "=", "2", "\n", "label", "=", "label", ".", "reshape", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "nb_classes", ")", ",", "order", "=", "'F'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "32", ",", "32", ",", "3", ")", "\n", "\n", "from", "keras", ".", "models", "import", "Sequential", "\n", "from", "keras", ".", "layers", ".", "core", "import", "Dense", ",", "Dropout", ",", "Activation", ",", "Flatten", "\n", "from", "keras", ".", "layers", ".", "pooling", "import", "MaxPooling2D", "\n", "from", "keras", ".", "layers", ".", "convolutional", "import", "Convolution2D", ",", "Conv2D", "\n", "from", "keras", ".", "optimizers", "import", "Adam", "\n", "from", "keras", "import", "optimizers", "\n", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "32", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "32", ",", "32", ",", "3", ")", ",", "name", "=", "'Conv2D-1'", ")", ")", "\n", "model", ".", "add", "(", "MaxPooling2D", "(", "pool_size", "=", "2", ",", "name", "=", "'MaxPool'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ",", "name", "=", "'Dropout-1'", ")", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "64", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "name", "=", "'Conv2D-2'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ",", "name", "=", "'Dropout-2'", ")", ")", "\n", "model", ".", "add", "(", "Flatten", "(", "name", "=", "'flatten'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "name", "=", "'Dense'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'Output'", ")", ")", "\n", "sgd", "=", "optimizers", ".", "sgd", "(", "lr", "=", "1e-4", ")", "\n", "\n", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "sgd", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "label", ".", "shape", ")", "\n", "print", "(", "x_test", ".", "shape", ")", "\n", "print", "(", "y_test", ".", "shape", ")", "\n", "evals", "=", "model", ".", "fit", "(", "x", ",", "label", ",", "batch_size", "=", "256", ",", "epochs", "=", "250", ",", "validation_data", "=", "(", "x_test", ",", "y_test", ")", ",", "shuffle", "=", "True", ")", "\n", "return", "evals", ".", "history", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-fmnist.pipeline": [[16, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "joblib.load", "print", "numpy.hsplit", "label.reshape.reshape", "x.reshape.reshape", "fashion_mnist.load_data", "np_utils.to_categorical", "np_utils.to_categorical", "x_train.reshape.reshape", "x_test.reshape.reshape", "Sequential", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "optimizers.sgd", "Sequential.compile", "print", "print", "print", "print", "Sequential.fit", "x_train.reshape.astype", "x_test.reshape.astype", "Conv2D", "MaxPooling2D", "Dropout", "Conv2D", "Dropout", "Flatten", "Dense", "Dense"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "pipeline", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train classifier and evaluate their accuracy'", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "help", "=", "'datafile name'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "import", "joblib", "\n", "data", "=", "joblib", ".", "load", "(", "args", ".", "data", ")", "\n", "print", "(", "args", ".", "data", ")", "\n", "\n", "x", ",", "label", "=", "np", ".", "hsplit", "(", "data", ",", "[", "-", "10", "]", ")", "\n", "nb_classes", "=", "10", "\n", "label", "=", "label", ".", "reshape", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "nb_classes", ")", ",", "order", "=", "'F'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "from", "keras", ".", "datasets", "import", "fashion_mnist", "\n", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "fashion_mnist", ".", "load_data", "(", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "y_train", "=", "np_utils", ".", "to_categorical", "(", "y_train", ",", "10", ")", "\n", "y_test", "=", "np_utils", ".", "to_categorical", "(", "y_test", ",", "10", ")", "\n", "x_train", "=", "x_train", ".", "reshape", "(", "x_train", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "x_train", "=", "x_train", ".", "astype", "(", "'float32'", ")", "/", "255.", "\n", "x_test", "=", "x_test", ".", "reshape", "(", "x_test", ".", "shape", "[", "0", "]", ",", "28", ",", "28", ",", "1", ")", "\n", "x_test", "=", "x_test", ".", "astype", "(", "'float32'", ")", "/", "255.", "\n", "\n", "from", "keras", ".", "models", "import", "Sequential", "\n", "from", "keras", ".", "layers", ".", "core", "import", "Dense", ",", "Dropout", ",", "Activation", ",", "Flatten", "\n", "from", "keras", ".", "layers", ".", "pooling", "import", "MaxPooling2D", "\n", "from", "keras", ".", "layers", ".", "convolutional", "import", "Convolution2D", ",", "Conv2D", "\n", "from", "keras", ".", "optimizers", "import", "Adam", "\n", "from", "keras", "import", "optimizers", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "32", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "28", ",", "28", ",", "1", ")", ",", "name", "=", "'Conv2D-1'", ")", ")", "\n", "model", ".", "add", "(", "MaxPooling2D", "(", "pool_size", "=", "2", ",", "name", "=", "'MaxPool'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ",", "name", "=", "'Dropout-1'", ")", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "64", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "name", "=", "'Conv2D-2'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ",", "name", "=", "'Dropout-2'", ")", ")", "\n", "model", ".", "add", "(", "Flatten", "(", "name", "=", "'flatten'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "name", "=", "'Dense'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'Output'", ")", ")", "\n", "sgd", "=", "optimizers", ".", "sgd", "(", "lr", "=", "2e-3", ")", "\n", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "sgd", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "label", ".", "shape", ")", "\n", "print", "(", "x_test", ".", "shape", ")", "\n", "print", "(", "y_test", ".", "shape", ")", "\n", "train_accs", "=", "[", "]", "\n", "eval_accs", "=", "[", "]", "\n", "history", "=", "model", ".", "fit", "(", "x", ",", "label", ",", "batch_size", "=", "512", ",", "epochs", "=", "600", ",", "validation_data", "=", "(", "x_test", ",", "y_test", ")", ",", "shuffle", "=", "True", ")", "\n", "if", "'acc'", "in", "history", ".", "history", ":", "\n", "        ", "train_accs", "=", "history", ".", "history", "[", "'acc'", "]", "\n", "", "else", ":", "\n", "        ", "train_accs", "=", "history", ".", "history", "[", "'accuracy'", "]", "\n", "", "if", "'val_acc'", "in", "history", ".", "history", ":", "\n", "        ", "eval_accs", "=", "history", ".", "history", "[", "'val_acc'", "]", "\n", "", "else", ":", "\n", "        ", "eval_accs", "=", "history", ".", "history", "[", "'val_accuracy'", "]", "\n", "", "return", "train_accs", ",", "eval_accs", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-hair.load_celeb": [[18, 26], ["joblib.load", "joblib.load", "print", "np_utils.to_categorical", "np_utils.to_categorical.sum", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "load_celeb", "(", ")", ":", "\n", "    ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-tst-ups-hair-x.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-tst-ups-hair-y.pkl'", ")", "\n", "print", "(", "tst_y", ".", "sum", "(", ")", ",", "len", "(", "tst_y", ")", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "3", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-hair.load_celeb_train": [[28, 36], ["joblib.load", "joblib.load", "print", "np_utils.to_categorical", "np_utils.to_categorical.sum", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "def", "load_celeb_train", "(", ")", ":", "\n", "    ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-trn-ups-hair-x.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celeb-trn-ups-hair-y.pkl'", ")", "\n", "print", "(", "tst_y", ".", "sum", "(", ")", ",", "len", "(", "tst_y", ")", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "3", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-hair.pipeline": [[42, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "joblib.load", "print", "print", "numpy.hsplit", "label.reshape.reshape", "x.reshape.reshape", "Sequential", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "optimizers.sgd", "Sequential.compile", "print", "print", "print", "print", "Sequential.fit", "Conv2D", "MaxPooling2D", "Dropout", "Conv2D", "Dropout", "Flatten", "Dense", "Dense"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "pipeline", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train classifier and evaluate their accuracy'", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "help", "=", "'datafile name'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data", "=", "joblib", ".", "load", "(", "args", ".", "data", ")", "\n", "print", "(", "args", ".", "data", ")", "\n", "\n", "print", "(", "data", ".", "shape", ")", "\n", "x", ",", "label", "=", "np", ".", "hsplit", "(", "data", ",", "[", "-", "3", "]", ")", "\n", "nb_classes", "=", "3", "\n", "label", "=", "label", ".", "reshape", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "nb_classes", ")", ",", "order", "=", "'F'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ",", "3", ")", "\n", "\n", "from", "keras", ".", "models", "import", "Sequential", "\n", "from", "keras", ".", "layers", ".", "core", "import", "Dense", ",", "Dropout", ",", "Activation", ",", "Flatten", "\n", "from", "keras", ".", "layers", ".", "pooling", "import", "MaxPooling2D", "\n", "from", "keras", ".", "layers", ".", "convolutional", "import", "Convolution2D", ",", "Conv2D", "\n", "from", "keras", ".", "optimizers", "import", "Adam", "\n", "from", "keras", "import", "optimizers", "\n", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "32", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "64", ",", "64", ",", "3", ")", ",", "name", "=", "'Conv2D-1'", ")", ")", "\n", "model", ".", "add", "(", "MaxPooling2D", "(", "pool_size", "=", "2", ",", "name", "=", "'MaxPool'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ",", "name", "=", "'Dropout-1'", ")", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "64", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "name", "=", "'Conv2D-2'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ",", "name", "=", "'Dropout-2'", ")", ")", "\n", "model", ".", "add", "(", "Flatten", "(", "name", "=", "'flatten'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "name", "=", "'Dense'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'Output'", ")", ")", "\n", "sgd", "=", "optimizers", ".", "sgd", "(", "lr", "=", "1e-4", ")", "\n", "\n", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "sgd", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "label", ".", "shape", ")", "\n", "print", "(", "x_test", ".", "shape", ")", "\n", "print", "(", "y_test", ".", "shape", ")", "\n", "evals", "=", "model", ".", "fit", "(", "x", ",", "label", ",", "batch_size", "=", "256", ",", "epochs", "=", "250", ",", "validation_data", "=", "(", "x_test", ",", "y_test", ")", ",", "shuffle", "=", "True", ")", "\n", "return", "evals", ".", "history", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-celebA.load_celeb": [[17, 25], ["joblib.load", "joblib.load", "print", "np_utils.to_categorical", "np_utils.to_categorical.sum", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "load_celeb", "(", ")", ":", "\n", "    ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-x.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-tst-gender.pkl'", ")", "\n", "print", "(", "tst_y", ".", "sum", "(", ")", ",", "len", "(", "tst_y", ")", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "2", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-celebA.load_celeb_train": [[26, 34], ["joblib.load", "joblib.load", "print", "np_utils.to_categorical", "np_utils.to_categorical.sum", "len"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load", "home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["", "def", "load_celeb_train", "(", ")", ":", "\n", "    ", "celebA_directory", "=", "'../../data/celebA/'", "\n", "tst_x", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-x-lg-ups.pkl'", ")", "\n", "tst_y", "=", "joblib", ".", "load", "(", "celebA_directory", "+", "'celebA-trn-gender-lg-ups.pkl'", ")", "\n", "print", "(", "tst_y", ".", "sum", "(", ")", ",", "len", "(", "tst_y", ")", ")", "\n", "from", "keras", ".", "utils", "import", "np_utils", "\n", "tst_y", "=", "np_utils", ".", "to_categorical", "(", "tst_y", ",", "2", ")", "\n", "return", "tst_x", ",", "tst_y", "\n", "\n"]], "home.repos.pwc.inspect_result.ai-secure_g-pate.evaluation.train-classifier-celebA.pipeline": [[39, 82], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "joblib.load", "print", "print", "numpy.hsplit", "label.reshape.reshape", "x.reshape.reshape", "Sequential", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "Sequential.add", "optimizers.sgd", "Sequential.compile", "print", "print", "print", "print", "Sequential.fit", "Conv2D", "MaxPooling2D", "Dropout", "Conv2D", "Dropout", "Flatten", "Dense", "Dense"], "function", ["home.repos.pwc.inspect_result.ai-secure_g-pate.None.model.DCGAN.load"], ["def", "pipeline", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train classifier and evaluate their accuracy'", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "help", "=", "'datafile name'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data", "=", "joblib", ".", "load", "(", "args", ".", "data", ")", "\n", "print", "(", "args", ".", "data", ")", "\n", "print", "(", "data", ".", "shape", ")", "\n", "x", ",", "label", "=", "np", ".", "hsplit", "(", "data", ",", "[", "-", "2", "]", ")", "\n", "nb_classes", "=", "2", "\n", "label", "=", "label", ".", "reshape", "(", "(", "label", ".", "shape", "[", "0", "]", ",", "nb_classes", ")", ",", "order", "=", "'F'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ",", "3", ")", "\n", "from", "keras", ".", "models", "import", "Sequential", "\n", "from", "keras", ".", "layers", ".", "core", "import", "Dense", ",", "Dropout", ",", "Activation", ",", "Flatten", "\n", "from", "keras", ".", "layers", ".", "pooling", "import", "MaxPooling2D", "\n", "from", "keras", ".", "layers", ".", "convolutional", "import", "Convolution2D", ",", "Conv2D", "\n", "from", "keras", ".", "optimizers", "import", "Adam", "\n", "from", "keras", "import", "optimizers", "\n", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "32", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "64", ",", "64", ",", "3", ")", ",", "name", "=", "'Conv2D-1'", ")", ")", "\n", "model", ".", "add", "(", "MaxPooling2D", "(", "pool_size", "=", "2", ",", "name", "=", "'MaxPool'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ",", "name", "=", "'Dropout-1'", ")", ")", "\n", "model", ".", "add", "(", "Conv2D", "(", "64", ",", "kernel_size", "=", "3", ",", "activation", "=", "'relu'", ",", "name", "=", "'Conv2D-2'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ",", "name", "=", "'Dropout-2'", ")", ")", "\n", "model", ".", "add", "(", "Flatten", "(", "name", "=", "'flatten'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "name", "=", "'Dense'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'Output'", ")", ")", "\n", "sgd", "=", "optimizers", ".", "sgd", "(", "lr", "=", "1e-4", ")", "\n", "\n", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "sgd", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "label", ".", "shape", ")", "\n", "print", "(", "x_test", ".", "shape", ")", "\n", "print", "(", "y_test", ".", "shape", ")", "\n", "evals", "=", "model", ".", "fit", "(", "x", ",", "label", ",", "batch_size", "=", "256", ",", "epochs", "=", "250", ",", "validation_data", "=", "(", "x_test", ",", "y_test", ")", ",", "shuffle", "=", "True", ")", "\n", "return", "evals", ".", "history", "\n", "\n"]]}