{"home.repos.pwc.inspect_result.matthewcym_sflm.None.run.main": [[282, 647], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.warning", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "src.dataset.FewShotDataset", "src.dataset.FewShotDataset", "transformers.set_seed", "model_fn.from_pretrained", "src.trainer.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.exists", "os.listdir", "ValueError", "bool", "logger.info", "src.dataset.FewShotDataset", "src.dataset.FewShotDataset", "model.to.resize_token_embeddings", "src.models.resize_token_type_embeddings", "torch.tensor().long().cuda", "src.trainer.Trainer.train", "src.trainer.Trainer.is_world_master", "model_fn.from_pretrained", "model.to.to", "str", "logger.info", "logging.info", "filelock.FileLock", "len", "logger.info", "ValueError", "logger.info", "old_template.replace.replace", "range", "logger.info", "logger.info", "bool", "len", "predictions.reshape", "predictions.reshape().mean.mean", "p.label_ids.reshape", "p.label_ids.reshape.mean", "label_ids_avg.astype.astype", "run.main.build_compute_metrics_fn"], "function", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.models.resize_token_type_embeddings", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DynamicDataTrainingArguments", ",", "DynamicTrainingArguments", ")", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "if", "'prompt'", "in", "model_args", ".", "few_shot_type", ":", "\n", "        ", "data_args", ".", "prompt", "=", "True", "\n", "\n", "", "if", "training_args", ".", "no_train", ":", "\n", "        ", "training_args", ".", "do_train", "=", "False", "\n", "", "if", "training_args", ".", "no_predict", ":", "\n", "        ", "training_args", ".", "do_predict", "=", "False", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "\n", "# Load prompt/template/mapping file", "\n", "if", "data_args", ".", "prompt", ":", "\n", "        ", "if", "data_args", ".", "prompt_path", "is", "not", "None", ":", "\n", "            ", "assert", "data_args", ".", "prompt_id", "is", "not", "None", "\n", "prompt_list", "=", "[", "]", "\n", "with", "open", "(", "data_args", ".", "prompt_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "template", ",", "mapping", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "prompt_list", ".", "append", "(", "(", "template", ",", "mapping", ")", ")", "\n", "\n", "", "", "data_args", ".", "template", ",", "data_args", ".", "mapping", "=", "prompt_list", "[", "data_args", ".", "prompt_id", "]", "\n", "logger", ".", "info", "(", "\"Specify load the %d-th prompt: %s | %s\"", "%", "(", "data_args", ".", "prompt_id", ",", "data_args", ".", "template", ",", "data_args", ".", "mapping", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "data_args", ".", "template_path", "is", "not", "None", ":", "\n", "                ", "with", "open", "(", "data_args", ".", "template_path", ")", "as", "f", ":", "\n", "                    ", "data_args", ".", "template_list", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", ">", "0", ":", "\n", "                            ", "data_args", ".", "template_list", ".", "append", "(", "line", ")", "\n", "\n", "# Load top-n templates", "\n", "", "", "", "if", "data_args", ".", "top_n_template", "is", "not", "None", ":", "\n", "                    ", "data_args", ".", "template_list", "=", "data_args", ".", "template_list", "[", ":", "data_args", ".", "top_n_template", "]", "\n", "", "logger", ".", "info", "(", "\"Load top-%d templates from %s\"", "%", "(", "len", "(", "data_args", ".", "template_list", ")", ",", "data_args", ".", "template_path", ")", ")", "\n", "\n", "# ... or load i-th template", "\n", "if", "data_args", ".", "template_id", "is", "not", "None", ":", "\n", "                    ", "data_args", ".", "template", "=", "data_args", ".", "template_list", "[", "data_args", ".", "template_id", "]", "\n", "data_args", ".", "template_list", "=", "None", "\n", "logger", ".", "info", "(", "\"Specify load the %d-th template: %s\"", "%", "(", "data_args", ".", "template_id", ",", "data_args", ".", "template", ")", ")", "\n", "\n", "", "", "if", "data_args", ".", "mapping_path", "is", "not", "None", ":", "\n", "                ", "assert", "data_args", ".", "mapping_id", "is", "not", "None", "# Only can use one label word mapping", "\n", "with", "open", "(", "data_args", ".", "mapping_path", ")", "as", "f", ":", "\n", "                    ", "mapping_list", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "mapping_list", ".", "append", "(", "line", ")", "\n", "\n", "", "", "data_args", ".", "mapping", "=", "mapping_list", "[", "data_args", ".", "mapping_id", "]", "\n", "logger", ".", "info", "(", "\"Specify using the %d-th mapping: %s\"", "%", "(", "data_args", ".", "mapping_id", ",", "data_args", ".", "mapping", ")", ")", "\n", "\n", "# Check save path", "\n", "", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Output directory ({training_args.output_dir}) already exists.\"", ")", "\n", "\n", "", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "try", ":", "\n", "        ", "num_labels", "=", "num_labels_mapping", "[", "data_args", ".", "task_name", "]", "\n", "output_mode", "=", "output_modes_mapping", "[", "data_args", ".", "task_name", "]", "\n", "logger", ".", "info", "(", "\"Task name: {}, number of labels: {}, output mode: {}\"", ".", "format", "(", "data_args", ".", "task_name", ",", "num_labels", ",", "output_mode", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "data_args", ".", "task_name", ")", ")", "\n", "\n", "# Automatically generate template for using demonstrations", "\n", "", "if", "data_args", ".", "auto_demo", "and", "model_args", ".", "few_shot_type", "==", "'prompt-demo'", ":", "\n", "# GPT-3's in-context learning", "\n", "        ", "if", "data_args", ".", "gpt3_in_context_head", "or", "data_args", ".", "gpt3_in_context_tail", ":", "\n", "            ", "logger", ".", "info", "(", "\"Automatically convert the template to GPT-3's in-context learning.\"", ")", "\n", "assert", "data_args", ".", "template_list", "is", "None", "\n", "\n", "old_template", "=", "data_args", ".", "template", "\n", "new_template", "=", "old_template", "+", "''", "\n", "old_template", "=", "old_template", ".", "replace", "(", "'*cls*'", ",", "''", ")", "\n", "# Single sentence or sentence pair?", "\n", "sent_num", "=", "1", "\n", "if", "\"_1\"", "in", "old_template", ":", "\n", "                ", "sent_num", "=", "2", "\n", "", "for", "instance_id", "in", "range", "(", "data_args", ".", "gpt3_in_context_num", ")", ":", "\n", "                ", "sub_template", "=", "old_template", "+", "''", "\n", "# Replace sent_id", "\n", "for", "sent_id", "in", "range", "(", "sent_num", ")", ":", "\n", "                    ", "sub_template", "=", "sub_template", ".", "replace", "(", "\"_{}*\"", ".", "format", "(", "sent_id", ")", ",", "\"_{}*\"", ".", "format", "(", "sent_num", "+", "sent_num", "*", "instance_id", "+", "sent_id", ")", ")", "\n", "# Replace mask", "\n", "", "sub_template", "=", "sub_template", ".", "replace", "(", "\"*mask*\"", ",", "\"*labelx_{}*\"", ".", "format", "(", "instance_id", ")", ")", "\n", "if", "data_args", ".", "gpt3_in_context_tail", ":", "\n", "                    ", "new_template", "=", "new_template", "+", "sub_template", "# Put context at the end", "\n", "", "else", ":", "\n", "                    ", "new_template", "=", "sub_template", "+", "new_template", "# Put context at the beginning", "\n", "", "", "logger", ".", "info", "(", "\"| {} => {}\"", ".", "format", "(", "data_args", ".", "template", ",", "new_template", ")", ")", "\n", "data_args", ".", "template", "=", "new_template", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Automatically convert the template to using demonstrations.\"", ")", "\n", "if", "data_args", ".", "template_list", "is", "not", "None", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "data_args", ".", "template_list", ")", ")", ":", "\n", "                    ", "old_template", "=", "data_args", ".", "template_list", "[", "i", "]", "\n", "new_template", "=", "old_template", "+", "''", "\n", "old_template", "=", "old_template", ".", "replace", "(", "'*cls*'", ",", "''", ")", "\n", "# Single sentence or sentence pair?", "\n", "sent_num", "=", "1", "\n", "if", "\"_1\"", "in", "old_template", ":", "\n", "                        ", "sent_num", "=", "2", "\n", "", "for", "label_id", "in", "range", "(", "num_labels", ")", ":", "\n", "                        ", "sub_template", "=", "old_template", "+", "''", "\n", "# Replace sent id", "\n", "for", "sent_id", "in", "range", "(", "sent_num", ")", ":", "\n", "                            ", "sub_template", "=", "sub_template", ".", "replace", "(", "\"_{}*\"", ".", "format", "(", "sent_id", ")", ",", "\"_{}*\"", ".", "format", "(", "sent_num", "+", "sent_num", "*", "label_id", "+", "sent_id", ")", ")", "\n", "# Replace mask", "\n", "", "sub_template", "=", "sub_template", ".", "replace", "(", "\"*mask*\"", ",", "\"*label_{}*\"", ".", "format", "(", "label_id", ")", ")", "\n", "new_template", "=", "new_template", "+", "sub_template", "\n", "", "logger", ".", "info", "(", "\"| {} => {}\"", ".", "format", "(", "data_args", ".", "template_list", "[", "i", "]", ",", "new_template", ")", ")", "\n", "data_args", ".", "template_list", "[", "i", "]", "=", "new_template", "\n", "", "", "else", ":", "\n", "                ", "old_template", "=", "data_args", ".", "template", "\n", "new_template", "=", "old_template", "+", "''", "\n", "old_template", "=", "old_template", ".", "replace", "(", "'*cls*'", ",", "''", ")", "\n", "# Single sentence or sentence pair?", "\n", "sent_num", "=", "1", "\n", "if", "\"_1\"", "in", "old_template", ":", "\n", "                    ", "sent_num", "=", "2", "\n", "", "for", "label_id", "in", "range", "(", "num_labels", ")", ":", "\n", "                    ", "sub_template", "=", "old_template", "+", "''", "\n", "# Replace sent id", "\n", "for", "sent_id", "in", "range", "(", "sent_num", ")", ":", "\n", "                        ", "sub_template", "=", "sub_template", ".", "replace", "(", "\"_{}\"", ".", "format", "(", "sent_id", ")", ",", "\"_{}\"", ".", "format", "(", "sent_num", "+", "sent_num", "*", "label_id", "+", "sent_id", ")", ")", "\n", "# Replace mask", "\n", "", "sub_template", "=", "sub_template", ".", "replace", "(", "\"*mask*\"", ",", "\"*label_{}*\"", ".", "format", "(", "label_id", ")", ")", "\n", "new_template", "=", "new_template", "+", "sub_template", "\n", "", "logger", ".", "info", "(", "\"| {} => {}\"", ".", "format", "(", "data_args", ".", "template", ",", "new_template", ")", ")", "\n", "data_args", ".", "template", "=", "new_template", "\n", "\n", "# Create config", "\n", "", "", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "data_args", ".", "task_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "if", "'prompt'", "in", "model_args", ".", "few_shot_type", ":", "\n", "        ", "if", "config", ".", "model_type", "==", "'roberta'", ":", "\n", "            ", "model_fn", "=", "RobertaForPromptFinetuning", "\n", "", "elif", "config", ".", "model_type", "==", "'bert'", ":", "\n", "            ", "model_fn", "=", "BertForPromptFinetuning", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "", "elif", "model_args", ".", "few_shot_type", "==", "'finetune'", ":", "\n", "        ", "model_fn", "=", "AutoModelForSequenceClassification", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "special_tokens", "=", "[", "]", "\n", "\n", "# Create tokenizer", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "additional_special_tokens", "=", "special_tokens", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "# Get our special datasets.", "\n", "train_dataset", "=", "(", "\n", "FewShotDataset", "(", "data_args", ",", "tokenizer", "=", "tokenizer", ",", "mode", "=", "\"train\"", ",", "use_demo", "=", "(", "\"demo\"", "in", "model_args", ".", "few_shot_type", ")", ")", "\n", ")", "\n", "unlabeled_dataset", "=", "(", "\n", "FewShotDataset", "(", "data_args", ",", "tokenizer", "=", "tokenizer", ",", "mode", "=", "\"unlabeled\"", ",", "use_demo", "=", "(", "\"demo\"", "in", "model_args", ".", "few_shot_type", ")", ")", "\n", ")", "\n", "eval_dataset", "=", "(", "\n", "FewShotDataset", "(", "data_args", ",", "tokenizer", "=", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "use_demo", "=", "(", "\"demo\"", "in", "model_args", ".", "few_shot_type", ")", ")", "\n", "if", "training_args", ".", "do_eval", "\n", "else", "None", "\n", ")", "\n", "test_dataset", "=", "(", "\n", "FewShotDataset", "(", "data_args", ",", "tokenizer", "=", "tokenizer", ",", "mode", "=", "\"test\"", ",", "use_demo", "=", "(", "\"demo\"", "in", "model_args", ".", "few_shot_type", ")", ")", "\n", "if", "training_args", ".", "do_predict", "\n", "else", "None", "\n", ")", "\n", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "model", "=", "model_fn", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "# For BERT, increase the size of the segment (token type) embeddings", "\n", "if", "config", ".", "model_type", "==", "'bert'", ":", "\n", "        ", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "resize_token_type_embeddings", "(", "model", ",", "new_num_types", "=", "10", ",", "random_segment", "=", "model_args", ".", "random_segment", ")", "\n", "\n", "# Pass dataset and argument information to the model", "\n", "", "if", "data_args", ".", "prompt", ":", "\n", "        ", "model", ".", "label_word_list", "=", "torch", ".", "tensor", "(", "train_dataset", ".", "label_word_list", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "", "model", ".", "model_args", "=", "model_args", "\n", "model", ".", "data_args", "=", "data_args", "\n", "model", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "# Build metric", "\n", "def", "build_compute_metrics_fn", "(", "task_name", ":", "str", ")", "->", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", ":", "\n", "        ", "def", "compute_metrics_fn", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "# Note: the eval dataloader is sequential, so the examples are in order.", "\n", "# We average the logits over each sample for using demonstrations.", "\n", "            ", "predictions", "=", "p", ".", "predictions", "\n", "num_logits", "=", "predictions", ".", "shape", "[", "-", "1", "]", "\n", "logits", "=", "predictions", ".", "reshape", "(", "[", "eval_dataset", ".", "num_sample", ",", "-", "1", ",", "num_logits", "]", ")", "\n", "logits", "=", "logits", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "if", "num_logits", "==", "1", ":", "\n", "                ", "preds", "=", "np", ".", "squeeze", "(", "logits", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "\n", "# Just for sanity, assert label ids are the same.", "\n", "", "label_ids", "=", "p", ".", "label_ids", ".", "reshape", "(", "[", "eval_dataset", ".", "num_sample", ",", "-", "1", "]", ")", "\n", "label_ids_avg", "=", "label_ids", ".", "mean", "(", "axis", "=", "0", ")", "\n", "label_ids_avg", "=", "label_ids_avg", ".", "astype", "(", "p", ".", "label_ids", ".", "dtype", ")", "\n", "assert", "(", "label_ids_avg", "-", "label_ids", "[", "0", "]", ")", ".", "mean", "(", ")", "<", "1e-2", "\n", "label_ids", "=", "label_ids", "[", "0", "]", "\n", "\n", "return", "compute_metrics_mapping", "[", "task_name", "]", "(", "task_name", ",", "preds", ",", "label_ids", ")", "\n", "\n", "", "return", "compute_metrics_fn", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "unlabeled_dataset", "=", "unlabeled_dataset", ",", "\n", "eval_dataset", "=", "eval_dataset", ",", "\n", "compute_metrics", "=", "build_compute_metrics_fn", "(", "data_args", ".", "task_name", ")", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "train", "(", "model_path", "=", "model_args", ".", "model_name_or_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "else", "None", ")", "\n", "# Use the early stop, so do not save the model in the end (unless specify save_at_last)", "\n", "if", "training_args", ".", "save_at_last", ":", "\n", "            ", "trainer", ".", "save_model", "(", "training_args", ".", "output_dir", ")", "\n", "\n", "", "if", "trainer", ".", "is_world_master", "(", ")", ":", "\n", "            ", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "torch", ".", "save", "(", "model_args", ",", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"model_args.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "data_args", ",", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"data_args.bin\"", ")", ")", "\n", "\n", "# Reload the best checkpoint (for eval)", "\n", "", "model", "=", "model_fn", ".", "from_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "model", "=", "model", ".", "to", "(", "training_args", ".", "device", ")", "\n", "trainer", ".", "model", "=", "model", "\n", "if", "data_args", ".", "prompt", ":", "\n", "            ", "model", ".", "label_word_list", "=", "torch", ".", "tensor", "(", "train_dataset", ".", "label_word_list", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "", "model", ".", "model_args", "=", "model_args", "\n", "model", ".", "data_args", "=", "data_args", "\n", "model", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "# Evaluation", "\n", "", "final_result", "=", "{", "\n", "'time'", ":", "str", "(", "datetime", ".", "today", "(", ")", ")", ",", "\n", "}", "\n", "\n", "eval_results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Validate ***\"", ")", "\n", "\n", "eval_datasets", "=", "[", "eval_dataset", "]", "\n", "\n", "for", "eval_dataset", "in", "eval_datasets", ":", "\n", "            ", "trainer", ".", "compute_metrics", "=", "build_compute_metrics_fn", "(", "eval_dataset", ".", "args", ".", "task_name", ")", "\n", "output", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ")", "\n", "eval_result", "=", "output", ".", "metrics", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "f\"eval_results_{eval_dataset.args.task_name}.txt\"", "\n", ")", "\n", "if", "trainer", ".", "is_world_master", "(", ")", ":", "\n", "                ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                    ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "eval_dataset", ".", "args", ".", "task_name", ")", ")", "\n", "for", "key", ",", "value", "in", "eval_result", ".", "items", "(", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "value", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "value", ")", ")", "\n", "final_result", "[", "eval_dataset", ".", "args", ".", "task_name", "+", "'_dev_'", "+", "key", "]", "=", "value", "\n", "", "", "", "eval_results", ".", "update", "(", "eval_result", ")", "\n", "\n", "", "", "test_results", "=", "{", "}", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logging", ".", "info", "(", "\"*** Test ***\"", ")", "\n", "test_datasets", "=", "[", "test_dataset", "]", "\n", "if", "data_args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "mnli_mm_data_args", "=", "dataclasses", ".", "replace", "(", "data_args", ",", "task_name", "=", "\"mnli-mm\"", ")", "\n", "test_datasets", ".", "append", "(", "\n", "FewShotDataset", "(", "mnli_mm_data_args", ",", "tokenizer", "=", "tokenizer", ",", "mode", "=", "\"test\"", ",", "use_demo", "=", "(", "'demo'", "in", "model_args", ".", "few_shot_type", ")", ")", "\n", ")", "\n", "\n", "", "for", "test_dataset", "in", "test_datasets", ":", "\n", "            ", "trainer", ".", "compute_metrics", "=", "build_compute_metrics_fn", "(", "test_dataset", ".", "args", ".", "task_name", ")", "\n", "output", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "test_dataset", ")", "\n", "test_result", "=", "output", ".", "metrics", "\n", "\n", "output_test_file", "=", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "f\"test_results_{test_dataset.args.task_name}.txt\"", "\n", ")", "\n", "if", "trainer", ".", "is_world_master", "(", ")", ":", "\n", "                ", "with", "open", "(", "output_test_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                    ", "logger", ".", "info", "(", "\"***** Test results {} *****\"", ".", "format", "(", "test_dataset", ".", "args", ".", "task_name", ")", ")", "\n", "for", "key", ",", "value", "in", "test_result", ".", "items", "(", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "value", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "value", ")", ")", "\n", "final_result", "[", "test_dataset", ".", "args", ".", "task_name", "+", "'_test_'", "+", "key", "]", "=", "value", "\n", "\n", "", "", "if", "training_args", ".", "save_logit", ":", "\n", "                    ", "predictions", "=", "output", ".", "predictions", "\n", "num_logits", "=", "predictions", ".", "shape", "[", "-", "1", "]", "\n", "logits", "=", "predictions", ".", "reshape", "(", "[", "test_dataset", ".", "num_sample", ",", "-", "1", ",", "num_logits", "]", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "save_logit_dir", ",", "\"{}-{}-{}.npy\"", ".", "format", "(", "test_dataset", ".", "task_name", ",", "training_args", ".", "model_id", ",", "training_args", ".", "array_id", ")", ")", ",", "logits", ")", "\n", "\n", "", "", "test_results", ".", "update", "(", "test_result", ")", "\n", "\n", "", "", "with", "FileLock", "(", "'log.lock'", ")", ":", "\n", "        ", "with", "open", "(", "'log'", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "final_result", ".", "update", "(", "vars", "(", "model_args", ")", ")", "\n", "final_result", ".", "update", "(", "vars", "(", "training_args", ")", ")", "\n", "final_result", ".", "update", "(", "vars", "(", "data_args", ")", ")", "\n", "if", "'evaluation_strategy'", "in", "final_result", ":", "\n", "                ", "final_result", ".", "pop", "(", "'evaluation_strategy'", ")", "\n", "", "f", ".", "write", "(", "str", "(", "final_result", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.BertForPromptFinetuning.__init__": [[34, 52], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "transformers.modeling_bert.BertModel", "transformers.modeling_bert.BertOnlyMLMHead", "models.BertForPromptFinetuning.init_weights"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# These attributes should be assigned once the model is initialized", "\n", "self", ".", "model_args", "=", "None", "\n", "self", ".", "data_args", "=", "None", "\n", "self", ".", "label_word_list", "=", "None", "\n", "\n", "# For regression", "\n", "self", ".", "lb", "=", "None", "\n", "self", ".", "ub", "=", "None", "\n", "\n", "# For label search.", "\n", "self", ".", "return_full_softmax", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.BertForPromptFinetuning.mlm_forward": [[53, 74], ["models.BertForPromptFinetuning.bert", "models.BertForPromptFinetuning.cls", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "models.BertForPromptFinetuning.view", "labels.view"], "methods", ["None"], ["", "def", "mlm_forward", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.BertForPromptFinetuning.bff_forward": [[75, 135], ["input_ids.size", "models.BertForPromptFinetuning.bert", "models.BertForPromptFinetuning.cls", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mask_pos.squeeze.squeeze.squeeze", "len", "nn.LogSoftmax.append", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax.", "prediction_mask_scores[].unsqueeze", "torch.KLDivLoss", "torch.KLDivLoss", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "nn.LogSoftmax.view", "nn.LogSoftmax.view", "torch.stack.view", "torch.stack.view", "sequence_output.size", "nn.LogSoftmax.size", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "models.BertForPromptFinetuning.new", "logits[].unsqueeze", "torch.stack.view", "torch.stack.view", "torch.stack.view", "torch.stack.view"], "methods", ["None"], ["", "def", "bff_forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "mask_pos", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "batch_size", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "if", "mask_pos", "is", "not", "None", ":", "\n", "            ", "mask_pos", "=", "mask_pos", ".", "squeeze", "(", ")", "\n", "\n", "# Encode everything", "\n", "", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", "\n", ")", "\n", "\n", "# Get <mask> token representation", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "sequence_mask_output", "=", "sequence_output", "[", "torch", ".", "arange", "(", "sequence_output", ".", "size", "(", "0", ")", ")", ",", "mask_pos", "]", "\n", "\n", "# Logits over vocabulary tokens", "\n", "prediction_mask_scores", "=", "self", ".", "cls", "(", "sequence_mask_output", ")", "\n", "\n", "# Exit early and only return mask logits.", "\n", "if", "self", ".", "return_full_softmax", ":", "\n", "            ", "if", "labels", "is", "not", "None", ":", "\n", "                ", "return", "torch", ".", "zeros", "(", "1", ",", "out", "=", "prediction_mask_scores", ".", "new", "(", ")", ")", ",", "prediction_mask_scores", "\n", "", "return", "prediction_mask_scores", "\n", "\n", "# Return logits for each label", "\n", "", "logits", "=", "[", "]", "\n", "for", "label_id", "in", "range", "(", "len", "(", "self", ".", "label_word_list", ")", ")", ":", "\n", "            ", "logits", ".", "append", "(", "prediction_mask_scores", "[", ":", ",", "self", ".", "label_word_list", "[", "label_id", "]", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "", "logits", "=", "torch", ".", "cat", "(", "logits", ",", "-", "1", ")", "\n", "\n", "# Regression task", "\n", "if", "self", ".", "config", ".", "num_labels", "==", "1", ":", "\n", "            ", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "-", "1", ")", "\n", "logits", "=", "logsoftmax", "(", "logits", ")", "# Log prob of right polarity", "\n", "\n", "", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "# Regression task", "\n", "                ", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "log_target", "=", "True", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "1", "-", "(", "labels", ".", "view", "(", "-", "1", ")", "-", "self", ".", "lb", ")", "/", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", ",", "(", "labels", ".", "view", "(", "-", "1", ")", "-", "self", ".", "lb", ")", "/", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", "]", ",", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "2", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "output", "=", "(", "logits", ",", ")", "\n", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "# Regression output", "\n", "            ", "output", "=", "(", "torch", ".", "exp", "(", "logits", "[", "...", ",", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "*", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", "+", "self", ".", "lb", ",", ")", "\n", "", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.BertForPromptFinetuning.forward": [[136, 157], ["models.BertForPromptFinetuning.mlm_forward", "models.BertForPromptFinetuning.bff_forward"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.mlm_forward", "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.bff_forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "mask_pos", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "mlm", "=", "False", "\n", ")", ":", "\n", "        ", "if", "mlm", ":", "\n", "            ", "return", "self", ".", "mlm_forward", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "bff_forward", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mask_pos", "=", "mask_pos", ",", "\n", "labels", "=", "labels", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.__init__": [[161, 180], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "transformers.modeling_roberta.RobertaModel", "transformers.modeling_roberta.RobertaClassificationHead", "transformers.modeling_roberta.RobertaLMHead", "models.RobertaForPromptFinetuning.init_weights"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# These attributes should be assigned once the model is initialized", "\n", "self", ".", "model_args", "=", "None", "\n", "self", ".", "data_args", "=", "None", "\n", "self", ".", "label_word_list", "=", "None", "\n", "\n", "# For regression", "\n", "self", ".", "lb", "=", "None", "\n", "self", ".", "ub", "=", "None", "\n", "\n", "# For auto label search.", "\n", "self", ".", "return_full_softmax", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.bff_forward": [[181, 239], ["input_ids.size", "models.RobertaForPromptFinetuning.roberta", "models.RobertaForPromptFinetuning.lm_head", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mask_pos.squeeze.squeeze.squeeze", "len", "nn.LogSoftmax.append", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax.", "prediction_mask_scores[].unsqueeze", "torch.KLDivLoss", "torch.KLDivLoss", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "nn.LogSoftmax.view", "nn.LogSoftmax.view", "torch.stack.view", "torch.stack.view", "sequence_output.size", "nn.LogSoftmax.size", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "models.RobertaForPromptFinetuning.new", "logits[].unsqueeze", "torch.stack.view", "torch.stack.view", "torch.stack.view", "torch.stack.view"], "methods", ["None"], ["", "def", "bff_forward", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mask_pos", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "batch_size", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "if", "mask_pos", "is", "not", "None", ":", "\n", "            ", "mask_pos", "=", "mask_pos", ".", "squeeze", "(", ")", "\n", "\n", "# Encode everything", "\n", "", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", "\n", ")", "\n", "\n", "# Get <mask> token representation", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "sequence_mask_output", "=", "sequence_output", "[", "torch", ".", "arange", "(", "sequence_output", ".", "size", "(", "0", ")", ")", ",", "mask_pos", "]", "\n", "\n", "# Logits over vocabulary tokens", "\n", "prediction_mask_scores", "=", "self", ".", "lm_head", "(", "sequence_mask_output", ")", "\n", "\n", "# Exit early and only return mask logits.", "\n", "if", "self", ".", "return_full_softmax", ":", "\n", "            ", "if", "labels", "is", "not", "None", ":", "\n", "                ", "return", "torch", ".", "zeros", "(", "1", ",", "out", "=", "prediction_mask_scores", ".", "new", "(", ")", ")", ",", "prediction_mask_scores", "\n", "", "return", "prediction_mask_scores", "\n", "\n", "# Return logits for each label", "\n", "", "logits", "=", "[", "]", "\n", "for", "label_id", "in", "range", "(", "len", "(", "self", ".", "label_word_list", ")", ")", ":", "\n", "            ", "logits", ".", "append", "(", "prediction_mask_scores", "[", ":", ",", "self", ".", "label_word_list", "[", "label_id", "]", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "", "logits", "=", "torch", ".", "cat", "(", "logits", ",", "-", "1", ")", "\n", "\n", "# Regression task", "\n", "if", "self", ".", "config", ".", "num_labels", "==", "1", ":", "\n", "            ", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "-", "1", ")", "\n", "logits", "=", "logsoftmax", "(", "logits", ")", "# Log prob of right polarity", "\n", "\n", "", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "# Regression task", "\n", "                ", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "log_target", "=", "True", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "1", "-", "(", "labels", ".", "view", "(", "-", "1", ")", "-", "self", ".", "lb", ")", "/", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", ",", "\n", "(", "labels", ".", "view", "(", "-", "1", ")", "-", "self", ".", "lb", ")", "/", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", "]", ",", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "2", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "output", "=", "(", "logits", ",", ")", "\n", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "# Regression output", "\n", "            ", "output", "=", "(", "torch", ".", "exp", "(", "logits", "[", "...", ",", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "*", "(", "self", ".", "ub", "-", "self", ".", "lb", ")", "+", "self", ".", "lb", ",", ")", "\n", "", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.mlm_forward": [[240, 259], ["models.RobertaForPromptFinetuning.roberta", "models.RobertaForPromptFinetuning.lm_head", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "models.RobertaForPromptFinetuning.view", "labels.view"], "methods", ["None"], ["", "def", "mlm_forward", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.forward": [[260, 280], ["models.RobertaForPromptFinetuning.mlm_forward", "models.RobertaForPromptFinetuning.bff_forward"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.mlm_forward", "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.RobertaForPromptFinetuning.bff_forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mask_pos", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "mlm", "=", "False", "\n", ")", ":", "\n", "        ", "if", "mlm", ":", "\n", "            ", "return", "self", ".", "mlm_forward", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "bff_forward", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mask_pos", "=", "mask_pos", ",", "\n", "labels", "=", "labels", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.models.resize_token_type_embeddings": [[13, 30], ["hasattr", "torch.Embedding", "hasattr", "old_token_type_embeddings.weight.size", "old_token_type_embeddings.weight.size"], "function", ["None"], ["def", "resize_token_type_embeddings", "(", "model", ",", "new_num_types", ":", "int", ",", "random_segment", ":", "bool", ")", ":", "\n", "    ", "\"\"\"\n    Resize the segment (token type) embeddings for BERT\n    \"\"\"", "\n", "if", "hasattr", "(", "model", ",", "'bert'", ")", ":", "\n", "        ", "old_token_type_embeddings", "=", "model", ".", "bert", ".", "embeddings", ".", "token_type_embeddings", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "new_token_type_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_types", ",", "old_token_type_embeddings", ".", "weight", ".", "size", "(", "1", ")", ")", "\n", "if", "not", "random_segment", ":", "\n", "        ", "new_token_type_embeddings", ".", "weight", ".", "data", "[", ":", "old_token_type_embeddings", ".", "weight", ".", "size", "(", "0", ")", "]", "=", "old_token_type_embeddings", ".", "weight", ".", "data", "\n", "\n", "", "model", ".", "config", ".", "type_vocab_size", "=", "new_num_types", "\n", "if", "hasattr", "(", "model", ",", "'bert'", ")", ":", "\n", "        ", "model", ".", "bert", ".", "embeddings", ".", "token_type_embeddings", "=", "new_token_type_embeddings", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.__init__": [[148, 271], ["logger.info", "transformers.trainer_utils.set_seed", "transformers.trainer_callback.CallbackHandler", "trainer.Trainer.add_callback", "trainer.Trainer.is_world_process_zero", "transformers.file_utils.is_datasets_available", "transformers.trainer_callback.TrainerState", "transformers.trainer_callback.TrainerControl", "trainer.Trainer.callback_handler.on_init_end", "logger.info", "transformers.training_args.TrainingArguments", "trainer.Trainer.call_model_init", "trainer.Trainer.to", "RuntimeError", "warnings.warn", "kwargs.pop", "trainer.Trainer.remove_callback", "trainer.Trainer.add_callback", "warnings.warn", "kwargs.pop", "os.makedirs", "transformers.file_utils.is_torch_tpu_available", "isinstance", "callable", "warnings.warn", "logger.info", "ValueError", "ValueError", "ValueError", "isinstance", "isinstance", "isinstance", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "TensorBoardCallback", "list", "callable", "getattr", "isinstance", "isinstance", "isinstance", "trainer.Trainer._remove_unused_columns", "trainer.Trainer._remove_unused_columns", "trainer.Trainer._remove_unused_columns", "type", "transformers.modeling_auto.MODEL_FOR_QUESTION_ANSWERING_MAPPING.values", "kwargs.keys"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "Union", "[", "PreTrainedModel", ",", "torch", ".", "nn", ".", "Module", "]", "=", "None", ",", "\n", "args", ":", "TrainingArguments", "=", "None", ",", "\n", "data_collator", ":", "Optional", "[", "DataCollator", "]", "=", "None", ",", "\n", "train_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "unlabeled_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "tokenizer", ":", "Optional", "[", "\"PreTrainedTokenizerBase\"", "]", "=", "None", ",", "\n", "model_init", ":", "Callable", "[", "[", "]", ",", "PreTrainedModel", "]", "=", "None", ",", "\n", "compute_metrics", ":", "Optional", "[", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", "]", "=", "None", ",", "\n", "callbacks", ":", "Optional", "[", "List", "[", "TrainerCallback", "]", "]", "=", "None", ",", "\n", "optimizers", ":", "Tuple", "[", "torch", ".", "optim", ".", "Optimizer", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "]", "=", "(", "None", ",", "None", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "if", "args", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"No `TrainingArguments` passed, using the current path as `output_dir`.\"", ")", "\n", "args", "=", "TrainingArguments", "(", "\"tmp_trainer\"", ")", "\n", "", "self", ".", "args", "=", "args", "\n", "logger", ".", "info", "(", "self", ".", "args", ")", "\n", "# Seed must be set before instantiating the model when using model", "\n", "set_seed", "(", "self", ".", "args", ".", "seed", ")", "\n", "assert", "(", "\n", "model", "is", "not", "None", "or", "model_init", "is", "not", "None", "\n", ")", ",", "\"You must provide a model to use `Trainer`, either by using the `model` argument or the `model_init` argument.\"", "\n", "self", ".", "model_init", "=", "model_init", "\n", "if", "model", "is", "None", "and", "model_init", "is", "not", "None", ":", "\n", "            ", "model", "=", "self", ".", "call_model_init", "(", ")", "\n", "", "self", ".", "model", "=", "model", ".", "to", "(", "args", ".", "device", ")", "if", "model", "is", "not", "None", "else", "None", "\n", "default_collator", "=", "default_data_collator", "\n", "self", ".", "data_collator", "=", "data_collator", "if", "data_collator", "is", "not", "None", "else", "default_collator", "\n", "self", ".", "train_dataset", "=", "train_dataset", "\n", "self", ".", "unlabeled_dataset", "=", "unlabeled_dataset", "\n", "self", ".", "eval_dataset", "=", "eval_dataset", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "prob_list", "=", "[", "]", "\n", "self", ".", "compute_metrics", "=", "compute_metrics", "\n", "self", ".", "optimizer", ",", "self", ".", "lr_scheduler", "=", "optimizers", "\n", "if", "model_init", "is", "not", "None", "and", "(", "self", ".", "optimizer", "is", "not", "None", "or", "self", ".", "lr_scheduler", "is", "not", "None", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Passing a `model_init` is incompatible with providing the `optimizers` argument.\"", "\n", "\"You should subclass `Trainer` and override the `create_optimizer_and_scheduler` method.\"", "\n", ")", "\n", "", "callbacks", "=", "DEFAULT_CALLBACKS", "if", "callbacks", "is", "None", "else", "DEFAULT_CALLBACKS", "+", "callbacks", "\n", "self", ".", "callback_handler", "=", "CallbackHandler", "(", "callbacks", ",", "self", ".", "model", ",", "self", ".", "optimizer", ",", "self", ".", "lr_scheduler", ")", "\n", "self", ".", "add_callback", "(", "PrinterCallback", "if", "self", ".", "args", ".", "disable_tqdm", "else", "DEFAULT_PROGRESS_CALLBACK", ")", "\n", "\n", "# Deprecated arguments", "\n", "if", "\"tb_writer\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Passing `tb_writer` as a keyword argument is deprecated and won't be possible in a \"", "\n", "+", "\"future version. Use `TensorBoardCallback(tb_writer=...)` instead and pass it to the `callbacks`\"", "\n", "+", "\"argument\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "tb_writer", "=", "kwargs", ".", "pop", "(", "\"tb_writer\"", ")", "\n", "self", ".", "remove_callback", "(", "TensorBoardCallback", ")", "\n", "self", ".", "add_callback", "(", "TensorBoardCallback", "(", "tb_writer", "=", "tb_writer", ")", ")", "\n", "", "if", "\"prediction_loss_only\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a \"", "\n", "+", "\"future version. Use `args.prediction_loss_only` instead. Setting \"", "\n", "+", "f\"`args.prediction_loss_only={kwargs['prediction_loss_only']}\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "self", ".", "args", ".", "prediction_loss_only", "=", "kwargs", ".", "pop", "(", "\"prediction_loss_only\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "\n", "# Will be set to True by `self._setup_loggers()` on first call to `self.log()`.", "\n", "self", ".", "_loggers_initialized", "=", "False", "\n", "\n", "# Create output directory if needed", "\n", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "is_torch_tpu_available", "(", ")", "and", "isinstance", "(", "self", ".", "model", ",", "PreTrainedModel", ")", ":", "\n", "# Set an xla_device flag on the model's config.", "\n", "# We'll find a more elegant and not need to do this in the future.", "\n", "            ", "self", ".", "model", ".", "config", ".", "xla_device", "=", "True", "\n", "", "if", "not", "callable", "(", "self", ".", "data_collator", ")", "and", "callable", "(", "getattr", "(", "self", ".", "data_collator", ",", "\"collate_batch\"", ",", "None", ")", ")", ":", "\n", "            ", "self", ".", "data_collator", "=", "self", ".", "data_collator", ".", "collate_batch", "\n", "warnings", ".", "warn", "(", "\n", "(", "\n", "\"The `data_collator` should now be a simple callable (function, class with `__call__`), classes \"", "\n", "+", "\"with a `collate_batch` are deprecated and won't be supported in a future version.\"", "\n", ")", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "\n", "", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"max_steps is given, it will override any value given in num_train_epochs\"", ")", "\n", "\n", "# Enforce rules on using datasets with no __len__", "\n", "", "if", "train_dataset", "is", "not", "None", "and", "not", "isinstance", "(", "train_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", "and", "args", ".", "max_steps", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"train_dataset does not implement __len__, max_steps has to be specified\"", ")", "\n", "", "if", "unlabeled_dataset", "is", "not", "None", "and", "not", "isinstance", "(", "unlabeled_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", "and", "args", ".", "max_steps", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"unlabeled_dataset does not implement __len__, max_steps has to be specified\"", ")", "\n", "", "if", "eval_dataset", "is", "not", "None", "and", "not", "isinstance", "(", "eval_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"eval_dataset must implement __len__\"", ")", "\n", "\n", "", "if", "is_datasets_available", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "train_dataset", ",", "datasets", ".", "Dataset", ")", ":", "\n", "                ", "self", ".", "_remove_unused_columns", "(", "self", ".", "train_dataset", ",", "description", "=", "\"training\"", ")", "\n", "", "if", "isinstance", "(", "unlabeled_dataset", ",", "datasets", ".", "Dataset", ")", ":", "\n", "                ", "self", ".", "_remove_unused_columns", "(", "self", ".", "unlabeled_dataset", ",", "description", "=", "\"self-training\"", ")", "\n", "", "if", "isinstance", "(", "eval_dataset", ",", "datasets", ".", "Dataset", ")", ":", "\n", "                ", "self", ".", "_remove_unused_columns", "(", "self", ".", "eval_dataset", ",", "description", "=", "\"evaluation\"", ")", "\n", "\n", "", "", "self", ".", "state", "=", "TrainerState", "(", ")", "\n", "self", ".", "control", "=", "TrainerControl", "(", ")", "\n", "# Internal variable for total_flos used to count as tensors (for distributed + TPU), will be sent in the", "\n", "# state at each call to self.log.", "\n", "self", ".", "_total_flos", "=", "None", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "            ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "self", ".", "hp_search_backend", "=", "None", "\n", "self", ".", "use_tune_checkpoints", "=", "False", "\n", "default_label_names", "=", "(", "\n", "[", "\"start_positions, end_positions\"", "]", "\n", "if", "type", "(", "self", ".", "model", ")", "in", "MODEL_FOR_QUESTION_ANSWERING_MAPPING", ".", "values", "(", ")", "\n", "else", "[", "\"labels\"", "]", "\n", ")", "\n", "self", ".", "label_names", "=", "default_label_names", "if", "self", ".", "args", ".", "label_names", "is", "None", "else", "self", ".", "args", ".", "label_names", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_init_end", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer._get_unlabeled_sampler": [[272, 282], ["isinstance", "transformers.file_utils.is_torch_tpu_available", "transformers.trainer_pt_utils.get_tpu_sampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler"], "methods", ["None"], ["", "def", "_get_unlabeled_sampler", "(", "self", ")", "->", "Optional", "[", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "Sampler", "]", ":", "\n", "        ", "if", "not", "isinstance", "(", "self", ".", "unlabeled_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", ":", "\n", "            ", "return", "None", "\n", "", "elif", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "return", "get_tpu_sampler", "(", "self", ".", "unlabeled_dataset", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "RandomSampler", "(", "self", ".", "unlabeled_dataset", ")", "\n", "if", "self", ".", "args", ".", "local_rank", "==", "-", "1", "\n", "else", "DistributedSampler", "(", "self", ".", "unlabeled_dataset", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.get_unlabeled_dataloader": [[284, 296], ["trainer.Trainer._get_unlabeled_sampler", "torch.utils.data.dataloader.DataLoader", "torch.utils.data.dataloader.DataLoader", "ValueError", "int"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer._get_unlabeled_sampler"], ["", "", "def", "get_unlabeled_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "if", "self", ".", "unlabeled_dataset", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trainer: self-training requires a unlabeled_dataset.\"", ")", "\n", "", "unlabeled_sampler", "=", "self", ".", "_get_unlabeled_sampler", "(", ")", "\n", "\n", "return", "DataLoader", "(", "\n", "self", ".", "unlabeled_dataset", ",", "\n", "batch_size", "=", "int", "(", "self", ".", "args", ".", "train_batch_size", "*", "self", ".", "args", ".", "mu", ")", ",", "\n", "sampler", "=", "unlabeled_sampler", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ",", "\n", "drop_last", "=", "self", ".", "args", ".", "dataloader_drop_last", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "dataloader_num_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.create_optimizer_and_scheduler": [[298, 345], ["trainer.Trainer.model.named_parameters", "transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "int", "print", "print", "print", "print", "params.items", "params.items", "any", "print", "Exception", "any", "n[].split", "n.find"], "methods", ["None"], ["", "def", "create_optimizer_and_scheduler", "(", "self", ",", "num_training_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Based on Transformers' default one, we add fixing layer option where the bottom n layers' parameters\n        are fixed and only the top layers are further fine-tuned.\n        \"\"\"", "\n", "if", "self", ".", "optimizer", "is", "None", ":", "\n", "            ", "params", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "self", ".", "args", ".", "fix_layers", ">", "0", ":", "\n", "                    ", "if", "'encoder.layer'", "in", "n", ":", "\n", "                        ", "try", ":", "\n", "                            ", "layer_num", "=", "int", "(", "n", "[", "n", ".", "find", "(", "'encoder.layer'", ")", "+", "14", ":", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "                            ", "print", "(", "n", ")", "\n", "raise", "Exception", "(", "\"\"", ")", "\n", "", "if", "layer_num", ">=", "self", ".", "args", ".", "fix_layers", ":", "\n", "                            ", "print", "(", "'yes'", ",", "n", ")", "\n", "params", "[", "n", "]", "=", "p", "\n", "", "else", ":", "\n", "                            ", "print", "(", "'no '", ",", "n", ")", "\n", "", "", "elif", "'embeddings'", "in", "n", ":", "\n", "                        ", "print", "(", "'no '", ",", "n", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'yes'", ",", "n", ")", "\n", "params", "[", "n", "]", "=", "p", "\n", "", "", "else", ":", "\n", "                    ", "params", "[", "n", "]", "=", "p", "\n", "", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "params", ".", "items", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "params", ".", "items", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "self", ".", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "betas", "=", "(", "self", ".", "args", ".", "adam_beta1", ",", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", ")", "\n", "", "if", "self", ".", "lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_training_steps", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.set_mu": [[347, 350], ["int", "len", "len", "len", "len"], "methods", ["None"], ["", "", "def", "set_mu", "(", "self", ")", ":", "\n", "        ", "self", ".", "args", ".", "mu", "=", "int", "(", "len", "(", "self", ".", "unlabeled_dataset", ")", "/", "len", "(", "self", ".", "train_dataset", ")", ")", "\n", "assert", "len", "(", "self", ".", "unlabeled_dataset", ")", "%", "len", "(", "self", ".", "train_dataset", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_st_loss": [[351, 375], ["copy.deepcopy", "utils.mask_tokens", "model", "model", "torch.CrossEntropyLoss().cuda", "torch.CrossEntropyLoss().cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "trainer.Trainer.prob_list.append", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.max", "torch.max", "torch.max", "torch.max", "scores.ge().float", "torch.softmax.mean", "torch.softmax.mean", "len", "trainer.Trainer.prob_list.pop", "torch.softmax.sum", "torch.softmax.sum", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "scores.ge", "torch.CrossEntropyLoss().cuda."], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.utils.mask_tokens"], ["", "def", "compute_st_loss", "(", "self", ",", "model", ",", "unlabeled_inputs", ")", ":", "\n", "        ", "unlabeled_inputs_aug", "=", "copy", ".", "deepcopy", "(", "unlabeled_inputs", ")", "\n", "unlabeled_inputs_aug", "[", "'input_ids'", "]", ",", "_", "=", "mask_tokens", "(", "inputs", "=", "unlabeled_inputs_aug", "[", "'input_ids'", "]", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ")", "\n", "\n", "unlabeled_outputs", "=", "model", "(", "**", "unlabeled_inputs", ")", "\n", "unlabeled_logits", "=", "unlabeled_outputs", "[", "1", "]", "\n", "unlabeled_outputs_aug", "=", "model", "(", "**", "unlabeled_inputs_aug", ")", "\n", "unlabeled_logits_aug", "=", "unlabeled_outputs_aug", "[", "1", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "probs", "=", "torch", ".", "softmax", "(", "unlabeled_logits", ",", "dim", "=", "1", ")", "\n", "self", ".", "prob_list", ".", "append", "(", "probs", ".", "mean", "(", "0", ")", ")", "\n", "if", "len", "(", "self", ".", "prob_list", ")", ">", "32", ":", "\n", "                ", "self", ".", "prob_list", ".", "pop", "(", "0", ")", "\n", "\n", "", "prob_avg", "=", "torch", ".", "stack", "(", "self", ".", "prob_list", ",", "dim", "=", "0", ")", ".", "mean", "(", "0", ")", "\n", "probs", "=", "probs", "/", "prob_avg", "\n", "probs", "=", "probs", "/", "probs", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "scores", ",", "unlabeled_guess", "=", "torch", ".", "max", "(", "probs", ",", "dim", "=", "1", ")", "\n", "mask", "=", "scores", ".", "ge", "(", "self", ".", "args", ".", "threshold", ")", ".", "float", "(", ")", "\n", "", "st_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", ".", "cuda", "(", ")", "\n", "st_loss", "=", "(", "st_loss_fct", "(", "unlabeled_logits_aug", ",", "unlabeled_guess", ")", "*", "mask", ")", ".", "mean", "(", ")", "\n", "return", "st_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_mlm_loss": [[376, 383], ["copy.deepcopy", "utils.mask_tokens", "model"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.utils.mask_tokens"], ["", "def", "compute_mlm_loss", "(", "self", ",", "model", ",", "unlabeled_inputs", ")", ":", "\n", "        ", "unlabeled_inputs_mlm", "=", "copy", ".", "deepcopy", "(", "unlabeled_inputs", ")", "\n", "unlabeled_inputs_mlm", "[", "'input_ids'", "]", ",", "unlabeled_inputs_mlm", "[", "'labels'", "]", "=", "mask_tokens", "(", "inputs", "=", "unlabeled_inputs_mlm", "[", "'input_ids'", "]", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ")", "\n", "mlm_outputs", "=", "model", "(", "**", "unlabeled_inputs_mlm", ",", "mlm", "=", "True", ")", "\n", "mlm_loss", "=", "mlm_outputs", "[", "0", "]", "\n", "return", "mlm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_loss": [[384, 408], ["model", "trainer.Trainer.compute_st_loss", "trainer.Trainer.compute_mlm_loss"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_st_loss", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_mlm_loss"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "labeled_inputs", ",", "unlabeled_inputs", ")", ":", "\n", "        ", "\"\"\"\n        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n\n        Subclass and override for custom behavior.\n        \"\"\"", "\n", "labeled_outputs", "=", "model", "(", "**", "labeled_inputs", ")", "\n", "labeled_loss", "=", "labeled_outputs", "[", "0", "]", "\n", "if", "self", ".", "args", ".", "use_st_loss", ":", "\n", "            ", "st_loss", "=", "self", ".", "compute_st_loss", "(", "model", ",", "unlabeled_inputs", ")", "\n", "", "if", "self", ".", "args", ".", "use_mlm_loss", ":", "\n", "            ", "mlm_loss", "=", "self", ".", "compute_mlm_loss", "(", "model", ",", "unlabeled_inputs", ")", "\n", "\n", "# Save past state if it exists", "\n", "", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "            ", "self", ".", "_past", "=", "labeled_outputs", "[", "self", ".", "args", ".", "past_index", "]", "\n", "# We don't use .loss here since the model may return tuples instead of ModelOutput.", "\n", "\n", "", "loss", "=", "labeled_loss", "\n", "if", "self", ".", "args", ".", "use_st_loss", ":", "\n", "            ", "loss", "=", "loss", "+", "self", ".", "args", ".", "lam1", "*", "st_loss", "\n", "", "if", "self", ".", "args", ".", "use_mlm_loss", ":", "\n", "            ", "loss", "=", "loss", "+", "self", ".", "args", ".", "lam2", "*", "mlm_loss", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.training_step": [[409, 453], ["model.train", "trainer.Trainer._prepare_inputs", "trainer.Trainer._prepare_inputs", "trainer.Trainer.detach", "trainer.Trainer.compute_loss", "trainer.Trainer.mean", "trainer.Trainer.scaler.scale().backward", "autocast", "trainer.Trainer.compute_loss", "trainer.Trainer.backward", "trainer.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.train", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_loss", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.compute_loss"], ["", "def", "training_step", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "labeled_inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ",", "unlabeled_inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Perform a training step on a batch of inputs.\n\n        Subclass and override to inject custom behavior.\n\n        Args:\n            model (:obj:`nn.Module`):\n                The model to train.\n            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n                The inputs and targets of the model.\n\n                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n\n        Return:\n            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n        \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "labeled_inputs", "=", "self", ".", "_prepare_inputs", "(", "labeled_inputs", ")", "\n", "unlabeled_inputs", "=", "self", ".", "_prepare_inputs", "(", "unlabeled_inputs", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "            ", "with", "autocast", "(", ")", ":", "\n", "                ", "loss", "=", "self", ".", "compute_loss", "(", "model", ",", "labeled_inputs", ",", "unlabeled_inputs", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "compute_loss", "(", "model", ",", "labeled_inputs", ",", "unlabeled_inputs", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "            ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "return", "loss", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.train": [[454, 683], ["trainer.Trainer.get_train_dataloader", "trainer.Trainer.set_mu", "logger.info", "trainer.Trainer.get_unlabeled_dataloader", "trainer.Trainer.create_optimizer_and_scheduler", "transformers.is_torch_tpu_available", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.parallel.DistributedDataParallel.zero_grad", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.trange", "logger.info", "float", "len", "int", "os.path.isfile", "os.path.isfile", "optimizer.load_state_dict", "scheduler.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "trainer.Trainer.num_examples", "int", "transformers.is_torch_tpu_available", "enumerate", "hasattr", "delattr", "transformers.trainer_utils.TrainOutput", "int", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "os.path.join", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "transformers.is_apex_available", "ImportError", "xm.xrt_world_size", "int", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "isinstance", "isinstance", "trainer.Trainer.sampler.set_epoch", "trainer.Trainer.sampler.set_epoch", "pl.ParallelLoader().per_device_loader", "tqdm.tqdm.tqdm", "pl.ParallelLoader().per_device_loader", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "zip", "trainer.Trainer.training_step", "tqdm.tqdm.trange.close", "xm.master_print", "os.path.join", "os.path.join", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "logger.info", "trainer.Trainer.is_local_master", "transformers.is_torch_tpu_available", "scheduler.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.tqdm.close", "tqdm.tqdm.tqdm.close", "met.metrics_report", "len", "[].split", "len", "len", "pl.ParallelLoader", "pl.ParallelLoader", "trainer.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "xm.optimizer_step", "torch.tensor().to.item", "torch.tensor().to.item", "torch.nn.utils.clip_grad_norm_.item", "torch.nn.utils.clip_grad_norm_.item", "trainer.Trainer.log", "trainer.Trainer.evaluate", "trainer.Trainer.dev_objective", "trainer.Trainer.is_local_master", "trainer.Trainer.is_local_master", "len", "len", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "trainer.Trainer.scaler.step", "trainer.Trainer.scaler.update", "optimizer.step", "len", "logger.info", "trainer.Trainer.save_model", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.parallel.DistributedDataParallel.parameters", "packaging.version.parse", "packaging.version.parse", "scheduler.get_last_lr", "scheduler.get_lr", "model_path.split"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.set_mu", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.get_unlabeled_dataloader", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.create_optimizer_and_scheduler", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.training_step", "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.evaluate"], ["", "def", "train", "(", "self", ",", "model_path", "=", "None", ",", "dev_objective", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Main training entry point.\n\n        The training logic is directly borrowed from transformers.Trainer (version 3.0.2).\n        Add early stopping.\n        \"\"\"", "\n", "self", ".", "best_dir", "=", "None", "\n", "self", ".", "prob_list", "=", "[", "]", "\n", "self", ".", "objective", "=", "-", "float", "(", "\"inf\"", ")", "\n", "self", ".", "dev_objective", "=", "dev_objective", "if", "dev_objective", "is", "not", "None", "else", "default_dev_objective", "\n", "\n", "# Data loading.", "\n", "train_dataloader", "=", "self", ".", "get_train_dataloader", "(", ")", "\n", "num_update_steps_per_epoch", "=", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "if", "num_update_steps_per_epoch", "==", "0", ":", "\n", "            ", "num_update_steps_per_epoch", "=", "1", "\n", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", ":", "\n", "            ", "t_total", "=", "self", ".", "args", ".", "max_steps", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "max_steps", "//", "num_update_steps_per_epoch", "+", "int", "(", "\n", "self", ".", "args", ".", "max_steps", "%", "num_update_steps_per_epoch", ">", "0", "\n", ")", "\n", "", "else", ":", "\n", "            ", "t_total", "=", "int", "(", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "*", "self", ".", "args", ".", "num_train_epochs", ")", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "num_train_epochs", "\n", "# Load unlabeled data", "\n", "", "self", ".", "set_mu", "(", ")", "\n", "logger", ".", "info", "(", "self", ".", "args", ".", "mu", ")", "\n", "total_train_batch_size", "=", "(", "\n", "self", ".", "args", ".", "train_batch_size", "\n", "*", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", "unlabeled_dataloader", "=", "self", ".", "get_unlabeled_dataloader", "(", ")", "\n", "\n", "# set optimizer and scheduler", "\n", "self", ".", "create_optimizer_and_scheduler", "(", "num_training_steps", "=", "t_total", ")", "\n", "optimizer", "=", "self", ".", "optimizer", "\n", "scheduler", "=", "self", ".", "lr_scheduler", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "model_path", "is", "not", "None", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"optimizer.pt\"", ")", ",", "map_location", "=", "self", ".", "args", ".", "device", ")", "\n", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "model", "=", "self", ".", "model", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "            ", "if", "not", "transformers", ".", "is_apex_available", "(", ")", ":", "\n", "                ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "self", ".", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "self", ".", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "self", ".", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "self", ".", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train", "\n", "", "if", "transformers", ".", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "total_train_batch_size", "=", "self", ".", "args", ".", "train_batch_size", "*", "xm", ".", "xrt_world_size", "(", ")", "\n", "", "else", ":", "\n", "            ", "total_train_batch_size", "=", "(", "\n", "self", ".", "args", ".", "train_batch_size", "\n", "*", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "self", ".", "num_examples", "(", "train_dataloader", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per device = %d\"", ",", "self", ".", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "total_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "self", ".", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "model_path", "is", "not", "None", ":", "\n", "# set global_step to global_step of last saved checkpoint from model path", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "global_step", "=", "int", "(", "model_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "epochs_trained", "=", "self", ".", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "self", ".", "global_step", "%", "(", "\n", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "self", ".", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "self", ".", "global_step", "=", "0", "\n", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "logging_loss_scalar", "=", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "not", "self", ".", "is_local_master", "(", ")", "\n", ")", "\n", "for", "epoch", "in", "train_iterator", ":", "\n", "            ", "if", "isinstance", "(", "train_dataloader", ",", "DataLoader", ")", "and", "isinstance", "(", "train_dataloader", ".", "sampler", ",", "DistributedSampler", ")", ":", "\n", "                ", "train_dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "unlabeled_dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "", "if", "transformers", ".", "is_torch_tpu_available", "(", ")", ":", "\n", "                ", "labeled_parallel_loader", "=", "pl", ".", "ParallelLoader", "(", "train_dataloader", ",", "[", "self", ".", "args", ".", "device", "]", ")", ".", "per_device_loader", "(", "\n", "self", ".", "args", ".", "device", "\n", ")", "\n", "labeled_epoch_iterator", "=", "tqdm", "(", "labeled_parallel_loader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "not", "self", ".", "is_local_master", "(", ")", ")", "\n", "# add unlabled iterator", "\n", "unlabeled_parallel_loader", "=", "pl", ".", "ParallelLoader", "(", "unlabeled_dataloader", ",", "[", "self", ".", "args", ".", "device", "]", ")", ".", "per_device_loader", "(", "\n", "self", ".", "args", ".", "device", "\n", ")", "\n", "unlabeled_epoch_iterator", "=", "tqdm", "(", "unlabeled_parallel_loader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "not", "self", ".", "is_local_master", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "labeled_epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "True", ")", "\n", "unlabeled_epoch_iterator", "=", "tqdm", "(", "unlabeled_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "True", ")", "\n", "\n", "# Reset the past mems state at the beginning of each epoch if necessary.", "\n", "", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "                ", "self", ".", "_past", "=", "None", "\n", "\n", "", "for", "step", ",", "(", "labeled_inputs", ",", "unlabeled_inputs", ")", "in", "enumerate", "(", "zip", "(", "labeled_epoch_iterator", ",", "unlabeled_epoch_iterator", ")", ")", ":", "\n", "# for step, labeled_inputs in enumerate(labeled_epoch_iterator):", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "                ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                    ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "tr_loss", "+=", "self", ".", "training_step", "(", "model", ",", "labeled_inputs", ",", "unlabeled_inputs", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "(", "\n", "# last step in epoch but step is always smaller than gradient_accumulation_steps", "\n", "len", "(", "labeled_epoch_iterator", ")", "<=", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "and", "(", "step", "+", "1", ")", "==", "len", "(", "labeled_epoch_iterator", ")", "\n", ")", ":", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "unscale_", "(", "optimizer", ")", "\n", "norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", ":", "\n", "                        ", "norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                        ", "norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "if", "transformers", ".", "is_torch_tpu_available", "(", ")", ":", "\n", "                        ", "xm", ".", "optimizer_step", "(", "optimizer", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "optimizer", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "self", ".", "global_step", "+=", "1", "\n", "self", ".", "epoch", "=", "epoch", "+", "(", "step", "+", "1", ")", "/", "len", "(", "labeled_epoch_iterator", ")", "\n", "\n", "if", "(", "self", ".", "args", ".", "logging_steps", ">", "0", "and", "self", ".", "global_step", "%", "self", ".", "args", ".", "logging_steps", "==", "0", ")", "or", "(", "\n", "self", ".", "global_step", "==", "1", "and", "self", ".", "args", ".", "logging_first_step", "\n", ")", ":", "\n", "                        ", "logs", "=", "{", "}", "\n", "tr_loss_scalar", "=", "tr_loss", ".", "item", "(", ")", "\n", "logs", "[", "\"loss\"", "]", "=", "(", "tr_loss_scalar", "-", "logging_loss_scalar", ")", "/", "self", ".", "args", ".", "logging_steps", "\n", "logs", "[", "\"norm\"", "]", "=", "norm", ".", "item", "(", ")", "\n", "# backward compatibility for pytorch schedulers", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "(", "\n", "scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", "\n", "else", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", ")", "\n", "logging_loss_scalar", "=", "tr_loss_scalar", "\n", "\n", "self", ".", "log", "(", "logs", ")", "\n", "\n", "# ----------------------------------------------------------------------", "\n", "# BEGIN CHANGES.", "\n", "# ----------------------------------------------------------------------", "\n", "\n", "", "metrics", "=", "None", "\n", "if", "self", ".", "args", ".", "evaluate_during_training", "and", "self", ".", "global_step", "%", "self", ".", "args", ".", "eval_steps", "==", "0", ":", "\n", "                        ", "output", "=", "self", ".", "evaluate", "(", ")", "\n", "metrics", "=", "output", ".", "metrics", "\n", "objective", "=", "self", ".", "dev_objective", "(", "metrics", ")", "\n", "if", "objective", ">", "self", ".", "objective", ":", "\n", "                            ", "logger", ".", "info", "(", "\"Best dev result: {}\"", ".", "format", "(", "objective", ")", ")", "\n", "self", ".", "objective", "=", "objective", "\n", "self", ".", "save_model", "(", "self", ".", "args", ".", "output_dir", ")", "\n", "\n", "# ----------------------------------------------------------------------", "\n", "# END CHANGES.", "\n", "# ----------------------------------------------------------------------", "\n", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">", "self", ".", "args", ".", "max_steps", ":", "\n", "                    ", "labeled_epoch_iterator", ".", "close", "(", ")", "\n", "unlabeled_epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">", "self", ".", "args", ".", "max_steps", ":", "\n", "                ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "if", "self", ".", "args", ".", "tpu_metrics_debug", "or", "self", ".", "args", ".", "debug", ":", "\n", "# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)", "\n", "                ", "xm", ".", "master_print", "(", "met", ".", "metrics_report", "(", ")", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "past_index", "and", "hasattr", "(", "self", ",", "\"_past\"", ")", ":", "\n", "# Clean the state at the end of training", "\n", "            ", "delattr", "(", "self", ",", "\"_past\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\"", ")", "\n", "return", "TrainOutput", "(", "self", ".", "global_step", ",", "tr_loss", "/", "self", ".", "global_step", ")", ",", "self", ".", "objective", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.Trainer.evaluate": [[688, 720], ["trainer.Trainer.get_eval_dataloader", "trainer.Trainer.prediction_loop", "trainer.Trainer.log", "ValueError", "xm.master_print", "isinstance", "met.metrics_report"], "methods", ["None"], ["def", "evaluate", "(", "self", ",", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Run evaluation and returns metrics.\n\n        The calling script will be responsible for providing a method to compute metrics, as they are\n        task-dependent (pass it to the init :obj:`compute_metrics` argument).\n\n        You can also subclass and override this method to inject custom behavior.\n\n        Args:\n            eval_dataset (:obj:`Dataset`, `optional`):\n                Pass a dataset if you wish to override :obj:`self.eval_dataset`. If it is an :obj:`datasets.Dataset`,\n                columns not accepted by the ``model.forward()`` method are automatically removed. It must implement\n                the :obj:`__len__` method.\n\n        Returns:\n            A dictionary containing the evaluation loss and the potential metrics computed from the predictions.\n        \"\"\"", "\n", "if", "eval_dataset", "is", "not", "None", "and", "not", "isinstance", "(", "eval_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"eval_dataset must implement __len__\"", ")", "\n", "\n", "", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "eval_dataset", ")", "\n", "\n", "output", "=", "self", ".", "prediction_loop", "(", "eval_dataloader", ",", "description", "=", "\"Evaluation\"", ")", "\n", "\n", "self", ".", "log", "(", "output", ".", "metrics", ")", "\n", "\n", "if", "self", ".", "args", ".", "tpu_metrics_debug", "or", "self", ".", "args", ".", "debug", ":", "\n", "# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)", "\n", "            ", "xm", ".", "master_print", "(", "met", ".", "metrics_report", "(", ")", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.trainer.default_dev_objective": [[123, 141], ["Exception"], "function", ["None"], ["def", "default_dev_objective", "(", "metrics", ")", ":", "\n", "    ", "\"\"\"\n    Objective used for picking the best model on development sets\n    \"\"\"", "\n", "if", "\"eval_mnli/acc\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_mnli/acc\"", "]", "\n", "", "elif", "\"eval_mnli-mm/acc\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "", "elif", "\"eval_f1\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_f1\"", "]", "\n", "", "elif", "\"eval_mcc\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_mcc\"", "]", "\n", "", "elif", "\"eval_pearson\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_pearson\"", "]", "\n", "", "elif", "\"eval_acc\"", "in", "metrics", ":", "\n", "        ", "return", "metrics", "[", "\"eval_acc\"", "]", "\n", "\n", "", "raise", "Exception", "(", "\"No metric founded for {}\"", ".", "format", "(", "metrics", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.OurInputFeatures.to_json_string": [[39, 42], ["json.dumps", "dataclasses.asdict"], "methods", ["None"], ["def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "dataclasses", ".", "asdict", "(", "self", ")", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.__init__": [[262, 472], ["dataset.FewShotDataset.processor.get_labels", "len", "logger.info", "os.path.join", "logger.info", "list", "range", "logger.info", "eval", "logger.info", "len", "filelock.FileLock", "numpy.load", "numpy.load", "logger.info", "len", "range", "range", "logger.info", "len", "str", "os.path.exists", "time.time", "torch.load", "logger.info", "logger.info", "dataset.FewShotDataset.processor.get_train_examples", "time.time", "torch.save", "logger.info", "os.path.join", "os.path.join", "len", "len", "len", "len", "len", "len", "dataset.FewShotDataset.example_idx.append", "dataset.FewShotDataset.select_context", "dataset.FewShotDataset.features.append", "tokenizer._convert_token_to_id", "tokenizer._convert_token_to_id", "dataset.FewShotDataset.processor.get_dev_examples", "os.path.join", "sim_score.sort", "dataset.FewShotDataset.convert_fn", "len", "tokenizer._convert_id_to_token", "len", "len", "time.time", "dataset.FewShotDataset.processor.get_test_examples", "time.time", "sim_score.append", "int", "int", "tokenizer.tokenize", "tokenizer.tokenize", "dataset.FewShotDataset.processor.get_unlabeled_examples", "print", "print", "sentence_transformers.util.pytorch_cos_sim", "context_indices.append", "context_indices.append", "len", "len", "print", "len", "print", "float", "float"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_labels", "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_train_examples", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.select_context", "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_dev_examples", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.convert_fn", "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_test_examples", "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_unlabeled_examples"], ["def", "__init__", "(", "self", ",", "args", ",", "tokenizer", ",", "cache_dir", "=", "None", ",", "mode", "=", "\"train\"", ",", "use_demo", "=", "False", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "task_name", "=", "args", ".", "task_name", "\n", "self", ".", "processor", "=", "processors_mapping", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# If not using demonstrations, use use_demo=True", "\n", "self", ".", "use_demo", "=", "use_demo", "\n", "if", "self", ".", "use_demo", ":", "\n", "            ", "logger", ".", "info", "(", "\"Use demonstrations\"", ")", "\n", "", "assert", "mode", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", ",", "\"unlabeled\"", "]", "\n", "\n", "# Get label list and (for prompt) label word list", "\n", "self", ".", "label_list", "=", "self", ".", "processor", ".", "get_labels", "(", ")", "\n", "self", ".", "num_labels", "=", "len", "(", "self", ".", "label_list", ")", "\n", "if", "args", ".", "prompt", ":", "\n", "            ", "assert", "args", ".", "mapping", "is", "not", "None", "\n", "self", ".", "label_to_word", "=", "eval", "(", "args", ".", "mapping", ")", "\n", "\n", "for", "key", "in", "self", ".", "label_to_word", ":", "\n", "# For RoBERTa/BART/T5, tokenization also considers space, so we use space+word as label words.", "\n", "                ", "if", "self", ".", "label_to_word", "[", "key", "]", "[", "0", "]", "not", "in", "[", "'<'", ",", "'['", ",", "'.'", ",", "','", "]", ":", "\n", "# Make sure space+word is in the vocabulary", "\n", "                    ", "assert", "len", "(", "tokenizer", ".", "tokenize", "(", "' '", "+", "self", ".", "label_to_word", "[", "key", "]", ")", ")", "==", "1", "\n", "self", ".", "label_to_word", "[", "key", "]", "=", "tokenizer", ".", "_convert_token_to_id", "(", "tokenizer", ".", "tokenize", "(", "' '", "+", "self", ".", "label_to_word", "[", "key", "]", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "label_to_word", "[", "key", "]", "=", "tokenizer", ".", "_convert_token_to_id", "(", "self", ".", "label_to_word", "[", "key", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Label {} to word {} ({})\"", ".", "format", "(", "key", ",", "tokenizer", ".", "_convert_id_to_token", "(", "self", ".", "label_to_word", "[", "key", "]", ")", ",", "self", ".", "label_to_word", "[", "key", "]", ")", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "label_list", ")", ">", "1", ":", "\n", "                ", "self", ".", "label_word_list", "=", "[", "self", ".", "label_to_word", "[", "label", "]", "for", "label", "in", "self", ".", "label_list", "]", "\n", "", "else", ":", "\n", "# Regression task", "\n", "# '0' represents low polarity and '1' represents high polarity.", "\n", "                ", "self", ".", "label_word_list", "=", "[", "self", ".", "label_to_word", "[", "label", "]", "for", "label", "in", "[", "'0'", ",", "'1'", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "label_to_word", "=", "None", "\n", "self", ".", "label_word_list", "=", "None", "\n", "\n", "# Multiple sampling: when using demonstrations, we sample different combinations of demonstrations during ", "\n", "# inference and aggregate the results by averaging the logits. The number of different samples is num_sample.", "\n", "", "if", "(", "mode", "in", "[", "\"train\"", ",", "\"unlabeled\"", "]", ")", "or", "not", "self", ".", "use_demo", ":", "\n", "# We do not do multiple sampling when not using demonstrations or when it's the training mode ", "\n", "            ", "self", ".", "num_sample", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_sample", "=", "args", ".", "num_sample", "\n", "\n", "# If we use multiple templates, we also need to do multiple sampling during inference.", "\n", "", "if", "args", ".", "prompt", "and", "args", ".", "template_list", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"There are %d templates. Multiply num_sample by %d\"", "%", "(", "len", "(", "args", ".", "template_list", ")", ",", "len", "(", "args", ".", "template_list", ")", ")", ")", "\n", "self", ".", "num_sample", "*=", "len", "(", "args", ".", "template_list", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Total num_sample for mode %s: %d\"", "%", "(", "mode", ",", "self", ".", "num_sample", ")", ")", "\n", "\n", "# Load cache", "\n", "# Cache name distinguishes mode, task name, tokenizer, and length. So if you change anything beyond these elements, make sure to clear your cache.", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "cache_dir", "if", "cache_dir", "is", "not", "None", "else", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "\n", "tokenizer", ".", "__class__", ".", "__name__", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "args", ".", "task_name", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Creating/loading examples from dataset file at {args.data_dir}\"", ")", "\n", "\n", "lock_path", "=", "cached_features_file", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "                ", "start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "support_examples", ",", "self", ".", "query_examples", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "logger", ".", "info", "(", "\n", "f\"Loading features from cached file {cached_features_file} [took %.3f s]\"", ",", "time", ".", "time", "(", ")", "-", "start", "\n", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "f\"Creating features from dataset file at {args.data_dir}\"", ")", "\n", "\n", "# The support examples are sourced from the training set.", "\n", "self", ".", "support_examples", "=", "self", ".", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "if", "mode", "==", "\"dev\"", ":", "\n", "                    ", "self", ".", "query_examples", "=", "self", ".", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "                    ", "self", ".", "query_examples", "=", "self", ".", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"unlabeled\"", ":", "\n", "                    ", "self", ".", "query_examples", "=", "self", ".", "processor", ".", "get_unlabeled_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "query_examples", "=", "self", ".", "support_examples", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "torch", ".", "save", "(", "[", "self", ".", "support_examples", ",", "self", ".", "query_examples", "]", ",", "cached_features_file", ")", "\n", "# ^ This seems to take a lot of time so I want to investigate why and how we can improve.", "\n", "logger", ".", "info", "(", "\n", "\"Saving features into cached file %s [took %.3f s]\"", ",", "cached_features_file", ",", "time", ".", "time", "(", ")", "-", "start", "\n", ")", "\n", "\n", "# For filtering in using demonstrations, load pre-calculated embeddings", "\n", "", "", "if", "self", ".", "use_demo", "and", "args", ".", "demo_filter", ":", "\n", "            ", "split_name", "=", "''", "\n", "if", "mode", "==", "'train'", ":", "\n", "                ", "split_name", "=", "'train'", "\n", "", "elif", "mode", "==", "'dev'", ":", "\n", "                ", "if", "args", ".", "task_name", "==", "'mnli'", ":", "\n", "                    ", "split_name", "=", "'dev_matched'", "\n", "", "elif", "args", ".", "task_name", "==", "'mnli-mm'", ":", "\n", "                    ", "split_name", "=", "'dev_mismatched'", "\n", "", "else", ":", "\n", "                    ", "split_name", "=", "'dev'", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "                ", "if", "args", ".", "task_name", "==", "'mnli'", ":", "\n", "                    ", "split_name", "=", "'test_matched'", "\n", "", "elif", "args", ".", "task_name", "==", "'mnli-mm'", ":", "\n", "                    ", "split_name", "=", "'test_mismatched'", "\n", "", "else", ":", "\n", "                    ", "split_name", "=", "'test'", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "support_emb", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train_{}.npy\"", ".", "format", "(", "args", ".", "demo_filter_model", ")", ")", ")", "\n", "self", ".", "query_emb", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"{}_{}.npy\"", ".", "format", "(", "split_name", ",", "args", ".", "demo_filter_model", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Load embeddings (for demonstration filtering) from {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"{}_{}.npy\"", ".", "format", "(", "split_name", ",", "args", ".", "demo_filter_model", ")", ")", ")", ")", "\n", "\n", "assert", "len", "(", "self", ".", "support_emb", ")", "==", "len", "(", "self", ".", "support_examples", ")", "\n", "assert", "len", "(", "self", ".", "query_emb", ")", "==", "len", "(", "self", ".", "query_examples", ")", "\n", "\n", "# Size is expanded by num_sample", "\n", "", "self", ".", "size", "=", "len", "(", "self", ".", "query_examples", ")", "*", "self", ".", "num_sample", "\n", "\n", "# Prepare examples (especially for using demonstrations)", "\n", "support_indices", "=", "list", "(", "range", "(", "len", "(", "self", ".", "support_examples", ")", ")", ")", "\n", "self", ".", "example_idx", "=", "[", "]", "\n", "for", "sample_idx", "in", "range", "(", "self", ".", "num_sample", ")", ":", "\n", "            ", "for", "query_idx", "in", "range", "(", "len", "(", "self", ".", "query_examples", ")", ")", ":", "\n", "# If training, exclude the current example. Else keep all.", "\n", "                ", "if", "self", ".", "use_demo", "and", "args", ".", "demo_filter", ":", "\n", "# Demonstration filtering", "\n", "                    ", "candidate", "=", "[", "support_idx", "for", "support_idx", "in", "support_indices", "\n", "if", "support_idx", "!=", "query_idx", "or", "mode", "!=", "\"train\"", "]", "\n", "sim_score", "=", "[", "]", "\n", "for", "support_idx", "in", "candidate", ":", "\n", "                        ", "sim_score", ".", "append", "(", "(", "support_idx", ",", "util", ".", "pytorch_cos_sim", "(", "self", ".", "support_emb", "[", "support_idx", "]", ",", "self", ".", "query_emb", "[", "query_idx", "]", ")", ")", ")", "\n", "", "sim_score", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "# Regression task", "\n", "                        ", "limit_each_label", "=", "int", "(", "len", "(", "sim_score", ")", "//", "2", "*", "args", ".", "demo_filter_rate", ")", "\n", "count_each_label", "=", "{", "'0'", ":", "0", ",", "'1'", ":", "0", "}", "\n", "context_indices", "=", "[", "]", "\n", "\n", "if", "args", ".", "debug_mode", ":", "\n", "                            ", "print", "(", "\"Query %s: %s\"", "%", "(", "self", ".", "query_examples", "[", "query_idx", "]", ".", "label", ",", "self", ".", "query_examples", "[", "query_idx", "]", ".", "text_a", ")", ")", "# debug", "\n", "", "for", "support_idx", ",", "score", "in", "sim_score", ":", "\n", "                            ", "if", "count_each_label", "[", "'0'", "if", "float", "(", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", ")", "<=", "median_mapping", "[", "args", ".", "task_name", "]", "else", "'1'", "]", "<", "limit_each_label", ":", "\n", "                                ", "count_each_label", "[", "'0'", "if", "float", "(", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", ")", "<=", "median_mapping", "[", "args", ".", "task_name", "]", "else", "'1'", "]", "+=", "1", "\n", "context_indices", ".", "append", "(", "support_idx", ")", "\n", "if", "args", ".", "debug_mode", ":", "\n", "                                    ", "print", "(", "\"    %.4f %s | %s\"", "%", "(", "score", ",", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", ",", "self", ".", "support_examples", "[", "support_idx", "]", ".", "text_a", ")", ")", "# debug", "\n", "", "", "", "", "else", ":", "\n", "                        ", "limit_each_label", "=", "int", "(", "len", "(", "sim_score", ")", "//", "self", ".", "num_labels", "*", "args", ".", "demo_filter_rate", ")", "\n", "count_each_label", "=", "{", "label", ":", "0", "for", "label", "in", "self", ".", "label_list", "}", "\n", "context_indices", "=", "[", "]", "\n", "\n", "if", "args", ".", "debug_mode", ":", "\n", "                            ", "print", "(", "\"Query %s: %s\"", "%", "(", "self", ".", "query_examples", "[", "query_idx", "]", ".", "label", ",", "self", ".", "query_examples", "[", "query_idx", "]", ".", "text_a", ")", ")", "# debug", "\n", "", "for", "support_idx", ",", "score", "in", "sim_score", ":", "\n", "                            ", "if", "count_each_label", "[", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", "]", "<", "limit_each_label", ":", "\n", "                                ", "count_each_label", "[", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", "]", "+=", "1", "\n", "context_indices", ".", "append", "(", "support_idx", ")", "\n", "if", "args", ".", "debug_mode", ":", "\n", "                                    ", "print", "(", "\"    %.4f %s | %s\"", "%", "(", "score", ",", "self", ".", "support_examples", "[", "support_idx", "]", ".", "label", ",", "self", ".", "support_examples", "[", "support_idx", "]", ".", "text_a", ")", ")", "# debug", "\n", "", "", "", "", "", "else", ":", "\n", "# Using demonstrations without filtering", "\n", "                    ", "context_indices", "=", "[", "support_idx", "for", "support_idx", "in", "support_indices", "\n", "if", "support_idx", "!=", "query_idx", "or", "mode", "!=", "\"train\"", "]", "\n", "\n", "# We'll subsample context_indices further later.", "\n", "", "self", ".", "example_idx", ".", "append", "(", "(", "query_idx", ",", "context_indices", ",", "sample_idx", ")", ")", "\n", "\n", "# If it is not training, we pre-process the data; otherwise, we process the data online.", "\n", "", "", "if", "mode", "not", "in", "[", "\"train\"", ",", "\"unlabeled\"", "]", ":", "\n", "            ", "self", ".", "features", "=", "[", "]", "\n", "_", "=", "0", "\n", "for", "query_idx", ",", "context_indices", ",", "bootstrap_idx", "in", "self", ".", "example_idx", ":", "\n", "# The input (query) example", "\n", "                ", "example", "=", "self", ".", "query_examples", "[", "query_idx", "]", "\n", "# The demonstrations", "\n", "supports", "=", "self", ".", "select_context", "(", "[", "self", ".", "support_examples", "[", "i", "]", "for", "i", "in", "context_indices", "]", ")", "\n", "\n", "if", "args", ".", "template_list", "is", "not", "None", ":", "\n", "                    ", "template", "=", "args", ".", "template_list", "[", "sample_idx", "%", "len", "(", "args", ".", "template_list", ")", "]", "# Use template in order", "\n", "", "else", ":", "\n", "                    ", "template", "=", "args", ".", "template", "\n", "\n", "", "self", ".", "features", ".", "append", "(", "self", ".", "convert_fn", "(", "\n", "example", "=", "example", ",", "\n", "supports", "=", "supports", ",", "\n", "use_demo", "=", "self", ".", "use_demo", ",", "\n", "label_list", "=", "self", ".", "label_list", ",", "\n", "prompt", "=", "args", ".", "prompt", ",", "\n", "template", "=", "template", ",", "\n", "label_word_list", "=", "self", ".", "label_word_list", ",", "\n", "verbose", "=", "True", "if", "_", "==", "0", "else", "False", ",", "\n", ")", ")", "\n", "\n", "_", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "features", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.select_context": [[473, 507], ["len", "numpy.random.permutation", "range", "numpy.random.permutation", "len", "min", "selection.append", "len", "len", "len", "len", "selection.append", "sum", "counts.values", "len", "float"], "methods", ["None"], ["", "", "def", "select_context", "(", "self", ",", "context_examples", ")", ":", "\n", "        ", "\"\"\"\n        Select demonstrations from provided examples.\n        \"\"\"", "\n", "max_demo_per_label", "=", "1", "\n", "counts", "=", "{", "k", ":", "0", "for", "k", "in", "self", ".", "label_list", "}", "\n", "if", "len", "(", "self", ".", "label_list", ")", "==", "1", ":", "\n", "# Regression", "\n", "            ", "counts", "=", "{", "'0'", ":", "0", ",", "'1'", ":", "0", "}", "\n", "", "selection", "=", "[", "]", "\n", "\n", "if", "self", ".", "args", ".", "gpt3_in_context_head", "or", "self", ".", "args", ".", "gpt3_in_context_tail", ":", "\n", "# For GPT-3's in-context learning, we sample gpt3_in_context_num demonstrations randomly. ", "\n", "            ", "order", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "context_examples", ")", ")", "\n", "for", "i", "in", "range", "(", "min", "(", "self", ".", "args", ".", "gpt3_in_context_num", ",", "len", "(", "order", ")", ")", ")", ":", "\n", "                ", "selection", ".", "append", "(", "context_examples", "[", "order", "[", "i", "]", "]", ")", "\n", "", "", "else", ":", "\n", "# Our sampling strategy", "\n", "            ", "order", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "context_examples", ")", ")", "\n", "\n", "for", "i", "in", "order", ":", "\n", "                ", "label", "=", "context_examples", "[", "i", "]", ".", "label", "\n", "if", "len", "(", "self", ".", "label_list", ")", "==", "1", ":", "\n", "# Regression", "\n", "                    ", "label", "=", "'0'", "if", "float", "(", "label", ")", "<=", "median_mapping", "[", "self", ".", "args", ".", "task_name", "]", "else", "'1'", "\n", "", "if", "counts", "[", "label", "]", "<", "max_demo_per_label", ":", "\n", "                    ", "selection", ".", "append", "(", "context_examples", "[", "i", "]", ")", "\n", "counts", "[", "label", "]", "+=", "1", "\n", "", "if", "sum", "(", "counts", ".", "values", "(", ")", ")", "==", "len", "(", "counts", ")", "*", "max_demo_per_label", ":", "\n", "                    ", "break", "\n", "\n", "", "", "assert", "len", "(", "selection", ")", ">", "0", "\n", "\n", "", "return", "selection", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.__len__": [[508, 510], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.__getitem__": [[511, 538], ["dataset.FewShotDataset.select_context", "dataset.FewShotDataset.convert_fn", "len"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.select_context", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.convert_fn"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "self", ".", "features", "is", "None", ":", "\n", "            ", "query_idx", ",", "context_indices", ",", "bootstrap_idx", "=", "self", ".", "example_idx", "[", "i", "]", "\n", "# The input (query) example", "\n", "example", "=", "self", ".", "query_examples", "[", "query_idx", "]", "\n", "# The demonstrations", "\n", "supports", "=", "self", ".", "select_context", "(", "[", "self", ".", "support_examples", "[", "i", "]", "for", "i", "in", "context_indices", "]", ")", "\n", "\n", "if", "self", ".", "args", ".", "template_list", "is", "not", "None", ":", "\n", "                ", "template", "=", "self", ".", "args", ".", "template_list", "[", "sample_idx", "%", "len", "(", "self", ".", "args", ".", "template_list", ")", "]", "\n", "", "else", ":", "\n", "                ", "template", "=", "self", ".", "args", ".", "template", "\n", "\n", "", "features", "=", "self", ".", "convert_fn", "(", "\n", "example", "=", "example", ",", "\n", "supports", "=", "supports", ",", "\n", "use_demo", "=", "self", ".", "use_demo", ",", "\n", "label_list", "=", "self", ".", "label_list", ",", "\n", "prompt", "=", "self", ".", "args", ".", "prompt", ",", "\n", "template", "=", "template", ",", "\n", "label_word_list", "=", "self", ".", "label_word_list", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "self", ".", "features", "[", "i", "]", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.get_labels": [[539, 541], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.FewShotDataset.convert_fn": [[542, 657], ["len", "dataset.tokenize_multipart_input", "dataset.OurInputFeatures", "dataset.input_example_to_tuple", "dataset.tokenize_multipart_input", "dataset.OurInputFeatures", "logger.info", "logger.info", "logger.info", "logger.info", "enumerate", "len", "float", "label_map.items", "range", "dataset.input_example_to_tuple", "range", "dataset.input_example_to_tuple", "support_labels.append", "len", "dataset.FewShotDataset.tokenizer.decode", "len", "len", "len", "filter", "filter", "dataset.input_example_to_tuple", "dataset.input_example_to_tuple", "float", "float"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.tokenize_multipart_input", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.tokenize_multipart_input", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple", "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple"], ["", "def", "convert_fn", "(", "\n", "self", ",", "\n", "example", ",", "\n", "supports", ",", "\n", "use_demo", "=", "False", ",", "\n", "label_list", "=", "None", ",", "\n", "prompt", "=", "False", ",", "\n", "template", "=", "None", ",", "\n", "label_word_list", "=", "None", ",", "\n", "verbose", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns a list of processed \"InputFeatures\".\n        \"\"\"", "\n", "max_length", "=", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# Prepare labels", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "# Mapping the label names to label ids", "\n", "if", "len", "(", "label_list", ")", "==", "1", ":", "\n", "# Regression", "\n", "            ", "label_map", "=", "{", "'0'", ":", "0", ",", "'1'", ":", "1", "}", "\n", "\n", "# Get example's label id (for training/inference)", "\n", "", "if", "example", ".", "label", "is", "None", ":", "\n", "            ", "example_label", "=", "None", "\n", "", "elif", "len", "(", "label_list", ")", "==", "1", ":", "\n", "# Regerssion", "\n", "            ", "example_label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "example_label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "# Prepare other features", "\n", "", "if", "not", "use_demo", ":", "\n", "# No using demonstrations", "\n", "            ", "inputs", "=", "tokenize_multipart_input", "(", "\n", "input_text_list", "=", "input_example_to_tuple", "(", "example", ")", ",", "\n", "max_length", "=", "max_length", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "task_name", "=", "self", ".", "args", ".", "task_name", ",", "\n", "prompt", "=", "prompt", ",", "\n", "template", "=", "template", ",", "\n", "label_word_list", "=", "label_word_list", ",", "\n", "first_sent_limit", "=", "self", ".", "args", ".", "first_sent_limit", ",", "\n", "other_sent_limit", "=", "self", ".", "args", ".", "other_sent_limit", ",", "\n", ")", "\n", "features", "=", "OurInputFeatures", "(", "**", "inputs", ",", "label", "=", "example_label", ")", "\n", "\n", "", "else", ":", "\n", "# Using demonstrations", "\n", "\n", "# Max length", "\n", "            ", "if", "self", ".", "args", ".", "double_demo", ":", "\n", "# When using demonstrations, double the maximum length", "\n", "# Note that in this case, args.max_seq_length is the maximum length for a single sentence", "\n", "                ", "max_length", "=", "max_length", "*", "2", "\n", "", "if", "self", ".", "args", ".", "gpt3_in_context_head", "or", "self", ".", "args", ".", "gpt3_in_context_tail", ":", "\n", "# When using GPT-3's in-context learning, take the maximum tokenization length of the model (512)", "\n", "                ", "max_length", "=", "512", "\n", "\n", "# All input sentences, including the query and the demonstrations, are put into augmented_examples, ", "\n", "# and are numbered based on the order (starting from 0). For single sentence tasks, the input (query)", "\n", "# is the sentence 0; for sentence-pair tasks, the input (query) is the sentence 0 and 1. Note that for GPT-3's ", "\n", "# in-context learning, the input (query) might be at the end instead of the beginning (gpt3_in_context_head)", "\n", "", "augmented_example", "=", "[", "]", "\n", "query_text", "=", "input_example_to_tuple", "(", "example", ")", "# Input sentence list for query", "\n", "support_by_label", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "label_map", ")", ")", "]", "\n", "\n", "if", "self", ".", "args", ".", "gpt3_in_context_head", "or", "self", ".", "args", ".", "gpt3_in_context_tail", ":", "\n", "                ", "support_labels", "=", "[", "]", "\n", "augmented_example", "=", "query_text", "\n", "for", "support_example", "in", "supports", ":", "\n", "                    ", "augmented_example", "+=", "input_example_to_tuple", "(", "support_example", ")", "\n", "current_label", "=", "support_example", ".", "label", "\n", "if", "len", "(", "label_list", ")", "==", "1", ":", "\n", "                        ", "current_label", "=", "'0'", "if", "float", "(", "current_label", ")", "<=", "median_mapping", "[", "self", ".", "args", ".", "task_name", "]", "else", "'1'", "# Regression", "\n", "", "support_labels", ".", "append", "(", "label_map", "[", "current_label", "]", ")", "\n", "", "", "else", ":", "\n", "# Group support examples by label", "\n", "                ", "for", "label_name", ",", "label_id", "in", "label_map", ".", "items", "(", ")", ":", "\n", "                    ", "if", "len", "(", "label_list", ")", "==", "1", ":", "\n", "# Regression", "\n", "                        ", "for", "support_example", "in", "filter", "(", "lambda", "s", ":", "(", "'0'", "if", "float", "(", "s", ".", "label", ")", "<=", "median_mapping", "[", "self", ".", "args", ".", "task_name", "]", "else", "'1'", ")", "==", "label_name", ",", "supports", ")", ":", "\n", "                            ", "support_by_label", "[", "label_id", "]", "+=", "input_example_to_tuple", "(", "support_example", ")", "\n", "", "", "else", ":", "\n", "                        ", "for", "support_example", "in", "filter", "(", "lambda", "s", ":", "s", ".", "label", "==", "label_name", ",", "supports", ")", ":", "\n", "                            ", "support_by_label", "[", "label_id", "]", "+=", "input_example_to_tuple", "(", "support_example", ")", "\n", "\n", "", "", "", "augmented_example", "=", "query_text", "\n", "for", "label_id", "in", "range", "(", "len", "(", "label_map", ")", ")", ":", "\n", "                    ", "augmented_example", "+=", "support_by_label", "[", "label_id", "]", "\n", "\n", "# Tokenization (based on the template)", "\n", "", "", "inputs", "=", "tokenize_multipart_input", "(", "\n", "input_text_list", "=", "augmented_example", ",", "\n", "max_length", "=", "max_length", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "task_name", "=", "self", ".", "args", ".", "task_name", ",", "\n", "prompt", "=", "prompt", ",", "\n", "template", "=", "template", ",", "\n", "label_word_list", "=", "label_word_list", ",", "\n", "first_sent_limit", "=", "self", ".", "args", ".", "first_sent_limit", ",", "\n", "other_sent_limit", "=", "self", ".", "args", ".", "other_sent_limit", ",", "\n", "truncate_head", "=", "self", ".", "args", ".", "truncate_head", ",", "\n", "gpt3", "=", "self", ".", "args", ".", "gpt3_in_context_head", "or", "self", ".", "args", ".", "gpt3_in_context_tail", ",", "\n", "support_labels", "=", "None", "if", "not", "(", "self", ".", "args", ".", "gpt3_in_context_head", "or", "self", ".", "args", ".", "gpt3_in_context_tail", ")", "else", "support_labels", "\n", ")", "\n", "features", "=", "OurInputFeatures", "(", "**", "inputs", ",", "label", "=", "example_label", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"features: %s\"", "%", "features", ")", "\n", "logger", ".", "info", "(", "\"text: %s\"", "%", "self", ".", "tokenizer", ".", "decode", "(", "features", ".", "input_ids", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_string": [[43, 49], ["None"], "function", ["None"], ["", "", "def", "input_example_to_string", "(", "example", ",", "sep_token", ")", ":", "\n", "    ", "if", "example", ".", "text_b", "is", "None", ":", "\n", "        ", "return", "example", ".", "text_a", "\n", "", "else", ":", "\n", "# Warning: very simple hack here", "\n", "        ", "return", "example", ".", "text_a", "+", "' '", "+", "sep_token", "+", "' '", "+", "example", ".", "text_b", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.input_example_to_tuple": [[50, 59], ["pandas.isna", "logger.warn"], "function", ["None"], ["", "", "def", "input_example_to_tuple", "(", "example", ")", ":", "\n", "    ", "if", "example", ".", "text_b", "is", "None", ":", "\n", "        ", "if", "pd", ".", "isna", "(", "example", ".", "text_a", ")", "or", "example", ".", "text_a", "is", "None", ":", "\n", "            ", "return", "[", "''", "]", "\n", "logger", ".", "warn", "(", "\"Empty input\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "example", ".", "text_a", "]", "\n", "", "", "else", ":", "\n", "        ", "return", "[", "example", ".", "text_a", ",", "example", ".", "text_b", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.dataset.tokenize_multipart_input": [[60, 256], ["tokenizer.encode", "template.split", "enumerate", "enumerate", "logger.warn", "len", "input_ids.append", "attention_mask.append", "token_type_ids.append", "len", "len", "input_ids.index", "type", "new_tokens.append", "int", "pandas.isna", "dataset.tokenize_multipart_input.enc"], "function", ["None"], ["", "", "def", "tokenize_multipart_input", "(", "\n", "input_text_list", ",", "\n", "max_length", ",", "\n", "tokenizer", ",", "\n", "task_name", "=", "None", ",", "\n", "prompt", "=", "False", ",", "\n", "template", "=", "None", ",", "\n", "label_word_list", "=", "None", ",", "\n", "first_sent_limit", "=", "None", ",", "\n", "other_sent_limit", "=", "None", ",", "\n", "gpt3", "=", "False", ",", "\n", "truncate_head", "=", "False", ",", "\n", "support_labels", "=", "None", ",", "\n", ")", ":", "\n", "    ", "def", "enc", "(", "text", ")", ":", "\n", "        ", "return", "tokenizer", ".", "encode", "(", "text", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "input_ids", "=", "[", "]", "\n", "attention_mask", "=", "[", "]", "\n", "token_type_ids", "=", "[", "]", "# Only for BERT", "\n", "mask_pos", "=", "None", "# Position of the mask token", "\n", "\n", "if", "prompt", ":", "\n", "        ", "\"\"\"\n        Concatenate all sentences and prompts based on the provided template.\n        Template example: '*cls*It was*mask*.*sent_0**<sep>*label_0:*sent_1**<sep>**label_1*:*sent_2**<sep>*'\n        *xx* represent variables:\n            *cls*: cls_token\n            *mask*: mask_token\n            *sep*: sep_token\n            *sep+*: sep_token, also means +1 for segment id\n            *sent_i*: sentence i (input_text_list[i])\n            *sent-_i*: same as above, but delete the last token\n            *sentl_i*: same as above, but use lower case for the first word\n            *sentl-_i*: same as above, but use lower case for the first word and delete the last token\n            *+sent_i*: same as above, but add a space before the sentence\n            *+sentl_i*: same as above, but add a space before the sentence and use lower case for the first word\n            *label_i*: label_word_list[i]\n            *label_x*: label depends on the example id (support_labels needed). this is only used in GPT-3's in-context learning\n\n        Use \"_\" to replace space.\n        PAY ATTENTION TO SPACE!! DO NOT leave space before variables, for this will lead to extra space token.\n        \"\"\"", "\n", "assert", "template", "is", "not", "None", "\n", "\n", "special_token_mapping", "=", "{", "\n", "'cls'", ":", "tokenizer", ".", "cls_token_id", ",", "'mask'", ":", "tokenizer", ".", "mask_token_id", ",", "'sep'", ":", "tokenizer", ".", "sep_token_id", ",", "'sep+'", ":", "tokenizer", ".", "sep_token_id", ",", "\n", "}", "\n", "template_list", "=", "template", ".", "split", "(", "'*'", ")", "# Get variable list in the template", "\n", "segment_id", "=", "0", "# Current segment id. Segment id +1 if encountering sep+.", "\n", "\n", "for", "part_id", ",", "part", "in", "enumerate", "(", "template_list", ")", ":", "\n", "            ", "new_tokens", "=", "[", "]", "\n", "segment_plus_1_flag", "=", "False", "\n", "if", "part", "in", "special_token_mapping", ":", "\n", "                ", "if", "part", "==", "'cls'", "and", "'T5'", "in", "type", "(", "tokenizer", ")", ".", "__name__", ":", "\n", "# T5 does not have cls token", "\n", "                    ", "continue", "\n", "", "new_tokens", ".", "append", "(", "special_token_mapping", "[", "part", "]", ")", "\n", "if", "part", "==", "'sep+'", ":", "\n", "                    ", "segment_plus_1_flag", "=", "True", "\n", "", "", "elif", "part", "[", ":", "6", "]", "==", "'label_'", ":", "\n", "# Note that label_word_list already has extra space, so do not add more space ahead of it.", "\n", "                ", "label_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "label_word", "=", "label_word_list", "[", "label_id", "]", "\n", "new_tokens", ".", "append", "(", "label_word", ")", "\n", "", "elif", "part", "[", ":", "7", "]", "==", "'labelx_'", ":", "\n", "                ", "instance_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "label_id", "=", "support_labels", "[", "instance_id", "]", "\n", "label_word", "=", "label_word_list", "[", "label_id", "]", "\n", "new_tokens", ".", "append", "(", "label_word", ")", "\n", "", "elif", "part", "[", ":", "5", "]", "==", "'sent_'", ":", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "new_tokens", "+=", "enc", "(", "input_text_list", "[", "sent_id", "]", ")", "\n", "", "elif", "part", "[", ":", "6", "]", "==", "'+sent_'", ":", "\n", "# Add space", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "new_tokens", "+=", "enc", "(", "' '", "+", "input_text_list", "[", "sent_id", "]", ")", "\n", "", "elif", "part", "[", ":", "6", "]", "==", "'sent-_'", ":", "\n", "# Delete the last token", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "new_tokens", "+=", "enc", "(", "input_text_list", "[", "sent_id", "]", "[", ":", "-", "1", "]", ")", "\n", "", "elif", "part", "[", ":", "6", "]", "==", "'sentl_'", ":", "\n", "# Lower case the first token", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "text", "=", "input_text_list", "[", "sent_id", "]", "\n", "text", "=", "text", "[", ":", "1", "]", ".", "lower", "(", ")", "+", "text", "[", "1", ":", "]", "\n", "new_tokens", "+=", "enc", "(", "text", ")", "\n", "", "elif", "part", "[", ":", "7", "]", "==", "'+sentl_'", ":", "\n", "# Lower case the first token and add space ", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "text", "=", "input_text_list", "[", "sent_id", "]", "\n", "text", "=", "text", "[", ":", "1", "]", ".", "lower", "(", ")", "+", "text", "[", "1", ":", "]", "\n", "new_tokens", "+=", "enc", "(", "' '", "+", "text", ")", "\n", "", "elif", "part", "[", ":", "7", "]", "==", "'sentl-_'", ":", "\n", "# Lower case the first token and discard the last token", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "text", "=", "input_text_list", "[", "sent_id", "]", "\n", "text", "=", "text", "[", ":", "1", "]", ".", "lower", "(", ")", "+", "text", "[", "1", ":", "]", "\n", "new_tokens", "+=", "enc", "(", "text", "[", ":", "-", "1", "]", ")", "\n", "", "elif", "part", "[", ":", "6", "]", "==", "'sentu_'", ":", "\n", "# Upper case the first token", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "text", "=", "input_text_list", "[", "sent_id", "]", "\n", "text", "=", "text", "[", ":", "1", "]", ".", "upper", "(", ")", "+", "text", "[", "1", ":", "]", "\n", "new_tokens", "+=", "enc", "(", "text", ")", "\n", "", "elif", "part", "[", ":", "7", "]", "==", "'+sentu_'", ":", "\n", "# Upper case the first token and add space", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "text", "=", "input_text_list", "[", "sent_id", "]", "\n", "text", "=", "text", "[", ":", "1", "]", ".", "upper", "(", ")", "+", "text", "[", "1", ":", "]", "\n", "new_tokens", "+=", "enc", "(", "' '", "+", "text", ")", "\n", "", "else", ":", "\n", "# Just natural language prompt", "\n", "                ", "part", "=", "part", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "# handle special case when T5 tokenizer might add an extra space", "\n", "if", "len", "(", "part", ")", "==", "1", ":", "\n", "                    ", "new_tokens", ".", "append", "(", "tokenizer", ".", "_convert_token_to_id", "(", "part", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_tokens", "+=", "enc", "(", "part", ")", "\n", "\n", "", "", "if", "part", "[", ":", "4", "]", "==", "'sent'", "or", "part", "[", "1", ":", "5", "]", "==", "'sent'", ":", "\n", "# If this part is the sentence, limit the sentence length", "\n", "                ", "sent_id", "=", "int", "(", "part", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "if", "sent_id", "==", "0", ":", "\n", "                    ", "if", "first_sent_limit", "is", "not", "None", ":", "\n", "                        ", "new_tokens", "=", "new_tokens", "[", ":", "first_sent_limit", "]", "\n", "", "", "else", ":", "\n", "                    ", "if", "other_sent_limit", "is", "not", "None", ":", "\n", "                        ", "new_tokens", "=", "new_tokens", "[", ":", "other_sent_limit", "]", "\n", "\n", "", "", "", "input_ids", "+=", "new_tokens", "\n", "attention_mask", "+=", "[", "1", "for", "i", "in", "range", "(", "len", "(", "new_tokens", ")", ")", "]", "\n", "token_type_ids", "+=", "[", "segment_id", "for", "i", "in", "range", "(", "len", "(", "new_tokens", ")", ")", "]", "\n", "\n", "if", "segment_plus_1_flag", ":", "\n", "                ", "segment_id", "+=", "1", "\n", "", "", "", "else", ":", "\n", "        ", "input_ids", "=", "[", "tokenizer", ".", "cls_token_id", "]", "\n", "attention_mask", "=", "[", "1", "]", "\n", "token_type_ids", "=", "[", "0", "]", "\n", "\n", "for", "sent_id", ",", "input_text", "in", "enumerate", "(", "input_text_list", ")", ":", "\n", "            ", "if", "input_text", "is", "None", ":", "\n", "# Do not have text_b", "\n", "                ", "continue", "\n", "", "if", "pd", ".", "isna", "(", "input_text", ")", "or", "input_text", "is", "None", ":", "\n", "# Empty input", "\n", "                ", "input_text", "=", "''", "\n", "", "input_tokens", "=", "enc", "(", "input_text", ")", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "input_ids", "+=", "input_tokens", "\n", "attention_mask", "+=", "[", "1", "for", "i", "in", "range", "(", "len", "(", "input_tokens", ")", ")", "]", "\n", "token_type_ids", "+=", "[", "sent_id", "for", "i", "in", "range", "(", "len", "(", "input_tokens", ")", ")", "]", "\n", "\n", "", "if", "'T5'", "in", "type", "(", "tokenizer", ")", ".", "__name__", ":", "# T5 does not have CLS token", "\n", "            ", "input_ids", "=", "input_ids", "[", "1", ":", "]", "\n", "attention_mask", "=", "attention_mask", "[", "1", ":", "]", "\n", "token_type_ids", "=", "token_type_ids", "[", "1", ":", "]", "\n", "\n", "# Padding", "\n", "", "", "if", "first_sent_limit", "is", "not", "None", "and", "len", "(", "input_ids", ")", ">", "max_length", ":", "\n", "# If using sentence limit, the total length still exceeds the maximum limit, report a warning", "\n", "        ", "logger", ".", "warn", "(", "\"Input exceeds max_length limit: {}\"", ".", "format", "(", "tokenizer", ".", "decode", "(", "input_ids", ")", ")", ")", "\n", "\n", "", "while", "len", "(", "input_ids", ")", "<", "max_length", ":", "\n", "        ", "input_ids", ".", "append", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "attention_mask", ".", "append", "(", "0", ")", "\n", "token_type_ids", ".", "append", "(", "0", ")", "\n", "\n", "# Truncate", "\n", "", "if", "len", "(", "input_ids", ")", ">", "max_length", ":", "\n", "        ", "if", "truncate_head", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", "-", "max_length", ":", "]", "\n", "attention_mask", "=", "attention_mask", "[", "-", "max_length", ":", "]", "\n", "token_type_ids", "=", "token_type_ids", "[", "-", "max_length", ":", "]", "\n", "", "else", ":", "\n", "# Default is to truncate the tail", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", "max_length", "]", "\n", "attention_mask", "=", "attention_mask", "[", ":", "max_length", "]", "\n", "token_type_ids", "=", "token_type_ids", "[", ":", "max_length", "]", "\n", "\n", "# Find mask token", "\n", "", "", "if", "prompt", ":", "\n", "        ", "mask_pos", "=", "[", "input_ids", ".", "index", "(", "tokenizer", ".", "mask_token_id", ")", "]", "\n", "# Make sure that the masked position is inside the max_length", "\n", "assert", "mask_pos", "[", "0", "]", "<", "max_length", "\n", "\n", "", "result", "=", "{", "'input_ids'", ":", "input_ids", ",", "'attention_mask'", ":", "attention_mask", "}", "\n", "if", "'BERT'", "in", "type", "(", "tokenizer", ")", ".", "__name__", ":", "\n", "# Only provide token type ids for BERT", "\n", "        ", "result", "[", "'token_type_ids'", "]", "=", "token_type_ids", "\n", "\n", "", "if", "prompt", ":", "\n", "        ", "result", "[", "'mask_pos'", "]", "=", "mask_pos", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_example_from_tensor_dict": [[32, 39], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_train_examples": [[41, 45], ["logger.info", "processors.MrpcProcessor._create_examples", "processors.MrpcProcessor._read_tsv", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_dev_examples": [[46, 49], ["processors.MrpcProcessor._create_examples", "processors.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_test_examples": [[50, 53], ["processors.MrpcProcessor._create_examples", "processors.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_unlabeled_examples": [[54, 56], ["processors.MrpcProcessor._create_examples", "processors.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor.get_labels": [[57, 60], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MrpcProcessor._create_examples": [[61, 73], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "0", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_example_from_tensor_dict": [[78, 85], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"premise\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"hypothesis\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_train_examples": [[87, 90], ["processors.MnliProcessor._create_examples", "processors.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_dev_examples": [[91, 94], ["processors.MnliProcessor._create_examples", "processors.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_matched.tsv\"", ")", ")", ",", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_test_examples": [[95, 98], ["processors.MnliProcessor._create_examples", "processors.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_matched.tsv\"", ")", ")", ",", "\"test_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_unlabeled_examples": [[99, 101], ["processors.MnliProcessor._create_examples", "processors.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor.get_labels": [[102, 105], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliProcessor._create_examples": [[106, 118], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "8", "]", "\n", "text_b", "=", "line", "[", "9", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliMismatchedProcessor.get_dev_examples": [[123, 126], ["processors.MnliMismatchedProcessor._create_examples", "processors.MnliMismatchedProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ")", ",", "\"dev_mismatched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.MnliMismatchedProcessor.get_test_examples": [[127, 130], ["processors.MnliMismatchedProcessor._create_examples", "processors.MnliMismatchedProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_mismatched.tsv\"", ")", ")", ",", "\"test_mismatched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_example_from_tensor_dict": [[135, 142], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"premise\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"hypothesis\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_train_examples": [[144, 147], ["processors.SnliProcessor._create_examples", "processors.SnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_dev_examples": [[148, 151], ["processors.SnliProcessor._create_examples", "processors.SnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_test_examples": [[152, 155], ["processors.SnliProcessor._create_examples", "processors.SnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_unlabeled_examples": [[156, 158], ["processors.SnliProcessor._create_examples", "processors.SnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor.get_labels": [[159, 162], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.SnliProcessor._create_examples": [[163, 175], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "7", "]", "\n", "text_b", "=", "line", "[", "8", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_example_from_tensor_dict": [[180, 187], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_train_examples": [[189, 192], ["processors.Sst2Processor._create_examples", "processors.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_dev_examples": [[193, 196], ["processors.Sst2Processor._create_examples", "processors.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_test_examples": [[197, 200], ["processors.Sst2Processor._create_examples", "processors.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_unlabeled_examples": [[201, 203], ["processors.Sst2Processor._create_examples", "processors.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor.get_labels": [[204, 207], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.Sst2Processor._create_examples": [[208, 220], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "text_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "text_index", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_example_from_tensor_dict": [[225, 232], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"question\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_train_examples": [[234, 237], ["processors.QnliProcessor._create_examples", "processors.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_dev_examples": [[238, 241], ["processors.QnliProcessor._create_examples", "processors.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_test_examples": [[242, 245], ["processors.QnliProcessor._create_examples", "processors.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_unlabeled_examples": [[246, 248], ["processors.QnliProcessor._create_examples", "processors.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor.get_labels": [[249, 252], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.QnliProcessor._create_examples": [[253, 265], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_example_from_tensor_dict": [[270, 277], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_train_examples": [[279, 282], ["processors.RteProcessor._create_examples", "processors.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_dev_examples": [[283, 286], ["processors.RteProcessor._create_examples", "processors.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_test_examples": [[287, 290], ["processors.RteProcessor._create_examples", "processors.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_unlabeled_examples": [[291, 293], ["processors.RteProcessor._create_examples", "processors.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.tsv\"", ")", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor.get_labels": [[294, 297], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.RteProcessor._create_examples": [[298, 310], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.__init__": [[317, 319], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "task_name", ")", ":", "\n", "        ", "self", ".", "task_name", "=", "task_name", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_example_from_tensor_dict": [[320, 327], ["transformers.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_train_examples": [[329, 332], ["processors.TextClassificationProcessor._create_examples", "pandas.read_csv().values.tolist", "pandas.read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.csv\"", ")", ",", "header", "=", "None", ")", ".", "values", ".", "tolist", "(", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_dev_examples": [[333, 336], ["processors.TextClassificationProcessor._create_examples", "pandas.read_csv().values.tolist", "pandas.read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.csv\"", ")", ",", "header", "=", "None", ")", ".", "values", ".", "tolist", "(", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_test_examples": [[337, 340], ["processors.TextClassificationProcessor._create_examples", "pandas.read_csv().values.tolist", "pandas.read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.csv\"", ")", ",", "header", "=", "None", ")", ".", "values", ".", "tolist", "(", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_unlabeled_examples": [[341, 343], ["processors.TextClassificationProcessor._create_examples", "pandas.read_csv().values.tolist", "pandas.read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_examples", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"unlabeled.csv\"", ")", ",", "header", "=", "None", ")", ".", "values", ".", "tolist", "(", ")", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor.get_labels": [[344, 360], ["list", "range", "list", "range", "list", "range", "list", "range", "list", "range", "list", "Exception", "range"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "if", "self", ".", "task_name", "==", "\"mr\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "2", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"sst-5\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "5", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"subj\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "2", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"trec\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "6", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"cr\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "2", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"mpqa\"", ":", "\n", "            ", "return", "list", "(", "range", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"task_name not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.TextClassificationProcessor._create_examples": [[361, 383], ["enumerate", "examples.append", "transformers.InputExample", "examples.append", "transformers.InputExample", "examples.append", "pandas.isna", "pandas.isna", "transformers.InputExample", "examples.append", "Exception", "transformers.InputExample"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "if", "self", ".", "task_name", "==", "\"ag_news\"", ":", "\n", "                ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "line", "[", "1", "]", "+", "'. '", "+", "line", "[", "2", "]", ",", "short_text", "=", "line", "[", "1", "]", "+", "\".\"", ",", "label", "=", "line", "[", "0", "]", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"yelp_review_full\"", ":", "\n", "                ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "line", "[", "1", "]", ",", "short_text", "=", "line", "[", "1", "]", ",", "label", "=", "line", "[", "0", "]", ")", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"yahoo_answers\"", ":", "\n", "                ", "text", "=", "line", "[", "1", "]", "\n", "if", "not", "pd", ".", "isna", "(", "line", "[", "2", "]", ")", ":", "\n", "                    ", "text", "+=", "' '", "+", "line", "[", "2", "]", "\n", "", "if", "not", "pd", ".", "isna", "(", "line", "[", "3", "]", ")", ":", "\n", "                    ", "text", "+=", "' '", "+", "line", "[", "3", "]", "\n", "", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "short_text", "=", "line", "[", "1", "]", ",", "label", "=", "line", "[", "0", "]", ")", ")", "\n", "", "elif", "self", ".", "task_name", "in", "[", "'mr'", ",", "'sst-5'", ",", "'subj'", ",", "'trec'", ",", "'cr'", ",", "'mpqa'", "]", ":", "\n", "                ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "line", "[", "1", "]", ",", "label", "=", "line", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Task_name not supported.\"", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.processors.text_classification_metrics": [[385, 387], ["None"], "function", ["None"], ["", "", "def", "text_classification_metrics", "(", "task_name", ",", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "{", "\"acc\"", ":", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.src.utils.mask_tokens": [[6, 38], ["inputs.cpu.cpu", "inputs.cpu.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "torch.randint", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "len", "inputs.cpu.cuda", "inputs.clone.cuda", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli().bool", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["None"], ["def", "mask_tokens", "(", "inputs", ":", "torch", ".", "Tensor", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "mask_probability", "=", "0.15", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"", "\n", "\n", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "", "inputs", "=", "inputs", ".", "cpu", "(", ")", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "mask_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "&", "~", "indices_replaced", "\n", "random_words", "=", "torch", ".", "randint", "(", "len", "(", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.get_label": [[10, 30], ["line.strip().split.strip().split", "line.strip().split.strip"], "function", ["None"], ["def", "get_label", "(", "task", ",", "line", ")", ":", "\n", "    ", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "# GLUE style", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "task", "==", "'MNLI'", ":", "\n", "            ", "return", "line", "[", "-", "1", "]", "\n", "", "elif", "task", "==", "'MRPC'", ":", "\n", "            ", "return", "line", "[", "0", "]", "\n", "", "elif", "task", "==", "'QNLI'", ":", "\n", "            ", "return", "line", "[", "-", "1", "]", "\n", "", "elif", "task", "==", "'RTE'", ":", "\n", "            ", "return", "line", "[", "-", "1", "]", "\n", "", "elif", "task", "==", "'SNLI'", ":", "\n", "            ", "return", "line", "[", "-", "1", "]", "\n", "", "elif", "task", "==", "'SST-2'", ":", "\n", "            ", "return", "line", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "        ", "return", "line", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.load_datasets": [[32, 59], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "open", "f.readlines"], "function", ["None"], ["", "", "def", "load_datasets", "(", "data_dir", ",", "tasks", ")", ":", "\n", "    ", "datasets", "=", "{", "}", "\n", "for", "task", "in", "tasks", ":", "\n", "        ", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "# GLUE style (tsv)", "\n", "            ", "dataset", "=", "{", "}", "\n", "dirname", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "task", ")", "\n", "if", "task", "==", "\"MNLI\"", ":", "\n", "                ", "splits", "=", "[", "\"train\"", ",", "\"dev_matched\"", ",", "\"dev_mismatched\"", "]", "\n", "", "else", ":", "\n", "                ", "splits", "=", "[", "\"train\"", ",", "\"dev\"", "]", "\n", "", "for", "split", "in", "splits", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "f\"{split}.tsv\"", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "                    ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "dataset", "[", "split", "]", "=", "lines", "\n", "", "datasets", "[", "task", "]", "=", "dataset", "\n", "", "else", ":", "\n", "# Other datasets (csv)", "\n", "            ", "dataset", "=", "{", "}", "\n", "dirname", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "task", ")", "\n", "splits", "=", "[", "\"train\"", ",", "\"test\"", "]", "\n", "for", "split", "in", "splits", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "f\"{split}.csv\"", ")", "\n", "dataset", "[", "split", "]", "=", "pd", ".", "read_csv", "(", "filename", ",", "header", "=", "None", ")", "\n", "", "datasets", "[", "task", "]", "=", "dataset", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.split_header": [[61, 69], ["ValueError"], "function", ["None"], ["", "def", "split_header", "(", "task", ",", "lines", ")", ":", "\n", "    ", "\"\"\"\n    Returns if the task file has a header or not. Only for GLUE tasks.\n    \"\"\"", "\n", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "        ", "return", "lines", "[", "0", ":", "1", "]", ",", "lines", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown GLUE task.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.main": [[71, 190], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "print", "generate_data.load_datasets", "print", "load_datasets.items", "numpy.random.seed", "print", "os.path.join", "os.path.join", "os.makedirs", "generate_data.split_header", "numpy.random.shuffle", "dataset[].values.tolist", "numpy.random.shuffle", "dataset.items", "dataset[].to_csv", "generate_data.get_label", "pandas.DataFrame", "pandas.DataFrame.to_csv", "pandas.DataFrame", "pandas.DataFrame.to_csv", "pandas.DataFrame", "pandas.DataFrame.to_csv", "split.replace.startswith", "split.replace.replace", "os.path.join", "label_list[].append", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join", "open", "os.path.join", "f.write", "os.path.join", "f.write", "os.path.join", "f.write", "pandas.DataFrame.append", "pandas.DataFrame.append", "new_unlabeled.append", "os.path.join", "f.write", "f.write", "f.write", "f.write"], "function", ["home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.load_datasets", "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.split_header", "home.repos.pwc.inspect_result.matthewcym_sflm.tools.generate_data.get_label"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "\"Training examples for each class.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mu'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"ratio between unlabeled data versus labeled data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "'SST-2'", ",", "'sst-5'", ",", "'mr'", ",", "'cr'", ",", "'mpqa'", ",", "'subj'", ",", "'MRPC'", ",", "'MNLI'", ",", "'SNLI'", ",", "'QNLI'", ",", "'RTE'", "]", ",", "\n", "help", "=", "\"Task names\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "100", ",", "13", ",", "21", ",", "42", ",", "87", "]", ",", "\n", "help", "=", "\"Random seeds\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"data/original\"", ",", "\n", "help", "=", "\"Path to original data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"data/few-shot\"", ",", "\n", "help", "=", "\"Output path\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "k", "=", "args", ".", "k", "\n", "mu", "=", "args", ".", "mu", "\n", "print", "(", "\"K =\"", ",", "k", ")", "\n", "print", "(", "'MU = '", ",", "mu", ")", "\n", "\n", "datasets", "=", "load_datasets", "(", "args", ".", "data_dir", ",", "args", ".", "task", ")", "\n", "\n", "for", "seed", "in", "args", ".", "seed", ":", "\n", "        ", "print", "(", "\"Seed = %d\"", "%", "(", "seed", ")", ")", "\n", "for", "task", ",", "dataset", "in", "datasets", ".", "items", "(", ")", ":", "\n", "# Set random seed", "\n", "            ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "# Shuffle the training set", "\n", "print", "(", "\"| Task = %s\"", "%", "(", "task", ")", ")", "\n", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "# GLUE style ", "\n", "                ", "train_header", ",", "train_lines", "=", "split_header", "(", "task", ",", "dataset", "[", "\"train\"", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_lines", ")", "\n", "", "else", ":", "\n", "# Other datasets ", "\n", "                ", "train_lines", "=", "dataset", "[", "'train'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_lines", ")", "\n", "\n", "# Set up dir", "\n", "", "task_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "task", ")", "\n", "setting_dir", "=", "os", ".", "path", ".", "join", "(", "task_dir", ",", "f\"{k}-{mu}-{seed}\"", ")", "\n", "os", ".", "makedirs", "(", "setting_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Write test splits", "\n", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "# GLUE style", "\n", "# Use the original development set as the test set (the original test sets are not publicly available)", "\n", "                ", "for", "split", ",", "lines", "in", "dataset", ".", "items", "(", ")", ":", "\n", "                    ", "if", "split", ".", "startswith", "(", "\"train\"", ")", ":", "\n", "                        ", "continue", "\n", "", "split", "=", "split", ".", "replace", "(", "'dev'", ",", "'test'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "f\"{split}.tsv\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                        ", "for", "line", "in", "lines", ":", "\n", "                            ", "f", ".", "write", "(", "line", ")", "\n", "", "", "", "", "else", ":", "\n", "# Other datasets", "\n", "# Use the original test sets", "\n", "                ", "dataset", "[", "'test'", "]", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "'test.csv'", ")", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n", "# Get label list for balanced sampling", "\n", "", "label_list", "=", "{", "}", "\n", "for", "line", "in", "train_lines", ":", "\n", "                ", "label", "=", "get_label", "(", "task", ",", "line", ")", "\n", "if", "label", "not", "in", "label_list", ":", "\n", "                    ", "label_list", "[", "label", "]", "=", "[", "line", "]", "\n", "", "else", ":", "\n", "                    ", "label_list", "[", "label", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "if", "task", "in", "[", "\"MNLI\"", ",", "\"MRPC\"", ",", "\"QNLI\"", ",", "\"RTE\"", ",", "\"SNLI\"", ",", "\"SST-2\"", "]", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "\"train.tsv\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "for", "line", "in", "train_header", ":", "\n", "                        ", "f", ".", "write", "(", "line", ")", "\n", "", "for", "label", "in", "label_list", ":", "\n", "                        ", "for", "line", "in", "label_list", "[", "label", "]", "[", ":", "k", "]", ":", "\n", "                            ", "f", ".", "write", "(", "line", ")", "\n", "", "", "", "name", "=", "\"dev.tsv\"", "\n", "if", "task", "==", "'MNLI'", ":", "\n", "                    ", "name", "=", "\"dev_matched.tsv\"", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "name", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "for", "line", "in", "train_header", ":", "\n", "                        ", "f", ".", "write", "(", "line", ")", "\n", "", "for", "label", "in", "label_list", ":", "\n", "                        ", "for", "line", "in", "label_list", "[", "label", "]", "[", "k", ":", "2", "*", "k", "]", ":", "\n", "                            ", "f", ".", "write", "(", "line", ")", "\n", "", "", "", "name", "=", "\"unlabeled.tsv\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "name", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "for", "line", "in", "train_header", ":", "\n", "                        ", "f", ".", "write", "(", "line", ")", "\n", "", "for", "label", "in", "label_list", ":", "\n", "                        ", "for", "line", "in", "label_list", "[", "label", "]", "[", "2", "*", "k", ":", "2", "*", "k", "+", "mu", "*", "k", "]", ":", "\n", "                            ", "f", ".", "write", "(", "line", ")", "\n", "", "", "", "", "else", ":", "\n", "                ", "new_train", "=", "[", "]", "\n", "for", "label", "in", "label_list", ":", "\n", "                    ", "for", "line", "in", "label_list", "[", "label", "]", "[", ":", "k", "]", ":", "\n", "                        ", "new_train", ".", "append", "(", "line", ")", "\n", "", "", "new_train", "=", "DataFrame", "(", "new_train", ")", "\n", "new_train", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "'train.csv'", ")", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n", "new_dev", "=", "[", "]", "\n", "for", "label", "in", "label_list", ":", "\n", "                    ", "for", "line", "in", "label_list", "[", "label", "]", "[", "k", ":", "2", "*", "k", "]", ":", "\n", "                        ", "new_dev", ".", "append", "(", "line", ")", "\n", "", "", "new_dev", "=", "DataFrame", "(", "new_dev", ")", "\n", "new_dev", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "'dev.csv'", ")", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n", "new_unlabeled", "=", "[", "]", "\n", "for", "label", "in", "label_list", ":", "\n", "                    ", "for", "line", "in", "label_list", "[", "label", "]", "[", "2", "*", "k", ":", "2", "*", "k", "+", "mu", "*", "k", "]", ":", "\n", "                        ", "new_unlabeled", ".", "append", "(", "line", ")", "\n", "", "", "new_unlabled", "=", "DataFrame", "(", "new_unlabeled", ")", "\n", "new_unlabled", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "setting_dir", ",", "'unlabeled.csv'", ")", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n"]]}