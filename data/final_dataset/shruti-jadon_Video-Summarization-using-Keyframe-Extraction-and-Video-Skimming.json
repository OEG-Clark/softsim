{"home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.vgg16.VGG16": [[30, 152], ["keras.models.Model", "ValueError", "keras.backend.image_dim_ordering", "keras.layers.Input", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.MaxPooling2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.MaxPooling2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.MaxPooling2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.MaxPooling2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.Convolution2D", "keras.layers.MaxPooling2D", "print", "keras.backend.is_keras_tensor", "keras.layers.Input", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.backend.image_dim_ordering", "keras.backend.image_dim_ordering", "keras.models.Model.load_weights", "keras.models.Model.load_weights", "keras.utils.data_utils.get_file", "keras.utils.data_utils.get_file", "keras.backend.backend", "warnings.warn", "keras.utils.layer_utils.convert_all_kernels_in_model", "keras.utils.data_utils.get_file", "keras.utils.data_utils.get_file", "keras.backend.backend", "keras.utils.layer_utils.convert_all_kernels_in_model"], "function", ["None"], ["def", "VGG16", "(", "include_top", "=", "True", ",", "weights", "=", "'imagenet'", ",", "\n", "input_tensor", "=", "None", ")", ":", "\n", "    ", "'''Instantiate the VGG16 architecture,\n    optionally loading weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_dim_ordering=\"tf\"` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The dimension ordering\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n\n    # Returns\n        A Keras model instance.\n    '''", "\n", "if", "weights", "not", "in", "{", "'imagenet'", ",", "None", "}", ":", "\n", "        ", "raise", "ValueError", "(", "'The `weights` argument should be either '", "\n", "'`None` (random initialization) or `imagenet` '", "\n", "'(pre-training on ImageNet).'", ")", "\n", "# Determine proper input shape", "\n", "", "if", "K", ".", "image_dim_ordering", "(", ")", "==", "'th'", ":", "\n", "        ", "if", "include_top", ":", "\n", "            ", "input_shape", "=", "(", "3", ",", "224", ",", "224", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "(", "3", ",", "None", ",", "None", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "include_top", ":", "\n", "            ", "input_shape", "=", "(", "224", ",", "224", ",", "3", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "(", "None", ",", "None", ",", "3", ")", "\n", "\n", "", "", "if", "input_tensor", "is", "None", ":", "\n", "        ", "img_input", "=", "Input", "(", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "K", ".", "is_keras_tensor", "(", "input_tensor", ")", ":", "\n", "            ", "img_input", "=", "Input", "(", "tensor", "=", "input_tensor", ")", "\n", "", "else", ":", "\n", "            ", "img_input", "=", "input_tensor", "\n", "# Block 1", "\n", "", "", "x", "=", "Convolution2D", "(", "64", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block1_conv1'", ")", "(", "img_input", ")", "\n", "x", "=", "Convolution2D", "(", "64", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block1_conv2'", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block1_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 2", "\n", "x", "=", "Convolution2D", "(", "128", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block2_conv1'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "128", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block2_conv2'", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block2_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 3", "\n", "x", "=", "Convolution2D", "(", "256", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block3_conv1'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "256", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block3_conv2'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "256", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block3_conv3'", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block3_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 4", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block4_conv1'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block4_conv2'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block4_conv3'", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block4_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 5", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block5_conv1'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block5_conv2'", ")", "(", "x", ")", "\n", "x", "=", "Convolution2D", "(", "512", ",", "3", ",", "3", ",", "activation", "=", "'relu'", ",", "border_mode", "=", "'same'", ",", "name", "=", "'block5_conv3'", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block5_pool'", ")", "(", "x", ")", "\n", "\n", "if", "include_top", ":", "\n", "# Classification block", "\n", "        ", "x", "=", "Flatten", "(", "name", "=", "'flatten'", ")", "(", "x", ")", "\n", "x", "=", "Dense", "(", "4096", ",", "activation", "=", "'relu'", ",", "name", "=", "'fc1'", ")", "(", "x", ")", "\n", "x", "=", "Dense", "(", "4096", ",", "activation", "=", "'relu'", ",", "name", "=", "'fc2'", ")", "(", "x", ")", "\n", "x", "=", "Dense", "(", "1000", ",", "activation", "=", "'softmax'", ",", "name", "=", "'predictions'", ")", "(", "x", ")", "\n", "\n", "# Create model", "\n", "", "model", "=", "Model", "(", "img_input", ",", "x", ")", "\n", "\n", "# load weights", "\n", "if", "weights", "==", "'imagenet'", ":", "\n", "        ", "print", "(", "'K.image_dim_ordering:'", ",", "K", ".", "image_dim_ordering", "(", ")", ")", "\n", "if", "K", ".", "image_dim_ordering", "(", ")", "==", "'th'", ":", "\n", "            ", "if", "include_top", ":", "\n", "                ", "weights_path", "=", "get_file", "(", "'vgg16_weights_th_dim_ordering_th_kernels.h5'", ",", "\n", "TH_WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "", "else", ":", "\n", "                ", "weights_path", "=", "get_file", "(", "'vgg16_weights_th_dim_ordering_th_kernels_notop.h5'", ",", "\n", "TH_WEIGHTS_PATH_NO_TOP", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "", "model", ".", "load_weights", "(", "weights_path", ")", "\n", "if", "K", ".", "backend", "(", ")", "==", "'tensorflow'", ":", "\n", "                ", "warnings", ".", "warn", "(", "'You are using the TensorFlow backend, yet you '", "\n", "'are using the Theano '", "\n", "'image dimension ordering convention '", "\n", "'(`image_dim_ordering=\"th\"`). '", "\n", "'For best performance, set '", "\n", "'`image_dim_ordering=\"tf\"` in '", "\n", "'your Keras config '", "\n", "'at ~/.keras/keras.json.'", ")", "\n", "convert_all_kernels_in_model", "(", "model", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "include_top", ":", "\n", "                ", "weights_path", "=", "get_file", "(", "'vgg16_weights_tf_dim_ordering_tf_kernels.h5'", ",", "\n", "TF_WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "", "else", ":", "\n", "                ", "weights_path", "=", "get_file", "(", "'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'", ",", "\n", "TF_WEIGHTS_PATH_NO_TOP", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "", "model", ".", "load_weights", "(", "weights_path", ")", "\n", "if", "K", ".", "backend", "(", ")", "==", "'theano'", ":", "\n", "                ", "convert_all_kernels_in_model", "(", "model", ")", "\n", "", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.vsumm_feat.save_keyframes": [[38, 52], ["int", "print", "open", "print", "int", "print", "enumerate", "print", "open.write", "cv2.imwrite", "str", "str", "str", "str"], "function", ["None"], ["def", "save_keyframes", "(", "frame_indices", ",", "summary_frames", ")", ":", "\n", "\t", "global", "sampling_rate", ",", "num_centroids", "\n", "if", "int", "(", "sys", ".", "argv", "[", "6", "]", ")", "==", "1", ":", "\n", "\t\t", "print", "(", "\"Saving frame indices\"", ")", "\n", "out_file", "=", "open", "(", "sys", ".", "argv", "[", "7", "]", "+", "\"frame_indices_\"", "+", "sys", ".", "argv", "[", "8", "]", "+", "'_'", "+", "str", "(", "num_centroids", ")", "+", "\"_\"", "+", "str", "(", "sampling_rate", ")", "+", "\".txt\"", ",", "'w'", ")", "\n", "for", "idx", "in", "frame_indices", ":", "\n", "\t\t\t", "out_file", ".", "write", "(", "str", "(", "idx", "*", "sampling_rate", ")", "+", "'\\n'", ")", "\n", "", "print", "(", "\"Saved indices\"", ")", "\n", "\n", "", "if", "int", "(", "sys", ".", "argv", "[", "5", "]", ")", "==", "1", ":", "\n", "            ", "print", "(", "\"Saving frames\"", ")", "\n", "for", "i", ",", "frame", "in", "enumerate", "(", "summary_frames", ")", ":", "\n", "                ", "cv2", ".", "imwrite", "(", "str", "(", "sys", ".", "argv", "[", "7", "]", ")", "+", "\"keyframes/frame%d.jpg\"", "%", "i", ",", "frame", ")", "\n", "", "print", "(", "\"Frames saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.vsumm_feat.main": [[53, 125], ["print", "cv2.VideoCapture", "print", "cv2.VideoCapture.isOpened", "numpy.array", "print", "print", "get_video_feat.get_cnn_feat", "print", "print", "int", "sklearn.mixture.GaussianMixture().fit", "print", "print", "GaussianMixture().fit.transform", "range", "sorted", "print", "os.path.abspath", "sys.argv[].split", "int", "int", "len", "print", "print", "print", "sorted.append", "vsumm_feat.save_keyframes", "os.path.expanduser", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "np.array.append", "str", "sklearn.mixture.GaussianMixture", "numpy.argmin", "len", "numpy.asarray", "video_address[].split", "int", "int", "len", "len", "scipy.io.loadmat().get", "numpy.argmin", "scipy.io.loadmat", "len"], "function", ["home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.get_video_feat.get_cnn_feat", "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.vsumm_feat.save_keyframes"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "global", "num_bins", ",", "sampling_rate", ",", "num_centroids", ",", "percent", "\n", "print", "(", "\"Opening video!\"", ")", "\n", "capture", "=", "cv2", ".", "VideoCapture", "(", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", ")", "\n", "print", "(", "\"Video opened\\nChoosing frames\"", ")", "\n", "\n", "#choosing the subset of frames from which video summary will be generateed", "\n", "frames", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "(", "capture", ".", "isOpened", "(", ")", ")", ":", "\n", "        ", "if", "i", "%", "sampling_rate", "==", "0", ":", "\n", "            ", "capture", ".", "set", "(", "1", ",", "i", ")", "\n", "# print i", "\n", "ret", ",", "frame", "=", "capture", ".", "read", "(", ")", "\n", "if", "frame", "is", "None", ":", "\n", "                ", "break", "\n", "#im = np.expand_dims(im, axis=0) #convert to (1, width, height, depth)", "\n", "# print frame.shape", "\n", "", "frames", ".", "append", "(", "np", ".", "asarray", "(", "frame", ")", ")", "\n", "", "i", "+=", "1", "\n", "", "frames", "=", "np", ".", "array", "(", "frames", ")", "#convert to (num_frames, width, height, depth)", "\n", "\n", "print", "(", "\"Frames chosen\"", ")", "\n", "print", "(", "\"Length of video %d\"", "%", "frames", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# REPLACE WITH APPROPRIATE FEATURES", "\n", "features", "=", "get_cnn_feat", "(", "frames", ")", "\n", "print", "(", "\"Shape of features \"", "+", "str", "(", "features", ".", "shape", ")", ")", "\n", "\n", "# clustering: defaults to using the features", "\n", "print", "(", "\"Clustering\"", ")", "\n", "\n", "# converting percentage to actual number", "\n", "num_centroids", "=", "int", "(", "percent", "*", "frames", ".", "shape", "[", "0", "]", "*", "sampling_rate", "/", "100", ")", "\n", "\n", "# choose number of centroids for clustering from user required frames (specified in GT folder for each video)", "\n", "if", "percent", "==", "-", "1", ":", "\n", "    \t", "video_address", "=", "sys", ".", "argv", "[", "1", "]", ".", "split", "(", "'/'", ")", "\n", "gt_file", "=", "video_address", "[", "len", "(", "video_address", ")", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.mat'", "\n", "video_address", "[", "len", "(", "video_address", ")", "-", "1", "]", "=", "gt_file", "\n", "video_address", "[", "len", "(", "video_address", ")", "-", "2", "]", "=", "'GT'", "\n", "gt_file", "=", "'/'", ".", "join", "(", "video_address", ")", "\n", "num_frames", "=", "int", "(", "scipy", ".", "io", ".", "loadmat", "(", "gt_file", ")", ".", "get", "(", "'user_score'", ")", ".", "shape", "[", "0", "]", ")", "\n", "# automatic summary sizing: summary assumed to be 1/10 of original video", "\n", "num_centroids", "=", "int", "(", "0.1", "*", "num_frames", ")", "\n", "\n", "", "if", "len", "(", "frames", ")", "<", "num_centroids", ":", "\n", "        ", "print", "(", "\"Samples too less to generate such a large summary\"", ")", "\n", "print", "(", "\"Changing to maximum possible centroids\"", ")", "\n", "num_centroids", "=", "frames", ".", "shape", "[", "0", "]", "\n", "\n", "#kmeans=KMeans(n_clusters=num_centroids).fit(features)", "\n", "", "kmeans", "=", "GaussianMixture", "(", "n_components", "=", "num_centroids", ")", ".", "fit", "(", "features", ")", "\n", "print", "(", "\"Done Clustering!\"", ")", "\n", "\n", "print", "(", "\"Generating summary frames\"", ")", "\n", "summary_frames", "=", "[", "]", "\n", "\n", "# transforms into cluster-distance space (n_cluster dimensional)", "\n", "features_transform", "=", "kmeans", ".", "transform", "(", "features", ")", "\n", "frame_indices", "=", "[", "]", "\n", "for", "cluster", "in", "range", "(", "features_transform", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "print", "(", "\"Frame number: %d\"", "%", "(", "np", ".", "argmin", "(", "features_transform", ".", "T", "[", "cluster", "]", ")", "*", "sampling_rate", ")", ")", "\n", "frame_indices", ".", "append", "(", "np", ".", "argmin", "(", "features_transform", ".", "T", "[", "cluster", "]", ")", ")", "\n", "\n", "# frames generated in sequence from original video", "\n", "", "frame_indices", "=", "sorted", "(", "frame_indices", ")", "\n", "summary_frames", "=", "[", "frames", "[", "i", "]", "for", "i", "in", "frame_indices", "]", "\n", "print", "(", "\"Generated summary\"", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", ">", "5", "and", "(", "int", "(", "sys", ".", "argv", "[", "5", "]", ")", "==", "1", "or", "int", "(", "sys", ".", "argv", "[", "6", "]", ")", "==", "1", ")", ":", "\n", "        ", "save_keyframes", "(", "frame_indices", ",", "summary_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.get_video_feat.get_cnn_feat": [[13, 39], ["sklearn.decomposition.PCA", "numpy.array", "vgg16.VGG16", "keras.models.Model", "numpy.ndarray", "sklearn.decomposition.PCA.fit_transform", "cv2.resize().astype", "numpy.expand_dims", "np.array.append", "keras.models.Model.predict", "numpy.asarray", "cv2.resize", "vgg16.VGG16.get_layer"], "function", ["home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.vgg16.VGG16"], ["def", "get_cnn_feat", "(", "frames_raw", ")", ":", "\n", "    ", "frames", "=", "[", "]", "\n", "pca", "=", "PCA", "(", "n_components", "=", "500", ")", "\n", "for", "im", "in", "frames_raw", ":", "\n", "#print im.shape", "\n", "        ", "im", "=", "cv2", ".", "resize", "(", "im", ",", "(", "224", ",", "224", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "im", "[", ":", ",", ":", ",", "0", "]", "-=", "103.939", "\n", "im", "[", ":", ",", ":", ",", "1", "]", "-=", "116.779", "\n", "im", "[", ":", ",", ":", ",", "2", "]", "-=", "123.68", "\n", "# print im.shape", "\n", "im", "=", "np", ".", "expand_dims", "(", "im", ",", "axis", "=", "0", ")", "\n", "#print im.shape", "\n", "frames", ".", "append", "(", "np", ".", "asarray", "(", "im", ")", ")", "\n", "", "frames", "=", "np", ".", "array", "(", "frames", ")", "\n", "#print frames.shape", "\n", "\n", "base_model", "=", "VGG16", "(", "weights", "=", "'imagenet'", ",", "include_top", "=", "True", ")", "\n", "model", "=", "Model", "(", "input", "=", "base_model", ".", "input", ",", "output", "=", "base_model", ".", "get_layer", "(", "'fc2'", ")", ".", "output", ")", "\n", "\n", "i", "=", "0", "\n", "features", "=", "np", ".", "ndarray", "(", "(", "frames", ".", "shape", "[", "0", "]", ",", "4096", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "x", "in", "frames", ":", "\n", "#print x.shape", "\n", "        ", "features", "[", "i", ",", ":", "]", "=", "model", ".", "predict", "(", "x", ")", "\n", "i", "+=", "1", "\n", "", "return", "pca", ".", "fit_transform", "(", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.get_video_feat.get_color_hist": [[40, 54], ["print", "numpy.asarray", "print", "np.asarray.append", "cv2.calcHist", "numpy.asarray().flatten", "str", "enumerate", "int", "numpy.asarray"], "function", ["None"], ["", "def", "get_color_hist", "(", "frames_raw", ",", "num_bins", ")", ":", "\n", "    ", "print", "(", "\"Generating linear Histrograms using OpenCV\"", ")", "\n", "channels", "=", "[", "'b'", ",", "'g'", ",", "'r'", "]", "\n", "\n", "hist", "=", "[", "]", "\n", "for", "frame", "in", "frames_raw", ":", "\n", "        ", "feature_value", "=", "[", "cv2", ".", "calcHist", "(", "[", "frame", "]", ",", "[", "i", "]", ",", "None", ",", "[", "int", "(", "num_bins", ")", "]", ",", "[", "0", ",", "256", "]", ")", "for", "i", ",", "col", "in", "enumerate", "(", "channels", ")", "]", "\n", "hist", ".", "append", "(", "np", ".", "asarray", "(", "feature_value", ")", ".", "flatten", "(", ")", ")", "\n", "\n", "", "hist", "=", "np", ".", "asarray", "(", "hist", ")", "\n", "#print \"Done generating!\"", "\n", "print", "(", "\"Shape of histogram: \"", "+", "str", "(", "hist", ".", "shape", ")", ")", "\n", "\n", "return", "hist", "", "", ""]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.imagenet_utils.preprocess_input": [[11, 29], ["keras.backend.image_dim_ordering"], "function", ["None"], ["def", "preprocess_input", "(", "x", ",", "dim_ordering", "=", "'default'", ")", ":", "\n", "    ", "if", "dim_ordering", "==", "'default'", ":", "\n", "        ", "dim_ordering", "=", "K", ".", "image_dim_ordering", "(", ")", "\n", "", "assert", "dim_ordering", "in", "{", "'tf'", ",", "'th'", "}", "\n", "\n", "if", "dim_ordering", "==", "'th'", ":", "\n", "        ", "x", "[", ":", ",", "0", ",", ":", ",", ":", "]", "-=", "103.939", "\n", "x", "[", ":", ",", "1", ",", ":", ",", ":", "]", "-=", "116.779", "\n", "x", "[", ":", ",", "2", ",", ":", ",", ":", "]", "-=", "123.68", "\n", "# 'RGB'->'BGR'", "\n", "x", "=", "x", "[", ":", ",", ":", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "        ", "x", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-=", "103.939", "\n", "x", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-=", "116.779", "\n", "x", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-=", "123.68", "\n", "# 'RGB'->'BGR'", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.VSUMM.imagenet_utils.decode_predictions": [[31, 49], ["ValueError", "keras.utils.data_utils.get_file", "json.load", "results.append", "len", "open", "str", "pred.argsort", "tuple", "str"], "function", ["None"], ["", "def", "decode_predictions", "(", "preds", ",", "top", "=", "5", ")", ":", "\n", "    ", "global", "CLASS_INDEX", "\n", "if", "len", "(", "preds", ".", "shape", ")", "!=", "2", "or", "preds", ".", "shape", "[", "1", "]", "!=", "1000", ":", "\n", "        ", "raise", "ValueError", "(", "'`decode_predictions` expects '", "\n", "'a batch of predictions '", "\n", "'(i.e. a 2D array of shape (samples, 1000)). '", "\n", "'Found array with shape: '", "+", "str", "(", "preds", ".", "shape", ")", ")", "\n", "", "if", "CLASS_INDEX", "is", "None", ":", "\n", "        ", "fpath", "=", "get_file", "(", "'imagenet_class_index.json'", ",", "\n", "CLASS_INDEX_PATH", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "CLASS_INDEX", "=", "json", ".", "load", "(", "open", "(", "fpath", ")", ")", "\n", "", "results", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "        ", "top_indices", "=", "pred", ".", "argsort", "(", ")", "[", "-", "top", ":", "]", "[", ":", ":", "-", "1", "]", "\n", "result", "=", "[", "tuple", "(", "CLASS_INDEX", "[", "str", "(", "i", ")", "]", ")", "+", "(", "pred", "[", "i", "]", ",", ")", "for", "i", "in", "top_indices", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.shruti-jadon_Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming.Shot_Boundary.scc.strongly_connected_components_tree": [[2, 110], ["set", "len", "stack.append", "set", "set.update", "scc.strongly_connected_components_tree.dfs"], "function", ["None"], ["def", "strongly_connected_components_tree", "(", "vertices", ",", "edges", ")", ":", "\n", "    ", "\"\"\"\n    Find the strongly connected components of a directed graph.\n\n    Uses a recursive linear-time algorithm described by Tarjan [2]_ to find all\n    strongly connected components of a directed graph.\n\n    Parameters\n    ----------\n    vertices : iterable\n        A sequence or other iterable of vertices.  Each vertex should be\n        hashable.\n\n    edges : mapping\n        Dictionary (or mapping) that maps each vertex v to an iterable of the\n        vertices w that are linked to v by a directed edge (v, w).\n\n    Returns\n    -------\n    components : iterator\n        An iterator that yields sets of vertices.  Each set produced gives the\n        vertices of one strongly connected component.\n\n    Raises\n    ------\n    RuntimeError\n        If the graph is deep enough that the algorithm exceeds Python's\n        recursion limit.\n\n    Notes\n    -----\n    The algorithm has running time proportional to the total number of vertices\n    and edges.  It's practical to use this algorithm on graphs with hundreds of\n    thousands of vertices and edges.\n\n    The algorithm is recursive.  Deep graphs may cause Python to exceed its\n    recursion limit.\n\n    `vertices` will be iterated over exactly once, and `edges[v]` will be\n    iterated over exactly once for each vertex `v`.  `edges[v]` is permitted to\n    specify the same vertex multiple times, and it's permissible for `edges[v]`\n    to include `v` itself.  (In graph-theoretic terms, loops and multiple edges\n    are permitted.)\n\n    References\n    ----------\n    .. [1] Harold N. Gabow, \"Path-based depth-first search for strong and\n       biconnected components,\" Inf. Process. Lett. 74 (2000) 107--114.\n\n    .. [2] Robert E. Tarjan, \"Depth-first search and linear graph algorithms,\"\n       SIAM J.Comput. 1 (2) (1972) 146--160.\n\n    Examples\n    --------\n    Example from Gabow's paper [1]_.\n\n    >>> vertices = [1, 2, 3, 4, 5, 6]\n    >>> edges = {1: [2, 3], 2: [3, 4], 3: [], 4: [3, 5], 5: [2, 6], 6: [3, 4]}\n    >>> for scc in strongly_connected_components_tree(vertices, edges):\n    ...     print(scc)\n    ...\n    set([3])\n    set([2, 4, 5, 6])\n    set([1])\n\n    Example from Tarjan's paper [2]_.\n\n    >>> vertices = [1, 2, 3, 4, 5, 6, 7, 8]\n    >>> edges = {1: [2], 2: [3, 8], 3: [4, 7], 4: [5],\n    ...          5: [3, 6], 6: [], 7: [4, 6], 8: [1, 7]}\n    >>> for scc in  strongly_connected_components_tree(vertices, edges):\n    ...     print(scc)\n    ...\n    set([6])\n    set([3, 4, 5, 7])\n    set([8, 1, 2])\n\n    \"\"\"", "\n", "identified", "=", "set", "(", ")", "\n", "stack", "=", "[", "]", "\n", "index", "=", "{", "}", "\n", "lowlink", "=", "{", "}", "\n", "\n", "def", "dfs", "(", "v", ")", ":", "\n", "        ", "index", "[", "v", "]", "=", "len", "(", "stack", ")", "\n", "stack", ".", "append", "(", "v", ")", "\n", "lowlink", "[", "v", "]", "=", "index", "[", "v", "]", "\n", "\n", "for", "w", "in", "edges", "[", "v", "]", ":", "\n", "            ", "if", "w", "not", "in", "index", ":", "\n", "# For Python >= 3.3, replace with \"yield from dfs(w)\"", "\n", "                ", "for", "scc", "in", "dfs", "(", "w", ")", ":", "\n", "                    ", "yield", "scc", "\n", "", "lowlink", "[", "v", "]", "=", "min", "(", "lowlink", "[", "v", "]", ",", "lowlink", "[", "w", "]", ")", "\n", "", "elif", "w", "not", "in", "identified", ":", "\n", "                ", "lowlink", "[", "v", "]", "=", "min", "(", "lowlink", "[", "v", "]", ",", "lowlink", "[", "w", "]", ")", "\n", "\n", "", "", "if", "lowlink", "[", "v", "]", "==", "index", "[", "v", "]", ":", "\n", "            ", "scc", "=", "set", "(", "stack", "[", "index", "[", "v", "]", ":", "]", ")", "\n", "del", "stack", "[", "index", "[", "v", "]", ":", "]", "\n", "identified", ".", "update", "(", "scc", ")", "\n", "yield", "scc", "\n", "\n", "", "", "for", "v", "in", "vertices", ":", "\n", "        ", "if", "v", "not", "in", "index", ":", "\n", "# For Python >= 3.3, replace with \"yield from dfs(v)\"", "\n", "            ", "for", "scc", "in", "dfs", "(", "v", ")", ":", "\n", "                ", "yield", "scc", "", "", "", "", "", ""]]}