{"home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.build_dataloader": [[44, 55], ["data.TokenBucketSampler", "torch.utils.data.DataLoader"], "function", ["None"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.build_mlm_dataset": [[57, 68], ["data.ConcatDatasetWithLens", "data.MlmDatasetForVCR", "data.MlmDatasetForVCR", "zip"], "function", ["None"], ["", "def", "build_mlm_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "datasets", "=", "[", "MlmDatasetForVCR", "(", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "dataset", "=", "MlmDatasetForVCR", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.build_mrfr_dataset": [[70, 79], ["data.ConcatDatasetWithLens", "data.MrfrDatasetForVCR", "data.MrfrDatasetForVCR", "zip"], "function", ["None"], ["", "def", "build_mrfr_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrfr_collate_for_vcr", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.build_mrc_dataset": [[81, 90], ["data.ConcatDatasetWithLens", "data.MrcDatasetForVCR", "data.MrcDatasetForVCR", "zip"], "function", ["None"], ["", "def", "build_mrc_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrc_collate_for_vcr", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.load_img_feat": [[92, 111], ["db_list.split", "len", "data.DetectFeatLmdb"], "function", ["None"], ["", "def", "load_img_feat", "(", "db_list", ",", "all_img_dbs", ",", "opts", ")", ":", "\n", "    ", "db_", "=", "db_list", ".", "split", "(", "\";\"", ")", "\n", "assert", "len", "(", "db_", ")", "<=", "2", ",", "\"More than two img_dbs found\"", "\n", "gt_db_path", ",", "db_path", "=", "\"\"", ",", "\"\"", "\n", "for", "d", "in", "db_", ":", "\n", "        ", "if", "\"gt\"", "in", "d", ":", "\n", "            ", "gt_db_path", "=", "d", "\n", "", "else", ":", "\n", "            ", "db_path", "=", "d", "\n", "", "", "if", "gt_db_path", "!=", "\"\"", ":", "\n", "        ", "img_db_gt", "=", "DetectFeatLmdb", "(", "\n", "gt_db_path", ",", "-", "1", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "100", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "all_img_dbs", ".", "path2imgdb", "[", "gt_db_path", "]", "=", "img_db_gt", "\n", "", "else", ":", "\n", "        ", "img_db_gt", "=", "None", "\n", "", "img_db", "=", "all_img_dbs", "[", "db_path", "]", "if", "db_path", "!=", "\"\"", "else", "None", "\n", "all_img_dbs", ".", "path2imgdb", "[", "db_path", "]", "=", "img_db", "\n", "return", "img_db", ",", "img_db_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.create_dataloaders": [[113, 174], ["data.ImageLmdbGroup", "enumerate", "pretrain_vcr.load_img_feat", "task.startswith", "utils.logger.LOGGER.info", "pretrain_vcr.build_dataloader", "len", "len", "len", "len", "pretrain_vcr.load_img_feat", "img_db.append", "img_db_gt.append", "len", "len", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "data.VcrTxtTokLmdb", "pretrain_vcr.build_mlm_dataset", "task.startswith", "data.PrefetchLoader", "data.VcrTxtTokLmdb", "pretrain_vcr.build_mrfr_dataset", "task.startswith", "pretrain_vcr.build_mrc_dataset", "ValueError", "len", "horovod.torch.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mlm_dataset", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrfr_dataset", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrc_dataset"], ["", "def", "create_dataloaders", "(", "datasets", ",", "is_train", ",", "opts", ",", "all_img_dbs", "=", "None", ")", ":", "\n", "    ", "if", "all_img_dbs", "is", "None", ":", "\n", "        ", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "", "dataloaders", "=", "{", "}", "\n", "\n", "for", "dset", "in", "datasets", ":", "\n", "        ", "for", "vcr_task", "in", "[", "\"qa\"", ",", "\"qar\"", "]", ":", "\n", "            ", "if", "is_train", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "\n", "assert", "len", "(", "dset", "[", "'tasks'", "]", ")", "==", "len", "(", "dset", "[", "'mix_ratio'", "]", ")", "\n", "img_db", ",", "img_db_gt", "=", "[", "]", ",", "[", "]", "\n", "for", "img_path", "in", "dset", "[", "'img'", "]", ":", "\n", "                    ", "curr_img_db", ",", "curr_img_db_gt", "=", "load_img_feat", "(", "\n", "img_path", ",", "all_img_dbs", ",", "opts", ")", "\n", "img_db", ".", "append", "(", "curr_img_db", ")", "\n", "img_db_gt", ".", "append", "(", "curr_img_db_gt", ")", "\n", "", "", "else", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "==", "1", "\n", "img_db", ",", "img_db_gt", "=", "load_img_feat", "(", "\n", "dset", "[", "'img'", "]", "[", "0", "]", ",", "all_img_dbs", ",", "opts", ")", "\n", "\n", "", "for", "i", ",", "t", "in", "enumerate", "(", "dset", "[", "'tasks'", "]", ")", ":", "\n", "                ", "task", "=", "f'{t}_{dset[\"name\"]}'", "\n", "\n", "if", "is_train", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} train dataset with vcr_{vcr_task}, \"", "\n", "f\"{dset['db']}, {[img.img_dir for img in img_db]},\"", "\n", "f\"{[img.img_dir for img in img_db_gt]}\"", ")", "\n", "txt_db", "=", "[", "VcrTxtTokLmdb", "(", "path", ",", "opts", ".", "max_txt_len", ",", "\n", "task", "=", "vcr_task", ")", "\n", "for", "path", "in", "dset", "[", "'db'", "]", "]", "\n", "", "else", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} val dataset with vcr_{vcr_task}, \"", "\n", "f\"{dset['db']}, {img_db.img_dir},\"", "\n", "f\"{img_db_gt.img_dir}\"", ")", "\n", "txt_db", "=", "VcrTxtTokLmdb", "(", "dset", "[", "'db'", "]", "[", "0", "]", ",", "-", "1", ",", "\n", "task", "=", "vcr_task", ")", "\n", "\n", "", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n", "                    ", "dataset", "=", "build_mlm_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "                    ", "dataset", "=", "build_mrfr_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "                    ", "dataset", "=", "build_mrc_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"{len(dataset[0])*hvd.size()} samples loaded\"", ")", "\n", "loader", "=", "build_dataloader", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "if", "is_train", ":", "\n", "                    ", "ratio", "=", "dset", "[", "'mix_ratio'", "]", "[", "i", "]", "\n", "dataloaders", "[", "task", "]", "=", "(", "loader", ",", "ratio", ")", "\n", "", "else", ":", "\n", "                    ", "dataloaders", "[", "task", "]", "=", "PrefetchLoader", "(", "loader", ")", "\n", "", "", "", "", "return", "dataloaders", ",", "all_img_dbs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.main": [[176, 344], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "all", "pretrain_vcr.create_dataloaders", "pretrain_vcr.create_dataloaders", "data.MetaLoader", "data.PrefetchLoader", "model.pretrain_vcr.UniterForPretrainingForVCR.from_pretrained", "UniterForPretrainingForVCR.from_pretrained.init_type_embedding", "UniterForPretrainingForVCR.from_pretrained.init_word_embedding", "UniterForPretrainingForVCR.from_pretrained.to", "UniterForPretrainingForVCR.from_pretrained.train", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "time.time", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "enumerate", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "json.load", "torch.load", "horovod.torch.load", "utils.logger.RunningMeter", "batch[].size", "UniterForPretrainingForVCR.from_pretrained.", "loss.mean.size", "loss.mean.mean", "utils.logger.LOGGER.info", "pretrain_vcr.validate", "utils.misc.NoOp.save", "horovod.torch.rank", "os.path.join", "os.path.join", "os.path.join", "open", "enumerate", "len", "train_dataloaders.keys", "name.split", "apex.amp.scale_loss", "scaled_loss.backward", "loss.mean.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "UniterForPretrainingForVCR.from_pretrained.parameters", "train_dataloaders.keys", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "train_dataloaders.keys", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "pretrain_vcr.validate", "utils.misc.NoOp.save", "json.load", "float", "apex.amp.master_params", "all", "sum", "int", "sum", "int", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "open", "UniterForPretrainingForVCR.from_pretrained.parameters", "task2loss.values", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.create_dataloaders", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.create_dataloaders", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_word_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "args", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "all_dbs", "=", "[", "db", "for", "datasets", "in", "[", "opts", ".", "train_datasets", ",", "opts", ".", "val_datasets", "]", "\n", "for", "dset", "in", "datasets", "for", "db", "in", "dset", "[", "'db'", "]", "]", "\n", "\n", "tokenizer", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "assert", "all", "(", "tokenizer", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "\n", "# build data loaders", "\n", "train_dataloaders", ",", "all_img_dbs", "=", "create_dataloaders", "(", "\n", "opts", ".", "train_datasets", ",", "True", ",", "opts", ")", "\n", "val_dataloaders", ",", "_", "=", "create_dataloaders", "(", "\n", "opts", ".", "val_datasets", ",", "False", ",", "opts", ",", "all_img_dbs", ")", "\n", "meta_loader", "=", "MetaLoader", "(", "train_dataloaders", ",", "\n", "accum_steps", "=", "opts", ".", "gradient_accumulation_steps", ",", "\n", "distributed", "=", "n_gpu", ">", "1", ")", "\n", "meta_loader", "=", "PrefetchLoader", "(", "meta_loader", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "", "model", "=", "UniterForPretrainingForVCR", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "img_label_dim", "=", "IMG_LABEL_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "init_word_embedding", "(", "NUM_SPECIAL_TOKENS", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "task2scaler", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "train_dataloaders", ".", "keys", "(", ")", ")", "}", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "num_losses", "=", "len", "(", "task2scaler", ")", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "# to compute training statistics", "\n", "task2loss", "=", "{", "task", ":", "RunningMeter", "(", "f'loss/{task}'", ")", "\n", "for", "task", "in", "train_dataloaders", ".", "keys", "(", ")", "}", "\n", "\n", "n_examples", "=", "defaultdict", "(", "int", ")", "\n", "n_in_units", "=", "defaultdict", "(", "int", ")", "\n", "n_loss_units", "=", "defaultdict", "(", "int", ")", "\n", "grad_norm", "=", "0", "\n", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "for", "step", ",", "(", "name", ",", "batch", ")", "in", "enumerate", "(", "meta_loader", ")", ":", "\n", "# forward pass", "\n", "        ", "n_examples", "[", "name", "]", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "n_in_units", "[", "name", "]", "+=", "(", "batch", "[", "'attn_masks'", "]", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "task", "=", "name", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "loss", "=", "model", "(", "batch", ",", "task", "=", "task", ",", "compute_loss", "=", "True", ")", "\n", "n_loss_units", "[", "name", "]", "+=", "loss", ".", "size", "(", "0", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "# loss is not normalized in model", "\n", "\n", "# backward pass", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", ",", "\n", "loss_id", "=", "task2scaler", "[", "name", "]", ")", "as", "scaled_loss", ":", "\n", "            ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "", "task2loss", "[", "name", "]", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# optimizer update and logging", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "            ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "{", "ll", ".", "name", ":", "ll", ".", "val", "\n", "for", "ll", "in", "task2loss", ".", "values", "(", ")", "\n", "if", "ll", ".", "val", "is", "not", "None", "}", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                ", "LOGGER", ".", "info", "(", "f'==============Step {global_step}==============='", ")", "\n", "for", "t", "in", "train_dataloaders", ".", "keys", "(", ")", ":", "\n", "                    ", "assert", "all", "(", "tt", "==", "t", "for", "tt", "in", "all_gather_list", "(", "t", ")", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", "[", "t", "]", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "tot_in", "=", "sum", "(", "all_gather_list", "(", "n_in_units", "[", "t", "]", ")", ")", "\n", "in_per_sec", "=", "int", "(", "tot_in", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "tot_l", "=", "sum", "(", "all_gather_list", "(", "n_loss_units", "[", "t", "]", ")", ")", "\n", "l_per_sec", "=", "int", "(", "tot_l", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{t}: {tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_ex_per_s'", ",", "ex_per_sec", ",", "\n", "global_step", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_in_per_s'", ",", "in_per_sec", ",", "\n", "global_step", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_loss_per_s'", ",", "l_per_sec", ",", "\n", "global_step", ")", "\n", "", "LOGGER", ".", "info", "(", "'==============================================='", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f'Step {global_step}: start validation'", ")", "\n", "validate", "(", "model", ",", "val_dataloaders", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "", "if", "global_step", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "LOGGER", ".", "info", "(", "f'Step {global_step}: start validation'", ")", "\n", "validate", "(", "model", ",", "val_dataloaders", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.validate": [[346, 362], ["model.eval", "val_dataloaders.items", "model.train", "utils.logger.LOGGER.info", "task.startswith", "utils.logger.TB_LOGGER.log_scaler_dict", "pretrain_vcr.validate_mlm", "task.startswith", "pretrain_vcr.validate_mrfr", "task.startswith", "validate_mrc.items", "pretrain_vcr.validate_mrc", "ValueError", "validate_mrc.items"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mlm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrfr", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrc"], ["", "", "def", "validate", "(", "model", ",", "val_dataloaders", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "for", "task", ",", "loader", "in", "val_dataloaders", ".", "items", "(", ")", ":", "\n", "        ", "LOGGER", ".", "info", "(", "f\"validate on {task} task\"", ")", "\n", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n", "            ", "val_log", "=", "validate_mlm", "(", "model", ",", "loader", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "            ", "val_log", "=", "validate_mrfr", "(", "model", ",", "loader", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "            ", "val_log", "=", "validate_mrc", "(", "model", ",", "loader", ",", "task", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "", "val_log", "=", "{", "f'{task}_{k}'", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "\n", "{", "f'valid_{task}/{k}'", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.validate_mlm": [[364, 391], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "utils.logger.LOGGER.info", "model", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "labels.numel", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "int", "model.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mlm", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MLM validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_correct", "=", "0", "\n", "n_word", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "task", "=", "'mlm'", ",", "compute_loss", "=", "False", ")", "\n", "labels", "=", "batch", "[", "'txt_labels'", "]", "\n", "labels", "=", "labels", "[", "labels", "!=", "-", "1", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "labels", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_correct", "+=", "(", "scores", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word", "+=", "labels", ".", "numel", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "n_correct", "=", "sum", "(", "all_gather_list", "(", "n_correct", ")", ")", "\n", "n_word", "=", "sum", "(", "all_gather_list", "(", "n_word", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_word", "\n", "acc", "=", "n_correct", "/", "n_word", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'acc'", ":", "acc", ",", "\n", "'tok_per_s'", ":", "n_word", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"acc: {acc*100:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.accuracy_count": [[393, 398], ["out.max"], "function", ["None"], ["", "def", "accuracy_count", "(", "out", ",", "labels", ")", ":", "\n", "    ", "outputs", "=", "out", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "mask", "=", "labels", "!=", "-", "1", "\n", "n_correct", "=", "(", "outputs", "==", "labels", ")", ".", "masked_select", "(", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.validate_mrfr": [[400, 419], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "utils.logger.LOGGER.info", "model", "batch[].sum().item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "model.sum().item", "batch[].sum", "int", "model.sum"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mrfr", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MRFR validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_feat", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "loss", "=", "model", "(", "batch", ",", "task", "=", "'mrfr'", ",", "compute_loss", "=", "True", ")", "\n", "val_loss", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "IMG_DIM", "\n", "n_feat", "+=", "batch", "[", "'img_mask_tgt'", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "n_feat", "=", "sum", "(", "all_gather_list", "(", "n_feat", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_feat", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'feat_per_s'", ":", "n_feat", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"loss: {val_loss:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.validate_mrc": [[421, 461], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "utils.logger.LOGGER.info", "model", "F.cross_entropy.item", "batch[].sum().item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "torch.nn.functional.log_softmax", "torch.nn.functional.kl_div", "pretrain_vcr.compute_accuracy_for_soft_targets", "torch.nn.functional.cross_entropy", "pretrain_vcr.compute_accuracy_for_soft_targets", "batch[].sum", "int", "label_targets[].max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.compute_accuracy_for_soft_targets", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.compute_accuracy_for_soft_targets"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mrc", "(", "model", ",", "val_loader", ",", "task", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MRC validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_feat", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "tot_score", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "prediction_soft_label", "=", "model", "(", "\n", "batch", ",", "task", "=", "task", ",", "compute_loss", "=", "False", ")", "\n", "if", "\"kl\"", "in", "task", ":", "\n", "            ", "prediction_soft_label", "=", "F", ".", "log_softmax", "(", "\n", "prediction_soft_label", ",", "dim", "=", "-", "1", ")", "\n", "label_targets", "=", "batch", "[", "'label_targets'", "]", "\n", "loss", "=", "F", ".", "kl_div", "(", "\n", "prediction_soft_label", ",", "label_targets", ",", "reduction", "=", "'sum'", ")", "\n", "tot_score", "+=", "compute_accuracy_for_soft_targets", "(", "\n", "prediction_soft_label", ",", "label_targets", ")", "\n", "", "else", ":", "\n", "# background class should not be the target", "\n", "            ", "cls_label_targets", "=", "label_targets", "[", ":", ",", "1", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "+", "1", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "prediction_soft_label", ",", "cls_label_targets", ",", "\n", "ignore_index", "=", "0", ",", "reduction", "=", "'sum'", ")", "\n", "tot_score", "+=", "compute_accuracy_for_soft_targets", "(", "\n", "prediction_soft_label", "[", ":", ",", "1", ":", "]", ",", "label_targets", "[", ":", ",", "1", ":", "]", ")", "\n", "", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_feat", "+=", "batch", "[", "'img_mask_tgt'", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_feat", "=", "sum", "(", "all_gather_list", "(", "n_feat", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_feat", "\n", "val_acc", "=", "tot_score", "/", "n_feat", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'acc'", ":", "val_acc", ",", "\n", "'feat_per_s'", ":", "n_feat", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain_vcr.compute_accuracy_for_soft_targets": [[463, 468], ["out.max", "labels.max"], "function", ["None"], ["", "def", "compute_accuracy_for_soft_targets", "(", "out", ",", "labels", ")", ":", "\n", "    ", "outputs", "=", "out", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "labels", "=", "labels", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "# argmax", "\n", "n_correct", "=", "(", "outputs", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_re.create_dataloader": [[40, 62], ["data.DetectFeatLmdb", "data.ReTxtTokLmdb", "data.sampler.DistributedSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "horovod.torch.size", "horovod.torch.rank", "data.ReDataset", "data.re_collate", "data.ReEvalDataset", "data.re_eval_collate"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.re_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.re_eval_collate"], ["def", "create_dataloader", "(", "img_path", ",", "txt_path", ",", "batch_size", ",", "is_train", ",", "\n", "dset_cls", ",", "collate_fn", ",", "opts", ")", ":", "\n", "    ", "img_db_type", "=", "\"gt\"", "if", "\"coco_gt\"", "in", "img_path", "else", "\"det\"", "\n", "conf_th", "=", "-", "1", "if", "img_db_type", "==", "\"gt\"", "else", "opts", ".", "conf_th", "\n", "num_bb", "=", "100", "if", "img_db_type", "==", "\"gt\"", "else", "opts", ".", "num_bb", "\n", "img_db", "=", "DetectFeatLmdb", "(", "img_path", ",", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "txt_db", "=", "ReTxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", "if", "is_train", "else", "-", "1", ")", "\n", "if", "is_train", ":", "\n", "        ", "dset", "=", "dset_cls", "(", "txt_db", ",", "img_db", ")", "\n", "", "else", ":", "\n", "        ", "dset", "=", "dset_cls", "(", "txt_db", ",", "img_db", ",", "use_gt_feat", "=", "img_db_type", "==", "\"gt\"", ")", "\n", "", "batch_size", "=", "(", "opts", ".", "train_batch_size", "if", "is_train", "\n", "else", "opts", ".", "val_batch_size", ")", "\n", "sampler", "=", "DistributedSampler", "(", "dset", ",", "num_replicas", "=", "hvd", ".", "size", "(", ")", ",", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", ",", "shuffle", "=", "False", ")", "\n", "dataloader", "=", "DataLoader", "(", "dset", ",", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "dataloader", "=", "PrefetchLoader", "(", "dataloader", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_re.build_optimizer": [[64, 100], ["OptimCls", "model.named_parameters", "model.named_parameters", "ValueError", "any", "any", "any", "any"], "function", ["None"], ["", "def", "build_optimizer", "(", "model", ",", "opts", ")", ":", "\n", "    ", "\"\"\" Re linear may get larger learning rate \"\"\"", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'re_output'", "not", "in", "n", "]", "\n", "param_top", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'re_output'", "in", "n", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "# currently Adam only", "\n", "if", "opts", ".", "optim", "==", "'adam'", ":", "\n", "        ", "OptimCls", "=", "Adam", "\n", "", "elif", "opts", ".", "optim", "==", "'adamax'", ":", "\n", "        ", "OptimCls", "=", "Adamax", "\n", "", "elif", "opts", ".", "optim", "==", "'adamw'", ":", "\n", "        ", "OptimCls", "=", "AdamW", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid optimizer'", ")", "\n", "", "optimizer", "=", "OptimCls", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "opts", ".", "learning_rate", ",", "betas", "=", "opts", ".", "betas", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_re.main": [[102, 283], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "utils.logger.LOGGER.info", "train_re.create_dataloader", "train_re.create_dataloader", "all", "model.re.UniterForReferringExpressionComprehension.from_pretrained", "UniterForReferringExpressionComprehension.from_pretrained.to", "UniterForReferringExpressionComprehension.from_pretrained.train", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "train_re.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForReferringExpressionComprehension.from_pretrained.train", "time.time", "build_optimizer.zero_grad", "train_re.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "utils.logger.LOGGER.info", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "torch.load", "horovod.torch.load", "json.load", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "os.makedirs", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "len", "build_optimizer.step", "enumerate", "train_re.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "utils.logger.LOGGER.info", "create_dataloader.loader.dataset.shuffle", "open", "json.dump", "horovod.torch.rank", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "batch[].size", "UniterForReferringExpressionComprehension.from_pretrained.", "loss.sum.sum", "utils.logger.RunningMeter.", "utils.misc.NoOp.save", "UniterForReferringExpressionComprehension.from_pretrained.parameters", "apex.amp.scale_loss", "scaled_loss.backward", "loss.sum.item", "optim.get_lr_sched", "enumerate", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "build_optimizer.step", "build_optimizer.zero_grad", "utils.misc.NoOp.update", "json.load", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "open", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "UniterForReferringExpressionComprehension.from_pretrained.parameters", "ValueError", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "# train_examples = None", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.train_txt_db}, \"", "\n", "f\"{opts.train_img_db}\"", ")", "\n", "train_dataloader", "=", "create_dataloader", "(", "opts", ".", "train_img_db", ",", "opts", ".", "train_txt_db", ",", "\n", "opts", ".", "train_batch_size", ",", "True", ",", "\n", "ReDataset", ",", "re_collate", ",", "opts", ")", "\n", "val_dataloader", "=", "create_dataloader", "(", "opts", ".", "val_img_db", ",", "opts", ".", "val_txt_db", ",", "\n", "opts", ".", "val_batch_size", ",", "False", ",", "\n", "ReEvalDataset", ",", "re_eval_collate", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "all_dbs", "=", "[", "opts", ".", "train_txt_db", ",", "opts", ".", "val_txt_db", "]", "\n", "toker", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'toker'", "]", "\n", "assert", "all", "(", "toker", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'toker'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "model", "=", "UniterForReferringExpressionComprehension", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "loss", "=", "opts", ".", "train_loss", ",", "\n", "margin", "=", "opts", ".", "margin", ",", "\n", "hard_ratio", "=", "opts", ".", "hard_ratio", ",", "mlp", "=", "opts", ".", "mlp", ",", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "\n", "#  Apex", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ",", "'model_epoch'", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results'", ")", ")", "# store RE predictions", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataloader", ".", "dataset", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "best_val_acc", ",", "best_epoch", "=", "None", ",", "None", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "global_step", "==", "0", ":", "\n", "        ", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "while", "True", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "\n", "", "n_examples", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "sum", "(", ")", "# sum over vectorized loss TODO: investigate", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "\n", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                    ", "if", "i", "==", "0", "or", "i", "==", "1", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "*", "opts", ".", "lr_mul", "\n", "", "elif", "i", "==", "2", "or", "i", "==", "3", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", ")", "\n", "", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'============Step {global_step}============='", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "'==========================================='", ")", "\n", "\n", "# evaluate after each epoch", "\n", "", "", "", "val_log", ",", "_", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "\n", "# save model", "\n", "n_epoch", "+=", "1", "\n", "model_saver", ".", "save", "(", "model", ",", "n_epoch", ")", "\n", "LOGGER", ".", "info", "(", "f\"finished {n_epoch} epochs\"", ")", "\n", "\n", "# save best model", "\n", "if", "best_val_acc", "is", "None", "or", "val_log", "[", "'valid/acc'", "]", ">", "best_val_acc", ":", "\n", "            ", "best_val_acc", "=", "val_log", "[", "'valid/acc'", "]", "\n", "best_epoch", "=", "n_epoch", "\n", "model_saver", ".", "save", "(", "model", ",", "'best'", ")", "\n", "\n", "# shuffle training data for the next epoch", "\n", "", "train_dataloader", ".", "loader", ".", "dataset", ".", "shuffle", "(", ")", "\n", "\n", "# is training finished?", "\n", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "val_log", ",", "results", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'results_{global_step}_'", "\n", "f'rank{rank}_final.json'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "f'{global_step}_final'", ")", "\n", "\n", "# print best model", "\n", "LOGGER", ".", "info", "(", "\n", "f'best_val_acc = {best_val_acc*100:.2f}% at epoch {best_epoch}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_re.validate": [[285, 323], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "enumerate", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "model", "torch.argmax().cpu().detach().numpy", "horovod.torch.argmax().cpu().detach().numpy", "zip", "time.time", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "torch.argmax().cpu().detach", "horovod.torch.argmax().cpu().detach", "pred_box.tolist", "tgt_box.tolist", "val_dataloader.loader.dataset.computeIoU", "int", "int", "torch.argmax().cpu", "horovod.torch.argmax().cpu", "torch.argmax", "horovod.torch.argmax"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReEvalDataset.computeIoU"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_dataloader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running evaluation.\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "predictions", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_dataloader", ")", ":", "\n", "# inputs", "\n", "        ", "(", "tgt_box_list", ",", "obj_boxes_list", ",", "sent_ids", ")", "=", "(", "\n", "batch", "[", "'tgt_box'", "]", ",", "batch", "[", "'obj_boxes'", "]", ",", "batch", "[", "'sent_ids'", "]", ")", "\n", "# scores (n, max_num_bb)", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "ixs", "=", "torch", ".", "argmax", "(", "scores", ",", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# (n, )", "\n", "\n", "# pred_boxes", "\n", "for", "ix", ",", "obj_boxes", ",", "tgt_box", ",", "sent_id", "in", "zip", "(", "ixs", ",", "obj_boxes_list", ",", "tgt_box_list", ",", "sent_ids", ")", ":", "\n", "            ", "pred_box", "=", "obj_boxes", "[", "ix", "]", "\n", "predictions", "[", "int", "(", "sent_id", ")", "]", "=", "{", "\n", "'pred_box'", ":", "pred_box", ".", "tolist", "(", ")", ",", "\n", "'tgt_box'", ":", "tgt_box", ".", "tolist", "(", ")", "}", "\n", "if", "val_dataloader", ".", "loader", ".", "dataset", ".", "computeIoU", "(", "\n", "pred_box", ",", "tgt_box", ")", ">", ".5", ":", "\n", "                ", "tot_score", "+=", "1", "\n", "", "n_ex", "+=", "1", "\n", "\n", "", "", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/acc'", ":", "val_acc", ",", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "\n", "f\"validation ({n_ex} sents) finished in {int(tot_time)} seconds\"", "\n", "f\", accuracy: {val_acc*100:.2f}%\"", ")", "\n", "return", "val_log", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_ve.create_dataloader": [[42, 54], ["data.DetectFeatLmdb", "data.TxtTokLmdb", "data.TokenBucketSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "data.VeDataset", "data.ve_collate", "data.VeEvalDataset", "data.ve_eval_collate", "data.VeEvalDataset", "data.ve_eval_collate"], "function", ["None"], ["def", "create_dataloader", "(", "img_path", ",", "txt_path", ",", "batch_size", ",", "is_train", ",", "\n", "dset_cls", ",", "collate_fn", ",", "opts", ")", ":", "\n", "    ", "img_db", "=", "DetectFeatLmdb", "(", "img_path", ",", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "txt_db", "=", "TxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", "if", "is_train", "else", "-", "1", ")", "\n", "dset", "=", "dset_cls", "(", "txt_db", ",", "img_db", ")", "\n", "sampler", "=", "TokenBucketSampler", "(", "dset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "PrefetchLoader", "(", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_ve.main": [[56, 221], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "utils.logger.LOGGER.info", "train_ve.create_dataloader", "train_ve.create_dataloader", "train_ve.create_dataloader", "model.ve.UniterForVisualEntailment.from_pretrained", "UniterForVisualEntailment.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForVisualEntailment.from_pretrained.train", "time.time", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "torch.load", "horovod.torch.load", "json.load", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "pickle.dump", "os.makedirs", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "len", "enumerate", "utils.logger.LOGGER.info", "utils.misc.NoOp.save", "horovod.torch.rank", "open", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "batch[].size", "UniterForVisualEntailment.from_pretrained.", "utils.logger.RunningMeter.", "utils.logger.LOGGER.info", "train_ve.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "UniterForVisualEntailment.from_pretrained.parameters", "os.path.join", "model.mean", "batch[].size", "apex.amp.scale_loss", "scaled_loss.backward", "model.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "open", "json.dump", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "utils.misc.NoOp.save", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "utils.logger.LOGGER.info", "train_ve.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "UniterForVisualEntailment.from_pretrained.parameters", "open", "json.dump", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "# train_examples = None", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.train_txt_db}, \"", "\n", "f\"{opts.train_img_db}\"", ")", "\n", "train_dataloader", "=", "create_dataloader", "(", "opts", ".", "train_img_db", ",", "opts", ".", "train_txt_db", ",", "\n", "opts", ".", "train_batch_size", ",", "True", ",", "\n", "VeDataset", ",", "ve_collate", ",", "opts", ")", "\n", "val_dataloader", "=", "create_dataloader", "(", "opts", ".", "val_img_db", ",", "opts", ".", "val_txt_db", ",", "\n", "opts", ".", "val_batch_size", ",", "False", ",", "\n", "VeEvalDataset", ",", "ve_eval_collate", ",", "opts", ")", "\n", "test_dataloader", "=", "create_dataloader", "(", "opts", ".", "test_img_db", ",", "opts", ".", "test_txt_db", ",", "\n", "opts", ".", "val_batch_size", ",", "False", ",", "\n", "VeEvalDataset", ",", "ve_eval_collate", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "", "bert_model", "=", "json", ".", "load", "(", "open", "(", "f'{opts.train_txt_db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "if", "'bert'", "not", "in", "bert_model", ":", "\n", "        ", "bert_model", "=", "'bert-large-cased'", "# quick hack for glove exp", "\n", "", "model", "=", "UniterForVisualEntailment", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "state_dict", "=", "checkpoint", ",", "img_dim", "=", "IMG_DIM", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "pickle", ".", "dump", "(", "ans2label", ",", "\n", "open", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ",", "'ans2label.pkl'", ")", ",", "'wb'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results'", ")", ")", "# store VQA predictions", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataloader", ".", "dataset", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "n_examples", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "*", "batch", "[", "'targets'", "]", ".", "size", "(", "1", ")", "# instance-leval bce", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'============Step {global_step}============='", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "f'==========================================='", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "for", "split", ",", "loader", "in", "[", "(", "\"val\"", ",", "val_dataloader", ")", ",", "\n", "(", "\"test\"", ",", "test_dataloader", ")", "]", ":", "\n", "                        ", "LOGGER", ".", "info", "(", "f\"Step {global_step}: start running \"", "\n", "f\"validation on {split} split...\"", ")", "\n", "val_log", ",", "results", "=", "validate", "(", "\n", "model", ",", "loader", ",", "label2ans", ",", "split", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'{split}_results_{global_step}_'", "\n", "f'rank{rank}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "n_epoch", "+=", "1", "\n", "LOGGER", ".", "info", "(", "f\"Step {global_step}: finished {n_epoch} epochs\"", ")", "\n", "", "if", "opts", ".", "num_train_steps", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "for", "split", ",", "loader", "in", "[", "(", "\"val\"", ",", "val_dataloader", ")", ",", "\n", "(", "\"test\"", ",", "test_dataloader", ")", "]", ":", "\n", "            ", "LOGGER", ".", "info", "(", "f\"Step {global_step}: start running \"", "\n", "f\"validation on {split} split...\"", ")", "\n", "val_log", ",", "results", "=", "validate", "(", "model", ",", "loader", ",", "label2ans", ",", "split", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'{split}_results_{global_step}_'", "\n", "f'rank{rank}_final.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_ve.validate": [[223, 258], ["torch.no_grad", "horovod.torch.no_grad", "model.eval", "time.time", "enumerate", "sum", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "model", "torch.nn.functional.binary_cross_entropy_with_logits", "F.binary_cross_entropy_with_logits.item", "compute_score_with_logits().sum().item", "zip", "len", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "compute_score_with_logits().sum", "[].cpu().tolist", "int", "train_ve.compute_score_with_logits", "[].cpu", "model.max", "utils.misc.VE_IDX2ENT", "utils.misc.VE_IDX2ENT"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.compute_score_with_logits"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ",", "label2ans", ",", "split", "=", "'val'", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "val_loss", "=", "0", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "targets", "=", "batch", "[", "'targets'", "]", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "scores", ",", "targets", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tot_score", "+=", "compute_score_with_logits", "(", "scores", ",", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "answers", "=", "[", "label2ans", "[", "i", "]", "\n", "for", "i", "in", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", "\n", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", "\n", "qids", "=", "batch", "[", "'qids'", "]", "\n", "for", "qid", ",", "answer", "in", "zip", "(", "qids", ",", "answers", ")", ":", "\n", "            ", "results", "[", "qid", "]", "=", "answer", "\n", "", "n_ex", "+=", "len", "(", "qids", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "f'valid/{split}_loss'", ":", "val_loss", ",", "\n", "f'valid/{split}_acc'", ":", "val_acc", ",", "\n", "f'valid/{split}_ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_ve.compute_score_with_logits": [[260, 266], ["torch.zeros", "horovod.torch.zeros", "torch.zeros.scatter_", "torch.max", "horovod.torch.max", "logits.view", "labels.size"], "function", ["None"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ",", "device", "=", "labels", ".", "device", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.load_img_feat": [[34, 54], ["dir_list.split", "len", "data.DetectFeatLmdb", "data.DetectFeatLmdb"], "function", ["None"], ["def", "load_img_feat", "(", "dir_list", ",", "opts", ")", ":", "\n", "    ", "dir_", "=", "dir_list", ".", "split", "(", "\";\"", ")", "\n", "assert", "len", "(", "dir_", ")", "<=", "2", ",", "\"More than two img_dirs found\"", "\n", "img_db_gt", ",", "img_db", "=", "None", ",", "None", "\n", "gt_db_path", ",", "db_path", "=", "\"\"", ",", "\"\"", "\n", "for", "d", "in", "dir_", ":", "\n", "        ", "if", "\"gt\"", "in", "d", ":", "\n", "            ", "gt_db_path", "=", "d", "\n", "", "else", ":", "\n", "            ", "db_path", "=", "d", "\n", "", "", "if", "gt_db_path", "!=", "\"\"", ":", "\n", "        ", "img_db_gt", "=", "DetectFeatLmdb", "(", "\n", "gt_db_path", ",", "-", "1", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "100", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "", "if", "db_path", "!=", "\"\"", ":", "\n", "        ", "img_db", "=", "DetectFeatLmdb", "(", "\n", "db_path", ",", "opts", ".", "conf_th", ",", "\n", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "opts", ".", "num_bb", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "", "return", "img_db", ",", "img_db_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.save_for_submission": [[56, 84], ["numpy.stack", "pandas.DataFrame", "probs_df.set_index.set_index", "open", "json.load", "sorted", "os.path.join", "json.load.items", "ids_grp.append", "np.stack.append", "np.stack.reshape", "numpy.array().reshape", "range", "int", "range", "numpy.array", "item[].split"], "function", ["None"], ["", "def", "save_for_submission", "(", "pred_file", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "pred_file", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "probs_grp", "=", "[", "]", "\n", "ids_grp", "=", "[", "]", "\n", "ordered_data", "=", "sorted", "(", "data", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "item", ":", "int", "(", "item", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "1", "]", ")", ")", "\n", "for", "annot_id", ",", "scores", "in", "ordered_data", ":", "\n", "            ", "ids_grp", ".", "append", "(", "annot_id", ")", "\n", "probs_grp", ".", "append", "(", "np", ".", "array", "(", "scores", ")", ".", "reshape", "(", "1", ",", "5", ",", "4", ")", ")", "\n", "\n", "# Double check the IDs are in the same order for everything", "\n", "# assert [x == ids_grp[0] for x in ids_grp]", "\n", "\n", "", "", "probs_grp", "=", "np", ".", "stack", "(", "probs_grp", ",", "1", ")", "\n", "# essentially probs_grp is a [num_ex, 5, 4] array of probabilities.", "\n", "# The 5 'groups' are", "\n", "# [answer, rationale_conditioned_on_a0, rationale_conditioned_on_a1,", "\n", "#          rationale_conditioned_on_a2, rationale_conditioned_on_a3].", "\n", "# We will flatten this to a CSV file so it's easy to submit.", "\n", "group_names", "=", "[", "'answer'", "]", "+", "[", "f'rationale_conditioned_on_a{i}'", "\n", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "probs_df", "=", "pd", ".", "DataFrame", "(", "data", "=", "probs_grp", ".", "reshape", "(", "(", "-", "1", ",", "20", ")", ")", ",", "\n", "columns", "=", "[", "f'{group_name}_{i}'", "\n", "for", "group_name", "in", "group_names", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "probs_df", "[", "'annot_id'", "]", "=", "ids_grp", "\n", "probs_df", "=", "probs_df", ".", "set_index", "(", "'annot_id'", ",", "drop", "=", "True", ")", "\n", "return", "probs_df", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.main": [[86, 162], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.Struct", "inf_vcr.load_img_feat", "data.VcrTxtTokLmdb", "data.VcrEvalDataset", "model.vcr.UniterForVisualCommonsenseReasoning.from_pretrained", "amp.initialize.init_type_embedding", "amp.initialize.init_word_embedding", "os.path.exists", "torch.load", "horovod.torch.load", "torch.load.get", "set", "set", "amp.initialize.named_parameters", "checkpoint.get.items", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "amp.initialize.load_state_dict", "amp.initialize.to", "torch.utils.data.DataLoader", "data.PrefetchLoader", "inf_vcr.evaluate", "utils.distributed.all_gather_list", "horovod.torch.local_rank", "horovod.torch.local_rank", "json.load", "set.add", "apex.amp.initialize", "os.makedirs", "all_results.update", "horovod.torch.rank", "inf_vcr.save_for_submission", "save_for_submission.to_csv", "horovod.torch.rank", "open", "set.remove", "set.add", "os.path.exists", "open", "json.dump", "list", "list"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_word_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.save_for_submission"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "\n", "", "hps_file", "=", "f'{opts.output_dir}/log/hps.json'", "\n", "model_opts", "=", "Struct", "(", "json", ".", "load", "(", "open", "(", "hps_file", ")", ")", ")", "\n", "\n", "assert", "opts", ".", "split", "in", "opts", ".", "img_db", "and", "opts", ".", "split", "in", "opts", ".", "txt_db", "\n", "# load DBs and image dirs", "\n", "eval_img_db", ",", "eval_img_db_gt", "=", "load_img_feat", "(", "opts", ".", "img_db", ",", "model_opts", ")", "\n", "eval_txt_db", "=", "VcrTxtTokLmdb", "(", "opts", ".", "txt_db", ",", "-", "1", ")", "\n", "eval_dataset", "=", "VcrEvalDataset", "(", "\n", "\"test\"", ",", "eval_txt_db", ",", "img_db", "=", "eval_img_db", ",", "\n", "img_db_gt", "=", "eval_img_db_gt", ")", "\n", "\n", "# Prepare model", "\n", "model", "=", "UniterForVisualCommonsenseReasoning", ".", "from_pretrained", "(", "\n", "f'{opts.output_dir}/log/model.json'", ",", "state_dict", "=", "{", "}", ",", "\n", "img_dim", "=", "IMG_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "init_word_embedding", "(", "NUM_SPECIAL_TOKENS", ")", "\n", "if", "exists", "(", "opts", ".", "checkpoint", ")", ":", "\n", "        ", "ckpt_file", "=", "opts", ".", "checkpoint", "\n", "", "else", ":", "\n", "        ", "ckpt_file", "=", "f'{opts.output_dir}/ckpt/model_step_{opts.checkpoint}.pt'", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_file", ")", "\n", "state_dict", "=", "checkpoint", ".", "get", "(", "'model_state'", ",", "checkpoint", ")", "\n", "matched_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "set", "(", ")", "\n", "missing_keys", "=", "set", "(", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "missing_keys", ".", "add", "(", "name", ")", "\n", "", "for", "key", ",", "data", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", "in", "missing_keys", ":", "\n", "            ", "matched_state_dict", "[", "key", "]", "=", "data", "\n", "missing_keys", ".", "remove", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "unexpected_keys", ".", "add", "(", "key", ")", "\n", "", "", "LOGGER", ".", "info", "(", "f\"Unexpected_keys: {list(unexpected_keys)}\"", ")", "\n", "LOGGER", ".", "info", "(", "f\"Missing_keys: {list(missing_keys)}\"", ")", "\n", "model", ".", "load_state_dict", "(", "matched_state_dict", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "if", "opts", ".", "fp16", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "enabled", "=", "True", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "\n", "batch_size", "=", "opts", ".", "batch_size", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "vcr_eval_collate", ")", "\n", "eval_dataloader", "=", "PrefetchLoader", "(", "eval_dataloader", ")", "\n", "\n", "_", ",", "results", "=", "evaluate", "(", "model", ",", "eval_dataloader", ")", "\n", "result_dir", "=", "f'{opts.output_dir}/results_{opts.split}'", "\n", "if", "not", "exists", "(", "result_dir", ")", "and", "rank", "==", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "result_dir", ")", "\n", "\n", "", "all_results", "=", "{", "}", "\n", "for", "id2res", "in", "all_gather_list", "(", "results", ")", ":", "\n", "        ", "all_results", ".", "update", "(", "id2res", ")", "\n", "", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "with", "open", "(", "f'{result_dir}/'", "\n", "f'results_{opts.checkpoint}_all.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "all_results", ",", "f", ")", "\n", "", "probs_df", "=", "save_for_submission", "(", "\n", "f'{result_dir}/results_{opts.checkpoint}_all.json'", ")", "\n", "probs_df", ".", "to_csv", "(", "f'{result_dir}/results_{opts.checkpoint}_all.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.evaluate": [[164, 233], ["torch.no_grad", "horovod.torch.no_grad", "model.eval", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "sum", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "horovod.torch.rank", "tqdm.tqdm", "utils.misc.NoOp", "model", "scores.view.view", "zip", "len", "utils.misc.NoOp.update", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "len", "torch.max", "horovod.torch.max", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "F.cross_entropy.item", "inf_vcr.compute_accuracies", "score.cpu().tolist", "len", "qa_targets.squeeze", "range", "torch.stack", "horovod.torch.stack", "qar_targets.squeeze", "int", "qa_targets[].item", "torch.stack.append", "score.cpu", "range"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.compute_accuracies"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"start running evaluation ...\"", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "val_pbar", "=", "tqdm", "(", "total", "=", "len", "(", "eval_loader", ")", ")", "\n", "", "else", ":", "\n", "        ", "val_pbar", "=", "NoOp", "(", ")", "\n", "", "val_qa_loss", ",", "val_qar_loss", "=", "0", ",", "0", "\n", "tot_qa_score", ",", "tot_qar_score", ",", "tot_score", "=", "0", ",", "0", ",", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "        ", "qids", "=", "batch", "[", "'qids'", "]", "\n", "qa_targets", ",", "qar_targets", "=", "batch", "[", "'qa_targets'", "]", ",", "batch", "[", "'qar_targets'", "]", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "scores", "=", "scores", ".", "view", "(", "len", "(", "qids", ")", ",", "-", "1", ")", "\n", "if", "torch", ".", "max", "(", "qa_targets", ")", ">", "-", "1", ":", "\n", "            ", "vcr_qa_loss", "=", "F", ".", "cross_entropy", "(", "\n", "scores", "[", ":", ",", ":", "4", "]", ",", "qa_targets", ".", "squeeze", "(", "-", "1", ")", ",", "reduction", "=", "\"sum\"", ")", "\n", "if", "scores", ".", "shape", "[", "1", "]", ">", "8", ":", "\n", "                ", "qar_scores", "=", "[", "]", "\n", "for", "batch_id", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "answer_ind", "=", "qa_targets", "[", "batch_id", "]", ".", "item", "(", ")", "\n", "qar_index", "=", "[", "4", "+", "answer_ind", "*", "4", "+", "i", "\n", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "qar_scores", ".", "append", "(", "scores", "[", "batch_id", ",", "qar_index", "]", ")", "\n", "", "qar_scores", "=", "torch", ".", "stack", "(", "qar_scores", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "qar_scores", "=", "scores", "[", ":", ",", "4", ":", "]", "\n", "", "vcr_qar_loss", "=", "F", ".", "cross_entropy", "(", "\n", "qar_scores", ",", "qar_targets", ".", "squeeze", "(", "-", "1", ")", ",", "reduction", "=", "\"sum\"", ")", "\n", "val_qa_loss", "+=", "vcr_qa_loss", ".", "item", "(", ")", "\n", "val_qar_loss", "+=", "vcr_qar_loss", ".", "item", "(", ")", "\n", "\n", "curr_qa_score", ",", "curr_qar_score", ",", "curr_score", "=", "compute_accuracies", "(", "\n", "scores", "[", ":", ",", ":", "4", "]", ",", "qa_targets", ",", "qar_scores", ",", "qar_targets", ")", "\n", "tot_qar_score", "+=", "curr_qar_score", "\n", "tot_qa_score", "+=", "curr_qa_score", "\n", "tot_score", "+=", "curr_score", "\n", "", "for", "qid", ",", "score", "in", "zip", "(", "qids", ",", "scores", ")", ":", "\n", "            ", "results", "[", "qid", "]", "=", "score", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "", "n_ex", "+=", "len", "(", "qids", ")", "\n", "val_pbar", ".", "update", "(", "1", ")", "\n", "", "val_qa_loss", "=", "sum", "(", "all_gather_list", "(", "val_qa_loss", ")", ")", "\n", "val_qar_loss", "=", "sum", "(", "all_gather_list", "(", "val_qar_loss", ")", ")", "\n", "tot_qa_score", "=", "sum", "(", "all_gather_list", "(", "tot_qa_score", ")", ")", "\n", "tot_qar_score", "=", "sum", "(", "all_gather_list", "(", "tot_qar_score", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_qa_loss", "/=", "n_ex", "\n", "val_qar_loss", "/=", "n_ex", "\n", "val_qa_acc", "=", "tot_qa_score", "/", "n_ex", "\n", "val_qar_acc", "=", "tot_qar_score", "/", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", ",", "\n", "'valid/vcr_qa_loss'", ":", "val_qa_loss", ",", "\n", "'valid/vcr_qar_loss'", ":", "val_qar_loss", ",", "\n", "'valid/acc_qa'", ":", "val_qa_acc", ",", "\n", "'valid/acc_qar'", ":", "val_qar_acc", ",", "\n", "'valid/acc'", ":", "val_acc", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"evaluation finished in {int(tot_time)} seconds, \"", "\n", "f\"score_qa: {val_qa_acc*100:.2f} \"", "\n", "f\"score_qar: {val_qar_acc*100:.2f} \"", "\n", "f\"score: {val_acc*100:.2f} \"", ")", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vcr.compute_accuracies": [[235, 245], ["matched_qa.sum().item", "matched_qar.sum().item", "matched_joined.sum().item", "out_qa.max", "out_qar.max", "outputs_qa.squeeze", "labels_qa.squeeze", "outputs_qar.squeeze", "labels_qar.squeeze", "matched_qa.sum", "matched_qar.sum", "matched_joined.sum"], "function", ["None"], ["", "def", "compute_accuracies", "(", "out_qa", ",", "labels_qa", ",", "out_qar", ",", "labels_qar", ")", ":", "\n", "    ", "outputs_qa", "=", "out_qa", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "outputs_qar", "=", "out_qar", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "matched_qa", "=", "outputs_qa", ".", "squeeze", "(", ")", "==", "labels_qa", ".", "squeeze", "(", ")", "\n", "matched_qar", "=", "outputs_qar", ".", "squeeze", "(", ")", "==", "labels_qar", ".", "squeeze", "(", ")", "\n", "matched_joined", "=", "matched_qa", "&", "matched_qar", "\n", "n_correct_qa", "=", "matched_qa", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_correct_qar", "=", "matched_qar", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_correct_joined", "=", "matched_joined", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct_qa", ",", "n_correct_qar", ",", "n_correct_joined", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.bert_tokenize": [[20, 30], ["text.strip().split", "tokenizer.tokenize", "ids.extend", "text.strip", "tokenizer.convert_tokens_to_ids"], "function", ["None"], ["@", "curry", "\n", "def", "bert_tokenize", "(", "tokenizer", ",", "text", ")", ":", "\n", "    ", "ids", "=", "[", "]", "\n", "for", "word", "in", "text", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "        ", "ws", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "if", "not", "ws", ":", "\n", "# some special char", "\n", "            ", "continue", "\n", "", "ids", ".", "extend", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "ws", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.process_nlvr2": [[32, 54], ["tqdm.tqdm", "json.loads", "tokenizer", "len", "id_.split"], "function", ["None"], ["", "def", "process_nlvr2", "(", "jsonl", ",", "db", ",", "tokenizer", ",", "missing", "=", "None", ")", ":", "\n", "    ", "id2len", "=", "{", "}", "\n", "txt2img", "=", "{", "}", "# not sure if useful", "\n", "for", "line", "in", "tqdm", "(", "jsonl", ",", "desc", "=", "'processing NLVR2'", ")", ":", "\n", "        ", "example", "=", "json", ".", "loads", "(", "line", ")", "\n", "id_", "=", "example", "[", "'identifier'", "]", "\n", "img_id", "=", "'-'", ".", "join", "(", "id_", ".", "split", "(", "'-'", ")", "[", ":", "-", "1", "]", ")", "\n", "img_fname", "=", "(", "f'nlvr2_{img_id}-img0.npz'", ",", "f'nlvr2_{img_id}-img1.npz'", ")", "\n", "if", "missing", "and", "(", "img_fname", "[", "0", "]", "in", "missing", "or", "img_fname", "[", "1", "]", "in", "missing", ")", ":", "\n", "            ", "continue", "\n", "", "input_ids", "=", "tokenizer", "(", "example", "[", "'sentence'", "]", ")", "\n", "if", "'label'", "in", "example", ":", "\n", "            ", "target", "=", "1", "if", "example", "[", "'label'", "]", "==", "'True'", "else", "0", "\n", "", "else", ":", "\n", "            ", "target", "=", "None", "\n", "", "txt2img", "[", "id_", "]", "=", "img_fname", "\n", "id2len", "[", "id_", "]", "=", "len", "(", "input_ids", ")", "\n", "example", "[", "'input_ids'", "]", "=", "input_ids", "\n", "example", "[", "'img_fname'", "]", "=", "img_fname", "\n", "example", "[", "'target'", "]", "=", "target", "\n", "db", "[", "id_", "]", "=", "example", "\n", "", "return", "id2len", ",", "txt2img", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.process_referring_expressions": [[56, 113], ["set", "print", "tqdm.tqdm", "images.append", "annotations.append", "tokenizer", "len", "len", "int", "str", "str", "str"], "function", ["None"], ["", "def", "process_referring_expressions", "(", "refs", ",", "instances", ",", "iid_to_ann_ids", ",", "\n", "db", ",", "tokenizer", ",", "split", ")", ":", "\n", "    ", "\"\"\"\n    Inputs:\n    - refs: [ref_id, ann_id, image_id, split, sent_ids, sentences]\n    - instances: {images, annotations, categories}\n    - iid_to_ann_ids: image_id -> ann_ids ordered by extracted butd features\n    Return:\n    - id2len : sent_id -> tokenized question length\n    - images : [{id, file_name, ann_ids, height, width} ]\n    - annotations: [{id, area, bbox, image_id, category_id, iscrowd}]\n    - categories : [{id, name, supercategory}]\n    \"\"\"", "\n", "# images within split", "\n", "image_set", "=", "set", "(", "[", "ref", "[", "'image_id'", "]", "for", "ref", "in", "refs", "if", "ref", "[", "'split'", "]", "==", "split", "]", ")", "\n", "images", "=", "[", "]", "\n", "for", "img", "in", "instances", "[", "'images'", "]", ":", "\n", "        ", "if", "img", "[", "'id'", "]", "in", "image_set", ":", "\n", "            ", "images", ".", "append", "(", "{", "\n", "'id'", ":", "img", "[", "'id'", "]", ",", "'file_name'", ":", "img", "[", "'file_name'", "]", ",", "\n", "'ann_ids'", ":", "iid_to_ann_ids", "[", "str", "(", "img", "[", "'id'", "]", ")", "]", ",", "\n", "'height'", ":", "img", "[", "'height'", "]", ",", "'width'", ":", "img", "[", "'width'", "]", "}", ")", "\n", "# Images = {img['id']: img for img in images}", "\n", "# anns within split", "\n", "", "", "annotations", "=", "[", "]", "\n", "for", "ann", "in", "instances", "[", "'annotations'", "]", ":", "\n", "        ", "if", "ann", "[", "'image_id'", "]", "in", "image_set", ":", "\n", "            ", "annotations", ".", "append", "(", "{", "\n", "'id'", ":", "ann", "[", "'id'", "]", ",", "'area'", ":", "ann", "[", "'area'", "]", ",", "'bbox'", ":", "ann", "[", "'bbox'", "]", ",", "\n", "'image_id'", ":", "ann", "[", "'image_id'", "]", ",", "\n", "'category_id'", ":", "ann", "[", "'category_id'", "]", ",", "\n", "'iscrowd'", ":", "ann", "[", "'iscrowd'", "]", "\n", "}", ")", "\n", "", "", "Anns", "=", "{", "ann", "[", "'id'", "]", ":", "ann", "for", "ann", "in", "annotations", "}", "\n", "# category info", "\n", "categories", "=", "instances", "[", "'categories'", "]", "\n", "# refs within split", "\n", "refs", "=", "[", "ref", "for", "ref", "in", "refs", "if", "ref", "[", "'split'", "]", "==", "split", "]", "\n", "print", "(", "f\"Processing {len(refs)} annotations...\"", ")", "\n", "id2len", "=", "{", "}", "\n", "for", "ref", "in", "tqdm", "(", "refs", ",", "desc", "=", "'processing referring expressions'", ")", ":", "\n", "        ", "ref_id", "=", "ref", "[", "'ref_id'", "]", "\n", "ann_id", "=", "ref", "[", "'ann_id'", "]", "\n", "image_id", "=", "ref", "[", "'image_id'", "]", "\n", "img_fname", "=", "f\"visual_grounding_coco_gt_{int(image_id):012}.npz\"", "\n", "for", "sent", "in", "ref", "[", "'sentences'", "]", ":", "\n", "            ", "sent_id", "=", "sent", "[", "'sent_id'", "]", "\n", "input_ids", "=", "tokenizer", "(", "sent", "[", "'sent'", "]", ")", "\n", "id2len", "[", "str", "(", "sent_id", ")", "]", "=", "len", "(", "input_ids", ")", "\n", "db", "[", "str", "(", "sent_id", ")", "]", "=", "{", "\n", "'sent_id'", ":", "sent_id", ",", "'sent'", ":", "sent", "[", "'sent'", "]", ",", "\n", "'ref_id'", ":", "ref_id", ",", "'ann_id'", ":", "ann_id", ",", "\n", "'image_id'", ":", "image_id", ",", "'bbox'", ":", "Anns", "[", "ann_id", "]", "[", "'bbox'", "]", ",", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'img_fname'", ":", "img_fname", "\n", "}", "\n", "", "", "return", "id2len", ",", "images", ",", "annotations", ",", "categories", ",", "refs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.main": [[115, 163], ["vars", "pytorch_pretrained_bert.BertTokenizer.from_pretrained", "prepro.bert_tokenize", "cytoolz.curry", "zip", "os.path.exists", "os.makedirs", "ValueError", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "len", "open", "json.dump", "cytoolz.curry.", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "vars", "open", "json.dump", "open", "prepro.process_nlvr2", "pickle.load", "json.load", "prepro.process_referring_expressions", "set", "open", "open", "json.load", "[].split", "json.load", "open", "open", "[].split", "opts.output.split"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.bert_tokenize", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.process_nlvr2", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.prepro.process_referring_expressions"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "if", "not", "exists", "(", "opts", ".", "output", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "opts", ".", "output", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Found existing DB. Please explicitly remove '", "\n", "'for re-processing'", ")", "\n", "", "meta", "=", "vars", "(", "opts", ")", "\n", "meta", "[", "'tokenizer'", "]", "=", "opts", ".", "toker", "\n", "toker", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "opts", ".", "toker", ",", "do_lower_case", "=", "'uncased'", "in", "opts", ".", "toker", ")", "\n", "tokenizer", "=", "bert_tokenize", "(", "toker", ")", "\n", "meta", "[", "'UNK'", "]", "=", "toker", ".", "convert_tokens_to_ids", "(", "[", "'[UNK]'", "]", ")", "[", "0", "]", "\n", "meta", "[", "'CLS'", "]", "=", "toker", ".", "convert_tokens_to_ids", "(", "[", "'[CLS]'", "]", ")", "[", "0", "]", "\n", "meta", "[", "'SEP'", "]", "=", "toker", ".", "convert_tokens_to_ids", "(", "[", "'[SEP]'", "]", ")", "[", "0", "]", "\n", "meta", "[", "'MASK'", "]", "=", "toker", ".", "convert_tokens_to_ids", "(", "[", "'[MASK]'", "]", ")", "[", "0", "]", "\n", "meta", "[", "'v_range'", "]", "=", "(", "toker", ".", "convert_tokens_to_ids", "(", "'!'", ")", "[", "0", "]", ",", "\n", "len", "(", "toker", ".", "vocab", ")", ")", "\n", "with", "open", "(", "f'{opts.output}/meta.json'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "vars", "(", "opts", ")", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "open_db", "=", "curry", "(", "open_lmdb", ",", "opts", ".", "output", ",", "readonly", "=", "False", ")", "\n", "output_field_name", "=", "[", "'id2len'", ",", "'txt2img'", "]", "\n", "with", "open_db", "(", ")", "as", "db", ":", "\n", "        ", "if", "opts", ".", "task", "==", "'nlvr'", ":", "\n", "            ", "with", "open", "(", "opts", ".", "annotations", "[", "0", "]", ")", "as", "ann", ":", "\n", "                ", "if", "opts", ".", "missing_imgs", "is", "not", "None", ":", "\n", "                    ", "missing_imgs", "=", "set", "(", "json", ".", "load", "(", "open", "(", "opts", ".", "missing_imgs", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "missing_imgs", "=", "None", "\n", "", "jsons", "=", "process_nlvr2", "(", "\n", "ann", ",", "db", ",", "tokenizer", ",", "missing_imgs", ")", "\n", "", "", "elif", "opts", ".", "task", "==", "'re'", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "open", "(", "opts", ".", "annotations", "[", "0", "]", ",", "'rb'", ")", ")", "\n", "instances", "=", "json", ".", "load", "(", "open", "(", "opts", ".", "annotations", "[", "1", "]", ",", "'r'", ")", ")", "\n", "iid_to_ann_ids", "=", "json", ".", "load", "(", "\n", "open", "(", "opts", ".", "annotations", "[", "2", "]", ",", "'r'", ")", ")", "[", "'iid_to_ann_ids'", "]", "\n", "# dirs/refcoco_testA_bert-base-cased.db -> testA", "\n", "img_split", "=", "opts", ".", "output", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "jsons", "=", "process_referring_expressions", "(", "\n", "data", ",", "instances", ",", "iid_to_ann_ids", ",", "\n", "db", ",", "tokenizer", ",", "img_split", ")", "\n", "output_field_name", "=", "[", "\n", "'id2len'", ",", "'images'", ",", "'annotations'", ",", "\n", "'categories'", ",", "'refs'", "]", "\n", "\n", "", "", "for", "dump", ",", "name", "in", "zip", "(", "jsons", ",", "output_field_name", ")", ":", "\n", "        ", "with", "open", "(", "f'{opts.output}/{name}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "dump", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_itm.main": [[31, 92], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "data.DetectFeatLmdb", "data.TxtTokLmdb", "data.ItmEvalDataset", "torch.load", "horovod.torch.load", "model.itm.UniterForImageTextRetrieval.from_pretrained", "amp.initialize.to", "apex.amp.initialize", "torch.utils.data.DataLoader", "data.PrefetchLoader", "inf_itm.evaluate", "horovod.torch.local_rank", "horovod.torch.local_rank", "utils.misc.Struct", "amp.initialize.init_output", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "horovod.torch.rank", "json.load", "os.makedirs", "open", "json.dump", "open", "pickle.dump", "open", "json.dump", "open", "os.path.exists", "vars"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.init_output"], ["def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "train_config", "is", "not", "None", ":", "\n", "        ", "train_opts", "=", "Struct", "(", "json", ".", "load", "(", "open", "(", "opts", ".", "train_config", ")", ")", ")", "\n", "opts", ".", "conf_th", "=", "train_opts", ".", "conf_th", "\n", "opts", ".", "max_bb", "=", "train_opts", ".", "max_bb", "\n", "opts", ".", "min_bb", "=", "train_opts", ".", "min_bb", "\n", "opts", ".", "num_bb", "=", "train_opts", ".", "num_bb", "\n", "\n", "# load DBs and image dirs", "\n", "", "eval_img_db", "=", "DetectFeatLmdb", "(", "opts", ".", "img_db", ",", "\n", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "\n", "opts", ".", "min_bb", ",", "opts", ".", "num_bb", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "eval_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "txt_db", ",", "-", "1", ")", "\n", "eval_dataset", "=", "ItmEvalDataset", "(", "eval_txt_db", ",", "eval_img_db", ",", "opts", ".", "batch_size", ")", "\n", "\n", "# Prepare model", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "model", "=", "UniterForImageTextRetrieval", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "img_dim", "=", "IMG_DIM", ")", "\n", "if", "'rank_output'", "not", "in", "checkpoint", ":", "\n", "        ", "model", ".", "init_output", "(", ")", "# zero shot setting", "\n", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "model", "=", "amp", ".", "initialize", "(", "model", ",", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "itm_eval_collate", ")", "\n", "eval_dataloader", "=", "PrefetchLoader", "(", "eval_dataloader", ")", "\n", "\n", "eval_log", ",", "results", "=", "evaluate", "(", "model", ",", "eval_dataloader", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "if", "not", "exists", "(", "opts", ".", "output_dir", ")", "and", "rank", "==", "0", ":", "\n", "            ", "os", ".", "makedirs", "(", "opts", ".", "output_dir", ")", "\n", "", "with", "open", "(", "f'{opts.output_dir}/config.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "opts", ")", ",", "f", ")", "\n", "", "with", "open", "(", "f'{opts.output_dir}/results.bin'", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "with", "open", "(", "f'{opts.output_dir}/scores.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "eval_log", ",", "f", ")", "\n", "", "LOGGER", ".", "info", "(", "f'evaluation finished'", ")", "\n", "LOGGER", ".", "info", "(", "\n", "f\"======================== Results =========================\\n\"", "\n", "f\"image retrieval R1: {eval_log['img_r1']*100:.2f},\\n\"", "\n", "f\"image retrieval R5: {eval_log['img_r5']*100:.2f},\\n\"", "\n", "f\"image retrieval R10: {eval_log['img_r10']*100:.2f}\\n\"", "\n", "f\"text retrieval R1: {eval_log['txt_r1']*100:.2f},\\n\"", "\n", "f\"text retrieval R5: {eval_log['txt_r5']*100:.2f},\\n\"", "\n", "f\"text retrieval R10: {eval_log['txt_r10']*100:.2f}\"", ")", "\n", "LOGGER", ".", "info", "(", "\"========================================================\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_itm.evaluate": [[94, 116], ["torch.no_grad", "horovod.torch.no_grad", "model.eval", "time.time", "utils.logger.LOGGER.info", "utils.itm_eval.inference", "horovod.torch.allgather", "utils.itm_eval.itm_eval", "utils.logger.LOGGER.info", "hvd.allgather.size", "horovod.torch.rank", "time.time", "utils.distributed.all_gather_list", "len", "len", "tuple", "int"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.inference", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.itm_eval", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "st", "=", "time", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"start running Image/Text Retrieval evaluation ...\"", ")", "\n", "score_matrix", "=", "inference", "(", "model", ",", "eval_loader", ")", "\n", "dset", "=", "eval_loader", ".", "dataset", "\n", "all_score", "=", "hvd", ".", "allgather", "(", "score_matrix", ")", "\n", "all_txt_ids", "=", "[", "i", "for", "ids", "in", "all_gather_list", "(", "dset", ".", "ids", ")", "\n", "for", "i", "in", "ids", "]", "\n", "all_img_ids", "=", "dset", ".", "all_img_ids", "\n", "assert", "all_score", ".", "size", "(", ")", "==", "(", "len", "(", "all_txt_ids", ")", ",", "len", "(", "all_img_ids", ")", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "!=", "0", ":", "\n", "        ", "return", "{", "}", ",", "tuple", "(", ")", "\n", "# NOTE: only use rank0 to compute final scores", "\n", "", "eval_log", "=", "itm_eval", "(", "all_score", ",", "all_txt_ids", ",", "all_img_ids", ",", "\n", "dset", ".", "txt2img", ",", "dset", ".", "img2txts", ")", "\n", "\n", "results", "=", "(", "all_score", ",", "all_txt_ids", ",", "all_img_ids", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "LOGGER", ".", "info", "(", "f\"evaluation finished in {int(tot_time)} seconds, \"", ")", "\n", "return", "eval_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm.build_dataloader": [[36, 44], ["torch.utils.data.DataLoader", "data.PrefetchLoader", "data.itm_val_collate", "data.itm_eval_collate", "data.itm_eval_collate", "data.itm_rank_collate"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_val_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_rank_collate"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "batch_size", "=", "opts", ".", "train_batch_size", "if", "is_train", "else", "1", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "is_train", ",", "drop_last", "=", "is_train", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "dataloader", "=", "PrefetchLoader", "(", "dataloader", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm.main": [[46, 272], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "utils.logger.LOGGER.info", "data.ImageLmdbGroup", "utils.logger.LOGGER.info", "zip", "torch.utils.data.ConcatDataset", "utils.logger.LOGGER.info", "data.TxtTokLmdb", "data.ItmValDataset", "train_itm.build_dataloader", "utils.logger.LOGGER.info", "data.ItmEvalDataset", "train_itm.build_dataloader", "data.TxtTokLmdb", "data.ItmEvalDataset", "train_itm.build_dataloader", "model.itm.UniterForImageTextRetrieval.from_pretrained", "UniterForImageTextRetrieval.from_pretrained.init_output", "UniterForImageTextRetrieval.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForImageTextRetrieval.from_pretrained.train", "time.time", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "utils.misc.NoOp.close", "utils.logger.LOGGER.info", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "horovod.torch.rank", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "utils.logger.add_log_to_file", "os.makedirs", "os.makedirs", "os.makedirs", "utils.misc.NoOp", "utils.misc.NoOp", "len", "len", "data.TxtTokLmdb", "train_datasets.append", "torch.load", "horovod.torch.load", "train_itm.build_dataloader", "enumerate", "utils.logger.LOGGER.info", "train_itm.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "utils.itm_eval.evaluate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.LOGGER.info", "horovod.torch.rank", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "data.ItmRankDataset", "len", "horovod.torch.size", "batch[].size", "UniterForImageTextRetrieval.from_pretrained.", "loss.mean.mean", "utils.logger.RunningMeter.", "horovod.torch.rank", "UniterForImageTextRetrieval.from_pretrained.parameters", "apex.amp.scale_loss", "scaled_loss.backward", "loss.mean.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "utils.misc.NoOp.save", "utils.itm_eval.evaluate.items", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "utils.logger.LOGGER.info", "utils.itm_eval.evaluate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "train_itm.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "UniterForImageTextRetrieval.from_pretrained.parameters", "time.time", "validate.items"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.init_output", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "# store ITM predictions", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_val'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_test'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_train'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "# train_examples = None", "\n", "", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.train_txt_dbs}, \"", "\n", "f\"{opts.train_img_dbs}\"", ")", "\n", "# check multiple DBs", "\n", "assert", "len", "(", "opts", ".", "train_txt_dbs", ")", "==", "len", "(", "opts", ".", "train_img_dbs", ")", ",", "\"train txt_db and img_db have different length\"", "\n", "\n", "# load DBs and image dirs", "\n", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "# train", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset \"", "\n", "f\"{opts.train_txt_dbs}, {opts.train_img_dbs}\"", ")", "\n", "train_datasets", "=", "[", "]", "\n", "for", "txt_path", ",", "img_path", "in", "zip", "(", "opts", ".", "train_txt_dbs", ",", "opts", ".", "train_img_dbs", ")", ":", "\n", "        ", "img_db", "=", "all_img_dbs", "[", "img_path", "]", "\n", "txt_db", "=", "TxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", ")", "\n", "train_datasets", ".", "append", "(", "ItmRankDataset", "(", "txt_db", ",", "img_db", ",", "\n", "opts", ".", "negative_size", ")", ")", "\n", "", "train_dataset", "=", "ConcatDataset", "(", "train_datasets", ")", "\n", "\n", "# val", "\n", "LOGGER", ".", "info", "(", "f\"Loading Val Dataset {opts.val_txt_db}, {opts.val_img_db}\"", ")", "\n", "val_img_db", "=", "all_img_dbs", "[", "opts", ".", "val_img_db", "]", "\n", "val_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "val_txt_db", ",", "-", "1", ")", "\n", "val_dataset", "=", "ItmValDataset", "(", "val_txt_db", ",", "val_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "val_dataset", ",", "itm_val_collate", ",", "\n", "False", ",", "opts", ")", "\n", "# eval", "\n", "LOGGER", ".", "info", "(", "f\"Loading val, test Dataset for full evaluation: \"", "\n", "f\"{opts.val_txt_db}, {opts.val_img_db}\"", "\n", "f\"{opts.test_txt_db}, {opts.test_img_db}\"", ")", "\n", "eval_dataset_val", "=", "ItmEvalDataset", "(", "val_txt_db", ",", "val_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "eval_loader_val", "=", "build_dataloader", "(", "eval_dataset_val", ",", "itm_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "test_img_db", "=", "all_img_dbs", "[", "opts", ".", "test_img_db", "]", "\n", "test_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "test_txt_db", ",", "-", "1", ")", "\n", "eval_dataset_test", "=", "ItmEvalDataset", "(", "test_txt_db", ",", "test_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "eval_loader_test", "=", "build_dataloader", "(", "eval_dataset_test", ",", "itm_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "model", "=", "UniterForImageTextRetrieval", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "state_dict", "=", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "margin", "=", "opts", ".", "margin", ")", "\n", "model", ".", "init_output", "(", ")", "# pretrain ITM head is different from ranking head", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "LOGGER", ".", "info", "(", "f\"***** Running training on {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", "*", "hvd", ".", "size", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "train_dataloader", "=", "build_dataloader", "(", "\n", "train_dataset", ",", "itm_rank_collate", ",", "True", ",", "opts", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "n_examples", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'------------Step {global_step}-------------'", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "f'-------------------------------------------'", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "if", "opts", ".", "full_val", ":", "\n", "                        ", "LOGGER", ".", "info", "(", "\n", "f\"========================== Step {global_step} \"", "\n", "f\"==========================\"", ")", "\n", "val_log", "=", "evaluate", "(", "model", ",", "eval_loader_val", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "\n", "{", "f\"valid/{k}\"", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", ")", "\n", "LOGGER", ".", "info", "(", "f\"image retrieval R1: \"", "\n", "f\"{val_log['img_r1']*100:.2f},\\n\"", "\n", "f\"image retrieval R5: \"", "\n", "f\"{val_log['img_r5']*100:.2f},\\n\"", "\n", "f\"image retrieval R10: \"", "\n", "f\"{val_log['img_r10']*100:.2f}\\n\"", "\n", "f\"text retrieval R1: \"", "\n", "f\"{val_log['txt_r1']*100:.2f},\\n\"", "\n", "f\"text retrieval R5: \"", "\n", "f\"{val_log['txt_r5']*100:.2f},\\n\"", "\n", "f\"text retrieval R10: \"", "\n", "f\"{val_log['txt_r10']*100:.2f}\"", ")", "\n", "LOGGER", ".", "info", "(", "\"=================================\"", "\n", "\"=================================\"", ")", "\n", "", "else", ":", "\n", "                        ", "val_log", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "n_epoch", "+=", "1", "\n", "LOGGER", ".", "info", "(", "f\"finished {n_epoch} epochs\"", ")", "\n", "\n", "", "pbar", ".", "close", "(", ")", "\n", "if", "opts", ".", "num_train_steps", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "# final validation", "\n", "        ", "val_log", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n", "# evaluation", "\n", "", "for", "split", ",", "loader", "in", "[", "(", "'val'", ",", "eval_loader_val", ")", ",", "\n", "(", "'test'", ",", "eval_loader_test", ")", "]", ":", "\n", "        ", "eval_log", "=", "evaluate", "(", "model", ",", "loader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "{", "f\"eval/{split}_{k}\"", ":", "v", "\n", "for", "k", ",", "v", "in", "eval_log", ".", "items", "(", ")", "}", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "!=", "0", ":", "\n", "            ", "continue", "\n", "", "LOGGER", ".", "info", "(", "\n", "f\"========================= {split} ===========================\\n\"", "\n", "f\"image retrieval R1: {eval_log['img_r1']*100:.2f},\\n\"", "\n", "f\"image retrieval R5: {eval_log['img_r5']*100:.2f},\\n\"", "\n", "f\"image retrieval R10: {eval_log['img_r10']*100:.2f}\\n\"", "\n", "f\"text retrieval R1: {eval_log['txt_r1']*100:.2f},\\n\"", "\n", "f\"text retrieval R5: {eval_log['txt_r5']*100:.2f},\\n\"", "\n", "f\"text retrieval R10: {eval_log['txt_r10']*100:.2f}\"", ")", "\n", "", "LOGGER", ".", "info", "(", "\"=========================================================\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm.validate": [[274, 316], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "sum", "model.train", "utils.logger.LOGGER.info", "utils.misc.NoOp.close", "horovod.torch.rank", "tqdm.tqdm", "utils.misc.NoOp", "model", "model.squeeze().topk", "rank.item.numel", "utils.misc.NoOp.update", "utils.distributed.all_gather_list", "sum", "sum", "sum", "time.time", "rank.item.item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "len", "model.squeeze", "int"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "val_loader", ")", ")", "\n", "", "else", ":", "\n", "        ", "pbar", "=", "NoOp", "(", ")", "\n", "", "LOGGER", ".", "info", "(", "\"start running Image Retrieval validation ...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "\n", "recall_at_1", ",", "recall_at_5", ",", "recall_at_10", "=", "0", ",", "0", ",", "0", "\n", "for", "batch", "in", "val_loader", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "_", ",", "indices", "=", "scores", ".", "squeeze", "(", "1", ")", ".", "topk", "(", "10", ",", "dim", "=", "0", ")", "\n", "rank", "=", "(", "indices", "==", "0", ")", ".", "nonzero", "(", ")", "\n", "if", "rank", ".", "numel", "(", ")", ":", "\n", "            ", "rank", "=", "rank", ".", "item", "(", ")", "\n", "if", "rank", "<", "1", ":", "\n", "                ", "recall_at_1", "+=", "1", "\n", "", "if", "rank", "<", "5", ":", "\n", "                ", "recall_at_5", "+=", "1", "\n", "", "if", "rank", "<", "10", ":", "\n", "                ", "recall_at_10", "+=", "1", "\n", "", "", "n_ex", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "recall_at_1", "=", "sum", "(", "all_gather_list", "(", "recall_at_1", ")", ")", "/", "n_ex", "\n", "recall_at_5", "=", "sum", "(", "all_gather_list", "(", "recall_at_5", ")", ")", "/", "n_ex", "\n", "recall_at_10", "=", "sum", "(", "all_gather_list", "(", "recall_at_10", ")", ")", "/", "n_ex", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_log", "=", "{", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", ",", "\n", "'valid/recall_1'", ":", "recall_at_1", ",", "\n", "'valid/recall_5'", ":", "recall_at_5", ",", "\n", "'valid/recall_10'", ":", "recall_at_10", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"recall_1: {recall_at_1*100:.2f}, \"", "\n", "f\"recall_5: {recall_at_5*100:.2f}, \"", "\n", "f\"recall_10: {recall_at_10*100:.2f}\"", ")", "\n", "pbar", ".", "close", "(", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader": [[41, 53], ["data.DetectFeatLmdb", "data.TxtTokLmdb", "dset_cls", "data.TokenBucketSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader"], "function", ["None"], ["def", "create_dataloader", "(", "img_path", ",", "txt_path", ",", "batch_size", ",", "is_train", ",", "\n", "dset_cls", ",", "collate_fn", ",", "opts", ")", ":", "\n", "    ", "img_db", "=", "DetectFeatLmdb", "(", "img_path", ",", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "txt_db", "=", "TxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", "if", "is_train", "else", "-", "1", ")", "\n", "dset", "=", "dset_cls", "(", "txt_db", ",", "img_db", ",", "opts", ".", "use_img_type", ")", "\n", "sampler", "=", "TokenBucketSampler", "(", "dset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "PrefetchLoader", "(", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.main": [[55, 239], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "utils.logger.LOGGER.info", "train_nlvr2.create_dataloader", "train_nlvr2.create_dataloader", "train_nlvr2.create_dataloader", "ModelCls.from_pretrained", "ModelCls.from_pretrained.init_type_embedding", "ModelCls.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "ModelCls.from_pretrained.train", "time.time", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "torch.load", "horovod.torch.load", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "os.makedirs", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "len", "enumerate", "utils.logger.LOGGER.info", "utils.misc.NoOp.save", "horovod.torch.rank", "ValueError", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "targets.size", "ModelCls.from_pretrained.", "loss.mean.mean", "utils.logger.RunningMeter.", "utils.logger.LOGGER.info", "train_nlvr2.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "ValueError", "ModelCls.from_pretrained.parameters", "apex.amp.scale_loss", "scaled_loss.backward", "loss.mean.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "open", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.misc.NoOp.save", "f.write", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "utils.logger.LOGGER.info", "train_nlvr2.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "ModelCls.from_pretrained.parameters", "open", "time.time", "f.write"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.create_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "# train_examples = None", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.train_txt_db}, \"", "\n", "f\"{opts.train_img_db}\"", ")", "\n", "if", "'paired'", "in", "opts", ".", "model", ":", "\n", "        ", "DatasetCls", "=", "Nlvr2PairedDataset", "\n", "EvalDatasetCls", "=", "Nlvr2PairedEvalDataset", "\n", "collate_fn", "=", "nlvr2_paired_collate", "\n", "eval_collate_fn", "=", "nlvr2_paired_eval_collate", "\n", "if", "opts", ".", "model", "==", "'paired'", ":", "\n", "            ", "ModelCls", "=", "UniterForNlvr2Paired", "\n", "", "elif", "opts", ".", "model", "==", "'paired-attn'", ":", "\n", "            ", "ModelCls", "=", "UniterForNlvr2PairedAttn", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unrecognized model type'", ")", "\n", "", "", "elif", "opts", ".", "model", "==", "'triplet'", ":", "\n", "        ", "DatasetCls", "=", "Nlvr2TripletDataset", "\n", "EvalDatasetCls", "=", "Nlvr2TripletEvalDataset", "\n", "ModelCls", "=", "UniterForNlvr2Triplet", "\n", "collate_fn", "=", "nlvr2_triplet_collate", "\n", "eval_collate_fn", "=", "nlvr2_triplet_eval_collate", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unrecognized model type'", ")", "\n", "\n", "# data loaders", "\n", "", "train_dataloader", "=", "create_dataloader", "(", "opts", ".", "train_img_db", ",", "opts", ".", "train_txt_db", ",", "\n", "opts", ".", "train_batch_size", ",", "True", ",", "\n", "DatasetCls", ",", "collate_fn", ",", "opts", ")", "\n", "val_dataloader", "=", "create_dataloader", "(", "opts", ".", "val_img_db", ",", "opts", ".", "val_txt_db", ",", "\n", "opts", ".", "val_batch_size", ",", "False", ",", "\n", "EvalDatasetCls", ",", "eval_collate_fn", ",", "opts", ")", "\n", "test_dataloader", "=", "create_dataloader", "(", "opts", ".", "test_img_db", ",", "opts", ".", "test_txt_db", ",", "\n", "opts", ".", "val_batch_size", ",", "False", ",", "\n", "EvalDatasetCls", ",", "eval_collate_fn", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "model", "=", "ModelCls", ".", "from_pretrained", "(", "opts", ".", "model_config", ",", "state_dict", "=", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results'", ")", ")", "# store val predictions", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataloader", ".", "dataset", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "n_examples", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'Step {global_step}: '", "\n", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "for", "split", ",", "loader", "in", "[", "(", "'val'", ",", "val_dataloader", ")", ",", "\n", "(", "'test'", ",", "test_dataloader", ")", "]", ":", "\n", "                        ", "LOGGER", ".", "info", "(", "f\"Step {global_step}: start running \"", "\n", "f\"validation on {split} split...\"", ")", "\n", "log", ",", "results", "=", "validate", "(", "model", ",", "loader", ",", "split", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'{split}_results_{global_step}_'", "\n", "f'rank{rank}.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "for", "id_", ",", "ans", "in", "results", ":", "\n", "                                ", "f", ".", "write", "(", "f'{id_},{ans}\\n'", ")", "\n", "", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "n_epoch", "+=", "1", "\n", "LOGGER", ".", "info", "(", "f\"Step {global_step}: finished {n_epoch} epochs\"", ")", "\n", "", "if", "opts", ".", "num_train_steps", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "for", "split", ",", "loader", "in", "[", "(", "'val'", ",", "val_dataloader", ")", ",", "\n", "(", "'test'", ",", "test_dataloader", ")", "]", ":", "\n", "            ", "LOGGER", ".", "info", "(", "f\"Step {global_step}: start running \"", "\n", "f\"validation on {split} split...\"", ")", "\n", "log", ",", "results", "=", "validate", "(", "model", ",", "loader", ",", "split", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'{split}_results_{global_step}_'", "\n", "f'rank{rank}.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "for", "id_", ",", "ans", "in", "results", ":", "\n", "                    ", "f", ".", "write", "(", "f'{id_},{ans}\\n'", ")", "\n", "", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_nlvr2.validate": [[241, 277], ["torch.no_grad", "horovod.torch.no_grad", "model.eval", "time.time", "enumerate", "sum", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "model", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "results.extend", "len", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "zip", "[].cpu().tolist", "int", "[].cpu", "model.max", "model.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ",", "split", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "val_loss", "=", "0", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "qids", "=", "batch", "[", "'qids'", "]", "\n", "targets", "=", "batch", "[", "'targets'", "]", "\n", "del", "batch", "[", "'targets'", "]", "\n", "del", "batch", "[", "'qids'", "]", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "targets", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tot_score", "+=", "(", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "[", "1", "]", "==", "targets", "\n", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "answers", "=", "[", "'True'", "if", "i", "==", "1", "else", "'False'", "\n", "for", "i", "in", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", "\n", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", "\n", "results", ".", "extend", "(", "zip", "(", "qids", ",", "answers", ")", ")", "\n", "n_ex", "+=", "len", "(", "qids", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "f'valid/{split}_loss'", ":", "val_loss", ",", "\n", "f'valid/{split}_acc'", ":", "val_acc", ",", "\n", "f'valid/{split}_ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_dataloader": [[44, 55], ["data.TokenBucketSampler", "torch.utils.data.DataLoader"], "function", ["None"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_dataloader_itm": [[57, 69], ["data.TokenBucketSamplerForItm", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "build_dataloader_itm", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSamplerForItm", "(", "\n", "dataset", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mlm_dataset": [[71, 81], ["data.ConcatDatasetWithLens", "data.MlmDataset", "data.MlmDataset", "zip"], "function", ["None"], ["", "def", "build_mlm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "collate_fn", "=", "mlm_collate", "\n", "datasets", "=", "[", "MlmDataset", "(", "t", ",", "i", ")", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "collate_fn", "=", "mlm_collate", "\n", "dataset", "=", "MlmDataset", "(", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrfr_dataset": [[83, 92], ["data.ConcatDatasetWithLens", "data.MrfrDataset", "data.MrfrDataset", "zip"], "function", ["None"], ["", "def", "build_mrfr_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrfrDataset", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrfrDataset", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrfr_collate", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrc_dataset": [[94, 103], ["data.ConcatDatasetWithLens", "data.MrcDataset", "data.MrcDataset", "zip"], "function", ["None"], ["", "def", "build_mrc_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrcDataset", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrcDataset", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrc_collate", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_itm_dataset": [[105, 114], ["data.ConcatDatasetWithLens", "data.ItmDataset", "data.ItmDataset", "zip"], "function", ["None"], ["", "def", "build_itm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "ItmDataset", "(", "t", ",", "i", ",", "opts", ".", "itm_neg_prob", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "ItmDataset", "(", "txt_db", ",", "img_db", ",", "opts", ".", "itm_neg_prob", ")", "\n", "", "collate_fn", "=", "itm_ot_collate", "if", "opts", ".", "itm_ot_lambda", ">", "0", "else", "itm_collate", "\n", "return", "dataset", ",", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.create_dataloaders": [[116, 166], ["data.ImageLmdbGroup", "enumerate", "task.startswith", "utils.logger.LOGGER.info", "task.startswith", "len", "len", "len", "len", "len", "len", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "data.TxtTokLmdb", "pretrain.build_mlm_dataset", "task.startswith", "pretrain.build_dataloader_itm", "pretrain.build_dataloader", "data.PrefetchLoader", "data.TxtTokLmdb", "pretrain.build_mrfr_dataset", "task.startswith", "pretrain.build_mrc_dataset", "task.startswith", "pretrain.build_itm_dataset", "ValueError", "len", "horovod.torch.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mlm_dataset", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_dataloader_itm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrfr_dataset", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_mrc_dataset", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.build_itm_dataset"], ["", "def", "create_dataloaders", "(", "datasets", ",", "is_train", ",", "opts", ",", "all_img_dbs", "=", "None", ")", ":", "\n", "    ", "if", "all_img_dbs", "is", "None", ":", "\n", "        ", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "", "dataloaders", "=", "{", "}", "\n", "for", "dset", "in", "datasets", ":", "\n", "        ", "if", "is_train", ":", "\n", "            ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "\n", "assert", "len", "(", "dset", "[", "'tasks'", "]", ")", "==", "len", "(", "dset", "[", "'mix_ratio'", "]", ")", "\n", "img_db", "=", "[", "all_img_dbs", "[", "path", "]", "for", "path", "in", "dset", "[", "'img'", "]", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "==", "1", "\n", "img_db", "=", "all_img_dbs", "[", "dset", "[", "'img'", "]", "[", "0", "]", "]", "\n", "\n", "", "for", "i", ",", "t", "in", "enumerate", "(", "dset", "[", "'tasks'", "]", ")", ":", "\n", "            ", "task", "=", "f'{t}_{dset[\"name\"]}'", "\n", "\n", "if", "is_train", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f\"Loading {task} train dataset \"", "\n", "f\"{dset['db']}, {[img.img_dir for img in img_db]}\"", ")", "\n", "txt_db", "=", "[", "TxtTokLmdb", "(", "path", ",", "opts", ".", "max_txt_len", ")", "\n", "for", "path", "in", "dset", "[", "'db'", "]", "]", "\n", "", "else", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f\"Loading {task} validation dataset, \"", "\n", "f\"{dset['db']}, {img_db.img_dir}\"", ")", "\n", "txt_db", "=", "TxtTokLmdb", "(", "dset", "[", "'db'", "]", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n", "                ", "dataset", "=", "build_mlm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "                ", "dataset", "=", "build_mrfr_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "                ", "dataset", "=", "build_mrc_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "                ", "dataset", "=", "build_itm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"{len(dataset[0])*hvd.size()} samples loaded\"", ")", "\n", "if", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "# itm handles distributed training in dset not sampler", "\n", "                ", "loader", "=", "build_dataloader_itm", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                ", "loader", "=", "build_dataloader", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "", "if", "is_train", ":", "\n", "                ", "ratio", "=", "dset", "[", "'mix_ratio'", "]", "[", "i", "]", "\n", "dataloaders", "[", "task", "]", "=", "(", "loader", ",", "ratio", ")", "\n", "", "else", ":", "\n", "                ", "dataloaders", "[", "task", "]", "=", "PrefetchLoader", "(", "loader", ")", "\n", "", "", "", "return", "dataloaders", ",", "all_img_dbs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.main": [[168, 368], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "all", "pretrain.create_dataloaders", "pretrain.create_dataloaders", "data.MetaLoader", "data.PrefetchLoader", "model.pretrain.UniterForPretraining.from_pretrained", "UniterForPretraining.from_pretrained.to", "UniterForPretraining.from_pretrained.train", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "time.time", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "enumerate", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "json.load", "torch.load", "horovod.torch.load", "utils.logger.RunningMeter", "train_dataloaders.keys", "batch[].size", "UniterForPretraining.from_pretrained.", "task.startswith", "utils.logger.LOGGER.info", "pretrain.validate", "utils.misc.NoOp.save", "horovod.torch.rank", "os.path.join", "os.path.join", "os.path.join", "open", "enumerate", "len", "train_dataloaders.keys", "task.startswith", "name.split", "itm_loss.mean.size", "itm_loss.mean.mean", "loss.mean.size", "loss.mean.mean", "apex.amp.scale_loss", "scaled_loss.backward", "loss.mean.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "UniterForPretraining.from_pretrained.parameters", "train_dataloaders.keys", "utils.logger.RunningMeter", "utils.logger.RunningMeter", "utils.logger.RunningMeter", "utils.logger.RunningMeter", "ot_pos.mean().item.mean().item", "ot_neg.mean().item.mean().item", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "train_dataloaders.keys", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "pretrain.validate", "utils.misc.NoOp.save", "json.load", "math.isnan", "math.isnan", "itm_loss.mean.item", "ot_loss.item", "float", "apex.amp.master_params", "all", "sum", "int", "sum", "int", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "open", "ot_pos.mean().item.sum", "ot_neg.mean().item.sum", "ot_pos.mean().item.size", "ot_neg.mean().item.size", "ot_pos.mean().item.mean", "ot_neg.mean().item.mean", "UniterForPretraining.from_pretrained.parameters", "task2loss.values", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.create_dataloaders", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.create_dataloaders", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "args", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "all_dbs", "=", "[", "db", "for", "datasets", "in", "[", "opts", ".", "train_datasets", ",", "opts", ".", "val_datasets", "]", "\n", "for", "dset", "in", "datasets", "for", "db", "in", "dset", "[", "'db'", "]", "]", "\n", "\n", "tokenizer", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "assert", "all", "(", "tokenizer", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "\n", "# build data loaders", "\n", "train_dataloaders", ",", "all_img_dbs", "=", "create_dataloaders", "(", "\n", "opts", ".", "train_datasets", ",", "True", ",", "opts", ")", "\n", "val_dataloaders", ",", "_", "=", "create_dataloaders", "(", "\n", "opts", ".", "val_datasets", ",", "False", ",", "opts", ",", "all_img_dbs", ")", "\n", "meta_loader", "=", "MetaLoader", "(", "train_dataloaders", ",", "\n", "accum_steps", "=", "opts", ".", "gradient_accumulation_steps", ",", "\n", "distributed", "=", "n_gpu", ">", "1", ")", "\n", "meta_loader", "=", "PrefetchLoader", "(", "meta_loader", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "", "model", "=", "UniterForPretraining", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "img_label_dim", "=", "IMG_LABEL_DIM", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "task2scaler", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "train_dataloaders", ".", "keys", "(", ")", ")", "}", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "num_losses", "=", "len", "(", "task2scaler", ")", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "# to compute training statistics", "\n", "task2loss", "=", "{", "task", ":", "RunningMeter", "(", "f'loss/{task}'", ")", "\n", "for", "task", "in", "train_dataloaders", ".", "keys", "(", ")", "}", "\n", "# ITM w/ OT", "\n", "if", "opts", ".", "itm_ot_lambda", ">", "0", ":", "\n", "        ", "for", "task", "in", "train_dataloaders", ".", "keys", "(", ")", ":", "\n", "            ", "if", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "                ", "task2loss", "[", "f'{task}_xe'", "]", "=", "RunningMeter", "(", "f'loss/{task}_xe'", ")", "\n", "task2loss", "[", "f'{task}_ot'", "]", "=", "RunningMeter", "(", "f'loss/{task}_ot'", ")", "\n", "task2loss", "[", "f'{task}_ot_pos'", "]", "=", "RunningMeter", "(", "\n", "f'loss/{task}_ot_pos'", ")", "\n", "task2loss", "[", "f'{task}_ot_neg'", "]", "=", "RunningMeter", "(", "\n", "f'loss/{task}_ot_neg'", ")", "\n", "\n", "", "", "", "n_examples", "=", "defaultdict", "(", "int", ")", "\n", "n_in_units", "=", "defaultdict", "(", "int", ")", "\n", "n_loss_units", "=", "defaultdict", "(", "int", ")", "\n", "grad_norm", "=", "0", "\n", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "for", "step", ",", "(", "name", ",", "batch", ")", "in", "enumerate", "(", "meta_loader", ")", ":", "\n", "# forward pass", "\n", "        ", "n_examples", "[", "name", "]", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "n_in_units", "[", "name", "]", "+=", "(", "batch", "[", "'attn_masks'", "]", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "task", "=", "name", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "loss", "=", "model", "(", "batch", ",", "task", "=", "task", ",", "compute_loss", "=", "True", ")", "\n", "if", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "# OT", "\n", "            ", "itm_loss", ",", "ot_loss", "=", "loss", "\n", "n_loss_units", "[", "name", "]", "+=", "itm_loss", ".", "size", "(", "0", ")", "\n", "itm_loss", "=", "itm_loss", ".", "mean", "(", ")", "\n", "if", "ot_loss", "is", "not", "None", ":", "\n", "                ", "ot_pos", ",", "ot_neg", "=", "ot_loss", "\n", "ot_loss", "=", "(", "ot_pos", ".", "sum", "(", ")", "-", "ot_neg", ".", "sum", "(", ")", "\n", ")", "/", "(", "ot_pos", ".", "size", "(", "0", ")", "+", "ot_neg", ".", "size", "(", "0", ")", ")", "\n", "\n", "# NOTE: be ware of empty tensor", "\n", "ot_pos", "=", "ot_pos", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "if", "not", "math", ".", "isnan", "(", "ot_pos", ")", ":", "\n", "                    ", "task2loss", "[", "f'{name}_ot_pos'", "]", "(", "ot_pos", ")", "\n", "", "ot_neg", "=", "ot_neg", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "if", "not", "math", ".", "isnan", "(", "ot_neg", ")", ":", "\n", "                    ", "task2loss", "[", "f'{name}_ot_neg'", "]", "(", "ot_neg", ")", "\n", "\n", "", "loss", "=", "itm_loss", "+", "opts", ".", "itm_ot_lambda", "*", "ot_loss", "\n", "task2loss", "[", "f'{name}_xe'", "]", "(", "itm_loss", ".", "item", "(", ")", ")", "\n", "task2loss", "[", "f'{name}_ot'", "]", "(", "ot_loss", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "itm_loss", "\n", "", "", "else", ":", "\n", "            ", "n_loss_units", "[", "name", "]", "+=", "loss", ".", "size", "(", "0", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "# loss is not normalized in model", "\n", "\n", "# backward pass", "\n", "", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", ",", "\n", "loss_id", "=", "task2scaler", "[", "name", "]", ")", "as", "scaled_loss", ":", "\n", "            ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "", "task2loss", "[", "name", "]", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# optimizer update and logging", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "            ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "{", "ll", ".", "name", ":", "ll", ".", "val", "\n", "for", "ll", "in", "task2loss", ".", "values", "(", ")", "\n", "if", "ll", ".", "val", "is", "not", "None", "}", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                ", "LOGGER", ".", "info", "(", "f'==============Step {global_step}==============='", ")", "\n", "for", "t", "in", "train_dataloaders", ".", "keys", "(", ")", ":", "\n", "                    ", "assert", "all", "(", "tt", "==", "t", "for", "tt", "in", "all_gather_list", "(", "t", ")", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", "[", "t", "]", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "tot_in", "=", "sum", "(", "all_gather_list", "(", "n_in_units", "[", "t", "]", ")", ")", "\n", "in_per_sec", "=", "int", "(", "tot_in", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "tot_l", "=", "sum", "(", "all_gather_list", "(", "n_loss_units", "[", "t", "]", ")", ")", "\n", "l_per_sec", "=", "int", "(", "tot_l", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{t}: {tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_ex_per_s'", ",", "ex_per_sec", ",", "\n", "global_step", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_in_per_s'", ",", "in_per_sec", ",", "\n", "global_step", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "f'perf/{t}_loss_per_s'", ",", "l_per_sec", ",", "\n", "global_step", ")", "\n", "", "LOGGER", ".", "info", "(", "'==============================================='", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f'Step {global_step}: start validation'", ")", "\n", "validate", "(", "model", ",", "val_dataloaders", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "", "if", "global_step", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "LOGGER", ".", "info", "(", "f'Step {global_step}: start validation'", ")", "\n", "validate", "(", "model", ",", "val_dataloaders", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate": [[370, 388], ["model.eval", "val_dataloaders.items", "model.train", "utils.logger.LOGGER.info", "task.startswith", "utils.logger.TB_LOGGER.log_scaler_dict", "pretrain.validate_mlm", "task.startswith", "pretrain.validate_mrfr", "task.startswith", "validate_itm.items", "pretrain.validate_mrc", "task.startswith", "validate_itm.items", "pretrain.validate_itm", "ValueError"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mlm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrfr", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrc", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_itm"], ["", "", "def", "validate", "(", "model", ",", "val_dataloaders", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "for", "task", ",", "loader", "in", "val_dataloaders", ".", "items", "(", ")", ":", "\n", "        ", "LOGGER", ".", "info", "(", "f\"validate on {task} task\"", ")", "\n", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n", "            ", "val_log", "=", "validate_mlm", "(", "model", ",", "loader", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "            ", "val_log", "=", "validate_mrfr", "(", "model", ",", "loader", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "            ", "val_log", "=", "validate_mrc", "(", "model", ",", "loader", ",", "task", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "            ", "val_log", "=", "validate_itm", "(", "model", ",", "loader", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "", "val_log", "=", "{", "f'{task}_{k}'", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "\n", "{", "f'valid_{task}/{k}'", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mlm": [[390, 417], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "utils.logger.LOGGER.info", "model", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "labels.numel", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "int", "model.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mlm", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MLM validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_correct", "=", "0", "\n", "n_word", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "task", "=", "'mlm'", ",", "compute_loss", "=", "False", ")", "\n", "labels", "=", "batch", "[", "'txt_labels'", "]", "\n", "labels", "=", "labels", "[", "labels", "!=", "-", "1", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "labels", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_correct", "+=", "(", "scores", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word", "+=", "labels", ".", "numel", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "n_correct", "=", "sum", "(", "all_gather_list", "(", "n_correct", ")", ")", "\n", "n_word", "=", "sum", "(", "all_gather_list", "(", "n_word", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_word", "\n", "acc", "=", "n_correct", "/", "n_word", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'acc'", ":", "acc", ",", "\n", "'tok_per_s'", ":", "n_word", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"acc: {acc*100:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.accuracy_count": [[419, 424], ["out.max"], "function", ["None"], ["", "def", "accuracy_count", "(", "out", ",", "labels", ")", ":", "\n", "    ", "outputs", "=", "out", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "mask", "=", "labels", "!=", "-", "1", "\n", "n_correct", "=", "(", "outputs", "==", "labels", ")", ".", "masked_select", "(", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrfr": [[426, 445], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "utils.logger.LOGGER.info", "model", "batch[].sum().item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "model.sum().item", "batch[].sum", "int", "model.sum"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mrfr", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MRFR validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_feat", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "loss", "=", "model", "(", "batch", ",", "task", "=", "'mrfr'", ",", "compute_loss", "=", "True", ")", "\n", "val_loss", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "IMG_DIM", "\n", "n_feat", "+=", "batch", "[", "'img_mask_tgt'", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "n_feat", "=", "sum", "(", "all_gather_list", "(", "n_feat", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_feat", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'feat_per_s'", ":", "n_feat", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"loss: {val_loss:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_mrc": [[447, 487], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "utils.logger.LOGGER.info", "model", "F.cross_entropy.item", "batch[].sum().item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "torch.nn.functional.log_softmax", "torch.nn.functional.kl_div", "pretrain.compute_accuracy_for_soft_targets", "torch.nn.functional.cross_entropy", "pretrain.compute_accuracy_for_soft_targets", "batch[].sum", "int", "label_targets[].max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.compute_accuracy_for_soft_targets", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.compute_accuracy_for_soft_targets"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_mrc", "(", "model", ",", "val_loader", ",", "task", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running MRC validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "n_feat", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "tot_score", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "prediction_soft_label", "=", "model", "(", "\n", "batch", ",", "task", "=", "task", ",", "compute_loss", "=", "False", ")", "\n", "if", "\"kl\"", "in", "task", ":", "\n", "            ", "prediction_soft_label", "=", "F", ".", "log_softmax", "(", "\n", "prediction_soft_label", ",", "dim", "=", "-", "1", ")", "\n", "label_targets", "=", "batch", "[", "'label_targets'", "]", "\n", "loss", "=", "F", ".", "kl_div", "(", "\n", "prediction_soft_label", ",", "label_targets", ",", "reduction", "=", "'sum'", ")", "\n", "tot_score", "+=", "compute_accuracy_for_soft_targets", "(", "\n", "prediction_soft_label", ",", "label_targets", ")", "\n", "", "else", ":", "\n", "# background class should not be the target", "\n", "            ", "cls_label_targets", "=", "label_targets", "[", ":", ",", "1", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "+", "1", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "prediction_soft_label", ",", "cls_label_targets", ",", "\n", "ignore_index", "=", "0", ",", "reduction", "=", "'sum'", ")", "\n", "tot_score", "+=", "compute_accuracy_for_soft_targets", "(", "\n", "prediction_soft_label", "[", ":", ",", "1", ":", "]", ",", "label_targets", "[", ":", ",", "1", ":", "]", ")", "\n", "", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_feat", "+=", "batch", "[", "'img_mask_tgt'", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_feat", "=", "sum", "(", "all_gather_list", "(", "n_feat", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_feat", "\n", "val_acc", "=", "tot_score", "/", "n_feat", "\n", "val_log", "=", "{", "'loss'", ":", "val_loss", ",", "\n", "'acc'", ":", "val_acc", ",", "\n", "'feat_per_s'", ":", "n_feat", "/", "tot_time", "}", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.compute_accuracy_for_soft_targets": [[489, 494], ["out.max", "labels.max"], "function", ["None"], ["", "def", "compute_accuracy_for_soft_targets", "(", "out", ",", "labels", ")", ":", "\n", "    ", "outputs", "=", "out", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "labels", "=", "labels", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "# argmax", "\n", "n_correct", "=", "(", "outputs", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.pretrain.validate_itm": [[496, 545], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "time.time", "enumerate", "sum", "sum", "sum", "utils.logger.LOGGER.info", "model", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "len", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "sum", "sum", "sum", "isinstance", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "ot_pos.sum().item.sum().item", "ot_neg.sum().item.sum().item", "ot_loss.sum().item", "int", "ot_pos.sum().item.sum", "ot_neg.sum().item.sum", "ot_loss.sum", "scores.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate_itm", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running ITM validation...\"", ")", "\n", "val_loss", "=", "0", "\n", "tot_ot_loss", "=", "0", "\n", "tot_ot_pos", "=", "0", "\n", "tot_ot_neg", "=", "0", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", ",", "ot_loss", "=", "model", "(", "batch", ",", "task", "=", "'itm'", ",", "compute_loss", "=", "False", ")", "\n", "if", "ot_loss", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "ot_loss", ",", "tuple", ")", ":", "\n", "                ", "ot_pos", ",", "ot_neg", "=", "ot_loss", "\n", "ot_pos", "=", "ot_pos", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "ot_neg", "=", "ot_neg", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "tot_ot_pos", "+=", "ot_pos", "\n", "tot_ot_neg", "+=", "ot_neg", "\n", "tot_ot_loss", "+=", "ot_pos", "-", "ot_neg", "\n", "", "else", ":", "\n", "                ", "tot_ot_loss", "+=", "ot_loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "targets", "=", "batch", "[", "'targets'", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "targets", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "tot_score", "+=", "(", "scores", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "==", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_ex", "+=", "len", "(", "targets", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/loss'", ":", "val_loss", ",", "\n", "'valid/acc'", ":", "val_acc", ",", "\n", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "\n", "if", "ot_loss", "is", "not", "None", ":", "\n", "        ", "tot_ot_loss", "=", "sum", "(", "all_gather_list", "(", "tot_ot_loss", ")", ")", "\n", "tot_ot_pos", "=", "sum", "(", "all_gather_list", "(", "tot_ot_pos", ")", ")", "\n", "tot_ot_neg", "=", "sum", "(", "all_gather_list", "(", "tot_ot_neg", ")", ")", "\n", "val_log", "[", "'valid/ot_loss'", "]", "=", "tot_ot_loss", "/", "n_ex", "\n", "val_log", "[", "'valid/ot_pos'", "]", "=", "tot_ot_pos", "/", "n_ex", "\n", "val_log", "[", "'valid/ot_neg'", "]", "=", "tot_ot_neg", "/", "n_ex", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm_hard_negatives.build_dataloader": [[37, 44], ["torch.utils.data.DataLoader", "data.PrefetchLoader", "data.itm_rank_hn_collate", "data.itm_rank_hn_collate", "data.itm_val_collate", "data.itm_eval_collate", "data.itm_eval_collate"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_rank_hn_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_rank_hn_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_val_collate"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "is_train", ",", "drop_last", "=", "is_train", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "dataloader", "=", "PrefetchLoader", "(", "dataloader", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm_hard_negatives.main": [[46, 296], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "utils.logger.LOGGER.info", "data.ImageLmdbGroup", "utils.logger.LOGGER.info", "zip", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "train_itm_hard_negatives.build_dataloader", "train_itm_hard_negatives.build_dataloader", "utils.logger.LOGGER.info", "data.TxtTokLmdb", "data.ItmValDataset", "train_itm_hard_negatives.build_dataloader", "utils.logger.LOGGER.info", "data.ItmEvalDataset", "train_itm_hard_negatives.build_dataloader", "data.TxtTokLmdb", "data.ItmEvalDataset", "train_itm_hard_negatives.build_dataloader", "model.itm.UniterForImageTextRetrievalHardNeg.from_pretrained", "UniterForImageTextRetrievalHardNeg.from_pretrained.init_output", "UniterForImageTextRetrievalHardNeg.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "optim.misc.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForImageTextRetrievalHardNeg.from_pretrained.train", "time.time", "iter", "optim.misc.build_optimizer.zero_grad", "optim.misc.build_optimizer.step", "utils.misc.NoOp.close", "train_itm_hard_negatives.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "utils.logger.LOGGER.info", "horovod.torch.local_rank", "horovod.torch.local_rank", "horovod.torch.rank", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "utils.logger.add_log_to_file", "os.makedirs", "os.makedirs", "os.makedirs", "utils.misc.NoOp", "utils.misc.NoOp", "len", "len", "data.TxtTokLmdb", "train_datasets_t.append", "train_datasets_i.append", "torch.load", "horovod.torch.load", "sum", "utils.itm_eval.evaluate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.LOGGER.info", "horovod.torch.rank", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "data.ItmRankDatasetHardNegFromText", "data.ItmRankDatasetHardNegFromImage", "utils.distributed.all_gather_list", "batch_i[].size", "UniterForImageTextRetrievalHardNeg.from_pretrained.", "model.numel", "batch[].size", "UniterForImageTextRetrievalHardNeg.from_pretrained.", "model.numel", "utils.logger.RunningMeter.", "horovod.torch.rank", "UniterForImageTextRetrievalHardNeg.from_pretrained.parameters", "len", "next", "model.mean", "apex.amp.scale_loss", "scaled_loss.backward", "model.mean", "apex.amp.scale_loss", "scaled_loss.backward", "model.item", "optim.get_lr_sched", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "optim.misc.build_optimizer.step", "optim.misc.build_optimizer.zero_grad", "utils.misc.NoOp.update", "iter", "next", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "utils.misc.NoOp.save", "utils.itm_eval.evaluate.items", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.logger.LOGGER.info", "utils.itm_eval.evaluate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "train_itm_hard_negatives.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "UniterForImageTextRetrievalHardNeg.from_pretrained.parameters", "time.time", "time.time", "validate.items"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.init_output", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "# store ITM predictions", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_val'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_test'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results_train'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "# train_examples = None", "\n", "", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.train_txt_dbs}, \"", "\n", "f\"{opts.train_img_dbs}\"", ")", "\n", "# check multiple DBs", "\n", "assert", "len", "(", "opts", ".", "train_txt_dbs", ")", "==", "len", "(", "opts", ".", "train_img_dbs", ")", ",", "\"train txt_db and img_db have different length\"", "\n", "\n", "# load DBs and image dirs", "\n", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "# train", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset \"", "\n", "f\"{opts.train_txt_dbs}, {opts.train_img_dbs}\"", ")", "\n", "train_datasets_t", "=", "[", "]", "\n", "train_datasets_i", "=", "[", "]", "\n", "for", "txt_path", ",", "img_path", "in", "zip", "(", "opts", ".", "train_txt_dbs", ",", "opts", ".", "train_img_dbs", ")", ":", "\n", "        ", "img_db", "=", "all_img_dbs", "[", "img_path", "]", "\n", "txt_db", "=", "TxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", ")", "\n", "train_datasets_t", ".", "append", "(", "\n", "ItmRankDatasetHardNegFromText", "(", "txt_db", ",", "img_db", ",", "opts", ".", "negative_size", ")", ")", "\n", "train_datasets_i", ".", "append", "(", "\n", "ItmRankDatasetHardNegFromImage", "(", "txt_db", ",", "img_db", ",", "opts", ".", "negative_size", ")", ")", "\n", "", "train_dataset_t", "=", "ConcatDataset", "(", "train_datasets_t", ")", "\n", "train_dataset_i", "=", "ConcatDataset", "(", "train_datasets_i", ")", "\n", "train_dataloader_t", "=", "build_dataloader", "(", "\n", "train_dataset_t", ",", "itm_rank_hn_collate", ",", "True", ",", "opts", ")", "\n", "train_dataloader_i", "=", "build_dataloader", "(", "\n", "train_dataset_i", ",", "itm_rank_hn_collate", ",", "True", ",", "opts", ")", "\n", "\n", "# val", "\n", "LOGGER", ".", "info", "(", "f\"Loading Val Dataset {opts.val_txt_db}, {opts.val_img_db}\"", ")", "\n", "val_img_db", "=", "all_img_dbs", "[", "opts", ".", "val_img_db", "]", "\n", "val_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "val_txt_db", ",", "-", "1", ")", "\n", "val_dataset", "=", "ItmValDataset", "(", "val_txt_db", ",", "val_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "val_dataset", ",", "itm_val_collate", ",", "\n", "False", ",", "opts", ")", "\n", "# eval", "\n", "LOGGER", ".", "info", "(", "f\"Loading val, test Dataset for full evaluation: \"", "\n", "f\"{opts.val_txt_db}, {opts.val_img_db}\"", "\n", "f\"{opts.test_txt_db}, {opts.test_img_db}\"", ")", "\n", "eval_dataset_val", "=", "ItmEvalDataset", "(", "val_txt_db", ",", "val_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "eval_loader_val", "=", "build_dataloader", "(", "eval_dataset_val", ",", "itm_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "test_img_db", "=", "all_img_dbs", "[", "opts", ".", "test_img_db", "]", "\n", "test_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "test_txt_db", ",", "-", "1", ")", "\n", "eval_dataset_test", "=", "ItmEvalDataset", "(", "test_txt_db", ",", "test_img_db", ",", "\n", "opts", ".", "inf_minibatch_size", ")", "\n", "eval_loader_test", "=", "build_dataloader", "(", "eval_dataset_test", ",", "itm_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "model", "=", "UniterForImageTextRetrievalHardNeg", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "state_dict", "=", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "margin", "=", "opts", ".", "margin", ",", "hard_size", "=", "opts", ".", "hard_neg_size", ")", "\n", "model", ".", "init_output", "(", ")", "# pretrain ITM head is different from ranking head", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "LOGGER", ".", "info", "(", "f\"***** Running training on {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "\n", "sum", "(", "all_gather_list", "(", "len", "(", "train_dataset_t", ")", ")", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "global_step", "=", "0", "\n", "step", "=", "0", "\n", "n_examples", "=", "0", "\n", "n_hard_ex", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "train_iter_i", "=", "iter", "(", "train_dataloader_i", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "for", "batch", "in", "train_dataloader_t", ":", "\n", "\n", "# hard text from image", "\n", "            ", "try", ":", "\n", "                ", "batch_i", "=", "next", "(", "train_iter_i", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "train_iter_i", "=", "iter", "(", "train_dataloader_i", ")", "\n", "batch_i", "=", "next", "(", "train_iter_i", ")", "\n", "", "n_examples", "+=", "batch_i", "[", "'attn_masks'", "]", ".", "size", "(", "0", ")", "\n", "loss", "=", "model", "(", "batch_i", ",", "sample_from", "=", "'i'", ",", "compute_loss", "=", "True", ")", "\n", "n_hard_ex", "+=", "loss", ".", "numel", "(", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "/", "opts", ".", "train_batch_size", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "True", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "\n", "# hard image from text", "\n", "", "n_examples", "+=", "batch", "[", "'attn_masks'", "]", ".", "size", "(", "0", ")", "\n", "loss", "=", "model", "(", "batch", ",", "sample_from", "=", "'t'", ",", "compute_loss", "=", "True", ")", "\n", "n_hard_ex", "+=", "loss", ".", "numel", "(", ")", "\n", "# NOTE we use gradient accumulation to implemented train_batch_size", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "/", "opts", ".", "train_batch_size", "\n", "\n", "step", "+=", "1", "\n", "delay_unscale", "=", "step", "%", "opts", ".", "train_batch_size", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "if", "step", "%", "opts", ".", "train_batch_size", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'------------Step {global_step}-------------'", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "tot_hn", "=", "sum", "(", "all_gather_list", "(", "n_hard_ex", ")", ")", "\n", "hn_per_sec", "=", "int", "(", "tot_hn", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} ({tot_hn}) examples (hard) '", "\n", "f'trained at {ex_per_sec} ({hn_per_sec}) ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/hn_per_s'", ",", "\n", "hn_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "f'-------------------------------------------'", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "if", "opts", ".", "full_val", ":", "\n", "                        ", "LOGGER", ".", "info", "(", "\n", "f\"========================== Step {global_step} \"", "\n", "f\"==========================\"", ")", "\n", "val_log", "=", "evaluate", "(", "model", ",", "eval_loader_val", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "\n", "{", "f\"valid/{k}\"", ":", "v", "for", "k", ",", "v", "in", "val_log", ".", "items", "(", ")", "}", ")", "\n", "LOGGER", ".", "info", "(", "f\"image retrieval R1: \"", "\n", "f\"{val_log['img_r1']*100:.2f},\\n\"", "\n", "f\"image retrieval R5: \"", "\n", "f\"{val_log['img_r5']*100:.2f},\\n\"", "\n", "f\"image retrieval R10: \"", "\n", "f\"{val_log['img_r10']*100:.2f}\\n\"", "\n", "f\"text retrieval R1: \"", "\n", "f\"{val_log['txt_r1']*100:.2f},\\n\"", "\n", "f\"text retrieval R5: \"", "\n", "f\"{val_log['txt_r5']*100:.2f},\\n\"", "\n", "f\"text retrieval R10: \"", "\n", "f\"{val_log['txt_r10']*100:.2f}\"", ")", "\n", "LOGGER", ".", "info", "(", "\"=================================\"", "\n", "\"=================================\"", ")", "\n", "", "else", ":", "\n", "                        ", "val_log", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "# final validation", "\n", "val_log", "=", "validate", "(", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "f'{global_step}_final'", ")", "\n", "\n", "# evaluation", "\n", "for", "split", ",", "loader", "in", "[", "(", "'val'", ",", "eval_loader_val", ")", ",", "\n", "(", "'test'", ",", "eval_loader_test", ")", "]", ":", "\n", "        ", "eval_log", "=", "evaluate", "(", "model", ",", "loader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "{", "f\"eval/{split}_{k}\"", ":", "v", "\n", "for", "k", ",", "v", "in", "eval_log", ".", "items", "(", ")", "}", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "!=", "0", ":", "\n", "            ", "continue", "\n", "", "LOGGER", ".", "info", "(", "\n", "f\"========================= {split} ===========================\\n\"", "\n", "f\"image retrieval R1: {eval_log['img_r1']*100:.2f},\\n\"", "\n", "f\"image retrieval R5: {eval_log['img_r5']*100:.2f},\\n\"", "\n", "f\"image retrieval R10: {eval_log['img_r10']*100:.2f}\\n\"", "\n", "f\"text retrieval R1: {eval_log['txt_r1']*100:.2f},\\n\"", "\n", "f\"text retrieval R5: {eval_log['txt_r5']*100:.2f},\\n\"", "\n", "f\"text retrieval R10: {eval_log['txt_r10']*100:.2f}\"", ")", "\n", "", "LOGGER", ".", "info", "(", "\"=========================================================\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_itm_hard_negatives.validate": [[298, 340], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "sum", "model.train", "utils.logger.LOGGER.info", "utils.misc.NoOp.close", "horovod.torch.rank", "tqdm.tqdm", "utils.misc.NoOp", "model", "model.squeeze().topk", "rank.item.numel", "utils.misc.NoOp.update", "utils.distributed.all_gather_list", "sum", "sum", "sum", "time.time", "rank.item.item", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "len", "model.squeeze", "int"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "val_loader", ")", ")", "\n", "", "else", ":", "\n", "        ", "pbar", "=", "NoOp", "(", ")", "\n", "", "LOGGER", ".", "info", "(", "\"start running Image Retrieval validation ...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "\n", "recall_at_1", ",", "recall_at_5", ",", "recall_at_10", "=", "0", ",", "0", ",", "0", "\n", "for", "batch", "in", "val_loader", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "_", ",", "indices", "=", "scores", ".", "squeeze", "(", "1", ")", ".", "topk", "(", "10", ",", "dim", "=", "0", ")", "\n", "rank", "=", "(", "indices", "==", "0", ")", ".", "nonzero", "(", ")", "\n", "if", "rank", ".", "numel", "(", ")", ":", "\n", "            ", "rank", "=", "rank", ".", "item", "(", ")", "\n", "if", "rank", "<", "1", ":", "\n", "                ", "recall_at_1", "+=", "1", "\n", "", "if", "rank", "<", "5", ":", "\n", "                ", "recall_at_5", "+=", "1", "\n", "", "if", "rank", "<", "10", ":", "\n", "                ", "recall_at_10", "+=", "1", "\n", "", "", "n_ex", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "recall_at_1", "=", "sum", "(", "all_gather_list", "(", "recall_at_1", ")", ")", "/", "n_ex", "\n", "recall_at_5", "=", "sum", "(", "all_gather_list", "(", "recall_at_5", ")", ")", "/", "n_ex", "\n", "recall_at_10", "=", "sum", "(", "all_gather_list", "(", "recall_at_10", ")", ")", "/", "n_ex", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_log", "=", "{", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", ",", "\n", "'valid/recall_1'", ":", "recall_at_1", ",", "\n", "'valid/recall_5'", ":", "recall_at_5", ",", "\n", "'valid/recall_10'", ":", "recall_at_10", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"recall_1: {recall_at_1*100:.2f}, \"", "\n", "f\"recall_5: {recall_at_5*100:.2f}, \"", "\n", "f\"recall_10: {recall_at_10*100:.2f}\"", ")", "\n", "pbar", ".", "close", "(", ")", "\n", "return", "val_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vqa.main": [[31, 97], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.Struct", "json.load", "data.DetectFeatLmdb", "data.TxtTokLmdb", "data.VqaEvalDataset", "os.path.exists", "torch.load", "horovod.torch.load", "model.vqa.UniterForVisualQuestionAnswering.from_pretrained", "amp.initialize.to", "data.TokenBucketSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "inf_vqa.evaluate", "list", "horovod.torch.local_rank", "horovod.torch.local_rank", "json.load", "open", "len", "apex.amp.initialize", "os.makedirs", "cytoolz.concat", "utils.distributed.all_gather_list", "horovod.torch.rank", "horovod.torch.rank", "open", "json.load.items", "len", "os.path.exists", "utils.distributed.all_gather_list", "all_logits.update", "open", "json.dump", "numpy.savez"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "hps_file", "=", "f'{opts.output_dir}/log/hps.json'", "\n", "model_opts", "=", "Struct", "(", "json", ".", "load", "(", "open", "(", "hps_file", ")", ")", ")", "\n", "\n", "# train_examples = None", "\n", "ans2label_file", "=", "f'{opts.output_dir}/ckpt/ans2label.json'", "\n", "ans2label", "=", "json", ".", "load", "(", "open", "(", "ans2label_file", ")", ")", "\n", "label2ans", "=", "{", "label", ":", "ans", "for", "ans", ",", "label", "in", "ans2label", ".", "items", "(", ")", "}", "\n", "\n", "# load DBs and image dirs", "\n", "eval_img_db", "=", "DetectFeatLmdb", "(", "opts", ".", "img_db", ",", "\n", "model_opts", ".", "conf_th", ",", "model_opts", ".", "max_bb", ",", "\n", "model_opts", ".", "min_bb", ",", "model_opts", ".", "num_bb", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "eval_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "txt_db", ",", "-", "1", ")", "\n", "eval_dataset", "=", "VqaEvalDataset", "(", "len", "(", "ans2label", ")", ",", "eval_txt_db", ",", "eval_img_db", ")", "\n", "\n", "# Prepare model", "\n", "if", "exists", "(", "opts", ".", "checkpoint", ")", ":", "\n", "        ", "ckpt_file", "=", "opts", ".", "checkpoint", "\n", "", "else", ":", "\n", "        ", "ckpt_file", "=", "f'{opts.output_dir}/ckpt/model_step_{opts.checkpoint}.pt'", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_file", ")", "\n", "model", "=", "UniterForVisualQuestionAnswering", ".", "from_pretrained", "(", "\n", "f'{opts.output_dir}/log/model.json'", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "num_answer", "=", "len", "(", "ans2label", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "if", "opts", ".", "fp16", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "enabled", "=", "True", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "", "sampler", "=", "TokenBucketSampler", "(", "eval_dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "opts", ".", "batch_size", ",", "droplast", "=", "False", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "\n", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "vqa_eval_collate", ")", "\n", "eval_dataloader", "=", "PrefetchLoader", "(", "eval_dataloader", ")", "\n", "\n", "val_log", ",", "results", ",", "logits", "=", "evaluate", "(", "model", ",", "eval_dataloader", ",", "label2ans", ",", "\n", "opts", ".", "save_logits", ")", "\n", "result_dir", "=", "f'{opts.output_dir}/results_test'", "\n", "if", "not", "exists", "(", "result_dir", ")", "and", "rank", "==", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "result_dir", ")", "\n", "\n", "", "all_results", "=", "list", "(", "concat", "(", "all_gather_list", "(", "results", ")", ")", ")", "\n", "if", "opts", ".", "save_logits", ":", "\n", "        ", "all_logits", "=", "{", "}", "\n", "for", "id2logit", "in", "all_gather_list", "(", "logits", ")", ":", "\n", "            ", "all_logits", ".", "update", "(", "id2logit", ")", "\n", "", "", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "with", "open", "(", "f'{result_dir}/'", "\n", "f'results_{opts.checkpoint}_all.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "all_results", ",", "f", ")", "\n", "", "if", "opts", ".", "save_logits", ":", "\n", "            ", "np", ".", "savez", "(", "f'{result_dir}/logits_{opts.checkpoint}_all.npz'", ",", "\n", "**", "all_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vqa.evaluate": [[99, 132], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "enumerate", "sum", "model.train", "utils.logger.LOGGER.info", "model", "zip", "len", "utils.distributed.all_gather_list", "time.time", "results.append", "scores.cpu.cpu", "enumerate", "len", "horovod.torch.size", "utils.logger.LOGGER.info", "[].cpu().tolist", "scores[].half().numpy", "horovod.torch.rank", "int", "int", "int", "[].cpu", "scores[].half", "len", "scores.cpu.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ",", "label2ans", ",", "save_logits", "=", "False", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running evaluation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "logits", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "        ", "qids", "=", "batch", "[", "'qids'", "]", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "answers", "=", "[", "label2ans", "[", "i", "]", "\n", "for", "i", "in", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", "\n", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", "\n", "for", "qid", ",", "answer", "in", "zip", "(", "qids", ",", "answers", ")", ":", "\n", "            ", "results", ".", "append", "(", "{", "'answer'", ":", "answer", ",", "'question_id'", ":", "int", "(", "qid", ")", "}", ")", "\n", "", "if", "save_logits", ":", "\n", "            ", "scores", "=", "scores", ".", "cpu", "(", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qids", ")", ":", "\n", "                ", "logits", "[", "qid", "]", "=", "scores", "[", "i", "]", ".", "half", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "if", "i", "%", "100", "==", "0", "and", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "            ", "n_results", "=", "len", "(", "results", ")", "\n", "n_results", "*=", "hvd", ".", "size", "(", ")", "# an approximation to avoid hangs", "\n", "LOGGER", ".", "info", "(", "f'{n_results}/{len(eval_loader.dataset)} '", "\n", "'answers predicted'", ")", "\n", "", "n_ex", "+=", "len", "(", "qids", ")", "\n", "", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_log", "=", "{", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"evaluation finished in {int(tot_time)} seconds \"", "\n", "f\"at {int(n_ex/tot_time)} examples per second\"", ")", "\n", "return", "val_log", ",", "results", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_vqa.compute_score_with_logits": [[134, 140], ["torch.zeros", "horovod.torch.zeros", "torch.zeros.scatter_", "torch.max", "horovod.torch.max", "logits.view", "labels.size"], "function", ["None"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ",", "device", "=", "labels", ".", "device", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_nlvr2.main": [[25, 81], ["horovod.torch.init", "torch.device", "horovod.torch.device", "utils.misc.Struct", "data.DetectFeatLmdb", "data.TxtTokLmdb", "EvalDatasetCls", "data.TokenBucketSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "torch.load", "horovod.torch.load", "model.model.UniterConfig.from_json_file", "ModelCls", "amp.initialize.init_type_embedding", "amp.initialize.load_state_dict", "amp.initialize.to", "apex.amp.initialize", "inf_nlvr2.evaluate", "print", "json.load", "os.path.exists", "os.makedirs", "open", "open", "ValueError", "f.write", "ValueError"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.from_json_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate"], ["def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "# support single GPU only", "\n", "train_opts", "=", "Struct", "(", "json", ".", "load", "(", "open", "(", "f'{opts.train_dir}/log/hps.json'", ")", ")", ")", "\n", "\n", "if", "'paired'", "in", "train_opts", ".", "model", ":", "\n", "        ", "EvalDatasetCls", "=", "Nlvr2PairedEvalDataset", "\n", "eval_collate_fn", "=", "nlvr2_paired_eval_collate", "\n", "if", "train_opts", ".", "model", "==", "'paired'", ":", "\n", "            ", "ModelCls", "=", "UniterForNlvr2Paired", "\n", "", "elif", "train_opts", ".", "model", "==", "'paired-attn'", ":", "\n", "            ", "ModelCls", "=", "UniterForNlvr2PairedAttn", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unrecognized model type'", ")", "\n", "", "", "elif", "train_opts", ".", "model", "==", "'triplet'", ":", "\n", "        ", "EvalDatasetCls", "=", "Nlvr2TripletEvalDataset", "\n", "ModelCls", "=", "UniterForNlvr2Triplet", "\n", "eval_collate_fn", "=", "nlvr2_triplet_eval_collate", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unrecognized model type'", ")", "\n", "\n", "", "img_db", "=", "DetectFeatLmdb", "(", "opts", ".", "img_db", ",", "\n", "train_opts", ".", "conf_th", ",", "train_opts", ".", "max_bb", ",", "\n", "train_opts", ".", "min_bb", ",", "train_opts", ".", "num_bb", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "txt_db", ",", "-", "1", ")", "\n", "dset", "=", "EvalDatasetCls", "(", "txt_db", ",", "img_db", ",", "train_opts", ".", "use_img_type", ")", "\n", "batch_size", "=", "(", "train_opts", ".", "val_batch_size", "if", "opts", ".", "batch_size", "is", "None", "\n", "else", "opts", ".", "batch_size", ")", "\n", "sampler", "=", "TokenBucketSampler", "(", "dset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "False", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "eval_collate_fn", ")", "\n", "eval_dataloader", "=", "PrefetchLoader", "(", "eval_dataloader", ")", "\n", "\n", "# Prepare model", "\n", "ckpt_file", "=", "f'{opts.train_dir}/ckpt/model_step_{opts.ckpt}.pt'", "\n", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_file", ")", "\n", "model_config", "=", "UniterConfig", ".", "from_json_file", "(", "\n", "f'{opts.train_dir}/log/model.json'", ")", "\n", "model", "=", "ModelCls", "(", "model_config", ",", "img_dim", "=", "IMG_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", "=", "amp", ".", "initialize", "(", "model", ",", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "results", "=", "evaluate", "(", "model", ",", "eval_dataloader", ",", "device", ")", "\n", "# write results", "\n", "if", "not", "exists", "(", "opts", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "opts", ".", "output_dir", ")", "\n", "", "with", "open", "(", "f'{opts.output_dir}/results.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "id_", ",", "ans", "in", "results", ":", "\n", "            ", "f", ".", "write", "(", "f'{id_},{ans}\\n'", ")", "\n", "", "", "print", "(", "f'all results written'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_nlvr2.evaluate": [[83, 107], ["torch.no_grad", "horovod.torch.no_grad", "print", "model.eval", "time.time", "enumerate", "model.train", "print", "model", "results.extend", "len", "print", "len", "time.time", "zip", "[].cpu().tolist", "int", "int", "len", "[].cpu", "model.max"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ",", "device", ")", ":", "\n", "    ", "print", "(", "\"start running evaluation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "        ", "qids", "=", "batch", "[", "'qids'", "]", "\n", "del", "batch", "[", "'targets'", "]", "\n", "del", "batch", "[", "'qids'", "]", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "answers", "=", "[", "'True'", "if", "i", "==", "1", "else", "'False'", "\n", "for", "i", "in", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", "\n", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", "\n", "results", ".", "extend", "(", "zip", "(", "qids", ",", "answers", ")", ")", "\n", "n_results", "=", "len", "(", "results", ")", "\n", "print", "(", "f'{n_results}/{len(eval_loader.dataset)} answers predicted'", ")", "\n", "n_ex", "+=", "len", "(", "qids", ")", "\n", "", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "model", ".", "train", "(", ")", "\n", "print", "(", "f\"evaluation finished in {int(tot_time)} seconds \"", "\n", "f\"at {int(n_ex/tot_time)} examples per second\"", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.build_dataloader": [[39, 49], ["data.TokenBucketSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "data.vqa_collate", "data.vqa_eval_collate"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.vqa_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.vqa_eval_collate"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "batch_size", "=", "(", "opts", ".", "train_batch_size", "if", "is_train", "\n", "else", "opts", ".", "val_batch_size", ")", "\n", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "dataloader", "=", "PrefetchLoader", "(", "dataloader", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.build_optimizer": [[51, 87], ["OptimCls", "model.named_parameters", "model.named_parameters", "ValueError", "any", "any", "any", "any"], "function", ["None"], ["", "def", "build_optimizer", "(", "model", ",", "opts", ")", ":", "\n", "    ", "\"\"\" vqa linear may get larger learning rate \"\"\"", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'vqa_output'", "not", "in", "n", "]", "\n", "param_top", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'vqa_output'", "in", "n", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "# currently Adam only", "\n", "if", "opts", ".", "optim", "==", "'adam'", ":", "\n", "        ", "OptimCls", "=", "Adam", "\n", "", "elif", "opts", ".", "optim", "==", "'adamax'", ":", "\n", "        ", "OptimCls", "=", "Adamax", "\n", "", "elif", "opts", ".", "optim", "==", "'adamw'", ":", "\n", "        ", "OptimCls", "=", "AdamW", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid optimizer'", ")", "\n", "", "optimizer", "=", "OptimCls", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "opts", ".", "learning_rate", ",", "betas", "=", "opts", ".", "betas", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.main": [[89, 265], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "json.load", "data.ImageLmdbGroup", "utils.logger.LOGGER.info", "zip", "data.ConcatDatasetWithLens", "train_vqa.build_dataloader", "utils.logger.LOGGER.info", "data.TxtTokLmdb", "data.VqaEvalDataset", "train_vqa.build_dataloader", "all", "model.vqa.UniterForVisualQuestionAnswering.from_pretrained", "UniterForVisualQuestionAnswering.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "train_vqa.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForVisualQuestionAnswering.from_pretrained.train", "time.time", "build_optimizer.zero_grad", "build_optimizer.step", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "open", "data.TxtTokLmdb", "train_datasets.append", "len", "torch.load", "horovod.torch.load", "json.load", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "json.dump", "os.makedirs", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "enumerate", "utils.logger.LOGGER.info", "train_vqa.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "horovod.torch.rank", "json.load.items", "data.VqaDataset", "open", "len", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "len", "horovod.torch.size", "batch[].size", "UniterForVisualQuestionAnswering.from_pretrained.", "utils.logger.RunningMeter.", "open", "json.dump", "len", "UniterForVisualQuestionAnswering.from_pretrained.parameters", "os.path.join", "model.mean", "batch[].size", "apex.amp.scale_loss", "scaled_loss.backward", "model.item", "optim.get_lr_sched", "enumerate", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "build_optimizer.step", "build_optimizer.zero_grad", "utils.misc.NoOp.update", "os.path.dirname", "json.load", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "train_vqa.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "os.path.abspath", "open", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "open", "json.dump", "UniterForVisualQuestionAnswering.from_pretrained.parameters", "ValueError", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "ans2label", "=", "json", ".", "load", "(", "open", "(", "f'{dirname(abspath(__file__))}'", "\n", "f'/utils/ans2label.json'", ")", ")", "\n", "label2ans", "=", "{", "label", ":", "ans", "for", "ans", ",", "label", "in", "ans2label", ".", "items", "(", ")", "}", "\n", "\n", "# load DBs and image dirs", "\n", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "# train", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset \"", "\n", "f\"{opts.train_txt_dbs}, {opts.train_img_dbs}\"", ")", "\n", "train_datasets", "=", "[", "]", "\n", "for", "txt_path", ",", "img_path", "in", "zip", "(", "opts", ".", "train_txt_dbs", ",", "opts", ".", "train_img_dbs", ")", ":", "\n", "        ", "img_db", "=", "all_img_dbs", "[", "img_path", "]", "\n", "txt_db", "=", "TxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", ")", "\n", "train_datasets", ".", "append", "(", "VqaDataset", "(", "len", "(", "ans2label", ")", ",", "txt_db", ",", "img_db", ")", ")", "\n", "", "train_dataset", "=", "ConcatDatasetWithLens", "(", "train_datasets", ")", "\n", "train_dataloader", "=", "build_dataloader", "(", "train_dataset", ",", "vqa_collate", ",", "True", ",", "opts", ")", "\n", "# val", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset {opts.val_txt_db}, {opts.val_img_db}\"", ")", "\n", "val_img_db", "=", "all_img_dbs", "[", "opts", ".", "val_img_db", "]", "\n", "val_txt_db", "=", "TxtTokLmdb", "(", "opts", ".", "val_txt_db", ",", "-", "1", ")", "\n", "val_dataset", "=", "VqaEvalDataset", "(", "len", "(", "ans2label", ")", ",", "val_txt_db", ",", "val_img_db", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "val_dataset", ",", "vqa_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "all_dbs", "=", "opts", ".", "train_txt_dbs", "+", "[", "opts", ".", "val_txt_db", "]", "\n", "toker", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "assert", "all", "(", "toker", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "model", "=", "UniterForVisualQuestionAnswering", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "num_answer", "=", "len", "(", "ans2label", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "global_step", "=", "0", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "json", ".", "dump", "(", "ans2label", ",", "\n", "open", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ",", "'ans2label.json'", ")", ",", "'w'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results'", ")", ")", "# store VQA predictions", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", "*", "hvd", ".", "size", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "n_examples", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "*", "batch", "[", "'targets'", "]", ".", "size", "(", "1", ")", "# instance-leval bce", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                    ", "if", "i", "==", "0", "or", "i", "==", "1", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "*", "opts", ".", "lr_mul", "\n", "", "elif", "i", "==", "2", "or", "i", "==", "3", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", ")", "\n", "", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'============Step {global_step}============='", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "f'==========================================='", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "val_log", ",", "results", "=", "validate", "(", "\n", "model", ",", "val_dataloader", ",", "label2ans", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'results_{global_step}_'", "\n", "f'rank{rank}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                        ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "n_epoch", "+=", "1", "\n", "LOGGER", ".", "info", "(", "f\"finished {n_epoch} epochs\"", ")", "\n", "", "if", "opts", ".", "num_train_steps", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "val_log", ",", "results", "=", "validate", "(", "model", ",", "val_dataloader", ",", "label2ans", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'results_{global_step}_'", "\n", "f'rank{rank}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.validate": [[267, 302], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "enumerate", "sum", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "model", "torch.nn.functional.binary_cross_entropy_with_logits", "F.binary_cross_entropy_with_logits.item", "compute_score_with_logits().sum().item", "zip", "len", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "compute_score_with_logits().sum", "[].cpu().tolist", "int", "train_vqa.compute_score_with_logits", "[].cpu", "model.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.compute_score_with_logits"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ",", "label2ans", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running validation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "val_loss", "=", "0", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "targets", "=", "batch", "[", "'targets'", "]", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "scores", ",", "targets", ",", "reduction", "=", "'sum'", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tot_score", "+=", "compute_score_with_logits", "(", "scores", ",", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "answers", "=", "[", "label2ans", "[", "i", "]", "\n", "for", "i", "in", "scores", ".", "max", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", "\n", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", "\n", "for", "qid", ",", "answer", "in", "zip", "(", "batch", "[", "'qids'", "]", ",", "answers", ")", ":", "\n", "            ", "results", "[", "qid", "]", "=", "answer", "\n", "", "n_ex", "+=", "len", "(", "batch", "[", "'qids'", "]", ")", "\n", "", "val_loss", "=", "sum", "(", "all_gather_list", "(", "val_loss", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_loss", "/=", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/loss'", ":", "val_loss", ",", "\n", "'valid/acc'", ":", "val_acc", ",", "\n", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score: {val_acc*100:.2f}\"", ")", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vqa.compute_score_with_logits": [[304, 310], ["torch.zeros", "horovod.torch.zeros", "torch.zeros.scatter_", "torch.max", "horovod.torch.max", "logits.view", "labels.size"], "function", ["None"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ",", "device", "=", "labels", ".", "device", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_re.write_to_tmp": [[31, 35], ["open", "open.write"], "function", ["None"], ["def", "write_to_tmp", "(", "txt", ",", "tmp_file", ")", ":", "\n", "    ", "if", "tmp_file", ":", "\n", "        ", "f", "=", "open", "(", "tmp_file", ",", "\"a\"", ")", "\n", "f", ".", "write", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_re.main": [[37, 115], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "json.load", "utils.misc.Struct", "os.path.exists", "torch.load", "horovod.torch.load", "model.re.UniterForReferringExpressionComprehension.from_pretrained", "amp.initialize.to", "horovod.torch.broadcast_parameters", "data.DetectFeatLmdb", "opts.txt_db.split", "inf_re.write_to_tmp", "horovod.torch.local_rank", "horovod.torch.local_rank", "open", "amp.initialize.state_dict", "apex.amp.initialize", "print", "data.ReTxtTokLmdb", "data.ReEvalDataset", "data.sampler.DistributedSampler", "torch.utils.data.DataLoader", "data.PrefetchLoader", "inf_re.evaluate", "inf_re.write_to_tmp", "list", "print", "horovod.torch.rank", "os.makedirs", "cytoolz.concat", "horovod.torch.rank", "os.path.exists", "utils.distributed.all_gather_list", "[].split", "opts.img_db.split", "open", "json.dump", "[].split", "txt_db.split", "txt_db.split"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_re.write_to_tmp", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_re.write_to_tmp", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "hps_file", "=", "f'{opts.output_dir}/log/hps.json'", "\n", "model_opts", "=", "json", ".", "load", "(", "open", "(", "hps_file", ")", ")", "\n", "if", "'mlp'", "not", "in", "model_opts", ":", "\n", "        ", "model_opts", "[", "'mlp'", "]", "=", "1", "\n", "", "model_opts", "=", "Struct", "(", "model_opts", ")", "\n", "# Prepare model", "\n", "if", "exists", "(", "opts", ".", "checkpoint", ")", ":", "\n", "        ", "ckpt_file", "=", "opts", ".", "checkpoint", "\n", "", "else", ":", "\n", "        ", "ckpt_file", "=", "f'{opts.output_dir}/ckpt/model_epoch_{opts.checkpoint}.pt'", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_file", ")", "\n", "model", "=", "UniterForReferringExpressionComprehension", ".", "from_pretrained", "(", "\n", "f'{opts.output_dir}/log/model.json'", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "mlp", "=", "model_opts", ".", "mlp", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "hvd", ".", "broadcast_parameters", "(", "model", ".", "state_dict", "(", ")", ",", "root_rank", "=", "0", ")", "\n", "if", "opts", ".", "fp16", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "enabled", "=", "True", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "# load DBs and image dirs", "\n", "", "img_db_type", "=", "\"gt\"", "if", "\"coco_gt\"", "in", "opts", ".", "img_db", "else", "\"det\"", "\n", "conf_th", "=", "-", "1", "if", "img_db_type", "==", "\"gt\"", "else", "model_opts", ".", "conf_th", "\n", "num_bb", "=", "100", "if", "img_db_type", "==", "\"gt\"", "else", "model_opts", ".", "num_bb", "\n", "eval_img_db", "=", "DetectFeatLmdb", "(", "opts", ".", "img_db", ",", "\n", "conf_th", ",", "model_opts", ".", "max_bb", ",", "\n", "model_opts", ".", "min_bb", ",", "num_bb", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "\n", "# Prepro txt_dbs", "\n", "txt_dbs", "=", "opts", ".", "txt_db", ".", "split", "(", "':'", ")", "\n", "for", "txt_db", "in", "txt_dbs", ":", "\n", "        ", "print", "(", "f'Evaluating {txt_db}'", ")", "\n", "eval_txt_db", "=", "ReTxtTokLmdb", "(", "txt_db", ",", "-", "1", ")", "\n", "eval_dataset", "=", "ReEvalDataset", "(", "\n", "eval_txt_db", ",", "eval_img_db", ",", "use_gt_feat", "=", "img_db_type", "==", "\"gt\"", ")", "\n", "\n", "sampler", "=", "DistributedSampler", "(", "eval_dataset", ",", "num_replicas", "=", "n_gpu", ",", "\n", "rank", "=", "rank", ",", "shuffle", "=", "False", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "opts", ".", "batch_size", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "re_eval_collate", ")", "\n", "eval_dataloader", "=", "PrefetchLoader", "(", "eval_dataloader", ")", "\n", "\n", "# evaluate", "\n", "val_log", ",", "results", "=", "evaluate", "(", "model", ",", "eval_dataloader", ")", "\n", "\n", "result_dir", "=", "f'{opts.output_dir}/results_test'", "\n", "if", "not", "exists", "(", "result_dir", ")", "and", "rank", "==", "0", ":", "\n", "            ", "os", ".", "makedirs", "(", "result_dir", ")", "\n", "", "write_to_tmp", "(", "\n", "f\"{txt_db.split('_')[1].split('.')[0]}-acc({img_db_type}): {results['acc']*100:.2f}% \"", ",", "\n", "args", ".", "tmp_file", ")", "\n", "\n", "all_results", "=", "list", "(", "concat", "(", "all_gather_list", "(", "results", ")", ")", ")", "\n", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "            ", "db_split", "=", "txt_db", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "# refcoco+_val", "\n", "img_dir", "=", "opts", ".", "img_db", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "# re_coco_gt", "\n", "with", "open", "(", "f'{result_dir}/'", "\n", "f'results_{opts.checkpoint}_{db_split}_on_{img_dir}_all.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "all_results", ",", "f", ")", "\n", "# print", "\n", "", "", "print", "(", "f'{opts.output_dir}/results_test'", ")", "\n", "\n", "", "write_to_tmp", "(", "f'\\n'", ",", "args", ".", "tmp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.inf_re.evaluate": [[117, 159], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "enumerate", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "model", "torch.argmax().cpu().detach().numpy", "horovod.torch.argmax().cpu().detach().numpy", "zip", "utils.distributed.all_gather_list", "time.time", "utils.distributed.all_gather_list", "predictions.append", "len", "horovod.torch.size", "utils.logger.LOGGER.info", "torch.argmax().cpu().detach", "horovod.torch.argmax().cpu().detach", "eval_loader.loader.dataset.computeIoU", "horovod.torch.rank", "int", "int", "pred_box.tolist", "tgt_box.tolist", "torch.argmax().cpu", "horovod.torch.argmax().cpu", "len", "torch.argmax", "horovod.torch.argmax"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReEvalDataset.computeIoU"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "LOGGER", ".", "info", "(", "\"start running evaluation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "tot_score", "=", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "predictions", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "        ", "(", "tgt_box_list", ",", "obj_boxes_list", ",", "sent_ids", ")", "=", "(", "\n", "batch", "[", "'tgt_box'", "]", ",", "batch", "[", "'obj_boxes'", "]", ",", "batch", "[", "'sent_ids'", "]", ")", "\n", "# scores (n, max_num_bb)", "\n", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "ixs", "=", "torch", ".", "argmax", "(", "scores", ",", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# (n, )", "\n", "\n", "# pred_boxes", "\n", "for", "ix", ",", "obj_boxes", ",", "tgt_box", ",", "sent_id", "in", "zip", "(", "ixs", ",", "obj_boxes_list", ",", "tgt_box_list", ",", "sent_ids", ")", ":", "\n", "            ", "pred_box", "=", "obj_boxes", "[", "ix", "]", "\n", "predictions", ".", "append", "(", "{", "'sent_id'", ":", "int", "(", "sent_id", ")", ",", "\n", "'pred_box'", ":", "pred_box", ".", "tolist", "(", ")", ",", "\n", "'tgt_box'", ":", "tgt_box", ".", "tolist", "(", ")", "}", ")", "\n", "if", "eval_loader", ".", "loader", ".", "dataset", ".", "computeIoU", "(", "pred_box", ",", "tgt_box", ")", ">", ".5", ":", "\n", "                ", "tot_score", "+=", "1", "\n", "", "n_ex", "+=", "1", "\n", "", "if", "i", "%", "100", "==", "0", "and", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "            ", "n_results", "=", "len", "(", "predictions", ")", "\n", "n_results", "*=", "hvd", ".", "size", "(", ")", "# an approximation to avoid hangs", "\n", "LOGGER", ".", "info", "(", "f'{n_results}/{len(eval_loader.dataset)} '", "\n", "'answers predicted'", ")", "\n", "", "", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/acc'", ":", "val_acc", ",", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation ({n_ex} sents) finished in\"", "\n", "f\" {int(tot_time)} seconds\"", "\n", "f\", accuracy: {val_acc*100:.2f}%\"", ")", "\n", "# summarizae", "\n", "results", "=", "{", "'acc'", ":", "val_acc", ",", "'predictions'", ":", "predictions", "}", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader": [[40, 55], ["data.PrefetchLoader", "data.TokenBucketSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data.vcr_collate", "data.vcr_eval_collate", "data.vcr_eval_collate"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.vcr_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.vcr_eval_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.vcr_eval_collate"], ["def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "batch_size", "=", "(", "opts", ".", "train_batch_size", "if", "is_train", "\n", "else", "opts", ".", "val_batch_size", ")", "\n", "if", "is_train", ":", "\n", "        ", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "opts", ".", "pin_mem", ",", "collate_fn", "=", "collate_fn", ")", "\n", "", "dataloader", "=", "PrefetchLoader", "(", "dataloader", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_optimizer": [[57, 93], ["OptimCls", "model.named_parameters", "model.named_parameters", "ValueError", "any", "any", "any", "any"], "function", ["None"], ["", "def", "build_optimizer", "(", "model", ",", "opts", ")", ":", "\n", "    ", "\"\"\" vqa linear may get larger learning rate \"\"\"", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'vcr_output'", "not", "in", "n", "]", "\n", "param_top", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "'vcr_output'", "in", "n", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_top", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'lr'", ":", "opts", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "# currently Adam only", "\n", "if", "opts", ".", "optim", "==", "'adam'", ":", "\n", "        ", "OptimCls", "=", "Adam", "\n", "", "elif", "opts", ".", "optim", "==", "'adamax'", ":", "\n", "        ", "OptimCls", "=", "Adamax", "\n", "", "elif", "opts", ".", "optim", "==", "'adamw'", ":", "\n", "        ", "OptimCls", "=", "AdamW", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid optimizer'", ")", "\n", "", "optimizer", "=", "OptimCls", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "opts", ".", "learning_rate", ",", "betas", "=", "opts", ".", "betas", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat": [[95, 114], ["db_list.split", "len", "data.DetectFeatLmdb"], "function", ["None"], ["", "def", "load_img_feat", "(", "db_list", ",", "all_img_dbs", ",", "opts", ")", ":", "\n", "    ", "db_", "=", "db_list", ".", "split", "(", "\";\"", ")", "\n", "assert", "len", "(", "db_", ")", "<=", "2", ",", "\"More than two img_dbs found\"", "\n", "gt_db_path", ",", "db_path", "=", "\"\"", ",", "\"\"", "\n", "for", "d", "in", "db_", ":", "\n", "        ", "if", "\"gt\"", "in", "d", ":", "\n", "            ", "gt_db_path", "=", "d", "\n", "", "else", ":", "\n", "            ", "db_path", "=", "d", "\n", "", "", "if", "gt_db_path", "!=", "\"\"", ":", "\n", "        ", "img_db_gt", "=", "DetectFeatLmdb", "(", "\n", "gt_db_path", ",", "-", "1", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "100", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "all_img_dbs", ".", "path2imgdb", "[", "gt_db_path", "]", "=", "img_db_gt", "\n", "", "else", ":", "\n", "        ", "img_db_gt", "=", "None", "\n", "", "img_db", "=", "all_img_dbs", "[", "db_path", "]", "if", "db_path", "!=", "\"\"", "else", "None", "\n", "all_img_dbs", ".", "path2imgdb", "[", "db_path", "]", "=", "img_db", "\n", "return", "img_db", ",", "img_db_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.main": [[116, 315], ["horovod.torch.init", "horovod.torch.size", "torch.device", "horovod.torch.device", "torch.cuda.set_device", "horovod.torch.cuda.set_device", "horovod.torch.rank", "utils.logger.LOGGER.info", "utils.misc.set_random_seed", "data.ImageLmdbGroup", "utils.logger.LOGGER.info", "zip", "data.ConcatDatasetWithLens", "train_vcr.build_dataloader", "utils.logger.LOGGER.info", "train_vcr.load_img_feat", "data.VcrTxtTokLmdb", "data.VcrEvalDataset", "data.VcrEvalDataset", "train_vcr.build_dataloader", "train_vcr.build_dataloader", "all", "model.vcr.UniterForVisualCommonsenseReasoning.from_pretrained", "UniterForVisualCommonsenseReasoning.from_pretrained.init_type_embedding", "UniterForVisualCommonsenseReasoning.from_pretrained.init_word_embedding", "UniterForVisualCommonsenseReasoning.from_pretrained.to", "utils.distributed.broadcast_tensors", "utils.misc.set_dropout", "train_vcr.build_optimizer", "apex.amp.initialize", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.RunningMeter", "UniterForVisualCommonsenseReasoning.from_pretrained.train", "time.time", "build_optimizer.zero_grad", "build_optimizer.step", "train_vcr.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "horovod.torch.local_rank", "horovod.torch.local_rank", "ValueError", "train_vcr.load_img_feat", "data.VcrTxtTokLmdb", "data.VcrTxtTokLmdb", "train_datasets.append", "train_datasets.append", "torch.load", "horovod.torch.load", "json.load", "torch.load", "horovod.torch.load", "torch.load.get", "set", "set", "UniterForVisualCommonsenseReasoning.from_pretrained.named_parameters", "checkpoint.get.items", "print", "print", "UniterForVisualCommonsenseReasoning.from_pretrained.load_state_dict", "utils.save.save_training_meta", "utils.logger.TB_LOGGER.create", "tqdm.tqdm", "utils.save.ModelSaver", "os.makedirs", "utils.logger.add_log_to_file", "utils.misc.NoOp", "utils.misc.NoOp", "enumerate", "utils.logger.LOGGER.info", "train_vcr.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "open", "json.dump", "horovod.torch.rank", "data.VcrDataset", "data.VcrDataset", "open", "set.add", "list", "list", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "horovod.torch.size", "batch[].size", "UniterForVisualCommonsenseReasoning.from_pretrained.", "loss.mean.mean", "utils.logger.RunningMeter.", "set.remove", "set.add", "UniterForVisualCommonsenseReasoning.from_pretrained.parameters", "apex.amp.scale_loss", "scaled_loss.backward", "loss.mean.item", "optim.get_lr_sched", "enumerate", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.TB_LOGGER.step", "build_optimizer.step", "build_optimizer.zero_grad", "utils.misc.NoOp.update", "json.load", "utils.distributed.all_reduce_and_rescale_tensors", "torch.nn.utils.clip_grad_norm_", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "sum", "int", "utils.logger.LOGGER.info", "utils.logger.TB_LOGGER.add_scalar", "utils.logger.LOGGER.info", "train_vcr.validate", "utils.logger.TB_LOGGER.log_scaler_dict", "utils.misc.NoOp.save", "open", "float", "apex.amp.master_params", "utils.distributed.all_gather_list", "UniterForVisualCommonsenseReasoning.from_pretrained.parameters", "ValueError", "time.time"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.build_dataloader", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_word_embedding", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.load_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "# load DBs and image dirs", "\n", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "# train", "\n", "LOGGER", ".", "info", "(", "f\"Loading Train Dataset \"", "\n", "f\"{opts.train_txt_dbs}, {opts.train_img_dbs}\"", ")", "\n", "train_datasets", "=", "[", "]", "\n", "for", "txt_path", ",", "img_path", "in", "zip", "(", "opts", ".", "train_txt_dbs", ",", "opts", ".", "train_img_dbs", ")", ":", "\n", "        ", "img_db", ",", "img_db_gt", "=", "load_img_feat", "(", "img_path", ",", "all_img_dbs", ",", "opts", ")", "\n", "qa_txt_db", "=", "VcrTxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", ",", "task", "=", "\"qa\"", ")", "\n", "qar_txt_db", "=", "VcrTxtTokLmdb", "(", "txt_path", ",", "opts", ".", "max_txt_len", ",", "task", "=", "\"qar\"", ")", "\n", "train_datasets", ".", "append", "(", "\n", "VcrDataset", "(", "qa_txt_db", ",", "img_db_gt", "=", "img_db_gt", ",", "img_db", "=", "img_db", ")", ")", "\n", "train_datasets", ".", "append", "(", "\n", "VcrDataset", "(", "qar_txt_db", ",", "img_db_gt", "=", "img_db_gt", ",", "img_db", "=", "img_db", ")", ")", "\n", "", "train_dataset", "=", "ConcatDatasetWithLens", "(", "train_datasets", ")", "\n", "train_dataloader", "=", "build_dataloader", "(", "train_dataset", ",", "vcr_collate", ",", "True", ",", "opts", ")", "\n", "# val", "\n", "LOGGER", ".", "info", "(", "f\"Loading Val Dataset {opts.val_txt_db}, {opts.val_img_db}\"", ")", "\n", "val_img_db", ",", "val_img_db_gt", "=", "load_img_feat", "(", "\n", "opts", ".", "val_img_db", ",", "all_img_dbs", ",", "opts", ")", "\n", "val_txt_db", "=", "VcrTxtTokLmdb", "(", "opts", ".", "val_txt_db", ",", "-", "1", ")", "\n", "val_dataset", "=", "VcrEvalDataset", "(", "\n", "\"val\"", ",", "val_txt_db", ",", "img_db", "=", "val_img_db", ",", "img_db_gt", "=", "val_img_db_gt", ")", "\n", "val_final_dataset", "=", "VcrEvalDataset", "(", "\n", "\"test\"", ",", "val_txt_db", ",", "img_db", "=", "val_img_db", ",", "img_db_gt", "=", "val_img_db_gt", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "val_dataset", ",", "vcr_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "val_final_dataloader", "=", "build_dataloader", "(", "\n", "val_final_dataset", ",", "vcr_eval_collate", ",", "\n", "False", ",", "opts", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", "and", "opts", ".", "checkpoint_from", "==", "\"pretrain\"", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "\n", "", "all_dbs", "=", "opts", ".", "train_txt_dbs", "+", "[", "opts", ".", "val_txt_db", "]", "\n", "toker", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "assert", "all", "(", "toker", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "model", "=", "UniterForVisualCommonsenseReasoning", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "img_dim", "=", "IMG_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "init_word_embedding", "(", "NUM_SPECIAL_TOKENS", ")", "\n", "if", "opts", ".", "checkpoint_from", "==", "\"vcr_pretrain\"", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "state_dict", "=", "checkpoint", ".", "get", "(", "'model_state'", ",", "checkpoint", ")", "\n", "matched_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "set", "(", ")", "\n", "missing_keys", "=", "set", "(", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "missing_keys", ".", "add", "(", "name", ")", "\n", "", "for", "key", ",", "data", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "missing_keys", ":", "\n", "                ", "matched_state_dict", "[", "key", "]", "=", "data", "\n", "missing_keys", ".", "remove", "(", "key", ")", "\n", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "add", "(", "key", ")", "\n", "", "", "print", "(", "\"Unexpected_keys:\"", ",", "list", "(", "unexpected_keys", ")", ")", "\n", "print", "(", "\"Missing_keys:\"", ",", "list", "(", "missing_keys", ")", ")", "\n", "model", ".", "load_state_dict", "(", "matched_state_dict", ",", "strict", "=", "False", ")", "\n", "", "del", "checkpoint", "\n", "model", ".", "to", "(", "device", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "global_step", "=", "0", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "opts", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "opts", ".", "output_dir", ",", "'results'", ")", ")", "# store VQA predictions", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", "*", "hvd", ".", "size", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "running_loss", "=", "RunningMeter", "(", "'loss'", ")", "\n", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0", "\n", "n_epoch", "=", "0", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "while", "True", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "n_examples", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "loss", "=", "model", "(", "batch", ",", "compute_loss", "=", "True", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ",", "delay_unscale", "=", "delay_unscale", "\n", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "if", "not", "delay_unscale", ":", "\n", "# gather gradients from every processes", "\n", "# do this before unscaling to make sure every process uses", "\n", "# the same gradient scale", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "", "running_loss", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "\n", "# learning rate scheduling", "\n", "lr_this_step", "=", "get_lr_sched", "(", "global_step", ",", "opts", ")", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                    ", "if", "i", "==", "0", "or", "i", "==", "1", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "*", "opts", ".", "lr_mul", "\n", "", "elif", "i", "==", "2", "or", "i", "==", "3", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", ")", "\n", "", "", "TB_LOGGER", ".", "add_scalar", "(", "'lr'", ",", "lr_this_step", ",", "global_step", ")", "\n", "\n", "# log loss", "\n", "# NOTE: not gathered across GPUs for efficiency", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'loss'", ",", "running_loss", ".", "val", ",", "global_step", ")", "\n", "TB_LOGGER", ".", "step", "(", ")", "\n", "\n", "# update model params", "\n", "if", "opts", ".", "grad_norm", "!=", "-", "1", ":", "\n", "                    ", "grad_norm", "=", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "opts", ".", "grad_norm", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'grad_norm'", ",", "grad_norm", ",", "global_step", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "# monitor training throughput", "\n", "                    ", "LOGGER", ".", "info", "(", "f'============Step {global_step}============='", ")", "\n", "tot_ex", "=", "sum", "(", "all_gather_list", "(", "n_examples", ")", ")", "\n", "ex_per_sec", "=", "int", "(", "tot_ex", "/", "(", "time", "(", ")", "-", "start", ")", ")", "\n", "LOGGER", ".", "info", "(", "f'{tot_ex} examples trained at '", "\n", "f'{ex_per_sec} ex/s'", ")", "\n", "TB_LOGGER", ".", "add_scalar", "(", "'perf/ex_per_s'", ",", "\n", "ex_per_sec", ",", "global_step", ")", "\n", "LOGGER", ".", "info", "(", "'==========================================='", ")", "\n", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "==", "0", ":", "\n", "                    ", "val_log", ",", "results", "=", "validate", "(", "\n", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "global_step", ">=", "opts", ".", "num_train_steps", ":", "\n", "            ", "break", "\n", "", "n_epoch", "+=", "1", "\n", "LOGGER", ".", "info", "(", "f\"finished {n_epoch} epochs\"", ")", "\n", "", "if", "global_step", "%", "opts", ".", "valid_steps", "!=", "0", ":", "\n", "        ", "val_log", ",", "results", "=", "validate", "(", "\n", "model", ",", "val_dataloader", ")", "\n", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "", "val_log", ",", "results", "=", "validate", "(", "model", ",", "val_final_dataloader", ")", "\n", "with", "open", "(", "f'{opts.output_dir}/results/'", "\n", "f'results_{global_step}_final_qa_qar_'", "\n", "f'rank{rank}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "TB_LOGGER", ".", "log_scaler_dict", "(", "val_log", ")", "\n", "model_saver", ".", "save", "(", "model", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.compute_accuracies": [[317, 327], ["matched_qa.sum().item", "matched_qar.sum().item", "matched_joined.sum().item", "out_qa.max", "out_qar.max", "outputs_qa.squeeze", "labels_qa.squeeze", "outputs_qar.squeeze", "labels_qar.squeeze", "matched_qa.sum", "matched_qar.sum", "matched_joined.sum"], "function", ["None"], ["", "def", "compute_accuracies", "(", "out_qa", ",", "labels_qa", ",", "out_qar", ",", "labels_qar", ")", ":", "\n", "    ", "outputs_qa", "=", "out_qa", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "outputs_qar", "=", "out_qar", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "matched_qa", "=", "outputs_qa", ".", "squeeze", "(", ")", "==", "labels_qa", ".", "squeeze", "(", ")", "\n", "matched_qar", "=", "outputs_qar", ".", "squeeze", "(", ")", "==", "labels_qar", ".", "squeeze", "(", ")", "\n", "matched_joined", "=", "matched_qa", "&", "matched_qar", "\n", "n_correct_qa", "=", "matched_qa", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_correct_qar", "=", "matched_qar", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_correct_joined", "=", "matched_joined", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct_qa", ",", "n_correct_qar", ",", "n_correct_joined", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.validate": [[329, 397], ["torch.no_grad", "horovod.torch.no_grad", "utils.logger.LOGGER.info", "model.eval", "time.time", "enumerate", "sum", "sum", "sum", "sum", "sum", "sum", "model.train", "utils.logger.LOGGER.info", "horovod.torch.rank", "tqdm.tqdm", "utils.misc.NoOp", "model", "scores.view.view", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "F.cross_entropy.item", "F.cross_entropy.item", "train_vcr.compute_accuracies", "zip", "len", "utils.misc.NoOp.update", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "utils.distributed.all_gather_list", "time.time", "len", "qa_targets.squeeze", "range", "torch.stack", "horovod.torch.stack", "qar_targets.squeeze", "score.cpu().tolist", "len", "qa_targets[].item", "torch.stack.append", "int", "score.cpu", "range"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.None.train_vcr.compute_accuracies", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "model", ",", "val_loader", ")", ":", "\n", "    ", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "val_pbar", "=", "tqdm", "(", "total", "=", "len", "(", "val_loader", ")", ")", "\n", "", "else", ":", "\n", "        ", "val_pbar", "=", "NoOp", "(", ")", "\n", "", "LOGGER", ".", "info", "(", "\"start running validation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "val_qa_loss", ",", "val_qar_loss", "=", "0", ",", "0", "\n", "tot_qa_score", ",", "tot_qar_score", ",", "tot_score", "=", "0", ",", "0", ",", "0", "\n", "n_ex", "=", "0", "\n", "st", "=", "time", "(", ")", "\n", "results", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "qa_targets", "=", "batch", "[", "'qa_targets'", "]", "\n", "qar_targets", "=", "batch", "[", "'qar_targets'", "]", "\n", "qids", "=", "batch", "[", "'qids'", "]", "\n", "scores", "=", "scores", ".", "view", "(", "len", "(", "qids", ")", ",", "-", "1", ")", "\n", "vcr_qa_loss", "=", "F", ".", "cross_entropy", "(", "\n", "scores", "[", ":", ",", ":", "4", "]", ",", "qa_targets", ".", "squeeze", "(", "-", "1", ")", ",", "reduction", "=", "\"sum\"", ")", "\n", "if", "scores", ".", "shape", "[", "1", "]", ">", "8", ":", "\n", "            ", "qar_scores", "=", "[", "]", "\n", "for", "batch_id", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "answer_ind", "=", "qa_targets", "[", "batch_id", "]", ".", "item", "(", ")", "\n", "qar_index", "=", "[", "4", "+", "answer_ind", "*", "4", "+", "i", "\n", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "qar_scores", ".", "append", "(", "scores", "[", "batch_id", ",", "qar_index", "]", ")", "\n", "", "qar_scores", "=", "torch", ".", "stack", "(", "qar_scores", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "qar_scores", "=", "scores", "[", ":", ",", "4", ":", "]", "\n", "", "vcr_qar_loss", "=", "F", ".", "cross_entropy", "(", "\n", "qar_scores", ",", "qar_targets", ".", "squeeze", "(", "-", "1", ")", ",", "reduction", "=", "\"sum\"", ")", "\n", "val_qa_loss", "+=", "vcr_qa_loss", ".", "item", "(", ")", "\n", "val_qar_loss", "+=", "vcr_qar_loss", ".", "item", "(", ")", "\n", "curr_qa_score", ",", "curr_qar_score", ",", "curr_score", "=", "compute_accuracies", "(", "\n", "scores", "[", ":", ",", ":", "4", "]", ",", "qa_targets", ",", "qar_scores", ",", "qar_targets", ")", "\n", "tot_qar_score", "+=", "curr_qar_score", "\n", "tot_qa_score", "+=", "curr_qa_score", "\n", "tot_score", "+=", "curr_score", "\n", "for", "qid", ",", "score", "in", "zip", "(", "qids", ",", "scores", ")", ":", "\n", "            ", "results", "[", "qid", "]", "=", "score", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "", "n_ex", "+=", "len", "(", "qids", ")", "\n", "val_pbar", ".", "update", "(", "1", ")", "\n", "", "val_qa_loss", "=", "sum", "(", "all_gather_list", "(", "val_qa_loss", ")", ")", "\n", "val_qar_loss", "=", "sum", "(", "all_gather_list", "(", "val_qar_loss", ")", ")", "\n", "tot_qa_score", "=", "sum", "(", "all_gather_list", "(", "tot_qa_score", ")", ")", "\n", "tot_qar_score", "=", "sum", "(", "all_gather_list", "(", "tot_qar_score", ")", ")", "\n", "tot_score", "=", "sum", "(", "all_gather_list", "(", "tot_score", ")", ")", "\n", "n_ex", "=", "sum", "(", "all_gather_list", "(", "n_ex", ")", ")", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "val_qa_loss", "/=", "n_ex", "\n", "val_qar_loss", "/=", "n_ex", "\n", "val_qa_acc", "=", "tot_qa_score", "/", "n_ex", "\n", "val_qar_acc", "=", "tot_qar_score", "/", "n_ex", "\n", "val_acc", "=", "tot_score", "/", "n_ex", "\n", "val_log", "=", "{", "'valid/vcr_qa_loss'", ":", "val_qa_loss", ",", "\n", "'valid/vcr_qar_loss'", ":", "val_qar_loss", ",", "\n", "'valid/acc_qa'", ":", "val_qa_acc", ",", "\n", "'valid/acc_qar'", ":", "val_qar_acc", ",", "\n", "'valid/acc'", ":", "val_acc", ",", "\n", "'valid/ex_per_s'", ":", "n_ex", "/", "tot_time", "}", "\n", "model", ".", "train", "(", ")", "\n", "LOGGER", ".", "info", "(", "f\"validation finished in {int(tot_time)} seconds, \"", "\n", "f\"score_qa: {val_qa_acc*100:.2f} \"", "\n", "f\"score_qar: {val_qar_acc*100:.2f} \"", "\n", "f\"score: {val_acc*100:.2f} \"", ")", "\n", "return", "val_log", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors": [[16, 44], ["sum", "tensors[].new().zero_", "horovod.torch.allreduce_", "tensors[].new().zero_.div_", "t.numel", "buffer_t[].copy_", "t.numel", "t.view().copy_", "t.numel", "tensors[].new", "t.view", "t.view"], "function", ["None"], ["def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors at once (as a flattened tensor)\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "sz", "=", "sum", "(", "t", ".", "numel", "(", ")", "for", "t", "in", "tensors", ")", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "sz", ")", ".", "zero_", "(", ")", "\n", "\n", "# copy tensors into buffer_t", "\n", "offset", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "hvd", ".", "allreduce_", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_reduce_and_rescale_tensors_chunked": [[46, 98], ["tensors[].new().zero_", "horovod.torch.allreduce_", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors_chunked.all_reduce_buffer"], "function", ["None"], ["", "", "def", "all_reduce_and_rescale_tensors_chunked", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "hvd", ".", "allreduce_", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "hvd", ".", "allreduce_", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.broadcast_tensors": [[100, 149], ["tensors[].new().zero_", "horovod.torch.broadcast_", "len", "distributed.broadcast_tensors.broadcast_buffer"], "function", ["None"], ["", "", "def", "broadcast_tensors", "(", "tensors", ",", "root_rank", ",", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"broadcast tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to broadcast\n        root_rank: rank to broadcast\n        buffer_size: broadcast chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "broadcast_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# broadcast", "\n", "", "hvd", ".", "broadcast_", "(", "buffer_t", "[", ":", "offset", "]", ",", "root_rank", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, broadcast directly", "\n", "            ", "hvd", ".", "broadcast_", "(", "t", ",", "root_rank", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, broadcast and replace buffer with tensor", "\n", "            ", "broadcast_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "broadcast_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._encode": [[151, 166], ["len", "max", "range", "torch.ByteTensor", "horovod.torch.ByteTensor", "math.floor", "torch.cuda.ByteTensor", "horovod.torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "horovod.torch.cuda.ByteTensor", "list", "math.log"], "function", ["None"], ["", "", "def", "_encode", "(", "enc", ",", "max_size", ",", "use_max_size", "=", "False", ")", ":", "\n", "    ", "enc_size", "=", "len", "(", "enc", ")", "\n", "enc_byte", "=", "max", "(", "math", ".", "floor", "(", "math", ".", "log", "(", "max_size", ",", "256", ")", "+", "1", ")", ",", "1", ")", "\n", "if", "use_max_size", ":", "\n", "# this is used for broadcasting", "\n", "        ", "buffer_", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", "+", "enc_byte", ")", "\n", "", "else", ":", "\n", "        ", "buffer_", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "enc_size", "+", "enc_byte", ")", "\n", "", "remainder", "=", "enc_size", "\n", "for", "i", "in", "range", "(", "enc_byte", ")", ":", "\n", "        ", "base", "=", "256", "**", "(", "enc_byte", "-", "i", "-", "1", ")", "\n", "buffer_", "[", "i", "]", "=", "remainder", "//", "base", "\n", "remainder", "%=", "base", "\n", "", "buffer_", "[", "enc_byte", ":", "enc_byte", "+", "enc_size", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "return", "buffer_", ",", "enc_byte", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._decode": [[168, 174], ["sum", "bytes", "buffer_[].tolist", "buffer_[].item", "range"], "function", ["None"], ["", "def", "_decode", "(", "buffer_", ",", "enc_byte", ")", ":", "\n", "    ", "size", "=", "sum", "(", "256", "**", "(", "enc_byte", "-", "i", "-", "1", ")", "*", "buffer_", "[", "i", "]", ".", "item", "(", ")", "\n", "for", "i", "in", "range", "(", "enc_byte", ")", ")", "\n", "bytes_list", "=", "bytes", "(", "buffer_", "[", "enc_byte", ":", "enc_byte", "+", "size", "]", ".", "tolist", "(", ")", ")", "\n", "shift", "=", "size", "+", "enc_byte", "\n", "return", "bytes_list", ",", "shift", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list": [[179, 196], ["pickle.dumps", "len", "horovod.torch.allgather().max().item", "distributed._encode", "horovod.torch.allgather", "range", "horovod.torch.size", "distributed._decode", "pickle.loads", "results.append", "horovod.torch.allgather().max", "horovod.torch.allgather", "torch.tensor().cuda", "horovod.torch.tensor().cuda", "torch.tensor", "horovod.torch.tensor"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._encode", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._decode"], ["def", "all_gather_list", "(", "data", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "max_size", "=", "hvd", ".", "allgather", "(", "torch", ".", "tensor", "(", "[", "enc_size", "]", ")", ".", "cuda", "(", ")", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "in_buffer", ",", "enc_byte", "=", "_encode", "(", "enc", ",", "max_size", ")", "\n", "\n", "out_buffer", "=", "hvd", ".", "allgather", "(", "in_buffer", "[", ":", "enc_byte", "+", "enc_size", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "hvd", ".", "size", "(", ")", ")", ":", "\n", "        ", "bytes_list", ",", "shift", "=", "_decode", "(", "out_buffer", ",", "enc_byte", ")", "\n", "out_buffer", "=", "out_buffer", "[", "shift", ":", "]", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.any_broadcast": [[198, 210], ["pickle.dumps", "horovod.torch.allgather().max().item", "distributed._encode", "horovod.torch.broadcast_", "distributed._decode", "pickle.loads", "horovod.torch.allgather().max", "horovod.torch.allgather", "torch.tensor().cuda", "horovod.torch.tensor().cuda", "torch.tensor", "horovod.torch.tensor", "len"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._encode", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed._decode"], ["", "def", "any_broadcast", "(", "data", ",", "root_rank", ")", ":", "\n", "    ", "\"\"\"broadcast arbitrary data from root_rank to all nodes.\"\"\"", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "\n", "max_size", "=", "hvd", ".", "allgather", "(", "torch", ".", "tensor", "(", "[", "len", "(", "enc", ")", "]", ")", ".", "cuda", "(", ")", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "buffer_", ",", "enc_byte", "=", "_encode", "(", "enc", ",", "max_size", ",", "use_max_size", "=", "True", ")", "\n", "\n", "hvd", ".", "broadcast_", "(", "buffer_", ",", "root_rank", ")", "\n", "\n", "bytes_list", ",", "_", "=", "_decode", "(", "buffer_", ",", "enc_byte", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.itm_eval": [[18, 67], ["torch.no_grad", "horovod.torch.no_grad", "score_matrix.topk", "torch.LongTensor().to().unsqueeze().expand_as", "horovod.torch.LongTensor().to().unsqueeze().expand_as", "min.numel", "score_matrix.topk", "enumerate", "len", "len", "len", "min", "enumerate", "torch.LongTensor().to().unsqueeze", "horovod.torch.LongTensor().to().unsqueeze", "len", "len", "len", "enumerate", "torch.LongTensor().to", "horovod.torch.LongTensor().to", "r.item", "r.numel", "torch.LongTensor", "horovod.torch.LongTensor"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "itm_eval", "(", "score_matrix", ",", "txt_ids", ",", "img_ids", ",", "txt2img", ",", "img2txts", ")", ":", "\n", "# image retrieval", "\n", "    ", "img2j", "=", "{", "i", ":", "j", "for", "j", ",", "i", "in", "enumerate", "(", "img_ids", ")", "}", "\n", "_", ",", "rank_txt", "=", "score_matrix", ".", "topk", "(", "10", ",", "dim", "=", "1", ")", "\n", "gt_img_j", "=", "torch", ".", "LongTensor", "(", "[", "img2j", "[", "txt2img", "[", "txt_id", "]", "]", "\n", "for", "txt_id", "in", "txt_ids", "]", ",", "\n", ")", ".", "to", "(", "rank_txt", ".", "device", "\n", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "rank_txt", ")", "\n", "rank", "=", "(", "rank_txt", "==", "gt_img_j", ")", ".", "nonzero", "(", ")", "\n", "if", "rank", ".", "numel", "(", ")", ":", "\n", "        ", "ir_r1", "=", "(", "rank", "<", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "txt_ids", ")", "\n", "ir_r5", "=", "(", "rank", "<", "5", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "txt_ids", ")", "\n", "ir_r10", "=", "(", "rank", "<", "10", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "txt_ids", ")", "\n", "", "else", ":", "\n", "        ", "ir_r1", ",", "ir_r5", ",", "ir_r10", "=", "0", ",", "0", ",", "0", "\n", "\n", "# text retrieval", "\n", "", "txt2i", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "txt_ids", ")", "}", "\n", "_", ",", "rank_img", "=", "score_matrix", ".", "topk", "(", "10", ",", "dim", "=", "0", ")", "\n", "tr_r1", ",", "tr_r5", ",", "tr_r10", "=", "0", ",", "0", ",", "0", "\n", "for", "j", ",", "img_id", "in", "enumerate", "(", "img_ids", ")", ":", "\n", "        ", "gt_is", "=", "[", "txt2i", "[", "t", "]", "for", "t", "in", "img2txts", "[", "img_id", "]", "]", "\n", "ranks", "=", "[", "(", "rank_img", "[", ":", ",", "j", "]", "==", "i", ")", ".", "nonzero", "(", ")", "for", "i", "in", "gt_is", "]", "\n", "rank", "=", "min", "(", "[", "10", "]", "+", "[", "r", ".", "item", "(", ")", "for", "r", "in", "ranks", "if", "r", ".", "numel", "(", ")", "]", ")", "\n", "if", "rank", "<", "1", ":", "\n", "            ", "tr_r1", "+=", "1", "\n", "", "if", "rank", "<", "5", ":", "\n", "            ", "tr_r5", "+=", "1", "\n", "", "if", "rank", "<", "10", ":", "\n", "            ", "tr_r10", "+=", "1", "\n", "", "", "tr_r1", "/=", "len", "(", "img_ids", ")", "\n", "tr_r5", "/=", "len", "(", "img_ids", ")", "\n", "tr_r10", "/=", "len", "(", "img_ids", ")", "\n", "\n", "tr_mean", "=", "(", "tr_r1", "+", "tr_r5", "+", "tr_r10", ")", "/", "3", "\n", "ir_mean", "=", "(", "ir_r1", "+", "ir_r5", "+", "ir_r10", ")", "/", "3", "\n", "r_mean", "=", "(", "tr_mean", "+", "ir_mean", ")", "/", "2", "\n", "\n", "eval_log", "=", "{", "'txt_r1'", ":", "tr_r1", ",", "\n", "'txt_r5'", ":", "tr_r5", ",", "\n", "'txt_r10'", ":", "tr_r10", ",", "\n", "'txt_r_mean'", ":", "tr_mean", ",", "\n", "'img_r1'", ":", "ir_r1", ",", "\n", "'img_r5'", ":", "ir_r5", ",", "\n", "'img_r10'", ":", "ir_r10", ",", "\n", "'img_r_mean'", ":", "ir_mean", ",", "\n", "'r_mean'", ":", "r_mean", "}", "\n", "return", "eval_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.evaluate": [[69, 90], ["torch.no_grad", "horovod.torch.no_grad", "time.time", "logger.LOGGER.info", "itm_eval.inference", "horovod.torch.allgather", "itm_eval.itm_eval", "logger.LOGGER.info", "hvd.allgather.size", "horovod.torch.rank", "time.time", "distributed.all_gather_list", "len", "len", "int"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.inference", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.itm_eval", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.all_gather_list"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "st", "=", "time", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"start running Image/Text Retrieval evaluation ...\"", ")", "\n", "score_matrix", "=", "inference", "(", "model", ",", "eval_loader", ")", "\n", "dset", "=", "eval_loader", ".", "dataset", "\n", "all_score", "=", "hvd", ".", "allgather", "(", "score_matrix", ")", "\n", "all_txt_ids", "=", "[", "i", "for", "ids", "in", "all_gather_list", "(", "dset", ".", "ids", ")", "\n", "for", "i", "in", "ids", "]", "\n", "all_img_ids", "=", "dset", ".", "all_img_ids", "\n", "assert", "all_score", ".", "size", "(", ")", "==", "(", "len", "(", "all_txt_ids", ")", ",", "len", "(", "all_img_ids", ")", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "!=", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "# NOTE: only use rank0 to compute final scores", "\n", "", "eval_log", "=", "itm_eval", "(", "all_score", ",", "all_txt_ids", ",", "all_img_ids", ",", "\n", "dset", ".", "txt2img", ",", "dset", ".", "img2txts", ")", "\n", "\n", "tot_time", "=", "time", "(", ")", "-", "st", "\n", "LOGGER", ".", "info", "(", "f\"evaluation finished in {int(tot_time)} seconds\"", ")", "\n", "return", "eval_log", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.itm_eval.inference": [[92, 115], ["torch.no_grad", "horovod.torch.no_grad", "model.eval", "torch.zeros", "horovod.torch.zeros", "enumerate", "model.train", "misc.NoOp.close", "horovod.torch.rank", "tqdm.tqdm", "misc.NoOp", "len", "len", "misc.NoOp.update", "torch.device", "horovod.torch.device", "model", "model.size", "model.data.squeeze().half", "torch.zeros.size", "len", "model.data.squeeze"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "inference", "(", "model", ",", "eval_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hvd", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "eval_loader", ")", ")", "\n", "", "else", ":", "\n", "        ", "pbar", "=", "NoOp", "(", ")", "\n", "", "score_matrix", "=", "torch", ".", "zeros", "(", "len", "(", "eval_loader", ".", "dataset", ")", ",", "\n", "len", "(", "eval_loader", ".", "dataset", ".", "all_img_ids", ")", ",", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", ",", "\n", "dtype", "=", "torch", ".", "float16", ")", "\n", "for", "i", ",", "mini_batches", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "        ", "j", "=", "0", "\n", "for", "batch", "in", "mini_batches", ":", "\n", "            ", "scores", "=", "model", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "bs", "=", "scores", ".", "size", "(", "0", ")", "\n", "score_matrix", ".", "data", "[", "i", ",", "j", ":", "j", "+", "bs", "]", "=", "scores", ".", "data", ".", "squeeze", "(", "1", ")", ".", "half", "(", ")", "\n", "j", "+=", "bs", "\n", "", "assert", "j", "==", "score_matrix", ".", "size", "(", "1", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "pbar", ".", "close", "(", ")", "\n", "return", "score_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.__init__": [[28, 31], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_logger", "=", "None", "\n", "self", ".", "_global_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.create": [[32, 34], ["tensorboardX.SummaryWriter"], "methods", ["None"], ["", "def", "create", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "_logger", "=", "tensorboardX", ".", "SummaryWriter", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.noop": [[35, 37], ["None"], "methods", ["None"], ["", "def", "noop", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.step": [[38, 40], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_global_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.global_step": [[41, 44], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_step", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict": [[45, 58], ["log_dict.items", "isinstance", "logger.TensorboardLogger.log_scaler_dict", "logger.TensorboardLogger._logger.add_scalar"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.log_scaler_dict"], ["", "def", "log_scaler_dict", "(", "self", ",", "log_dict", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "\"\"\" log a dictionary of scalar values\"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "prefix", ":", "\n", "            ", "prefix", "=", "f'{prefix}_'", "\n", "", "for", "name", ",", "value", "in", "log_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "                ", "self", ".", "log_scaler_dict", "(", "value", ",", "self", ".", "_global_step", ",", "\n", "prefix", "=", "f'{prefix}{name}'", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_logger", ".", "add_scalar", "(", "f'{prefix}{name}'", ",", "value", ",", "\n", "self", ".", "_global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.TensorboardLogger.__getattr__": [[59, 63], ["logger.TensorboardLogger._logger.__getattribute__"], "methods", ["None"], ["", "", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "return", "self", ".", "noop", "\n", "", "return", "self", ".", "_logger", ".", "__getattribute__", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.RunningMeter.__init__": [[72, 76], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "val", "=", "None", ",", "smooth", "=", "0.99", ")", ":", "\n", "        ", "self", ".", "_name", "=", "name", "\n", "self", ".", "_sm", "=", "smooth", "\n", "self", ".", "_val", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.RunningMeter.__call__": [[77, 82], ["math.isnan"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "value", ")", ":", "\n", "        ", "val", "=", "(", "value", "if", "self", ".", "_val", "is", "None", "\n", "else", "value", "*", "(", "1", "-", "self", ".", "_sm", ")", "+", "self", ".", "_val", "*", "self", ".", "_sm", ")", "\n", "if", "not", "math", ".", "isnan", "(", "val", ")", ":", "\n", "            ", "self", ".", "_val", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.RunningMeter.__str__": [[83, 85], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f'{self._name}: {self._val:.4f}'", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.RunningMeter.val": [[86, 91], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_val", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "return", "self", ".", "_val", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.RunningMeter.name": [[92, 95], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.logger.add_log_to_file": [[20, 25], ["logging.FileHandler", "logging.Formatter", "logging.FileHandler.setFormatter", "LOGGER.addHandler"], "function", ["None"], ["def", "add_log_to_file", "(", "log_path", ")", ":", "\n", "    ", "fh", "=", "logging", ".", "FileHandler", "(", "log_path", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "_LOG_FMT", ",", "datefmt", "=", "_DATE_FMT", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "LOGGER", ".", "addHandler", "(", "fh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.__init__": [[58, 62], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "output_dir", ",", "prefix", "=", "'model_step'", ",", "suffix", "=", "'pt'", ")", ":", "\n", "        ", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "suffix", "=", "suffix", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save": [[63, 74], ["os.path.join", "torch.save", "hasattr", "torch.save", "isinstance", "v.cpu", "model.state_dict().items", "optimizer.state_dict", "model.state_dict"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.ModelSaver.save"], ["", "def", "save", "(", "self", ",", "model", ",", "step", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "output_model_file", "=", "join", "(", "self", ".", "output_dir", ",", "\n", "f\"{self.prefix}_{step}.{self.suffix}\"", ")", "\n", "state_dict", "=", "{", "k", ":", "v", ".", "cpu", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "v", "\n", "for", "k", ",", "v", "in", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "}", "\n", "torch", ".", "save", "(", "state_dict", ",", "output_model_file", ")", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "dump", "=", "{", "'step'", ":", "step", ",", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "}", "\n", "if", "hasattr", "(", "optimizer", ",", "'_amp_stash'", ")", ":", "\n", "                ", "pass", "# TODO fp16 optimizer", "\n", "", "torch", ".", "save", "(", "dump", ",", "f'{self.output_dir}/train_state_{step}.pt'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.save.save_training_meta": [[17, 55], ["json.load", "os.path.exists", "os.makedirs", "os.makedirs", "open", "json.dump", "open", "open", "json.dump", "utils.logger.LOGGER.info", "subprocess.run", "subprocess.run.stdout.decode().strip", "utils.logger.LOGGER.info", "subprocess.run", "subprocess.run.stdout.decode().strip", "utils.logger.LOGGER.info", "os.path.abspath", "subprocess.check_output().strip", "os.path.join", "os.path.join", "os.path.join", "vars", "os.path.join", "os.path.dirname", "open", "json.dump", "utils.logger.LOGGER.exception", "utils.logger.LOGGER.warn", "subprocess.run.stdout.decode", "subprocess.run.stdout.decode", "subprocess.check_output", "os.path.join", "bool"], "function", ["None"], ["def", "save_training_meta", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "rank", ">", "0", ":", "\n", "        ", "return", "\n", "\n", "", "if", "not", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "join", "(", "args", ".", "output_dir", ",", "'log'", ")", ")", "\n", "os", ".", "makedirs", "(", "join", "(", "args", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "\n", "", "with", "open", "(", "join", "(", "args", ".", "output_dir", ",", "'log'", ",", "'hps.json'", ")", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "writer", ",", "indent", "=", "4", ")", "\n", "", "model_config", "=", "json", ".", "load", "(", "open", "(", "args", ".", "model_config", ")", ")", "\n", "with", "open", "(", "join", "(", "args", ".", "output_dir", ",", "'log'", ",", "'model.json'", ")", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "json", ".", "dump", "(", "model_config", ",", "writer", ",", "indent", "=", "4", ")", "\n", "# git info", "\n", "", "try", ":", "\n", "        ", "LOGGER", ".", "info", "(", "\"Waiting on git info....\"", ")", "\n", "c", "=", "subprocess", ".", "run", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--abbrev-ref\"", ",", "\"HEAD\"", "]", ",", "\n", "timeout", "=", "10", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "git_branch_name", "=", "c", ".", "stdout", ".", "decode", "(", ")", ".", "strip", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"Git branch: %s\"", ",", "git_branch_name", ")", "\n", "c", "=", "subprocess", ".", "run", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"HEAD\"", "]", ",", "\n", "timeout", "=", "10", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "git_sha", "=", "c", ".", "stdout", ".", "decode", "(", ")", ".", "strip", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"Git SHA: %s\"", ",", "git_sha", ")", "\n", "git_dir", "=", "abspath", "(", "dirname", "(", "__file__", ")", ")", "\n", "git_status", "=", "subprocess", ".", "check_output", "(", "\n", "[", "'git'", ",", "'status'", ",", "'--short'", "]", ",", "\n", "cwd", "=", "git_dir", ",", "universal_newlines", "=", "True", ")", ".", "strip", "(", ")", "\n", "with", "open", "(", "join", "(", "args", ".", "output_dir", ",", "'log'", ",", "'git_info.json'", ")", ",", "\n", "'w'", ")", "as", "writer", ":", "\n", "            ", "json", ".", "dump", "(", "{", "'branch'", ":", "git_branch_name", ",", "\n", "'is_dirty'", ":", "bool", "(", "git_status", ")", ",", "\n", "'status'", ":", "git_status", ",", "\n", "'sha'", ":", "git_sha", "}", ",", "\n", "writer", ",", "indent", "=", "4", ")", "\n", "", "", "except", "subprocess", ".", "TimeoutExpired", "as", "e", ":", "\n", "        ", "LOGGER", ".", "exception", "(", "e", ")", "\n", "LOGGER", ".", "warn", "(", "\"Git info not found. Moving right along...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.NoOp.__getattr__": [[19, 21], ["None"], "methods", ["None"], ["def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "noop", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.NoOp.noop": [[22, 24], ["None"], "methods", ["None"], ["", "def", "noop", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.Struct.__init__": [[53, 55], ["misc.Struct.__dict__.update"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dict_", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "dict_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.parse_with_config": [[26, 37], ["parser.parse_args", "json.load", "json.load.items", "open", "arg[].split", "arg.startswith", "setattr"], "function", ["None"], ["", "", "def", "parse_with_config", "(", "parser", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "config", "is", "not", "None", ":", "\n", "        ", "config_args", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config", ")", ")", "\n", "override_keys", "=", "{", "arg", "[", "2", ":", "]", ".", "split", "(", "'='", ")", "[", "0", "]", "for", "arg", "in", "sys", ".", "argv", "[", "1", ":", "]", "\n", "if", "arg", ".", "startswith", "(", "'--'", ")", "}", "\n", "for", "k", ",", "v", "in", "config_args", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "not", "in", "override_keys", ":", "\n", "                ", "setattr", "(", "args", ",", "k", ",", "v", ")", "\n", "", "", "", "del", "args", ".", "config", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_dropout": [[57, 64], ["model.named_modules", "isinstance", "utils.logger.LOGGER.info"], "function", ["None"], ["", "", "def", "set_dropout", "(", "model", ",", "drop_p", ")", ":", "\n", "    ", "for", "name", ",", "module", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "# we might want to tune dropout for smaller dataset", "\n", "        ", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Dropout", ")", ":", "\n", "            ", "if", "module", ".", "p", "!=", "drop_p", ":", "\n", "                ", "module", ".", "p", "=", "drop_p", "\n", "LOGGER", ".", "info", "(", "f'{name} set to {drop_p}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.misc.set_random_seed": [[66, 71], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "", "", "def", "set_random_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.__init__": [[22, 39], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "\n", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - \"", "\n", "\"should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - \"", "\n", "\"should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - \"", "\n", "\"should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.adamw.AdamW.step": [[40, 104], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "'Adam does not support sparse '", "\n", "'gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1.0", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1.0", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "'lr'", "]", "\n", "if", "group", "[", "'correct_bias'", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "(", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "\n", "/", "bias_correction1", ")", "\n", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is", "\n", "# *not* the correct way of using L2 regularization/weight decay", "\n", "# with Adam, since that will interact with the m and v", "\n", "# parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't", "\n", "# interact with the m/v parameters. This is equivalent to", "\n", "# adding the square of the weights to the loss with plain", "\n", "# (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", "*", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.misc.build_optimizer": [[12, 36], ["list", "OptimCls", "model.named_parameters", "ValueError", "any", "any"], "function", ["None"], ["import", "numpy", "as", "np", "\n", "\n", "from", "utils", ".", "logger", "import", "LOGGER", "\n", "\n", "\n", "class", "NoOp", "(", "object", ")", ":", "\n", "    ", "\"\"\" useful for distributed training No-Ops \"\"\"", "\n", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "noop", "\n", "\n", "", "def", "noop", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "\n", "\n", "\n", "", "", "def", "parse_with_config", "(", "parser", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "config", "is", "not", "None", ":", "\n", "        ", "config_args", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config", ")", ")", "\n", "override_keys", "=", "{", "arg", "[", "2", ":", "]", ".", "split", "(", "'='", ")", "[", "0", "]", "for", "arg", "in", "sys", ".", "argv", "[", "1", ":", "]", "\n", "if", "arg", ".", "startswith", "(", "'--'", ")", "}", "\n", "for", "k", ",", "v", "in", "config_args", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "not", "in", "override_keys", ":", "\n", "                ", "setattr", "(", "args", ",", "k", ",", "v", ")", "\n", "", "", "", "del", "args", ".", "config", "\n", "return", "args", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.noam_schedule": [[10, 15], ["None"], "function", ["None"], ["def", "noam_schedule", "(", "step", ",", "warmup_step", "=", "4000", ")", ":", "\n", "    ", "\"\"\" original Transformer schedule\"\"\"", "\n", "if", "step", "<=", "warmup_step", ":", "\n", "        ", "return", "step", "/", "warmup_step", "\n", "", "return", "(", "warmup_step", "**", "0.5", ")", "*", "(", "step", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.warmup_linear": [[17, 22], ["max"], "function", ["None"], ["", "def", "warmup_linear", "(", "step", ",", "warmup_step", ",", "tot_step", ")", ":", "\n", "    ", "\"\"\" BERT schedule \"\"\"", "\n", "if", "step", "<", "warmup_step", ":", "\n", "        ", "return", "step", "/", "warmup_step", "\n", "", "return", "max", "(", "0", ",", "(", "tot_step", "-", "step", ")", "/", "(", "tot_step", "-", "warmup_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.vqa_schedule": [[24, 38], ["math.ceil"], "function", ["None"], ["", "def", "vqa_schedule", "(", "step", ",", "warmup_interval", ",", "decay_interval", ",", "\n", "decay_start", ",", "decay_rate", ")", ":", "\n", "    ", "\"\"\" VQA schedule from MCAN \"\"\"", "\n", "if", "step", "<", "warmup_interval", ":", "\n", "        ", "return", "1", "/", "4", "\n", "", "elif", "step", "<", "2", "*", "warmup_interval", ":", "\n", "        ", "return", "2", "/", "4", "\n", "", "elif", "step", "<", "3", "*", "warmup_interval", ":", "\n", "        ", "return", "3", "/", "4", "\n", "", "elif", "step", ">=", "decay_start", ":", "\n", "        ", "num_decay", "=", "ceil", "(", "(", "step", "-", "decay_start", ")", "/", "decay_interval", ")", "\n", "return", "decay_rate", "**", "num_decay", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.get_lr_sched": [[40, 47], ["sched.warmup_linear"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.optim.sched.warmup_linear"], ["", "", "def", "get_lr_sched", "(", "global_step", ",", "opts", ")", ":", "\n", "# learning rate scheduling", "\n", "    ", "lr_this_step", "=", "opts", ".", "learning_rate", "*", "warmup_linear", "(", "\n", "global_step", ",", "opts", ".", "warmup_steps", ",", "opts", ".", "num_train_steps", ")", "\n", "if", "lr_this_step", "<=", "0", ":", "\n", "        ", "lr_this_step", "=", "1e-8", "\n", "", "return", "lr_this_step", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.init_type_embedding": [[12, 22], ["torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["from", "time", "import", "time", "\n", "\n", "import", "torch", "\n", "from", "torch", ".", "utils", ".", "data", "import", "DataLoader", "\n", "from", "torch", ".", "nn", "import", "functional", "as", "F", "\n", "from", "torch", ".", "nn", ".", "utils", "import", "clip_grad_norm_", "\n", "\n", "from", "apex", "import", "amp", "\n", "from", "horovod", "import", "torch", "as", "hvd", "\n", "\n", "from", "tqdm", "import", "tqdm", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.init_word_embedding": [[23, 33], ["pretrain_vcr.UniterForPretrainingForVCR.uniter.embeddings.word_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "layer.BertOnlyMLMHead"], "methods", ["None"], ["\n", "from", "data", "import", "(", "TokenBucketSampler", ",", "\n", "MetaLoader", ",", "PrefetchLoader", ",", "DetectFeatLmdb", ",", "\n", "VcrTxtTokLmdb", ",", "ImageLmdbGroup", ",", "ConcatDatasetWithLens", ",", "\n", "MlmDatasetForVCR", ",", "mlm_collate_for_vcr", ",", "\n", "MrfrDatasetForVCR", ",", "mrfr_collate_for_vcr", ",", "\n", "MrcDatasetForVCR", ",", "mrc_collate_for_vcr", ")", "\n", "\n", "from", "model", ".", "pretrain_vcr", "import", "UniterForPretrainingForVCR", "\n", "from", "optim", "import", "get_lr_sched", "\n", "from", "optim", ".", "misc", "import", "build_optimizer", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.forward": [[34, 69], ["collections.defaultdict", "pretrain_vcr.UniterForPretrainingForVCR.forward_mlm", "pretrain_vcr.UniterForPretrainingForVCR.forward_mrfr", "task.startswith", "pretrain_vcr.UniterForPretrainingForVCR.forward_mrc", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mlm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrfr", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrc"], ["\n", "from", "utils", ".", "logger", "import", "LOGGER", ",", "TB_LOGGER", ",", "RunningMeter", ",", "add_log_to_file", "\n", "from", "utils", ".", "distributed", "import", "(", "all_reduce_and_rescale_tensors", ",", "all_gather_list", ",", "\n", "broadcast_tensors", ")", "\n", "from", "utils", ".", "save", "import", "ModelSaver", ",", "save_training_meta", "\n", "from", "utils", ".", "misc", "import", "NoOp", ",", "parse_with_config", ",", "set_dropout", ",", "set_random_seed", "\n", "from", "utils", ".", "const", "import", "IMG_DIM", ",", "IMG_LABEL_DIM", ",", "BUCKET_SIZE", "\n", "NUM_SPECIAL_TOKENS", "=", "81", "\n", "\n", "\n", "def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n", "\n", "", "def", "build_mlm_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "datasets", "=", "[", "MlmDatasetForVCR", "(", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "dataset", "=", "MlmDatasetForVCR", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "collate_fn", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.forward_mlm": [[71, 93], ["pretrain_vcr.UniterForPretrainingForVCR.uniter", "pretrain_vcr.UniterForPretrainingForVCR._compute_masked_hidden", "pretrain_vcr.UniterForPretrainingForVCR.cls", "torch.nn.functional.cross_entropy", "input_ids.size"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrfr_collate_for_vcr", "\n", "\n", "\n", "", "def", "build_mrc_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrc_collate_for_vcr", "\n", "\n", "\n", "", "def", "load_img_feat", "(", "db_list", ",", "all_img_dbs", ",", "opts", ")", ":", "\n", "    ", "db_", "=", "db_list", ".", "split", "(", "\";\"", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.forward_mrfr": [[95, 117], ["pretrain_vcr.UniterForPretrainingForVCR.uniter", "pretrain_vcr.UniterForPretrainingForVCR._compute_masked_hidden", "pretrain_vcr.UniterForPretrainingForVCR.feat_regress", "torch.nn.functional.mse_loss"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["gt_db_path", ",", "db_path", "=", "\"\"", ",", "\"\"", "\n", "for", "d", "in", "db_", ":", "\n", "        ", "if", "\"gt\"", "in", "d", ":", "\n", "            ", "gt_db_path", "=", "d", "\n", "", "else", ":", "\n", "            ", "db_path", "=", "d", "\n", "", "", "if", "gt_db_path", "!=", "\"\"", ":", "\n", "        ", "img_db_gt", "=", "DetectFeatLmdb", "(", "\n", "gt_db_path", ",", "-", "1", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "100", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "all_img_dbs", ".", "path2imgdb", "[", "gt_db_path", "]", "=", "img_db_gt", "\n", "", "else", ":", "\n", "        ", "img_db_gt", "=", "None", "\n", "", "img_db", "=", "all_img_dbs", "[", "db_path", "]", "if", "db_path", "!=", "\"\"", "else", "None", "\n", "all_img_dbs", ".", "path2imgdb", "[", "db_path", "]", "=", "img_db", "\n", "return", "img_db", ",", "img_db_gt", "\n", "\n", "\n", "", "def", "create_dataloaders", "(", "datasets", ",", "is_train", ",", "opts", ",", "all_img_dbs", "=", "None", ")", ":", "\n", "    ", "if", "all_img_dbs", "is", "None", ":", "\n", "        ", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "", "dataloaders", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain_vcr.UniterForPretrainingForVCR.forward_mrc": [[119, 150], ["pretrain_vcr.UniterForPretrainingForVCR.uniter", "pretrain_vcr.UniterForPretrainingForVCR._compute_masked_hidden", "pretrain_vcr.UniterForPretrainingForVCR.region_classifier", "torch.nn.functional.log_softmax", "torch.nn.functional.kl_div", "torch.nn.functional.cross_entropy", "torch.max"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["for", "dset", "in", "datasets", ":", "\n", "        ", "for", "vcr_task", "in", "[", "\"qa\"", ",", "\"qar\"", "]", ":", "\n", "            ", "if", "is_train", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "\n", "assert", "len", "(", "dset", "[", "'tasks'", "]", ")", "==", "len", "(", "dset", "[", "'mix_ratio'", "]", ")", "\n", "img_db", ",", "img_db_gt", "=", "[", "]", ",", "[", "]", "\n", "for", "img_path", "in", "dset", "[", "'img'", "]", ":", "\n", "                    ", "curr_img_db", ",", "curr_img_db_gt", "=", "load_img_feat", "(", "\n", "img_path", ",", "all_img_dbs", ",", "opts", ")", "\n", "img_db", ".", "append", "(", "curr_img_db", ")", "\n", "img_db_gt", ".", "append", "(", "curr_img_db_gt", ")", "\n", "", "", "else", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "==", "1", "\n", "img_db", ",", "img_db_gt", "=", "load_img_feat", "(", "\n", "dset", "[", "'img'", "]", "[", "0", "]", ",", "all_img_dbs", ",", "opts", ")", "\n", "\n", "", "for", "i", ",", "t", "in", "enumerate", "(", "dset", "[", "'tasks'", "]", ")", ":", "\n", "                ", "task", "=", "f'{t}_{dset[\"name\"]}'", "\n", "\n", "if", "is_train", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} train dataset with vcr_{vcr_task}, \"", "\n", "f\"{dset['db']}, {[img.img_dir for img in img_db]},\"", "\n", "f\"{[img.img_dir for img in img_db_gt]}\"", ")", "\n", "txt_db", "=", "[", "VcrTxtTokLmdb", "(", "path", ",", "opts", ".", "max_txt_len", ",", "\n", "task", "=", "vcr_task", ")", "\n", "for", "path", "in", "dset", "[", "'db'", "]", "]", "\n", "", "else", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} val dataset with vcr_{vcr_task}, \"", "\n", "f\"{dset['db']}, {img_db.img_dir},\"", "\n", "f\"{img_db_gt.img_dir}\"", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ve.UniterForVisualEntailment.__init__": [[13, 15], ["vqa.UniterForVisualQuestionAnswering.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ",", "3", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Paired.__init__": [[20, 25], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "torch.nn.Linear", "nlvr2.UniterForNlvr2Paired.apply"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Paired.init_type_embedding": [[26, 35], ["torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Paired.forward": [[36, 63], ["collections.defaultdict", "nlvr2.UniterForNlvr2Paired.uniter", "nlvr2.UniterForNlvr2Paired.uniter.pooler", "nlvr2.UniterForNlvr2Paired.contiguous().view", "nlvr2.UniterForNlvr2Paired.nlvr2_output", "nlvr2.UniterForNlvr2Paired.size", "torch.nn.functional.cross_entropy", "nlvr2.UniterForNlvr2Paired.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "img_type_ids", "=", "img_type_ids", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "# concat CLS of the pair", "\n", "n_pair", "=", "pooled_output", ".", "size", "(", "0", ")", "//", "2", "\n", "reshaped_output", "=", "pooled_output", ".", "contiguous", "(", ")", ".", "view", "(", "n_pair", ",", "-", "1", ")", "\n", "answer_scores", "=", "self", ".", "nlvr2_output", "(", "reshaped_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "nlvr2_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Triplet.__init__": [[68, 73], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "torch.nn.Linear", "nlvr2.UniterForNlvr2Triplet.apply"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Triplet.init_type_embedding": [[74, 83], ["torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2Triplet.forward": [[84, 108], ["collections.defaultdict", "nlvr2.UniterForNlvr2Triplet.uniter", "nlvr2.UniterForNlvr2Triplet.uniter.pooler", "nlvr2.UniterForNlvr2Triplet.nlvr2_output", "torch.nn.functional.cross_entropy"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "img_type_ids", "=", "img_type_ids", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "answer_scores", "=", "self", ".", "nlvr2_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "nlvr2_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.AttentionPool.__init__": [[112, 116], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "drop", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.AttentionPool.forward": [[117, 126], ["nlvr2.AttentionPool.fc().squeeze", "nlvr2.AttentionPool.dropout", "nlvr2.AttentionPool.unsqueeze().matmul().squeeze", "torch.nn.functional.softmax", "nlvr2.AttentionPool.fc", "mask.to", "nlvr2.AttentionPool.unsqueeze().matmul", "nlvr2.AttentionPool.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"input: [B, T, D], mask = [B, T]\"\"\"", "\n", "score", "=", "self", ".", "fc", "(", "input_", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "to", "(", "dtype", "=", "input_", ".", "dtype", ")", "*", "-", "1e4", "\n", "score", "=", "score", "+", "mask", "\n", "", "norm_score", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "score", ",", "dim", "=", "1", ")", ")", "\n", "output", "=", "norm_score", ".", "unsqueeze", "(", "1", ")", ".", "matmul", "(", "input_", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2PairedAttn.__init__": [[132, 149], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "attention.MultiheadAttention", "attention.MultiheadAttention", "torch.nn.Sequential", "nlvr2.AttentionPool", "torch.nn.Linear", "nlvr2.UniterForNlvr2PairedAttn.apply", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "attn1", "=", "MultiheadAttention", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "num_attention_heads", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "attn2", "=", "MultiheadAttention", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "num_attention_heads", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ")", "\n", "self", ".", "attn_pool", "=", "AttentionPool", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "2", "*", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2PairedAttn.init_type_embedding": [[150, 159], ["torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.nlvr2.UniterForNlvr2PairedAttn.forward": [[160, 205], ["collections.defaultdict", "nlvr2.UniterForNlvr2PairedAttn.uniter", "nlvr2.UniterForNlvr2PairedAttn.size", "nlvr2.UniterForNlvr2PairedAttn.contiguous().view().chunk", "mask.contiguous().view().chunk", "nlvr2.UniterForNlvr2PairedAttn.transpose", "nlvr2.UniterForNlvr2PairedAttn.transpose", "nlvr2.UniterForNlvr2PairedAttn.attn1", "nlvr2.UniterForNlvr2PairedAttn.attn2", "nlvr2.UniterForNlvr2PairedAttn.fc().transpose", "nlvr2.UniterForNlvr2PairedAttn.fc().transpose", "nlvr2.UniterForNlvr2PairedAttn.attn_pool", "nlvr2.UniterForNlvr2PairedAttn.attn_pool", "nlvr2.UniterForNlvr2PairedAttn.nlvr2_output", "torch.cat", "torch.nn.functional.cross_entropy", "nlvr2.UniterForNlvr2PairedAttn.contiguous().view", "mask.contiguous().view", "nlvr2.UniterForNlvr2PairedAttn.fc", "nlvr2.UniterForNlvr2PairedAttn.fc", "torch.cat", "torch.cat", "nlvr2.UniterForNlvr2PairedAttn.contiguous", "mask.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "img_type_ids", "=", "img_type_ids", ")", "\n", "# separate left image and right image", "\n", "bs", ",", "tl", ",", "d", "=", "sequence_output", ".", "size", "(", ")", "\n", "left_out", ",", "right_out", "=", "sequence_output", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "bs", "//", "2", ",", "tl", "*", "2", ",", "d", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "# bidirectional attention", "\n", "mask", "=", "attn_masks", "==", "0", "\n", "left_mask", ",", "right_mask", "=", "mask", ".", "contiguous", "(", ")", ".", "view", "(", "bs", "//", "2", ",", "tl", "*", "2", "\n", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "left_out", "=", "left_out", ".", "transpose", "(", "0", ",", "1", ")", "\n", "right_out", "=", "right_out", ".", "transpose", "(", "0", ",", "1", ")", "\n", "l2r_attn", ",", "_", "=", "self", ".", "attn1", "(", "left_out", ",", "right_out", ",", "right_out", ",", "\n", "key_padding_mask", "=", "right_mask", ")", "\n", "r2l_attn", ",", "_", "=", "self", ".", "attn2", "(", "right_out", ",", "left_out", ",", "left_out", ",", "\n", "key_padding_mask", "=", "left_mask", ")", "\n", "left_out", "=", "self", ".", "fc", "(", "torch", ".", "cat", "(", "[", "l2r_attn", ",", "left_out", "]", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "right_out", "=", "self", ".", "fc", "(", "torch", ".", "cat", "(", "[", "r2l_attn", ",", "right_out", "]", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# attention pooling and final prediction", "\n", "left_out", "=", "self", ".", "attn_pool", "(", "left_out", ",", "left_mask", ")", "\n", "right_out", "=", "self", ".", "attn_pool", "(", "right_out", ",", "right_mask", ")", "\n", "answer_scores", "=", "self", ".", "nlvr2_output", "(", "\n", "torch", ".", "cat", "(", "[", "left_out", ",", "right_out", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "nlvr2_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.cost_matrix_cosine": [[11, 22], ["torch.nn.functional.normalize", "torch.nn.functional.normalize", "F.normalize.matmul", "x.dim", "y.dim", "x.size", "y.size", "x.size", "y.size", "F.normalize.transpose"], "function", ["None"], ["def", "cost_matrix_cosine", "(", "x", ",", "y", ",", "eps", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\" Compute cosine distnace across every pairs of x, y (batched)\n    [B, L_x, D] [B, L_y, D] -> [B, Lx, Ly]\"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "\n", "assert", "x", ".", "size", "(", "0", ")", "==", "y", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", "\n", "x_norm", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "y_norm", "=", "F", ".", "normalize", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "cosine_sim", "=", "x_norm", ".", "matmul", "(", "y_norm", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "cosine_dist", "=", "1", "-", "cosine_sim", "\n", "return", "cosine_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.trace": [[24, 33], ["x.size", "torch.eye().unsqueeze().expand_as", "x.masked_select().contiguous().view().sum", "torch.eye().unsqueeze", "x.masked_select().contiguous().view", "torch.eye", "x.masked_select().contiguous", "x.masked_select"], "function", ["None"], ["", "def", "trace", "(", "x", ")", ":", "\n", "    ", "\"\"\" compute trace of input tensor (batched) \"\"\"", "\n", "b", ",", "m", ",", "n", "=", "x", ".", "size", "(", ")", "\n", "assert", "m", "==", "n", "\n", "mask", "=", "torch", ".", "eye", "(", "n", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "x", ".", "device", "\n", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "x", ")", "\n", "trace", "=", "x", ".", "masked_select", "(", "mask", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "b", ",", "n", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "trace", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.ipot": [[35, 67], ["torch.no_grad", "C.size", "torch.ones", "torch.exp", "sigma.view.masked_fill_", "joint_pad.transpose.transpose", "torch.ones.masked_fill_", "torch.exp.masked_fill_", "x_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "range", "torch.ones.masked_fill_", "torch.ones", "x_len.unsqueeze().unsqueeze.unsqueeze", "sigma.view.view", "range", "x_len.unsqueeze().unsqueeze.unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze", "C.transpose", "x_pad.to", "y_pad.to", "delta.view", "Q.matmul().view", "delta.matmul", "Q.matmul"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "ipot", "(", "C", ",", "x_len", ",", "x_pad", ",", "y_len", ",", "y_pad", ",", "joint_pad", ",", "beta", ",", "iteration", ",", "k", ")", ":", "\n", "    ", "\"\"\" [B, M, N], [B], [B, M], [B], [B, N], [B, M, N]\"\"\"", "\n", "b", ",", "m", ",", "n", "=", "C", ".", "size", "(", ")", "\n", "sigma", "=", "torch", ".", "ones", "(", "b", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", "\n", ")", "/", "x_len", ".", "unsqueeze", "(", "1", ")", "\n", "T", "=", "torch", ".", "ones", "(", "b", ",", "n", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "C", ".", "transpose", "(", "1", ",", "2", ")", "/", "beta", ")", "\n", "\n", "# mask padded positions", "\n", "sigma", ".", "masked_fill_", "(", "x_pad", ",", "0", ")", "\n", "joint_pad", "=", "joint_pad", ".", "transpose", "(", "1", ",", "2", ")", "\n", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "A", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "# broadcastable lengths", "\n", "x_len", "=", "x_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "y_len", "=", "y_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# mask to zero out padding in delta and sigma", "\n", "x_mask", "=", "(", "x_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "y_mask", "=", "(", "y_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "_", "in", "range", "(", "iteration", ")", ":", "\n", "        ", "Q", "=", "A", "*", "T", "# bs * n * m", "\n", "sigma", "=", "sigma", ".", "view", "(", "b", ",", "m", ",", "1", ")", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "delta", "=", "1", "/", "(", "y_len", "*", "Q", ".", "matmul", "(", "sigma", ")", ".", "view", "(", "b", ",", "1", ",", "n", ")", "+", "y_mask", ")", "\n", "sigma", "=", "1", "/", "(", "x_len", "*", "delta", ".", "matmul", "(", "Q", ")", "+", "x_mask", ")", "\n", "", "T", "=", "delta", ".", "view", "(", "b", ",", "n", ",", "1", ")", "*", "Q", "*", "sigma", "\n", "", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.optimal_transport_dist": [[69, 86], ["ot.cost_matrix_cosine", "cost_matrix_cosine.masked_fill_", "ot.ipot", "ot.trace", "txt_pad.unsqueeze", "img_pad.unsqueeze", "cost_matrix_cosine.detach", "cost_matrix_cosine.matmul", "ipot.detach", "txt_pad.size", "txt_pad.sum", "img_pad.size", "img_pad.sum"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.cost_matrix_cosine", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.ipot", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.trace"], ["", "def", "optimal_transport_dist", "(", "txt_emb", ",", "img_emb", ",", "txt_pad", ",", "img_pad", ",", "\n", "beta", "=", "0.5", ",", "iteration", "=", "50", ",", "k", "=", "1", ")", ":", "\n", "    ", "\"\"\" [B, M, D], [B, N, D], [B, M], [B, N]\"\"\"", "\n", "cost", "=", "cost_matrix_cosine", "(", "txt_emb", ",", "img_emb", ")", "\n", "# mask the padded inputs", "\n", "joint_pad", "=", "txt_pad", ".", "unsqueeze", "(", "-", "1", ")", "|", "img_pad", ".", "unsqueeze", "(", "-", "2", ")", "\n", "cost", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "txt_len", "=", "(", "txt_pad", ".", "size", "(", "1", ")", "-", "txt_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "img_len", "=", "(", "img_pad", ".", "size", "(", "1", ")", "-", "img_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "\n", "T", "=", "ipot", "(", "cost", ".", "detach", "(", ")", ",", "txt_len", ",", "txt_pad", ",", "img_len", ",", "img_pad", ",", "joint_pad", ",", "\n", "beta", ",", "iteration", ",", "k", ")", "\n", "distance", "=", "trace", "(", "cost", ".", "matmul", "(", "T", ".", "detach", "(", ")", ")", ")", "\n", "return", "distance", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.RegionFeatureRegression.__init__": [[21, 29], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Parameter", "torch.nn.Linear", "layer.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["from", "horovod", "import", "torch", "as", "hvd", "\n", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "data", "import", "(", "TokenBucketSampler", ",", "TokenBucketSamplerForItm", ",", "\n", "MetaLoader", ",", "PrefetchLoader", ",", "\n", "TxtTokLmdb", ",", "ImageLmdbGroup", ",", "ConcatDatasetWithLens", ",", "\n", "MlmDataset", ",", "MrfrDataset", ",", "MrcDataset", ",", "\n", "mlm_collate", ",", "mrfr_collate", ",", "mrc_collate", ",", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.RegionFeatureRegression.forward": [[30, 34], ["pretrain.RegionFeatureRegression.net", "torch.nn.functional.linear", "pretrain.RegionFeatureRegression.weight.t"], "methods", ["None"], ["ItmDataset", ",", "itm_collate", ",", "itm_ot_collate", ")", "\n", "\n", "from", "model", ".", "pretrain", "import", "UniterForPretraining", "\n", "from", "optim", "import", "get_lr_sched", "\n", "from", "optim", ".", "misc", "import", "build_optimizer", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.RegionClassification.__init__": [[38, 44], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Linear", "layer.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["broadcast_tensors", ")", "\n", "from", "utils", ".", "save", "import", "ModelSaver", ",", "save_training_meta", "\n", "from", "utils", ".", "misc", "import", "NoOp", ",", "parse_with_config", ",", "set_dropout", ",", "set_random_seed", "\n", "from", "utils", ".", "const", "import", "IMG_DIM", ",", "IMG_LABEL_DIM", ",", "BUCKET_SIZE", "\n", "\n", "\n", "def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.RegionClassification.forward": [[45, 48], ["pretrain.RegionClassification.net"], "methods", ["None"], ["    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.__init__": [[52, 64], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "layer.BertOnlyMLMHead", "pretrain.RegionFeatureRegression", "pretrain.RegionClassification", "torch.nn.Linear", "pretrain.UniterForPretraining.apply"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n", "\n", "", "def", "build_dataloader_itm", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSamplerForItm", "(", "\n", "dataset", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward": [[65, 106], ["collections.defaultdict", "pretrain.UniterForPretraining.forward_mlm", "pretrain.UniterForPretraining.forward_mrfr", "pretrain.UniterForPretraining.forward_itm", "task.startswith", "pretrain.UniterForPretraining.forward_mrc", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mlm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrfr", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_itm", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrc"], ["loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n", "\n", "", "def", "build_mlm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "collate_fn", "=", "mlm_collate", "\n", "datasets", "=", "[", "MlmDataset", "(", "t", ",", "i", ")", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "collate_fn", "=", "mlm_collate", "\n", "dataset", "=", "MlmDataset", "(", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "collate_fn", "\n", "\n", "\n", "", "def", "build_mrfr_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrfrDataset", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrfrDataset", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrfr_collate", "\n", "\n", "\n", "", "def", "build_mrc_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrcDataset", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrcDataset", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrc_collate", "\n", "\n", "\n", "", "def", "build_itm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mlm": [[107, 128], ["pretrain.UniterForPretraining.uniter", "pretrain.UniterForPretraining._compute_masked_hidden", "pretrain.UniterForPretraining.cls", "torch.nn.functional.cross_entropy", "input_ids.size"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["        ", "datasets", "=", "[", "ItmDataset", "(", "t", ",", "i", ",", "opts", ".", "itm_neg_prob", ")", "\n", "for", "t", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "ItmDataset", "(", "txt_db", ",", "img_db", ",", "opts", ".", "itm_neg_prob", ")", "\n", "", "collate_fn", "=", "itm_ot_collate", "if", "opts", ".", "itm_ot_lambda", ">", "0", "else", "itm_collate", "\n", "return", "dataset", ",", "collate_fn", "\n", "\n", "\n", "", "def", "create_dataloaders", "(", "datasets", ",", "is_train", ",", "opts", ",", "all_img_dbs", "=", "None", ")", ":", "\n", "    ", "if", "all_img_dbs", "is", "None", ":", "\n", "        ", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "", "dataloaders", "=", "{", "}", "\n", "for", "dset", "in", "datasets", ":", "\n", "        ", "if", "is_train", ":", "\n", "            ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "\n", "assert", "len", "(", "dset", "[", "'tasks'", "]", ")", "==", "len", "(", "dset", "[", "'mix_ratio'", "]", ")", "\n", "img_db", "=", "[", "all_img_dbs", "[", "path", "]", "for", "path", "in", "dset", "[", "'img'", "]", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "==", "1", "\n", "img_db", "=", "all_img_dbs", "[", "dset", "[", "'img'", "]", "[", "0", "]", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden": [[129, 134], ["mask.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "hidden[].contiguous().view", "hidden.size", "mask.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "hidden[].contiguous"], "methods", ["None"], ["\n", "", "for", "i", ",", "t", "in", "enumerate", "(", "dset", "[", "'tasks'", "]", ")", ":", "\n", "            ", "task", "=", "f'{t}_{dset[\"name\"]}'", "\n", "\n", "if", "is_train", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f\"Loading {task} train dataset \"", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrfr": [[135, 155], ["pretrain.UniterForPretraining.uniter", "pretrain.UniterForPretraining._compute_masked_hidden", "pretrain.UniterForPretraining.feat_regress", "torch.nn.functional.mse_loss"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["f\"{dset['db']}, {[img.img_dir for img in img_db]}\"", ")", "\n", "txt_db", "=", "[", "TxtTokLmdb", "(", "path", ",", "opts", ".", "max_txt_len", ")", "\n", "for", "path", "in", "dset", "[", "'db'", "]", "]", "\n", "", "else", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f\"Loading {task} validation dataset, \"", "\n", "f\"{dset['db']}, {img_db.img_dir}\"", ")", "\n", "txt_db", "=", "TxtTokLmdb", "(", "dset", "[", "'db'", "]", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n", "                ", "dataset", "=", "build_mlm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "                ", "dataset", "=", "build_mrfr_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "                ", "dataset", "=", "build_mrc_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n", "                ", "dataset", "=", "build_itm_dataset", "(", "txt_db", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"{len(dataset[0])*hvd.size()} samples loaded\"", ")", "\n", "if", "task", ".", "startswith", "(", "'itm'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_itm": [[156, 200], ["pretrain.UniterForPretraining.uniter", "pretrain.UniterForPretraining.uniter.pooler", "pretrain.UniterForPretraining.itm_output", "pretrain.UniterForPretraining.size", "input_ids.size", "img_feat.size", "max", "ot_scatter.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros().scatter_", "ot.optimal_transport_dist().to", "ot.optimal_transport_dist().to.masked_select", "ot.optimal_transport_dist().to.masked_select", "torch.nn.functional.cross_entropy", "ot_scatter.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.zeros", "ot.optimal_transport_dist", "txt_emb.float", "img_emb.float"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.ot.optimal_transport_dist"], ["# itm handles distributed training in dset not sampler", "\n", "                ", "loader", "=", "build_dataloader_itm", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                ", "loader", "=", "build_dataloader", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "", "if", "is_train", ":", "\n", "                ", "ratio", "=", "dset", "[", "'mix_ratio'", "]", "[", "i", "]", "\n", "dataloaders", "[", "task", "]", "=", "(", "loader", ",", "ratio", ")", "\n", "", "else", ":", "\n", "                ", "dataloaders", "[", "task", "]", "=", "PrefetchLoader", "(", "loader", ")", "\n", "", "", "", "return", "dataloaders", ",", "all_img_dbs", "\n", "\n", "\n", "", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "save_training_meta", "(", "opts", ")", "\n", "TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "args", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "all_dbs", "=", "[", "db", "for", "datasets", "in", "[", "opts", ".", "train_datasets", ",", "opts", ".", "val_datasets", "]", "\n", "for", "dset", "in", "datasets", "for", "db", "in", "dset", "[", "'db'", "]", "]", "\n", "\n", "tokenizer", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining.forward_mrc": [[201, 230], ["pretrain.UniterForPretraining.uniter", "pretrain.UniterForPretraining._compute_masked_hidden", "pretrain.UniterForPretraining.region_classifier", "torch.nn.functional.log_softmax", "torch.nn.functional.kl_div", "torch.nn.functional.cross_entropy", "torch.max"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.pretrain.UniterForPretraining._compute_masked_hidden"], ["assert", "all", "(", "tokenizer", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "\n", "# build data loaders", "\n", "train_dataloaders", ",", "all_img_dbs", "=", "create_dataloaders", "(", "\n", "opts", ".", "train_datasets", ",", "True", ",", "opts", ")", "\n", "val_dataloaders", ",", "_", "=", "create_dataloaders", "(", "\n", "opts", ".", "val_datasets", ",", "False", ",", "opts", ",", "all_img_dbs", ")", "\n", "meta_loader", "=", "MetaLoader", "(", "train_dataloaders", ",", "\n", "accum_steps", "=", "opts", ".", "gradient_accumulation_steps", ",", "\n", "distributed", "=", "n_gpu", ">", "1", ")", "\n", "meta_loader", "=", "PrefetchLoader", "(", "meta_loader", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "", "model", "=", "UniterForPretraining", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "img_label_dim", "=", "IMG_LABEL_DIM", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "task2scaler", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "train_dataloaders", ".", "keys", "(", ")", ")", "}", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vqa.UniterForVisualQuestionAnswering.__init__": [[20, 30], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "torch.nn.Sequential", "vqa.UniterForVisualQuestionAnswering.apply", "torch.nn.Linear", "layer.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "num_answer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "vqa_output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "2", ")", ",", "\n", "GELU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", "*", "2", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "num_answer", ")", "\n", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vqa.UniterForVisualQuestionAnswering.forward": [[31, 53], ["collections.defaultdict", "vqa.UniterForVisualQuestionAnswering.uniter", "vqa.UniterForVisualQuestionAnswering.uniter.pooler", "vqa.UniterForVisualQuestionAnswering.vqa_output", "torch.nn.functional.binary_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "answer_scores", "=", "self", ".", "vqa_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "vqa_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "vqa_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.GELU.forward": [[48, 51], ["layer.gelu"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.gelu"], ["    ", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "        ", "output", "=", "gelu", "(", "input_", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.__init__": [[54, 69], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.transpose_for_scores": [[70, 74], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.forward": [[75, 102], ["layer.BertSelfAttention.query", "layer.BertSelfAttention.key", "layer.BertSelfAttention.value", "layer.BertSelfAttention.transpose_for_scores", "layer.BertSelfAttention.transpose_for_scores", "layer.BertSelfAttention.transpose_for_scores", "torch.matmul", "layer.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "layer.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfOutput.__init__": [[105, 110], ["torch.nn.Module.__init__", "torch.nn.Linear", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertSelfOutput.forward": [[111, 116], ["layer.BertSelfOutput.dense", "layer.BertSelfOutput.dropout", "layer.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertAttention.__init__": [[119, 123], ["torch.nn.Module.__init__", "layer.BertSelfAttention", "layer.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertAttention.forward": [[124, 128], ["layer.BertAttention.self", "layer.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertIntermediate.__init__": [[131, 138], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertIntermediate.forward": [[139, 143], ["layer.BertIntermediate.dense", "layer.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertOutput.__init__": [[146, 151], ["torch.nn.Module.__init__", "torch.nn.Linear", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertOutput.forward": [[152, 157], ["layer.BertOutput.dense", "layer.BertOutput.dropout", "layer.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertLayer.__init__": [[160, 165], ["torch.nn.Module.__init__", "layer.BertAttention", "layer.BertIntermediate", "layer.BertOutput"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertLayer.forward": [[166, 171], ["layer.BertLayer.attention", "layer.BertLayer.intermediate", "layer.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertPooler.__init__": [[174, 178], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertPooler.forward": [[179, 186], ["layer.BertPooler.dense", "layer.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertPredictionHeadTransform.__init__": [[189, 197], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "apex.normalization.fused_layer_norm.FusedLayerNorm"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertPredictionHeadTransform.forward": [[198, 203], ["layer.BertPredictionHeadTransform.dense", "layer.BertPredictionHeadTransform.transform_act_fn", "layer.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertLMPredictionHead.__init__": [[206, 218], ["torch.nn.Module.__init__", "layer.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertLMPredictionHead.forward": [[219, 223], ["layer.BertLMPredictionHead.transform", "layer.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertOnlyMLMHead.__init__": [[226, 230], ["torch.nn.Module.__init__", "layer.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "\n", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.BertOnlyMLMHead.forward": [[231, 234], ["layer.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.gelu": [[31, 38], ["torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.layer.swish": [[40, 42], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.MultiheadAttention.__init__": [[297, 331], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Linear", "attention.MultiheadAttention._reset_parameters", "torch.empty", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "attention.MultiheadAttention.register_parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.MultiheadAttention._reset_parameters"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", ",", "kdim", "=", "None", ",", "vdim", "=", "None", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "_qkv_same_embed_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "empty", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "\n", "if", "self", ".", "_qkv_same_embed_dim", "is", "False", ":", "\n", "            ", "self", ".", "q_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "k_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "self", ".", "kdim", ")", ")", "\n", "self", ".", "v_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "self", ".", "vdim", ")", ")", "\n", "\n", "", "if", "bias", ":", "\n", "            ", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "empty", "(", "3", "*", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'in_proj_bias'", ",", "None", ")", "\n", "", "self", ".", "out_proj", "=", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "empty", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "empty", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "_reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.MultiheadAttention._reset_parameters": [[332, 347], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_qkv_same_embed_dim", ":", "\n", "            ", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "", "else", ":", "\n", "            ", "xavier_uniform_", "(", "self", ".", "q_proj_weight", ")", "\n", "xavier_uniform_", "(", "self", ".", "k_proj_weight", ")", "\n", "xavier_uniform_", "(", "self", ".", "v_proj_weight", ")", "\n", "\n", "", "if", "self", ".", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.MultiheadAttention.forward": [[348, 403], ["hasattr", "attention.multi_head_attention_forward", "attention.multi_head_attention_forward", "hasattr", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.multi_head_attention_forward", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.multi_head_attention_forward"], ["", "", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "True", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "r\"\"\"\n    Args:\n        query, key, value: map a query and a set of key-value pairs to an output.\n            See \"Attention Is All You Need\" for more details.\n        key_padding_mask: if provided, specified padding elements in the key will\n            be ignored by the attention. This is an binary mask. When the value is True,\n            the corresponding value on the attention layer will be filled with -inf.\n        need_weights: output attn_output_weights.\n        attn_mask: mask that prevents attention to certain positions. This is an additive mask\n            (i.e. the values will be added to the attention layer).\n\n    Shape:\n        - Inputs:\n        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key_padding_mask: :math:`(N, S)`, ByteTensor, where N is the batch size, S is the source sequence length.\n        - attn_mask: :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n\n        - Outputs:\n        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n          E is the embedding dimension.\n        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n          L is the target sequence length, S is the source sequence length.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "'_qkv_same_embed_dim'", ")", "and", "self", ".", "_qkv_same_embed_dim", "is", "False", ":", "\n", "            ", "return", "multi_head_attention_forward", "(", "\n", "query", ",", "key", ",", "value", ",", "self", ".", "embed_dim", ",", "self", ".", "num_heads", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "self", ".", "bias_v", ",", "self", ".", "add_zero_attn", ",", "\n", "self", ".", "dropout", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "need_weights", "=", "need_weights", ",", "\n", "attn_mask", "=", "attn_mask", ",", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj_weight", ",", "k_proj_weight", "=", "self", ".", "k_proj_weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj_weight", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ",", "'_qkv_same_embed_dim'", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "'A new version of MultiheadAttention module has been implemented. \\\n                    Please re-train your model with the new module'", ",", "\n", "UserWarning", ")", "\n", "\n", "", "return", "multi_head_attention_forward", "(", "\n", "query", ",", "key", ",", "value", ",", "self", ".", "embed_dim", ",", "self", ".", "num_heads", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "self", ".", "bias_v", ",", "self", ".", "add_zero_attn", ",", "\n", "self", ".", "dropout", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "need_weights", "=", "need_weights", ",", "\n", "attn_mask", "=", "attn_mask", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.attention.multi_head_attention_forward": [[13, 266], ["torch.equal", "query.size", "torch.nn.functional.linear.contiguous().view().transpose", "torch.nn.functional.linear.size", "torch.bmm", "torch.nn.functional.softmax", "torch.nn.functional.dropout", "torch.bmm", "torch.nn.functional.linear.transpose().contiguous().view", "torch.nn.functional.linear", "torch.equal", "torch.equal", "list", "key.size", "value.size", "float", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional.size", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional.size", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional.size", "torch.nn.functional.linear.contiguous().view().transpose", "torch.nn.functional.linear.contiguous().view().transpose", "torch.cat", "torch.cat", "torch.nn.functional.linear.transpose", "list", "torch.cat.unsqueeze", "attn_output_weights.view.view", "attn_output_weights.view.masked_fill", "attn_output_weights.view.view", "list", "attn_output_weights.view.view", "query.size", "torch.nn.functional.linear().chunk", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.cat", "torch.cat", "torch.nn.functional.linear.contiguous().view", "static_k.size", "static_k.size", "static_v.size", "static_v.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "attn_output_weights.view.size", "torch.cat.unsqueeze().unsqueeze", "float", "torch.nn.functional.linear.size", "torch.nn.functional.linear.transpose().contiguous", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "query.size", "key.size", "value.size", "torch.cat", "torch.cat", "torch.nn.functional.linear.contiguous().view", "torch.nn.functional.linear.contiguous().view", "torch.zeros", "torch.zeros", "attn_output_weights.view.sum", "torch.nn.functional.linear", "torch.nn.functional.linear().chunk", "bias_k.repeat", "bias_v.repeat", "torch.nn.functional.linear.contiguous", "torch.zeros", "torch.zeros", "torch.cat.unsqueeze", "torch.nn.functional.linear.transpose", "torch.zeros", "torch.zeros", "torch.nn.functional.linear.contiguous", "torch.nn.functional.linear.contiguous", "torch.nn.functional.linear", "torch.nn.functional.linear.size", "torch.nn.functional.linear.size", "torch.nn.functional.linear.size", "torch.nn.functional.linear.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "function", ["None"], ["def", "multi_head_attention_forward", "(", "query", ",", "# type: Tensor", "\n", "key", ",", "# type: Tensor", "\n", "value", ",", "# type: Tensor", "\n", "embed_dim_to_check", ",", "# type: int", "\n", "num_heads", ",", "# type: int", "\n", "in_proj_weight", ",", "# type: Tensor", "\n", "in_proj_bias", ",", "# type: Tensor", "\n", "bias_k", ",", "# type: Optional[Tensor]", "\n", "bias_v", ",", "# type: Optional[Tensor]", "\n", "add_zero_attn", ",", "# type: bool", "\n", "dropout_p", ",", "# type: float", "\n", "out_proj_weight", ",", "# type: Tensor", "\n", "out_proj_bias", ",", "# type: Tensor", "\n", "training", "=", "True", ",", "# type: bool", "\n", "key_padding_mask", "=", "None", ",", "# type: Optional[Tensor]", "\n", "need_weights", "=", "True", ",", "# type: bool", "\n", "attn_mask", "=", "None", ",", "# type: Optional[Tensor]", "\n", "use_separate_proj_weight", "=", "False", ",", "# type: bool", "\n", "q_proj_weight", "=", "None", ",", "# type: Optional[Tensor]", "\n", "k_proj_weight", "=", "None", ",", "# type: Optional[Tensor]", "\n", "v_proj_weight", "=", "None", ",", "# type: Optional[Tensor]", "\n", "static_k", "=", "None", ",", "# type: Optional[Tensor]", "\n", "static_v", "=", "None", "# type: Optional[Tensor]", "\n", ")", ":", "\n", "# type: (...) -> Tuple[Tensor, Optional[Tensor]]", "\n", "    ", "r\"\"\"\n    Args:\n        query, key, value: map a query and a set of key-value pairs to an output.\n            See \"Attention Is All You Need\" for more details.\n        embed_dim_to_check: total dimension of the model.\n        num_heads: parallel attention heads.\n        in_proj_weight, in_proj_bias: input projection weight and bias.\n        bias_k, bias_v: bias of the key and value sequences to be added at dim=0.\n        add_zero_attn: add a new batch of zeros to the key and\n                       value sequences at dim=1.\n        dropout_p: probability of an element to be zeroed.\n        out_proj_weight, out_proj_bias: the output projection weight and bias.\n        training: apply dropout if is ``True``.\n        key_padding_mask: if provided, specified padding elements in the key will\n            be ignored by the attention. This is an binary mask. When the value is True,\n            the corresponding value on the attention layer will be filled with -inf.\n        need_weights: output attn_output_weights.\n        attn_mask: mask that prevents attention to certain positions. This is an additive mask\n            (i.e. the values will be added to the attention layer).\n        use_separate_proj_weight: the function accept the proj. weights for query, key,\n            and value in differnt forms. If false, in_proj_weight will be used, which is\n            a combination of q_proj_weight, k_proj_weight, v_proj_weight.\n        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.\n        static_k, static_v: static key and value used for attention operators.\n\n\n    Shape:\n        Inputs:\n        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key_padding_mask: :math:`(N, S)`, ByteTensor, where N is the batch size, S is the source sequence length.\n        - attn_mask: :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n\n        Outputs:\n        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n          E is the embedding dimension.\n        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n          L is the target sequence length, S is the source sequence length.\n    \"\"\"", "\n", "\n", "qkv_same", "=", "torch", ".", "equal", "(", "query", ",", "key", ")", "and", "torch", ".", "equal", "(", "key", ",", "value", ")", "\n", "kv_same", "=", "torch", ".", "equal", "(", "key", ",", "value", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "embed_dim_to_check", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "head_dim", "*", "num_heads", "==", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "scaling", "=", "float", "(", "head_dim", ")", "**", "-", "0.5", "\n", "\n", "if", "use_separate_proj_weight", "is", "not", "True", ":", "\n", "        ", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "linear", "(", "query", ",", "in_proj_weight", ",", "in_proj_bias", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "            ", "_b", "=", "in_proj_bias", "\n", "_start", "=", "0", "\n", "_end", "=", "embed_dim", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", "_end", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "_end", "]", "\n", "", "q", "=", "linear", "(", "query", ",", "_w", ",", "_b", ")", "\n", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "None", "\n", "v", "=", "None", "\n", "", "else", ":", "\n", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "                ", "_b", "=", "in_proj_bias", "\n", "_start", "=", "embed_dim", "\n", "_end", "=", "None", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                    ", "_b", "=", "_b", "[", "_start", ":", "]", "\n", "", "k", ",", "v", "=", "linear", "(", "key", ",", "_w", ",", "_b", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "", "else", ":", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "            ", "_b", "=", "in_proj_bias", "\n", "_start", "=", "0", "\n", "_end", "=", "embed_dim", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", "_end", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "_end", "]", "\n", "", "q", "=", "linear", "(", "query", ",", "_w", ",", "_b", ")", "\n", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "_b", "=", "in_proj_bias", "\n", "_start", "=", "embed_dim", "\n", "_end", "=", "embed_dim", "*", "2", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", "_end", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "_end", "]", "\n", "", "k", "=", "linear", "(", "key", ",", "_w", ",", "_b", ")", "\n", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "_b", "=", "in_proj_bias", "\n", "_start", "=", "embed_dim", "*", "2", "\n", "_end", "=", "None", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "]", "\n", "", "v", "=", "linear", "(", "value", ",", "_w", ",", "_b", ")", "\n", "", "", "else", ":", "\n", "        ", "q_proj_weight_non_opt", "=", "torch", ".", "jit", ".", "_unwrap_optional", "(", "q_proj_weight", ")", "\n", "len1", ",", "len2", "=", "q_proj_weight_non_opt", ".", "size", "(", ")", "\n", "assert", "len1", "==", "embed_dim", "and", "len2", "==", "query", ".", "size", "(", "-", "1", ")", "\n", "\n", "k_proj_weight_non_opt", "=", "torch", ".", "jit", ".", "_unwrap_optional", "(", "k_proj_weight", ")", "\n", "len1", ",", "len2", "=", "k_proj_weight_non_opt", ".", "size", "(", ")", "\n", "assert", "len1", "==", "embed_dim", "and", "len2", "==", "key", ".", "size", "(", "-", "1", ")", "\n", "\n", "v_proj_weight_non_opt", "=", "torch", ".", "jit", ".", "_unwrap_optional", "(", "v_proj_weight", ")", "\n", "len1", ",", "len2", "=", "v_proj_weight_non_opt", ".", "size", "(", ")", "\n", "assert", "len1", "==", "embed_dim", "and", "len2", "==", "value", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "q", "=", "linear", "(", "query", ",", "q_proj_weight_non_opt", ",", "in_proj_bias", "[", "0", ":", "embed_dim", "]", ")", "\n", "k", "=", "linear", "(", "key", ",", "k_proj_weight_non_opt", ",", "in_proj_bias", "[", "embed_dim", ":", "(", "embed_dim", "*", "2", ")", "]", ")", "\n", "v", "=", "linear", "(", "value", ",", "v_proj_weight_non_opt", ",", "in_proj_bias", "[", "(", "embed_dim", "*", "2", ")", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "linear", "(", "query", ",", "q_proj_weight_non_opt", ",", "in_proj_bias", ")", "\n", "k", "=", "linear", "(", "key", ",", "k_proj_weight_non_opt", ",", "in_proj_bias", ")", "\n", "v", "=", "linear", "(", "value", ",", "v_proj_weight_non_opt", ",", "in_proj_bias", ")", "\n", "", "", "q", "=", "q", "*", "scaling", "\n", "\n", "if", "bias_k", "is", "not", "None", "and", "bias_v", "is", "not", "None", ":", "\n", "        ", "if", "static_k", "is", "None", "and", "static_v", "is", "None", ":", "\n", "            ", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "\n", "torch", ".", "zeros", "(", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "attn_mask", ".", "dtype", ",", "\n", "device", "=", "attn_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "key_padding_mask", ".", "dtype", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "static_k", "is", "None", ",", "\"bias cannot be added to static key.\"", "\n", "assert", "static_v", "is", "None", ",", "\"bias cannot be added to static value.\"", "\n", "", "", "else", ":", "\n", "        ", "assert", "bias_k", "is", "None", "\n", "assert", "bias_v", "is", "None", "\n", "\n", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "num_heads", ",", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "        ", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "num_heads", ",", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "        ", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "num_heads", ",", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "if", "static_k", "is", "not", "None", ":", "\n", "        ", "assert", "static_k", ".", "size", "(", "0", ")", "==", "bsz", "*", "num_heads", "\n", "assert", "static_k", ".", "size", "(", "2", ")", "==", "head_dim", "\n", "k", "=", "static_k", "\n", "\n", "", "if", "static_v", "is", "not", "None", ":", "\n", "        ", "assert", "static_v", ".", "size", "(", "0", ")", "==", "bsz", "*", "num_heads", "\n", "assert", "static_v", ".", "size", "(", "2", ")", "==", "head_dim", "\n", "v", "=", "static_v", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "        ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "add_zero_attn", ":", "\n", "        ", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "torch", ".", "zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ",", "dtype", "=", "k", ".", "dtype", ",", "device", "=", "k", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "torch", ".", "zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ",", "dtype", "=", "v", ".", "dtype", ",", "device", "=", "v", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "torch", ".", "zeros", "(", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "attn_mask", ".", "dtype", ",", "\n", "device", "=", "attn_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "key_padding_mask", ".", "dtype", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "attn_output_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_output_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "        ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "attn_output_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "        ", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "bsz", ",", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_output_weights", "=", "attn_output_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", ",", "\n", ")", "\n", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "bsz", "*", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_output_weights", "=", "softmax", "(", "\n", "attn_output_weights", ",", "dim", "=", "-", "1", ")", "\n", "attn_output_weights", "=", "dropout", "(", "attn_output_weights", ",", "p", "=", "dropout_p", ",", "training", "=", "training", ")", "\n", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_output_weights", ",", "v", ")", "\n", "assert", "list", "(", "attn_output", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "num_heads", ",", "tgt_len", ",", "head_dim", "]", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn_output", "=", "linear", "(", "attn_output", ",", "out_proj_weight", ",", "out_proj_bias", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# average attention weights over heads", "\n", "        ", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "bsz", ",", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "return", "attn_output", ",", "attn_output_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "num_heads", "\n", "", "else", ":", "\n", "        ", "return", "attn_output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.__init__": [[27, 85], ["isinstance", "json.loads.items", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs UniterConfig.\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in\n                `UniterModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer\n                encoder.\n            num_attention_heads: Number of attention heads for each attention\n                layer in the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e.\n                feed-forward) layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string)\n                in the encoder and pooler. If string, \"gelu\", \"relu\" and\n                \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully\n                connected layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this\n                model might ever be used with. Typically set this to something\n                large just in case (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed\n                into `UniterModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer\n                for initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\n", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size \"", "\n", "\"(int) or the path to a pretrained model config \"", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.from_dict": [[88, 96], ["model.UniterConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `UniterConfig` from a\n           Python dictionary of parameters.\"\"\"", "\n", "config", "=", "UniterConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.from_json_file": [[97, 103], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `UniterConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.__repr__": [[104, 106], ["str", "model.UniterConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.to_dict": [[107, 111], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.to_json_string": [[112, 115], ["json.dumps", "model.UniterConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.__init__": [[121, 132], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "UniterConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of \"", "\n", "\"class `UniterConfig`. To create a model from a Google \"", "\n", "\"pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.init_weights": [[133, 147], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses", "\n", "# truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "FusedLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterPreTrainedModel.from_pretrained": [[148, 215], ["cls.UniterConfig.from_json_file", "logger.info", "cls", "state_dict.copy.copy.keys", "zip", "getattr", "state_dict.copy.copy.copy", "cls.UniterPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "config_file", ",", "state_dict", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a UniterPreTrainedModel from a pre-trained model file or a\n        pytorch state dict.\n        Params:\n            config_file: config json file\n            state_dict: an state dictionnary\n            *inputs, **kwargs: additional input for the specific Uniter class\n        \"\"\"", "\n", "# Load config", "\n", "config", "=", "UniterConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "# Load from a PyTorch state_dict", "\n", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "(", "{", "}", "if", "metadata", "is", "None", "\n", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "\n", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'bert'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'bert.'", ")", "\n", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'bert.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from \"", "\n", "\"pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in \"", "\n", "\"{}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for '", "\n", "'{}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\n", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterTextEmbeddings.__init__": [[218, 231], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "\n", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "\n", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model", "\n", "# variable name and be able to load any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "FusedLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterTextEmbeddings.forward": [[232, 246], ["model.UniterTextEmbeddings.word_embeddings", "model.UniterTextEmbeddings.position_embeddings", "model.UniterTextEmbeddings.token_type_embeddings", "model.UniterTextEmbeddings.LayerNorm", "model.UniterTextEmbeddings.dropout", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "(", "words_embeddings", "\n", "+", "position_embeddings", "\n", "+", "token_type_embeddings", ")", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterImageEmbeddings.__init__": [[249, 260], ["torch.nn.Module.__init__", "torch.nn.Linear", "apex.normalization.fused_layer_norm.FusedLayerNorm", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear", "torch.nn.Embedding", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_linear", "=", "nn", ".", "Linear", "(", "img_dim", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "img_layer_norm", "=", "FusedLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "pos_layer_norm", "=", "FusedLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "pos_linear", "=", "nn", ".", "Linear", "(", "7", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "mask_embedding", "=", "nn", ".", "Embedding", "(", "2", ",", "img_dim", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# tf naming convention for layer norm", "\n", "self", ".", "LayerNorm", "=", "FusedLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterImageEmbeddings.forward": [[261, 273], ["model.UniterImageEmbeddings.img_layer_norm", "model.UniterImageEmbeddings.pos_layer_norm", "model.UniterImageEmbeddings.LayerNorm", "model.UniterImageEmbeddings.dropout", "model.UniterImageEmbeddings.mask_embedding.weight.data[].fill_", "model.UniterImageEmbeddings.mask_embedding", "model.UniterImageEmbeddings.img_linear", "model.UniterImageEmbeddings.pos_linear", "img_masks.long"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img_feat", ",", "img_pos_feat", ",", "type_embeddings", ",", "img_masks", "=", "None", ")", ":", "\n", "        ", "if", "img_masks", "is", "not", "None", ":", "\n", "            ", "self", ".", "mask_embedding", ".", "weight", ".", "data", "[", "0", ",", ":", "]", ".", "fill_", "(", "0", ")", "\n", "mask", "=", "self", ".", "mask_embedding", "(", "img_masks", ".", "long", "(", ")", ")", "\n", "img_feat", "=", "img_feat", "+", "mask", "\n", "\n", "", "transformed_im", "=", "self", ".", "img_layer_norm", "(", "self", ".", "img_linear", "(", "img_feat", ")", ")", "\n", "transformed_pos", "=", "self", ".", "pos_layer_norm", "(", "self", ".", "pos_linear", "(", "img_pos_feat", ")", ")", "\n", "embeddings", "=", "transformed_im", "+", "transformed_pos", "+", "type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterEncoder.__init__": [[276, 281], ["torch.nn.Module.__init__", "layer.BertLayer.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "\n", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterEncoder.forward": [[282, 293], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "hidden_states", "=", "input_", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel.__init__": [[298, 305], ["model.UniterPreTrainedModel.__init__", "model.UniterTextEmbeddings", "model.UniterImageEmbeddings", "model.UniterEncoder", "layer.BertPooler", "model.UniterModel.apply"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "UniterTextEmbeddings", "(", "config", ")", "\n", "self", ".", "img_embeddings", "=", "UniterImageEmbeddings", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "encoder", "=", "UniterEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_txt_embeddings": [[306, 310], ["model.UniterModel.embeddings"], "methods", ["None"], ["", "def", "_compute_txt_embeddings", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "txt_type_ids", "=", "None", ")", ":", "\n", "        ", "output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", ",", "txt_type_ids", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_img_embeddings": [[311, 320], ["model.UniterModel.embeddings.token_type_embeddings", "model.UniterModel.img_embeddings", "torch.ones_like", "img_feat[].long"], "methods", ["None"], ["", "def", "_compute_img_embeddings", "(", "self", ",", "img_feat", ",", "img_pos_feat", ",", "img_masks", "=", "None", ",", "\n", "img_type_ids", "=", "None", ")", ":", "\n", "        ", "if", "img_type_ids", "is", "None", ":", "\n", "            ", "img_type_ids", "=", "torch", ".", "ones_like", "(", "img_feat", "[", ":", ",", ":", ",", "0", "]", ".", "long", "(", ")", ")", "\n", "", "img_type_embeddings", "=", "self", ".", "embeddings", ".", "token_type_embeddings", "(", "\n", "img_type_ids", ")", "\n", "output", "=", "self", ".", "img_embeddings", "(", "img_feat", ",", "img_pos_feat", ",", "\n", "img_type_embeddings", ",", "img_masks", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_img_txt_embeddings": [[321, 335], ["model.UniterModel._compute_txt_embeddings", "model.UniterModel._compute_img_embeddings", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.gather", "torch.cat", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_img_embeddings"], ["", "def", "_compute_img_txt_embeddings", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", ",", "img_masks", "=", "None", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ")", ":", "\n", "        ", "txt_emb", "=", "self", ".", "_compute_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "txt_type_ids", ")", "\n", "img_emb", "=", "self", ".", "_compute_img_embeddings", "(", "\n", "img_feat", ",", "img_pos_feat", ",", "img_masks", ",", "img_type_ids", ")", "\n", "# align back to most compact input", "\n", "gather_index", "=", "gather_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "\n", "-", "1", ",", "-", "1", ",", "self", ".", "config", ".", "hidden_size", ")", "\n", "embedding_output", "=", "torch", ".", "gather", "(", "torch", ".", "cat", "(", "[", "txt_emb", ",", "img_emb", "]", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "index", "=", "gather_index", ")", "\n", "return", "embedding_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel.forward": [[336, 368], ["attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "model.UniterModel.encoder", "model.UniterModel._compute_img_embeddings", "attention_mask.unsqueeze", "model.UniterModel._compute_txt_embeddings", "model.UniterModel._compute_img_txt_embeddings", "next", "model.UniterModel.parameters"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_img_embeddings", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.model.UniterModel._compute_img_txt_embeddings", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attention_mask", ",", "gather_index", "=", "None", ",", "img_masks", "=", "None", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ")", ":", "\n", "# compute self-attention mask", "\n", "        ", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# embedding layer", "\n", "if", "input_ids", "is", "None", ":", "\n", "# image only", "\n", "            ", "embedding_output", "=", "self", ".", "_compute_img_embeddings", "(", "\n", "img_feat", ",", "img_pos_feat", ",", "img_masks", ",", "img_type_ids", ")", "\n", "", "elif", "img_feat", "is", "None", ":", "\n", "# text only", "\n", "            ", "embedding_output", "=", "self", ".", "_compute_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "txt_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "embedding_output", "=", "self", ".", "_compute_img_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", ",", "img_masks", ",", "txt_type_ids", ",", "img_type_ids", ")", "\n", "\n", "", "encoded_layers", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.__init__": [[21, 31], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "torch.nn.Sequential", "vcr.UniterForVisualCommonsenseReasoning.apply", "torch.nn.Linear", "torch.nn.ReLU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "vcr_output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", "*", "2", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "2", ")", "\n", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_type_embedding": [[32, 42], ["torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "4", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "0", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "new_emb", ".", "weight", ".", "data", "[", "3", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.init_word_embedding": [[43, 51], ["vcr.UniterForVisualCommonsenseReasoning.uniter.embeddings.word_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.apply", "torch.nn.Embedding.weight.data[].copy_"], "methods", ["None"], ["", "def", "init_word_embedding", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "orig_word_num", "=", "self", ".", "uniter", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "size", "(", "0", ")", "\n", "new_emb", "=", "nn", ".", "Embedding", "(", "\n", "orig_word_num", "+", "num_special_tokens", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "data", "\n", "new_emb", ".", "weight", ".", "data", "[", ":", "orig_word_num", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "word_embeddings", "=", "new_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.vcr.UniterForVisualCommonsenseReasoning.forward": [[52, 78], ["collections.defaultdict", "vcr.UniterForVisualCommonsenseReasoning.uniter", "vcr.UniterForVisualCommonsenseReasoning.uniter.pooler", "vcr.UniterForVisualCommonsenseReasoning.vcr_output", "torch.nn.functional.cross_entropy", "targets.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "txt_type_ids", "=", "batch", "[", "'txt_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "txt_type_ids", "=", "txt_type_ids", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "rank_scores", "=", "self", ".", "vcr_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "vcr_loss", "=", "F", ".", "cross_entropy", "(", "\n", "rank_scores", ",", "targets", ".", "squeeze", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ")", "\n", "return", "vcr_loss", "\n", "", "else", ":", "\n", "            ", "rank_scores", "=", "rank_scores", "[", ":", ",", "1", ":", "]", "\n", "return", "rank_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension.__init__": [[22, 46], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "re.UniterForReferringExpressionComprehension.apply", "torch.nn.Linear", "torch.nn.CrossEntropyLoss", "torch.nn.Sequential", "ValueError", "torch.nn.Linear", "layer.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "loss", "=", "\"cls\"", ",", "\n", "margin", "=", "0.2", ",", "hard_ratio", "=", "0.3", ",", "mlp", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "if", "mlp", "==", "1", ":", "\n", "            ", "self", ".", "re_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "", "elif", "mlp", "==", "2", ":", "\n", "            ", "self", ".", "re_output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "GELU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"MLP restricted to be 1 or 2 layers.\"", ")", "\n", "", "self", ".", "loss", "=", "loss", "\n", "assert", "self", ".", "loss", "in", "[", "'cls'", ",", "'rank'", "]", "\n", "if", "self", ".", "loss", "==", "'rank'", ":", "\n", "            ", "self", ".", "margin", "=", "margin", "\n", "self", ".", "hard_ratio", "=", "hard_ratio", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension.forward": [[47, 93], ["collections.defaultdict", "re.UniterForReferringExpressionComprehension.uniter", "re.UniterForReferringExpressionComprehension._get_image_hidden", "re.UniterForReferringExpressionComprehension.re_output().squeeze", "scores.masked_fill.masked_fill.masked_fill", "re.UniterForReferringExpressionComprehension.re_output", "re.UniterForReferringExpressionComprehension.crit", "len", "scores.masked_fill.masked_fill.gather", "torch.sigmoid().view", "re.UniterForReferringExpressionComprehension.sample_neg_ix", "scores.masked_fill.masked_fill.gather", "torch.sigmoid().view", "torch.clamp", "targets.squeeze", "pos_ix.view", "re.UniterForReferringExpressionComprehension.view", "torch.sigmoid", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension._get_image_hidden", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension.sample_neg_ix"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "obj_masks", "=", "batch", "[", "'obj_masks'", "]", "\n", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "# get only the region part", "\n", "txt_lens", ",", "num_bbs", "=", "batch", "[", "\"txt_lens\"", "]", ",", "batch", "[", "\"num_bbs\"", "]", "\n", "sequence_output", "=", "self", ".", "_get_image_hidden", "(", "\n", "sequence_output", ",", "txt_lens", ",", "num_bbs", ")", "\n", "\n", "# re score (n, max_num_bb)", "\n", "scores", "=", "self", ".", "re_output", "(", "sequence_output", ")", ".", "squeeze", "(", "2", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "obj_masks", ",", "-", "1e4", ")", "# mask out non-objects", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "\"targets\"", "]", "\n", "if", "self", ".", "loss", "==", "'cls'", ":", "\n", "                ", "ce_loss", "=", "self", ".", "crit", "(", "scores", ",", "targets", ".", "squeeze", "(", "-", "1", ")", ")", "# (n, ) as no reduction", "\n", "return", "ce_loss", "\n", "", "else", ":", "\n", "# ranking", "\n", "                ", "_n", "=", "len", "(", "num_bbs", ")", "\n", "# positive (target)", "\n", "pos_ix", "=", "targets", "\n", "pos_sc", "=", "scores", ".", "gather", "(", "1", ",", "pos_ix", ".", "view", "(", "_n", ",", "1", ")", ")", "# (n, 1)", "\n", "pos_sc", "=", "torch", ".", "sigmoid", "(", "pos_sc", ")", ".", "view", "(", "-", "1", ")", "# (n, ) sc[0, 1]", "\n", "# negative", "\n", "neg_ix", "=", "self", ".", "sample_neg_ix", "(", "scores", ",", "targets", ",", "num_bbs", ")", "\n", "neg_sc", "=", "scores", ".", "gather", "(", "1", ",", "neg_ix", ".", "view", "(", "_n", ",", "1", ")", ")", "# (n, 1)", "\n", "neg_sc", "=", "torch", ".", "sigmoid", "(", "neg_sc", ")", ".", "view", "(", "-", "1", ")", "# (n, ) sc[0, 1]", "\n", "# ranking", "\n", "mm_loss", "=", "torch", ".", "clamp", "(", "\n", "self", ".", "margin", "+", "neg_sc", "-", "pos_sc", ",", "0", ")", "# (n, )", "\n", "return", "mm_loss", "\n", "", "", "else", ":", "\n", "# (n, max_num_bb)", "\n", "            ", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension.sample_neg_ix": [[94, 124], ["torch.argsort", "range", "torch.tensor().type", "len", "targets.type", "torch.tensor().type.numel", "targets.numel", "numpy.random.uniform", "cand_ixs[].tolist", "random.randint", "torch.tensor().type.append", "torch.tensor", "random.randint", "torch.tensor().type.append"], "methods", ["None"], ["", "", "def", "sample_neg_ix", "(", "self", ",", "scores", ",", "targets", ",", "num_bbs", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n        :scores    (n, max_num_bb)\n        :targets   (n, )\n        :num_bbs   list of [num_bb]\n        return:\n        :neg_ix    (n, ) easy/hard negative (!= target)\n        \"\"\"", "\n", "neg_ix", "=", "[", "]", "\n", "cand_ixs", "=", "torch", ".", "argsort", "(", "\n", "scores", ",", "dim", "=", "-", "1", ",", "descending", "=", "True", ")", "# (n, num_bb)", "\n", "for", "i", "in", "range", "(", "len", "(", "num_bbs", ")", ")", ":", "\n", "            ", "num_bb", "=", "num_bbs", "[", "i", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "1", ")", "<", "self", ".", "hard_ratio", ":", "\n", "# sample hard negative, w/ highest score", "\n", "                ", "for", "ix", "in", "cand_ixs", "[", "i", "]", ".", "tolist", "(", ")", ":", "\n", "                    ", "if", "ix", "!=", "targets", "[", "i", "]", ":", "\n", "                        ", "assert", "ix", "<", "num_bb", ",", "f'ix={ix}, num_bb={num_bb}'", "\n", "neg_ix", ".", "append", "(", "ix", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "# sample easy negative, i.e., random one", "\n", "                ", "ix", "=", "random", ".", "randint", "(", "0", ",", "num_bb", "-", "1", ")", "# [0, num_bb-1]", "\n", "while", "ix", "==", "targets", "[", "i", "]", ":", "\n", "                    ", "ix", "=", "random", ".", "randint", "(", "0", ",", "num_bb", "-", "1", ")", "\n", "", "neg_ix", ".", "append", "(", "ix", ")", "\n", "", "", "neg_ix", "=", "torch", ".", "tensor", "(", "neg_ix", ")", ".", "type", "(", "targets", ".", "type", "(", ")", ")", "\n", "assert", "neg_ix", ".", "numel", "(", ")", "==", "targets", ".", "numel", "(", ")", "\n", "return", "neg_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension._get_image_hidden": [[125, 150], ["max", "sequence_output.size", "zip", "torch.cat", "sequence_output.split", "outputs.append", "torch.cat", "re.UniterForReferringExpressionComprehension._get_pad"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension._get_pad"], ["", "def", "_get_image_hidden", "(", "self", ",", "sequence_output", ",", "txt_lens", ",", "num_bbs", ")", ":", "\n", "        ", "\"\"\"\n        Extracting the img_hidden part from sequence_output.\n        Inputs:\n        - sequence_output: (n, txt_len+num_bb, hid_size)\n        - txt_lens       : [txt_len]\n        - num_bbs        : [num_bb]\n        Output:\n        - img_hidden     : (n, max_num_bb, hid_size)\n        \"\"\"", "\n", "outputs", "=", "[", "]", "\n", "max_bb", "=", "max", "(", "num_bbs", ")", "\n", "hid_size", "=", "sequence_output", ".", "size", "(", "-", "1", ")", "\n", "for", "seq_out", ",", "len_", ",", "nbb", "in", "zip", "(", "sequence_output", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ",", "\n", "txt_lens", ",", "num_bbs", ")", ":", "\n", "            ", "img_hid", "=", "seq_out", "[", ":", ",", "len_", ":", "len_", "+", "nbb", ",", ":", "]", "\n", "if", "nbb", "<", "max_bb", ":", "\n", "                ", "img_hid", "=", "torch", ".", "cat", "(", "\n", "[", "img_hid", ",", "self", ".", "_get_pad", "(", "\n", "img_hid", ",", "max_bb", "-", "nbb", ",", "hid_size", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "", "outputs", ".", "append", "(", "img_hid", ")", "\n", "\n", "", "img_hidden", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "0", ")", "\n", "return", "img_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.re.UniterForReferringExpressionComprehension._get_pad": [[151, 154], ["torch.zeros"], "methods", ["None"], ["", "def", "_get_pad", "(", "self", ",", "t", ",", "len_", ",", "hidden_size", ")", ":", "\n", "        ", "pad", "=", "torch", ".", "zeros", "(", "1", ",", "len_", ",", "hidden_size", ",", "dtype", "=", "t", ".", "dtype", ",", "device", "=", "t", ".", "device", ")", "\n", "return", "pad", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.__init__": [[17, 24], ["model.UniterPreTrainedModel.__init__", "model.UniterModel", "torch.nn.Linear", "torch.nn.Linear", "itm.UniterForImageTextRetrieval.apply"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "margin", "=", "0.2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "itm_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "rank_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.init_output": [[25, 29], ["None"], "methods", ["None"], ["", "def", "init_output", "(", "self", ")", ":", "\n", "        ", "\"\"\" need to be called after from pretrained \"\"\"", "\n", "self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "itm_output", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "itm_output", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrieval.forward": [[30, 56], ["collections.defaultdict", "itm.UniterForImageTextRetrieval.uniter", "itm.UniterForImageTextRetrieval.uniter.pooler", "itm.UniterForImageTextRetrieval.rank_output", "torch.sigmoid", "torch.sigmoid.contiguous().view", "torch.clamp", "torch.sigmoid.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attention_mask", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "rank_scores", "=", "self", ".", "rank_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "# triplet loss", "\n", "            ", "rank_scores_sigmoid", "=", "torch", ".", "sigmoid", "(", "rank_scores", ")", "\n", "sample_size", "=", "batch", "[", "'sample_size'", "]", "\n", "scores", "=", "rank_scores_sigmoid", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "sample_size", ")", "\n", "pos", "=", "scores", "[", ":", ",", ":", "1", "]", "\n", "neg", "=", "scores", "[", ":", ",", "1", ":", "]", "\n", "rank_loss", "=", "torch", ".", "clamp", "(", "self", ".", "margin", "+", "neg", "-", "pos", ",", "0", ")", "\n", "return", "rank_loss", "\n", "", "else", ":", "\n", "            ", "return", "rank_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg.__init__": [[61, 64], ["itm.UniterForImageTextRetrieval.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "margin", "=", "0.2", ",", "hard_size", "=", "16", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ",", "margin", ")", "\n", "self", ".", "hard_size", "=", "hard_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg.forward": [[65, 91], ["batch[].size", "itm.UniterForImageTextRetrieval.forward", "itm.UniterForImageTextRetrieval.forward", "input_ids.size", "input_ids.expand", "ValueError", "torch.no_grad", "itm.UniterForImageTextRetrievalHardNeg.eval", "itm.UniterForImageTextRetrieval.forward", "itm.UniterForImageTextRetrievalHardNeg._get_hard_batch", "itm.UniterForImageTextRetrievalHardNeg.train", "img_feat.size", "img_feat.expand", "img_pos_feat.size", "img_pos_feat.expand"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg.forward", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg.forward", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg.forward", "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg._get_hard_batch"], ["", "def", "forward", "(", "self", ",", "batch", ",", "sample_from", "=", "'t'", ",", "compute_loss", "=", "True", ")", ":", "\n", "# expect same input_ids for all pairs", "\n", "        ", "batch_size", "=", "batch", "[", "'attn_masks'", "]", ".", "size", "(", "0", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "if", "sample_from", "==", "'t'", ":", "\n", "            ", "if", "input_ids", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'input_ids'", "]", "=", "input_ids", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "", "", "elif", "sample_from", "==", "'i'", ":", "\n", "            ", "if", "img_feat", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'img_feat'", "]", "=", "img_feat", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "-", "1", ")", "\n", "", "if", "img_pos_feat", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'img_pos_feat'", "]", "=", "img_pos_feat", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "-", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "compute_loss", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "eval", "(", ")", "\n", "scores", "=", "super", "(", ")", ".", "forward", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "hard_batch", "=", "self", ".", "_get_hard_batch", "(", "batch", ",", "scores", ",", "sample_from", ")", "\n", "self", ".", "train", "(", ")", "\n", "", "return", "super", "(", ")", ".", "forward", "(", "hard_batch", ",", "compute_loss", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "forward", "(", "batch", ",", "compute_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.model.itm.UniterForImageTextRetrievalHardNeg._get_hard_batch": [[92, 140], ["collections.defaultdict", "torch.cat", "attention_mask.index_select.index_select.index_select", "gather_index.index_select.index_select.index_select", "position_ids.size", "attention_mask.index_select.index_select.sum().max().item", "[].topk", "torch.zeros", "input_ids.index_select.index_select.size", "img_feat.index_select", "img_pos_feat.index_select", "input_ids.index_select.index_select.index_select", "ValueError", "attention_mask.index_select.index_select.sum().max", "scores.squeeze", "attention_mask.index_select.index_select.sum"], "methods", ["None"], ["", "", "def", "_get_hard_batch", "(", "self", ",", "batch", ",", "scores", ",", "sample_from", "=", "'t'", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "hard_batch", "=", "{", "'sample_size'", ":", "self", ".", "hard_size", "+", "1", "}", "\n", "\n", "# NOTE first example is positive", "\n", "hard_indices", "=", "scores", ".", "squeeze", "(", "-", "1", ")", "[", "1", ":", "]", ".", "topk", "(", "\n", "self", ".", "hard_size", ",", "sorted", "=", "False", ")", "[", "1", "]", "+", "1", "\n", "indices", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "hard_indices", ".", "device", ")", ",", "\n", "hard_indices", "]", ")", "\n", "\n", "attention_mask", "=", "attention_mask", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "gather_index", "=", "gather_index", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "if", "position_ids", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "            ", "position_ids", "=", "position_ids", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "\n", "", "if", "sample_from", "==", "'t'", ":", "\n", "# cut to minimum padding", "\n", "            ", "max_len", "=", "attention_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "max_i", "=", "max_len", "-", "input_ids", ".", "size", "(", "1", ")", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", ":", "max_len", "]", "\n", "gather_index", "=", "gather_index", "[", ":", ",", ":", "max_len", "]", "\n", "img_feat", "=", "img_feat", ".", "index_select", "(", "0", ",", "indices", ")", "[", ":", ",", ":", "max_i", ",", ":", "]", "\n", "img_pos_feat", "=", "img_pos_feat", ".", "index_select", "(", "0", ",", "indices", ")", "[", ":", ",", ":", "max_i", ",", ":", "]", "\n", "# expect same input_ids for all pairs", "\n", "input_ids", "=", "input_ids", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "", "elif", "sample_from", "==", "'i'", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "# expect same image features for all pairs", "\n", "img_feat", "=", "img_feat", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "img_pos_feat", "=", "img_pos_feat", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "", "hard_batch", "[", "'input_ids'", "]", "=", "input_ids", "\n", "hard_batch", "[", "'position_ids'", "]", "=", "position_ids", "\n", "hard_batch", "[", "'img_feat'", "]", "=", "img_feat", "\n", "hard_batch", "[", "'img_pos_feat'", "]", "=", "img_pos_feat", "\n", "hard_batch", "[", "'attn_masks'", "]", "=", "attention_mask", "\n", "hard_batch", "[", "'gather_index'", "]", "=", "gather_index", "\n", "\n", "return", "hard_batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir._compute_nbb": [[25, 29], ["max", "min", "int"], "function", ["None"], ["def", "_compute_nbb", "(", "img_dump", ",", "conf_th", ",", "max_bb", ",", "min_bb", ",", "num_bb", ")", ":", "\n", "    ", "num_bb", "=", "max", "(", "min_bb", ",", "(", "img_dump", "[", "'conf'", "]", ">", "conf_th", ")", ".", "sum", "(", ")", ")", "\n", "num_bb", "=", "min", "(", "max_bb", ",", "num_bb", ")", "\n", "return", "int", "(", "num_bb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.load_npz": [[31, 57], ["os.path.basename", "numpy.load", "np.load.items", "convert_imgdir._compute_nbb", "print", "arr.astype.astype", "ValueError"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb._compute_nbb"], ["", "@", "curry", "\n", "def", "load_npz", "(", "conf_th", ",", "max_bb", ",", "min_bb", ",", "num_bb", ",", "fname", ",", "keep_all", "=", "False", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "img_dump", "=", "np", ".", "load", "(", "fname", ",", "allow_pickle", "=", "True", ")", "\n", "if", "keep_all", ":", "\n", "            ", "nbb", "=", "None", "\n", "", "else", ":", "\n", "            ", "nbb", "=", "_compute_nbb", "(", "img_dump", ",", "conf_th", ",", "max_bb", ",", "min_bb", ",", "num_bb", ")", "\n", "", "dump", "=", "{", "}", "\n", "for", "key", ",", "arr", "in", "img_dump", ".", "items", "(", ")", ":", "\n", "            ", "if", "arr", ".", "dtype", "==", "np", ".", "float32", ":", "\n", "                ", "arr", "=", "arr", ".", "astype", "(", "np", ".", "float16", ")", "\n", "", "if", "arr", ".", "ndim", "==", "2", ":", "\n", "                ", "dump", "[", "key", "]", "=", "arr", "[", ":", "nbb", ",", ":", "]", "\n", "", "elif", "arr", ".", "ndim", "==", "1", ":", "\n", "                ", "dump", "[", "key", "]", "=", "arr", "[", ":", "nbb", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'wrong ndim'", ")", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "# corrupted file", "\n", "        ", "print", "(", "f'corrupted file {fname}'", ",", "e", ")", "\n", "dump", "=", "{", "}", "\n", "nbb", "=", "0", "\n", "\n", "", "name", "=", "basename", "(", "fname", ")", "\n", "return", "name", ",", "dump", ",", "nbb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.dumps_npz": [[59, 66], ["io.BytesIO", "writer.getvalue", "numpy.savez_compressed", "numpy.savez"], "function", ["None"], ["", "def", "dumps_npz", "(", "dump", ",", "compress", "=", "False", ")", ":", "\n", "    ", "with", "io", ".", "BytesIO", "(", ")", "as", "writer", ":", "\n", "        ", "if", "compress", ":", "\n", "            ", "np", ".", "savez_compressed", "(", "writer", ",", "**", "dump", ",", "allow_pickle", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "np", ".", "savez", "(", "writer", ",", "**", "dump", ",", "allow_pickle", "=", "True", ")", "\n", "", "return", "writer", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.dumps_msgpack": [[68, 70], ["msgpack.dumps"], "function", ["None"], ["", "", "def", "dumps_msgpack", "(", "dump", ")", ":", "\n", "    ", "return", "msgpack", ".", "dumps", "(", "dump", ",", "use_bin_type", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.main": [[72, 118], ["os.path.basename", "lmdb.open", "lmdb.open.begin", "glob.glob", "convert_imgdir.load_npz", "os.path.exists", "os.makedirs", "multiprocessing.Pool", "tqdm.tqdm", "enumerate", "env.begin.put", "env.begin.commit", "lmdb.open.close", "pool.imap_unordered", "env.begin.put", "pbar.update", "open", "json.dump", "len", "convert_imgdir.dumps_npz", "convert_imgdir.dumps_msgpack", "env.begin.commit", "lmdb.open.begin", "json.dumps().encode", "fname.encode", "json.dumps", "list", "name2nbb.keys"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.load_npz", "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.dumps_npz", "home.repos.pwc.inspect_result.ChenRocks_UNITER.scripts.convert_imgdir.dumps_msgpack"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "if", "opts", ".", "img_dir", "[", "-", "1", "]", "==", "'/'", ":", "\n", "        ", "opts", ".", "img_dir", "=", "opts", ".", "img_dir", "[", ":", "-", "1", "]", "\n", "", "split", "=", "basename", "(", "opts", ".", "img_dir", ")", "\n", "if", "opts", ".", "keep_all", ":", "\n", "        ", "db_name", "=", "'all'", "\n", "", "else", ":", "\n", "        ", "if", "opts", ".", "conf_th", "==", "-", "1", ":", "\n", "            ", "db_name", "=", "f'feat_numbb{opts.num_bb}'", "\n", "", "else", ":", "\n", "            ", "db_name", "=", "(", "f'feat_th{opts.conf_th}_max{opts.max_bb}'", "\n", "f'_min{opts.min_bb}'", ")", "\n", "", "", "if", "opts", ".", "compress", ":", "\n", "        ", "db_name", "+=", "'_compressed'", "\n", "", "if", "not", "exists", "(", "f'{opts.output}/{split}'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "f'{opts.output}/{split}'", ")", "\n", "", "env", "=", "lmdb", ".", "open", "(", "f'{opts.output}/{split}/{db_name}'", ",", "map_size", "=", "1024", "**", "4", ")", "\n", "txn", "=", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "files", "=", "glob", ".", "glob", "(", "f'{opts.img_dir}/*.npz'", ")", "\n", "load", "=", "load_npz", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "opts", ".", "num_bb", ",", "\n", "keep_all", "=", "opts", ".", "keep_all", ")", "\n", "name2nbb", "=", "{", "}", "\n", "with", "mp", ".", "Pool", "(", "opts", ".", "nproc", ")", "as", "pool", ",", "tqdm", "(", "total", "=", "len", "(", "files", ")", ")", "as", "pbar", ":", "\n", "        ", "for", "i", ",", "(", "fname", ",", "features", ",", "nbb", ")", "in", "enumerate", "(", "\n", "pool", ".", "imap_unordered", "(", "load", ",", "files", ",", "chunksize", "=", "128", ")", ")", ":", "\n", "            ", "if", "not", "features", ":", "\n", "                ", "continue", "# corrupted feature", "\n", "", "if", "opts", ".", "compress", ":", "\n", "                ", "dump", "=", "dumps_npz", "(", "features", ",", "compress", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "dump", "=", "dumps_msgpack", "(", "features", ")", "\n", "", "txn", ".", "put", "(", "key", "=", "fname", ".", "encode", "(", "'utf-8'", ")", ",", "value", "=", "dump", ")", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "txn", ".", "commit", "(", ")", "\n", "txn", "=", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "", "name2nbb", "[", "fname", "]", "=", "nbb", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "txn", ".", "put", "(", "key", "=", "b'__keys__'", ",", "\n", "value", "=", "json", ".", "dumps", "(", "list", "(", "name2nbb", ".", "keys", "(", ")", ")", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "txn", ".", "commit", "(", ")", "\n", "env", ".", "close", "(", ")", "\n", "", "if", "opts", ".", "conf_th", "!=", "-", "1", "and", "not", "opts", ".", "keep_all", ":", "\n", "        ", "with", "open", "(", "f'{opts.output}/{split}/'", "\n", "f'nbb_th{opts.conf_th}_'", "\n", "f'max{opts.max_bb}_min{opts.min_bb}.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "name2nbb", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset.__init__": [[13, 15], ["vcr.VcrDetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["\n", "import", "torch", "\n", "from", "torch", ".", "utils", ".", "data", "import", "DataLoader", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset._get_input_ids": [[16, 63], ["len", "mlm.random_word", "len", "mlm.random_word", "len", "mlm.random_word"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.random_word", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.random_word", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.random_word"], ["from", "torch", ".", "nn", "import", "functional", "as", "F", "\n", "from", "torch", ".", "nn", ".", "utils", "import", "clip_grad_norm_", "\n", "\n", "from", "apex", "import", "amp", "\n", "from", "horovod", "import", "torch", "as", "hvd", "\n", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "data", "import", "(", "TokenBucketSampler", ",", "\n", "MetaLoader", ",", "PrefetchLoader", ",", "DetectFeatLmdb", ",", "\n", "VcrTxtTokLmdb", ",", "ImageLmdbGroup", ",", "ConcatDatasetWithLens", ",", "\n", "MlmDatasetForVCR", ",", "mlm_collate_for_vcr", ",", "\n", "MrfrDatasetForVCR", ",", "mrfr_collate_for_vcr", ",", "\n", "MrcDatasetForVCR", ",", "mrc_collate_for_vcr", ")", "\n", "\n", "from", "model", ".", "pretrain_vcr", "import", "UniterForPretrainingForVCR", "\n", "from", "optim", "import", "get_lr_sched", "\n", "from", "optim", ".", "misc", "import", "build_optimizer", "\n", "\n", "from", "utils", ".", "logger", "import", "LOGGER", ",", "TB_LOGGER", ",", "RunningMeter", ",", "add_log_to_file", "\n", "from", "utils", ".", "distributed", "import", "(", "all_reduce_and_rescale_tensors", ",", "all_gather_list", ",", "\n", "broadcast_tensors", ")", "\n", "from", "utils", ".", "save", "import", "ModelSaver", ",", "save_training_meta", "\n", "from", "utils", ".", "misc", "import", "NoOp", ",", "parse_with_config", ",", "set_dropout", ",", "set_random_seed", "\n", "from", "utils", ".", "const", "import", "IMG_DIM", ",", "IMG_LABEL_DIM", ",", "BUCKET_SIZE", "\n", "NUM_SPECIAL_TOKENS", "=", "81", "\n", "\n", "\n", "def", "build_dataloader", "(", "dataset", ",", "collate_fn", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "batch_size", "=", "opts", ".", "train_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "opts", ".", "val_batch_size", "\n", "", "sampler", "=", "TokenBucketSampler", "(", "dataset", ".", "lens", ",", "bucket_size", "=", "BUCKET_SIZE", ",", "\n", "batch_size", "=", "batch_size", ",", "droplast", "=", "is_train", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "opts", ".", "n_workers", ",", "pin_memory", "=", "opts", ".", "pin_mem", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "loader", "\n", "\n", "\n", "", "def", "build_mlm_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "datasets", "=", "[", "MlmDatasetForVCR", "(", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset.combine_txt_inputs": [[64, 76], ["torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["        ", "collate_fn", "=", "mlm_collate_for_vcr", "\n", "dataset", "=", "MlmDatasetForVCR", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "collate_fn", "\n", "\n", "\n", "", "def", "build_mrfr_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrfrDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MlmDatasetForVCR.__init__": [[112, 114], ["pretrain_vcr.VcrPretrainDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["\n", "", "def", "create_dataloaders", "(", "datasets", ",", "is_train", ",", "opts", ",", "all_img_dbs", "=", "None", ")", ":", "\n", "    ", "if", "all_img_dbs", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MlmDatasetForVCR.create_mlm_io": [[115, 120], ["pretrain_vcr.MlmDatasetForVCR._get_input_ids", "pretrain_vcr.MlmDatasetForVCR.combine_txt_inputs"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset.combine_txt_inputs"], ["        ", "all_img_dbs", "=", "ImageLmdbGroup", "(", "opts", ".", "conf_th", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "\n", "opts", ".", "num_bb", ",", "opts", ".", "compressed_db", ")", "\n", "", "dataloaders", "=", "{", "}", "\n", "\n", "for", "dset", "in", "datasets", ":", "\n", "        ", "for", "vcr_task", "in", "[", "\"qa\"", ",", "\"qar\"", "]", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MlmDatasetForVCR.__getitem__": [[121, 135], ["vcr.VcrDetectFeatTxtTokDataset.__getitem__", "pretrain_vcr.MlmDatasetForVCR._get_img_feat", "pretrain_vcr.MlmDatasetForVCR.create_mlm_io", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.MlmDataset.create_mlm_io"], ["            ", "if", "is_train", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "\n", "assert", "len", "(", "dset", "[", "'tasks'", "]", ")", "==", "len", "(", "dset", "[", "'mix_ratio'", "]", ")", "\n", "img_db", ",", "img_db_gt", "=", "[", "]", ",", "[", "]", "\n", "for", "img_path", "in", "dset", "[", "'img'", "]", ":", "\n", "                    ", "curr_img_db", ",", "curr_img_db_gt", "=", "load_img_feat", "(", "\n", "img_path", ",", "all_img_dbs", ",", "opts", ")", "\n", "img_db", ".", "append", "(", "curr_img_db", ")", "\n", "img_db_gt", ".", "append", "(", "curr_img_db_gt", ")", "\n", "", "", "else", ":", "\n", "                ", "assert", "len", "(", "dset", "[", "'db'", "]", ")", "==", "len", "(", "dset", "[", "'img'", "]", ")", "==", "1", "\n", "img_db", ",", "img_db_gt", "=", "load_img_feat", "(", "\n", "dset", "[", "'img'", "]", "[", "0", "]", ",", "all_img_dbs", ",", "opts", ")", "\n", "\n", "", "for", "i", ",", "t", "in", "enumerate", "(", "dset", "[", "'tasks'", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrfrDatasetForVCR.__init__": [[151, 154], ["pretrain_vcr.VcrPretrainDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["txt_db", "=", "VcrTxtTokLmdb", "(", "dset", "[", "'db'", "]", "[", "0", "]", ",", "-", "1", ",", "\n", "task", "=", "vcr_task", ")", "\n", "\n", "", "if", "task", ".", "startswith", "(", "'mlm'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrfrDatasetForVCR.__getitem__": [[155, 172], ["vcr.VcrDetectFeatTxtTokDataset.__getitem__", "pretrain_vcr.MrfrDatasetForVCR._get_input_ids", "pretrain_vcr.MrfrDatasetForVCR.combine_txt_inputs", "pretrain_vcr.MrfrDatasetForVCR._get_img_feat", "mrm._get_img_mask", "mrm._get_img_tgt_mask", "torch.ones", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset.combine_txt_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_mask", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_tgt_mask"], ["                    ", "dataset", "=", "build_mlm_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrfr'", ")", ":", "\n", "                    ", "dataset", "=", "build_mrfr_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "elif", "task", ".", "startswith", "(", "'mrc'", ")", ":", "\n", "                    ", "dataset", "=", "build_mrc_dataset", "(", "\n", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f'Undefined task {task}'", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "f\"{len(dataset[0])*hvd.size()} samples loaded\"", ")", "\n", "loader", "=", "build_dataloader", "(", "*", "dataset", ",", "is_train", ",", "opts", ")", "\n", "if", "is_train", ":", "\n", "                    ", "ratio", "=", "dset", "[", "'mix_ratio'", "]", "[", "i", "]", "\n", "dataloaders", "[", "task", "]", "=", "(", "loader", ",", "ratio", ")", "\n", "", "else", ":", "\n", "                    ", "dataloaders", "[", "task", "]", "=", "PrefetchLoader", "(", "loader", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR.__init__": [[196, 199], ["pretrain_vcr.VcrPretrainDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["TB_LOGGER", ".", "create", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "opts", ".", "num_train_steps", ")", "\n", "model_saver", "=", "ModelSaver", "(", "join", "(", "args", ".", "output_dir", ",", "'ckpt'", ")", ")", "\n", "add_log_to_file", "(", "join", "(", "opts", ".", "output_dir", ",", "'log'", ",", "'log.txt'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db": [[200, 207], ["img_db.get_dump", "torch.tensor", "torch.tensor", "torch.cat", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.get_dump"], ["", "else", ":", "\n", "        ", "LOGGER", ".", "disabled", "=", "True", "\n", "pbar", "=", "NoOp", "(", ")", "\n", "model_saver", "=", "NoOp", "(", ")", "\n", "\n", "", "all_dbs", "=", "[", "db", "for", "datasets", "in", "[", "opts", ".", "train_datasets", ",", "opts", ".", "val_datasets", "]", "\n", "for", "dset", "in", "datasets", "for", "db", "in", "dset", "[", "'db'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat": [[208, 232], ["torch.cat.size", "pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "torch.cat", "torch.cat", "torch.cat", "pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR._get_img_feat_for_db"], ["tokenizer", "=", "json", ".", "load", "(", "open", "(", "f'{all_dbs[0]}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "assert", "all", "(", "tokenizer", "==", "json", ".", "load", "(", "open", "(", "f'{db}/meta.json'", ")", ")", "[", "'bert'", "]", "\n", "for", "db", "in", "all_dbs", ")", "\n", "\n", "# build data loaders", "\n", "train_dataloaders", ",", "all_img_dbs", "=", "create_dataloaders", "(", "\n", "opts", ".", "train_datasets", ",", "True", ",", "opts", ")", "\n", "val_dataloaders", ",", "_", "=", "create_dataloaders", "(", "\n", "opts", ".", "val_datasets", ",", "False", ",", "opts", ",", "all_img_dbs", ")", "\n", "meta_loader", "=", "MetaLoader", "(", "train_dataloaders", ",", "\n", "accum_steps", "=", "opts", ".", "gradient_accumulation_steps", ",", "\n", "distributed", "=", "n_gpu", ">", "1", ")", "\n", "meta_loader", "=", "PrefetchLoader", "(", "meta_loader", ")", "\n", "\n", "# Prepare model", "\n", "if", "opts", ".", "checkpoint", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "opts", ".", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "{", "}", "\n", "", "model", "=", "UniterForPretrainingForVCR", ".", "from_pretrained", "(", "\n", "opts", ".", "model_config", ",", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "img_label_dim", "=", "IMG_LABEL_DIM", ")", "\n", "model", ".", "init_type_embedding", "(", ")", "\n", "model", ".", "init_word_embedding", "(", "NUM_SPECIAL_TOKENS", ")", "\n", "model", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.MrcDatasetForVCR.__getitem__": [[233, 251], ["vcr.VcrDetectFeatTxtTokDataset.__getitem__", "pretrain_vcr.MrcDatasetForVCR._get_input_ids", "pretrain_vcr.MrcDatasetForVCR.combine_txt_inputs", "pretrain_vcr.MrcDatasetForVCR._get_img_feat", "mrm._get_img_mask", "mrm._get_img_tgt_mask", "torch.ones", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.VcrPretrainDataset.combine_txt_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_mask", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_tgt_mask"], ["model", ".", "train", "(", ")", "\n", "# make sure every process has same model parameters in the beginning", "\n", "broadcast_tensors", "(", "[", "p", ".", "data", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "set_dropout", "(", "model", ",", "opts", ".", "dropout", ")", "\n", "\n", "# Prepare optimizer", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "opts", ")", "\n", "task2scaler", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "train_dataloaders", ".", "keys", "(", ")", ")", "}", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "num_losses", "=", "len", "(", "task2scaler", ")", ",", "\n", "enabled", "=", "opts", ".", "fp16", ",", "opt_level", "=", "'O2'", ")", "\n", "\n", "global_step", "=", "0", "\n", "LOGGER", ".", "info", "(", "f\"***** Running training with {n_gpu} GPUs *****\"", ")", "\n", "LOGGER", ".", "info", "(", "\"  Batch size = %d\"", ",", "opts", ".", "train_batch_size", ")", "\n", "LOGGER", ".", "info", "(", "\"  Accumulate steps = %d\"", ",", "opts", ".", "gradient_accumulation_steps", ")", "\n", "LOGGER", ".", "info", "(", "\"  Num steps = %d\"", ",", "opts", ".", "num_train_steps", ")", "\n", "\n", "# to compute training statistics", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.vcr_pretrain_collate": [[78, 109], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["", "return", "dataset", ",", "mrfr_collate_for_vcr", "\n", "\n", "\n", "", "def", "build_mrc_dataset", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ",", "is_train", ",", "opts", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "        ", "datasets", "=", "[", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "t", ",", "i_gt", ",", "i", ")", "\n", "for", "t", ",", "i_gt", ",", "i", "in", "zip", "(", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "]", "\n", "dataset", "=", "ConcatDatasetWithLens", "(", "datasets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "MrcDatasetForVCR", "(", "opts", ".", "mrm_prob", ",", "txt_db", ",", "img_db_gt", ",", "img_db", ")", "\n", "\n", "", "return", "dataset", ",", "mrc_collate_for_vcr", "\n", "\n", "\n", "", "def", "load_img_feat", "(", "db_list", ",", "all_img_dbs", ",", "opts", ")", ":", "\n", "    ", "db_", "=", "db_list", ".", "split", "(", "\";\"", ")", "\n", "assert", "len", "(", "db_", ")", "<=", "2", ",", "\"More than two img_dbs found\"", "\n", "gt_db_path", ",", "db_path", "=", "\"\"", ",", "\"\"", "\n", "for", "d", "in", "db_", ":", "\n", "        ", "if", "\"gt\"", "in", "d", ":", "\n", "            ", "gt_db_path", "=", "d", "\n", "", "else", ":", "\n", "            ", "db_path", "=", "d", "\n", "", "", "if", "gt_db_path", "!=", "\"\"", ":", "\n", "        ", "img_db_gt", "=", "DetectFeatLmdb", "(", "\n", "gt_db_path", ",", "-", "1", ",", "opts", ".", "max_bb", ",", "opts", ".", "min_bb", ",", "100", ",", "\n", "opts", ".", "compressed_db", ")", "\n", "all_img_dbs", ".", "path2imgdb", "[", "gt_db_path", "]", "=", "img_db_gt", "\n", "", "else", ":", "\n", "        ", "img_db_gt", "=", "None", "\n", "", "img_db", "=", "all_img_dbs", "[", "db_path", "]", "if", "db_path", "!=", "\"\"", "else", "None", "\n", "all_img_dbs", ".", "path2imgdb", "[", "db_path", "]", "=", "img_db", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.mlm_collate_for_vcr": [[137, 148], ["map", "pretrain_vcr.vcr_pretrain_collate", "torch.nn.utils.rnn.pad_sequence", "toolz.sandbox.unzip"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.vcr_pretrain_collate"], ["\n", "if", "is_train", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} train dataset with vcr_{vcr_task}, \"", "\n", "f\"{dset['db']}, {[img.img_dir for img in img_db]},\"", "\n", "f\"{[img.img_dir for img in img_db_gt]}\"", ")", "\n", "txt_db", "=", "[", "VcrTxtTokLmdb", "(", "path", ",", "opts", ".", "max_txt_len", ",", "\n", "task", "=", "vcr_task", ")", "\n", "for", "path", "in", "dset", "[", "'db'", "]", "]", "\n", "", "else", ":", "\n", "                    ", "LOGGER", ".", "info", "(", "\n", "f\"Loading {task} val dataset with vcr_{vcr_task}, \"", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.mrfr_collate_for_vcr": [[174, 193], ["map", "pretrain_vcr.vcr_pretrain_collate", "torch.nn.utils.rnn.pad_sequence", "mrm._get_feat_target", "torch.nn.utils.rnn.pad_sequence", "mrm._mask_img_feat", "toolz.sandbox.unzip"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.vcr_pretrain_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_feat_target", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._mask_img_feat"], ["\n", "\n", "", "def", "main", "(", "opts", ")", ":", "\n", "    ", "hvd", ".", "init", "(", ")", "\n", "n_gpu", "=", "hvd", ".", "size", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "hvd", ".", "local_rank", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "opts", ".", "rank", "=", "rank", "\n", "LOGGER", ".", "info", "(", "\"device: {} n_gpu: {}, rank: {}, \"", "\n", "\"16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "hvd", ".", "rank", "(", ")", ",", "opts", ".", "fp16", ")", ")", "\n", "\n", "if", "opts", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, \"", "\n", "\"should be >= 1\"", ".", "format", "(", "\n", "opts", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "set_random_seed", "(", "opts", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.mrc_collate_for_vcr": [[253, 274], ["map", "pretrain_vcr.vcr_pretrain_collate", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "mrm._get_targets", "torch.nn.utils.rnn.pad_sequence", "mrm._mask_img_feat", "toolz.sandbox.unzip", "f.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.pretrain_vcr.vcr_pretrain_collate", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_targets", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._mask_img_feat"], ["for", "task", "in", "train_dataloaders", ".", "keys", "(", ")", "}", "\n", "\n", "n_examples", "=", "defaultdict", "(", "int", ")", "\n", "n_in_units", "=", "defaultdict", "(", "int", ")", "\n", "n_loss_units", "=", "defaultdict", "(", "int", ")", "\n", "grad_norm", "=", "0", "\n", "\n", "start", "=", "time", "(", ")", "\n", "# quick hack for amp delay_unscale bug", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "for", "step", ",", "(", "name", ",", "batch", ")", "in", "enumerate", "(", "meta_loader", ")", ":", "\n", "# forward pass", "\n", "        ", "n_examples", "[", "name", "]", "+=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "n_in_units", "[", "name", "]", "+=", "(", "batch", "[", "'attn_masks'", "]", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "task", "=", "name", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "loss", "=", "model", "(", "batch", ",", "task", "=", "task", ",", "compute_loss", "=", "True", ")", "\n", "n_loss_units", "[", "name", "]", "+=", "loss", ".", "size", "(", "0", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "# loss is not normalized in model", "\n", "\n", "# backward pass", "\n", "delay_unscale", "=", "(", "step", "+", "1", ")", "%", "opts", ".", "gradient_accumulation_steps", "!=", "0", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.ve.VeDataset.__init__": [[12, 14], ["vqa.VqaDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ",", "3", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.ve.VeEvalDataset.__init__": [[17, 19], ["vqa.VqaEvalDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2PairedDataset.__init__": [[19, 32], ["isinstance", "isinstance", "data.get_ids_and_lens", "sum", "zip"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens"], ["\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2PairedDataset.__getitem__": [[33, 59], ["data.DetectFeatTxtTokDataset.__getitem__", "enumerate", "nlvr2.Nlvr2PairedDataset._get_img_feat", "copy.deepcopy", "torch.tensor", "torch.tensor", "outs.append", "tuple", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat"], ["", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "img_type_ids", "=", "img_type_ids", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "# concat CLS of the pair", "\n", "n_pair", "=", "pooled_output", ".", "size", "(", "0", ")", "//", "2", "\n", "reshaped_output", "=", "pooled_output", ".", "contiguous", "(", ")", ".", "view", "(", "n_pair", ",", "-", "1", ")", "\n", "answer_scores", "=", "self", ".", "nlvr2_output", "(", "reshaped_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2PairedEvalDataset.__getitem__": [[99, 103], ["nlvr2.Nlvr2PairedDataset.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__"], ["answer_scores", "=", "self", ".", "nlvr2_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2TripletDataset.__init__": [[116, 129], ["isinstance", "isinstance", "data.get_ids_and_lens", "sum", "zip"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens"], ["\n", "", "def", "forward", "(", "self", ",", "input_", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"input: [B, T, D], mask = [B, T]\"\"\"", "\n", "score", "=", "self", ".", "fc", "(", "input_", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "to", "(", "dtype", "=", "input_", ".", "dtype", ")", "*", "-", "1e4", "\n", "score", "=", "score", "+", "mask", "\n", "", "norm_score", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "score", ",", "dim", "=", "1", ")", ")", "\n", "output", "=", "norm_score", ".", "unsqueeze", "(", "1", ")", ".", "matmul", "(", "input_", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "output", "\n", "\n", "\n", "", "", "class", "UniterForNlvr2PairedAttn", "(", "UniterPreTrainedModel", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2TripletDataset.__getitem__": [[130, 165], ["data.DetectFeatTxtTokDataset.__getitem__", "enumerate", "torch.cat", "torch.cat", "copy.deepcopy", "torch.tensor", "torch.tensor", "nlvr2.Nlvr2TripletDataset._get_img_feat", "img_feats.append", "img_pos_feats.append", "torch.tensor", "torch.tensor.extend", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat"], ["\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "attn1", "=", "MultiheadAttention", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "num_attention_heads", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "attn2", "=", "MultiheadAttention", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "num_attention_heads", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ")", "\n", "self", ".", "attn_pool", "=", "AttentionPool", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "2", "*", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.Nlvr2TripletEvalDataset.__getitem__": [[205, 209], ["nlvr2.Nlvr2TripletDataset.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__"], ["", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_paired_collate": [[61, 96], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.Tensor().long", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.nn.utils.rnn.pad_sequence", "cytoolz.concat", "torch.arange", "torch.Tensor", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "\n", "\n", "", "", "", "class", "UniterForNlvr2Triplet", "(", "UniterPreTrainedModel", ")", ":", "\n", "    ", "\"\"\" Finetune UNITER for NLVR2 (triplet format)\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "nlvr2_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_paired_eval_collate": [[105, 113], ["nlvr2.nlvr2_paired_collate", "qids.append", "nlvr2_paired_collate.append"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_paired_collate"], ["return", "nlvr2_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "\n", "\n", "", "", "", "class", "AttentionPool", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\" attention pooling layer \"\"\"", "\n", "def", "__init__", "(", "self", ",", "hidden_size", ",", "drop", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_triplet_collate": [[167, 202], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.Tensor().long", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.nn.utils.rnn.pad_sequence", "torch.arange", "torch.Tensor", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "img_type_ids", "=", "batch", "[", "'img_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "img_type_ids", "=", "img_type_ids", ")", "\n", "# separate left image and right image", "\n", "bs", ",", "tl", ",", "d", "=", "sequence_output", ".", "size", "(", ")", "\n", "left_out", ",", "right_out", "=", "sequence_output", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "bs", "//", "2", ",", "tl", "*", "2", ",", "d", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "# bidirectional attention", "\n", "mask", "=", "attn_masks", "==", "0", "\n", "left_mask", ",", "right_mask", "=", "mask", ".", "contiguous", "(", ")", ".", "view", "(", "bs", "//", "2", ",", "tl", "*", "2", "\n", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "left_out", "=", "left_out", ".", "transpose", "(", "0", ",", "1", ")", "\n", "right_out", "=", "right_out", ".", "transpose", "(", "0", ",", "1", ")", "\n", "l2r_attn", ",", "_", "=", "self", ".", "attn1", "(", "left_out", ",", "right_out", ",", "right_out", ",", "\n", "key_padding_mask", "=", "right_mask", ")", "\n", "r2l_attn", ",", "_", "=", "self", ".", "attn2", "(", "right_out", ",", "left_out", ",", "left_out", ",", "\n", "key_padding_mask", "=", "left_mask", ")", "\n", "left_out", "=", "self", ".", "fc", "(", "torch", ".", "cat", "(", "[", "l2r_attn", ",", "left_out", "]", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "right_out", "=", "self", ".", "fc", "(", "torch", ".", "cat", "(", "[", "r2l_attn", ",", "right_out", "]", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# attention pooling and final prediction", "\n", "left_out", "=", "self", ".", "attn_pool", "(", "left_out", ",", "left_mask", ")", "\n", "right_out", "=", "self", ".", "attn_pool", "(", "right_out", ",", "right_mask", ")", "\n", "answer_scores", "=", "self", ".", "nlvr2_output", "(", "\n", "torch", ".", "cat", "(", "[", "left_out", ",", "right_out", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "nlvr2_loss", "=", "F", ".", "cross_entropy", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "nlvr2_loss", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_triplet_eval_collate": [[211, 219], ["nlvr2.nlvr2_triplet_collate", "qids.append", "nlvr2_triplet_collate.append"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.nlvr2.nlvr2_triplet_collate"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.MrfrDataset.__init__": [[45, 48], ["data.DetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_prob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "mask_prob", "=", "mask_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.MrfrDataset.__getitem__": [[49, 73], ["data.DetectFeatTxtTokDataset.__getitem__", "mrm.MrfrDataset.txt_db.combine_inputs", "mrm.MrfrDataset._get_img_feat", "mrm._get_img_mask", "mrm._get_img_tgt_mask", "torch.ones", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_mask", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_tgt_mask"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"\n        Return:\n        - input_ids    : (L, ), i.e., [cls, wd, wd, ..., sep, 0, 0], 0s padded\n        - img_feat     : (num_bb, d)\n        - img_pos_feat : (num_bb, 7)\n        - attn_masks   : (L + num_bb, ), ie., [1, 1, ..., 0, 0, 1, 1]\n        - img_mask     : (num_bb, ) between {0, 1}\n        \"\"\"", "\n", "example", "=", "super", "(", ")", ".", "__getitem__", "(", "i", ")", "\n", "# text input", "\n", "input_ids", "=", "example", "[", "'input_ids'", "]", "\n", "input_ids", "=", "self", ".", "txt_db", ".", "combine_inputs", "(", "input_ids", ")", "\n", "\n", "# image input features", "\n", "img_feat", ",", "img_pos_feat", ",", "num_bb", "=", "self", ".", "_get_img_feat", "(", "\n", "example", "[", "'img_fname'", "]", ")", "\n", "img_mask", "=", "_get_img_mask", "(", "self", ".", "mask_prob", ",", "num_bb", ")", "\n", "img_mask_tgt", "=", "_get_img_tgt_mask", "(", "img_mask", ",", "len", "(", "input_ids", ")", ")", "\n", "\n", "attn_masks", "=", "torch", ".", "ones", "(", "len", "(", "input_ids", ")", "+", "num_bb", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "(", "input_ids", ",", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "img_mask", ",", "img_mask_tgt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.MrcDataset.__init__": [[133, 136], ["data.DetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_prob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "mask_prob", "=", "mask_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.MrcDataset._get_img_feat": [[137, 145], ["mrm.MrcDataset.img_db.get_dump", "torch.tensor", "torch.tensor", "torch.cat", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.get_dump"], ["", "def", "_get_img_feat", "(", "self", ",", "fname", ")", ":", "\n", "        ", "img_dump", "=", "self", ".", "img_db", ".", "get_dump", "(", "fname", ")", "\n", "num_bb", "=", "self", ".", "img_db", ".", "name2nbb", "[", "fname", "]", "\n", "img_feat", "=", "torch", ".", "tensor", "(", "img_dump", "[", "'features'", "]", ")", "\n", "bb", "=", "torch", ".", "tensor", "(", "img_dump", "[", "'norm_bb'", "]", ")", "\n", "img_bb", "=", "torch", ".", "cat", "(", "[", "bb", ",", "bb", "[", ":", ",", "4", ":", "5", "]", "*", "bb", "[", ":", ",", "5", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "img_soft_label", "=", "torch", ".", "tensor", "(", "img_dump", "[", "'soft_labels'", "]", ")", "\n", "return", "img_feat", ",", "img_bb", ",", "img_soft_label", ",", "num_bb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.MrcDataset.__getitem__": [[146, 163], ["data.DetectFeatTxtTokDataset.__getitem__", "mrm.MrcDataset._get_img_feat", "mrm._get_img_mask", "mrm.MrcDataset.txt_db.combine_inputs", "mrm._get_img_tgt_mask", "torch.ones", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_mask", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_tgt_mask"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "example", "=", "super", "(", ")", ".", "__getitem__", "(", "i", ")", "\n", "img_feat", ",", "img_pos_feat", ",", "img_soft_labels", ",", "num_bb", "=", "self", ".", "_get_img_feat", "(", "\n", "example", "[", "'img_fname'", "]", ")", "\n", "\n", "# image input features", "\n", "img_mask", "=", "_get_img_mask", "(", "self", ".", "mask_prob", ",", "num_bb", ")", "\n", "\n", "# text input", "\n", "input_ids", "=", "example", "[", "'input_ids'", "]", "\n", "input_ids", "=", "self", ".", "txt_db", ".", "combine_inputs", "(", "input_ids", ")", "\n", "img_mask_tgt", "=", "_get_img_tgt_mask", "(", "img_mask", ",", "len", "(", "input_ids", ")", ")", "\n", "\n", "attn_masks", "=", "torch", ".", "ones", "(", "len", "(", "input_ids", ")", "+", "num_bb", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "(", "input_ids", ",", "img_feat", ",", "img_pos_feat", ",", "\n", "img_soft_labels", ",", "attn_masks", ",", "img_mask", ",", "img_mask_tgt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_mask": [[15, 22], ["torch.tensor", "any", "random.random", "range", "random.choice", "range"], "function", ["None"], ["def", "_get_img_mask", "(", "mask_prob", ",", "num_bb", ")", ":", "\n", "    ", "img_mask", "=", "[", "random", ".", "random", "(", ")", "<", "mask_prob", "for", "_", "in", "range", "(", "num_bb", ")", "]", "\n", "if", "not", "any", "(", "img_mask", ")", ":", "\n", "# at least mask 1", "\n", "        ", "img_mask", "[", "random", ".", "choice", "(", "range", "(", "num_bb", ")", ")", "]", "=", "True", "\n", "", "img_mask", "=", "torch", ".", "tensor", "(", "img_mask", ")", "\n", "return", "img_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_img_tgt_mask": [[24, 28], ["torch.zeros", "torch.cat"], "function", ["None"], ["", "def", "_get_img_tgt_mask", "(", "img_mask", ",", "txt_len", ")", ":", "\n", "    ", "z", "=", "torch", ".", "zeros", "(", "txt_len", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "img_mask_tgt", "=", "torch", ".", "cat", "(", "[", "z", ",", "img_mask", "]", ",", "dim", "=", "0", ")", "\n", "return", "img_mask_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_feat_target": [[30, 36], ["img_masks.unsqueeze().expand_as", "img_feat.size", "img_feat[].contiguous().view", "img_masks.unsqueeze", "img_feat[].contiguous"], "function", ["None"], ["", "def", "_get_feat_target", "(", "img_feat", ",", "img_masks", ")", ":", "\n", "    ", "img_masks_ext", "=", "img_masks", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "img_feat", ")", "# (n, m, d)", "\n", "feat_dim", "=", "img_feat", ".", "size", "(", "-", "1", ")", "\n", "feat_targets", "=", "img_feat", "[", "img_masks_ext", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "-", "1", ",", "feat_dim", ")", "# (s, d)", "\n", "return", "feat_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._mask_img_feat": [[38, 42], ["img_masks.unsqueeze().expand_as", "img_feat.data.masked_fill", "img_masks.unsqueeze"], "function", ["None"], ["", "def", "_mask_img_feat", "(", "img_feat", ",", "img_masks", ")", ":", "\n", "    ", "img_masks_ext", "=", "img_masks", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "img_feat", ")", "\n", "img_feat_masked", "=", "img_feat", ".", "data", ".", "masked_fill", "(", "img_masks_ext", ",", "0", ")", "\n", "return", "img_feat_masked", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.mrfr_collate": [[75, 122], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "mrm._get_feat_target", "mrm._mask_img_feat", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_feat_target", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._mask_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["", "", "def", "mrfr_collate", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Return:\n    - input_ids    : (n, max_L), i.e., [cls, wd, wd, ..., sep, 0, 0], 0s padded\n    - position_ids : (n, max_L)\n    - txt_lens     : list of [input_len]\n    - img_feat     : (n, max_num_bb, d)\n    - img_pos_feat : (n, max_num_bb, 7)\n    - num_bbs      : list of [num_bb]\n    - attn_masks   : (n, max_{L + num_bb}), ie., [1, 1, ..., 0, 0, 1, 1]\n    - img_masks    : (n, max_num_bb) between {0, 1}\n    \"\"\"", "\n", "(", "input_ids", ",", "img_feats", ",", "img_pos_feats", ",", "attn_masks", ",", "img_masks", ",", "img_mask_tgts", ",", "\n", ")", "=", "map", "(", "list", ",", "unzip", "(", "inputs", ")", ")", "\n", "\n", "txt_lens", "=", "[", "i", ".", "size", "(", "0", ")", "for", "i", "in", "input_ids", "]", "\n", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "0", ",", "input_ids", ".", "size", "(", "1", ")", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "num_bbs", "=", "[", "f", ".", "size", "(", "0", ")", "for", "f", "in", "img_feats", "]", "\n", "img_feat", "=", "pad_tensors", "(", "img_feats", ",", "num_bbs", ")", "\n", "img_pos_feat", "=", "pad_tensors", "(", "img_pos_feats", ",", "num_bbs", ")", "\n", "\n", "# mask features", "\n", "img_masks", "=", "pad_sequence", "(", "img_masks", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "feat_targets", "=", "_get_feat_target", "(", "img_feat", ",", "img_masks", ")", "\n", "img_feat", "=", "_mask_img_feat", "(", "img_feat", ",", "img_masks", ")", "\n", "img_mask_tgt", "=", "pad_sequence", "(", "img_mask_tgts", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "\n", "attn_masks", "=", "pad_sequence", "(", "attn_masks", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "bs", ",", "max_tl", "=", "input_ids", ".", "size", "(", ")", "\n", "out_size", "=", "attn_masks", ".", "size", "(", "1", ")", "\n", "gather_index", "=", "get_gather_index", "(", "txt_lens", ",", "num_bbs", ",", "bs", ",", "max_tl", ",", "out_size", ")", "\n", "\n", "batch", "=", "{", "'input_ids'", ":", "input_ids", ",", "\n", "'position_ids'", ":", "position_ids", ",", "\n", "'img_feat'", ":", "img_feat", ",", "\n", "'img_pos_feat'", ":", "img_pos_feat", ",", "\n", "'attn_masks'", ":", "attn_masks", ",", "\n", "'gather_index'", ":", "gather_index", ",", "\n", "'feat_targets'", ":", "feat_targets", ",", "\n", "'img_masks'", ":", "img_masks", ",", "\n", "'img_mask_tgt'", ":", "img_mask_tgt", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_targets": [[124, 130], ["img_soft_label.size", "img_masks.unsqueeze().expand_as", "img_soft_label[].contiguous().view", "img_masks.unsqueeze", "img_soft_label[].contiguous"], "function", ["None"], ["", "def", "_get_targets", "(", "img_masks", ",", "img_soft_label", ")", ":", "\n", "    ", "soft_label_dim", "=", "img_soft_label", ".", "size", "(", "-", "1", ")", "\n", "img_masks_ext_for_label", "=", "img_masks", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "img_soft_label", ")", "\n", "label_targets", "=", "img_soft_label", "[", "img_masks_ext_for_label", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "-", "1", ",", "soft_label_dim", ")", "\n", "return", "label_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm.mrc_collate": [[165, 201], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "mrm._get_targets", "mrm._mask_img_feat", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._get_targets", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mrm._mask_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["", "", "def", "mrc_collate", "(", "inputs", ")", ":", "\n", "    ", "(", "input_ids", ",", "img_feats", ",", "img_pos_feats", ",", "img_soft_labels", ",", "\n", "attn_masks", ",", "img_masks", ",", "img_mask_tgts", ")", "=", "map", "(", "list", ",", "unzip", "(", "inputs", ")", ")", "\n", "\n", "txt_lens", "=", "[", "i", ".", "size", "(", "0", ")", "for", "i", "in", "input_ids", "]", "\n", "num_bbs", "=", "[", "f", ".", "size", "(", "0", ")", "for", "f", "in", "img_feats", "]", "\n", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "0", ",", "input_ids", ".", "size", "(", "1", ")", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "img_feat", "=", "pad_tensors", "(", "img_feats", ",", "num_bbs", ")", "\n", "img_pos_feat", "=", "pad_tensors", "(", "img_pos_feats", ",", "num_bbs", ")", "\n", "img_soft_label", "=", "pad_tensors", "(", "img_soft_labels", ",", "num_bbs", ")", "\n", "img_masks", "=", "pad_sequence", "(", "img_masks", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "label_targets", "=", "_get_targets", "(", "img_masks", ",", "img_soft_label", ")", "\n", "\n", "img_feat", "=", "_mask_img_feat", "(", "img_feat", ",", "img_masks", ")", "\n", "img_mask_tgt", "=", "pad_sequence", "(", "img_mask_tgts", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "\n", "attn_masks", "=", "pad_sequence", "(", "attn_masks", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "bs", ",", "max_tl", "=", "input_ids", ".", "size", "(", ")", "\n", "out_size", "=", "attn_masks", ".", "size", "(", "1", ")", "\n", "gather_index", "=", "get_gather_index", "(", "txt_lens", ",", "num_bbs", ",", "bs", ",", "max_tl", ",", "out_size", ")", "\n", "\n", "batch", "=", "{", "'input_ids'", ":", "input_ids", ",", "\n", "'position_ids'", ":", "position_ids", ",", "\n", "'img_feat'", ":", "img_feat", ",", "\n", "'img_pos_feat'", ":", "img_pos_feat", ",", "\n", "'attn_masks'", ":", "attn_masks", ",", "\n", "'gather_index'", ":", "gather_index", ",", "\n", "'img_masks'", ":", "img_masks", ",", "\n", "'img_mask_tgt'", ":", "img_mask_tgt", ",", "\n", "'label_targets'", ":", "label_targets", "}", "\n", "return", "batch", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.MlmDataset.__init__": [[58, 61], ["isinstance", "data.DetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "txt_db", ",", "img_db", ")", ":", "\n", "        ", "assert", "isinstance", "(", "txt_db", ",", "TxtTokLmdb", ")", "\n", "super", "(", ")", ".", "__init__", "(", "txt_db", ",", "img_db", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.MlmDataset.__getitem__": [[62, 84], ["data.DetectFeatTxtTokDataset.__getitem__", "mlm.MlmDataset.create_mlm_io", "mlm.MlmDataset._get_img_feat", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.MlmDataset.create_mlm_io", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"\n        Return:\n        - input_ids    : (L, ), i.e., [cls, wd, wd, ..., sep, 0, 0], 0s padded\n        - img_feat     : (num_bb, d)\n        - img_pos_feat : (num_bb, 7)\n        - attn_masks   : (L + num_bb, ), ie., [1, 1, ..., 0, 0, 1, 1]\n        - txt_labels   : (L, ), [-1, -1, wid, -1, -1, -1]\n        0's padded so that (L + num_bb) % 8 == 0\n        \"\"\"", "\n", "example", "=", "super", "(", ")", ".", "__getitem__", "(", "i", ")", "\n", "\n", "# text input", "\n", "input_ids", ",", "txt_labels", "=", "self", ".", "create_mlm_io", "(", "example", "[", "'input_ids'", "]", ")", "\n", "\n", "# img input", "\n", "img_feat", ",", "img_pos_feat", ",", "num_bb", "=", "self", ".", "_get_img_feat", "(", "\n", "example", "[", "'img_fname'", "]", ")", "\n", "\n", "attn_masks", "=", "torch", ".", "ones", "(", "len", "(", "input_ids", ")", "+", "num_bb", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "input_ids", ",", "img_feat", ",", "img_pos_feat", ",", "attn_masks", ",", "txt_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.MlmDataset.create_mlm_io": [[85, 94], ["mlm.random_word", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.random_word"], ["", "def", "create_mlm_io", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "input_ids", ",", "txt_labels", "=", "random_word", "(", "input_ids", ",", "\n", "self", ".", "txt_db", ".", "v_range", ",", "\n", "self", ".", "txt_db", ".", "mask", ")", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "self", ".", "txt_db", ".", "cls_", "]", "\n", "+", "input_ids", "\n", "+", "[", "self", ".", "txt_db", ".", "sep", "]", ")", "\n", "txt_labels", "=", "torch", ".", "tensor", "(", "[", "-", "1", "]", "+", "txt_labels", "+", "[", "-", "1", "]", ")", "\n", "return", "input_ids", ",", "txt_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.random_word": [[17, 55], ["enumerate", "all", "random.random", "output_label.append", "output_label.append", "random.choice", "list", "range"], "function", ["None"], ["def", "random_word", "(", "tokens", ",", "vocab_range", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Masking some random tokens for Language Model task with probabilities as in\n        the original BERT paper.\n    :param tokens: list of int, tokenized sentence.\n    :param vocab_range: for choosing a random word\n    :return: (list of int, list of int), masked tokens and related labels for\n        LM prediction\n    \"\"\"", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "            ", "prob", "/=", "0.15", "\n", "\n", "# 80% randomly change token to mask token", "\n", "if", "prob", "<", "0.8", ":", "\n", "                ", "tokens", "[", "i", "]", "=", "mask", "\n", "\n", "# 10% randomly change token to random token", "\n", "", "elif", "prob", "<", "0.9", ":", "\n", "                ", "tokens", "[", "i", "]", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "*", "vocab_range", ")", ")", ")", "\n", "\n", "# -> rest 10% randomly keep current token", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "            ", "output_label", ".", "append", "(", "-", "1", ")", "\n", "", "", "if", "all", "(", "o", "==", "-", "1", "for", "o", "in", "output_label", ")", ":", "\n", "# at least mask 1", "\n", "        ", "output_label", "[", "0", "]", "=", "tokens", "[", "0", "]", "\n", "tokens", "[", "0", "]", "=", "mask", "\n", "\n", "", "return", "tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.mlm.mlm_collate": [[96, 137], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["", "", "def", "mlm_collate", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Return:\n    :input_ids    (n, max_L) padded with 0\n    :position_ids (n, max_L) padded with 0\n    :txt_lens     list of [txt_len]\n    :img_feat     (n, max_num_bb, feat_dim)\n    :img_pos_feat (n, max_num_bb, 7)\n    :num_bbs      list of [num_bb]\n    :attn_masks   (n, max_{L + num_bb}) padded with 0\n    :txt_labels   (n, max_L) padded with -1\n    \"\"\"", "\n", "(", "input_ids", ",", "img_feats", ",", "img_pos_feats", ",", "attn_masks", ",", "txt_labels", "\n", ")", "=", "map", "(", "list", ",", "unzip", "(", "inputs", ")", ")", "\n", "\n", "# text batches", "\n", "txt_lens", "=", "[", "i", ".", "size", "(", "0", ")", "for", "i", "in", "input_ids", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "txt_labels", "=", "pad_sequence", "(", "txt_labels", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "0", ",", "input_ids", ".", "size", "(", "1", ")", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# image batches", "\n", "num_bbs", "=", "[", "f", ".", "size", "(", "0", ")", "for", "f", "in", "img_feats", "]", "\n", "img_feat", "=", "pad_tensors", "(", "img_feats", ",", "num_bbs", ")", "\n", "img_pos_feat", "=", "pad_tensors", "(", "img_pos_feats", ",", "num_bbs", ")", "\n", "\n", "attn_masks", "=", "pad_sequence", "(", "attn_masks", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "\n", "bs", ",", "max_tl", "=", "input_ids", ".", "size", "(", ")", "\n", "out_size", "=", "attn_masks", ".", "size", "(", "1", ")", "\n", "gather_index", "=", "get_gather_index", "(", "txt_lens", ",", "num_bbs", ",", "bs", ",", "max_tl", ",", "out_size", ")", "\n", "\n", "batch", "=", "{", "'input_ids'", ":", "input_ids", ",", "\n", "'position_ids'", ":", "position_ids", ",", "\n", "'img_feat'", ":", "img_feat", ",", "\n", "'img_pos_feat'", ":", "img_pos_feat", ",", "\n", "'attn_masks'", ":", "attn_masks", ",", "\n", "'gather_index'", ":", "gather_index", ",", "\n", "'txt_labels'", ":", "txt_labels", "}", "\n", "return", "batch", "\n", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.__init__": [[49, 79], ["lmdb.open", "data.DetectFeatLmdb.env.begin", "collections.defaultdict", "data.DetectFeatLmdb._compute_nbb", "os.path.exists", "json.load", "open", "data._check_distributed"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb._compute_nbb", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._check_distributed"], ["    ", "def", "__init__", "(", "self", ",", "img_dir", ",", "conf_th", "=", "0.2", ",", "max_bb", "=", "100", ",", "min_bb", "=", "10", ",", "num_bb", "=", "36", ",", "\n", "compress", "=", "True", ")", ":", "\n", "        ", "self", ".", "img_dir", "=", "img_dir", "\n", "if", "conf_th", "==", "-", "1", ":", "\n", "            ", "db_name", "=", "f'feat_numbb{num_bb}'", "\n", "self", ".", "name2nbb", "=", "defaultdict", "(", "lambda", ":", "num_bb", ")", "\n", "", "else", ":", "\n", "            ", "db_name", "=", "f'feat_th{conf_th}_max{max_bb}_min{min_bb}'", "\n", "nbb", "=", "f'nbb_th{conf_th}_max{max_bb}_min{min_bb}.json'", "\n", "if", "not", "exists", "(", "f'{img_dir}/{nbb}'", ")", ":", "\n", "# nbb is not pre-computed", "\n", "                ", "self", ".", "name2nbb", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "name2nbb", "=", "json", ".", "load", "(", "open", "(", "f'{img_dir}/{nbb}'", ")", ")", "\n", "", "", "self", ".", "compress", "=", "compress", "\n", "if", "compress", ":", "\n", "            ", "db_name", "+=", "'_compressed'", "\n", "\n", "", "if", "self", ".", "name2nbb", "is", "None", ":", "\n", "            ", "if", "compress", ":", "\n", "                ", "db_name", "=", "'all_compressed'", "\n", "", "else", ":", "\n", "                ", "db_name", "=", "'all'", "\n", "# only read ahead on single node training", "\n", "", "", "self", ".", "env", "=", "lmdb", ".", "open", "(", "f'{img_dir}/{db_name}'", ",", "\n", "readonly", "=", "True", ",", "create", "=", "False", ",", "\n", "readahead", "=", "not", "_check_distributed", "(", ")", ")", "\n", "self", ".", "txn", "=", "self", ".", "env", ".", "begin", "(", "buffers", "=", "True", ")", "\n", "if", "self", ".", "name2nbb", "is", "None", ":", "\n", "            ", "self", ".", "name2nbb", "=", "self", ".", "_compute_nbb", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb._compute_nbb": [[80, 96], ["json.loads", "tqdm.tqdm.tqdm", "data.DetectFeatLmdb.txn.get().decode", "data.DetectFeatLmdb.txn.get", "data.compute_num_bb", "fname.encode", "msgpack.loads", "data.DetectFeatLmdb.txn.get", "io.BytesIO", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.compute_num_bb"], ["", "", "def", "_compute_nbb", "(", "self", ")", ":", "\n", "        ", "name2nbb", "=", "{", "}", "\n", "fnames", "=", "json", ".", "loads", "(", "self", ".", "txn", ".", "get", "(", "key", "=", "b'__keys__'", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "for", "fname", "in", "tqdm", "(", "fnames", ",", "desc", "=", "'reading images'", ")", ":", "\n", "            ", "dump", "=", "self", ".", "txn", ".", "get", "(", "fname", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "if", "self", ".", "compress", ":", "\n", "                ", "with", "io", ".", "BytesIO", "(", "dump", ")", "as", "reader", ":", "\n", "                    ", "img_dump", "=", "np", ".", "load", "(", "reader", ",", "allow_pickle", "=", "True", ")", "\n", "confs", "=", "img_dump", "[", "'conf'", "]", "\n", "", "", "else", ":", "\n", "                ", "img_dump", "=", "msgpack", ".", "loads", "(", "dump", ",", "raw", "=", "False", ")", "\n", "confs", "=", "img_dump", "[", "'conf'", "]", "\n", "", "name2nbb", "[", "fname", "]", "=", "compute_num_bb", "(", "confs", ",", "self", ".", "conf_th", ",", "\n", "self", ".", "min_bb", ",", "self", ".", "max_bb", ")", "\n", "\n", "", "return", "name2nbb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.__del__": [[97, 99], ["data.DetectFeatLmdb.env.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.get_dump": [[100, 113], ["data.DetectFeatLmdb.txn.get", "file_name.encode", "msgpack.loads", "data._fp16_to_fp32", "io.BytesIO", "numpy.load", "data._fp16_to_fp32", "_fp16_to_fp32.items"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._fp16_to_fp32", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._fp16_to_fp32"], ["", "def", "get_dump", "(", "self", ",", "file_name", ")", ":", "\n", "# hack for MRC", "\n", "        ", "dump", "=", "self", ".", "txn", ".", "get", "(", "file_name", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "nbb", "=", "self", ".", "name2nbb", "[", "file_name", "]", "\n", "if", "self", ".", "compress", ":", "\n", "            ", "with", "io", ".", "BytesIO", "(", "dump", ")", "as", "reader", ":", "\n", "                ", "img_dump", "=", "np", ".", "load", "(", "reader", ",", "allow_pickle", "=", "True", ")", "\n", "img_dump", "=", "_fp16_to_fp32", "(", "img_dump", ")", "\n", "", "", "else", ":", "\n", "            ", "img_dump", "=", "msgpack", ".", "loads", "(", "dump", ",", "raw", "=", "False", ")", "\n", "img_dump", "=", "_fp16_to_fp32", "(", "img_dump", ")", "\n", "", "img_dump", "=", "{", "k", ":", "arr", "[", ":", "nbb", ",", "...", "]", "for", "k", ",", "arr", "in", "img_dump", ".", "items", "(", ")", "}", "\n", "return", "img_dump", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatLmdb.__getitem__": [[114, 127], ["data.DetectFeatLmdb.txn.get", "torch.tensor().float", "torch.tensor().float", "file_name.encode", "msgpack.loads", "io.BytesIO", "numpy.load", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "dump", "=", "self", ".", "txn", ".", "get", "(", "file_name", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "nbb", "=", "self", ".", "name2nbb", "[", "file_name", "]", "\n", "if", "self", ".", "compress", ":", "\n", "            ", "with", "io", ".", "BytesIO", "(", "dump", ")", "as", "reader", ":", "\n", "                ", "img_dump", "=", "np", ".", "load", "(", "reader", ",", "allow_pickle", "=", "True", ")", "\n", "img_dump", "=", "{", "'features'", ":", "img_dump", "[", "'features'", "]", ",", "\n", "'norm_bb'", ":", "img_dump", "[", "'norm_bb'", "]", "}", "\n", "", "", "else", ":", "\n", "            ", "img_dump", "=", "msgpack", ".", "loads", "(", "dump", ",", "raw", "=", "False", ")", "\n", "", "img_feat", "=", "torch", ".", "tensor", "(", "img_dump", "[", "'features'", "]", "[", ":", "nbb", ",", ":", "]", ")", ".", "float", "(", ")", "\n", "img_bb", "=", "torch", ".", "tensor", "(", "img_dump", "[", "'norm_bb'", "]", "[", ":", "nbb", ",", ":", "]", ")", ".", "float", "(", ")", "\n", "return", "img_feat", ",", "img_bb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtLmdb.__init__": [[139, 154], ["lmdb.open", "data.TxtLmdb.env.begin", "lmdb.open", "data.TxtLmdb.env.begin", "data._check_distributed"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._check_distributed"], ["    ", "def", "__init__", "(", "self", ",", "db_dir", ",", "readonly", "=", "True", ")", ":", "\n", "        ", "self", ".", "readonly", "=", "readonly", "\n", "if", "readonly", ":", "\n", "# training", "\n", "            ", "self", ".", "env", "=", "lmdb", ".", "open", "(", "db_dir", ",", "\n", "readonly", "=", "True", ",", "create", "=", "False", ",", "\n", "readahead", "=", "not", "_check_distributed", "(", ")", ")", "\n", "self", ".", "txn", "=", "self", ".", "env", ".", "begin", "(", "buffers", "=", "True", ")", "\n", "self", ".", "write_cnt", "=", "None", "\n", "", "else", ":", "\n", "# prepro", "\n", "            ", "self", ".", "env", "=", "lmdb", ".", "open", "(", "db_dir", ",", "readonly", "=", "False", ",", "create", "=", "True", ",", "\n", "map_size", "=", "4", "*", "1024", "**", "4", ")", "\n", "self", ".", "txn", "=", "self", ".", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "self", ".", "write_cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtLmdb.__del__": [[155, 159], ["data.TxtLmdb.env.close", "data.TxtLmdb.txn.commit"], "methods", ["None"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "write_cnt", ":", "\n", "            ", "self", ".", "txn", ".", "commit", "(", ")", "\n", "", "self", ".", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtLmdb.__getitem__": [[160, 163], ["msgpack.loads", "lz4.frame.decompress", "data.TxtLmdb.txn.get", "key.encode"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "msgpack", ".", "loads", "(", "decompress", "(", "self", ".", "txn", ".", "get", "(", "key", ".", "encode", "(", "'utf-8'", ")", ")", ")", ",", "\n", "raw", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtLmdb.__setitem__": [[164, 176], ["data.TxtLmdb.txn.put", "ValueError", "key.encode", "lz4.frame.compress", "data.TxtLmdb.txn.commit", "data.TxtLmdb.env.begin", "msgpack.dumps"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "# NOTE: not thread safe", "\n", "        ", "if", "self", ".", "readonly", ":", "\n", "            ", "raise", "ValueError", "(", "'readonly text DB'", ")", "\n", "", "ret", "=", "self", ".", "txn", ".", "put", "(", "key", ".", "encode", "(", "'utf-8'", ")", ",", "\n", "compress", "(", "msgpack", ".", "dumps", "(", "value", ",", "use_bin_type", "=", "True", ")", ")", ")", "\n", "self", ".", "write_cnt", "+=", "1", "\n", "if", "self", ".", "write_cnt", "%", "1000", "==", "0", ":", "\n", "            ", "self", ".", "txn", ".", "commit", "(", ")", "\n", "self", ".", "txn", "=", "self", ".", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "self", ".", "write_cnt", "=", "0", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.__init__": [[179, 196], ["data.TxtLmdb", "json.load", "json.load", "open", "open", "json.load().items", "json.load", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "db_dir", ",", "max_txt_len", "=", "60", ")", ":", "\n", "        ", "if", "max_txt_len", "==", "-", "1", ":", "\n", "            ", "self", ".", "id2len", "=", "json", ".", "load", "(", "open", "(", "f'{db_dir}/id2len.json'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "id2len", "=", "{", "\n", "id_", ":", "len_", "\n", "for", "id_", ",", "len_", "in", "json", ".", "load", "(", "open", "(", "f'{db_dir}/id2len.json'", ")", "\n", ")", ".", "items", "(", ")", "\n", "if", "len_", "<=", "max_txt_len", "\n", "}", "\n", "", "self", ".", "db_dir", "=", "db_dir", "\n", "self", ".", "db", "=", "TxtLmdb", "(", "db_dir", ",", "readonly", "=", "True", ")", "\n", "meta", "=", "json", ".", "load", "(", "open", "(", "f'{db_dir}/meta.json'", ",", "'r'", ")", ")", "\n", "self", ".", "cls_", "=", "meta", "[", "'CLS'", "]", "\n", "self", ".", "sep", "=", "meta", "[", "'SEP'", "]", "\n", "self", ".", "mask", "=", "meta", "[", "'MASK'", "]", "\n", "self", ".", "v_range", "=", "meta", "[", "'v_range'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.__getitem__": [[197, 200], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "id_", ")", ":", "\n", "        ", "txt_dump", "=", "self", ".", "db", "[", "id_", "]", "\n", "return", "txt_dump", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs": [[201, 206], ["torch.tensor", "input_ids.extend"], "methods", ["None"], ["", "def", "combine_inputs", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "input_ids", "=", "[", "self", ".", "cls_", "]", "\n", "for", "ids", "in", "inputs", ":", "\n", "            ", "input_ids", ".", "extend", "(", "ids", "+", "[", "self", ".", "sep", "]", ")", "\n", "", "return", "torch", ".", "tensor", "(", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.txt2img": [[207, 211], ["json.load", "open"], "methods", ["None"], ["", "@", "property", "\n", "def", "txt2img", "(", "self", ")", ":", "\n", "        ", "txt2img", "=", "json", ".", "load", "(", "open", "(", "f'{self.db_dir}/txt2img.json'", ")", ")", "\n", "return", "txt2img", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.img2txts": [[212, 216], ["json.load", "open"], "methods", ["None"], ["", "@", "property", "\n", "def", "img2txts", "(", "self", ")", ":", "\n", "        ", "img2txts", "=", "json", ".", "load", "(", "open", "(", "f'{self.db_dir}/img2txts.json'", ")", ")", "\n", "return", "img2txts", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatTxtTokDataset.__init__": [[229, 239], ["isinstance", "isinstance", "data.get_ids_and_lens", "zip"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens"], ["    ", "def", "__init__", "(", "self", ",", "txt_db", ",", "img_db", ")", ":", "\n", "        ", "assert", "isinstance", "(", "txt_db", ",", "TxtTokLmdb", ")", "\n", "assert", "isinstance", "(", "img_db", ",", "DetectFeatLmdb", ")", "\n", "self", ".", "txt_db", "=", "txt_db", "\n", "self", ".", "img_db", "=", "img_db", "\n", "txt_lens", ",", "self", ".", "ids", "=", "get_ids_and_lens", "(", "txt_db", ")", "\n", "\n", "txt2img", "=", "txt_db", ".", "txt2img", "\n", "self", ".", "lens", "=", "[", "tl", "+", "self", ".", "img_db", ".", "name2nbb", "[", "txt2img", "[", "id_", "]", "]", "\n", "for", "tl", ",", "id_", "in", "zip", "(", "txt_lens", ",", "self", ".", "ids", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatTxtTokDataset.__len__": [[240, 242], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatTxtTokDataset.__getitem__": [[243, 247], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "id_", "=", "self", ".", "ids", "[", "i", "]", "\n", "example", "=", "self", ".", "txt_db", "[", "id_", "]", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.DetectFeatTxtTokDataset._get_img_feat": [[248, 253], ["torch.cat", "img_feat.size"], "methods", ["None"], ["", "def", "_get_img_feat", "(", "self", ",", "fname", ")", ":", "\n", "        ", "img_feat", ",", "bb", "=", "self", ".", "img_db", "[", "fname", "]", "\n", "img_bb", "=", "torch", ".", "cat", "(", "[", "bb", ",", "bb", "[", ":", ",", "4", ":", "5", "]", "*", "bb", "[", ":", ",", "5", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "num_bb", "=", "img_feat", ".", "size", "(", "0", ")", "\n", "return", "img_feat", ",", "img_bb", ",", "num_bb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ConcatDatasetWithLens.__init__": [[284, 287], ["torch.utils.data.ConcatDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "datasets", ")", "\n", "self", ".", "lens", "=", "[", "l", "for", "dset", "in", "datasets", "for", "l", "in", "dset", ".", "lens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ConcatDatasetWithLens.__getattr__": [[288, 290], ["data.ConcatDatasetWithLens._run_method_on_all_dsets"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ConcatDatasetWithLens._run_method_on_all_dsets"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "_run_method_on_all_dsets", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ConcatDatasetWithLens._run_method_on_all_dsets": [[291, 296], ["dset.__getattribute__"], "methods", ["None"], ["", "def", "_run_method_on_all_dsets", "(", "self", ",", "name", ")", ":", "\n", "        ", "def", "run_all", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "[", "dset", ".", "__getattribute__", "(", "name", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "dset", "in", "self", ".", "datasets", "]", "\n", "", "return", "run_all", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ImageLmdbGroup.__init__": [[299, 306], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "conf_th", ",", "max_bb", ",", "min_bb", ",", "num_bb", ",", "compress", ")", ":", "\n", "        ", "self", ".", "path2imgdb", "=", "{", "}", "\n", "self", ".", "conf_th", "=", "conf_th", "\n", "self", ".", "max_bb", "=", "max_bb", "\n", "self", ".", "min_bb", "=", "min_bb", "\n", "self", ".", "num_bb", "=", "num_bb", "\n", "self", ".", "compress", "=", "compress", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.ImageLmdbGroup.__getitem__": [[307, 313], ["data.ImageLmdbGroup.path2imgdb.get", "data.DetectFeatLmdb"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "path", ")", ":", "\n", "        ", "img_db", "=", "self", ".", "path2imgdb", ".", "get", "(", "path", ",", "None", ")", "\n", "if", "img_db", "is", "None", ":", "\n", "            ", "img_db", "=", "DetectFeatLmdb", "(", "path", ",", "self", ".", "conf_th", ",", "self", ".", "max_bb", ",", "\n", "self", ".", "min_bb", ",", "self", ".", "num_bb", ",", "self", ".", "compress", ")", "\n", "", "return", "img_db", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._fp16_to_fp32": [[26, 31], ["arr.astype", "feat_dict.items"], "function", ["None"], ["def", "_fp16_to_fp32", "(", "feat_dict", ")", ":", "\n", "    ", "out", "=", "{", "k", ":", "arr", ".", "astype", "(", "np", ".", "float32", ")", "\n", "if", "arr", ".", "dtype", "==", "np", ".", "float16", "else", "arr", "\n", "for", "k", ",", "arr", "in", "feat_dict", ".", "items", "(", ")", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.compute_num_bb": [[33, 37], ["max", "min"], "function", ["None"], ["", "def", "compute_num_bb", "(", "confs", ",", "conf_th", ",", "min_bb", ",", "max_bb", ")", ":", "\n", "    ", "num_bb", "=", "max", "(", "min_bb", ",", "(", "confs", ">", "conf_th", ")", ".", "sum", "(", ")", ")", "\n", "num_bb", "=", "min", "(", "max_bb", ",", "num_bb", ")", "\n", "return", "num_bb", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data._check_distributed": [[39, 46], ["horovod.size", "horovod.local_size"], "function", ["None"], ["", "def", "_check_distributed", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "dist", "=", "hvd", ".", "size", "(", ")", "!=", "hvd", ".", "local_size", "(", ")", "\n", "", "except", "ValueError", ":", "\n", "# not using horovod", "\n", "        ", "dist", "=", "False", "\n", "", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.open_lmdb": [[129, 136], ["data.TxtLmdb"], "function", ["None"], ["", "", "@", "contextmanager", "\n", "def", "open_lmdb", "(", "db_dir", ",", "readonly", "=", "False", ")", ":", "\n", "    ", "db", "=", "TxtLmdb", "(", "db_dir", ",", "readonly", ")", "\n", "try", ":", "\n", "        ", "yield", "db", "\n", "", "finally", ":", "\n", "        ", "del", "db", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens": [[218, 226], ["isinstance", "list", "lens.append", "ids.append", "db.id2len.keys", "horovod.rank", "horovod.size"], "function", ["None"], ["", "", "def", "get_ids_and_lens", "(", "db", ")", ":", "\n", "    ", "assert", "isinstance", "(", "db", ",", "TxtTokLmdb", ")", "\n", "lens", "=", "[", "]", "\n", "ids", "=", "[", "]", "\n", "for", "id_", "in", "list", "(", "db", ".", "id2len", ".", "keys", "(", ")", ")", "[", "hvd", ".", "rank", "(", ")", ":", ":", "hvd", ".", "size", "(", ")", "]", ":", "\n", "        ", "lens", ".", "append", "(", "db", ".", "id2len", "[", "id_", "]", ")", "\n", "ids", ".", "append", "(", "id_", ")", "\n", "", "return", "lens", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors": [[255, 269], ["max", "len", "tensors[].size", "torch.zeros", "enumerate", "torch.zeros.data.fill_", "zip", "t.size"], "function", ["None"], ["", "", "def", "pad_tensors", "(", "tensors", ",", "lens", "=", "None", ",", "pad", "=", "0", ")", ":", "\n", "    ", "\"\"\"B x [T, ...]\"\"\"", "\n", "if", "lens", "is", "None", ":", "\n", "        ", "lens", "=", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "tensors", "]", "\n", "", "max_len", "=", "max", "(", "lens", ")", "\n", "bs", "=", "len", "(", "tensors", ")", "\n", "hid", "=", "tensors", "[", "0", "]", ".", "size", "(", "-", "1", ")", "\n", "dtype", "=", "tensors", "[", "0", "]", ".", "dtype", "\n", "output", "=", "torch", ".", "zeros", "(", "bs", ",", "max_len", ",", "hid", ",", "dtype", "=", "dtype", ")", "\n", "if", "pad", ":", "\n", "        ", "output", ".", "data", ".", "fill_", "(", "pad", ")", "\n", "", "for", "i", ",", "(", "t", ",", "l", ")", "in", "enumerate", "(", "zip", "(", "tensors", ",", "lens", ")", ")", ":", "\n", "        ", "output", ".", "data", "[", "i", ",", ":", "l", ",", "...", "]", "=", "t", ".", "data", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index": [[271, 280], ["torch.arange().unsqueeze().repeat", "enumerate", "len", "len", "zip", "torch.arange().unsqueeze", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "get_gather_index", "(", "txt_lens", ",", "num_bbs", ",", "batch_size", ",", "max_len", ",", "out_size", ")", ":", "\n", "    ", "assert", "len", "(", "txt_lens", ")", "==", "len", "(", "num_bbs", ")", "==", "batch_size", "\n", "gather_index", "=", "torch", ".", "arange", "(", "0", ",", "out_size", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "\n", "for", "i", ",", "(", "tl", ",", "nbb", ")", "in", "enumerate", "(", "zip", "(", "txt_lens", ",", "num_bbs", ")", ")", ":", "\n", "        ", "gather_index", ".", "data", "[", "i", ",", "tl", ":", "tl", "+", "nbb", "]", "=", "torch", ".", "arange", "(", "max_len", ",", "max_len", "+", "nbb", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "data", "\n", "", "return", "gather_index", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler.__init__": [[17, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "lens", ",", "bucket_size", ",", "batch_size", ",", "\n", "droplast", "=", "False", ",", "size_multiple", "=", "8", ")", ":", "\n", "        ", "self", ".", "_lens", "=", "lens", "\n", "self", ".", "_max_tok", "=", "batch_size", "\n", "self", ".", "_bucket_size", "=", "bucket_size", "\n", "self", ".", "_droplast", "=", "droplast", "\n", "self", ".", "_size_mul", "=", "size_multiple", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler._create_ids": [[25, 27], ["list", "range", "len"], "methods", ["None"], ["", "def", "_create_ids", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "range", "(", "len", "(", "self", ".", "_lens", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler._sort_fn": [[28, 30], ["None"], "methods", ["None"], ["", "def", "_sort_fn", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "_lens", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler.__iter__": [[31, 58], ["sampler.TokenBucketSampler._create_ids", "random.shuffle", "random.shuffle", "iter", "sorted", "cytoolz.partition_all", "range", "max", "batches.append", "len", "max", "batches.append", "list", "list.extend", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler._create_ids", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "ids", "=", "self", ".", "_create_ids", "(", ")", "\n", "random", ".", "shuffle", "(", "ids", ")", "\n", "buckets", "=", "[", "sorted", "(", "ids", "[", "i", ":", "i", "+", "self", ".", "_bucket_size", "]", ",", "\n", "key", "=", "self", ".", "_sort_fn", ",", "reverse", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "ids", ")", ",", "self", ".", "_bucket_size", ")", "]", "\n", "# fill batches until max_token (include padding)", "\n", "batches", "=", "[", "]", "\n", "for", "bucket", "in", "buckets", ":", "\n", "            ", "max_len", "=", "0", "\n", "batch_indices", "=", "[", "]", "\n", "for", "indices", "in", "partition_all", "(", "self", ".", "_size_mul", ",", "bucket", ")", ":", "\n", "                ", "max_len", "=", "max", "(", "max_len", ",", "max", "(", "self", ".", "_lens", "[", "i", "]", "for", "i", "in", "indices", ")", ")", "\n", "if", "(", "max_len", "*", "(", "len", "(", "batch_indices", ")", "+", "self", ".", "_size_mul", ")", "\n", ">", "self", ".", "_max_tok", ")", ":", "\n", "                    ", "if", "not", "batch_indices", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "\"max_tokens too small / max_seq_len too long\"", ")", "\n", "", "assert", "len", "(", "batch_indices", ")", "%", "self", ".", "_size_mul", "==", "0", "\n", "batches", ".", "append", "(", "batch_indices", ")", "\n", "batch_indices", "=", "list", "(", "indices", ")", "\n", "", "else", ":", "\n", "                    ", "batch_indices", ".", "extend", "(", "indices", ")", "\n", "", "", "if", "not", "self", ".", "_droplast", "and", "batch_indices", ":", "\n", "                ", "batches", ".", "append", "(", "batch_indices", ")", "\n", "", "", "random", ".", "shuffle", "(", "batches", ")", "\n", "return", "iter", "(", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.TokenBucketSampler.__len__": [[59, 61], ["ValueError"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"NOT supported. \"", "\n", "\"This has some randomness across epochs\"", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.DistributedSampler.__init__": [[83, 96], ["int", "horovod.size", "horovod.rank", "math.ceil", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "num_replicas", "is", "None", ":", "\n", "            ", "num_replicas", "=", "hvd", ".", "size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "num_samples", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "\n", "*", "1.0", "/", "self", ".", "num_replicas", ")", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.DistributedSampler.__iter__": [[97, 116], ["torch.Generator", "torch.Generator.manual_seed", "list", "iter", "range", "len", "torch.randperm().tolist", "len", "len", "len", "torch.randperm", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "# deterministically shuffle based on epoch", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "# add extra samples to make it evenly divisible", "\n", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "\n", "# subsample", "\n", "indices", "=", "indices", "[", "self", ".", "rank", ":", "self", ".", "total_size", ":", "self", ".", "num_replicas", "]", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "shufle_ind", "=", "torch", ".", "randperm", "(", "len", "(", "indices", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "[", "indices", "[", "i", "]", "for", "i", "in", "shufle_ind", "]", "\n", "", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.DistributedSampler.__len__": [[117, 119], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.sampler.DistributedSampler.set_epoch": [[120, 122], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.VqaDataset.__init__": [[24, 27], ["data.DetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "2", ")", ",", "\n", "GELU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", "*", "2", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "num_answer", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.VqaDataset.__getitem__": [[28, 42], ["data.DetectFeatTxtTokDataset.__getitem__", "vqa.VqaDataset._get_img_feat", "vqa.VqaDataset.txt_db.combine_inputs", "vqa._get_vqa_target", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa._get_vqa_target"], [")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.VqaEvalDataset.__getitem__": [[75, 93], ["data.DetectFeatTxtTokDataset.__getitem__", "vqa.VqaEvalDataset._get_img_feat", "vqa.VqaEvalDataset.txt_db.combine_inputs", "torch.ones", "vqa._get_vqa_target", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa._get_vqa_target"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa._get_vqa_target": [[14, 21], ["torch.zeros", "torch.zeros.scatter_", "torch.tensor", "torch.tensor"], "function", ["None"], ["from", ".", "model", "import", "UniterPreTrainedModel", ",", "UniterModel", "\n", "\n", "\n", "class", "UniterForVisualQuestionAnswering", "(", "UniterPreTrainedModel", ")", ":", "\n", "    ", "\"\"\" Finetune UNITER for VQA\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "num_answer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.vqa_collate": [[44, 72], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["answer_scores", "=", "self", ".", "vqa_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "vqa_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "answer_scores", ",", "targets", ",", "reduction", "=", "'none'", ")", "\n", "return", "vqa_loss", "\n", "", "else", ":", "\n", "            ", "return", "answer_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vqa.vqa_eval_collate": [[95, 127], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.nn.utils.rnn.pad_sequence", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "torch.stack", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrTxtTokLmdb.__init__": [[19, 46], ["data.TxtLmdb", "json.load", "json.load", "open", "open", "json.load().items", "json.load", "open"], "methods", ["None"], ["    ", "\"\"\" Finetune UNITER for VCR\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "self", ".", "vcr_output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", "*", "2", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "2", ")", "\n", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "init_type_embedding", "(", "self", ")", ":", "\n", "        ", "new_emb", "=", "nn", ".", "Embedding", "(", "4", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n", "new_emb", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "i", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "", "emb", "=", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "0", ",", ":", "]", "\n", "new_emb", ".", "weight", ".", "data", "[", "2", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "new_emb", ".", "weight", ".", "data", "[", "3", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "token_type_embeddings", "=", "new_emb", "\n", "\n", "", "def", "init_word_embedding", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "orig_word_num", "=", "self", ".", "uniter", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "size", "(", "0", ")", "\n", "new_emb", "=", "nn", ".", "Embedding", "(", "\n", "orig_word_num", "+", "num_special_tokens", ",", "self", ".", "uniter", ".", "config", ".", "hidden_size", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset.__init__": [[49, 73], ["isinstance", "data.get_ids_and_lens", "isinstance", "isinstance", "zip", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens"], ["new_emb", ".", "weight", ".", "data", "[", ":", "orig_word_num", ",", ":", "]", ".", "copy_", "(", "emb", ")", "\n", "self", ".", "uniter", ".", "embeddings", ".", "word_embeddings", "=", "new_emb", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "txt_type_ids", "=", "batch", "[", "'txt_type_ids'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "txt_type_ids", "=", "txt_type_ids", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "rank_scores", "=", "self", ".", "vcr_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "'targets'", "]", "\n", "vcr_loss", "=", "F", ".", "cross_entropy", "(", "\n", "rank_scores", ",", "targets", ".", "squeeze", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat": [[74, 94], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat", "torch.cat.size", "torch.cat", "torch.cat.size"], "methods", ["None"], ["return", "vcr_loss", "\n", "", "else", ":", "\n", "            ", "rank_scores", "=", "rank_scores", "[", ":", ",", "1", ":", "]", "\n", "return", "rank_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDataset.__init__": [[97, 101], ["vcr.VcrDetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDataset._get_input_ids": [[102, 120], ["len", "copy.deepcopy", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDataset.__getitem__": [[121, 160], ["data.DetectFeatTxtTokDataset.__getitem__", "vcr.VcrDataset._get_img_feat", "vcr.VcrDataset._get_input_ids", "enumerate", "tuple", "torch.ones", "torch.tensor", "torch.tensor", "outs.append", "torch.tensor().long", "torch.tensor().long", "len", "torch.tensor", "torch.tensor", "len", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset.__init__": [[197, 202], ["vcr.VcrDetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids": [[203, 233], ["enumerate", "enumerate", "len", "input_ids_for_choices.append", "type_ids_for_choices.append", "input_ids_for_choices.append", "type_ids_for_choices.append", "len", "len", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset.__getitem__": [[234, 260], ["data.DetectFeatTxtTokDataset.__getitem__", "vcr.VcrEvalDataset._get_img_feat", "vcr.VcrEvalDataset._get_input_ids", "torch.tensor", "torch.tensor", "enumerate", "torch.ones", "torch.tensor", "torch.tensor", "outs.append", "tuple", "int", "int", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrEvalDataset._get_input_ids"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.vcr_collate": [[162, 194], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "cytoolz.concat", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.vcr_eval_collate": [[262, 302], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "torch.stack", "torch.stack", "toolz.sandbox.unzip", "i.size", "f.size", "cytoolz.concat", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb.__init__": [[18, 55], ["json.load", "json.load", "json.load", "json.load", "data.TxtLmdb", "json.load", "open", "open", "open", "open", "json.load", "open", "open", "json.load().items", "json.load", "open"], "methods", ["None"], ["\n", "class", "UniterForReferringExpressionComprehension", "(", "UniterPreTrainedModel", ")", ":", "\n", "    ", "\"\"\" Finetune UNITER for RE\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "loss", "=", "\"cls\"", ",", "\n", "margin", "=", "0.2", ",", "hard_ratio", "=", "0.3", ",", "mlp", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "uniter", "=", "UniterModel", "(", "config", ",", "img_dim", ")", "\n", "if", "mlp", "==", "1", ":", "\n", "            ", "self", ".", "re_output", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "", "elif", "mlp", "==", "2", ":", "\n", "            ", "self", ".", "re_output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "GELU", "(", ")", ",", "\n", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"MLP restricted to be 1 or 2 layers.\"", ")", "\n", "", "self", ".", "loss", "=", "loss", "\n", "assert", "self", ".", "loss", "in", "[", "'cls'", ",", "'rank'", "]", "\n", "if", "self", ".", "loss", "==", "'rank'", ":", "\n", "            ", "self", ".", "margin", "=", "margin", "\n", "self", ".", "hard_ratio", "=", "hard_ratio", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attn_masks", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "obj_masks", "=", "batch", "[", "'obj_masks'", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb._get_sent_ids": [[56, 64], ["sent_ids.append", "str", "str"], "methods", ["None"], ["\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "attn_masks", ",", "gather_index", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "# get only the region part", "\n", "txt_lens", ",", "num_bbs", "=", "batch", "[", "\"txt_lens\"", "]", ",", "batch", "[", "\"num_bbs\"", "]", "\n", "sequence_output", "=", "self", ".", "_get_image_hidden", "(", "\n", "sequence_output", ",", "txt_lens", ",", "num_bbs", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb.shuffle": [[65, 69], ["random.shuffle", "re.ReTxtTokLmdb._get_sent_ids"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb._get_sent_ids"], ["\n", "# re score (n, max_num_bb)", "\n", "scores", "=", "self", ".", "re_output", "(", "sequence_output", ")", ".", "squeeze", "(", "2", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "obj_masks", ",", "-", "1e4", ")", "# mask out non-objects", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb.__getitem__": [[70, 74], ["None"], "methods", ["None"], ["if", "compute_loss", ":", "\n", "            ", "targets", "=", "batch", "[", "\"targets\"", "]", "\n", "if", "self", ".", "loss", "==", "'cls'", ":", "\n", "                ", "ce_loss", "=", "self", ".", "crit", "(", "scores", ",", "targets", ".", "squeeze", "(", "-", "1", ")", ")", "# (n, ) as no reduction", "\n", "return", "ce_loss", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.__init__": [[77, 83], ["isinstance", "isinstance", "re.ReDetectFeatTxtTokDataset.txt_db._get_sent_ids"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReTxtTokLmdb._get_sent_ids"], ["                ", "_n", "=", "len", "(", "num_bbs", ")", "\n", "# positive (target)", "\n", "pos_ix", "=", "targets", "\n", "pos_sc", "=", "scores", ".", "gather", "(", "1", ",", "pos_ix", ".", "view", "(", "_n", ",", "1", ")", ")", "# (n, 1)", "\n", "pos_sc", "=", "torch", ".", "sigmoid", "(", "pos_sc", ")", ".", "view", "(", "-", "1", ")", "# (n, ) sc[0, 1]", "\n", "# negative", "\n", "neg_ix", "=", "self", ".", "sample_neg_ix", "(", "scores", ",", "targets", ",", "num_bbs", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.__getitem__": [[84, 88], ["None"], "methods", ["None"], ["neg_sc", "=", "scores", ".", "gather", "(", "1", ",", "neg_ix", ".", "view", "(", "_n", ",", "1", ")", ")", "# (n, 1)", "\n", "neg_sc", "=", "torch", ".", "sigmoid", "(", "neg_sc", ")", ".", "view", "(", "-", "1", ")", "# (n, ) sc[0, 1]", "\n", "# ranking", "\n", "mm_loss", "=", "torch", ".", "clamp", "(", "\n", "self", ".", "margin", "+", "neg_sc", "-", "pos_sc", ",", "0", ")", "# (n, )", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle": [[89, 91], ["re.ReDetectFeatTxtTokDataset.txt_db.shuffle"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDetectFeatTxtTokDataset.shuffle"], ["return", "mm_loss", "\n", "", "", "else", ":", "\n", "# (n, max_num_bb)", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReDataset.__getitem__": [[94, 127], ["re.ReDetectFeatTxtTokDataset.__getitem__", "re.ReDataset._get_img_feat", "re.ReDataset.txt_db.combine_inputs", "torch.ones", "img[].index", "torch.tensor", "torch.tensor", "len", "int", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs"], ["", "", "def", "sample_neg_ix", "(", "self", ",", "scores", ",", "targets", ",", "num_bbs", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n        :scores    (n, max_num_bb)\n        :targets   (n, )\n        :num_bbs   list of [num_bb]\n        return:\n        :neg_ix    (n, ) easy/hard negative (!= target)\n        \"\"\"", "\n", "neg_ix", "=", "[", "]", "\n", "cand_ixs", "=", "torch", ".", "argsort", "(", "\n", "scores", ",", "dim", "=", "-", "1", ",", "descending", "=", "True", ")", "# (n, num_bb)", "\n", "for", "i", "in", "range", "(", "len", "(", "num_bbs", ")", ")", ":", "\n", "            ", "num_bb", "=", "num_bbs", "[", "i", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "1", ")", "<", "self", ".", "hard_ratio", ":", "\n", "# sample hard negative, w/ highest score", "\n", "                ", "for", "ix", "in", "cand_ixs", "[", "i", "]", ".", "tolist", "(", ")", ":", "\n", "                    ", "if", "ix", "!=", "targets", "[", "i", "]", ":", "\n", "                        ", "assert", "ix", "<", "num_bb", ",", "f'ix={ix}, num_bb={num_bb}'", "\n", "neg_ix", ".", "append", "(", "ix", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "# sample easy negative, i.e., random one", "\n", "                ", "ix", "=", "random", ".", "randint", "(", "0", ",", "num_bb", "-", "1", ")", "# [0, num_bb-1]", "\n", "while", "ix", "==", "targets", "[", "i", "]", ":", "\n", "                    ", "ix", "=", "random", ".", "randint", "(", "0", ",", "num_bb", "-", "1", ")", "\n", "", "neg_ix", ".", "append", "(", "ix", ")", "\n", "", "", "neg_ix", "=", "torch", ".", "tensor", "(", "neg_ix", ")", ".", "type", "(", "targets", ".", "type", "(", ")", ")", "\n", "assert", "neg_ix", ".", "numel", "(", ")", "==", "targets", ".", "numel", "(", ")", "\n", "return", "neg_ix", "\n", "\n", "", "def", "_get_image_hidden", "(", "self", ",", "sequence_output", ",", "txt_lens", ",", "num_bbs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReEvalDataset.__init__": [[176, 179], ["re.ReDetectFeatTxtTokDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReEvalDataset.__getitem__": [[180, 224], ["re.ReDetectFeatTxtTokDataset.__getitem__", "re.ReEvalDataset._get_img_feat", "numpy.stack", "torch.tensor", "numpy.array", "re.ReEvalDataset.txt_db.combine_inputs", "torch.ones", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.ReEvalDataset.computeIoU": [[226, 239], ["max", "max", "min", "min", "float"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.re_collate": [[129, 173], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["\n", "outputs", "=", "[", "]", "\n", "max_bb", "=", "max", "(", "num_bbs", ")", "\n", "hid_size", "=", "sequence_output", ".", "size", "(", "-", "1", ")", "\n", "for", "seq_out", ",", "len_", ",", "nbb", "in", "zip", "(", "sequence_output", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ",", "\n", "txt_lens", ",", "num_bbs", ")", ":", "\n", "            ", "img_hid", "=", "seq_out", "[", ":", ",", "len_", ":", "len_", "+", "nbb", ",", ":", "]", "\n", "if", "nbb", "<", "max_bb", ":", "\n", "                ", "img_hid", "=", "torch", ".", "cat", "(", "\n", "[", "img_hid", ",", "self", ".", "_get_pad", "(", "\n", "img_hid", ",", "max_bb", "-", "nbb", ",", "hid_size", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "", "outputs", ".", "append", "(", "img_hid", ")", "\n", "\n", "", "img_hidden", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "0", ")", "\n", "return", "img_hidden", "\n", "\n", "", "def", "_get_pad", "(", "self", ",", "t", ",", "len_", ",", "hidden_size", ")", ":", "\n", "        ", "pad", "=", "torch", ".", "zeros", "(", "1", ",", "len_", ",", "hidden_size", ",", "dtype", "=", "t", ".", "dtype", ",", "device", "=", "t", ".", "device", ")", "\n", "return", "pad", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.re.re_eval_collate": [[241, 288], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.nn.utils.rnn.pad_sequence", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.MetaLoader.__init__": [[19, 38], ["isinstance", "loaders.items", "isinstance", "iter", "loader.MetaLoader.sampling_pools.extend", "isinstance", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loaders", ",", "accum_steps", "=", "1", ",", "distributed", "=", "False", ")", ":", "\n", "        ", "assert", "isinstance", "(", "loaders", ",", "dict", ")", "\n", "self", ".", "name2loader", "=", "{", "}", "\n", "self", ".", "name2iter", "=", "{", "}", "\n", "self", ".", "sampling_pools", "=", "[", "]", "\n", "for", "n", ",", "l", "in", "loaders", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "l", ",", "tuple", ")", ":", "\n", "                ", "l", ",", "r", "=", "l", "\n", "", "elif", "isinstance", "(", "l", ",", "DataLoader", ")", ":", "\n", "                ", "r", "=", "1", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", ")", "\n", "", "self", ".", "name2loader", "[", "n", "]", "=", "l", "\n", "self", ".", "name2iter", "[", "n", "]", "=", "iter", "(", "l", ")", "\n", "self", ".", "sampling_pools", ".", "extend", "(", "[", "n", "]", "*", "r", ")", "\n", "\n", "", "self", ".", "accum_steps", "=", "accum_steps", "\n", "self", ".", "distributed", "=", "distributed", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.MetaLoader.__iter__": [[39, 58], ["random.choice", "next", "utils.distributed.any_broadcast", "iter", "next"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next", "home.repos.pwc.inspect_result.ChenRocks_UNITER.utils.distributed.any_broadcast", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\" this iterator will run indefinitely \"\"\"", "\n", "task", "=", "self", ".", "sampling_pools", "[", "0", "]", "\n", "while", "True", ":", "\n", "            ", "if", "self", ".", "step", "%", "self", ".", "accum_steps", "==", "0", ":", "\n", "                ", "task", "=", "random", ".", "choice", "(", "self", ".", "sampling_pools", ")", "\n", "if", "self", ".", "distributed", ":", "\n", "# make sure all process is training same task", "\n", "                    ", "task", "=", "any_broadcast", "(", "task", ",", "0", ")", "\n", "", "", "self", ".", "step", "+=", "1", "\n", "iter_", "=", "self", ".", "name2iter", "[", "task", "]", "\n", "try", ":", "\n", "                ", "batch", "=", "next", "(", "iter_", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "iter_", "=", "iter", "(", "self", ".", "name2loader", "[", "task", "]", ")", "\n", "batch", "=", "next", "(", "iter_", ")", "\n", "self", ".", "name2iter", "[", "task", "]", "=", "iter_", "\n", "\n", "", "yield", "task", ",", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.__init__": [[92, 95], ["torch.cuda.Stream"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "self", ".", "loader", "=", "loader", "\n", "self", ".", "stream", "=", "torch", ".", "cuda", ".", "Stream", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.__iter__": [[96, 103], ["iter", "loader.PrefetchLoader.preload", "loader.PrefetchLoader.next", "loader.PrefetchLoader.next"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.preload", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "loader_it", "=", "iter", "(", "self", ".", "loader", ")", "\n", "self", ".", "preload", "(", "loader_it", ")", "\n", "batch", "=", "self", ".", "next", "(", "loader_it", ")", "\n", "while", "batch", "is", "not", "None", ":", "\n", "            ", "yield", "batch", "\n", "batch", "=", "self", ".", "next", "(", "loader_it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.__len__": [[104, 106], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.preload": [[107, 124], ["loader.PrefetchLoader.next"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next"], ["", "def", "preload", "(", "self", ",", "it", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "batch", "=", "next", "(", "it", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "self", ".", "batch", "=", "None", "\n", "return", "\n", "# if record_stream() doesn't work, another option is to make sure", "\n", "# device inputs are created on the main stream.", "\n", "# self.next_input_gpu = torch.empty_like(self.next_input,", "\n", "#                                        device='cuda')", "\n", "# self.next_target_gpu = torch.empty_like(self.next_target,", "\n", "#                                         device='cuda')", "\n", "# Need to make sure the memory allocated for next_* is not still in use", "\n", "# by the main stream at the time we start copying to next_*:", "\n", "# self.stream.wait_stream(torch.cuda.current_stream())", "\n", "", "with", "torch", ".", "cuda", ".", "stream", "(", "self", ".", "stream", ")", ":", "\n", "            ", "self", ".", "batch", "=", "move_to_cuda", "(", "self", ".", "batch", ")", "\n", "# more code for the alternative if record_stream() doesn't work:", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.next": [[132, 139], ["torch.cuda.current_stream().wait_stream", "loader.PrefetchLoader.preload", "loader.record_cuda_stream", "torch.cuda.current_stream"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.preload", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.record_cuda_stream"], ["", "", "def", "next", "(", "self", ",", "it", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "wait_stream", "(", "self", ".", "stream", ")", "\n", "batch", "=", "self", ".", "batch", "\n", "if", "batch", "is", "not", "None", ":", "\n", "            ", "record_cuda_stream", "(", "batch", ")", "\n", "", "self", ".", "preload", "(", "it", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.PrefetchLoader.__getattr__": [[140, 143], ["loader.PrefetchLoader.loader.__getattribute__"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "method", "=", "self", ".", "loader", ".", "__getattribute__", "(", "name", ")", "\n", "return", "method", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.move_to_cuda": [[60, 72], ["isinstance", "batch.cuda", "isinstance", "isinstance", "loader.move_to_cuda", "tuple", "isinstance", "loader.move_to_cuda", "loader.move_to_cuda", "batch.items"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.move_to_cuda", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.move_to_cuda", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.move_to_cuda"], ["", "", "", "def", "move_to_cuda", "(", "batch", ")", ":", "\n", "    ", "if", "isinstance", "(", "batch", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "batch", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "", "elif", "isinstance", "(", "batch", ",", "list", ")", ":", "\n", "        ", "new_batch", "=", "[", "move_to_cuda", "(", "t", ")", "for", "t", "in", "batch", "]", "\n", "", "elif", "isinstance", "(", "batch", ",", "tuple", ")", ":", "\n", "        ", "new_batch", "=", "tuple", "(", "move_to_cuda", "(", "t", ")", "for", "t", "in", "batch", ")", "\n", "", "elif", "isinstance", "(", "batch", ",", "dict", ")", ":", "\n", "        ", "new_batch", "=", "{", "n", ":", "move_to_cuda", "(", "t", ")", "for", "n", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "        ", "return", "batch", "\n", "", "return", "new_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.record_cuda_stream": [[74, 85], ["isinstance", "batch.record_stream", "torch.cuda.current_stream", "isinstance", "isinstance", "isinstance", "loader.record_cuda_stream", "batch.values", "loader.record_cuda_stream"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.record_cuda_stream", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.loader.record_cuda_stream"], ["", "def", "record_cuda_stream", "(", "batch", ")", ":", "\n", "    ", "if", "isinstance", "(", "batch", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "batch", ".", "record_stream", "(", "torch", ".", "cuda", ".", "current_stream", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "batch", ",", "list", ")", "or", "isinstance", "(", "batch", ",", "tuple", ")", ":", "\n", "        ", "for", "t", "in", "batch", ":", "\n", "            ", "record_cuda_stream", "(", "t", ")", "\n", "", "", "elif", "isinstance", "(", "batch", ",", "dict", ")", ":", "\n", "        ", "for", "t", "in", "batch", ".", "values", "(", ")", ":", "\n", "            ", "record_cuda_stream", "(", "t", ")", "\n", "", "", "else", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.TokenBucketSamplerForItm.__init__": [[23, 26], ["sampler.TokenBucketSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], ["self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "init_output", "(", "self", ")", ":", "\n", "        ", "\"\"\" need to be called after from pretrained \"\"\"", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.TokenBucketSamplerForItm.__iter__": [[27, 32], ["sampler.TokenBucketSampler.__iter__", "itm.TokenBucketSamplerForItm.dset.new_epoch"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.TokenBucketSamplerForItm.__iter__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmDataset.new_epoch"], ["self", ".", "rank_output", ".", "weight", ".", "data", "=", "self", ".", "itm_output", ".", "weight", ".", "data", "[", "1", ":", ",", ":", "]", "\n", "self", ".", "rank_output", ".", "bias", ".", "data", "=", "self", ".", "itm_output", ".", "bias", ".", "data", "[", "1", ":", "]", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "compute_loss", "=", "True", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmDataset.__init__": [[52, 64], ["isinstance", "isinstance", "data.get_ids_and_lens", "list", "itm.ItmDataset.new_epoch", "set"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_ids_and_lens", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmDataset.new_epoch"], ["rank_loss", "=", "torch", ".", "clamp", "(", "self", ".", "margin", "+", "neg", "-", "pos", ",", "0", ")", "\n", "return", "rank_loss", "\n", "", "else", ":", "\n", "            ", "return", "rank_scores", "\n", "\n", "\n", "", "", "", "class", "UniterForImageTextRetrievalHardNeg", "(", "UniterForImageTextRetrieval", ")", ":", "\n", "    ", "\"\"\" Finetune UNITER for image text retrieval\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "config", ",", "img_dim", ",", "margin", "=", "0.2", ",", "hard_size", "=", "16", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "img_dim", ",", "margin", ")", "\n", "self", ".", "hard_size", "=", "hard_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmDataset.new_epoch": [[65, 79], ["numpy.random.choice", "enumerate", "zip", "itm.ItmDataset.train_imgs.append", "itm.ItmDataset.lens.append", "len", "data.DetectFeatTxtTokDataset.__getitem__", "itm.sample_negative"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative"], ["", "def", "forward", "(", "self", ",", "batch", ",", "sample_from", "=", "'t'", ",", "compute_loss", "=", "True", ")", ":", "\n", "# expect same input_ids for all pairs", "\n", "        ", "batch_size", "=", "batch", "[", "'attn_masks'", "]", ".", "size", "(", "0", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "if", "sample_from", "==", "'t'", ":", "\n", "            ", "if", "input_ids", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'input_ids'", "]", "=", "input_ids", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "", "", "elif", "sample_from", "==", "'i'", ":", "\n", "            ", "if", "img_feat", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'img_feat'", "]", "=", "img_feat", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "-", "1", ")", "\n", "", "if", "img_pos_feat", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "batch", "[", "'img_pos_feat'", "]", "=", "img_pos_feat", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "-", "1", ")", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmDataset.__getitem__": [[80, 96], ["data.DetectFeatTxtTokDataset.__getitem__", "itm.ItmDataset._get_img_feat", "itm.ItmDataset.txt_db.combine_inputs", "torch.ones", "torch.Tensor().long", "torch.Tensor().long.data.fill_", "len", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs"], ["            ", "raise", "ValueError", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "compute_loss", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "eval", "(", ")", "\n", "scores", "=", "super", "(", ")", ".", "forward", "(", "batch", ",", "compute_loss", "=", "False", ")", "\n", "hard_batch", "=", "self", ".", "_get_hard_batch", "(", "batch", ",", "scores", ",", "sample_from", ")", "\n", "self", ".", "train", "(", ")", "\n", "", "return", "super", "(", ")", ".", "forward", "(", "hard_batch", ",", "compute_loss", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "forward", "(", "batch", ",", "compute_loss", ")", "\n", "\n", "", "", "def", "_get_hard_batch", "(", "self", ",", "batch", ",", "scores", ",", "sample_from", "=", "'t'", ")", ":", "\n", "        ", "batch", "=", "defaultdict", "(", "lambda", ":", "None", ",", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", "\n", "img_feat", "=", "batch", "[", "'img_feat'", "]", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDataset.__init__": [[188, 203], ["data.DetectFeatTxtTokDataset.__init__", "collections.defaultdict", "itm.ItmRankDataset.txt2img.items", "list", "itm.ItmRankDataset.img2txts[].append", "itm.ItmRankDataset.img2txts.keys"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDataset.__getitem__": [[204, 221], ["itm.sample_negative", "itm.sample_negative", "id_pairs.extend", "itm.ItmRankDataset._collect_inputs", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDataset._collect_inputs"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDataset._collect_inputs": [[222, 238], ["itm.ItmRankDataset.txt_db.combine_inputs", "itm.ItmRankDataset._get_img_feat", "torch.ones", "inputs.append", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDatasetHardNegFromText.__init__": [[272, 281], ["data.DetectFeatTxtTokDataset.__init__", "list", "itm.ItmRankDatasetHardNegFromText.img2txts.keys"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDatasetHardNegFromText.__getitem__": [[282, 316], ["itm.ItmRankDatasetHardNegFromText.txt_db.combine_inputs", "input_ids.unsqueeze.unsqueeze.unsqueeze", "torch.arange().unsqueeze", "itm.sample_negative", "map", "data.pad_tensors", "data.pad_tensors", "input_ids.unsqueeze.unsqueeze.size", "torch.zeros().long", "enumerate", "torch.zeros().long.size", "data.get_gather_index", "toolz.sandbox.unzip", "torch.zeros().long.data[].fill_", "len", "torch.arange", "map", "torch.zeros", "len", "input_ids.unsqueeze.unsqueeze.size", "len", "max"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDatasetHardNegFromImage.__init__": [[319, 328], ["data.DetectFeatTxtTokDataset.__init__", "list", "itm.ItmRankDatasetHardNegFromImage.txt2img.keys"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmRankDatasetHardNegFromImage.__getitem__": [[329, 370], ["itm.ItmRankDatasetHardNegFromImage._get_img_feat", "img_feat.unsqueeze.unsqueeze.unsqueeze", "img_pos_feat.unsqueeze.unsqueeze.unsqueeze", "itm.sample_negative", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.zeros().long", "enumerate", "torch.zeros().long.size", "data.get_gather_index", "itm.ItmRankDatasetHardNegFromImage.txt_db.combine_inputs", "all_inputs.append", "txt_lens.append", "torch.zeros().long.data[].fill_", "len", "len", "torch.arange", "torch.zeros", "len", "itm.ItmRankDatasetHardNegFromImage.size", "len", "max"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.vcr.VcrDetectFeatTxtTokDataset._get_img_feat", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset.__init__": [[379, 388], ["data.DetectFeatTxtTokDataset.__init__", "list", "itm.ItmValDataset.img2txts.keys", "len"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset._get_batch_ids": [[389, 409], ["itm.ItmValDataset.all_img_ids.index", "len", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset.__getitem__": [[410, 416], ["itm.ItmValDataset._get_batch_ids", "itm.ItmValDataset.get_batch"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset._get_batch_ids", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset.get_batch"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset.get_batch": [[417, 447], ["data.DetectFeatTxtTokDataset.__getitem__", "itm.ItmValDataset.txt_db.combine_inputs", "input_ids.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze().expand().clone", "torch.arange().unsqueeze", "map", "data.pad_tensors", "data.pad_tensors", "input_ids.unsqueeze().expand().clone.unsqueeze().expand().clone.size", "torch.zeros().long", "enumerate", "torch.zeros().long.size", "data.get_gather_index", "toolz.sandbox.unzip", "torch.zeros().long.data[].fill_", "len", "input_ids.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze().expand", "torch.arange", "map", "torch.zeros", "len", "len", "input_ids.unsqueeze().expand().clone.unsqueeze().expand().clone.size", "len", "input_ids.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze", "max"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.TxtTokLmdb.combine_inputs", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__": [[455, 459], ["itm.ItmValDataset.__init__", "sorted", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__init__"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmEvalDataset.__getitem__": [[460, 466], ["range", "len", "mini_batches.append", "itm.ItmEvalDataset.get_batch"], "methods", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.ItmValDataset.get_batch"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._has_overlap": [[34, 39], ["set", "any", "len", "len"], "function", ["None"], ["img_feat", "=", "batch", "[", "'img_feat'", "]", "\n", "img_pos_feat", "=", "batch", "[", "'img_pos_feat'", "]", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "sequence_output", "=", "self", ".", "uniter", "(", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.sample_negative": [[41, 47], ["itm._has_overlap", "random.sample"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._has_overlap"], ["output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "uniter", ".", "pooler", "(", "sequence_output", ")", "\n", "rank_scores", "=", "self", ".", "rank_output", "(", "pooled_output", ")", "\n", "\n", "if", "compute_loss", ":", "\n", "# triplet loss", "\n", "            ", "rank_scores_sigmoid", "=", "torch", ".", "sigmoid", "(", "rank_scores", ")", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_collate": [[98, 126], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.cat", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], ["attention_mask", "=", "batch", "[", "'attn_masks'", "]", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", "\n", "hard_batch", "=", "{", "'sample_size'", ":", "self", ".", "hard_size", "+", "1", "}", "\n", "\n", "# NOTE first example is positive", "\n", "hard_indices", "=", "scores", ".", "squeeze", "(", "-", "1", ")", "[", "1", ":", "]", ".", "topk", "(", "\n", "self", ".", "hard_size", ",", "sorted", "=", "False", ")", "[", "1", "]", "+", "1", "\n", "indices", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "hard_indices", ".", "device", ")", ",", "\n", "hard_indices", "]", ")", "\n", "\n", "attention_mask", "=", "attention_mask", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "gather_index", "=", "gather_index", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "if", "position_ids", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "            ", "position_ids", "=", "position_ids", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "\n", "", "if", "sample_from", "==", "'t'", ":", "\n", "# cut to minimum padding", "\n", "            ", "max_len", "=", "attention_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "max_i", "=", "max_len", "-", "input_ids", ".", "size", "(", "1", ")", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", ":", "max_len", "]", "\n", "gather_index", "=", "gather_index", "[", ":", ",", ":", "max_len", "]", "\n", "img_feat", "=", "img_feat", ".", "index_select", "(", "0", ",", "indices", ")", "[", ":", ",", ":", "max_i", ",", ":", "]", "\n", "img_pos_feat", "=", "img_pos_feat", ".", "index_select", "(", "0", ",", "indices", ")", "[", ":", ",", ":", "max_i", ",", ":", "]", "\n", "# expect same input_ids for all pairs", "\n", "input_ids", "=", "input_ids", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "", "elif", "sample_from", "==", "'i'", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "index_select", "(", "0", ",", "indices", ")", "\n", "# expect same image features for all pairs", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._compute_ot_scatter": [[128, 136], ["torch.arange().unsqueeze().repeat", "enumerate", "len", "torch.arange().unsqueeze", "torch.arange", "torch.arange"], "function", ["None"], ["img_pos_feat", "=", "img_pos_feat", "[", ":", "self", ".", "hard_size", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "", "hard_batch", "[", "'input_ids'", "]", "=", "input_ids", "\n", "hard_batch", "[", "'position_ids'", "]", "=", "position_ids", "\n", "hard_batch", "[", "'img_feat'", "]", "=", "img_feat", "\n", "hard_batch", "[", "'img_pos_feat'", "]", "=", "img_pos_feat", "\n", "hard_batch", "[", "'attn_masks'", "]", "=", "attention_mask", "\n"]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._compute_pad": [[138, 143], ["torch.zeros", "enumerate", "len", "torch.zeros.data[].fill_"], "function", ["None"], ["\n", "return", "hard_batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_ot_collate": [[145, 185], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "torch.cat", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "max", "max", "itm._compute_ot_scatter", "itm._compute_pad", "itm._compute_pad", "toolz.sandbox.unzip", "i.size", "f.size", "torch.nn.utils.rnn.pad_sequence.size", "_compute_ot_scatter.max().item", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size", "_compute_ot_scatter.max"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._compute_ot_scatter", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._compute_pad", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm._compute_pad"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_rank_collate": [[240, 269], ["map", "torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "data.pad_tensors", "data.pad_tensors", "torch.nn.utils.rnn.pad_sequence", "len", "all", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "data.get_gather_index", "toolz.sandbox.unzip", "i.size", "f.size", "cytoolz.concat", "torch.arange", "torch.nn.utils.rnn.pad_sequence.size", "len"], "function", ["home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.pad_tensors", "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.data.get_gather_index"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_rank_hn_collate": [[372, 375], ["len"], "function", ["None"], []], "home.repos.pwc.inspect_result.ChenRocks_UNITER.data.itm.itm_val_collate": [[449, 452], ["len"], "function", ["None"], []]}