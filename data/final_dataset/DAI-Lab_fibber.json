{"home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.__init__": [[16, 80], ["object.__init__", "fibber.metrics.MetricBundle", "fibber.Fibber._strategy.fit", "fibber.datasets.dataset_utils.get_dataset", "fibber.datasets.dataset_utils.verify_dataset", "fibber.datasets.dataset_utils.verify_dataset", "fibber.paraphrase_strategies.RandomStrategy", "fibber.paraphrase_strategies.IdentityStrategy", "fibber.paraphrase_strategies.TextAttackStrategy", "fibber.paraphrase_strategies.ASRSStrategy", "logger.error", "logger.error"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_name", ",", "field", "=", "\"text0\"", ",", "\n", "trainset", "=", "None", ",", "testset", "=", "None", ",", "output_dir", "=", "\".\"", ",", "bert_clf_steps", "=", "5000", ")", ":", "\n", "        ", "\"\"\"Initialize\n\n        Args:\n            arg_dict (dict): a dict of hyper parameters for the MetricBundle and strategy.\n            dataset_name (str): the name of the dataset.\n            strategy_name (str): the strategy name.\n            field (str):\n            trainset (dict): fibber dataset.\n            testset (dict): fibber testset.\n            output_dir (str): directory to cache the strategy.\n        \"\"\"", "\n", "super", "(", "Fibber", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_field", "=", "field", "\n", "# setup dataset", "\n", "if", "dataset_name", "in", "builtin_datasets", ":", "\n", "            ", "if", "trainset", "is", "not", "None", "or", "testset", "is", "not", "None", ":", "\n", "                ", "logger", ".", "error", "(", "(", "\"dataset name %d conflict with builtin dataset. \"", "\n", "\"set trainset and testset to None.\"", ")", "%", "dataset_name", ")", "\n", "raise", "RuntimeError", "\n", "", "trainset", ",", "testset", "=", "get_dataset", "(", "dataset_name", ")", "\n", "", "else", ":", "\n", "            ", "verify_dataset", "(", "trainset", ")", "\n", "verify_dataset", "(", "testset", ")", "\n", "\n", "", "self", ".", "_metric_bundle", "=", "MetricBundle", "(", "\n", "field", "=", "field", ",", "\n", "enable_transformer_classifier", "=", "True", ",", "\n", "enable_bert_perplexity", "=", "True", ",", "\n", "enable_gpt2_perplexity", "=", "False", ",", "\n", "enable_glove_similarity", "=", "False", ",", "\n", "bert_ppl_gpu_id", "=", "arg_dict", "[", "\"bert_ppl_gpu_id\"", "]", ",", "\n", "use_gpu_id", "=", "arg_dict", "[", "\"use_gpu_id\"", "]", ",", "\n", "transformer_gpu_id", "=", "arg_dict", "[", "\"transformer_clf_gpu_id\"", "]", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "trainset", "=", "trainset", ",", "testset", "=", "testset", ",", "\n", "transformer_clf_steps", "=", "bert_clf_steps", ")", "\n", "\n", "strategy_gpu_id", "=", "arg_dict", "[", "\"strategy_gpu_id\"", "]", "\n", "if", "strategy_name", "==", "\"RandomStrategy\"", ":", "\n", "            ", "self", ".", "_strategy", "=", "RandomStrategy", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "\n", "self", ".", "_metric_bundle", ",", "field", "=", "field", ")", "\n", "", "if", "strategy_name", "==", "\"IdentityStrategy\"", ":", "\n", "            ", "self", ".", "_strategy", "=", "IdentityStrategy", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "\n", "self", ".", "_metric_bundle", ",", "field", "=", "field", ")", "\n", "", "if", "strategy_name", "==", "\"TextAttackStrategy\"", ":", "\n", "            ", "self", ".", "_strategy", "=", "TextAttackStrategy", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "\n", "self", ".", "_metric_bundle", ",", "field", "=", "field", ")", "\n", "", "if", "strategy_name", "==", "\"ASRSStrategy\"", ":", "\n", "            ", "self", ".", "_strategy", "=", "ASRSStrategy", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "\n", "self", ".", "_metric_bundle", ",", "field", "=", "field", ")", "\n", "", "if", "self", ".", "_strategy", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "\"unknown strategy name %s.\"", "%", "strategy_name", ")", "\n", "raise", "RuntimeError", "\n", "\n", "", "self", ".", "_strategy", ".", "fit", "(", "trainset", ")", "\n", "\n", "self", ".", "_trainset", "=", "trainset", "\n", "self", ".", "_testset", "=", "testset", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.paraphrase": [[81, 98], ["fibber.Fibber._strategy.paraphrase_example", "metrics.append", "fibber.Fibber._metric_bundle.measure_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example"], ["", "def", "paraphrase", "(", "self", ",", "data_record", ",", "n", "=", "20", ")", ":", "\n", "        ", "\"\"\"Paraphrase a given data record.\n\n        Args:\n            data_record (dict): data record to be paraphrased.\n            n (int): number of paraphrases.\n\n        Returns:\n            * a list of str as paraphrased sentences.\n            * a list of dict as corresponding metrics.\n        \"\"\"", "\n", "paraphrases", ",", "_", "=", "self", ".", "_strategy", ".", "paraphrase_example", "(", "data_record", ",", "n", ")", "\n", "metrics", "=", "[", "]", "\n", "for", "item", "in", "paraphrases", ":", "\n", "            ", "metrics", ".", "append", "(", "self", ".", "_metric_bundle", ".", "measure_example", "(", "\n", "data_record", "[", "self", ".", "_field", "]", ",", "item", ",", "data_record", ")", ")", "\n", "", "return", "data_record", "[", "self", ".", "_field", "]", ",", "paraphrases", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.paraphrase_a_random_sentence": [[99, 118], ["numpy.random.choice", "fibber.Fibber.paraphrase"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.paraphrase"], ["", "def", "paraphrase_a_random_sentence", "(", "self", ",", "n", "=", "20", ",", "from_testset", "=", "True", ")", ":", "\n", "        ", "\"\"\"Randomly pick one data, then paraphrase it.\n\n        Args:\n            n (int): number of paraphrases.\n            from_testset (bool): if true, select data from test set, otherwise from training set.\n\n        Returns:\n            * a str as the original text.\n            * a list of str as the paraphrased text.\n            * a list of dict as corresponding metrics.\n        \"\"\"", "\n", "dataset", "=", "self", ".", "_testset", "if", "from_testset", "else", "self", ".", "_trainset", "\n", "\n", "data_record", "=", "np", ".", "random", ".", "choice", "(", "dataset", "[", "\"data\"", "]", ")", "\n", "\n", "_", ",", "paraphrases", ",", "metrics", "=", "self", ".", "paraphrase", "(", "data_record", ",", "n", "=", "n", ")", "\n", "\n", "return", "data_record", "[", "self", ".", "_field", "]", ",", "paraphrases", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.get_metric_bundle": [[119, 122], ["None"], "methods", ["None"], ["", "def", "get_metric_bundle", "(", "self", ")", ":", "\n", "        ", "\"\"\"\"Get the metric bundle.\"\"\"", "\n", "return", "self", ".", "_metric_bundle", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.check_file_md5": [[15, 31], ["hashlib.md5", "os.path.exists", "open", "iter", "hashlib.md5.hexdigest", "hashlib.md5.update", "f.read"], "function", ["None"], ["def", "check_file_md5", "(", "filename", ",", "md5", ")", ":", "\n", "    ", "\"\"\"Check if the md5 of a given file is correct.\n\n    Args:\n        filename (str): a filename.\n        md5 (str): expected md5 hash value.\n    Returns:\n        (bool): Return True if md5 matches\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "return", "False", "\n", "", "hash_md5", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "for", "chunk", "in", "iter", "(", "lambda", ":", "f", ".", "read", "(", "4096", ")", ",", "b\"\"", ")", ":", "\n", "            ", "hash_md5", ".", "update", "(", "chunk", ")", "\n", "", "", "return", "hash_md5", ".", "hexdigest", "(", ")", "==", "md5", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file": [[33, 71], ["fibber.get_root_dir", "os.makedirs", "os.path.join", "os.path.join", "os.path.exists", "download_utils.check_file_md5", "logger.info", "logger.info", "tensorflow.keras.utils.get_file", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.check_file_md5"], ["", "def", "download_file", "(", "filename", ",", "url", ",", "md5", ",", "subdir", "=", "None", ",", "untar", "=", "False", ",", "unzip", "=", "False", ",", "abs_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download file from a given url.\n\n    This downloads a file to ``<fibber_root_dir>/subdir``. If the file already exists and the md5\n    matches, using the existing file.\n\n    Args:\n        filename (str): filename as a string.\n        url (str): the url to download the file.\n        md5 (str): the md5 checksum of the file.\n        subdir (str): the subdir to save the file. Dir will be created if not exists.\n        untar (bool): whether to untar the file.\n        unzip (bool): whether to unzip the file.\n        abs_path (str): a folder to download files. (ignore fibber_root_dir)\n    \"\"\"", "\n", "target_dir", "=", "get_root_dir", "(", ")", "\n", "if", "subdir", "is", "not", "None", ":", "\n", "        ", "target_dir", "=", "os", ".", "path", ".", "join", "(", "target_dir", ",", "subdir", ")", "\n", "", "if", "abs_path", "is", "not", "None", ":", "\n", "        ", "target_dir", "=", "abs_path", "\n", "", "os", ".", "makedirs", "(", "target_dir", ",", "exist_ok", "=", "True", ")", "\n", "target_file_absolute_path", "=", "os", ".", "path", ".", "join", "(", "target_dir", ",", "filename", ")", "\n", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "target_file_absolute_path", ")", "\n", "and", "check_file_md5", "(", "target_file_absolute_path", ",", "md5", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Load %s from cache. md5 checksum is correct.\"", ",", "filename", ")", "\n", "if", "untar", ":", "\n", "            ", "my_tar", "=", "tarfile", ".", "open", "(", "target_file_absolute_path", ")", "\n", "my_tar", ".", "extractall", "(", "target_dir", ")", "\n", "my_tar", ".", "close", "(", ")", "\n", "", "if", "unzip", ":", "\n", "            ", "my_zip", "=", "zipfile", ".", "ZipFile", "(", "target_file_absolute_path", ",", "\"r\"", ")", "\n", "my_zip", ".", "extractall", "(", "target_dir", ")", "\n", "my_zip", ".", "close", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Download %s to %s\"", ",", "filename", ",", "target_dir", ")", "\n", "tf_get_file", "(", "filename", ",", "origin", "=", "url", ",", "cache_subdir", "=", "\"\"", ",", "\n", "file_hash", "=", "md5", ",", "extract", "=", "untar", "or", "unzip", ",", "cache_dir", "=", "target_dir", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.setup_custom_logger": [[7, 17], ["logging.getLogger", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.setLevel", "getattr"], "function", ["None"], ["def", "setup_custom_logger", "(", "name", ",", "level", "=", "\"INFO\"", ")", ":", "\n", "    ", "\"\"\"Get a logger.\"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "\n", "handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "handler", ".", "setFormatter", "(", "G_FORMATTER", ")", "\n", "logger", ".", "addHandler", "(", "handler", ")", "\n", "\n", "logger", ".", "setLevel", "(", "getattr", "(", "logging", ",", "level", ")", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.add_file_handler": [[19, 24], ["logging.FileHandler", "logging.FileHandler.setFormatter", "logger.root.addHandler"], "function", ["None"], ["", "def", "add_file_handler", "(", "logger", ",", "filename", ")", ":", "\n", "    ", "\"\"\"Add file handler to a logger.\"\"\"", "\n", "file_handler", "=", "logging", ".", "FileHandler", "(", "filename", ")", "\n", "file_handler", ".", "setFormatter", "(", "G_FORMATTER", ")", "\n", "logger", ".", "root", ".", "addHandler", "(", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler": [[26, 33], ["isinstance"], "function", ["None"], ["", "def", "remove_logger_tf_handler", "(", "logger", ")", ":", "\n", "    ", "\"\"\"Remove all handlers except file handler.\n\n    This function can clean up the mess caused by tensorflow_hub.\n    \"\"\"", "\n", "logger", ".", "root", ".", "handlers", "=", "[", "item", "for", "item", "in", "logger", ".", "root", ".", "handlers", "\n", "if", "isinstance", "(", "item", ",", "logging", ".", "FileHandler", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir": [[12, 17], ["os.path.join", "os.makedirs", "os.path.expanduser"], "function", ["None"], ["def", "get_root_dir", "(", ")", ":", "\n", "    ", "\"\"\"Return ``~/.fibber``, the root dir for fibber to store datasets and common resources.\"\"\"", "\n", "root_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'~'", ")", ",", "\".fibber\"", ")", "\n", "os", ".", "makedirs", "(", "root_dir", ",", "exist_ok", "=", "True", ")", "\n", "return", "root_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.load_glove_model": [[13, 46], ["open().readlines", "numpy.zeros", "logger.info", "tqdm.tqdm", "line.split", "numpy.array", "id_to_tok.append", "open", "len", "float"], "function", ["None"], ["def", "load_glove_model", "(", "glove_file", ",", "dim", ")", ":", "\n", "    ", "\"\"\"Load glove embeddings from txt file.\n\n    Args:\n        glove_file: filename.\n        dim: the dimension of the embedding.\n\n    Returns:\n        a dict:\n            \"emb_table\": a numpy array of size(N, 300)\n            \"id2tok\": a list of strings.\n            \"tok2id\": a dict that maps word (string) to its id.\n    \"\"\"", "\n", "glove_file_lines", "=", "open", "(", "glove_file", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", ".", "readlines", "(", ")", "\n", "\n", "emb_table", "=", "np", ".", "zeros", "(", "(", "len", "(", "glove_file_lines", ")", ",", "dim", ")", ",", "dtype", "=", "'float32'", ")", "\n", "id_to_tok", "=", "[", "]", "\n", "tok_to_id", "=", "{", "}", "\n", "\n", "logger", ".", "info", "(", "\"Load glove embeddings as np array.\"", ")", "\n", "id", "=", "0", "\n", "for", "line", "in", "tqdm", ".", "tqdm", "(", "glove_file_lines", ")", ":", "\n", "        ", "split_line", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "split_line", "[", "0", "]", "\n", "emb_table", "[", "id", "]", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "split_line", "[", "1", ":", "]", "]", ")", "\n", "id_to_tok", ".", "append", "(", "word", ")", "\n", "tok_to_id", "[", "word", "]", "=", "id", "\n", "id", "+=", "1", "\n", "\n", "", "return", "{", "\n", "\"emb_table\"", ":", "emb_table", ",", "\n", "\"id2tok\"", ":", "id_to_tok", ",", "\n", "\"tok2id\"", ":", "tok_to_id", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_glove_emb": [[49, 73], ["fibber.download_utils.get_root_dir", "os.path.join", "resource_utils.load_glove_model", "os.path.exists", "fibber.download_utils.download_file", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.load_glove_model", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_glove_emb", "(", "download_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Download default pretrained glove embeddings and return a dict.\n\n    We use the 300-dimensional model trained on Wikipedia 2014 + Gigaword 5.\n    See https://nlp.stanford.edu/projects/glove/\n\n    Args:\n        download_only (bool): set True to only download. (Returns None)\n\n    Returns:\n        (dict): a dict of GloVe word embedding model.\n            \"emb_table\": a numpy array of size(N, 300)\n            \"id2tok\": a list of strings.\n            \"tok2id\": a dict that maps word (string) to its id.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"glove.6B.300d.txt\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"default-glove-embeddings\"", "]", ")", "\n", "\n", "", "if", "download_only", ":", "\n", "        ", "return", "None", "\n", "", "return", "load_glove_model", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"glove.6B.300d.txt\"", ")", ",", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_counter_fitted_vector": [[75, 98], ["fibber.download_utils.get_root_dir", "os.path.join", "resource_utils.load_glove_model", "os.path.exists", "fibber.download_utils.download_file", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.load_glove_model", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_counter_fitted_vector", "(", "download_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Download default pretrained counter fitted embeddings and return a dict.\n\n    See https://github.com/nmrksic/counter-fitting\n\n    Args:\n        download_only (bool): set True to only download. (Returns None)\n\n    Returns:\n        (dict): a dict of GloVe word embedding model.\n            \"emb_table\": a numpy array of size(N, 300)\n            \"id2tok\": a list of strings.\n            \"tok2id\": a dict that maps word (string) to its id.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"counter-fitted-vectors.txt\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"counter-fitted-vectors\"", "]", ")", "\n", "\n", "", "if", "download_only", ":", "\n", "        ", "return", "None", "\n", "", "return", "load_glove_model", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"counter-fitted-vectors.txt\"", ")", ",", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_stopwords": [[100, 115], ["fibber.download_utils.get_root_dir", "os.path.join", "fibber.download_utils.download_file", "open", "f.readlines", "x.strip().lower", "os.path.join", "os.path.join", "x.strip"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_stopwords", "(", ")", ":", "\n", "    ", "\"\"\"Download default stopword words.\n\n    Returns:\n        ([str]): a list of strings.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ")", "\n", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"default-stopwords\"", "]", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"stopwords.txt\"", ")", ")", "as", "f", ":", "\n", "        ", "stopwords", "=", "f", ".", "readlines", "(", ")", "\n", "", "stopwords", "=", "[", "x", ".", "strip", "(", ")", ".", "lower", "(", ")", "for", "x", "in", "stopwords", "]", "\n", "return", "stopwords", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_nltk_data": [[117, 130], ["fibber.download_utils.get_root_dir", "os.path.join", "fibber.download_utils.get_root_dir", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.exists", "fibber.download_utils.download_file", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_nltk_data", "(", ")", ":", "\n", "    ", "\"\"\"Download nltk data to ``<fibber_root_dir>/nltk_data``.\"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ",", "\"nltk_data\"", ",", "\"tokenizers\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"punkt\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"nltk-punkt\"", "]", ")", "\n", "\n", "", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ",", "\"nltk_data\"", ",", "\"corpora\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"stopwords\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"nltk_stopwords\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_universal_sentence_encoder": [[132, 146], ["fibber.download_utils.get_root_dir", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "", "def", "get_universal_sentence_encoder", "(", ")", ":", "\n", "    ", "\"\"\"Download pretrained universal sentence encoder.\n\n    Returns:\n        (str): directory of the downloaded model.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ",", "\"tfhub_pretrained\"", ",", "\n", "\"universal-sentence-encoder-large_5\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_dir", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "\"universal-sentence-encoder\"", "]", ")", "\n", "\n", "", "return", "data_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers": [[148, 165], ["fibber.download_utils.get_root_dir", "os.path.join", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_transformers", "(", "name", ")", ":", "\n", "    ", "\"\"\"Download pretrained transformer models.\n\n    Args:\n        name (str): the name of the pretrained models. options are ``[\"bert-base-cased\",\n            \"bert-base-uncased\", \"gpt2-medium\"]``.\n\n    Returns:\n        (str): directory of the downloaded model.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"common\"", ",", "\"transformers_pretrained\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "name", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ")", ",", "\n", "**", "downloadable_resource_urls", "[", "name", "]", ")", "\n", "\n", "", "return", "os", ".", "path", ".", "join", "(", "data_dir", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_bert_clf_demo": [[167, 174], ["fibber.download_utils.get_root_dir", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "def", "get_bert_clf_demo", "(", ")", ":", "\n", "    ", "\"\"\"Download the pretrained classifier for demo dataset.\"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"transformer_clf\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"demo\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "data_dir", ",", "\n", "**", "downloadable_resource_urls", "[", "\"bert-base-cased-clf-demo\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_bert_lm_demo": [[176, 183], ["fibber.download_utils.get_root_dir", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "", "def", "get_bert_lm_demo", "(", ")", ":", "\n", "    ", "\"\"\"Download the pretrained language model for demo dataset.\"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"bert_lm\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"demo\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "data_dir", ",", "\n", "**", "downloadable_resource_urls", "[", "\"bert-base-cased-lm-demo\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_wordpiece_emb_demo": [[185, 191], ["fibber.download_utils.get_root_dir", "os.path.join", "os.path.exists", "fibber.download_utils.download_file", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file"], ["", "", "def", "get_wordpiece_emb_demo", "(", ")", ":", "\n", "    ", "\"\"\"Download wordpiece embeddings for demo dataset.\"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"wordpiece_emb_conterfited\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"wordpiece_emb-demo-0500.pt\"", ")", ")", ":", "\n", "        ", "download_file", "(", "subdir", "=", "data_dir", ",", "**", "downloadable_resource_urls", "[", "\"wpe-demo\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.download_resources.download_all": [[6, 12], ["fibber.resources.resource_utils.get_nltk_data", "fibber.resources.resource_utils.get_glove_emb", "fibber.resources.resource_utils.get_transformers", "fibber.resources.resource_utils.get_universal_sentence_encoder", "fibber.resources.resource_utils.get_stopwords"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_nltk_data", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_glove_emb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_universal_sentence_encoder", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_stopwords"], ["def", "download_all", "(", ")", ":", "\n", "    ", "get_nltk_data", "(", ")", "\n", "get_glove_emb", "(", "download_only", "=", "True", ")", "\n", "get_transformers", "(", "\"bert-base-cased\"", ")", "\n", "get_universal_sentence_encoder", "(", ")", "\n", "get_stopwords", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.download_resources.download_resources_for_demo": [[14, 22], ["fibber.resources.resource_utils.get_nltk_data", "fibber.resources.resource_utils.get_universal_sentence_encoder", "fibber.resources.resource_utils.get_stopwords", "fibber.resources.resource_utils.get_bert_clf_demo", "fibber.resources.resource_utils.get_bert_lm_demo", "fibber.resources.resource_utils.get_wordpiece_emb_demo"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_nltk_data", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_universal_sentence_encoder", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_stopwords", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_bert_clf_demo", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_bert_lm_demo", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_wordpiece_emb_demo"], ["", "def", "download_resources_for_demo", "(", ")", ":", "\n", "    ", "get_nltk_data", "(", ")", "\n", "get_universal_sentence_encoder", "(", ")", "\n", "get_stopwords", "(", ")", "\n", "\n", "get_bert_clf_demo", "(", ")", "\n", "get_bert_lm_demo", "(", ")", "\n", "get_wordpiece_emb_demo", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.DatasetForTransformers.__init__": [[248, 288], ["transformers.AutoTokenizer.from_pretrained", "fibber.resources.get_transformers", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["def", "__init__", "(", "self", ",", "dataset", ",", "model_init", ",", "batch_size", ",", "exclude", "=", "-", "1", ",", "\n", "masked_lm", "=", "False", ",", "masked_lm_ratio", "=", "0.2", ",", "autoregressive_lm", "=", "False", ",", "\n", "select_field", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize.\n\n        Args:\n            dataset (dict): a dataset dict.\n            model_init (str): the pre-trained model name. select from ``['bert-base-cased',\n                'bert-base-uncased', 'bert-large-cased', and 'bert-large-uncased']``.\n            batch_size (int): the batch size in each step.\n            exclude (int): exclude one category from the data.\n                Use -1 (default) to include all categories.\n            masked_lm (bool): whether to randomly replace words with mask tokens.\n            masked_lm_ratio (float): the ratio of random masks. Ignored when masked_lm is False.\n            select_field (None or str): select one field. None to use all available fields.\n        \"\"\"", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "\n", "self", ".", "_pad_tok_id", "=", "self", ".", "_tokenizer", ".", "pad_token_id", "\n", "\n", "self", ".", "_masked_lm", "=", "masked_lm", "\n", "self", ".", "_masked_lm_ratio", "=", "masked_lm_ratio", "\n", "self", ".", "_mask_tok_id", "=", "self", ".", "_tokenizer", ".", "mask_token_id", "\n", "\n", "if", "select_field", "is", "None", ":", "\n", "            ", "if", "\"text1\"", "not", "in", "dataset", "[", "\"data\"", "]", ":", "\n", "                ", "self", ".", "_field", "=", "\"text0\"", "\n", "", "else", ":", "\n", "                ", "self", ".", "_field", "=", "\"both\"", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_field", "=", "select_field", "\n", "\n", "", "self", ".", "_autoregressive_lm", "=", "autoregressive_lm", "\n", "if", "self", ".", "_autoregressive_lm", "and", "self", ".", "_masked_lm", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"masked_lm and autoregressive_lm are used at the same time.\"", ")", "\n", "\n", "", "self", ".", "_data", "=", "dataset", "[", "\"data\"", "]", "\n", "if", "exclude", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_data", "=", "[", "item", "for", "item", "in", "self", ".", "_data", "if", "item", "[", "\"label\"", "]", "!=", "exclude", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.DatasetForTransformers.__iter__": [[289, 352], ["torch.utils.data.get_worker_info", "RuntimeError", "numpy.random.choice", "numpy.asarray", "len", "dataset_utils.DatasetForTransformers._tokenizer", "dataset_utils.DatasetForTransformers._tokenizer", "numpy.zeros_like", "torch.tensor", "tuple", "numpy.random.rand", "numpy.asarray", "numpy.random.rand", "numpy.random.randint", "numpy.sum", "torch.tensor", "tuple", "RuntimeError", "torch.tensor", "tuple"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "not", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"worker is not allowed.\"", ")", "\n", "\n", "", "while", "True", ":", "\n", "            ", "data_records", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "_data", ",", "self", ".", "_batch_size", ")", "\n", "\n", "if", "self", ".", "_field", "==", "\"both\"", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "data_records", "]", ",", "\n", "[", "item", "[", "\"text1\"", "]", "for", "item", "in", "data_records", "]", ",", "\n", "return_tensors", "=", "\"np\"", ",", "\n", "padding", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "[", "item", "[", "self", ".", "_field", "]", "for", "item", "in", "data_records", "]", ",", "\n", "return_tensors", "=", "\"np\"", ",", "\n", "padding", "=", "True", ")", "\n", "\n", "", "texts", "=", "batch_input", "[", "\"input_ids\"", "]", "\n", "masks", "=", "batch_input", "[", "\"attention_mask\"", "]", "\n", "if", "\"token_type_ids\"", "in", "batch_input", ":", "\n", "                ", "tok_types", "=", "batch_input", "[", "\"token_type_ids\"", "]", "\n", "", "else", ":", "\n", "                ", "tok_types", "=", "np", ".", "zeros_like", "(", "masks", ")", "\n", "", "labels", "=", "np", ".", "asarray", "(", "[", "item", "[", "\"label\"", "]", "for", "item", "in", "data_records", "]", ")", "\n", "max_text_len", "=", "len", "(", "texts", "[", "0", "]", ")", "\n", "\n", "if", "not", "self", ".", "_masked_lm", "and", "not", "self", ".", "_autoregressive_lm", ":", "\n", "                ", "ret", "=", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "[", "texts", ",", "masks", ",", "tok_types", ",", "labels", "]", "]", "\n", "yield", "tuple", "(", "ret", ")", "\n", "", "elif", "self", ".", "_masked_lm", ":", "\n", "                ", "rand_t", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "_batch_size", ",", "max_text_len", ")", "\n", "masked_pos", "=", "(", "rand_t", "<", "self", ".", "_masked_lm_ratio", ")", "*", "masks", "\n", "\n", "# No mask on cls and sep.", "\n", "masked_pos", "[", ":", ",", "0", "]", "=", "0", "\n", "masked_pos", "*=", "np", ".", "asarray", "(", "texts", "!=", "self", ".", "_tokenizer", ".", "sep_token_id", ",", "dtype", "=", "\"int\"", ")", "\n", "\n", "if", "np", ".", "sum", "(", "masked_pos", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "lm_labels", "=", "(", "masked_pos", "*", "texts", "-", "100", "*", "(", "1", "-", "masked_pos", ")", ")", "\n", "rand_t", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "_batch_size", ",", "max_text_len", ")", "\n", "filling", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "_tokenizer", ".", "vocab_size", ",", "\n", "(", "self", ".", "_batch_size", ",", "max_text_len", ")", ")", "\n", "filling", "=", "(", "(", "rand_t", "<", "0.8", ")", "*", "self", ".", "_mask_tok_id", "\n", "+", "(", "rand_t", ">=", "0.8", ")", "*", "(", "rand_t", "<", "0.9", ")", "*", "filling", "\n", "+", "(", "rand_t", ">=", "0.9", ")", "*", "texts", ")", "\n", "texts", "=", "masked_pos", "*", "filling", "+", "(", "1", "-", "masked_pos", ")", "*", "texts", "\n", "\n", "ret", "=", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "[", "texts", ",", "masks", ",", "tok_types", ",", "labels", ",", "lm_labels", "]", "]", "\n", "yield", "tuple", "(", "ret", ")", "\n", "", "elif", "self", ".", "_autoregressive_lm", ":", "\n", "                ", "lm_labels", "=", "texts", "*", "masks", "-", "100", "*", "(", "1", "-", "masks", ")", "\n", "# shift lm labels", "\n", "lm_labels", "[", ":", ",", ":", "-", "1", "]", "=", "lm_labels", "[", ":", ",", "1", ":", "]", "\n", "lm_labels", "[", ":", ",", "-", "1", "]", "=", "-", "100", "\n", "\n", "ret", "=", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "[", "texts", ",", "masks", ",", "tok_types", ",", "labels", ",", "lm_labels", "]", "]", "\n", "yield", "tuple", "(", "ret", ")", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"unexpected branch.\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_dataset": [[57, 91], ["fibber.get_root_dir", "os.path.join", "os.path.join", "os.path.join", "logger.info", "logger.info", "logger.error", "open", "json.load", "open", "json.load", "len", "len", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load"], ["def", "get_dataset", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"Load dataset from fibber root directory.\n\n    Users should make sure the data is downloaded to the ``datasets`` folder in fibber root\n    dir (default: ``~/.fibber/datasets``). Otherwise, assertion error is raised.\n\n    Args:\n        dataset_name (str): the name of the dataset. See ``https://dai-lab.github.io/fibber/``\n            for a full list of built-in datasets.\n\n    Returns:\n        (dict, dict): the function returns a tuple of two dict, representing the training set and\n        test set respectively.\n    \"\"\"", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"datasets\"", ")", "\n", "\n", "train_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", ",", "\"train.json\"", ")", "\n", "test_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset_name", ",", "\"test.json\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_filename", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "test_filename", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"%s dataset not found.\"", ",", "dataset_name", ")", "\n", "assert", "0", ",", "(", "\"Please use `python3 -m fibber.datasets.download_datasets` \"", "\n", "\"to download datasets.\"", ")", "\n", "\n", "", "with", "open", "(", "train_filename", ")", "as", "f", ":", "\n", "        ", "trainset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "test_filename", ")", "as", "f", ":", "\n", "        ", "testset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"%s training set has %d records.\"", ",", "dataset_name", ",", "len", "(", "trainset", "[", "\"data\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"%s test set has %d records.\"", ",", "dataset_name", ",", "len", "(", "testset", "[", "\"data\"", "]", ")", ")", "\n", "return", "trainset", ",", "testset", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_demo_dataset": [[93, 113], ["fibber.download_utils.download_file", "fibber.get_root_dir", "os.path.join", "logger.info", "logger.info", "open", "json.load", "open", "json.load", "len", "len", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.download_utils.download_file", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load"], ["", "def", "get_demo_dataset", "(", ")", ":", "\n", "    ", "\"\"\"download demo dataset.\n\n    Returns:\n        (dict, dict): trainset and testset.\n    \"\"\"", "\n", "download_file", "(", "subdir", "=", "\"\"", ",", "**", "downloadable_dataset_urls", "[", "\"mr-demo\"", "]", ")", "\n", "\n", "data_dir", "=", "get_root_dir", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"mr-demo\"", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.json\"", ")", ")", "as", "f", ":", "\n", "        ", "trainset", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.json\"", ")", ")", "as", "f", ":", "\n", "        ", "testset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Demo training set has %d records.\"", ",", "len", "(", "trainset", "[", "\"data\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"Demo test set has %d records.\"", ",", "len", "(", "testset", "[", "\"data\"", "]", ")", ")", "\n", "\n", "return", "trainset", ",", "testset", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.text_md5": [[115, 120], ["hashlib.md5", "hashlib.md5.update", "hashlib.md5.hexdigest", "x.encode"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["", "def", "text_md5", "(", "x", ")", ":", "\n", "    ", "\"\"\"Computes and returns the md5 hash of a str.\"\"\"", "\n", "m", "=", "hashlib", ".", "md5", "(", ")", "\n", "m", ".", "update", "(", "x", ".", "encode", "(", "'utf8'", ")", ")", "\n", "return", "m", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.subsample_dataset": [[122, 168], ["dict", "enumerate", "range", "len", "copy.deepcopy", "len", "bins[].append", "len", "numpy.random.shuffle", "range", "min", "data_list.append", "dataset.items", "len", "len", "copy.deepcopy", "len"], "function", ["None"], ["", "def", "subsample_dataset", "(", "dataset", ",", "n", ",", "offset", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sub-sample a dataset to `n` examples.\n\n    Data is selected evenly and randomly from each category. Data in each category is sorted by\n    its md5 hash value. The top ``(n // k)`` examples from each category are included in the\n    sub-sampled dataset, where ``k`` is the number of categories.\n\n    If ``n`` is not divisible by ``k``, one more data is sampled from the first ``(n % k)``\n    categories.\n\n    If the dataset has less than ``n`` examples, a copy of the original dataset will be returned.\n\n    Args:\n        dataset (dict): a dataset dict.\n        n (int): the size of the sub-sampled dataset.\n        offset (int): dataset offset.\n\n    Returns:\n        (dict): a sub-sampled dataset as a dict.\n    \"\"\"", "\n", "if", "n", ">", "len", "(", "dataset", "[", "\"data\"", "]", ")", ":", "\n", "        ", "return", "copy", ".", "deepcopy", "(", "dataset", ")", "\n", "\n", "", "bins", "=", "[", "[", "]", "for", "i", "in", "dataset", "[", "\"label_mapping\"", "]", "]", "\n", "offset", "=", "offset", "//", "len", "(", "bins", ")", "\n", "\n", "subset", "=", "dict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "dataset", ".", "items", "(", ")", "if", "k", "!=", "\"data\"", "]", ")", "\n", "\n", "for", "idx", ",", "data", "in", "enumerate", "(", "dataset", "[", "\"data\"", "]", ")", ":", "\n", "        ", "label", "=", "data", "[", "\"label\"", "]", "\n", "text", "=", "data", "[", "\"text0\"", "]", "\n", "if", "\"text1\"", "in", "data", ":", "\n", "            ", "text", "+=", "data", "[", "\"text1\"", "]", "\n", "\n", "", "bins", "[", "label", "]", ".", "append", "(", "idx", ")", "\n", "\n", "", "data_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "bins", ")", ")", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "bins", "[", "i", "]", ")", "\n", "m", "=", "n", "//", "len", "(", "bins", ")", "+", "(", "1", "if", "i", "<", "n", "%", "len", "(", "bins", ")", "else", "0", ")", "\n", "for", "j", "in", "range", "(", "offset", ",", "min", "(", "offset", "+", "m", ",", "len", "(", "bins", "[", "i", "]", ")", ")", ")", ":", "\n", "            ", "data_list", ".", "append", "(", "copy", ".", "deepcopy", "(", "dataset", "[", "\"data\"", "]", "[", "bins", "[", "i", "]", "[", "j", "]", "]", ")", ")", "\n", "\n", "", "", "subset", "[", "\"data\"", "]", "=", "data_list", "\n", "\n", "return", "subset", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset": [[170, 192], ["len", "tqdm.tqdm"], "function", ["None"], ["", "def", "verify_dataset", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Verify if the dataset dict contains necessary fields.\n\n    Assertion error is raised if there are missing or incorrect fields.\n\n    Args:\n        dataset (dict): a dataset dict.\n    \"\"\"", "\n", "assert", "\"label_mapping\"", "in", "dataset", "\n", "\n", "num_labels", "=", "len", "(", "dataset", "[", "\"label_mapping\"", "]", ")", "\n", "counter", "=", "[", "0", "]", "*", "num_labels", "\n", "\n", "for", "data_record", "in", "tqdm", ".", "tqdm", "(", "dataset", "[", "\"data\"", "]", ")", ":", "\n", "        ", "assert", "\"label\"", "in", "data_record", "\n", "label", "=", "data_record", "[", "\"label\"", "]", "\n", "assert", "0", "<=", "label", "<", "num_labels", "\n", "counter", "[", "label", "]", "+=", "1", "\n", "assert", "\"text0\"", "in", "data_record", "\n", "\n", "", "for", "item", "in", "counter", ":", "\n", "        ", "assert", "item", ">", "0", ",", "\"empty class\"", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.clip_sentence": [[194, 207], ["transformers.AutoTokenizer.from_pretrained", "logger.info", "tqdm.tqdm", "fibber.resources.get_transformers", "AutoTokenizer.from_pretrained.tokenize", "AutoTokenizer.from_pretrained.convert_tokens_to_string", "AutoTokenizer.from_pretrained.tokenize", "AutoTokenizer.from_pretrained.convert_tokens_to_string", "len"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "", "def", "clip_sentence", "(", "dataset", ",", "model_init", ",", "max_len", ")", ":", "\n", "    ", "\"\"\"Inplace clipping sentences.\"\"\"", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "logger", ".", "info", "(", "\"clipping the dataset to %d tokens.\"", ",", "max_len", ")", "\n", "for", "data_record", "in", "tqdm", ".", "tqdm", "(", "dataset", "[", "\"data\"", "]", ")", ":", "\n", "        ", "s0", "=", "tokenizer", ".", "tokenize", "(", "data_record", "[", "\"text0\"", "]", ")", "\n", "s0", "=", "s0", "[", ":", "max_len", "]", "\n", "data_record", "[", "\"text0\"", "]", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "s0", ")", "\n", "\n", "if", "\"text1\"", "in", "data_record", ":", "\n", "            ", "s1", "=", "tokenizer", ".", "tokenize", "(", "data_record", "[", "\"text1\"", "]", ")", "\n", "s1", "=", "s1", "[", ":", "(", "max_len", "-", "len", "(", "s0", ")", ")", "]", "\n", "data_record", "[", "\"text1\"", "]", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "s1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.convert_to_data_list": [[45, 59], ["data_list.append"], "function", ["None"], ["def", "convert_to_data_list", "(", "dataset_split", ",", "config", ",", "omit_unlabeled_data", ")", ":", "\n", "    ", "data_list", "=", "[", "]", "\n", "for", "item", "in", "dataset_split", ":", "\n", "        ", "if", "omit_unlabeled_data", "and", "item", "[", "config", ".", "label", "]", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "tmp", "=", "{", "\n", "\"label\"", ":", "item", "[", "config", ".", "label", "]", ",", "\n", "\"text0\"", ":", "item", "[", "config", ".", "text0", "]", "\n", "}", "\n", "if", "config", ".", "text1", "is", "not", "None", ":", "\n", "            ", "tmp", "[", "\"text1\"", "]", ":", "item", "[", "config", ".", "text1", "]", "\n", "\n", "", "data_list", ".", "append", "(", "tmp", ")", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.process_huggingface_dataset": [[61, 99], ["datasets.load_dataset", "os.makedirs", "len", "process_dataset.convert_to_data_list", "sklearn.model_selection.train_test_split", "sorted", "sorted", "isinstance", "process_dataset.convert_to_data_list", "sorted", "len", "open", "json.dump", "open", "json.dump", "open", "json.dump", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.convert_to_data_list", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.convert_to_data_list"], ["", "def", "process_huggingface_dataset", "(", "config", ",", "output_path", ",", "omit_unlabeled_data", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_dataset", "(", "config", ".", "dataset", ",", "config", ".", "subset", ")", "\n", "os", ".", "makedirs", "(", "output_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "len", "(", "config", ".", "splits", ")", "==", "2", ":", "\n", "        ", "for", "fibber_split", "in", "config", ".", "splits", ":", "\n", "            ", "if", "isinstance", "(", "config", ".", "splits", ",", "dict", ")", ":", "\n", "                ", "split", "=", "config", ".", "splits", "[", "fibber_split", "]", "\n", "", "else", ":", "\n", "                ", "split", "=", "fibber_split", "\n", "", "fibber_dataset", "=", "{", "\n", "\"label_mapping\"", ":", "dataset", "[", "split", "]", ".", "features", "[", "config", ".", "label", "]", ".", "names", ",", "\n", "}", "\n", "data_list", "=", "convert_to_data_list", "(", "dataset", "[", "split", "]", ",", "config", ",", "omit_unlabeled_data", ")", "\n", "\n", "data_list", "=", "sorted", "(", "data_list", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "\"label\"", "]", ",", "x", "[", "\"text0\"", "]", ")", ")", "\n", "fibber_dataset", "[", "\"data\"", "]", "=", "data_list", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "f\"{fibber_split}.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "fibber_dataset", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "", "", "else", ":", "\n", "        ", "assert", "len", "(", "config", ".", "splits", ")", "==", "1", "\n", "split", "=", "config", ".", "splits", "[", "0", "]", "\n", "data_list", "=", "convert_to_data_list", "(", "dataset", "[", "split", "]", ",", "config", ",", "omit_unlabeled_data", ")", "\n", "train_list", ",", "test_list", "=", "train_test_split", "(", "data_list", ",", "test_size", "=", "0.2", ",", "random_state", "=", "42", ")", "\n", "train_list", "=", "sorted", "(", "train_list", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "\"label\"", "]", ",", "x", "[", "\"text0\"", "]", ")", ")", "\n", "test_list", "=", "sorted", "(", "test_list", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "\"label\"", "]", ",", "x", "[", "\"text0\"", "]", ")", ")", "\n", "fibber_trainset", "=", "{", "\n", "\"label_mapping\"", ":", "dataset", "[", "split", "]", ".", "features", "[", "config", ".", "label", "]", ".", "names", ",", "\n", "\"data\"", ":", "train_list", "\n", "}", "\n", "fibber_testset", "=", "{", "\n", "\"label_mapping\"", ":", "dataset", "[", "split", "]", ".", "features", "[", "config", ".", "label", "]", ".", "names", ",", "\n", "\"data\"", ":", "test_list", "\n", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "\"train.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "fibber_trainset", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "\"test.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "fibber_testset", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.main": [[101, 111], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "process_dataset.process_huggingface_dataset", "fibber.get_root_dir", "list", "dataset_configs.keys"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.process_dataset.process_huggingface_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "list", "(", "dataset_configs", ".", "keys", "(", ")", ")", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--omit_unlabeled_data\"", ",", "choices", "=", "[", "\"0\"", ",", "\"1\"", "]", ",", "default", "=", "\"1\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "config", "=", "dataset_configs", "[", "args", ".", "dataset", "]", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"datasets\"", ",", "args", ".", "dataset", ")", "\n", "process_huggingface_dataset", "(", "config", ",", "output_path", ",", "\n", "omit_unlabeled_data", "=", "args", ".", "omit_unlabeled_data", "==", "\"1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.WordPieceDataset.__init__": [[16, 31], ["fibber.resources.get_counter_fitted_vector", "logger.info", "tqdm.tqdm", "nltk.word_tokenize", "x.lower"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_counter_fitted_vector"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "_glove", "=", "get_counter_fitted_vector", "(", ")", "\n", "\n", "data", "=", "[", "]", "\n", "logger", ".", "info", "(", "\"processing data for wordpiece embedding training\"", ")", "\n", "for", "item", "in", "tqdm", ".", "tqdm", "(", "dataset", "[", "\"data\"", "]", ")", ":", "\n", "            ", "text", "=", "item", "[", "\"text0\"", "]", "\n", "if", "\"text1\"", "in", "item", ":", "\n", "                ", "text", "+=", "\" \"", "+", "item", "[", "\"text1\"", "]", "\n", "\n", "", "text_toks", "=", "word_tokenize", "(", "text", ")", "\n", "data", "+=", "[", "x", "for", "x", "in", "text_toks", "if", "x", ".", "lower", "(", ")", "in", "self", ".", "_glove", "[", "\"tok2id\"", "]", "]", "\n", "", "self", ".", "_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.WordPieceDataset.__len__": [[32, 34], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.WordPieceDataset.__getitem__": [[35, 46], ["numpy.zeros", "asrs_utils_wpe.WordPieceDataset._tokenizer.convert_tokens_to_ids", "asrs_utils_wpe.WordPieceDataset._tokenizer.tokenize", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "w.lower"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "w", "=", "self", ".", "_data", "[", "i", "]", "\n", "\n", "g_emb", "=", "self", ".", "_glove", "[", "\"emb_table\"", "]", "[", "self", ".", "_glove", "[", "\"tok2id\"", "]", "[", "w", ".", "lower", "(", ")", "]", "]", "\n", "\n", "comp", "=", "np", ".", "zeros", "(", "self", ".", "_tokenizer", ".", "vocab_size", ")", "\n", "for", "tok_id", "in", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "\n", "self", ".", "_tokenizer", ".", "tokenize", "(", "w", ")", ")", ":", "\n", "            ", "comp", "[", "tok_id", "]", "=", "1", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "comp", ")", ".", "float", "(", ")", ",", "torch", ".", "tensor", "(", "g_emb", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.get_wordpiece_emb": [[48, 124], ["os.path.join", "os.makedirs", "os.path.join", "os.path.exists", "asrs_utils_wpe.WordPieceDataset", "torch.utils.data.DataLoader", "torch.nn.Linear().to", "torch.optim.SGD", "torch.optim.lr_scheduler.StepLR", "nn.Linear().to.weight.data.zero_", "tokenizer.vocab.items", "logger.info", "logger.info", "tqdm.tqdm", "tqdm.tqdm.close", "nn.Linear().to.weight.data.cpu().numpy", "torch.save", "fibber.get_root_dir", "torch.load", "logger.info", "enumerate", "torch.nn.Linear", "nn.Linear().to.parameters", "w.lower", "torch.tensor().to", "comp.to.to", "target.to.to", "nn.Linear().to.", "losses.append", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "torch.optim.lr_scheduler.StepLR.step", "tqdm.tqdm.set_postfix", "tqdm.tqdm.update", "nn.Linear().to.weight.data.cpu", "loss.detach().cpu().numpy", "torch.tensor", "numpy.mean", "target.to.std().detach().cpu().numpy", "loss.detach().cpu", "target.to.std().detach().cpu", "loss.detach", "target.to.std().detach", "w.lower", "target.to.std"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load"], ["", "", "def", "get_wordpiece_emb", "(", "dataset_name", ",", "trainset", ",", "tokenizer", ",", "device", ",", "\n", "steps", "=", "5000", ",", "bs", "=", "1000", ",", "lr", "=", "1", ",", "lr_halve_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"Transfer GloVe embeddings to BERT vocabulary.\n\n    The transfered embeddings will be stored at ``~.fibber/wordpiece_emb_conterfited/\n    wordpiece_emb_<dataset>_<steps>.pt``.\n\n    Args:\n        dataset_name (str): dataset name.\n        trainset (dict): the dataset dist.\n        tokenizer (transformers.PreTrainedTokenizer): the tokenizer that specifies wordpieces.\n        device (torch.Device): a device to train the model.\n        steps (int): transfering steps.\n        bs (int): transfering batch size.\n        lr (str): transfering learning rate.\n        lr_halve_steps (int): steps to halve the learning rate.\n    Returns:\n        (np.array): a array of size (300, N) where N is the vocabulary size for a bert-base model.\n    \"\"\"", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"wordpiece_emb_conterfited\"", ")", "\n", "os", ".", "makedirs", "(", "filename", ",", "exist_ok", "=", "True", ")", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "filename", ",", "\"wordpiece_emb-%s-%04d.pt\"", "%", "(", "dataset_name", ",", "steps", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "filename", ")", "\n", "logger", ".", "info", "(", "\"load wordpiece embeddings from %s\"", ",", "filename", ")", "\n", "return", "state_dict", "[", "\"embs\"", "]", "\n", "\n", "", "dataset", "=", "WordPieceDataset", "(", "trainset", ",", "tokenizer", "=", "tokenizer", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "bs", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "0", ",", "drop_last", "=", "True", ")", "\n", "\n", "linear", "=", "nn", ".", "Linear", "(", "tokenizer", ".", "vocab_size", ",", "300", ",", "bias", "=", "False", ")", ".", "to", "(", "device", ")", "\n", "opt", "=", "torch", ".", "optim", ".", "SGD", "(", "lr", "=", "lr", ",", "momentum", "=", "0.5", ",", "\n", "params", "=", "linear", ".", "parameters", "(", ")", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "\n", "opt", ",", "step_size", "=", "lr_halve_steps", ",", "gamma", "=", "0.5", ")", "\n", "\n", "linear", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "cc", "=", "0", "\n", "for", "w", ",", "wid", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "        ", "if", "w", ".", "lower", "(", ")", "in", "dataset", ".", "_glove", "[", "\"tok2id\"", "]", ":", "\n", "            ", "cc", "+=", "1", "\n", "linear", ".", "weight", ".", "data", "[", ":", ",", "wid", "]", "=", "torch", ".", "tensor", "(", "\n", "dataset", ".", "_glove", "[", "\"emb_table\"", "]", "[", "dataset", ".", "_glove", "[", "\"tok2id\"", "]", "[", "w", ".", "lower", "(", ")", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "", "", "logger", ".", "info", "(", "\"Overlap bert and counter fitted vectors: %d\"", ",", "cc", ")", "\n", "\n", "logger", ".", "info", "(", "\"train word piece embeddings\"", ")", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "total", "=", "steps", ")", "\n", "losses", "=", "[", "]", "\n", "global_step", "=", "0", "\n", "while", "True", ":", "\n", "        ", "for", "idx", ",", "(", "comp", ",", "target", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "comp", "=", "comp", ".", "to", "(", "device", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ")", "\n", "pred_emb", "=", "linear", "(", "comp", ")", "\n", "loss", "=", "(", "(", "pred_emb", "-", "target", ")", ".", "abs", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "losses", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "losses", "=", "losses", "[", "-", "20", ":", "]", "\n", "\n", "pbar", ".", "set_postfix", "(", "loss", "=", "np", ".", "mean", "(", "losses", ")", ",", "std", "=", "target", ".", "std", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "global_step", "+=", "1", "\n", "if", "global_step", ">=", "steps", ":", "\n", "                ", "break", "\n", "", "", "if", "global_step", ">=", "steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "wordpiece_emb", "=", "linear", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "torch", ".", "save", "(", "{", "\"embs\"", ":", "wordpiece_emb", "}", ",", "filename", ")", "\n", "return", "wordpiece_emb", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.__init__": [[22, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "clf_metric", ",", "field", ")", ":", "\n", "        ", "self", ".", "model", "=", "clf_metric", "\n", "self", ".", "_field", "=", "field", "\n", "self", ".", "_data_record", "=", "None", "\n", "self", ".", "_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.get_pred": [[28, 30], ["openattack_strategy.MyClassifier.get_prob().argmax", "openattack_strategy.MyClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.get_prob"], ["", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.set_data_record": [[31, 33], ["data_record.copy"], "methods", ["None"], ["", "def", "set_data_record", "(", "self", ",", "data_record", ")", ":", "\n", "        ", "self", ".", "_data_record", "=", "data_record", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.reset_counter": [[34, 36], ["None"], "methods", ["None"], ["", "def", "reset_counter", "(", "self", ")", ":", "\n", "        ", "self", ".", "_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.get_counter": [[37, 39], ["None"], "methods", ["None"], ["", "def", "get_counter", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.MyClassifier.get_prob": [[41, 47], ["len", "openattack_strategy.MyClassifier.model.predict_log_dist_batch", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "        ", "self", ".", "_counter", "+=", "len", "(", "input_", ")", "\n", "ret", "=", "self", ".", "model", ".", "predict_log_dist_batch", "(", "\n", "self", ".", "_data_record", "[", "self", ".", "_field", "]", ",", "input_", ",", "\n", "data_record", "=", "self", ".", "_data_record", ",", "field", "=", "self", ".", "_field", ")", "\n", "return", "np", ".", "exp", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.OpenAttackStrategy.__init__": [[64, 70], ["fibber.paraphrase_strategies.strategy_base.StrategyBase.__init__", "logger.error"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", ":", "\n", "        ", "if", "\"oa\"", "not", "in", "sys", ".", "modules", ":", "\n", "            ", "logger", ".", "error", "(", "\"OpenAttack not installed. Please install OpenAttack manually.\"", ")", "\n", "raise", "RuntimeError", "\n", "", "super", "(", "OpenAttackStrategy", ",", "self", ")", ".", "__init__", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.OpenAttackStrategy.__repr__": [[71, 73], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_strategy_config", "[", "\"recipe\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.OpenAttackStrategy.fit": [[74, 77], ["openattack_strategy.MyClassifier", "openattack_strategy.OpenAttackStrategy._metric_bundle.get_target_classifier", "getattr"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_victim", "=", "MyClassifier", "(", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", ",", "self", ".", "_field", ")", "\n", "self", ".", "_attacker", "=", "getattr", "(", "oa", ".", "attackers", ",", "self", ".", "_strategy_config", "[", "\"recipe\"", "]", ")", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.openattack_strategy.OpenAttackStrategy.paraphrase_example": [[78, 87], ["openattack_strategy.OpenAttackStrategy._victim.set_data_record", "openattack_strategy.OpenAttackStrategy._victim.reset_counter", "oa.AttackEval", "next", "oa.AttackEval.ieval", "openattack_strategy.OpenAttackStrategy._victim.get_counter"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.set_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.reset_counter", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.get_counter"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "\"\"\"Generate paraphrased sentences.\"\"\"", "\n", "self", ".", "_victim", ".", "set_data_record", "(", "data_record", ")", "\n", "self", ".", "_victim", ".", "reset_counter", "(", ")", "\n", "\n", "attack_text", "=", "data_record", "[", "self", ".", "_field", "]", "\n", "attack_eval", "=", "oa", ".", "AttackEval", "(", "self", ".", "_attacker", ",", "self", ".", "_victim", ")", "\n", "res", "=", "next", "(", "attack_eval", ".", "ieval", "(", "[", "{", "\"x\"", ":", "attack_text", ",", "\"y\"", ":", "data_record", "[", "\"label\"", "]", "}", "]", ")", ")", "\n", "return", "[", "res", "[", "\"result\"", "]", "]", "if", "res", "[", "\"success\"", "]", "else", "[", "attack_text", "]", ",", "self", ".", "_victim", ".", "get_counter", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.batch_encode": [[35, 37], ["textattack_strategy.DefaultTokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["    ", "def", "batch_encode", "(", "self", ",", "texts", ")", ":", "\n", "        ", "return", "[", "self", ".", "encode", "(", "item", ")", "for", "item", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode": [[38, 40], ["nltk.word_tokenize"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "word_tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.__init__": [[45, 54], ["hasattr", "textattack_strategy.DefaultTokenizer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "clf_metric", ",", "field", ")", ":", "\n", "        ", "self", ".", "model", "=", "clf_metric", "\n", "self", ".", "_field", "=", "field", "\n", "if", "hasattr", "(", "clf_metric", ",", "\"_tokenizer\"", ")", ":", "\n", "            ", "self", ".", "_tokenizer", "=", "clf_metric", ".", "_tokenizer", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tokenizer", "=", "DefaultTokenizer", "(", ")", "\n", "", "self", ".", "_data_record", "=", "None", "\n", "self", ".", "_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.__call__": [[55, 61], ["len", "textattack_strategy.CLFModel.model.predict_log_dist_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "__call__", "(", "self", ",", "text_list", ")", ":", "\n", "        ", "self", ".", "_counter", "+=", "len", "(", "text_list", ")", "\n", "ret", "=", "self", ".", "model", ".", "predict_log_dist_batch", "(", "\n", "self", ".", "_data_record", "[", "self", ".", "_field", "]", ",", "text_list", ",", "data_record", "=", "self", ".", "_data_record", ")", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.reset_counter": [[62, 64], ["None"], "methods", ["None"], ["", "def", "reset_counter", "(", "self", ")", ":", "\n", "        ", "self", ".", "_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.get_counter": [[65, 67], ["None"], "methods", ["None"], ["", "def", "get_counter", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.set_data_record": [[68, 70], ["None"], "methods", ["None"], ["", "def", "set_data_record", "(", "self", ",", "data_record", ")", ":", "\n", "        ", "self", ".", "_data_record", "=", "data_record", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize": [[71, 78], ["hasattr", "textattack_strategy.CLFModel._tokenizer.batch_encode", "textattack_strategy.CLFModel._tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.batch_encode", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["", "def", "tokenize", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Helper method that calls ``tokenizer.batch_encode`` if possible, and\n        if not, falls back to calling ``tokenizer.encode`` for each input.\"\"\"", "\n", "if", "hasattr", "(", "self", ".", "_tokenizer", ",", "\"batch_encode\"", ")", ":", "\n", "            ", "return", "self", ".", "_tokenizer", ".", "batch_encode", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "_tokenizer", ".", "encode", "(", "x", ")", "for", "x", "in", "inputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.TextAttackStrategy.__init__": [[96, 102], ["fibber.paraphrase_strategies.strategy_base.StrategyBase.__init__", "logger.error"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", ":", "\n", "        ", "if", "\"textattack\"", "not", "in", "sys", ".", "modules", ":", "\n", "            ", "logger", ".", "error", "(", "\"TextAttack not installed. Please install textattack manually.\"", ")", "\n", "raise", "RuntimeError", "\n", "", "super", "(", "TextAttackStrategy", ",", "self", ")", ".", "__init__", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.TextAttackStrategy.__repr__": [[103, 105], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_strategy_config", "[", "\"recipe\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.TextAttackStrategy.fit": [[106, 113], ["textattack_strategy.CLFModel", "getattr().build", "RuntimeError", "textattack_strategy.TextAttackStrategy._metric_bundle.get_target_classifier", "getattr"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "if", "ModelWrapper", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"no internet connection.\"", ")", "\n", "\n", "", "self", ".", "_model", "=", "CLFModel", "(", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", ",", "self", ".", "_field", ")", "\n", "self", ".", "_recipe", "=", "getattr", "(", "attack_recipes", ",", "self", ".", "_strategy_config", "[", "\"recipe\"", "]", "\n", ")", ".", "build", "(", "self", ".", "_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.TextAttackStrategy.paraphrase_example": [[114, 140], ["textattack_strategy.TextAttackStrategy._model.set_data_record", "textattack_strategy.TextAttackStrategy._model.reset_counter", "signal.signal", "signal.alarm", "signal.alarm", "textattack_strategy.TextAttackStrategy._model.get_counter", "isinstance", "textattack_strategy.TextAttackStrategy._recipe.attack", "logger.warn", "logger.warn", "traceback.print_exc"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.set_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.reset_counter", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.get_counter"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "\"\"\"Generate paraphrased sentences.\"\"\"", "\n", "self", ".", "_model", ".", "set_data_record", "(", "data_record", ")", "\n", "\n", "self", ".", "_model", ".", "reset_counter", "(", ")", "\n", "\n", "attack_text", "=", "data_record", "[", "self", ".", "_field", "]", "\n", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGALRM", ",", "alarm_handler", ")", "\n", "signal", ".", "alarm", "(", "self", ".", "_strategy_config", "[", "\"time_limit\"", "]", ")", "\n", "try", ":", "\n", "            ", "att", "=", "self", ".", "_recipe", ".", "attack", "(", "attack_text", ",", "data_record", "[", "\"label\"", "]", ")", "\n", "", "except", "TimeOutException", ":", "\n", "            ", "logger", ".", "warn", "(", "\"Timeout.\"", ")", "\n", "att", "=", "None", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "logger", ".", "warn", "(", "\"TextAttack package failure.\"", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "att", "=", "None", "\n", "", "signal", ".", "alarm", "(", "0", ")", "\n", "\n", "clf_count", "=", "self", ".", "_model", ".", "get_counter", "(", ")", "\n", "if", "isinstance", "(", "att", ",", "textattack", ".", "attack_results", ".", "SuccessfulAttackResult", ")", ":", "\n", "            ", "return", "[", "att", ".", "perturbed_result", ".", "attacked_text", ".", "text", "]", ",", "clf_count", "\n", "", "else", ":", "\n", "            ", "return", "[", "data_record", "[", "self", ".", "_field", "]", "]", ",", "clf_count", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.alarm_handler": [[29, 32], ["print", "textattack_strategy.TimeOutException"], "function", ["None"], ["", "def", "alarm_handler", "(", "signum", ",", "frame", ")", ":", "\n", "    ", "print", "(", "\"ALARM signal received\"", ")", "\n", "raise", "TimeOutException", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.SSRSStrategy.__repr__": [[235, 237], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"-\"", "+", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.SSRSStrategy.fit": [[238, 265], ["logger.info", "fibber.metrics.bert_lm_utils.get_lm", "ssrs_strategy.SSRSStrategy._metric_bundle.get_metric", "ssrs_strategy.SSRSStrategy._metric_bundle.get_metric", "ssrs_strategy.SSRSStrategy._metric_bundle.get_target_classifier", "ssrs_strategy.SSRSStrategy._metric_bundle.get_metric"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "# load BERT language model.", "\n", "        ", "logger", ".", "info", "(", "\"Load bert language model for ASRSStrategy.\"", ")", "\n", "\n", "self", ".", "_tokenizer", ",", "self", ".", "_bert_lms", "=", "get_lm", "(", "\"adv\"", ",", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_device", ",", "\n", "lm_steps", "=", "self", ".", "_strategy_config", "[", "\"lm_steps\"", "]", ")", "\n", "\n", "# Load useful metrics", "\n", "self", ".", "_sim_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\n", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", ")", "\n", "self", ".", "_bleu_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"SelfBleuMetric\"", ")", "\n", "self", ".", "_clf_metric", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_ppl_metrics", "=", "[", "\n", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"BertPerplexityMetric-exclude-%s\"", "%", "label", ")", "\n", "for", "label", "in", "trainset", "[", "\"label_mapping\"", "]", "]", "\n", "\n", "# config _decision_fn and _enforcing_dist_fn", "\n", "if", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"all\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "all_accept_criteria", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"joint_weighted_criteria\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "joint_weighted_criteria", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "self", ".", "_stats", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"accept\"", ":", "0", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.SSRSStrategy.paraphrase_example": [[267, 269], ["ssrs_strategy.SSRSStrategy.paraphrase_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.paraphrase_multiple_examples"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "return", "self", ".", "paraphrase_multiple_examples", "(", "[", "data_record", "]", "*", "n", ")", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.SSRSStrategy.paraphrase_multiple_examples": [[270, 361], ["ssrs_strategy.SSRSStrategy._bert_lms[].to", "range", "logger.info", "ssrs_strategy.SSRSStrategy.cpu", "torch.masked_select().view", "ssrs_strategy.sample_word_from_logits", "ssrs_strategy.assign_cadidates", "ssrs_strategy.SSRSStrategy._decision_fn", "ssrs_strategy.SSRSStrategy._tokenizer.tokenize", "numpy.random.randint", "min", "numpy.random.choice", "ssrs_strategy.smart_mask", "n_masks.append", "paraphrases_with_mask.append", "ssrs_strategy.SSRSStrategy._tokenizer().to", "ssrs_strategy.SSRSStrategy._tokenizer().to", "ssrs_strategy.SSRSStrategy.", "logits_lm.size", "ssrs_strategy.SSRSStrategy._tokenizer.convert_ids_to_tokens", "max", "len", "ssrs_strategy.SSRSStrategy._tokenizer.convert_tokens_to_string", "torch.masked_select", "numpy.sum", "numpy.sum", "numpy.sum", "len", "ssrs_strategy.SSRSStrategy._tokenizer", "ssrs_strategy.SSRSStrategy._tokenizer", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.sample_word_from_logits", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.assign_cadidates", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.smart_mask"], ["", "def", "paraphrase_multiple_examples", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "bert_lm", "=", "self", ".", "_bert_lms", "[", "data_record_list", "[", "0", "]", "[", "\"label\"", "]", "]", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "origin", "=", "[", "item", "[", "self", ".", "_field", "]", "for", "item", "in", "data_record_list", "]", "\n", "paraphrases", "=", "origin", "[", ":", "]", "\n", "context", "=", "None", "if", "self", ".", "_field", "==", "\"text0\"", "else", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "data_record_list", "]", "\n", "\n", "sampling_steps", "=", "self", ".", "_strategy_config", "[", "\"sampling_steps\"", "]", "\n", "window_size", "=", "self", ".", "_strategy_config", "[", "\"window_size\"", "]", "\n", "\n", "decision_fn_state", "=", "None", "\n", "for", "ii", "in", "range", "(", "sampling_steps", ")", ":", "\n", "            ", "paraphrases_tokenized", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "sent", ")", "for", "sent", "in", "paraphrases", "]", "\n", "paraphrases_with_mask", "=", "[", "]", "\n", "n_masks", "=", "[", "]", "\n", "for", "toks", "in", "paraphrases_tokenized", ":", "\n", "                ", "st", "=", "np", ".", "random", ".", "randint", "(", "max", "(", "len", "(", "toks", ")", "-", "window_size", ",", "1", ")", ")", "\n", "ed", "=", "min", "(", "st", "+", "window_size", ",", "len", "(", "toks", ")", ")", "\n", "if", "st", "-", "ed", "<", "window_size", ":", "\n", "                    ", "choices", "=", "[", "0", ",", "1", "]", "\n", "p", "=", "[", "0.8", ",", "0.2", "]", "\n", "", "else", ":", "\n", "                    ", "choices", "=", "[", "-", "1", ",", "0", ",", "1", "]", "\n", "p", "=", "[", "0.1", ",", "0.8", ",", "0.1", "]", "\n", "", "op", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "p", ")", "\n", "masked_part", ",", "n_mask_tmp", "=", "smart_mask", "(", "toks", "[", "st", ":", "ed", "]", ",", "op", ")", "\n", "n_masks", ".", "append", "(", "n_mask_tmp", ")", "\n", "paraphrases_with_mask", ".", "append", "(", "\n", "self", ".", "_tokenizer", ".", "convert_tokens_to_string", "(", "\n", "toks", "[", ":", "st", "]", "+", "masked_part", "+", "toks", "[", "ed", ":", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "_field", "==", "\"text1\"", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "context", ",", "paraphrases_with_mask", ",", "padding", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "else", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "paraphrases_with_mask", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "", "logits_lm", "=", "bert_lm", "(", "**", "batch_input", ")", "[", "0", "]", "\n", "\n", "logits_for_masked_toks", "=", "torch", ".", "masked_select", "(", "\n", "logits_lm", ",", "(", "batch_input", ".", "input_ids", "==", "self", ".", "_tokenizer", ".", "mask_token_id", ")", ".", "unsqueeze", "(", "2", ")", "\n", ")", ".", "view", "(", "-", "1", ",", "logits_lm", ".", "size", "(", "2", ")", ")", "\n", "logits_for_masked_toks", "[", ":", ",", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "-", "1e8", "\n", "logits_for_masked_toks", "[", ":", ",", "self", ".", "_tokenizer", ".", "mask_token_id", "]", "=", "-", "1e8", "\n", "logits_for_masked_toks", "[", ":", ",", "self", ".", "_tokenizer", ".", "cls_token_id", "]", "=", "-", "1e8", "\n", "\n", "logits_joint", "=", "logits_for_masked_toks", "\n", "candidate_ids", "=", "sample_word_from_logits", "(", "\n", "logits_joint", ",", "top_k", "=", "self", ".", "_strategy_config", "[", "\"top_k\"", "]", ",", "\n", "temperature", "=", "self", ".", "_strategy_config", "[", "\"temperature\"", "]", ")", "\n", "\n", "candidate_paraphrases", "=", "assign_cadidates", "(", "\n", "paraphrases_with_mask", ",", "self", ".", "_tokenizer", ".", "convert_ids_to_tokens", "(", "candidate_ids", ")", ",", "\n", "self", ".", "_tokenizer", ")", "\n", "log_prob_previous_ids", "=", "0", "\n", "log_prob_candidate_ids", "=", "0", "\n", "\n", "paraphrases", ",", "decision_fn_state", "=", "self", ".", "_decision_fn", "(", "\n", "origin_list", "=", "origin", ",", "prev_paraphrases", "=", "paraphrases", ",", "\n", "candidate_paraphrases", "=", "candidate_paraphrases", ",", "\n", "data_record_list", "=", "data_record_list", ",", "\n", "field", "=", "self", ".", "_field", ",", "\n", "sim_metric", "=", "self", ".", "_sim_metric", ",", "\n", "sim_threshold", "=", "self", ".", "_strategy_config", "[", "\"sim_threshold\"", "]", ",", "\n", "sim_weight", "=", "self", ".", "_strategy_config", "[", "\"sim_weight\"", "]", ",", "\n", "clf_metric", "=", "self", ".", "_clf_metric", ",", "clf_weight", "=", "self", ".", "_strategy_config", "[", "\"clf_weight\"", "]", ",", "\n", "ppl_metric", "=", "self", ".", "_ppl_metrics", "[", "data_record_list", "[", "0", "]", "[", "\"label\"", "]", "]", ",", "\n", "ppl_weight", "=", "self", ".", "_strategy_config", "[", "\"ppl_weight\"", "]", ",", "\n", "stats", "=", "self", ".", "_stats", ",", "state", "=", "decision_fn_state", ",", "\n", "log_prob_trans_forward", "=", "log_prob_candidate_ids", ",", "\n", "log_prob_trans_backward", "=", "log_prob_previous_ids", ",", "\n", "bleu_metric", "=", "self", ".", "_bleu_metric", ",", "\n", "bleu_weight", "=", "self", ".", "_strategy_config", "[", "\"bleu_weight\"", "]", ",", "\n", "bleu_threshold", "=", "self", ".", "_strategy_config", "[", "\"bleu_threshold\"", "]", ")", "\n", "\n", "if", "(", "self", ".", "_strategy_config", "[", "\"early_stop\"", "]", "==", "\"half\"", "\n", "and", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", ">=", "len", "(", "data_record_list", ")", "*", "0.5", ")", ":", "\n", "                ", "break", "\n", "", "if", "(", "self", ".", "_strategy_config", "[", "\"early_stop\"", "]", "==", "\"one\"", "\n", "and", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", ">=", "1", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Aggregated accept rate: %.2lf%%. Success rate: %.2lf%%\"", ",", "\n", "self", ".", "_stats", "[", "\"accept\"", "]", "/", "self", ".", "_stats", "[", "\"all\"", "]", "*", "100", ",", "\n", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", "/", "len", "(", "data_record_list", ")", "*", "100", ")", "\n", "\n", "bert_lm", ".", "cpu", "(", ")", "\n", "\n", "return", "paraphrases", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.tostring": [[11, 19], ["tokenizer.decode"], "function", ["None"], ["def", "tostring", "(", "tokenizer", ",", "seq", ")", ":", "\n", "    ", "\"\"\"Convert a sequence of word ids to a sentence. The post prossing is applied.\n\n    Args:\n        tokenizer (transformers.BertTokenizer): a BERT tokenizer.\n        seq (list): a list-like sequence of word ids.\n    \"\"\"", "\n", "return", "tokenizer", ".", "decode", "(", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.sample_word_from_logits": [[21, 40], ["logits.topk", "torch.distributions.categorical.Categorical", "kth_idx.gather().squeeze", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.sample().squeeze", "kth_idx.gather", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample().unsqueeze", "torch.distributions.categorical.Categorical.sample"], "function", ["None"], ["", "def", "sample_word_from_logits", "(", "logits", ",", "temperature", "=", "1.", ",", "top_k", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sample a word from a distribution.\n\n    Args:\n        logits (torch.Tensor): tensor of logits with size ``(batch_size, vocab_size)``.\n        temperature (float): the temperature of softmax. The PMF is\n            ``softmax(logits/temperature)``.\n        top_k (int): if ``k>0``, only sample from the top k most probable words.\n    \"\"\"", "\n", "logits", "=", "logits", "/", "temperature", "\n", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "kth_vals", ",", "kth_idx", "=", "logits", ".", "topk", "(", "top_k", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "kth_vals", ")", "\n", "idx", "=", "kth_idx", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "dist", ".", "sample", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "logits", ")", "\n", "idx", "=", "dist", ".", "sample", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.all_accept_criteria": [[42, 46], ["None"], "function", ["None"], ["", "def", "all_accept_criteria", "(", "candidate_paraphrases", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Always accept proposed words.\n    \"\"\"", "\n", "return", "candidate_paraphrases", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.sim_criteria_score": [[48, 65], ["sim_metric.measure_multiple_examples", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples"], ["", "def", "sim_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        sim_metric (MetricBase): a similarity metric object.\n        sim_threshold (float): the universal sentence encoder similarity threshold.\n        sim_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "use_semantic_similarity", "=", "sim_metric", ".", "measure_multiple_examples", "(", "origin_list", ",", "paraphrases", ")", "\n", "return", "(", "-", "sim_weight", "*", "(", "\n", "np", ".", "maximum", "(", "sim_threshold", "-", "np", ".", "asarray", "(", "use_semantic_similarity", ")", ",", "0", ")", ")", ",", "\n", "use_semantic_similarity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.ppl_criteria_score": [[67, 82], ["ppl_metric.measure_multiple_examples", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples"], ["", "def", "ppl_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "ppl_metric", ",", "ppl_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        ppl_metric (GPT2PerplexityMetric): a GPT2PerplexityMetric metric object.\n        ppl_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "ppl_ratio", "=", "ppl_metric", ".", "measure_multiple_examples", "(", "origin_list", ",", "paraphrases", ",", "use_ratio", "=", "True", ")", "\n", "return", "(", "-", "ppl_weight", "*", "(", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "ppl_ratio", ")", ",", "0", ")", ")", ",", "\n", "ppl_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.bleu_criteria_score": [[84, 87], ["bleu_metric.measure_multiple_examples", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples"], ["", "def", "bleu_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "bleu_metric", ",", "bleu_weight", ",", "bleu_threshold", ")", ":", "\n", "    ", "bleu_score", "=", "bleu_metric", ".", "measure_multiple_examples", "(", "origin_list", ",", "paraphrases", ")", "\n", "return", "-", "bleu_weight", "*", "np", ".", "maximum", "(", "bleu_threshold", "-", "np", ".", "asarray", "(", "bleu_score", ")", ",", "0", ")", ",", "bleu_score", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.clf_criteria_score": [[89, 113], ["clf_metric.predict_log_dist_multiple_examples", "numpy.exp", "zip", "numpy.asarray", "numpy.zeros", "pred_dist[].copy", "numpy.max", "not_correct.append", "np.asarray.append", "numpy.asarray", "len", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], ["", "def", "clf_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "data_record_list", ",", "field", ",", "clf_metric", ",", "\n", "clf_weight", ")", ":", "\n", "    ", "if", "clf_weight", "==", "0", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "len", "(", "paraphrases", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "", "dist_list", "=", "clf_metric", ".", "predict_log_dist_multiple_examples", "(", "origin_list", ",", "paraphrases", ",", "\n", "data_record_list", ",", "field", ")", "\n", "dist_list", "=", "np", ".", "exp", "(", "dist_list", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "not_correct", "=", "[", "]", "\n", "for", "pred_dist", ",", "data_record", "in", "zip", "(", "dist_list", ",", "data_record_list", ")", ":", "\n", "        ", "label", "=", "data_record", "[", "\"label\"", "]", "\n", "correct_prob", "=", "(", "pred_dist", "[", "label", "]", ")", ".", "copy", "(", ")", "\n", "pred_dist", "[", "label", "]", "=", "-", "1e8", "\n", "incorrect_prob", "=", "np", ".", "max", "(", "pred_dist", ")", "\n", "not_correct", ".", "append", "(", "correct_prob", "<", "incorrect_prob", ")", "\n", "# margin = 1 / len(pred_dist)", "\n", "# scores.append(correct_prob - incorrect_prob)", "\n", "scores", ".", "append", "(", "1", "-", "incorrect_prob", ")", "\n", "\n", "", "scores", "=", "np", ".", "asarray", "(", "scores", ")", "\n", "\n", "return", "-", "clf_weight", "*", "np", ".", "maximum", "(", "scores", ",", "0", ")", ",", "np", ".", "asarray", "(", "not_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.joint_weighted_criteria": [[115, 164], ["ssrs_strategy.joint_weighted_criteria.compute_criteria_score"], "function", ["None"], ["", "def", "joint_weighted_criteria", "(", "\n", "origin_list", ",", "prev_paraphrases", ",", "candidate_paraphrases", ",", "\n", "data_record_list", ",", "field", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ",", "\n", "clf_metric", ",", "clf_weight", ",", "ppl_metric", ",", "ppl_weight", ",", "stats", ",", "state", ",", "\n", "log_prob_trans_forward", ",", "log_prob_trans_backward", ",", "\n", "bleu_metric", ",", "bleu_weight", ",", "bleu_threshold", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "def", "compute_criteria_score", "(", "paraphrases", ")", ":", "\n", "        ", "ppl_score", ",", "ppl_ratio", "=", "ppl_criteria_score", "(", "origin_list", "=", "origin_list", ",", "paraphrases", "=", "paraphrases", ",", "\n", "ppl_metric", "=", "ppl_metric", ",", "ppl_weight", "=", "ppl_weight", ")", "\n", "sim_score", ",", "sim_value", "=", "sim_criteria_score", "(", "origin_list", "=", "origin_list", ",", "paraphrases", "=", "paraphrases", ",", "\n", "sim_metric", "=", "sim_metric", ",", "sim_weight", "=", "sim_weight", ",", "\n", "sim_threshold", "=", "sim_threshold", ")", "\n", "clf_score", ",", "is_incorrect", "=", "clf_criteria_score", "(", "origin_list", "=", "origin_list", ",", "\n", "paraphrases", "=", "paraphrases", ",", "\n", "data_record_list", "=", "data_record_list", ",", "\n", "field", "=", "field", ",", "clf_metric", "=", "clf_metric", ",", "\n", "clf_weight", "=", "clf_weight", ")", "\n", "bleu_score", ",", "bleu_value", "=", "bleu_criteria_score", "(", "origin_list", "=", "origin_list", ",", "\n", "paraphrases", "=", "paraphrases", ",", "\n", "bleu_metric", "=", "bleu_metric", ",", "\n", "bleu_weight", "=", "bleu_weight", ",", "\n", "bleu_threshold", "=", "bleu_threshold", ")", "\n", "return", "ppl_score", "+", "sim_score", "+", "clf_score", "+", "bleu_score", ",", "is_incorrect", "\n", "\n", "", "if", "state", "is", "not", "None", ":", "\n", "        ", "previous_criteria_score", "=", "state", "[", "0", "]", "\n", "previous_is_incorrect", "=", "state", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "previous_criteria_score", ",", "previous_is_incorrect", "=", "compute_criteria_score", "(", "prev_paraphrases", ")", "\n", "\n", "", "candidate_criteria_score", ",", "candidate_is_incorrect", "=", "compute_criteria_score", "(", "\n", "candidate_paraphrases", ")", "\n", "\n", "candidate_criteria_score", "-=", "previous_is_incorrect", "*", "(", "1", "-", "candidate_is_incorrect", ")", "*", "1e8", "\n", "\n", "alpha", "=", "np", ".", "exp", "(", "(", "candidate_criteria_score", "-", "previous_criteria_score", "\n", "+", "log_prob_trans_backward", "-", "log_prob_trans_forward", ")", ")", "\n", "\n", "accept", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "rand", "(", "len", "(", "alpha", ")", ")", "<", "alpha", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "stats", "[", "\"accept\"", "]", "+=", "np", ".", "sum", "(", "accept", ")", "\n", "stats", "[", "\"all\"", "]", "+=", "len", "(", "accept", ")", "\n", "state", "=", "(", "candidate_criteria_score", "*", "accept", "+", "previous_criteria_score", "*", "(", "1", "-", "accept", ")", ",", "\n", "candidate_is_incorrect", "*", "accept", "+", "previous_is_incorrect", "*", "(", "1", "-", "accept", ")", ")", "\n", "\n", "ret", "=", "[", "candidate_paraphrases", "[", "idx", "]", "if", "is_acc", "else", "prev_paraphrases", "[", "idx", "]", "\n", "for", "idx", ",", "is_acc", "in", "enumerate", "(", "accept", ")", "]", "\n", "return", "ret", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.none_constraint": [[166, 168], ["None"], "function", ["None"], ["", "def", "none_constraint", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.count_mask": [[170, 177], ["tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "count_mask", "(", "data", ",", "tokenizer", ")", ":", "\n", "    ", "counter", "=", "0", "\n", "for", "line", "in", "data", ":", "\n", "        ", "for", "tok", "in", "tokenizer", ".", "tokenize", "(", "line", ")", ":", "\n", "            ", "if", "tok", "==", "\"[MASK]\"", ":", "\n", "                ", "counter", "+=", "1", "\n", "", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.assign_cadidates": [[179, 193], ["tokenizer.tokenize", "tokenizer.tokenize.index", "ret.append", "tokenizer.convert_tokens_to_string"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "assign_cadidates", "(", "paraphrases_with_mask", ",", "candidate_words", ",", "tokenizer", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "p", "=", "0", "\n", "for", "paraphrase", "in", "paraphrases_with_mask", ":", "\n", "        ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "paraphrase", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "", "except", "BaseException", ":", "\n", "                ", "ret", ".", "append", "(", "tokenizer", ".", "convert_tokens_to_string", "(", "tokens", ")", ")", "\n", "break", "\n", "", "tokens", "[", "mask_index", "]", "=", "candidate_words", "[", "p", "]", "\n", "p", "+=", "1", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.ssrs_strategy.smart_mask": [[195, 210], ["numpy.random.randint", "ret.append", "len"], "function", ["None"], ["", "def", "smart_mask", "(", "toks", ",", "op", ")", ":", "\n", "    ", "if", "op", "==", "-", "1", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "toks", ")", ")", "\n", "del", "toks", "[", "idx", "]", "\n", "\n", "", "ret", "=", "[", "]", "\n", "counter", "=", "0", "\n", "for", "tok", "in", "toks", ":", "\n", "        ", "ret", ".", "append", "(", "\"[MASK]\"", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "if", "op", "==", "1", ":", "\n", "        ", "ret", "+=", "[", "\"[MASK]\"", "]", "\n", "counter", "+=", "op", "\n", "", "return", "ret", ",", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_strategy.SapStrategy.__init__": [[26, 33], ["fibber.paraphrase_strategies.strategy_base.StrategyBase.__init__"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ")", ":", "\n", "        ", "super", "(", "SapStrategy", ",", "self", ")", ".", "__init__", "(", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "\n", "output_dir", ",", "metric_bundle", ")", "\n", "self", ".", "_sim_metric", "=", "None", "\n", "self", ".", "_clf_metric", "=", "None", "\n", "self", ".", "_ppl_metric", "=", "None", "\n", "self", ".", "_adversarial_word_candidates", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_strategy.SapStrategy.fit": [[34, 68], ["sap_strategy.SapStrategy._metric_bundle.get_metric", "sap_strategy.SapStrategy._metric_bundle.get_target_classifier", "sap_strategy.SapStrategy._metric_bundle.get_metric", "sap_strategy.SapStrategy._clf_metric.get_model_and_tokenizer", "list", "sap_strategy.SapStrategy._clf_metric.get_model_init", "fibber.paraphrase_strategies.sap_utils_euba.solve_euba", "sorted", "isinstance", "RuntimeError", "tokenizer.vocab.items", "sap_strategy.SapStrategy.startswith", "sap_strategy.SapStrategy.startswith", "sorted", "sap_strategy.SapStrategy.startswith", "sorted", "RuntimeError", "fibber.datasets.subsample_dataset", "sap_strategy.SapStrategy._clf_metric.get_device", "float", "zip", "item[].encode().isalpha", "item[].encode", "item[].encode().isalpha", "[].encode().isalpha", "item[].encode", "[].encode"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_model_and_tokenizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_model_init", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.solve_euba", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.subsample_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_device", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_sim_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"USESimilarityMetric\"", ")", "\n", "self", ".", "_clf_metric", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_ppl_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"BertPerplexityMetric\"", ")", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "_clf_metric", ",", "TransformerClassifier", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Sap attack only supports TransformerClassifier.\"", ")", "\n", "\n", "", "model", ",", "tokenizer", "=", "self", ".", "_clf_metric", ".", "get_model_and_tokenizer", "(", ")", "\n", "vocabulary", "=", "list", "(", "tokenizer", ".", "vocab", ".", "items", "(", ")", ")", "\n", "model_init", "=", "self", ".", "_clf_metric", ".", "get_model_init", "(", ")", "\n", "\n", "if", "model_init", ".", "startswith", "(", "\"bert-\"", ")", "or", "model_init", ".", "startswith", "(", "\"distilbert-\"", ")", ":", "\n", "            ", "vocabulary", "=", "sorted", "(", "[", "item", "for", "item", "in", "vocabulary", "if", "item", "[", "0", "]", ".", "encode", "(", "\"utf8\"", ")", ".", "isalpha", "(", ")", "]", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "", "elif", "model_init", ".", "startswith", "(", "\"roberta-\"", ")", ":", "\n", "            ", "vocabulary", "=", "sorted", "(", "[", "item", "for", "item", "in", "vocabulary", "\n", "if", "item", "[", "0", "]", ".", "encode", "(", "\"utf8\"", ")", ".", "isalpha", "(", ")", "or", "(", "\n", "item", "[", "0", "]", "[", "0", "]", "==", "\"\u0120\"", "and", "item", "[", "0", "]", "[", "1", ":", "]", ".", "encode", "(", "\"utf8\"", ")", ".", "isalpha", "(", ")", ")", "]", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Only support BERT, distilBERT, RoBERTa.\"", ")", "\n", "\n", "", "kappa", ",", "_", "=", "solve_euba", "(", "\n", "clf_model", "=", "model", ",", "tokenizer", "=", "tokenizer", ",", "vocabulary", "=", "vocabulary", ",", "\n", "val_set", "=", "subsample_dataset", "(", "trainset", ",", "self", ".", "_strategy_config", "[", "\"euba_subsample_size\"", "]", ")", ",", "\n", "use_mask", "=", "True", ",", "use_top1", "=", "False", ",", "early_stop", "=", "512", ",", "batch_size", "=", "32", ",", "\n", "device", "=", "self", ".", "_clf_metric", ".", "get_device", "(", ")", ")", "\n", "\n", "sac_result", "=", "[", "(", "w", "[", "0", "]", ",", "float", "(", "eps", ")", ")", "\n", "for", "w", ",", "eps", "in", "zip", "(", "vocabulary", ",", "kappa", ")", "]", "\n", "sac_result", "=", "sorted", "(", "sac_result", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "\n", "self", ".", "_adversarial_word_candidates", "=", "sac_result", "[", ":", "50", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_strategy.SapStrategy.paraphrase_example": [[69, 103], ["numpy.random.shuffle", "range", "sap_strategy.SapStrategy._clf_metric.predict_example", "sap_strategy.construct_candidates", "len", "sap_strategy.SapStrategy._clf_metric.predict_batch", "len", "zip", "len", "sap_strategy.SapStrategy._ppl_metric.measure_batch", "sap_strategy.SapStrategy._sim_metric.measure_batch", "numpy.argmin", "len", "mis_clf_sents.append", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_strategy.construct_candidates", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "if", "self", ".", "_clf_metric", ".", "predict_example", "(", "\n", "data_record", "[", "\"text0\"", "]", ",", "data_record", "[", "\"text0\"", "]", ")", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "            ", "return", "[", "data_record", "[", "self", ".", "_field", "]", "]", ",", "0", "\n", "\n", "", "mis_clf_sents", "=", "[", "]", "\n", "all_sents", "=", "[", "]", "\n", "for", "item", "in", "self", ".", "_adversarial_word_candidates", ":", "\n", "            ", "target_word", "=", "item", "[", "0", "]", "\n", "all_sents", "+=", "construct_candidates", "(", "data_record", "[", "\"text0\"", "]", ",", "target_word", ")", "\n", "\n", "", "np", ".", "random", ".", "shuffle", "(", "all_sents", ")", "\n", "\n", "counter", "=", "0", "\n", "for", "st", "in", "range", "(", "0", ",", "len", "(", "all_sents", ")", ",", "64", ")", ":", "\n", "            ", "sents", "=", "all_sents", "[", "st", ":", "st", "+", "64", "]", "\n", "predicts", "=", "self", ".", "_clf_metric", ".", "predict_batch", "(", "data_record", "[", "\"text0\"", "]", ",", "sents", ")", "\n", "counter", "+=", "len", "(", "sents", ")", "\n", "for", "pp", ",", "ss", "in", "zip", "(", "predicts", ",", "sents", ")", ":", "\n", "                ", "if", "pp", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "                    ", "mis_clf_sents", ".", "append", "(", "ss", ")", "\n", "", "", "if", "len", "(", "mis_clf_sents", ")", ">=", "50", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "len", "(", "mis_clf_sents", ")", ">", "0", ":", "\n", "            ", "ppls", "=", "self", ".", "_ppl_metric", ".", "measure_batch", "(", "\n", "data_record", "[", "\"text0\"", "]", ",", "mis_clf_sents", ",", "use_ratio", "=", "True", ")", "\n", "sims", "=", "self", ".", "_sim_metric", ".", "measure_batch", "(", "data_record", "[", "\"text0\"", "]", ",", "mis_clf_sents", ")", "\n", "\n", "score", "=", "3", "*", "np", ".", "asarray", "(", "ppls", ")", "+", "20", "*", "(", "1", "-", "np", ".", "asarray", "(", "sims", ")", ")", "\n", "idx", "=", "np", ".", "argmin", "(", "score", ")", "\n", "return", "[", "mis_clf_sents", "[", "idx", "]", "]", ",", "counter", "\n", "", "else", ":", "\n", "            ", "return", "[", "data_record", "[", "self", ".", "_field", "]", "]", ",", "counter", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_strategy.construct_candidates": [[10, 16], ["sent.split", "range", "len", "ret.append"], "function", ["None"], ["def", "construct_candidates", "(", "sent", ",", "target_word", ")", ":", "\n", "    ", "ret", "=", "[", "sent", "]", "\n", "toks", "=", "sent", ".", "split", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "toks", ")", ")", ":", "\n", "        ", "ret", ".", "append", "(", "\" \"", ".", "join", "(", "toks", "[", ":", "i", "]", "+", "[", "target_word", "]", "+", "toks", "[", "i", "+", "1", ":", "]", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.EmbeddingGradHook.__init__": [[10, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "output", "=", "None", "\n", "self", ".", "_enable", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.EmbeddingGradHook.disable": [[14, 17], ["None"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "self", ".", "_enable", "=", "False", "\n", "self", ".", "output", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.EmbeddingGradHook.enable": [[18, 20], ["None"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "self", ".", "_enable", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.EmbeddingGradHook.__call__": [[21, 27], ["output_.retain_grad"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "module", ",", "input_", ",", "output_", ")", ":", "\n", "        ", "if", "self", ".", "_enable", ":", "\n", "            ", "self", ".", "output", "=", "output_", "\n", "output_", ".", "retain_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.pick_diag": [[29, 34], ["range", "torch.stack", "x.size", "ret.append"], "function", ["None"], ["", "", "", "def", "pick_diag", "(", "x", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "ret", ".", "append", "(", "x", "[", "i", ",", "i", "]", ")", "\n", "", "return", "torch", ".", "stack", "(", "ret", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.estimate_weight": [[36, 90], ["hook.enable", "len", "torch.tensor().to", "hook.disable", "torch.cat.detach", "range", "torch.cat", "sap_utils_euba.pick_diag", "sap_utils_euba.pick_diag", "clf_model", "log_prob.detach.backward", "log_prob.detach.detach", "torch.no_grad", "range", "torch.cat", "torch.tensor", "len", "min", "torch.tensor().to", "clf_model", "log_prob.detach.append", "torch.sum().backward", "pick_diag.append", "pick_diag.append", "torch.cat", "torch.cat", "torch.log_softmax", "hook.output.grad.clone", "hook.output.clone", "len", "min", "numpy.asarray", "numpy.tile", "torch.cat.append", "range", "len", "torch.log_softmax", "log_prob_tmp.clone", "hook.output.grad.clone", "hook.output.clone", "len", "np.tile.reshape", "torch.tensor", "torch.sum", "pick_diag.size", "torch.einsum", "torch.einsum", "embedding_layer", "torch.tensor().to", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.enable", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.disable", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.pick_diag", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.pick_diag"], ["", "def", "estimate_weight", "(", "clf_model", ",", "embedding_layer", ",", "vocabulary", ",", "hook", ",", "example", ",", "token_ids_raw", ",", "\n", "anchor_word_tokenizer_id", ",", "batch_size", ",", "device", ")", ":", "\n", "    ", "hook", ".", "enable", "(", ")", "\n", "sent_len", "=", "len", "(", "token_ids_raw", ")", "\n", "batch_input_raw", "=", "torch", ".", "tensor", "(", "[", "token_ids_raw", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "anchor_word_tokenizer_id", "is", "not", "None", ":", "\n", "        ", "input_text", "=", "[", "token_ids_raw", "[", ":", "i", "]", "+", "[", "anchor_word_tokenizer_id", "]", "+", "token_ids_raw", "[", "i", "+", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "sent_len", ")", "]", "\n", "log_prob", "=", "[", "]", "\n", "grad", "=", "[", "]", "\n", "emb_output", "=", "[", "]", "\n", "\n", "for", "st", "in", "range", "(", "0", ",", "len", "(", "input_text", ")", ",", "batch_size", ")", ":", "\n", "            ", "ed", "=", "min", "(", "st", "+", "batch_size", ",", "len", "(", "input_text", ")", ")", "\n", "batch_input", "=", "torch", ".", "tensor", "(", "input_text", "[", "st", ":", "ed", "]", ")", ".", "to", "(", "device", ")", "\n", "output", "=", "clf_model", "(", "batch_input", ",", "return_dict", "=", "True", ")", "\n", "log_prob_tmp", "=", "torch", ".", "log_softmax", "(", "output", "[", "\"logits\"", "]", ",", "dim", "=", "1", ")", "[", ":", ",", "example", "[", "\"label\"", "]", "]", "\n", "log_prob", ".", "append", "(", "log_prob_tmp", ".", "clone", "(", ")", ")", "\n", "torch", ".", "sum", "(", "log_prob_tmp", ")", ".", "backward", "(", ")", "\n", "grad", ".", "append", "(", "hook", ".", "output", ".", "grad", ".", "clone", "(", ")", ")", "\n", "emb_output", ".", "append", "(", "hook", ".", "output", ".", "clone", "(", ")", ")", "\n", "del", "output", "\n", "", "log_prob", "=", "torch", ".", "cat", "(", "log_prob", ",", "dim", "=", "0", ")", "\n", "grad", "=", "pick_diag", "(", "torch", ".", "cat", "(", "grad", ",", "dim", "=", "0", ")", ")", "\n", "emb_output", "=", "pick_diag", "(", "torch", ".", "cat", "(", "emb_output", ",", "dim", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "clf_model", "(", "batch_input_raw", ",", "return_dict", "=", "True", ")", "\n", "log_prob", "=", "torch", ".", "log_softmax", "(", "output", "[", "\"logits\"", "]", ",", "dim", "=", "1", ")", "[", "0", ",", "example", "[", "\"label\"", "]", "]", "\n", "log_prob", ".", "backward", "(", ")", "\n", "log_prob", "=", "log_prob", ".", "detach", "(", ")", "\n", "grad", "=", "hook", ".", "output", ".", "grad", ".", "clone", "(", ")", "[", "0", "]", "# L * d", "\n", "emb_output", "=", "hook", ".", "output", ".", "clone", "(", ")", "[", "0", "]", "# L * d", "\n", "del", "output", "\n", "\n", "", "hook", ".", "disable", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "weight", "=", "[", "]", "\n", "for", "st", "in", "range", "(", "0", ",", "len", "(", "vocabulary", ")", ",", "batch_size", ")", ":", "\n", "            ", "ed", "=", "min", "(", "st", "+", "batch_size", ",", "len", "(", "vocabulary", ")", ")", "\n", "# get a batch of words", "\n", "tmp", "=", "np", ".", "asarray", "(", "[", "item", "[", "1", "]", "for", "item", "in", "vocabulary", "[", "st", ":", "ed", "]", "]", ")", "\n", "# repeat each word L times", "\n", "tmp", "=", "np", ".", "tile", "(", "tmp", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "(", "1", ",", "grad", ".", "size", "(", "0", ")", ")", ")", "# batch * L", "\n", "\n", "weight", ".", "append", "(", "\n", "(", "torch", ".", "einsum", "(", "\"bld,ld->bl\"", ",", "embedding_layer", "(", "torch", ".", "tensor", "(", "tmp", ")", ".", "to", "(", "device", ")", ")", ",", "grad", ")", "\n", "-", "torch", ".", "einsum", "(", "\"ld,ld->l\"", ",", "emb_output", ",", "grad", ")", ")", "+", "log_prob", ")", "\n", "\n", "", "weight", "=", "torch", ".", "cat", "(", "weight", ",", "dim", "=", "0", ")", "# V * l", "\n", "weight", "[", ":", ",", "0", "]", "=", "1e8", "# change clf tok weight to inf", "\n", "weight", "[", ":", ",", "-", "1", "]", "=", "1e8", "# change eos tok to inf", "\n", "", "return", "weight", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.solve_euba": [[92, 226], ["numpy.zeros", "numpy.zeros", "max", "isinstance", "sap_utils_euba.EmbeddingGradHook", "embedding_layer.register_forward_hook", "tqdm.tqdm", "len", "isinstance", "len", "torch.tensor().to", "len", "len", "isinstance", "tokenizer", "sap_utils_euba.estimate_weight", "sap_utils_euba.estimate_weight", "torch.no_grad", "torch.argsort().detach().cpu().numpy", "weight.detach().cpu().numpy.detach().cpu().numpy", "numpy.argsort", "sorted", "print", "len", "RuntimeError", "torch.tensor", "len", "len", "torch.tensor().to.repeat", "torch.argmax().detach().cpu().numpy", "range", "len", "torch.tensor().to.repeat", "torch.argmax().detach().cpu().numpy", "range", "torch.argsort().detach().cpu", "weight.detach().cpu().numpy.detach().cpu", "batch_info.append", "len", "numpy.argmin", "batch_info.append", "len", "zip", "len", "torch.argmax().detach().cpu", "len", "torch.argmax().detach().cpu", "torch.argsort().detach", "weight.detach().cpu().numpy.detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argsort", "weight.detach().cpu().numpy.reshape", "torch.argmax", "torch.argmax", "clf_model", "clf_model"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.estimate_weight", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.sap_utils_euba.estimate_weight"], ["", "def", "solve_euba", "(", "clf_model", ",", "tokenizer", ",", "vocabulary", ",", "val_set", ",", "\n", "use_mask", ",", "use_top1", ",", "early_stop", ",", "batch_size", ",", "device", ")", ":", "\n", "    ", "incorrect", "=", "np", ".", "zeros", "(", "len", "(", "vocabulary", ")", ")", "\n", "detail_incorrect", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocabulary", ")", ",", "len", "(", "val_set", "[", "\"label_mapping\"", "]", ")", ")", ")", "\n", "\n", "early_stop_batch_cnt", "=", "max", "(", "early_stop", "//", "batch_size", ",", "1", ")", "\n", "\n", "if", "isinstance", "(", "clf_model", ",", "DistilBertForSequenceClassification", ")", ":", "\n", "        ", "lm_model", "=", "clf_model", ".", "distilbert", "\n", "", "elif", "isinstance", "(", "clf_model", ",", "BertForSequenceClassification", ")", ":", "\n", "        ", "lm_model", "=", "clf_model", ".", "bert", "\n", "", "elif", "isinstance", "(", "clf_model", ",", "RobertaForSequenceClassification", ")", ":", "\n", "        ", "lm_model", "=", "clf_model", ".", "roberta", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"unknown classifier.\"", ")", "\n", "\n", "", "embedding_layer", "=", "lm_model", ".", "embeddings", ".", "word_embeddings", "\n", "hook", "=", "EmbeddingGradHook", "(", ")", "\n", "embedding_layer", ".", "register_forward_hook", "(", "hook", ")", "\n", "\n", "iter_idx", "=", "0", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "val_set", "[", "\"data\"", "]", ")", "\n", "for", "example", "in", "pbar", ":", "\n", "        ", "iter_idx", "+=", "1", "\n", "token_ids_raw", "=", "tokenizer", "(", "example", "[", "\"text0\"", "]", ")", "[", "\"input_ids\"", "]", "\n", "sent_len", "=", "len", "(", "token_ids_raw", ")", "\n", "batch_input_raw", "=", "torch", ".", "tensor", "(", "[", "token_ids_raw", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "use_mask", ":", "\n", "            ", "weight", "=", "estimate_weight", "(", "\n", "clf_model", ",", "embedding_layer", ",", "vocabulary", ",", "hook", ",", "example", ",", "token_ids_raw", ",", "\n", "anchor_word_tokenizer_id", "=", "tokenizer", ".", "mask_token_id", ",", "batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "estimate_weight", "(", "\n", "clf_model", ",", "embedding_layer", ",", "vocabulary", ",", "hook", ",", "example", ",", "token_ids_raw", ",", "\n", "anchor_word_tokenizer_id", "=", "None", ",", "batch_size", "=", "batch_size", ",", "device", "=", "device", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "sorted_index", "=", "torch", ".", "argsort", "(", "weight", ".", "reshape", "(", "-", "1", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "weight", "=", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "word_verify_cnt", "=", "[", "0", "]", "*", "len", "(", "vocabulary", ")", "\n", "# if >= 0, the number of positions tried. if -1, attack succeed.", "\n", "\n", "# weight-based trail", "\n", "miss_counter", "=", "0", "\n", "current", "=", "0", "\n", "while", "current", "<", "len", "(", "sorted_index", ")", ":", "\n", "                ", "input_ids", "=", "batch_input_raw", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "batch_info", "=", "[", "]", "\n", "jj", "=", "0", "\n", "\n", "while", "current", "<", "len", "(", "sorted_index", ")", "and", "jj", "<", "batch_size", ":", "\n", "                    ", "wid", "=", "sorted_index", "[", "current", "]", "//", "sent_len", "\n", "pos", "=", "sorted_index", "[", "current", "]", "%", "sent_len", "\n", "current", "+=", "1", "\n", "\n", "if", "pos", "==", "0", "or", "pos", "==", "sent_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "word_verify_cnt", "[", "wid", "]", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "use_top1", "and", "word_verify_cnt", "[", "wid", "]", ">", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "input_ids", "[", "jj", ",", "pos", "]", "=", "vocabulary", "[", "wid", "]", "[", "1", "]", "\n", "word_verify_cnt", "[", "wid", "]", "+=", "1", "\n", "batch_info", ".", "append", "(", "wid", ")", "\n", "jj", "+=", "1", "\n", "\n", "", "preds", "=", "torch", ".", "argmax", "(", "clf_model", "(", "input_ids", ")", "[", "\"logits\"", "]", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "hit", "=", "False", "\n", "for", "j", "in", "range", "(", "len", "(", "batch_info", ")", ")", ":", "\n", "                    ", "if", "preds", "[", "j", "]", "!=", "example", "[", "\"label\"", "]", ":", "\n", "                        ", "if", "word_verify_cnt", "[", "batch_info", "[", "j", "]", "]", "!=", "-", "1", ":", "\n", "                            ", "word_verify_cnt", "[", "batch_info", "[", "j", "]", "]", "=", "-", "1", "\n", "incorrect", "[", "batch_info", "[", "j", "]", "]", "+=", "1", "\n", "detail_incorrect", "[", "batch_info", "[", "j", "]", ",", "example", "[", "\"label\"", "]", "]", "+=", "1", "\n", "hit", "=", "True", "\n", "\n", "", "", "", "if", "not", "hit", ":", "\n", "                    ", "miss_counter", "+=", "1", "\n", "if", "miss_counter", "==", "early_stop_batch_cnt", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "miss_counter", "=", "0", "\n", "\n", "# top words trail", "\n", "", "", "sorted_index", "=", "np", ".", "argsort", "(", "-", "detail_incorrect", "[", ":", ",", "example", "[", "\"label\"", "]", "]", ")", "\n", "current", "=", "0", "\n", "miss_counter", "=", "0", "\n", "while", "current", "<", "len", "(", "sorted_index", ")", ":", "\n", "                ", "input_ids", "=", "batch_input_raw", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "batch_info", "=", "[", "]", "\n", "jj", "=", "0", "\n", "\n", "while", "current", "<", "len", "(", "sorted_index", ")", "and", "jj", "<", "batch_size", ":", "\n", "                    ", "wid", "=", "sorted_index", "[", "current", "]", "\n", "pos", "=", "np", ".", "argmin", "(", "weight", "[", "wid", "]", ")", "\n", "current", "+=", "1", "\n", "if", "pos", "==", "0", "or", "pos", "==", "sent_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "word_verify_cnt", "[", "wid", "]", "!=", "0", ":", "\n", "                        ", "continue", "\n", "", "input_ids", "[", "jj", ",", "pos", "]", "=", "vocabulary", "[", "wid", "]", "[", "1", "]", "\n", "word_verify_cnt", "[", "wid", "]", "+=", "1", "\n", "batch_info", ".", "append", "(", "wid", ")", "\n", "jj", "+=", "1", "\n", "\n", "", "preds", "=", "torch", ".", "argmax", "(", "clf_model", "(", "input_ids", ")", "[", "\"logits\"", "]", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "hit", "=", "False", "\n", "for", "j", "in", "range", "(", "len", "(", "batch_info", ")", ")", ":", "\n", "                    ", "if", "preds", "[", "j", "]", "!=", "example", "[", "\"label\"", "]", ":", "\n", "                        ", "if", "word_verify_cnt", "[", "batch_info", "[", "j", "]", "]", "!=", "-", "1", ":", "\n", "                            ", "word_verify_cnt", "[", "batch_info", "[", "j", "]", "]", "=", "-", "1", "\n", "incorrect", "[", "batch_info", "[", "j", "]", "]", "+=", "1", "\n", "detail_incorrect", "[", "batch_info", "[", "j", "]", ",", "example", "[", "\"label\"", "]", "]", "+=", "1", "\n", "hit", "=", "True", "\n", "", "", "", "if", "not", "hit", ":", "\n", "                    ", "miss_counter", "+=", "1", "\n", "if", "miss_counter", "==", "early_stop_batch_cnt", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "miss_counter", "=", "0", "\n", "\n", "", "", "", "if", "iter_idx", "%", "10", "==", "0", ":", "\n", "            ", "result", "=", "[", "(", "w", "[", "0", "]", ",", "eps", ")", "for", "w", ",", "eps", "in", "zip", "(", "vocabulary", ",", "incorrect", ")", "]", "\n", "result", "=", "sorted", "(", "result", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "print", "(", "result", "[", ":", "10", "]", ")", "\n", "\n", "", "", "return", "incorrect", "/", "len", "(", "val_set", "[", "\"data\"", "]", ")", ",", "detail_incorrect", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ASRSStrategy.__repr__": [[281, 283], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"-\"", "+", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ASRSStrategy.fit": [[284, 333], ["logger.info", "fibber.metrics.bert_lm_utils.get_lm", "isinstance", "asrs_strategy.ASRSStrategy._metric_bundle.get_metric", "asrs_strategy.ASRSStrategy._metric_bundle.get_target_classifier", "asrs_strategy.ASRSStrategy._metric_bundle.get_metric", "fibber.paraphrase_strategies.asrs_utils_wpe.get_wordpiece_emb", "torch.nn.Embedding", "torch.tensor().float", "asrs_strategy.ASRSStrategy._word_embs.to", "asrs_strategy.ASRSStrategy._word_embs.eval", "asrs_strategy.ASRSStrategy._word_embs.parameters", "asrs_strategy.ASRSStrategy._bert_lm.to", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.get_wordpiece_emb"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "# load BERT language model.", "\n", "        ", "logger", ".", "info", "(", "\"Load bert language model for ASRSStrategy.\"", ")", "\n", "\n", "self", ".", "_tokenizer", ",", "lm", "=", "get_lm", "(", "\n", "self", ".", "_strategy_config", "[", "\"lm_option\"", "]", ",", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_device", ",", "\n", "lm_steps", "=", "self", ".", "_strategy_config", "[", "\"lm_steps\"", "]", ")", "\n", "\n", "if", "isinstance", "(", "lm", ",", "list", ")", ":", "\n", "            ", "self", ".", "_bert_lms", "=", "lm", "\n", "", "else", ":", "\n", "            ", "self", ".", "_bert_lm", "=", "lm", "\n", "self", ".", "_bert_lm", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "# Load useful metrics", "\n", "", "self", ".", "_sim_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\n", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", ")", "\n", "self", ".", "_clf_metric", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_ppl_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"BertPerplexityMetric\"", ")", "\n", "\n", "# load word piece embeddings.", "\n", "wpe", "=", "get_wordpiece_emb", "(", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_tokenizer", ",", "self", ".", "_device", ")", "\n", "self", ".", "_word_embs", "=", "nn", ".", "Embedding", "(", "self", ".", "_tokenizer", ".", "vocab_size", ",", "300", ")", "\n", "self", ".", "_word_embs", ".", "weight", ".", "data", "=", "torch", ".", "tensor", "(", "wpe", ".", "T", ")", ".", "float", "(", ")", "\n", "self", ".", "_word_embs", "=", "self", ".", "_word_embs", ".", "to", "(", "self", ".", "_device", ")", "\n", "self", ".", "_word_embs", ".", "eval", "(", ")", "\n", "for", "item", "in", "self", ".", "_word_embs", ".", "parameters", "(", ")", ":", "\n", "            ", "item", ".", "requires_grad", "=", "False", "\n", "\n", "# config _decision_fn and _enforcing_dist_fn", "\n", "", "if", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"all\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "all_accept_criteria", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"joint_weighted_criteria\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "joint_weighted_criteria", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "if", "self", ".", "_strategy_config", "[", "\"enforcing_dist\"", "]", "==", "\"none\"", ":", "\n", "            ", "self", ".", "_enforcing_dist_fn", "=", "none_constraint", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"enforcing_dist\"", "]", "==", "\"wpe\"", ":", "\n", "            ", "self", ".", "_enforcing_dist_fn", "=", "wpe_constraint", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"enforcing_dist\"", "]", "==", "\"allow_list\"", ":", "\n", "            ", "self", ".", "_enforcing_dist_fn", "=", "allow_list_constraint", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "self", ".", "_stats", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"accept\"", ":", "0", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ASRSStrategy._parallel_sequential_generation": [[335, 518], ["torch.zeros_like", "torch.zeros_like", "enumerate", "asrs_strategy.ASRSStrategy._word_embs().sum", "torch.nn.functional.one_hot().sum", "range", "torch.tensor().to", "torch.tensor().to", "len", "torch.cat", "numpy.random.randint", "min", "batch_tensor[].clone", "asrs_strategy.ASRSStrategy._enforcing_dist_fn", "numpy.arange", "numpy.random.shuffle", "batch_tensor[].clone", "asrs_strategy.ASRSStrategy._decision_fn", "asrs_strategy.tostring", "asrs_strategy.ASRSStrategy._tokenizer.tokenize", "range", "max", "torch.tensor().to", "asrs_strategy.ASRSStrategy._tokenizer.tokenize", "asrs_strategy.ASRSStrategy._word_embs", "torch.nn.functional.one_hot", "torch.cat", "torch.cat", "torch.nn.functional.log_softmax", "asrs_strategy.sample_word_from_logits", "zip", "asrs_strategy.ASRSStrategy._tokenizer.tokenize", "torch.tensor", "len", "numpy.random.randint", "torch.tensor", "torch.ones_like", "torch.tensor().to", "max", "max", "log_prob_candidate_ids.detach().cpu().numpy", "log_prob_previous_ids.detach().cpu().numpy", "numpy.sum", "torch.tensor().to.detach().cpu().numpy", "range", "seq.append", "seq_len.append", "range", "seq.append", "seq_len.append", "len", "len", "torch.tensor", "torch.zeros_like", "torch.ones_like", "asrs_strategy.ASRSStrategy._bert_lm", "asrs_strategy.ASRSStrategy._bert_lm", "torch.gather().squeeze", "torch.gather().squeeze", "len", "abs", "numpy.random.randint", "numpy.random.randint", "torch.tensor", "log_prob_candidate_ids.detach().cpu", "log_prob_previous_ids.detach().cpu", "torch.tensor().to.detach().cpu", "asrs_strategy.ASRSStrategy._tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "len", "len", "asrs_strategy.ASRSStrategy._tokenizer.convert_tokens_to_ids", "asrs_strategy.ASRSStrategy._tokenizer.convert_tokens_to_ids", "torch.gather", "torch.gather", "asrs_strategy.ASRSStrategy._tokenizer.convert_tokens_to_ids", "log_prob_candidate_ids.detach", "log_prob_previous_ids.detach", "torch.tensor().to.detach", "numpy.random.choice", "asrs_strategy.ASRSStrategy._tokenizer.tokenize", "range", "previous_ids[].unsqueeze", "sample_word_from_logits.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.tostring", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.sample_word_from_logits", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "_parallel_sequential_generation", "(", "\n", "self", ",", "original_text", ",", "seed", ",", "batch_size", ",", "burnin_steps", ",", "sampling_steps", ",", "field", ",", "\n", "data_record", ",", "early_stop", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "_strategy_config", "[", "\"seed_option\"", "]", "==", "\"origin\"", ":", "\n", "            ", "seq", "=", "[", "\"[CLS]\"", "]", "+", "self", ".", "_tokenizer", ".", "tokenize", "(", "seed", ")", "+", "[", "\"[SEP]\"", "]", "\n", "batch_tensor", "=", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "seq", ")", "]", "*", "batch_size", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "seq_len", "=", "[", "len", "(", "seq", ")", "]", "*", "batch_size", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"seed_option\"", "]", "==", "\"dynamic_len\"", ":", "\n", "            ", "seq_raw", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "seed", ")", "\n", "seq", "=", "[", "]", "\n", "seq_len", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "seq_t", "=", "seq_raw", "[", ":", "]", "\n", "length_change", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "_strategy_config", "[", "\"dynamic_len_min\"", "]", ",", "\n", "self", ".", "_strategy_config", "[", "\"dynamic_len_max\"", "]", "+", "1", ")", "\n", "# if shrink length, make sure at least 3 words in the sentence.", "\n", "if", "length_change", "<", "0", "and", "len", "(", "seq_raw", ")", "+", "length_change", "<", "3", ":", "\n", "                    ", "length_change", "=", "3", "-", "len", "(", "seq_raw", ")", "\n", "", "if", "length_change", "<", "0", ":", "\n", "                    ", "for", "j", "in", "range", "(", "abs", "(", "length_change", ")", ")", ":", "\n", "                        ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "seq_t", ")", ")", "\n", "seq_t", "=", "seq_t", "[", ":", "pos", "]", "+", "seq_t", "[", "pos", "+", "1", ":", "]", "\n", "", "seq", ".", "append", "(", "[", "\"[CLS]\"", "]", "+", "seq_t", "+", "[", "\"[SEP]\"", "]", ")", "\n", "seq_len", ".", "append", "(", "len", "(", "seq_t", ")", "+", "2", ")", "\n", "", "else", ":", "\n", "                    ", "for", "j", "in", "range", "(", "length_change", ")", ":", "\n", "                        ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "seq_t", ")", ")", "\n", "seq_t", "=", "seq_t", "[", ":", "pos", "]", "+", "[", "np", ".", "random", ".", "choice", "(", "seq_raw", ")", "]", "+", "seq_t", "[", "pos", ":", "]", "\n", "", "seq", ".", "append", "(", "[", "\"[CLS]\"", "]", "+", "seq_t", "+", "[", "\"[SEP]\"", "]", ")", "\n", "seq_len", ".", "append", "(", "len", "(", "seq_t", ")", "+", "2", ")", "\n", "", "assert", "len", "(", "seq", "[", "-", "1", "]", ")", "==", "2", "+", "len", "(", "seq_raw", ")", "+", "length_change", "\n", "assert", "seq_len", "[", "-", "1", "]", "==", "len", "(", "seq", "[", "-", "1", "]", ")", "\n", "", "max_len", "=", "max", "(", "seq_len", ")", "\n", "seq", "=", "[", "x", "+", "[", "\"[PAD]\"", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "for", "x", "in", "seq", "]", "\n", "batch_tensor", "=", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "x", ")", "for", "x", "in", "seq", "]", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "attention_mask", "=", "torch", ".", "zeros_like", "(", "batch_tensor", ")", "\n", "attention_mask_paraphrase_text_only", "=", "torch", ".", "zeros_like", "(", "attention_mask", ")", "\n", "for", "rid", ",", "ll", "in", "enumerate", "(", "seq_len", ")", ":", "\n", "            ", "attention_mask", "[", "rid", ",", ":", "ll", "]", "=", "1", "\n", "attention_mask_paraphrase_text_only", "[", "rid", ",", "1", ":", "ll", "-", "1", "]", "=", "1", "\n", "\n", "", "if", "field", "==", "\"text1\"", ":", "\n", "            ", "context_seq", "=", "[", "\"[CLS]\"", "]", "+", "self", ".", "_tokenizer", ".", "tokenize", "(", "data_record", "[", "\"text0\"", "]", ")", "\n", "context_tensor", "=", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "context_seq", ")", "]", "*", "batch_size", "\n", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "context_len", "=", "len", "(", "context_seq", ")", "\n", "batch_tensor", "[", ":", ",", "0", "]", "=", "self", ".", "_tokenizer", ".", "sep_token_id", "\n", "attention_mask", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "context_tensor", ")", ",", "\n", "attention_mask", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "context_tensor", "=", "None", "\n", "\n", "", "target_emb", "=", "(", "self", ".", "_word_embs", "(", "torch", ".", "tensor", "(", "[", "\n", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "_tokenizer", ".", "tokenize", "(", "original_text", ")", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", "]", ")", ".", "to", "(", "self", ".", "_device", ")", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "allow_list", "=", "F", ".", "one_hot", "(", "batch_tensor", "[", "0", "]", "*", "attention_mask_paraphrase_text_only", "[", "0", "]", ",", "\n", "self", ".", "_tokenizer", ".", "vocab_size", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "allow_list", "[", "0", "]", "=", "0", "\n", "\n", "decision_fn_state", "=", "None", "\n", "\n", "for", "ii", "in", "range", "(", "sampling_steps", ")", ":", "\n", "            ", "pos_st", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "max", "(", "seq_len", ")", "-", "1", ")", "\n", "pos_ed", "=", "min", "(", "pos_st", "+", "self", ".", "_strategy_config", "[", "\"window_size\"", "]", ",", "max", "(", "seq_len", ")", "-", "1", ")", "\n", "\n", "previous_ids", "=", "batch_tensor", "[", ":", ",", "pos_st", ":", "pos_ed", "]", ".", "clone", "(", ")", "\n", "batch_tensor", "[", ":", ",", "pos_st", ":", "pos_ed", "]", "=", "(", "\n", "self", ".", "_tokenizer", ".", "mask_token_id", "\n", "*", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos_st", ":", "pos_ed", "]", "\n", "+", "previous_ids", "*", "(", "1", "-", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos_st", ":", "pos_ed", "]", ")", ")", "\n", "\n", "if", "field", "==", "\"text1\"", ":", "\n", "                ", "batch_tensor_tmp", "=", "torch", ".", "cat", "(", "[", "context_tensor", ",", "batch_tensor", "]", ",", "dim", "=", "1", ")", "\n", "tok_type_tensor_tmp", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros_like", "(", "context_tensor", ")", ",", "\n", "torch", ".", "ones_like", "(", "batch_tensor", ")", "]", ",", "dim", "=", "1", ")", "\n", "logits_lm", "=", "self", ".", "_bert_lm", "(", "\n", "batch_tensor_tmp", ",", "\n", "token_type_ids", "=", "tok_type_tensor_tmp", ",", "\n", "attention_mask", "=", "attention_mask", ")", "[", "0", "]", "[", "\n", ":", ",", "context_len", "+", "pos_st", ":", "context_len", "+", "pos_ed", "]", "\n", "", "else", ":", "\n", "                ", "logits_lm", "=", "self", ".", "_bert_lm", "(", "\n", "batch_tensor", ",", "attention_mask", "=", "attention_mask", ")", "[", "0", "]", "[", ":", ",", "pos_st", ":", "pos_ed", "]", "\n", "", "logits_lm", "[", ":", ",", ":", ",", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "-", "1e8", "\n", "\n", "logits_enforcing", "=", "self", ".", "_enforcing_dist_fn", "(", "\n", "# for wpe constraint", "\n", "target_emb", "=", "target_emb", ",", "\n", "word_embs", "=", "self", ".", "_word_embs", ",", "\n", "batch_tensor", "=", "batch_tensor", ",", "\n", "pos_st", "=", "pos_st", ",", "\n", "pos_ed", "=", "pos_ed", ",", "\n", "wpe_threshold", "=", "self", ".", "_strategy_config", "[", "\"wpe_threshold\"", "]", ",", "\n", "wpe_weight", "=", "self", ".", "_strategy_config", "[", "\"wpe_weight\"", "]", ",", "\n", "# for naive constraint", "\n", "allow_list", "=", "allow_list", ",", "\n", "attention_mask_paraphrase_text_only", "=", "attention_mask_paraphrase_text_only", "\n", ")", "\n", "\n", "log_prob_previous_ids", "=", "0", "\n", "log_prob_candidate_ids", "=", "0", "\n", "\n", "sample_order", "=", "np", ".", "arange", "(", "pos_st", ",", "pos_ed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "sample_order", ")", "\n", "for", "pos", "in", "sample_order", ":", "\n", "                ", "if", "ii", "<", "burnin_steps", ":", "\n", "                    ", "if", "self", ".", "_strategy_config", "[", "\"burnin_enforcing_schedule\"", "]", "==", "\"0\"", ":", "\n", "                        ", "logits_joint", "=", "logits_lm", "[", ":", ",", "pos", "-", "pos_st", "]", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"burnin_enforcing_schedule\"", "]", "==", "\"1\"", ":", "\n", "                        ", "logits_joint", "=", "logits_lm", "[", ":", ",", "pos", "-", "pos_st", "]", "+", "logits_enforcing", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"burnin_enforcing_schedule\"", "]", "==", "\"linear\"", ":", "\n", "                        ", "logits_joint", "=", "logits_lm", "[", ":", ",", "pos", "-", "pos_st", "]", "+", "(", "\n", "(", "ii", "+", "1", ")", "/", "burnin_steps", ")", "*", "logits_enforcing", "\n", "", "else", ":", "\n", "                        ", "assert", "0", "\n", "", "", "else", ":", "\n", "                    ", "logits_joint", "=", "logits_lm", "[", ":", ",", "pos", "-", "pos_st", "]", "+", "logits_enforcing", "\n", "\n", "", "logits_joint", "=", "F", ".", "log_softmax", "(", "logits_joint", ",", "dim", "=", "1", ")", "\n", "\n", "top_k", "=", "self", ".", "_strategy_config", "[", "\"top_k\"", "]", "if", "(", "ii", ">=", "burnin_steps", ")", "else", "0", "\n", "\n", "candidate_ids", "=", "sample_word_from_logits", "(", "\n", "logits_joint", ",", "top_k", "=", "top_k", ",", "temperature", "=", "self", ".", "_strategy_config", "[", "\"temperature\"", "]", ")", "\n", "\n", "log_prob_previous_ids", "=", "log_prob_previous_ids", "+", "(", "\n", "torch", ".", "gather", "(", "\n", "logits_joint", ",", "dim", "=", "1", ",", "index", "=", "previous_ids", "[", ":", ",", "pos", "-", "pos_st", "]", ".", "unsqueeze", "(", "1", ")", "\n", ")", ".", "squeeze", "(", "1", ")", "*", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos", "]", ")", "\n", "log_prob_candidate_ids", "=", "log_prob_candidate_ids", "+", "(", "\n", "torch", ".", "gather", "(", "\n", "logits_joint", ",", "dim", "=", "1", ",", "index", "=", "candidate_ids", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "*", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos", "]", ")", "\n", "\n", "batch_tensor", "[", ":", ",", "pos", "]", "=", "(", "\n", "candidate_ids", "*", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos", "]", "\n", "+", "batch_tensor", "[", ":", ",", "pos", "]", "\n", "*", "(", "1", "-", "attention_mask_paraphrase_text_only", "[", ":", ",", "pos", "]", ")", ")", "\n", "\n", "", "candidate_ids", "=", "batch_tensor", "[", ":", ",", "pos_st", ":", "pos_ed", "]", ".", "clone", "(", ")", "\n", "\n", "if", "ii", "<", "burnin_steps", ":", "\n", "                ", "if", "self", ".", "_strategy_config", "[", "\"burnin_criteria_schedule\"", "]", "==", "\"0\"", ":", "\n", "                    ", "decision_fn_burnin_weight", "=", "0", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"burnin_criteria_schedule\"", "]", "==", "\"1\"", ":", "\n", "                    ", "decision_fn_burnin_weight", "=", "1", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"burnin_criteria_schedule\"", "]", "==", "\"linear\"", ":", "\n", "                    ", "decision_fn_burnin_weight", "=", "(", "ii", "+", "1", ")", "/", "burnin_steps", "\n", "", "else", ":", "\n", "                    ", "assert", "0", "\n", "", "", "else", ":", "\n", "                ", "decision_fn_burnin_weight", "=", "1", "\n", "\n", "", "final_ids", ",", "decision_fn_state", "=", "self", ".", "_decision_fn", "(", "\n", "tokenizer", "=", "self", ".", "_tokenizer", ",", "data_record", "=", "data_record", ",", "field", "=", "field", ",", "\n", "origin", "=", "data_record", "[", "field", "]", ",", "batch_tensor", "=", "batch_tensor", ",", "\n", "pos_st", "=", "pos_st", ",", "pos_ed", "=", "pos_ed", ",", "previous_ids", "=", "previous_ids", ",", "\n", "candidate_ids", "=", "candidate_ids", ",", "sim_metric", "=", "self", ".", "_sim_metric", ",", "\n", "sim_threshold", "=", "self", ".", "_strategy_config", "[", "\"sim_threshold\"", "]", ",", "\n", "sim_weight", "=", "self", ".", "_strategy_config", "[", "\"sim_weight\"", "]", ",", "\n", "clf_metric", "=", "self", ".", "_clf_metric", ",", "clf_weight", "=", "self", ".", "_strategy_config", "[", "\"clf_weight\"", "]", ",", "\n", "ppl_metric", "=", "self", ".", "_ppl_metric", ",", "ppl_weight", "=", "self", ".", "_strategy_config", "[", "\"ppl_weight\"", "]", ",", "\n", "burnin_weight", "=", "decision_fn_burnin_weight", ",", "stats", "=", "self", ".", "_stats", ",", "\n", "state", "=", "decision_fn_state", ",", "device", "=", "self", ".", "_device", ",", "\n", "seq_len", "=", "seq_len", ",", "\n", "log_prob_candidate_ids", "=", "log_prob_candidate_ids", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "log_prob_previous_ids", "=", "log_prob_previous_ids", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "batch_tensor", "[", ":", ",", "pos_st", ":", "pos_ed", "]", "=", "final_ids", "\n", "if", "early_stop", "and", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", ">=", "3", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "[", "tostring", "(", "self", ".", "_tokenizer", ",", "x", "[", "1", ":", "ll", "-", "1", "]", ")", "\n", "for", "x", ",", "ll", "in", "zip", "(", "batch_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "seq_len", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ASRSStrategy.paraphrase_example": [[519, 559], ["asrs_strategy.process_text", "math.ceil", "range", "logger.info", "asrs_strategy.ASRSStrategy._bert_lm.to", "asrs_strategy.ASRSStrategy._parallel_sequential_generation", "len", "asrs_strategy.ASRSStrategy._bert_lm.to", "torch.device"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.process_text", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ASRSStrategy._parallel_sequential_generation"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ",", "early_stop", "=", "False", ")", ":", "\n", "        ", "global", "asrs_clf_counter", "\n", "asrs_clf_counter", "=", "0", "\n", "\n", "if", "self", ".", "_strategy_config", "[", "\"lm_option\"", "]", "==", "\"adv\"", ":", "\n", "            ", "self", ".", "_bert_lm", "=", "self", ".", "_bert_lms", "[", "data_record", "[", "\"label\"", "]", "]", "\n", "self", ".", "_bert_lm", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "", "clipped_text", "=", "data_record", "[", "self", ".", "_field", "]", "\n", "clipped_text", "=", "process_text", "(", "clipped_text", ",", "PRE_PROCESSING_PATTERN", ")", "\n", "batch_size", "=", "self", ".", "_strategy_config", "[", "\"batch_size\"", "]", "\n", "\n", "sentences", "=", "[", "]", "\n", "n_batches", "=", "math", ".", "ceil", "(", "n", "/", "batch_size", ")", "\n", "last_batch_size", "=", "n", "%", "batch_size", "\n", "if", "last_batch_size", "==", "0", ":", "\n", "            ", "last_batch_size", "=", "batch_size", "\n", "\n", "", "for", "id", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "burnin_steps", "=", "self", ".", "_strategy_config", "[", "\"burnin_steps\"", "]", "\n", "sampling_steps", "=", "self", ".", "_strategy_config", "[", "\"sampling_steps\"", "]", "\n", "\n", "batch", "=", "self", ".", "_parallel_sequential_generation", "(", "\n", "clipped_text", ",", "\n", "clipped_text", "if", "\"seed\"", "not", "in", "data_record", "else", "data_record", "[", "\"seed\"", "]", ",", "\n", "batch_size", "if", "id", "!=", "n_batches", "-", "1", "else", "last_batch_size", ",", "\n", "burnin_steps", ",", "\n", "sampling_steps", ",", "\n", "self", ".", "_field", ",", "data_record", ",", "\n", "early_stop", "=", "early_stop", ")", "\n", "sentences", "+=", "batch", "\n", "\n", "", "assert", "len", "(", "sentences", ")", "==", "n", "\n", "\n", "if", "self", ".", "_strategy_config", "[", "\"lm_option\"", "]", "==", "\"adv\"", ":", "\n", "            ", "self", ".", "_bert_lm", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Aggregated accept rate: %.2lf%%.\"", ",", "\n", "self", ".", "_stats", "[", "\"accept\"", "]", "/", "self", ".", "_stats", "[", "\"all\"", "]", "*", "100", ")", "\n", "return", "sentences", "[", ":", "n", "]", ",", "asrs_clf_counter", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.process_text": [[39, 49], ["re.sub"], "function", ["None"], ["def", "process_text", "(", "text", ",", "patterns", ")", ":", "\n", "    ", "\"\"\"Processing the text using regex patterns.\n\n    Args:\n        text (str): the str to be post processed.\n        patterns (list): a list of substitution patterns.\n    \"\"\"", "\n", "for", "pattern", "in", "patterns", ":", "\n", "        ", "text", "=", "re", ".", "sub", "(", "pattern", "[", "0", "]", ",", "pattern", "[", "1", "]", ",", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.tostring": [[51, 59], ["asrs_strategy.process_text", "tokenizer.decode"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.process_text"], ["", "def", "tostring", "(", "tokenizer", ",", "seq", ")", ":", "\n", "    ", "\"\"\"Convert a sequence of word ids to a sentence. The post prossing is applied.\n\n    Args:\n        tokenizer (transformers.BertTokenizer): a BERT tokenizer.\n        seq (list): a list-like sequence of word ids.\n    \"\"\"", "\n", "return", "process_text", "(", "tokenizer", ".", "decode", "(", "seq", ")", ",", "POST_PROCESSING_PATTERN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.sample_word_from_logits": [[61, 80], ["logits.topk", "torch.distributions.categorical.Categorical", "kth_idx.gather().squeeze", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.sample().squeeze", "kth_idx.gather", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample().unsqueeze", "torch.distributions.categorical.Categorical.sample"], "function", ["None"], ["", "def", "sample_word_from_logits", "(", "logits", ",", "temperature", "=", "1.", ",", "top_k", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sample a word from a distribution.\n\n    Args:\n        logits (torch.Tensor): tensor of logits with size ``(batch_size, vocab_size)``.\n        temperature (float): the temperature of softmax. The PMF is\n            ``softmax(logits/temperature)``.\n        top_k (int): if ``k>0``, only sample from the top k most probable words.\n    \"\"\"", "\n", "logits", "=", "logits", "/", "temperature", "\n", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "kth_vals", ",", "kth_idx", "=", "logits", ".", "topk", "(", "top_k", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "kth_vals", ")", "\n", "idx", "=", "kth_idx", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "dist", ".", "sample", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "logits", ")", "\n", "idx", "=", "dist", ".", "sample", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.all_accept_criteria": [[82, 98], ["len", "len"], "function", ["None"], ["", "def", "all_accept_criteria", "(", "candidate_ids", ",", "stats", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Always accept proposed words.\n\n    Args:\n        candidate_ids (torch.Tensor): proposed word ids in this sampling step with\n            size ``(batch_size, pos_ed-pos_st)``.\n        stats (dict): a dict to keep track the accept rate.\n\n    Returns:\n        (np.array, None)\n            np.array is the same as candidate_ids.\n            None means this criteria does not have any state.\n    \"\"\"", "\n", "stats", "[", "\"accept\"", "]", "+=", "len", "(", "candidate_ids", ")", "\n", "stats", "[", "\"all\"", "]", "+=", "len", "(", "candidate_ids", ")", "\n", "return", "candidate_ids", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.sim_criteria_score": [[100, 117], ["sim_metric.measure_batch", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "sim_criteria_score", "(", "origin", ",", "paraphrases", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        sim_metric (MetricBase): a similarity metric object.\n        sim_threshold (float): the universal sentence encoder similarity threshold.\n        sim_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "use_semantic_similarity", "=", "sim_metric", ".", "measure_batch", "(", "origin", ",", "paraphrases", ")", "\n", "return", "(", "-", "sim_weight", "*", "(", "\n", "np", ".", "maximum", "(", "sim_threshold", "-", "np", ".", "asarray", "(", "use_semantic_similarity", ")", ",", "0", ")", "**", "2", ")", ",", "\n", "use_semantic_similarity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.ppl_criteria_score": [[119, 134], ["ppl_metric.measure_batch", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "ppl_criteria_score", "(", "origin", ",", "paraphrases", ",", "ppl_metric", ",", "ppl_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        ppl_metric (GPT2PerplexityMetric): a GPT2PerplexityMetric metric object.\n        ppl_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "ppl_ratio", "=", "ppl_metric", ".", "measure_batch", "(", "origin", ",", "paraphrases", ",", "use_ratio", "=", "True", ")", "\n", "return", "(", "-", "ppl_weight", "*", "(", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "ppl_ratio", ")", "-", "1", ",", "0", ")", "**", "2", ")", ",", "\n", "ppl_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.clf_criteria_score": [[136, 149], ["clf_metric.predict_log_dist_batch", "dist[].copy", "numpy.max", "len", "numpy.zeros", "len", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "clf_criteria_score", "(", "origin", ",", "paraphrases", ",", "data_record", ",", "field", ",", "clf_metric", ",", "clf_weight", ")", ":", "\n", "    ", "global", "asrs_clf_counter", "\n", "if", "clf_weight", "==", "0", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "len", "(", "paraphrases", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "", "dist", "=", "clf_metric", ".", "predict_log_dist_batch", "(", "origin", ",", "paraphrases", ",", "data_record", ")", "\n", "label", "=", "data_record", "[", "\"label\"", "]", "\n", "correct_prob", "=", "(", "dist", "[", ":", ",", "label", "]", ")", ".", "copy", "(", ")", "\n", "dist", "[", ":", ",", "label", "]", "=", "-", "1e8", "\n", "incorrect_prob", "=", "np", ".", "max", "(", "dist", ",", "axis", "=", "1", ")", "\n", "asrs_clf_counter", "+=", "len", "(", "paraphrases", ")", "\n", "return", "(", "-", "clf_weight", "*", "np", ".", "maximum", "(", "correct_prob", "-", "incorrect_prob", ",", "0", ")", ",", "\n", "incorrect_prob", ">", "correct_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.joint_weighted_criteria": [[151, 226], ["asrs_strategy.joint_weighted_criteria.compute_criteria_score"], "function", ["None"], ["", "def", "joint_weighted_criteria", "(", "\n", "tokenizer", ",", "data_record", ",", "field", ",", "origin", ",", "batch_tensor", ",", "\n", "pos_st", ",", "pos_ed", ",", "previous_ids", ",", "candidate_ids", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ",", "\n", "clf_metric", ",", "clf_weight", ",", "ppl_metric", ",", "ppl_weight", ",", "burnin_weight", ",", "stats", ",", "state", ",", "\n", "device", ",", "seq_len", ",", "log_prob_previous_ids", ",", "log_prob_candidate_ids", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Accept or reject candidate word using the joint weighted criteria.\n\n    Args:\n        tokenizer (transformers.BertTokenizer): a bert tokenizer.\n        data_record (dict): the data record dict.\n        field (str): the field to rewritten.\n        origin (str): original text. Same as ``data_record[field]``.\n        batch_tensor (torch.Tensor): tensor of a batch of text with size ``(batch_size, L)``.\n        pos_st (int): the start position of sampling (include).\n        pos_ed (int): the end position of sampling (exclude).\n        previous_ids (torch.Tensor): word ids before current step of sampling with\n            size ``(batch_size, pos_ed-pos_st)``.\n        candidate_ids (torch.Tensor): proposed word ids in this sampling step with\n            size ``(batch_size, pos_ed-pos_st)``.\n        sim_metric (USESimilarityMetric): a universal sentence encoder metric object.\n        sim_threshold (float): the universal sentence encoder similarity threshold.\n        sim_weight (float): the weight for USE criteria score.\n        clf_metric (BertClassifier): a BertClassifier metric.\n        clf_weight (float): the weight for BERT criteria score.\n        ppl_metric (GPT2PerplexityMetric): a GPT2PerplexityMetric metric.\n        ppl_weight (float): the weight for GPT2 criteria score.\n        burnin_weight (float): the discount factor.\n        stats (dict): a dict to keep track the accept rate.\n        state (np.array): the state is criteria score from the previous iteration.\n        seq_len (np.array): the valid length for each sentence in the batch.\n        device (torch.Device): the device that batch_tensor is on.\n    Returns:\n        (np.array, np.array)\n            a 2-D int array of size ``batch_size, pos_ed - pos_st``. Each row ``i`` is\n                either ``previous_ids[i, :]`` if rejected, or ``candidate_ids[i, :]`` if accepted.\n            a 1-D float array of criteria score.\n    \"\"\"", "\n", "if", "burnin_weight", "==", "0", ":", "\n", "        ", "return", "all_accept_criteria", "(", "candidate_ids", ",", "stats", ")", "\n", "\n", "", "def", "compute_criteria_score", "(", "fill_ids", ")", ":", "\n", "        ", "batch_tensor", "[", ":", ",", "pos_st", ":", "pos_ed", "]", "=", "fill_ids", "\n", "paraphrases", "=", "[", "tostring", "(", "tokenizer", ",", "x", "[", "1", ":", "ll", "-", "1", "]", ")", "\n", "for", "x", ",", "ll", "in", "zip", "(", "batch_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "seq_len", ")", "]", "\n", "ppl_score", ",", "ppl_ratio", "=", "ppl_criteria_score", "(", "origin", "=", "origin", ",", "paraphrases", "=", "paraphrases", ",", "\n", "ppl_metric", "=", "ppl_metric", ",", "ppl_weight", "=", "ppl_weight", ")", "\n", "sim_score", ",", "sim_value", "=", "sim_criteria_score", "(", "\n", "origin", "=", "origin", ",", "paraphrases", "=", "paraphrases", ",", "sim_metric", "=", "sim_metric", ",", "\n", "sim_weight", "=", "sim_weight", ",", "sim_threshold", "=", "sim_threshold", ")", "\n", "clf_score", ",", "is_incorrect", "=", "clf_criteria_score", "(", "\n", "origin", "=", "origin", ",", "paraphrases", "=", "paraphrases", ",", "data_record", "=", "data_record", ",", "\n", "field", "=", "field", ",", "clf_metric", "=", "clf_metric", ",", "clf_weight", "=", "clf_weight", ")", "\n", "return", "ppl_score", "+", "sim_score", "+", "clf_score", ",", "is_incorrect", "\n", "\n", "", "if", "state", "is", "not", "None", ":", "\n", "        ", "previous_criteria_score", "=", "state", "[", "0", "]", "\n", "previous_is_incorrect", "=", "state", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "previous_criteria_score", ",", "previous_is_incorrect", "=", "compute_criteria_score", "(", "previous_ids", ")", "\n", "\n", "", "candidate_criteria_score", ",", "candidate_is_incorrect", "=", "compute_criteria_score", "(", "candidate_ids", ")", "\n", "\n", "alpha", "=", "np", ".", "exp", "(", "(", "candidate_criteria_score", "-", "previous_criteria_score", "\n", "+", "log_prob_previous_ids", "-", "log_prob_candidate_ids", ")", "*", "burnin_weight", ")", "\n", "\n", "accept", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "rand", "(", "len", "(", "alpha", ")", ")", "<", "alpha", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "stats", "[", "\"accept\"", "]", "+=", "np", ".", "sum", "(", "accept", ")", "\n", "stats", "[", "\"all\"", "]", "+=", "len", "(", "accept", ")", "\n", "state", "=", "(", "candidate_criteria_score", "*", "accept", "+", "previous_criteria_score", "*", "(", "1", "-", "accept", ")", ",", "\n", "candidate_is_incorrect", "*", "accept", "+", "previous_is_incorrect", "*", "(", "1", "-", "accept", ")", ")", "\n", "\n", "accept", "=", "torch", ".", "tensor", "(", "accept", ")", ".", "to", "(", "device", ")", "\n", "ids", "=", "candidate_ids", "*", "accept", ".", "reshape", "(", "-", "1", ",", "1", ")", "+", "previous_ids", "*", "(", "1", "-", "accept", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", "\n", "return", "ids", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.none_constraint": [[228, 230], ["None"], "function", ["None"], ["", "def", "none_constraint", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.allow_list_constraint": [[232, 234], ["None"], "function", ["None"], ["", "def", "allow_list_constraint", "(", "allow_list", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "-", "1e6", "*", "(", "1", "-", "allow_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_strategy.wpe_constraint": [[236, 245], ["current_emb.sum.sum", "torch.nn.functional.cosine_similarity", "word_embs"], "function", ["None"], ["", "def", "wpe_constraint", "(", "target_emb", ",", "word_embs", ",", "batch_tensor", ",", "pos_st", ",", "pos_ed", ",", "\n", "wpe_threshold", ",", "wpe_weight", ",", "attention_mask_paraphrase_text_only", ",", "**", "kwargs", ")", ":", "\n", "    ", "current_emb", "=", "word_embs", "(", "batch_tensor", ")", "*", "attention_mask_paraphrase_text_only", "[", ":", ",", ":", ",", "None", "]", "\n", "current_emb", "[", ":", ",", "pos_st", ",", "pos_ed", "]", "=", "0", "\n", "current_emb", "=", "current_emb", ".", "sum", "(", "dim", "=", "1", ")", "\n", "candidate_emb", "=", "current_emb", "[", ":", ",", "None", ",", ":", "]", "+", "word_embs", ".", "weight", ".", "data", "[", "None", ",", ":", ",", ":", "]", "\n", "dis", "=", "F", ".", "cosine_similarity", "(", "candidate_emb", ",", "target_emb", "[", ":", ",", "None", ",", ":", "]", ",", "dim", "=", "2", ")", "\n", "dis", "=", "(", "wpe_threshold", "-", "dis", ")", ".", "clamp_", "(", "min", "=", "0", ")", "\n", "return", "-", "wpe_weight", "*", "dis", "*", "dis", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.identity_strategy.IdentityStrategy.paraphrase_example": [[9, 11], ["None"], "methods", ["None"], ["def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "return", "[", "data_record", "[", "self", ".", "_field", "]", "]", ",", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.remove_strategy.RemoveStrategy.fit": [[8, 11], ["remove_strategy.RemoveStrategy._metric_bundle.get_target_classifier", "remove_strategy.RemoveStrategy._metric_bundle.get_target_classifier"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_clf", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_tokenizer", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", ".", "_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.remove_strategy.RemoveStrategy.paraphrase_example": [[12, 23], ["remove_strategy.RemoveStrategy._tokenizer.tokenize", "range", "len", "remove_strategy.RemoveStrategy._tokenizer.convert_tokens_to_string", "remove_strategy.RemoveStrategy._clf.predict_example", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_example"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "text", "=", "data_record", "[", "self", ".", "_field", "]", "\n", "tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "            ", "current", "=", "self", ".", "_tokenizer", ".", "convert_tokens_to_string", "(", "tokens", "[", ":", "i", "]", "+", "tokens", "[", "i", "+", "1", ":", "]", ")", "\n", "pred", "=", "self", ".", "_clf", ".", "predict_example", "(", "None", ",", "current", ")", "\n", "if", "pred", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "                ", "return", "[", "current", "]", ",", "i", "+", "1", "\n", "\n", "", "", "return", "[", "text", "]", ",", "len", "(", "tokens", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.random_strategy.RandomStrategy.paraphrase_example": [[11, 20], ["text.split", "range", "numpy.random.shuffle", "ret.append"], "methods", ["None"], ["def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "text", "=", "data_record", "[", "self", ".", "_field", "]", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "tokens", ")", "\n", "ret", ".", "append", "(", "\" \"", ".", "join", "(", "tokens", ")", ")", "\n", "\n", "", "return", "ret", ",", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.cheat_strategy.CheatStrategy.paraphrase_example": [[9, 11], ["None"], "methods", ["None"], ["def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "return", "[", "data_record", "[", "\"ref\"", "]", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.FudgeStrategy.fit": [[43, 90], ["fudge_strategy.FudgeStrategy._metric_bundle.get_metric", "fudge_strategy.FudgeStrategy._metric_bundle.get_target_classifier", "transformers.GPT2TokenizerFast.from_pretrained", "os.path.exists", "transformers.GPT2LMHeadModel.from_pretrained().to", "fibber.metrics.classifier.transformer_classifier.get_optimizer", "fudge_strategy.FudgeStrategy._model.train", "tqdm.tqdm", "fudge_strategy.FudgeStrategy._model.eval", "fudge_strategy.FudgeStrategy._model.save_pretrained", "fibber.resources.get_transformers", "transformers.GPT2LMHeadModel.from_pretrained().to", "range", "numpy.random.choice", "zip", "fudge_strategy.make_batch", "fudge_strategy.make_batch", "torch.tensor", "torch.tensor", "torch.tensor", "fudge_strategy.FudgeStrategy._model", "opt.zero_grad", "output[].backward", "opt.step", "sche.step", "transformers.GPT2LMHeadModel.from_pretrained", "fudge_strategy.FudgeStrategy._model.parameters", "fudge_strategy.make_input_output_pair", "torch.tensor.to", "print", "transformers.GPT2LMHeadModel.from_pretrained", "fibber.resources.get_transformers", "torch.tensor.to", "torch.tensor.to"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.get_optimizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_input_output_pair", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_sim_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"USESimilarityMetric\"", ")", "\n", "self", ".", "_clf_metric", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "\n", "gpt2_pretrained_model", "=", "\"gpt2-medium\"", "\n", "self", ".", "_tokenizer", "=", "GPT2TokenizerFast", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "gpt2_pretrained_model", ")", ")", "\n", "\n", "path", "=", "\"gpt2-%s-1\"", "%", "self", ".", "_dataset_name", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "self", ".", "_model", "=", "GPT2LMHeadModel", ".", "from_pretrained", "(", "path", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "return", "\n", "\n", "", "self", ".", "_model", "=", "GPT2LMHeadModel", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "gpt2_pretrained_model", ")", ")", ".", "to", "(", "\n", "self", ".", "_device", ")", "\n", "\n", "opt", ",", "sche", "=", "get_optimizer", "(", "\"adam\"", ",", "lr", "=", "0.0001", ",", "decay", "=", "0.001", ",", "\n", "params", "=", "self", ".", "_model", ".", "parameters", "(", ")", ",", "train_step", "=", "5000", ")", "\n", "\n", "self", ".", "_model", ".", "train", "(", ")", "\n", "for", "i", "in", "tqdm", ".", "tqdm", "(", "range", "(", "5000", ")", ")", ":", "\n", "            ", "batch", "=", "np", ".", "random", ".", "choice", "(", "trainset", "[", "\"data\"", "]", ",", "size", "=", "8", ")", "\n", "text", "=", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "batch", "]", "\n", "input_output", "=", "[", "\n", "make_input_output_pair", "(", "\n", "self", ".", "_tokenizer", ",", "\"<|endoftext|> \"", "+", "x", "+", "\" <|endoftext|> \"", "+", "x", ")", "for", "x", "in", "text", "]", "\n", "input", ",", "output", "=", "zip", "(", "*", "input_output", ")", "\n", "\n", "toks_input", ",", "mask", "=", "make_batch", "(", "input", ")", "\n", "toks_output", ",", "_", "=", "make_batch", "(", "output", ")", "\n", "toks_output", "=", "toks_output", "*", "mask", "-", "100", "*", "(", "1", "-", "mask", ")", "\n", "toks_input", "=", "torch", ".", "tensor", "(", "toks_input", ")", "\n", "toks_output", "=", "torch", ".", "tensor", "(", "toks_output", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "mask", ")", "\n", "\n", "output", "=", "self", ".", "_model", "(", "toks_input", ".", "to", "(", "self", ".", "_device", ")", ",", "attention_mask", "=", "mask", ".", "to", "(", "self", ".", "_device", ")", ",", "\n", "labels", "=", "toks_output", ".", "to", "(", "self", ".", "_device", ")", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "output", "[", "0", "]", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "sche", ".", "step", "(", ")", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "output", "[", "0", "]", ")", "\n", "", "", "self", ".", "_model", ".", "eval", "(", ")", "\n", "self", ".", "_model", ".", "save_pretrained", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.FudgeStrategy.score": [[91, 105], ["fudge_strategy.FudgeStrategy._tokenizer.decode", "fudge_strategy.FudgeStrategy._sim_metric.measure_batch", "fudge_strategy.FudgeStrategy._clf_metric.predict_log_dist_batch", "dist[].copy", "numpy.max", "numpy.maximum", "numpy.maximum", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "score", "(", "self", ",", "data_record", ",", "tmp", ",", "text", ",", "ll", ")", ":", "\n", "        ", "t0_for_use", "=", "self", ".", "_tokenizer", ".", "decode", "(", "tmp", "[", "1", ":", "ll", "+", "1", "]", ")", "\n", "sim", "=", "self", ".", "_sim_metric", ".", "measure_batch", "(", "t0_for_use", ",", "text", ")", "\n", "\n", "dist", "=", "self", ".", "_clf_metric", ".", "predict_log_dist_batch", "(", "t0_for_use", ",", "text", ")", "\n", "label", "=", "data_record", "[", "\"label\"", "]", "\n", "\n", "# print(t0_for_use, text)", "\n", "correct_prob", "=", "(", "dist", "[", ":", ",", "label", "]", ")", ".", "copy", "(", ")", "\n", "dist", "[", ":", ",", "label", "]", "=", "-", "1e8", "\n", "incorrect_prob", "=", "np", ".", "max", "(", "dist", ",", "axis", "=", "1", ")", "\n", "\n", "return", "-", "np", ".", "maximum", "(", "correct_prob", "-", "incorrect_prob", ",", "0", ")", "-", "10", "*", "np", ".", "maximum", "(", "0.95", "-", "np", ".", "asarray", "(", "sim", ")", ",", "0", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.FudgeStrategy.paraphrase_example": [[106, 138], ["fudge_strategy.make_input_output_pair", "torch.tensor().to", "range", "range", "ret.append", "torch.tensor", "torch.log_softmax", "torch.log_softmax.topk", "kth_idx.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "torch.tensor().to.detach().cpu().numpy", "fudge_strategy.FudgeStrategy.score", "torch.tensor().to", "torch.softmax().detach().cpu().numpy", "numpy.random.choice", "fudge_strategy.FudgeStrategy._tokenizer.decode", "len", "fudge_strategy.FudgeStrategy._tokenizer.decode", "len", "fudge_strategy.FudgeStrategy._model", "kth_idx.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "torch.tensor().to.detach().cpu", "list", "torch.tensor", "torch.softmax().detach().cpu", "batch[].detach().cpu().numpy", "kth_idx.detach().cpu().numpy.detach().cpu().numpy.detach", "torch.tensor().to.detach", "len", "torch.softmax().detach", "batch[].detach().cpu", "len", "len", "torch.softmax", "batch[].detach", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_input_output_pair", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.FudgeStrategy.score"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "tmp", ",", "_", "=", "make_input_output_pair", "(", "\n", "self", ".", "_tokenizer", ",", "\n", "\"<|endoftext|> \"", "+", "data_record", "[", "\"text0\"", "]", "+", "\" <|endoftext|> \"", "+", "data_record", "[", "\"text0\"", "]", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "[", "tmp", "]", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "topk", "=", "20", "\n", "ret", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tmp", ")", "//", "2", "+", "2", ",", "len", "(", "tmp", ")", "-", "1", ")", ":", "\n", "                ", "lm_logits", "=", "self", ".", "_model", "(", "batch", "[", ":", ",", ":", "i", "+", "1", "]", ")", "[", "0", "]", "[", "0", ",", "-", "1", ",", ":", "]", "\n", "lm_logits", "[", "self", ".", "_tokenizer", ".", "eos_token_id", "]", "=", "-", "1e8", "\n", "lm_prob", "=", "torch", ".", "log_softmax", "(", "lm_logits", ",", "dim", "=", "0", ")", "\n", "kth_vals", ",", "kth_idx", "=", "lm_prob", ".", "topk", "(", "topk", ",", "dim", "=", "-", "1", ")", "\n", "\n", "kth_idx", "=", "kth_idx", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_np", "=", "batch", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "text", "=", "[", "list", "(", "batch_np", "[", "0", "]", "[", "len", "(", "tmp", ")", "//", "2", "+", "2", ":", "i", "+", "1", "]", ")", "+", "[", "t", "]", "for", "t", "in", "kth_idx", "]", "\n", "text", "=", "[", "self", ".", "_tokenizer", ".", "decode", "(", "t", ")", "for", "t", "in", "text", "]", "\n", "score", "=", "self", ".", "score", "(", "data_record", ",", "tmp", ",", "text", ",", "i", "-", "len", "(", "tmp", ")", "//", "2", "-", "1", ")", "\n", "\n", "kth_vals", "+=", "torch", ".", "tensor", "(", "score", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "kth_vals", "=", "torch", ".", "softmax", "(", "kth_vals", ",", "dim", "=", "0", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pick", "=", "np", ".", "random", ".", "choice", "(", "kth_idx", ",", "p", "=", "kth_vals", ")", "\n", "batch", "[", "0", "]", "[", "i", "+", "1", "]", "=", "pick", "\n", "\n", "", "ret", ".", "append", "(", "\n", "self", ".", "_tokenizer", ".", "decode", "(", "\n", "batch", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "len", "(", "tmp", ")", "//", "2", "+", "2", ":", "len", "(", "tmp", ")", "-", "1", "]", ")", ")", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.make_input_output_pair": [[13, 21], ["tokenizer.encode", "len"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["def", "make_input_output_pair", "(", "tokenizer", ",", "x", ")", ":", "\n", "    ", "\"\"\"Tokenize the text, then construct input and output for GPT2.\"\"\"", "\n", "toks", "=", "tokenizer", ".", "encode", "(", "x", ",", "add_special_tokens", "=", "True", ")", "\n", "\n", "(", "len", "(", "toks", ")", ")", "//", "2", "\n", "output", "=", "toks", "[", ":", "]", "\n", "# output[:half] = -100", "\n", "return", "toks", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.fudge_strategy.make_batch": [[23, 36], ["len", "max", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.asarray", "len", "len", "len"], "function", ["None"], ["", "def", "make_batch", "(", "toks_list", ")", ":", "\n", "    ", "\"\"\"Convert multiple text to a batch tensor.\"\"\"", "\n", "n", "=", "len", "(", "toks_list", ")", "\n", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "toks_list", "]", ")", "\n", "\n", "ids", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_len", ")", ",", "dtype", "=", "'int'", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_len", ")", ",", "dtype", "=", "'int'", ")", "\n", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "toks_list", ")", ":", "\n", "        ", "ids", "[", "i", ",", ":", "len", "(", "item", ")", "]", "=", "np", ".", "asarray", "(", "item", ")", "\n", "mask", "[", "i", ",", ":", "len", "(", "item", ")", "]", "=", "1", "\n", "\n", "", "return", "ids", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.__repr__": [[351, 353], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"-\"", "+", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.fit": [[354, 412], ["logger.info", "fibber.metrics.bert_lm_utils.get_lm", "rewrite_rollback_strategy.RewriteRollbackStrategy._bert_lm.to", "rewrite_rollback_strategy.RewriteRollbackStrategy._metric_bundle.get_metric", "rewrite_rollback_strategy.RewriteRollbackStrategy._metric_bundle.get_target_classifier", "rewrite_rollback_strategy.RewriteRollbackStrategy._metric_bundle.get_metric", "rewrite_rollback_strategy.RewriteRollbackStrategy._metric_bundle.get_metric", "fibber.paraphrase_strategies.asrs_utils_wpe.get_wordpiece_emb", "torch.nn.Embedding", "torch.tensor().float", "rewrite_rollback_strategy.RewriteRollbackStrategy._word_embs.to", "rewrite_rollback_strategy.RewriteRollbackStrategy._word_embs.eval", "rewrite_rollback_strategy.RewriteRollbackStrategy._word_embs.parameters", "numpy.zeros", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer.convert_tokens_to_ids", "torch.tensor().to", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.asrs_utils_wpe.get_wordpiece_emb"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "# load BERT language model.", "\n", "        ", "logger", ".", "info", "(", "\"Load bert language model for RewriteRollbackStrategy.\"", ")", "\n", "\n", "self", ".", "_tokenizer", ",", "lm", "=", "get_lm", "(", "\n", "self", ".", "_strategy_config", "[", "\"lm_option\"", "]", ",", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_device", ",", "\n", "lm_steps", "=", "self", ".", "_strategy_config", "[", "\"lm_steps\"", "]", ")", "\n", "\n", "self", ".", "_bert_lm", "=", "lm", "\n", "self", ".", "_bert_lm", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "# Load useful metrics", "\n", "self", ".", "_sim_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\n", "self", ".", "_strategy_config", "[", "\"sim_metric\"", "]", ")", "\n", "self", ".", "_clf_metric", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_ppl_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"BertPerplexityMetric\"", ")", "\n", "self", ".", "_edit_metric", "=", "self", ".", "_metric_bundle", ".", "get_metric", "(", "\"EditDistanceMetric\"", ")", "\n", "\n", "# load word piece embeddings.", "\n", "wpe", "=", "get_wordpiece_emb", "(", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_tokenizer", ",", "self", ".", "_device", ")", "\n", "assert", "wpe", ".", "shape", "[", "0", "]", "==", "300", "\n", "wpe", "[", ":", ",", "self", ".", "_tokenizer", ".", "mask_token_id", "]", "=", "0", "\n", "wpe", "[", ":", ",", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "wpe", "[", ":", ",", "self", ".", "_tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "\n", "self", ".", "_word_embs", "=", "nn", ".", "Embedding", "(", "self", ".", "_tokenizer", ".", "vocab_size", ",", "300", ")", "\n", "self", ".", "_word_embs", ".", "weight", ".", "data", "=", "torch", ".", "tensor", "(", "wpe", ".", "T", ")", ".", "float", "(", ")", "\n", "self", ".", "_word_embs", "=", "self", ".", "_word_embs", ".", "to", "(", "self", ".", "_device", ")", "\n", "self", ".", "_word_embs", ".", "eval", "(", ")", "\n", "for", "item", "in", "self", ".", "_word_embs", ".", "parameters", "(", ")", ":", "\n", "            ", "item", ".", "requires_grad", "=", "False", "\n", "\n", "# config _decision_fn and _enforcing_dist_fn", "\n", "", "if", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"all\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "all_accept_criteria", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"accept_criteria\"", "]", "==", "\"joint_weighted_criteria\"", ":", "\n", "            ", "self", ".", "_decision_fn", "=", "joint_weighted_criteria", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "if", "self", ".", "_strategy_config", "[", "\"enforcing_dist\"", "]", "==", "\"none\"", ":", "\n", "            ", "self", ".", "_enforcing_dist_fn", "=", "none_constraint", "\n", "", "elif", "self", ".", "_strategy_config", "[", "\"enforcing_dist\"", "]", "==", "\"wpe\"", ":", "\n", "            ", "self", ".", "_enforcing_dist_fn", "=", "wpe_constraint", "\n", "", "else", ":", "\n", "            ", "assert", "0", "\n", "\n", "", "self", ".", "_redflag_vocab", "=", "np", ".", "zeros", "(", "self", ".", "_tokenizer", ".", "vocab_size", ")", "\n", "self", ".", "_redflag_vocab", "[", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "1", "\n", "self", ".", "_redflag_vocab", "[", "self", ".", "_tokenizer", ".", "cls_token_id", "]", "=", "1", "\n", "self", ".", "_redflag_vocab", "[", "self", ".", "_tokenizer", ".", "mask_token_id", "]", "=", "1", "\n", "for", "item", "in", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "REDFLAG_WORDS", ")", ":", "\n", "            ", "self", ".", "_redflag_vocab", "[", "item", "]", "=", "1", "\n", "", "self", ".", "_redflag_vocab", "=", "torch", ".", "tensor", "(", "self", ".", "_redflag_vocab", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "self", ".", "_stats", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"accept\"", ":", "0", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.paraphrase_example": [[414, 416], ["rewrite_rollback_strategy.RewriteRollbackStrategy.paraphrase_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.paraphrase_multiple_examples"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "return", "self", ".", "paraphrase_multiple_examples", "(", "[", "data_record", "]", "*", "n", ")", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.RewriteRollbackStrategy.paraphrase_multiple_examples": [[417, 526], ["rewrite_rollback_strategy.compute_wpe_embedding", "range", "logger.info", "torch.masked_select().view", "rewrite_rollback_strategy.RewriteRollbackStrategy._enforcing_dist_fn", "rewrite_rollback_strategy.sample_word_from_logits", "rewrite_rollback_strategy.assign_candidates", "rewrite_rollback_strategy.RewriteRollbackStrategy._decision_fn", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer.tokenize", "numpy.random.randint", "min", "numpy.random.choice", "rewrite_rollback_strategy.smart_mask", "n_masks.append", "paraphrases_with_mask.append", "masked_part_text.append", "masked_index.append", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer().to", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer().to", "rewrite_rollback_strategy.RewriteRollbackStrategy._bert_lm", "logits_lm.size", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer.convert_ids_to_tokens", "range", "max", "len", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer.convert_tokens_to_string", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer.convert_tokens_to_string", "torch.masked_select", "len", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer", "rewrite_rollback_strategy.RewriteRollbackStrategy._tokenizer", "rewrite_rollback_strategy.roll_back", "numpy.sum", "numpy.sum", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.compute_wpe_embedding", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.sample_word_from_logits", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.assign_candidates", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.smart_mask", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.roll_back"], ["", "def", "paraphrase_multiple_examples", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "origin", "=", "[", "item", "[", "self", ".", "_field", "]", "for", "item", "in", "data_record_list", "]", "\n", "paraphrases", "=", "origin", "[", ":", "]", "\n", "context", "=", "None", "if", "self", ".", "_field", "==", "\"text0\"", "else", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "data_record_list", "]", "\n", "\n", "sampling_steps", "=", "self", ".", "_strategy_config", "[", "\"sampling_steps\"", "]", "\n", "window_size", "=", "self", ".", "_strategy_config", "[", "\"window_size\"", "]", "\n", "\n", "target_emb", "=", "compute_wpe_embedding", "(", "paraphrases", ",", "word_embs", "=", "self", ".", "_word_embs", ",", "\n", "tokenizer", "=", "self", ".", "_tokenizer", ",", "device", "=", "self", ".", "_device", ")", "\n", "\n", "decision_fn_state", "=", "None", "\n", "\n", "for", "ii", "in", "range", "(", "sampling_steps", ")", ":", "\n", "            ", "paraphrases_tokenized", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "sent", ")", "for", "sent", "in", "paraphrases", "]", "\n", "paraphrases_with_mask", "=", "[", "]", "\n", "masked_part_text", "=", "[", "]", "\n", "masked_index", "=", "[", "]", "\n", "n_masks", "=", "[", "]", "\n", "for", "toks", "in", "paraphrases_tokenized", ":", "\n", "                ", "st", "=", "np", ".", "random", ".", "randint", "(", "max", "(", "len", "(", "toks", ")", "-", "window_size", ",", "1", ")", ")", "\n", "ed", "=", "min", "(", "st", "+", "window_size", ",", "len", "(", "toks", ")", ")", "\n", "if", "st", "-", "ed", "<", "window_size", ":", "\n", "                    ", "choices", "=", "[", "0", ",", "1", "]", "\n", "p", "=", "[", "0.8", ",", "0.2", "]", "\n", "", "else", ":", "\n", "                    ", "choices", "=", "[", "-", "1", ",", "0", ",", "1", "]", "\n", "p", "=", "[", "0.1", ",", "0.8", ",", "0.1", "]", "\n", "", "op", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "p", ")", "\n", "masked_part", ",", "n_mask_tmp", "=", "smart_mask", "(", "toks", ",", "st", ",", "ed", ",", "op", ")", "\n", "n_masks", ".", "append", "(", "n_mask_tmp", ")", "\n", "paraphrases_with_mask", ".", "append", "(", "\n", "self", ".", "_tokenizer", ".", "convert_tokens_to_string", "(", "\n", "toks", "[", ":", "st", "]", "+", "masked_part", "+", "toks", "[", "ed", ":", "]", ")", ")", "\n", "masked_part_text", ".", "append", "(", "self", ".", "_tokenizer", ".", "convert_tokens_to_string", "(", "toks", "[", "st", ":", "ed", "]", ")", ")", "\n", "masked_index", ".", "append", "(", "(", "st", ",", "st", "+", "len", "(", "masked_part", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "_field", "==", "\"text1\"", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "context", ",", "paraphrases_with_mask", ",", "padding", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "else", ":", "\n", "                ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "paraphrases_with_mask", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "", "logits_lm", "=", "self", ".", "_bert_lm", "(", "**", "batch_input", ")", "[", "0", "]", "\n", "\n", "logits_for_masked_toks", "=", "torch", ".", "masked_select", "(", "\n", "logits_lm", ",", "(", "batch_input", ".", "input_ids", "==", "self", ".", "_tokenizer", ".", "mask_token_id", ")", ".", "unsqueeze", "(", "2", ")", "\n", ")", ".", "view", "(", "-", "1", ",", "logits_lm", ".", "size", "(", "2", ")", ")", "\n", "logits_for_masked_toks", "-=", "1e8", "*", "self", ".", "_redflag_vocab", "\n", "\n", "logits_enforcing", "=", "self", ".", "_enforcing_dist_fn", "(", "\n", "target_emb", "=", "target_emb", ",", "\n", "word_embs", "=", "self", ".", "_word_embs", ",", "\n", "paraphrases_with_mask", "=", "paraphrases_with_mask", ",", "\n", "n_masks", "=", "n_masks", ",", "\n", "tokenizer", "=", "self", ".", "_tokenizer", ",", "\n", "wpe_threshold", "=", "self", ".", "_strategy_config", "[", "\"wpe_threshold\"", "]", ",", "\n", "wpe_weight", "=", "self", ".", "_strategy_config", "[", "\"wpe_weight\"", "]", ",", "\n", "device", "=", "self", ".", "_device", "\n", ")", "\n", "\n", "logits_joint", "=", "logits_for_masked_toks", "+", "logits_enforcing", "\n", "candidate_ids", "=", "sample_word_from_logits", "(", "\n", "logits_joint", ",", "top_k", "=", "self", ".", "_strategy_config", "[", "\"top_k\"", "]", ",", "\n", "temperature", "=", "self", ".", "_strategy_config", "[", "\"temperature\"", "]", ")", "\n", "\n", "candidate_paraphrases", ",", "filled_in_text", "=", "assign_candidates", "(", "\n", "paraphrases_with_mask", ",", "self", ".", "_tokenizer", ".", "convert_ids_to_tokens", "(", "candidate_ids", ")", ",", "\n", "self", ".", "_tokenizer", ",", "masked_index", "=", "masked_index", ")", "\n", "log_prob_previous_ids", "=", "0", "\n", "log_prob_candidate_ids", "=", "0", "\n", "\n", "paraphrases", ",", "decision_fn_state", "=", "self", ".", "_decision_fn", "(", "\n", "origin_list", "=", "origin", ",", "prev_paraphrases", "=", "paraphrases", ",", "\n", "candidate_paraphrases", "=", "candidate_paraphrases", ",", "\n", "data_record_list", "=", "data_record_list", ",", "\n", "field", "=", "self", ".", "_field", ",", "\n", "sim_metric", "=", "self", ".", "_sim_metric", ",", "\n", "sim_threshold", "=", "self", ".", "_strategy_config", "[", "\"sim_threshold\"", "]", ",", "\n", "sim_weight", "=", "self", ".", "_strategy_config", "[", "\"sim_weight\"", "]", ",", "\n", "clf_metric", "=", "self", ".", "_clf_metric", ",", "clf_weight", "=", "self", ".", "_strategy_config", "[", "\"clf_weight\"", "]", ",", "\n", "ppl_metric", "=", "self", ".", "_ppl_metric", ",", "ppl_weight", "=", "self", ".", "_strategy_config", "[", "\"ppl_weight\"", "]", ",", "\n", "stats", "=", "self", ".", "_stats", ",", "state", "=", "decision_fn_state", ",", "\n", "log_prob_trans_forward", "=", "log_prob_candidate_ids", ",", "\n", "log_prob_trans_backward", "=", "log_prob_previous_ids", ",", "\n", "edit_metric", "=", "self", ".", "_edit_metric", ",", "\n", "masked_part_text", "=", "masked_part_text", ",", "\n", "filled_in_text", "=", "filled_in_text", ")", "\n", "\n", "if", "(", "ii", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "                ", "for", "kk", "in", "range", "(", "len", "(", "paraphrases", ")", ")", ":", "\n", "                    ", "if", "decision_fn_state", "[", "1", "]", "[", "kk", "]", ":", "\n", "                        ", "paraphrases", "[", "kk", "]", "=", "roll_back", "(", "\n", "data_record_list", "[", "kk", "]", ",", "paraphrases", "[", "kk", "]", ",", "self", ".", "_clf_metric", ")", "\n", "", "", "if", "(", "self", ".", "_strategy_config", "[", "\"early_stop\"", "]", "==", "\"half\"", "\n", "and", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", ">=", "len", "(", "data_record_list", ")", "*", "0.5", ")", ":", "\n", "                    ", "break", "\n", "", "if", "(", "self", ".", "_strategy_config", "[", "\"early_stop\"", "]", "==", "\"5\"", "\n", "and", "np", ".", "sum", "(", "decision_fn_state", "[", "1", "]", ")", ">=", "5", ")", ":", "\n", "                    ", "break", "\n", "", "decision_fn_state", "=", "None", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Aggregated accept rate: %.2lf%%. Success rate: %.2lf%%\"", ",", "\n", "self", ".", "_stats", "[", "\"accept\"", "]", "/", "self", ".", "_stats", "[", "\"all\"", "]", "*", "100", ",", "\n", "self", ".", "_stats", "[", "\"success\"", "]", ")", "\n", "\n", "return", "paraphrases", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.roll_back": [[18, 107], ["nltk.word_tokenize", "nltk.word_tokenize", "numpy.zeros", "range", "range", "range", "len", "len", "len", "range", "clf_metric.predict_log_dist_multiple_examples", "logger.warning", "len", "len", "len", "min", "rewrite_rollback_strategy.roll_back.check"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], ["def", "roll_back", "(", "record", ",", "adv", ",", "clf_metric", ")", ":", "\n", "    ", "s1", "=", "word_tokenize", "(", "record", "[", "\"text0\"", "]", ")", "\n", "s2", "=", "word_tokenize", "(", "adv", ")", "\n", "\n", "f", "=", "np", ".", "zeros", "(", "(", "len", "(", "s1", ")", "+", "1", ",", "len", "(", "s2", ")", "+", "1", ")", ",", "dtype", "=", "'int'", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "s1", ")", "+", "1", ")", ":", "\n", "        ", "f", "[", "i", ",", "0", "]", "=", "i", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "s2", ")", "+", "1", ")", ":", "\n", "        ", "f", "[", "0", ",", "i", "]", "=", "i", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "s1", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "s2", ")", ")", ":", "\n", "            ", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "min", "(", "f", "[", "i", ",", "j", "+", "1", "]", "+", "1", ",", "f", "[", "i", "+", "1", ",", "j", "]", "+", "1", ",", "f", "[", "i", ",", "j", "]", "+", "1", ")", "\n", "if", "s1", "[", "i", "]", "==", "s2", "[", "j", "]", ":", "\n", "                ", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "min", "(", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", ",", "f", "[", "i", "]", "[", "j", "]", ")", "\n", "\n", "", "", "", "p", "=", "len", "(", "s1", ")", "\n", "q", "=", "len", "(", "s2", ")", "\n", "\n", "def", "check", "(", "toks_prev", ",", "toks", ",", "record", ")", ":", "\n", "        ", "s", "=", "\" \"", ".", "join", "(", "toks", ")", "\n", "# return clf_metric.predict_example(None, s) != record[\"label\"]", "\n", "s_prev", "=", "\" \"", ".", "join", "(", "toks_prev", ")", "\n", "log_prob", "=", "clf_metric", ".", "predict_log_dist_multiple_examples", "(", "None", ",", "[", "s", ",", "s_prev", "]", ")", "\n", "label", "=", "record", "[", "\"label\"", "]", "\n", "return", "np", ".", "argmax", "(", "log_prob", "[", "0", "]", ")", "!=", "label", "or", "log_prob", "[", "0", ",", "label", "]", "<", "log_prob", "[", "1", ",", "label", "]", "\n", "\n", "", "cc", "=", "0", "\n", "\n", "while", "p", ">", "0", "or", "q", ">", "0", ":", "\n", "        ", "if", "p", "==", "0", ":", "\n", "            ", "s2tmp", "=", "s2", "[", ":", "]", "\n", "del", "s2tmp", "[", "q", "-", "1", "]", "\n", "if", "check", "(", "s2", ",", "s2tmp", ",", "record", ")", ":", "\n", "                ", "s2", "=", "s2tmp", "\n", "cc", "+=", "1", "\n", "", "q", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "q", "==", "0", ":", "\n", "            ", "s2tmp", "=", "[", "s1", "[", "p", "-", "1", "]", "]", "+", "s2", "[", ":", "]", "\n", "if", "check", "(", "s2", ",", "s2tmp", ",", "record", ")", ":", "\n", "                ", "s2", "=", "s2tmp", "\n", "cc", "+=", "1", "\n", "", "p", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "s1", "[", "p", "-", "1", "]", "==", "s2", "[", "q", "-", "1", "]", "and", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "-", "1", "]", "[", "q", "-", "1", "]", ":", "\n", "            ", "p", "-=", "1", "\n", "q", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "]", "[", "q", "-", "1", "]", "+", "1", ":", "\n", "            ", "s2tmp", "=", "s2", "[", ":", "]", "\n", "del", "s2tmp", "[", "q", "-", "1", "]", "\n", "if", "check", "(", "s2", ",", "s2tmp", ",", "record", ")", ":", "\n", "                ", "s2", "=", "s2tmp", "\n", "cc", "+=", "1", "\n", "", "q", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "-", "1", "]", "[", "q", "-", "1", "]", "+", "1", ":", "\n", "            ", "s2tmp", "=", "s2", "[", ":", "]", "\n", "s2tmp", "[", "q", "-", "1", "]", "=", "s1", "[", "p", "-", "1", "]", "\n", "if", "check", "(", "s2", ",", "s2tmp", ",", "record", ")", ":", "\n", "                ", "s2", "=", "s2tmp", "\n", "cc", "+=", "1", "\n", "", "p", "-=", "1", "\n", "q", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "-", "1", "]", "[", "q", "]", "+", "1", ":", "\n", "            ", "s2tmp", "=", "s2", "[", ":", "q", "]", "+", "[", "s1", "[", "p", "-", "1", "]", "]", "+", "s2", "[", "q", ":", "]", "\n", "if", "check", "(", "s2", ",", "s2tmp", ",", "record", ")", ":", "\n", "                ", "s2", "=", "s2tmp", "\n", "cc", "+=", "1", "\n", "", "p", "-=", "1", "\n", "continue", "\n", "\n", "", "logger", ".", "warning", "(", "\"incorrect rollback\"", ")", "\n", "break", "\n", "# print(p, q)", "\n", "# print(f[p][q], f[p - 1][q], f[p][q - 1], f[p - 1][q - 1])", "\n", "# print(s1[p - 1], s2[q - 1])", "\n", "# assert 0", "\n", "\n", "", "return", "\" \"", ".", "join", "(", "s2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.tostring": [[109, 117], ["tokenizer.decode"], "function", ["None"], ["", "def", "tostring", "(", "tokenizer", ",", "seq", ")", ":", "\n", "    ", "\"\"\"Convert a sequence of word ids to a sentence. The post prossing is applied.\n\n    Args:\n        tokenizer (transformers.BertTokenizer): a BERT tokenizer.\n        seq (list): a list-like sequence of word ids.\n    \"\"\"", "\n", "return", "tokenizer", ".", "decode", "(", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.sample_word_from_logits": [[119, 138], ["logits.topk", "torch.distributions.categorical.Categorical", "kth_idx.gather().squeeze", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.sample().squeeze", "kth_idx.gather", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample().unsqueeze", "torch.distributions.categorical.Categorical.sample"], "function", ["None"], ["", "def", "sample_word_from_logits", "(", "logits", ",", "temperature", "=", "1.", ",", "top_k", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sample a word from a distribution.\n\n    Args:\n        logits (torch.Tensor): tensor of logits with size ``(batch_size, vocab_size)``.\n        temperature (float): the temperature of softmax. The PMF is\n            ``softmax(logits/temperature)``.\n        top_k (int): if ``k>0``, only sample from the top k most probable words.\n    \"\"\"", "\n", "logits", "=", "logits", "/", "temperature", "\n", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "kth_vals", ",", "kth_idx", "=", "logits", ".", "topk", "(", "top_k", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "kth_vals", ")", "\n", "idx", "=", "kth_idx", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "dist", ".", "sample", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "dist", "=", "torch", ".", "distributions", ".", "categorical", ".", "Categorical", "(", "logits", "=", "logits", ")", "\n", "idx", "=", "dist", ".", "sample", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.all_accept_criteria": [[140, 144], ["None"], "function", ["None"], ["", "def", "all_accept_criteria", "(", "candidate_paraphrases", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Always accept proposed words.\n    \"\"\"", "\n", "return", "candidate_paraphrases", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.sim_criteria_score": [[146, 163], ["sim_metric.measure_multiple_examples", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples"], ["", "def", "sim_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        sim_metric (MetricBase): a similarity metric object.\n        sim_threshold (float): the universal sentence encoder similarity threshold.\n        sim_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "use_semantic_similarity", "=", "sim_metric", ".", "measure_multiple_examples", "(", "origin_list", ",", "paraphrases", ")", "\n", "return", "(", "-", "sim_weight", "*", "(", "\n", "np", ".", "maximum", "(", "sim_threshold", "-", "np", ".", "asarray", "(", "use_semantic_similarity", ")", ",", "0", ")", ")", ",", "\n", "use_semantic_similarity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.ppl_criteria_score": [[165, 180], ["ppl_metric.measure_multiple_examples", "numpy.maximum", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples"], ["", "def", "ppl_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "ppl_metric", ",", "ppl_weight", ")", ":", "\n", "    ", "\"\"\"Estimate the score of a sentence using USE.\n\n    Args:\n        origin (str): original sentence.\n        paraphrases ([str]): a list of paraphrase_list.\n        ppl_metric (GPT2PerplexityMetric): a GPT2PerplexityMetric metric object.\n        ppl_weight (float): the weight parameter for the criteria.\n\n    Returns:\n        (np.array): a numpy array of size ``(batch_size,)``. All entries ``<=0``.\n    \"\"\"", "\n", "ppl_ratio", "=", "ppl_metric", ".", "measure_multiple_examples", "(", "origin_list", ",", "paraphrases", ",", "use_ratio", "=", "True", ")", "\n", "return", "(", "-", "ppl_weight", "*", "(", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "ppl_ratio", ")", "-", "1", ",", "0", ")", ")", ",", "\n", "ppl_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.clf_criteria_score": [[182, 206], ["clf_metric.predict_log_dist_multiple_examples", "zip", "numpy.asarray", "numpy.zeros", "pred_dist[].copy", "numpy.max", "not_correct.append", "np.asarray.append", "numpy.asarray", "len", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], ["", "def", "clf_criteria_score", "(", "origin_list", ",", "paraphrases", ",", "data_record_list", ",", "field", ",", "clf_metric", ",", "\n", "clf_weight", ")", ":", "\n", "    ", "if", "clf_weight", "==", "0", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "len", "(", "paraphrases", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "", "dist_list", "=", "clf_metric", ".", "predict_log_dist_multiple_examples", "(", "\n", "origin_list", ",", "paraphrases", ",", "data_record_list", ")", "\n", "# dist_list = np.exp(dist_list)", "\n", "\n", "scores", "=", "[", "]", "\n", "not_correct", "=", "[", "]", "\n", "for", "pred_dist", ",", "data_record", "in", "zip", "(", "dist_list", ",", "data_record_list", ")", ":", "\n", "        ", "label", "=", "data_record", "[", "\"label\"", "]", "\n", "correct_prob", "=", "(", "pred_dist", "[", "label", "]", ")", ".", "copy", "(", ")", "\n", "pred_dist", "[", "label", "]", "=", "-", "1e8", "\n", "incorrect_prob", "=", "np", ".", "max", "(", "pred_dist", ")", "\n", "not_correct", ".", "append", "(", "correct_prob", "<", "incorrect_prob", ")", "\n", "# margin = 1 / len(pred_dist)", "\n", "scores", ".", "append", "(", "correct_prob", "-", "incorrect_prob", ")", "\n", "# scores.append(1 - incorrect_prob)", "\n", "\n", "", "scores", "=", "np", ".", "asarray", "(", "scores", ")", "\n", "\n", "return", "-", "clf_weight", "*", "np", ".", "maximum", "(", "scores", ",", "0", ")", ",", "np", ".", "asarray", "(", "not_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.joint_weighted_criteria": [[208, 253], ["rewrite_rollback_strategy.joint_weighted_criteria.compute_criteria_score"], "function", ["None"], ["", "def", "joint_weighted_criteria", "(", "\n", "origin_list", ",", "prev_paraphrases", ",", "candidate_paraphrases", ",", "\n", "data_record_list", ",", "field", ",", "sim_metric", ",", "sim_threshold", ",", "sim_weight", ",", "\n", "clf_metric", ",", "clf_weight", ",", "ppl_metric", ",", "ppl_weight", ",", "stats", ",", "state", ",", "\n", "log_prob_trans_forward", ",", "log_prob_trans_backward", ",", "edit_metric", ",", "\n", "masked_part_text", ",", "filled_in_text", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "def", "compute_criteria_score", "(", "paraphrases", ")", ":", "\n", "        ", "ppl_score", ",", "ppl_ratio", "=", "ppl_criteria_score", "(", "origin_list", "=", "origin_list", ",", "paraphrases", "=", "paraphrases", ",", "\n", "ppl_metric", "=", "ppl_metric", ",", "ppl_weight", "=", "ppl_weight", ")", "\n", "sim_score", ",", "sim_value", "=", "sim_criteria_score", "(", "origin_list", "=", "origin_list", ",", "paraphrases", "=", "paraphrases", ",", "\n", "sim_metric", "=", "sim_metric", ",", "sim_weight", "=", "sim_weight", ",", "\n", "sim_threshold", "=", "sim_threshold", ")", "\n", "clf_score", ",", "is_incorrect", "=", "clf_criteria_score", "(", "origin_list", "=", "origin_list", ",", "\n", "paraphrases", "=", "paraphrases", ",", "\n", "data_record_list", "=", "data_record_list", ",", "\n", "field", "=", "field", ",", "clf_metric", "=", "clf_metric", ",", "\n", "clf_weight", "=", "clf_weight", ")", "\n", "return", "ppl_score", "+", "sim_score", "+", "clf_score", ",", "is_incorrect", "\n", "\n", "", "if", "state", "is", "not", "None", ":", "\n", "        ", "previous_criteria_score", "=", "state", "[", "0", "]", "\n", "previous_is_incorrect", "=", "state", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "previous_criteria_score", ",", "previous_is_incorrect", "=", "compute_criteria_score", "(", "prev_paraphrases", ")", "\n", "\n", "", "candidate_criteria_score", ",", "candidate_is_incorrect", "=", "compute_criteria_score", "(", "\n", "candidate_paraphrases", ")", "\n", "\n", "candidate_criteria_score", "-=", "previous_is_incorrect", "*", "(", "1", "-", "candidate_is_incorrect", ")", "*", "1e8", "\n", "\n", "alpha", "=", "np", ".", "exp", "(", "(", "candidate_criteria_score", "-", "previous_criteria_score", "\n", "+", "log_prob_trans_backward", "-", "log_prob_trans_forward", ")", ")", "\n", "\n", "accept", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "rand", "(", "len", "(", "alpha", ")", ")", "<", "alpha", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "stats", "[", "\"accept\"", "]", "+=", "np", ".", "sum", "(", "accept", ")", "\n", "stats", "[", "\"all\"", "]", "+=", "len", "(", "accept", ")", "\n", "state", "=", "(", "candidate_criteria_score", "*", "accept", "+", "previous_criteria_score", "*", "(", "1", "-", "accept", ")", ",", "\n", "candidate_is_incorrect", "*", "accept", "+", "previous_is_incorrect", "*", "(", "1", "-", "accept", ")", ")", "\n", "\n", "ret", "=", "[", "candidate_paraphrases", "[", "idx", "]", "if", "is_acc", "else", "prev_paraphrases", "[", "idx", "]", "\n", "for", "idx", ",", "is_acc", "in", "enumerate", "(", "accept", ")", "]", "\n", "stats", "[", "\"success\"", "]", "=", "np", ".", "sum", "(", "state", "[", "1", "]", ")", "\n", "return", "ret", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.none_constraint": [[255, 257], ["None"], "function", ["None"], ["", "def", "none_constraint", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.compute_wpe_embedding": [[259, 262], ["tokenizer().to", "tokenizer", "word_embs"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer"], ["", "def", "compute_wpe_embedding", "(", "sents", ",", "word_embs", ",", "tokenizer", ",", "device", ")", ":", "\n", "    ", "batch_input", "=", "tokenizer", "(", "sents", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "device", ")", "\n", "return", "(", "word_embs", "(", "batch_input", ".", "input_ids", ")", "*", "batch_input", ".", "attention_mask", "[", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.wpe_constraint": [[264, 275], ["rewrite_rollback_strategy.compute_wpe_embedding", "torch.nn.functional.cosine_similarity", "enumerate", "torch.stack"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.compute_wpe_embedding"], ["", "def", "wpe_constraint", "(", "target_emb", ",", "word_embs", ",", "paraphrases_with_mask", ",", "n_masks", ",", "tokenizer", ",", "\n", "wpe_threshold", ",", "wpe_weight", ",", "device", ",", "**", "kwargs", ")", ":", "\n", "    ", "current_emb", "=", "compute_wpe_embedding", "(", "paraphrases_with_mask", ",", "word_embs", ",", "tokenizer", ",", "device", ")", "\n", "dis", "=", "F", ".", "cosine_similarity", "(", "(", "target_emb", "-", "current_emb", ")", "[", ":", ",", "None", ",", ":", "]", ",", "\n", "word_embs", ".", "weight", ".", "data", "[", "None", ",", ":", ",", ":", "]", ",", "dim", "=", "2", ")", "\n", "dis", "=", "(", "wpe_threshold", "-", "dis", ")", ".", "clamp_", "(", "min", "=", "0", ")", "\n", "dis", "=", "-", "wpe_weight", "*", "dis", "\n", "ret", "=", "[", "]", "\n", "for", "idx", ",", "cc", "in", "enumerate", "(", "n_masks", ")", ":", "\n", "        ", "ret", "+=", "[", "dis", "[", "idx", "]", "]", "*", "cc", "\n", "", "return", "torch", ".", "stack", "(", "ret", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.count_mask": [[277, 284], ["tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "count_mask", "(", "data", ",", "tokenizer", ")", ":", "\n", "    ", "counter", "=", "0", "\n", "for", "line", "in", "data", ":", "\n", "        ", "for", "tok", "in", "tokenizer", ".", "tokenize", "(", "line", ")", ":", "\n", "            ", "if", "tok", "==", "\"[MASK]\"", ":", "\n", "                ", "counter", "+=", "1", "\n", "", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.assign_candidates": [[286, 303], ["enumerate", "tokenizer.tokenize", "tokenizer.tokenize.index", "ret.append", "filled_in_part.append", "tokenizer.convert_tokens_to_string", "tokenizer.convert_tokens_to_string"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "assign_candidates", "(", "paraphrases_with_mask", ",", "candidate_words", ",", "tokenizer", ",", "masked_index", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "filled_in_part", "=", "[", "]", "\n", "p", "=", "0", "\n", "for", "idx", ",", "paraphrase", "in", "enumerate", "(", "paraphrases_with_mask", ")", ":", "\n", "        ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "paraphrase", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "", "except", "BaseException", ":", "\n", "                ", "ret", ".", "append", "(", "tokenizer", ".", "convert_tokens_to_string", "(", "tokens", ")", ")", "\n", "filled_in_part", ".", "append", "(", "tokenizer", ".", "convert_tokens_to_string", "(", "\n", "tokens", "[", "masked_index", "[", "idx", "]", "[", "0", "]", ":", "masked_index", "[", "idx", "]", "[", "1", "]", "]", ")", ")", "\n", "break", "\n", "", "tokens", "[", "mask_index", "]", "=", "candidate_words", "[", "p", "]", "\n", "p", "+=", "1", "\n", "", "", "return", "ret", ",", "filled_in_part", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.rewrite_rollback_strategy.smart_mask": [[305, 324], ["numpy.random.randint", "len", "tok.isalpha", "ret.append", "ret.append", "tok.lower", "tok.lower"], "function", ["None"], ["", "def", "smart_mask", "(", "toks_raw", ",", "st", ",", "ed", ",", "op", ")", ":", "\n", "    ", "toks", "=", "toks_raw", "[", "st", ":", "ed", "]", "\n", "if", "op", "==", "-", "1", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "toks", ")", ")", "\n", "del", "toks", "[", "idx", "]", "\n", "\n", "", "ret", "=", "[", "]", "\n", "counter", "=", "0", "\n", "for", "tok", "in", "toks", ":", "\n", "        ", "if", "tok", ".", "isalpha", "(", ")", "and", "(", "tok", ".", "lower", "(", ")", "==", "tok", ")", "and", "(", "tok", ".", "lower", "(", ")", "not", "in", "REDFLAG_WORDS", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\"[MASK]\"", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "            ", "ret", ".", "append", "(", "tok", ")", "\n", "\n", "", "", "if", "op", "==", "1", ":", "\n", "        ", "ret", "+=", "[", "\"[MASK]\"", "]", "\n", "counter", "+=", "op", "\n", "", "return", "ret", ",", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.__init__": [[38, 92], ["object.__init__", "dict", "str", "logger.warning", "torch.device", "logger.info", "torch.device", "logger.warning", "str", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", ":", "\n", "        ", "\"\"\"Initialize the paraphrase_strategies.\n\n        This function initialize the ``self._strategy_config``, ``self._metric_bundle``,\n        ``self._device``, ``self._output_dir``, ``self._dataset_name``.\n\n        **You should not overwrite this function.**\n\n        * self._strategy_config (dict): a dictionary that stores the strategy name and all\n          hyperparameter values. The dict is also saved to the results.\n        * self._metric_bundle (MetricBundle): the metrics that will be used to evaluate\n          paraphrases. Strategies can compute metrics during paraphrasing.\n        * self._device (torch.Device): any computation that requires a GPU accelerator should\n          use this device.\n        * self._output_dir (str): the dir name where the strategy can save files.\n        * self._dataset_name (str): the dataset name.\n\n        Args:\n            arg_dict (dict): all args load from command line.\n            dataset_name (str): the name of the dataset.\n            strategy_gpu_id (int): the gpu id to run the strategy.\n            output_dir (str): a directory to save any models or temporary files.\n            metric_bundle (MetricBundle): a MetricBundle object.\n        \"\"\"", "\n", "super", "(", "StrategyBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# paraphrase_strategies config will be saved to the results.", "\n", "self", ".", "_strategy_config", "=", "dict", "(", ")", "\n", "\n", "for", "p_name", ",", "p_type", ",", "p_default", ",", "p_help", "in", "self", ".", "__hyperparameters__", ":", "\n", "            ", "arg_name", "=", "\"%s_%s\"", "%", "(", "self", ".", "__abbr__", ",", "p_name", ")", "\n", "if", "arg_name", "not", "in", "arg_dict", ":", "\n", "                ", "logger", ".", "warning", "(", "\"%s_%s not found in args.\"", ",", "self", ".", "__abbr__", ",", "p_name", ")", "\n", "p_value", "=", "p_default", "\n", "", "else", ":", "\n", "                ", "p_value", "=", "arg_dict", "[", "arg_name", "]", "\n", "\n", "", "assert", "p_name", "not", "in", "self", ".", "_strategy_config", "\n", "self", ".", "_strategy_config", "[", "p_name", "]", "=", "p_value", "\n", "\n", "", "self", ".", "_strategy_config", "[", "\"strategy_name\"", "]", "=", "str", "(", "self", ")", "\n", "\n", "self", ".", "_metric_bundle", "=", "metric_bundle", "\n", "\n", "if", "strategy_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"%s is running on CPU.\"", "%", "str", "(", "self", ")", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s is running on GPU %d.\"", ",", "str", "(", "self", ")", ",", "strategy_gpu_id", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "strategy_gpu_id", ")", "\n", "\n", "", "self", ".", "_output_dir", "=", "output_dir", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_field", "=", "field", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.__repr__": [[93, 95], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.add_parser_args": [[96, 109], ["logger.info", "len", "parser.add_argument"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_parser_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"create commandline args for all hyperparameters in ``__hyperparameters__``.\n\n        Args:\n            parser: an arg parser.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"%s has %d args to set from command line.\"", ",", "\n", "cls", ".", "__name__", ",", "len", "(", "cls", ".", "__hyperparameters__", ")", ")", "\n", "\n", "for", "p_name", ",", "p_type", ",", "p_default", ",", "p_help", "in", "cls", ".", "__hyperparameters__", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\"--%s_%s\"", "%", "(", "cls", ".", "__abbr__", ",", "p_name", ")", ",", "type", "=", "p_type", ",", "\n", "default", "=", "p_default", ",", "help", "=", "p_help", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.fit": [[110, 117], ["logger.info"], "methods", ["None"], ["", "", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "\"\"\"Fit the paraphrase strategy on a training set.\n\n        Args:\n            trainset (dict): a fibber dataset.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Training is needed for this strategy. Did nothing.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_example": [[118, 133], ["NotImplementedError"], "methods", ["None"], ["", "def", "paraphrase_example", "(", "self", ",", "data_record", ",", "n", ")", ":", "\n", "        ", "\"\"\"Paraphrase one data record.\n\n        This function should be overwritten by subclasses. When overwriting this class, you can\n        use ``self._strategy_config``, ``self._metric_bundle``,  ``self._device``,\n        ``self._output_dir``, and ``self._dataset_name``\n\n        Args:\n            data_record (dict): a dict storing one data of a dataset.\n            n (int): number of paraphrases.\n\n        Returns:\n            ([str,]): A list contain at most n strings.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_dataset": [[134, 170], ["copy.deepcopy", "tqdm.tqdm", "dict", "copy.deepcopy", "results[].append", "open", "json.dump", "strategy_base.StrategyBase.paraphrase_example", "datetime.datetime.now().timestamp", "datetime.datetime.now().timestamp", "open", "json.dump", "paraphrase_set.items", "datetime.datetime.now", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_example"], ["", "def", "paraphrase_dataset", "(", "self", ",", "paraphrase_set", ",", "n", ",", "tmp_output_filename", ")", ":", "\n", "        ", "\"\"\"Paraphrase one dataset.\n\n        Args:\n            paraphrase_set (dict): a dict storing one data of a dataset.\n            n (int): number of paraphrases.\n            tmp_output_filename (str): the output json filename to save results during running.\n\n        Returns:\n            (dict): A dict containing the original text and paraphrased text.\n        \"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "dict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "paraphrase_set", ".", "items", "(", ")", "if", "k", "!=", "\"data\"", "]", ")", ")", "\n", "results", "[", "\"strategy_config\"", "]", "=", "self", ".", "_strategy_config", "\n", "results", "[", "\"data\"", "]", "=", "[", "]", "\n", "\n", "last_tmp_output_save_time", "=", "-", "1", "\n", "\n", "for", "data_record", "in", "tqdm", ".", "tqdm", "(", "paraphrase_set", "[", "\"data\"", "]", ")", ":", "\n", "            ", "data_record", "=", "copy", ".", "deepcopy", "(", "data_record", ")", "\n", "paraphrases", ",", "clf_count", "=", "(", "self", ".", "paraphrase_example", "(", "data_record", ",", "n", ")", "[", ":", "n", "]", ")", "\n", "\n", "data_record", "[", "self", ".", "_field", "+", "\"_paraphrases\"", "]", "=", "paraphrases", "\n", "data_record", "[", "\"clf_count\"", "]", "=", "clf_count", "\n", "\n", "results", "[", "\"data\"", "]", ".", "append", "(", "data_record", ")", "\n", "\n", "# save tmp output every 600 seconds", "\n", "if", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "-", "last_tmp_output_save_time", ">", "600", ":", "\n", "                ", "with", "open", "(", "tmp_output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "last_tmp_output_save_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "\n", "\n", "", "", "with", "open", "(", "tmp_output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.__init__": [[33, 110], ["object.__init__", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_classifier", "metric_utils.MetricBundle.add_classifier", "metric_utils.MetricBundle.add_metric", "len", "range", "metric_utils.MetricBundle.add_metric", "metric_utils.MetricBundle.add_metric", "fibber.metrics.distance.edit_distance_metric.EditDistanceMetric", "fibber.metrics.similarity.use_similarity_metric.USESimilarityMetric", "fibber.metrics.similarity.glove_similarity_metric.GloVeSimilarityMetric", "fibber.metrics.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric", "fibber.metrics.similarity.ce_similarity_metric.CESimilarityMetric", "fibber.metrics.classifier.transformer_classifier.TransformerClassifier", "fibber.metrics.classifier.fasttext_classifier.FasttextClassifier", "fibber.metrics.fluency.bert_perplexity_metric.BertPerplexityMetric", "metric_utils.MetricBundle.add_metric", "fibber.metrics.distance.self_bleu_metric.SelfBleuMetric", "fibber.metrics.distance.ref_bleu_metric.RefBleuMetric", "fibber.metrics.fluency.bert_perplexity_metric.BertPerplexityMetric"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric"], ["def", "__init__", "(", "self", ",", "\n", "enable_edit_distance", "=", "True", ",", "\n", "enable_use_similarity", "=", "True", ",", "\n", "enable_glove_similarity", "=", "True", ",", "\n", "enable_gpt2_perplexity", "=", "False", ",", "\n", "enable_transformer_classifier", "=", "True", ",", "\n", "enable_ce_similarity", "=", "False", ",", "\n", "enable_fasttext_classifier", "=", "False", ",", "\n", "enable_bert_perplexity", "=", "True", ",", "\n", "enable_bert_perplexity_per_class", "=", "False", ",", "\n", "enable_self_bleu", "=", "False", ",", "\n", "enable_ref_bleu", "=", "False", ",", "\n", "target_clf", "=", "\"transformer\"", ",", "\n", "field", "=", "\"text0\"", ",", "bs", "=", "32", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize various metrics.\n\n        Args:\n            enable_edit_distance (bool): whether to use editing distance in the bundle.\n            enable_use_similarity (bool): whether to use Universal sentence encoder to\n                compute sentence similarity\n            enable_glove_similarity (bool): whether to use Glove embeddings to compute\n                sentence similarity.\n            enable_gpt2_perplexity (bool): whether to use GPT2 to compute sentence quality.\n            enable_transformer_classifier (bool): whether to include BERT classifier prediction in\n                metrics.\n            enable_ce_similarity (bool): whether to use Cross Encoder to measure sentence\n                similarity.\n            enable_fasttext_classifier (bool): whether to include Fasttext classifier prediction\n                in metrics.\n            target_clf (str): choose from \"trasformer\", \"fasttext\".\n            field (str): the field where perturbation can happen.\n            bs (int): batch size.\n            kwargs: arguments for metrics. kwargs will be passed to all metrics.\n        \"\"\"", "\n", "super", "(", "MetricBundle", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_metrics", "=", "{", "}", "\n", "self", ".", "_classifiers", "=", "{", "}", "\n", "self", ".", "_target_clf", "=", "None", "\n", "self", ".", "_field", "=", "field", "\n", "\n", "self", ".", "_advanced_aggregation_fn", "=", "{", "}", "\n", "\n", "if", "enable_edit_distance", ":", "\n", "            ", "self", ".", "add_metric", "(", "EditDistanceMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_UNKNOWN", ")", "\n", "", "if", "enable_use_similarity", ":", "\n", "            ", "self", ".", "add_metric", "(", "USESimilarityMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_HIGHER_BETTER", ")", "\n", "", "if", "enable_glove_similarity", ":", "\n", "            ", "self", ".", "add_metric", "(", "GloVeSimilarityMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_HIGHER_BETTER", ")", "\n", "", "if", "enable_gpt2_perplexity", ":", "\n", "            ", "self", ".", "add_metric", "(", "GPT2PerplexityMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_LOWER_BETTER", ")", "\n", "", "if", "enable_ce_similarity", ":", "\n", "            ", "self", ".", "add_metric", "(", "CESimilarityMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_HIGHER_BETTER", ")", "\n", "", "if", "enable_transformer_classifier", ":", "\n", "            ", "self", ".", "add_classifier", "(", "TransformerClassifier", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "set_target_clf", "=", "(", "target_clf", "==", "\"transformer\"", ")", ")", "\n", "", "if", "enable_fasttext_classifier", ":", "\n", "            ", "self", ".", "add_classifier", "(", "FasttextClassifier", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "set_target_clf", "=", "(", "target_clf", "==", "\"fasttext\"", ")", ")", "\n", "", "if", "enable_bert_perplexity", ":", "\n", "            ", "self", ".", "add_metric", "(", "BertPerplexityMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_LOWER_BETTER", ")", "\n", "", "if", "enable_bert_perplexity_per_class", ":", "\n", "            ", "n_labels", "=", "len", "(", "kwargs", "[", "\"trainset\"", "]", "[", "\"label_mapping\"", "]", ")", "\n", "for", "i", "in", "range", "(", "n_labels", ")", ":", "\n", "                ", "self", ".", "add_metric", "(", "\n", "BertPerplexityMetric", "(", "bert_ppl_filter", "=", "i", ",", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "\n", "DIRECTION_LOWER_BETTER", ")", "\n", "", "", "if", "enable_self_bleu", ":", "\n", "            ", "self", ".", "add_metric", "(", "SelfBleuMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "DIRECTION_UNKNOWN", ")", "\n", "", "if", "enable_ref_bleu", ":", "\n", "            ", "self", ".", "add_metric", "(", "RefBleuMetric", "(", "field", "=", "field", ",", "bs", "=", "bs", ",", "**", "kwargs", ")", ",", "DIRECTION_HIGHER_BETTER", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_metric": [[111, 126], ["isinstance", "logger.error", "str", "logger.error", "str", "str", "str"], "methods", ["None"], ["", "", "def", "add_metric", "(", "self", ",", "metric", ",", "direction", ")", ":", "\n", "        ", "\"\"\"Add a customized metric to metric bundle.\n\n        Args:\n            metric (MetricBase): the metric object to add.\n            direction (str): choose from ``DIRECTION_HIGHER_BETTER``, ``DIRECTION_HIGHER_BETTER``\n                and ``DIRECTION_UNKNOWN``.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "metric", ",", "MetricBase", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"%s is not an instance of MetricBase.\"", ",", "str", "(", "metric", ")", ")", "\n", "raise", "RuntimeError", "\n", "", "if", "str", "(", "metric", ")", "in", "self", ".", "_metrics", ":", "\n", "            ", "logger", ".", "error", "(", "\"Duplicate metric %s.\"", ",", "str", "(", "metric", ")", ")", "\n", "raise", "RuntimeError", "\n", "", "self", ".", "_metrics", "[", "str", "(", "metric", ")", "]", "=", "(", "metric", ",", "direction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric": [[127, 141], ["None"], "methods", ["None"], ["", "def", "get_metric", "(", "self", ",", "metric_name", ")", ":", "\n", "        ", "\"\"\"Returns a metric in the bundle using the metric name.\n\n        Metric name is the class name of a metric.\n\n        Raises assertion error if metric is not found.\n\n        Args:\n            metric_name: the name of the matric.\n        Returns:\n            (MetricBase): a metric object.\n        \"\"\"", "\n", "assert", "metric_name", "in", "self", ".", "_metrics", "\n", "return", "self", ".", "_metrics", "[", "metric_name", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_direction": [[142, 156], ["None"], "methods", ["None"], ["", "def", "get_metric_direction", "(", "self", ",", "metric_name", ")", ":", "\n", "        ", "\"\"\"Returns the direction of a metric.\n\n        Metric name is the class name of a metric.\n\n        Raises assertion error if metric is not found.\n\n        Args:\n            metric_name: the name of the matric.\n        Returns:\n            (MetricBase): a metric object.\n        \"\"\"", "\n", "assert", "metric_name", "in", "self", ".", "_metrics", "\n", "return", "self", ".", "_metrics", "[", "metric_name", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_names": [[157, 164], ["list", "metric_utils.MetricBundle._metrics.keys"], "methods", ["None"], ["", "def", "get_metric_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"\"Returns all metric names in this metric bundle.\n\n        Returns:\n            list of str\n        \"\"\"", "\n", "return", "list", "(", "self", ".", "_metrics", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier": [[165, 177], ["isinstance", "str", "metric_utils.MetricBundle.set_target_classifier_by_name", "str", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.set_target_classifier_by_name"], ["", "def", "add_classifier", "(", "self", ",", "classifier_metric", ",", "set_target_clf", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set a target classifier to attack.\n\n        Args:\n            classifier_metric (ClassifierBase): A classifier metric to be added.\n            set_target_clf (bool): whether to set this classifier metric as target classifier.\n        \"\"\"", "\n", "assert", "isinstance", "(", "classifier_metric", ",", "ClassifierBase", ")", "\n", "self", ".", "_classifiers", "[", "str", "(", "classifier_metric", ")", "]", "=", "classifier_metric", "\n", "self", ".", "_target_clf", "=", "str", "(", "classifier_metric", ")", "\n", "if", "set_target_clf", ":", "\n", "            ", "self", ".", "set_target_classifier_by_name", "(", "str", "(", "classifier_metric", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier": [[178, 185], ["None"], "methods", ["None"], ["", "", "def", "get_classifier", "(", "self", ",", "classifier_name", ")", ":", "\n", "        ", "\"\"\"Returns the classifier in current metric bundle.\n\n        Args:\n            classifier_name (str): the name of the requested classifier.\n        \"\"\"", "\n", "return", "self", ".", "_classifiers", "[", "classifier_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier_names": [[186, 188], ["list", "metric_utils.MetricBundle._classifiers.keys"], "methods", ["None"], ["", "def", "get_classifier_names", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "_classifiers", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.set_target_classifier_by_name": [[189, 198], ["isinstance"], "methods", ["None"], ["", "def", "set_target_classifier_by_name", "(", "self", ",", "classifier_name", ")", ":", "\n", "        ", "\"\"\"Set a target classifier to attack.\n\n        Args:\n            classifier_name (str): set a classifier as target classifier.\n        \"\"\"", "\n", "assert", "isinstance", "(", "classifier_name", ",", "str", ")", "\n", "assert", "classifier_name", "in", "self", ".", "_classifiers", "\n", "self", ".", "_target_clf", "=", "classifier_name", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier_name": [[199, 202], ["None"], "methods", ["None"], ["", "def", "get_target_classifier_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the name of the target classifier.\"\"\"", "\n", "return", "self", ".", "_target_clf", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier": [[203, 206], ["metric_utils.MetricBundle.get_classifier", "metric_utils.MetricBundle.get_target_classifier_name"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier_name"], ["", "def", "get_target_classifier", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the classifier for attack.\"\"\"", "\n", "return", "self", ".", "get_classifier", "(", "self", ".", "get_target_classifier_name", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.replace_target_classifier": [[207, 211], ["metric_utils.MetricBundle.add_classifier", "metric_utils.MetricBundle.get_target_classifier_name"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier_name"], ["", "def", "replace_target_classifier", "(", "self", ",", "clf", ")", ":", "\n", "        ", "\"\"\"Remove the original target classifier and add a new classifier.\"\"\"", "\n", "del", "self", ".", "_classifiers", "[", "self", ".", "get_target_classifier_name", "(", ")", "]", "\n", "self", ".", "add_classifier", "(", "clf", ",", "set_target_clf", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.measure_example": [[212, 232], ["metric_utils.MetricBundle.get_metric_names", "metric_utils.MetricBundle.get_classifier_names", "metric_utils.MetricBundle.get_metric", "metric_utils.MetricBundle.measure_example", "metric_utils.MetricBundle.get_classifier", "metric_utils.MetricBundle.measure_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example"], ["", "def", "measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute the results of all metrics in the bundle for one pair of text.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record (dict): the data record.\n\n        Returns:\n            (dict): a dict with metric name as key.\n        \"\"\"", "\n", "ret", "=", "{", "}", "\n", "for", "name", "in", "self", ".", "get_metric_names", "(", ")", ":", "\n", "            ", "metric", "=", "self", ".", "get_metric", "(", "name", ")", "\n", "ret", "[", "name", "]", "=", "metric", ".", "measure_example", "(", "origin", ",", "paraphrase", ",", "data_record", ")", "\n", "", "for", "name", "in", "self", ".", "get_classifier_names", "(", ")", ":", "\n", "            ", "classifier", "=", "self", ".", "get_classifier", "(", "name", ")", "\n", "ret", "[", "name", "]", "=", "classifier", ".", "measure_example", "(", "\n", "origin", ",", "paraphrase", ",", "data_record", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.measure_batch": [[233, 256], ["metric_utils.MetricBundle.get_metric_names", "metric_utils.MetricBundle.get_classifier_names", "metric_utils.MetricBundle.get_metric", "metric_utils.MetricBundle.measure_batch", "range", "metric_utils.MetricBundle.get_classifier", "metric_utils.MetricBundle.measure_batch", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (list): a list containing dict of metrics for each paraphrase.\n        \"\"\"", "\n", "ret", "=", "[", "{", "}", "for", "i", "in", "range", "(", "len", "(", "paraphrase_list", ")", ")", "]", "\n", "for", "name", "in", "self", ".", "get_metric_names", "(", ")", ":", "\n", "            ", "metric", "=", "self", ".", "get_metric", "(", "name", ")", "\n", "result", "=", "metric", ".", "measure_batch", "(", "origin", ",", "paraphrase_list", ",", "data_record", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "paraphrase_list", ")", ")", ":", "\n", "                ", "ret", "[", "i", "]", "[", "name", "]", "=", "result", "[", "i", "]", "\n", "", "", "for", "name", "in", "self", ".", "get_classifier_names", "(", ")", ":", "\n", "            ", "classifier", "=", "self", ".", "get_classifier", "(", "name", ")", "\n", "result", "=", "classifier", ".", "measure_batch", "(", "origin", ",", "paraphrase_list", ",", "data_record", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "paraphrase_list", ")", ")", ":", "\n", "                ", "ret", "[", "i", "]", "[", "name", "]", "=", "result", "[", "i", "]", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.measure_dataset": [[257, 295], ["logger.info", "tqdm.tqdm", "dict", "metric_utils.MetricBundle.measure_example", "metric_utils.MetricBundle.measure_batch", "open", "json.dump", "datetime.datetime.now().timestamp", "datetime.datetime.now().timestamp", "open", "json.dump", "data_record.items", "datetime.datetime.now", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "measure_dataset", "(", "self", ",", "results", ",", "output_filename", ")", ":", "\n", "        ", "\"\"\"Compute the all metrics for results on a dataset.\n\n        Args:\n            results (dict): A fibber dataset with paraphrase_list.\n            output_filename (str): A json filename to store results and metrics.\n\n        Returns:\n            (dict): the results dict with ``original_text_metrics`` and ``paraphrase_metrics``\n                added.\n        \"\"\"", "\n", "last_output_save_time", "=", "-", "1", "\n", "logger", ".", "info", "(", "\"Start measuring.\"", ")", "\n", "\n", "for", "data_record", "in", "tqdm", ".", "tqdm", "(", "results", "[", "\"data\"", "]", ")", ":", "\n", "            ", "data_record_tmp", "=", "dict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "data_record", ".", "items", "(", ")", "\n", "if", "\"_paraphrases\"", "not", "in", "k", "]", ")", "\n", "\n", "# Run metrics on original text", "\n", "data_record", "[", "\"original_text_metrics\"", "]", "=", "self", ".", "measure_example", "(", "\n", "data_record", "[", "self", ".", "_field", "]", ",", "data_record", "[", "self", ".", "_field", "]", ",", "\n", "data_record_tmp", ")", "\n", "\n", "# Run metrics on paraphrased text", "\n", "data_record", "[", "\"paraphrase_metrics\"", "]", "=", "self", ".", "measure_batch", "(", "\n", "data_record", "[", "self", ".", "_field", "]", ",", "data_record", "[", "self", ".", "_field", "+", "\"_paraphrases\"", "]", ",", "\n", "data_record_tmp", ")", "\n", "\n", "# save tmp output every 30 seconds", "\n", "if", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "-", "last_output_save_time", ">", "30", ":", "\n", "                ", "with", "open", "(", "output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "\n", "\n", "", "", "with", "open", "(", "output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_advanced_aggregation_fn": [[296, 312], ["logger.error"], "methods", ["None"], ["", "def", "add_advanced_aggregation_fn", "(", "self", ",", "aggregation_name", ",", "aggregation_fn", ",", "direction", ")", ":", "\n", "        ", "\"\"\"Add advanced aggregation function.\n\n        Some aggregation function can aggregate multiple metrics, these aggregation functions\n        can be added here.\n\n        Args:\n            aggregation_name (str): the name of the aggregation.\n            aggregation_fn (fn): an aggregation function that takes ``data_record`` as arg.\n            direction (str): chose from DIRECTION_HIGHER_BETTER, DIRECTION_LOWER_BETTER,\n                and DIRECTION_UNKNOWN.\n        \"\"\"", "\n", "if", "aggregation_name", "in", "self", ".", "_advanced_aggregation_fn", ":", "\n", "            ", "logger", ".", "error", "(", "\"Duplicate advanced aggregation function %s.\"", ",", "aggregation_name", ")", "\n", "raise", "RuntimeError", "\n", "", "self", ".", "_advanced_aggregation_fn", "[", "aggregation_name", "]", "=", "(", "aggregation_fn", ",", "direction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn_names": [[313, 315], ["list", "metric_utils.MetricBundle._advanced_aggregation_fn.keys"], "methods", ["None"], ["", "def", "get_advanced_aggregation_fn_names", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "_advanced_aggregation_fn", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn_direction": [[316, 318], ["None"], "methods", ["None"], ["", "def", "get_advanced_aggregation_fn_direction", "(", "self", ",", "aggregation_name", ")", ":", "\n", "        ", "return", "self", ".", "_advanced_aggregation_fn", "[", "aggregation_name", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn": [[319, 321], ["None"], "methods", ["None"], ["", "def", "get_advanced_aggregation_fn", "(", "self", ",", "aggregation_name", ")", ":", "\n", "        ", "return", "self", ".", "_advanced_aggregation_fn", "[", "aggregation_name", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.aggregate_metrics": [[322, 369], ["pandas.DataFrame", "dict", "pandas.DataFrame", "pandas.DataFrame.columns.tolist", "len", "metric_utils.MetricBundle.get_advanced_aggregation_fn_names", "aggregated_result.append.append.append", "aggregated_result.append.append.mean", "metric_utils.MetricBundle.get_metric_direction", "numpy.mean", "float", "numpy.std", "float", "metric_utils.MetricBundle.get_advanced_aggregation_fn", "metric_utils.MetricBundle.get_advanced_aggregation_fn_direction", "metric_utils.MetricBundle.", "metric_utils.MetricBundle.get_classifier_names"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_direction", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_advanced_aggregation_fn_direction", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier_names"], ["", "def", "aggregate_metrics", "(", "self", ",", "dataset_name", ",", "paraphrase_strategy_name", ",", "experiment_name", ",", "results", ")", ":", "\n", "        ", "\"\"\"Aggregate paraphrase metrics on a dataset to a summary and store in a dict.\n\n        Args:\n            dataset_name (str): the name of the dataset.\n            paraphrase_strategy_name (str): the name of the paraphrase strategy.\n            experiment_name (str): the name of the experiment.\n            results (dict): the fibber dataset with paraphrases and metrics. The return value of\n                ``compute_metrics``.\n\n        Returns:\n            (dict): the aggregated metrics.\n        \"\"\"", "\n", "aggregated_result", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "data_record", "in", "results", "[", "\"data\"", "]", ":", "\n", "            ", "aggregate_result_tmp", "=", "{", "}", "\n", "metric_df", "=", "pd", ".", "DataFrame", "(", "data_record", "[", "\"paraphrase_metrics\"", "]", ")", "\n", "for", "metric_name", "in", "metric_df", ".", "columns", ".", "tolist", "(", ")", ":", "\n", "                ", "if", "metric_name", "in", "self", ".", "get_classifier_names", "(", ")", ":", "\n", "                    ", "continue", "\n", "", "metric_value", "=", "metric_df", "[", "metric_name", "]", ".", "values", "\n", "direction", "=", "self", ".", "get_metric_direction", "(", "metric_name", ")", "\n", "\n", "# aggregate mean", "\n", "agg_value", "=", "np", ".", "mean", "(", "metric_value", ")", "\n", "aggregate_result_tmp", "[", "metric_name", "+", "direction", "]", "=", "float", "(", "agg_value", ")", "\n", "\n", "# aggregate std", "\n", "agg_value", "=", "np", ".", "std", "(", "metric_value", ")", "\n", "aggregate_result_tmp", "[", "metric_name", "+", "\"_std\"", "]", "=", "float", "(", "agg_value", ")", "\n", "\n", "", "aggregate_result_tmp", "[", "\"ParaphrasesPerExample\"", "]", "=", "len", "(", "data_record", "[", "\"paraphrase_metrics\"", "]", ")", "\n", "\n", "for", "agg_name", "in", "self", ".", "get_advanced_aggregation_fn_names", "(", ")", ":", "\n", "                ", "agg_fn", "=", "self", ".", "get_advanced_aggregation_fn", "(", "agg_name", ")", "\n", "direction", "=", "self", ".", "get_advanced_aggregation_fn_direction", "(", "agg_name", ")", "\n", "aggregate_result_tmp", "[", "agg_name", "+", "direction", "]", "=", "agg_fn", "(", "data_record", ")", "\n", "\n", "", "aggregated_result", "=", "aggregated_result", ".", "append", "(", "aggregate_result_tmp", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "aggregated_result", "=", "dict", "(", "aggregated_result", ".", "mean", "(", "skipna", "=", "True", ")", ")", "\n", "# hack column order by adding 0", "\n", "aggregated_result", "[", "\"dataset_name\"", "]", "=", "dataset_name", "\n", "aggregated_result", "[", "\"paraphrase_strategy_name\"", "]", "=", "paraphrase_strategy_name", "\n", "aggregated_result", "[", "\"experiment_name\"", "]", "=", "experiment_name", "\n", "\n", "return", "aggregated_result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.write_summary": [[17, 22], ["summary.add_scalar", "summary.add_scalar", "numpy.mean"], "function", ["None"], ["def", "write_summary", "(", "stats", ",", "summary", ",", "global_step", ")", ":", "\n", "    ", "\"\"\"Save langauge model training summary.\"\"\"", "\n", "summary", ".", "add_scalar", "(", "\"loss_lm\"", ",", "np", ".", "mean", "(", "stats", "[", "\"lm_loss\"", "]", ")", ",", "global_step", ")", "\n", "summary", ".", "add_scalar", "(", "\"error_lm\"", ",", "1", "-", "stats", "[", "\"lm_correct\"", "]", "/", "stats", "[", "\"lm_total\"", "]", ",", "\n", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.new_stats": [[24, 30], ["None"], "function", ["None"], ["", "def", "new_stats", "(", ")", ":", "\n", "    ", "\"\"\"Create a new stats dict.\"\"\"", "\n", "return", "{", "\n", "\"lm_total\"", ":", "0", ",", "\n", "\"lm_correct\"", ":", "0", ",", "\n", "\"lm_loss\"", ":", "[", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.compute_lm_loss": [[33, 67], ["torch.masked_select().view", "torch.masked_select().view", "lm_model.cls", "torch.cross_entropy", "lm_model.cls.argmax().eq().float().sum().detach().cpu().numpy", "stats[].append", "lm_model.bert", "torch.masked_select().view.size", "torch.no_grad", "torch.no_grad", "torch.masked_select", "torch.masked_select", "F.cross_entropy.detach().cpu().numpy", "torch.masked_select", "torch.masked_select", "lm_label.gt", "lm_model.cls.argmax().eq().float().sum().detach().cpu", "lm_label.gt().unsqueeze", "F.cross_entropy.detach().cpu", "lm_model.cls.argmax().eq().float().sum().detach", "lm_label.gt", "F.cross_entropy.detach", "lm_model.cls.argmax().eq().float().sum", "lm_model.cls.argmax().eq().float", "lm_model.cls.argmax().eq", "lm_model.cls.argmax"], "function", ["None"], ["", "def", "compute_lm_loss", "(", "lm_model", ",", "seq", ",", "mask", ",", "tok_type", ",", "lm_label", ",", "stats", ")", ":", "\n", "    ", "\"\"\"Compute masked language model training loss.\n\n    Args:\n        lm_model (transformers.BertForMaskedLM): a BERT language model.\n        seq (torch.Tensor): an int tensor of size (batch_size, length) representing the word\n            pieces.\n        mask (torch.Tensor): an int tensor of size (batch_size, length) representing the attention\n            mask.\n        tok_type (torch.Tensor): an int tensor of size (batch_size, length) representing the\n            token type id.\n        lm_label (torch.Tensor): an int tensor of size (batch_size, length) representing the label\n            for each position. Use -100 if the loss is not computed for that position.\n        stats (dist): a dictionary storing training stats.\n\n    Returns:\n        (torch.Scalar) a scalar loss value.\n    \"\"\"", "\n", "lm_hid", "=", "lm_model", ".", "bert", "(", "seq", ",", "mask", ",", "tok_type", ")", "[", "0", "]", "\n", "lm_hid", "=", "torch", ".", "masked_select", "(", "lm_hid", ",", "lm_label", ".", "gt", "(", "0", ")", ".", "unsqueeze", "(", "2", ")", ")", ".", "view", "(", "-", "1", ",", "lm_hid", ".", "size", "(", "2", ")", ")", "\n", "logits", "=", "lm_model", ".", "cls", "(", "lm_hid", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "lm_label_squeeze", "=", "torch", ".", "masked_select", "(", "lm_label", ",", "lm_label", ".", "gt", "(", "0", ")", ")", "\n", "\n", "", "lm_loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "lm_label_squeeze", ")", "\n", "\n", "# lm_label is -100 for unmasked token or padding toks.", "\n", "stats", "[", "\"lm_total\"", "]", "+=", "(", "lm_label_squeeze", ">", "0", ")", ".", "int", "(", ")", ".", "sum", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "stats", "[", "\"lm_correct\"", "]", "+=", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "eq", "(", "lm_label_squeeze", ")", "\n", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "stats", "[", "\"lm_loss\"", "]", ".", "append", "(", "lm_loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "return", "lm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.fine_tune_lm": [[69, 179], ["os.path.join", "os.path.exists", "torch.utils.tensorboard.SummaryWriter", "BertLMHeadModel.from_pretrained.train", "BertLMHeadModel.from_pretrained.to", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "list", "fibber.metrics.classifier.transformer_classifier.get_optimizer", "bert_lm_utils.new_stats", "tqdm.tqdm", "BertLMHeadModel.from_pretrained.eval", "BertLMHeadModel.from_pretrained.to", "logger.info", "fibber.datasets.DatasetForTransformers", "transformers.BertForMaskedLM.from_pretrained", "fibber.datasets.DatasetForTransformers", "transformers.BertConfig.from_pretrained", "transformers.BertLMHeadModel.from_pretrained", "BertLMHeadModel.from_pretrained.parameters", "opt.zero_grad", "seq.to.to", "mask.to.to", "tok_type.to.to", "lm_label.to.to", "bert_lm_utils.compute_lm_loss", "compute_lm_loss.backward", "opt.step", "sche.step", "torch.device", "torch.device", "transformers.BertForMaskedLM.from_pretrained().eval", "transformers.BertConfig.from_pretrained", "transformers.BertLMHeadModel.from_pretrained().eval", "fibber.resources.get_transformers", "fibber.resources.get_transformers", "fibber.resources.get_transformers", "bert_lm_utils.write_summary", "bert_lm_utils.new_stats", "BertLMHeadModel.from_pretrained.to().eval", "BertLMHeadModel.from_pretrained.save_pretrained", "BertLMHeadModel.from_pretrained.to", "fibber.resources.get_transformers", "transformers.BertForMaskedLM.from_pretrained", "transformers.BertLMHeadModel.from_pretrained", "BertLMHeadModel.from_pretrained.to", "torch.device", "torch.device"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.get_optimizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.new_stats", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.compute_lm_loss", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.write_summary", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.new_stats", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["", "def", "fine_tune_lm", "(", "output_dir", ",", "trainset", ",", "filter", ",", "device", ",", "model_init", "=", "\"bert-base-cased\"", ",", "\n", "lm_steps", "=", "5000", ",", "lm_bs", "=", "32", ",", "lm_opt", "=", "\"adamw\"", ",", "lm_lr", "=", "0.0001", ",", "lm_decay", "=", "0.01", ",", "\n", "lm_period_summary", "=", "100", ",", "lm_period_save", "=", "5000", ",", "as_masked_lm", "=", "True", ",", "\n", "select_field", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a finetuned BERT language model on a given dataset.\n\n    The language model will be stored at ``<output_dir>/lm_all`` if filter is -1, or\n    ``<output_dir>/lm_filter_?`` if filter is not -1.\n\n    If filter is not -1. The pretrained langauge model will first be pretrained on the while\n    dataset, then it will be finetuned on the data excluding the filter category.\n\n    Args:\n        output_dir (str): a directory to store pretrained language model.\n        trainset (DatasetForTransformers): the training set for finetune the language model.\n        filter (int): a category to exclude from finetuning.\n        device (torch.Device): a device to train the model.\n        model_init (str): the backbone bert model.\n        lm_steps (int): finetuning steps.\n        lm_bs (int): finetuning batch size.\n        lm_opt (str): optimzer name. choose from [\"sgd\", \"adam\", \"adamW\"].\n        lm_lr (float): learning rate.\n        lm_decay (float): weight decay for the optimizer.\n        lm_period_summary (int): number of steps to write training summary.\n        lm_period_save (int): number of steps to save the finetuned model.\n        as_masked_lm (bool): use BERT as a masked language model. If False, use as auto-regressive.\n        select_field (None or str): select one field for language model.\n    Returns:\n        (BertForMaskedLM): a finetuned language model.\n    \"\"\"", "\n", "\n", "if", "as_masked_lm", ":", "\n", "        ", "if", "filter", "==", "-", "1", ":", "\n", "            ", "folder", "=", "\"masked_lm_all\"", "\n", "", "else", ":", "\n", "            ", "folder", "=", "\"masked_lm_filter_%d\"", "%", "filter", "\n", "", "", "else", ":", "\n", "        ", "if", "filter", "==", "-", "1", ":", "\n", "            ", "folder", "=", "\"autoregressive_lm_all\"", "\n", "", "else", ":", "\n", "            ", "folder", "=", "\"autoregressive_lm_filter_%d\"", "%", "filter", "\n", "\n", "", "", "output_dir_t", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "folder", ")", "\n", "\n", "ckpt_path_pattern", "=", "output_dir_t", "+", "\"/checkpoint-%04dk\"", "\n", "ckpt_path", "=", "ckpt_path_pattern", "%", "(", "lm_steps", "//", "1000", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Language model <%s> exists.\"", ",", "ckpt_path", ")", "\n", "if", "as_masked_lm", ":", "\n", "            ", "return", "BertForMaskedLM", ".", "from_pretrained", "(", "ckpt_path", ")", ".", "eval", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "config", ".", "is_decoder", "=", "True", "\n", "return", "BertLMHeadModel", ".", "from_pretrained", "(", "ckpt_path", ",", "config", "=", "config", ")", ".", "eval", "(", ")", "\n", "\n", "", "", "summary", "=", "SummaryWriter", "(", "output_dir_t", "+", "\"/summary\"", ")", "\n", "if", "as_masked_lm", ":", "\n", "        ", "dataset", "=", "DatasetForTransformers", "(", "trainset", ",", "model_init", ",", "lm_bs", ",", "exclude", "=", "filter", ",", "\n", "masked_lm", "=", "True", ",", "select_field", "=", "select_field", ")", "\n", "lm_model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "DatasetForTransformers", "(", "trainset", ",", "model_init", ",", "lm_bs", ",", "exclude", "=", "filter", ",", "\n", "autoregressive_lm", "=", "True", ",", "select_field", "=", "select_field", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "config", ".", "is_decoder", "=", "True", "\n", "lm_model", "=", "BertLMHeadModel", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ",", "\n", "config", "=", "config", ")", "\n", "", "lm_model", ".", "train", "(", ")", "\n", "lm_model", ".", "to", "(", "device", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "None", ",", "num_workers", "=", "0", ")", "\n", "\n", "params", "=", "list", "(", "lm_model", ".", "parameters", "(", ")", ")", "\n", "opt", ",", "sche", "=", "get_optimizer", "(", "lm_opt", ",", "lm_lr", ",", "lm_decay", ",", "lm_steps", ",", "params", ")", "\n", "\n", "global_step", "=", "0", "\n", "stats", "=", "new_stats", "(", ")", "\n", "\n", "for", "seq", ",", "mask", ",", "tok_type", ",", "label", ",", "lm_label", "in", "tqdm", ".", "tqdm", "(", "\n", "dataloader", ",", "total", "=", "lm_steps", ")", ":", "\n", "        ", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "\n", "seq", "=", "seq", ".", "to", "(", "device", ")", "\n", "mask", "=", "mask", ".", "to", "(", "device", ")", "\n", "tok_type", "=", "tok_type", ".", "to", "(", "device", ")", "\n", "lm_label", "=", "lm_label", ".", "to", "(", "device", ")", "\n", "\n", "lm_loss", "=", "compute_lm_loss", "(", "lm_model", ",", "seq", ",", "mask", ",", "tok_type", ",", "lm_label", ",", "stats", ")", "\n", "lm_loss", ".", "backward", "(", ")", "\n", "\n", "opt", ".", "step", "(", ")", "\n", "sche", ".", "step", "(", ")", "\n", "\n", "if", "global_step", "%", "lm_period_summary", "==", "0", ":", "\n", "            ", "write_summary", "(", "stats", ",", "summary", ",", "global_step", ")", "\n", "stats", "=", "new_stats", "(", ")", "\n", "\n", "", "if", "global_step", "%", "lm_period_save", "==", "0", "or", "global_step", "==", "lm_steps", ":", "\n", "            ", "lm_model", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", ".", "eval", "(", ")", "\n", "lm_model", ".", "save_pretrained", "(", "ckpt_path_pattern", "%", "(", "global_step", "//", "1000", ")", ")", "\n", "lm_model", ".", "to", "(", "device", ")", "\n", "\n", "", "if", "global_step", ">=", "lm_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "lm_model", ".", "eval", "(", ")", "\n", "lm_model", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "return", "lm_model", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm": [[181, 257], ["transformers.AutoTokenizer.from_pretrained", "os.path.join", "fibber.resources.get_transformers", "fibber.get_root_dir", "transformers.BertForMaskedLM.from_pretrained", "isinstance", "model.eval", "model.parameters", "fibber.resources.get_transformers", "bert_lm_utils.fine_tune_lm", "range", "len", "bert_lm_utils.fine_tune_lm", "fine_tune_lm.append", "bert_lm_utils.fine_tune_lm", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.fine_tune_lm", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.fine_tune_lm", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.fine_tune_lm"], ["", "def", "get_lm", "(", "lm_option", ",", "dataset_name", ",", "trainset", ",", "device", ",", "model_init", "=", "\"bert-base-cased\"", ",", "\n", "filter", "=", "-", "1", ",", "lm_steps", "=", "5000", ",", "lm_bs", "=", "32", ",", "lm_opt", "=", "\"adamw\"", ",", "lm_lr", "=", "0.0001", ",", "lm_decay", "=", "0.01", ",", "\n", "lm_period_summary", "=", "100", ",", "lm_period_save", "=", "5000", ",", "select_field", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a BERT language model or a list of language models on a given dataset.\n\n    The language model will be stored at ``<output_dir>/lm_all`` if lm_option is finetune.\n    The language model will be stored at ``<output_dir>/lm_filter_?`` if lm_option is adv.\n\n    If filter is not -1. The pretrained language model will first be pretrained on the while\n    dataset, then it will be finetuned on the data excluding the filter category.\n\n    The re\n\n    Args:\n        lm_option (str): choose from `[\"pretrain\", \"finetune\", \"adv\"]`.\n            pretrain means the pretrained BERT model without fine-tuning on current\n            dataset.\n            finetune means fine-tuning the BERT model on current dataset.\n            adv means adversarial tuning on current dataset.\n        dataset_name (str): a directory to store pretrained language model.\n        trainset (dict): the training set for finetune the language model.\n        device (torch.Device): a device to train the model.\n        model_init (str): the backbone bert model.\n        lm_steps (int): finetuning steps.\n        lm_bs (int): finetuning batch size.\n        lm_opt (str): optimzer name. choose from [\"sgd\", \"adam\", \"adamW\"].\n        lm_lr (float): learning rate.\n        lm_decay (float): weight decay for the optimizer.\n        lm_period_summary (int): number of steps to write training summary.\n        lm_period_save (int): number of steps to save the finetuned model.\n        select_field (str or None): train language model on one specific field.\n    Returns:\n        (BertTokenizerFast): the tokenizer for the language model.\n        (BertForMaskedLM): a finetuned language model if lm_option is pretrain or finetune.\n        ([BertForMaskedLM]): a list of finetuned language model if lm_option is adv. The i-th\n            language model in the list is fine-tuned on data not having label i.\n    \"\"\"", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"bert_lm\"", ",", "dataset_name", ")", "\n", "\n", "if", "lm_option", "==", "\"pretrain\"", ":", "\n", "        ", "assert", "filter", "==", "-", "1", "\n", "bert_lm", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "model_init", ")", ")", "\n", "", "elif", "lm_option", "==", "\"finetune\"", ":", "\n", "        ", "bert_lm", "=", "fine_tune_lm", "(", "\n", "output_dir", ",", "trainset", ",", "filter", ",", "device", ",", "model_init", "=", "model_init", ",", "\n", "lm_steps", "=", "lm_steps", ",", "lm_bs", "=", "lm_bs", ",", "lm_opt", "=", "lm_opt", ",", "lm_lr", "=", "lm_lr", ",", "lm_decay", "=", "lm_decay", ",", "\n", "lm_period_summary", "=", "lm_period_summary", ",", "lm_period_save", "=", "lm_period_save", ",", "\n", "select_field", "=", "select_field", ")", "\n", "", "elif", "lm_option", "==", "\"adv\"", ":", "\n", "        ", "bert_lm", "=", "[", "]", "\n", "assert", "filter", "==", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", ")", ":", "\n", "            ", "lm", "=", "fine_tune_lm", "(", "\n", "output_dir", ",", "trainset", ",", "i", ",", "device", ",", "model_init", "=", "model_init", ",", "\n", "lm_steps", "=", "lm_steps", ",", "lm_bs", "=", "lm_bs", ",", "lm_opt", "=", "lm_opt", ",", "lm_lr", "=", "lm_lr", ",", "lm_decay", "=", "lm_decay", ",", "\n", "lm_period_summary", "=", "lm_period_summary", ",", "lm_period_save", "=", "lm_period_save", ",", "\n", "select_field", "=", "select_field", ")", "\n", "bert_lm", ".", "append", "(", "lm", ")", "\n", "", "", "elif", "lm_option", "==", "\"ppl\"", ":", "\n", "        ", "bert_lm", "=", "fine_tune_lm", "(", "\n", "output_dir", ",", "trainset", ",", "filter", ",", "device", ",", "model_init", "=", "model_init", ",", "\n", "lm_steps", "=", "lm_steps", ",", "lm_bs", "=", "lm_bs", ",", "lm_opt", "=", "lm_opt", ",", "lm_lr", "=", "lm_lr", ",", "lm_decay", "=", "lm_decay", ",", "\n", "lm_period_summary", "=", "lm_period_summary", ",", "lm_period_save", "=", "lm_period_save", ",", "as_masked_lm", "=", "False", ",", "\n", "select_field", "=", "select_field", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"unsupported lm_option\"", ")", "\n", "\n", "", "for", "model", "in", "(", "bert_lm", "if", "isinstance", "(", "bert_lm", ",", "list", ")", "else", "[", "bert_lm", "]", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "for", "item", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "item", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "return", "tokenizer", ",", "bert_lm", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.__init__": [[22, 26], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "field", ",", "bs", "=", "32", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MetricBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_field", "=", "field", "\n", "self", ".", "_bs", "=", "bs", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.__repr__": [[27, 29], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase._measure_batch": [[30, 35], ["ret.append", "metric_base.MetricBase.measure_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "paraphrase", "in", "paraphrase_list", ":", "\n", "            ", "ret", ".", "append", "(", "self", ".", "measure_example", "(", "origin", ",", "paraphrase", ",", "data_record", ",", "**", "kwargs", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch": [[36, 56], ["range", "len", "metric_base.MetricBase._measure_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_batch"], ["", "def", "measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        If batch is larger than self._bs, the data will be split into smaller batches.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (list): a list containing the metric for each paraphrase.\n        \"\"\"", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "paraphrase_list", ")", ",", "self", ".", "_bs", ")", ":", "\n", "            ", "ret", "+=", "self", ".", "_measure_batch", "(", "origin", ",", "\n", "paraphrase_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "\n", "data_record", ",", "\n", "**", "kwargs", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase._measure_multiple_examples": [[57, 66], ["range", "len", "len", "len", "ret.append", "metric_base.MetricBase.measure_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "origin_list", ")", ")", ":", "\n", "            ", "ret", ".", "append", "(", "self", ".", "measure_example", "(", "\n", "origin_list", "[", "i", "]", ",", "paraphrase_list", "[", "i", "]", ",", "\n", "data_record_list", "[", "i", "]", "if", "data_record_list", "is", "not", "None", "else", "None", ",", "**", "kwargs", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_multiple_examples": [[67, 77], ["range", "len", "len", "len", "metric_base.MetricBase._measure_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_multiple_examples"], ["", "def", "measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "origin_list", ")", ",", "self", ".", "_bs", ")", ":", "\n", "            ", "ret", "+=", "self", ".", "_measure_multiple_examples", "(", "\n", "None", "if", "origin_list", "is", "None", "else", "origin_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "\n", "paraphrase_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "\n", "None", "if", "data_record_list", "is", "None", "else", "data_record_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "**", "kwargs", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase._measure_example": [[78, 81], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example": [[82, 84], ["metric_base.MetricBase._measure_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_example"], ["", "def", "measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_measure_example", "(", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor": [[11, 37], ["numpy.mean", "tmp.append"], "function", ["None"], ["def", "paraphrase_classification_accuracy_agg_fn_constructor", "(", "target_clf", ",", "type", ")", ":", "\n", "    ", "\"\"\"This function makes a aggregation function for the target classification metric.\n\n    The aggregation function outputs the after attack accuracy of the BERT classifier.\n\n    Args:\n        target_clf (str): the metric name of the target classifier.\n    \"\"\"", "\n", "\n", "if", "type", "==", "\"worst\"", ":", "\n", "        ", "def", "agg_fn", "(", "data_record", ")", ":", "\n", "            ", "if", "data_record", "[", "\"original_text_metrics\"", "]", "[", "target_clf", "]", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "                ", "return", "0", "\n", "", "for", "item", "in", "data_record", "[", "\"paraphrase_metrics\"", "]", ":", "\n", "                ", "if", "item", "[", "target_clf", "]", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "                    ", "return", "0", "\n", "", "", "return", "1", "\n", "", "", "elif", "type", "==", "\"avg\"", ":", "\n", "        ", "def", "agg_fn", "(", "data_record", ")", ":", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "item", "in", "data_record", "[", "\"paraphrase_metrics\"", "]", ":", "\n", "                ", "tmp", ".", "append", "(", "item", "[", "target_clf", "]", "!=", "data_record", "[", "\"label\"", "]", ")", "\n", "", "return", "np", ".", "mean", "(", "tmp", ")", "\n", "", "", "else", ":", "\n", "        ", "assert", "0", "\n", "", "return", "agg_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.editing_distance_element_worker": [[39, 42], ["fibber.metrics.distance.edit_distance_metric.EditDistanceMetric", "fibber.metrics.distance.edit_distance_metric.EditDistanceMetric.measure_example"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example"], ["", "def", "editing_distance_element_worker", "(", "x", ")", ":", "\n", "    ", "editing_distance_metric", "=", "EditDistanceMetric", "(", ")", "\n", "return", "editing_distance_metric", ".", "measure_example", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric": [[44, 68], ["None"], "function", ["None"], ["", "def", "get_best_adv_by_metric", "(", "data_record", ",", "target_clf", ",", "metric_name", ",", "lower_better", ")", ":", "\n", "    ", "\"\"\"Find the best adversarial example by some metric.\n\n    Args:\n        data_record (dict): a data record with paraphrases and metrics.\n        target_clf (str): the targeted classifier.\n        metric_name (str): the metric to pick the best adversarial example.\n        lower_better (bool): if true, find the adversarial example with the smallest metric value.\n    Returns:\n         (dict): the metrics of the best adversarial example. None if no legitimate adversarial\n            example is found or the original sentence is misclassified.\n    \"\"\"", "\n", "if", "data_record", "[", "\"original_text_metrics\"", "]", "[", "target_clf", "]", "!=", "data_record", "[", "\"label\"", "]", ":", "\n", "        ", "return", "None", "\n", "", "best_score", "=", "None", "\n", "best_metrics", "=", "None", "\n", "for", "metrics", "in", "data_record", "[", "\"paraphrase_metrics\"", "]", ":", "\n", "        ", "if", "metrics", "[", "target_clf", "]", "==", "data_record", "[", "\"label\"", "]", ":", "\n", "            ", "continue", "\n", "", "if", "best_score", "is", "None", "or", "(", "(", "lower_better", "and", "metrics", "[", "metric_name", "]", "<", "best_score", ")", "\n", "or", "(", "not", "lower_better", "and", "metrics", "[", "metric_name", "]", ">", "best_score", ")", ")", ":", "\n", "            ", "best_score", "=", "metrics", "[", "metric_name", "]", "\n", "best_metrics", "=", "metrics", "\n", "", "", "return", "best_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_metric_fn_constructor": [[70, 90], ["get_best_adv_fn"], "function", ["None"], ["", "def", "get_best_adv_metric_fn_constructor", "(", "get_best_adv_fn", ",", "metric_name", ",", "target_clf", ")", ":", "\n", "    ", "\"\"\"Returns an aggregation function that extracts the value of a specified metric for the best\n    adversarial example.\n\n    The aggregation function returns NaN if no legitimate adversarial example is found.\n\n    Args:\n        get_best_adv_fn (fn): a function that returns the metric dict of the best adversarial\n            example.\n        metric_name (str): a metric name.\n        target_clf (str): the targeted classifier.\n    Returns:\n        (fn): an aggregation function that takes data_record as an input.\n    \"\"\"", "\n", "def", "agg_fn", "(", "data_record", ")", ":", "\n", "        ", "best_metrics", "=", "get_best_adv_fn", "(", "data_record", ",", "target_clf", ")", "\n", "if", "best_metrics", "is", "not", "None", ":", "\n", "            ", "return", "best_metrics", "[", "metric_name", "]", "\n", "", "return", "math", ".", "nan", "\n", "", "return", "agg_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.query_count_fn_constructor": [[92, 99], ["None"], "function", ["None"], ["", "def", "query_count_fn_constructor", "(", "target_clf", ")", ":", "\n", "    ", "def", "agg_fn", "(", "data_record", ")", ":", "\n", "        ", "if", "data_record", "[", "\"original_text_metrics\"", "]", "[", "target_clf", "]", "==", "data_record", "[", "\"label\"", "]", ":", "\n", "            ", "return", "data_record", "[", "\"clf_count\"", "]", "\n", "", "else", ":", "\n", "            ", "return", "math", ".", "nan", "\n", "", "", "return", "agg_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.add_sentence_level_adversarial_attack_metrics": [[101, 141], ["metric_bundle.get_target_classifier_name", "metric_bundle.add_advanced_aggregation_fn", "metric_bundle.get_classifier_names", "attack_aggregation_utils.query_count_fn_constructor", "metric_bundle.add_advanced_aggregation_fn", "metric_bundle.get_metric_names", "attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor", "metric_bundle.add_advanced_aggregation_fn", "attack_aggregation_utils.get_best_adv_metric_fn_constructor", "metric_bundle.get_metric_direction", "metric_bundle.get_target_classifier_name", "attack_aggregation_utils.get_best_adv_by_metric"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier_name", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_advanced_aggregation_fn", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_classifier_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.query_count_fn_constructor", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_advanced_aggregation_fn", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_names", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_advanced_aggregation_fn", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_metric_fn_constructor", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_metric_direction", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier_name", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric"], ["", "def", "add_sentence_level_adversarial_attack_metrics", "(", "metric_bundle", ",", "\n", "best_adv_metric_name", "=", "None", ",", "\n", "best_adv_metric_lower_better", "=", "None", ",", "\n", "clf_agg_type", "=", "\"worst\"", ")", ":", "\n", "    ", "\"\"\"Add advanced aggregation functions related to adversarial attack to a specific metric\n    bundle.\n\n    Args:\n        metric_bundle (MetricBundle): a metric bundle object to add aggregation functions.\n        best_adv_metric_name (str):\n        best_adv_metric_lower_better (bool):\n    \"\"\"", "\n", "\n", "target_clf", "=", "metric_bundle", ".", "get_target_classifier_name", "(", ")", "\n", "\n", "metric_bundle", ".", "add_advanced_aggregation_fn", "(", "\n", "\"AverageQuery\"", ",", "\n", "query_count_fn_constructor", "(", "target_clf", ")", ",", "\n", "DIRECTION_LOWER_BETTER", "\n", ")", "\n", "\n", "for", "clf_name", "in", "metric_bundle", ".", "get_classifier_names", "(", ")", ":", "\n", "        ", "name", "=", "\"%s_Accuracy\"", "%", "clf_name", "\n", "if", "clf_name", "==", "target_clf", ":", "\n", "            ", "name", "+=", "\"_targeted\"", "\n", "", "metric_bundle", ".", "add_advanced_aggregation_fn", "(", "\n", "name", ",", "paraphrase_classification_accuracy_agg_fn_constructor", "(", "clf_name", ",", "clf_agg_type", ")", ",", "\n", "DIRECTION_LOWER_BETTER", "\n", ")", "\n", "\n", "", "if", "best_adv_metric_name", "is", "not", "None", ":", "\n", "        ", "for", "metric_name", "in", "metric_bundle", ".", "get_metric_names", "(", ")", ":", "\n", "            ", "metric_bundle", ".", "add_advanced_aggregation_fn", "(", "\n", "\"best_adv_%s\"", "%", "metric_name", ",", "\n", "get_best_adv_metric_fn_constructor", "(", "\n", "lambda", "_data_record", ",", "_target_clf", ":", "get_best_adv_by_metric", "(", "\n", "_data_record", ",", "_target_clf", ",", "\n", "best_adv_metric_name", ",", "best_adv_metric_lower_better", ")", ",", "\n", "metric_name", ",", "metric_bundle", ".", "get_target_classifier_name", "(", ")", ")", ",", "\n", "metric_bundle", ".", "get_metric_direction", "(", "metric_name", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record": [[5, 23], ["len", "len", "len", "len", "zip"], "function", ["None"], ["def", "make_data_record", "(", "label", ",", "origin_predict", ",", "paraphrase_ppl_list", ",", "\n", "paraphrase_sim_list", ",", "paraphrase_pred_list", ",", "classifier", ")", ":", "\n", "    ", "assert", "len", "(", "paraphrase_ppl_list", ")", "==", "len", "(", "paraphrase_sim_list", ")", "\n", "assert", "len", "(", "paraphrase_sim_list", ")", "==", "len", "(", "paraphrase_pred_list", ")", "\n", "\n", "return", "{", "\n", "\"label\"", ":", "label", ",", "\n", "\"original_text_metrics\"", ":", "{", "\n", "classifier", ":", "origin_predict", "\n", "}", ",", "\n", "\"paraphrase_metrics\"", ":", "[", "\n", "{", "\n", "\"GPT2PerplexityMetric\"", ":", "ppl", ",", "\n", "\"USESimilarityMetric\"", ":", "sim", ",", "\n", "classifier", ":", "pred", "\n", "}", "for", "ppl", ",", "sim", ",", "pred", "in", "zip", "(", "paraphrase_ppl_list", ",", "\n", "paraphrase_sim_list", ",", "\n", "paraphrase_pred_list", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.test_paraphrase_classification_accuracy_agg_fn_constructor": [[27, 58], ["fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor", "test_attack_aggragation_utils.make_data_record", "test_attack_aggragation_utils.make_data_record", "test_attack_aggragation_utils.make_data_record", "test_attack_aggragation_utils.make_data_record", "fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor.", "fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor.", "fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor.", "fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor."], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.paraphrase_classification_accuracy_agg_fn_constructor", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record"], ["", "def", "test_paraphrase_classification_accuracy_agg_fn_constructor", "(", ")", ":", "\n", "    ", "classifier", "=", "\"FooClassifier\"", "\n", "agg_fn", "=", "paraphrase_classification_accuracy_agg_fn_constructor", "(", "classifier", ",", "\"worst\"", ")", "\n", "\n", "data_record", "=", "make_data_record", "(", "label", "=", "1", ",", "origin_predict", "=", "0", ",", "\n", "paraphrase_ppl_list", "=", "[", "]", ",", "\n", "paraphrase_sim_list", "=", "[", "]", ",", "\n", "paraphrase_pred_list", "=", "[", "]", ",", "\n", "classifier", "=", "classifier", ")", "\n", "assert", "agg_fn", "(", "data_record", ")", "==", "0", "\n", "\n", "data_record", "=", "make_data_record", "(", "label", "=", "1", ",", "origin_predict", "=", "1", ",", "\n", "paraphrase_ppl_list", "=", "[", "]", ",", "\n", "paraphrase_sim_list", "=", "[", "]", ",", "\n", "paraphrase_pred_list", "=", "[", "]", ",", "\n", "classifier", "=", "classifier", ")", "\n", "assert", "agg_fn", "(", "data_record", ")", "==", "1", "\n", "\n", "data_record", "=", "make_data_record", "(", "label", "=", "1", ",", "origin_predict", "=", "1", ",", "\n", "paraphrase_ppl_list", "=", "[", "5", ",", "1.2", ",", "1.1", "]", ",", "\n", "paraphrase_sim_list", "=", "[", "0.98", ",", "0.7", ",", "0.95", "]", ",", "\n", "paraphrase_pred_list", "=", "[", "2", ",", "3", ",", "1", "]", ",", "\n", "classifier", "=", "classifier", ")", "\n", "assert", "agg_fn", "(", "data_record", ")", "==", "0", "\n", "\n", "data_record", "=", "make_data_record", "(", "label", "=", "1", ",", "origin_predict", "=", "1", ",", "\n", "paraphrase_ppl_list", "=", "[", "5", ",", "1.2", ",", "1.1", "]", ",", "\n", "paraphrase_sim_list", "=", "[", "0.98", ",", "0.7", ",", "0.95", "]", ",", "\n", "paraphrase_pred_list", "=", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "classifier", "=", "classifier", ")", "\n", "assert", "agg_fn", "(", "data_record", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.test_get_best_adv_by_metric": [[60, 78], ["test_attack_aggragation_utils.make_data_record", "fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric", "fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_attack_aggragation_utils.make_data_record", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.get_best_adv_by_metric"], ["", "def", "test_get_best_adv_by_metric", "(", ")", ":", "\n", "    ", "classifier", "=", "\"FooClassifier\"", "\n", "data_record", "=", "make_data_record", "(", "label", "=", "1", ",", "origin_predict", "=", "1", ",", "\n", "paraphrase_ppl_list", "=", "[", "5.1", ",", "1.2", ",", "1.1", ",", "1.25", ",", "1.3", ",", "1.4", "]", ",", "\n", "paraphrase_sim_list", "=", "[", "0.98", ",", "0.7", ",", "0.95", ",", "0.92", ",", "0.93", ",", "0.94", "]", ",", "\n", "paraphrase_pred_list", "=", "[", "2", ",", "3", ",", "1", ",", "4", ",", "5", ",", "6", "]", ",", "\n", "classifier", "=", "classifier", ")", "\n", "best_metric", "=", "get_best_adv_by_metric", "(", "\n", "data_record", ",", "classifier", ",", "\"GPT2PerplexityMetric\"", ",", "lower_better", "=", "True", ")", "\n", "assert", "best_metric", "[", "\"GPT2PerplexityMetric\"", "]", "==", "1.2", "\n", "assert", "best_metric", "[", "\"USESimilarityMetric\"", "]", "==", "0.7", "\n", "assert", "best_metric", "[", "classifier", "]", "==", "3", "\n", "\n", "best_metric", "=", "get_best_adv_by_metric", "(", "\n", "data_record", ",", "classifier", ",", "\"USESimilarityMetric\"", ",", "lower_better", "=", "False", ")", "\n", "assert", "best_metric", "[", "\"GPT2PerplexityMetric\"", "]", "==", "5.1", "\n", "assert", "best_metric", "[", "\"USESimilarityMetric\"", "]", "==", "0.98", "\n", "assert", "best_metric", "[", "classifier", "]", "==", "2", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_classifers.gpu_id": [[10, 15], ["pytest.fixture", "torch.cuda.device_count"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", ")", "\n", "def", "gpu_id", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_classifers.bert_classifier_on_demo": [[17, 25], ["pytest.fixture", "fibber.resources.resource_utils.get_bert_clf_demo", "fibber.datasets.dataset_utils.get_demo_dataset", "fibber.metrics.classifier.transformer_classifier.TransformerClassifier"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_bert_clf_demo", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_demo_dataset"], ["", "@", "pytest", ".", "fixture", "(", ")", "\n", "def", "bert_classifier_on_demo", "(", "gpu_id", ")", ":", "\n", "    ", "get_bert_clf_demo", "(", ")", "\n", "trainset", ",", "testset", "=", "get_demo_dataset", "(", ")", "\n", "bert_classifier", "=", "TransformerClassifier", "(", "\n", "\"demo\"", ",", "trainset", ",", "testset", ",", "transformer_clf_gpu_id", "=", "gpu_id", ",", "transformer_clf_steps", "=", "5000", ",", "\n", "field", "=", "\"text0\"", ")", "\n", "return", "bert_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_classifers.test_bert_classifier": [[27, 63], ["isinstance", "bert_classifier_on_demo.predict_log_dist_example", "bert_classifier_on_demo.predict_example", "bert_classifier_on_demo.measure_example", "bert_classifier_on_demo.predict_log_dist_batch", "numpy.all", "bert_classifier_on_demo.predict_batch", "all", "bert_classifier_on_demo.measure_batch", "all", "len", "numpy.argmax", "numpy.argmax", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_bert_classifier", "(", "bert_classifier_on_demo", ")", ":", "\n", "    ", "assert", "isinstance", "(", "bert_classifier_on_demo", ",", "TransformerClassifier", ")", "\n", "\n", "io_pairs", "=", "[", "\n", "(", "\"This is a bad movie\"", ",", "0", ")", ",", "\n", "(", "\"This is a good movie\"", ",", "1", ")", "\n", "]", "\n", "\n", "for", "x", ",", "y", "in", "io_pairs", ":", "\n", "        ", "dist", "=", "bert_classifier_on_demo", ".", "predict_log_dist_example", "(", "None", ",", "x", ")", "\n", "assert", "len", "(", "dist", ")", "==", "2", "\n", "assert", "np", ".", "argmax", "(", "dist", ")", "==", "y", "\n", "\n", "pred", "=", "bert_classifier_on_demo", ".", "predict_example", "(", "None", ",", "x", ")", "\n", "assert", "pred", "==", "y", "\n", "\n", "pred", "=", "bert_classifier_on_demo", ".", "measure_example", "(", "None", ",", "x", ")", "\n", "assert", "pred", "==", "y", "\n", "\n", "", "batched_io_pairs", "=", "[", "\n", "(", "[", "\"This is a bad movie.\"", ",", "\n", "\"This is a good movie and I want to buy a ticket.\"", "]", ",", "\n", "[", "0", ",", "1", "]", ")", "\n", "]", "\n", "\n", "for", "x", ",", "y", "in", "batched_io_pairs", ":", "\n", "        ", "dist", "=", "bert_classifier_on_demo", ".", "predict_log_dist_batch", "(", "None", ",", "x", ")", "\n", "assert", "dist", ".", "shape", "[", "0", "]", "==", "2", "and", "dist", ".", "shape", "[", "1", "]", "==", "2", "\n", "assert", "np", ".", "all", "(", "np", ".", "argmax", "(", "dist", ",", "axis", "=", "1", ")", "==", "y", ")", "\n", "\n", "pred", "=", "bert_classifier_on_demo", ".", "predict_batch", "(", "None", ",", "x", ")", "\n", "assert", "all", "(", "[", "a", "==", "b", "for", "a", ",", "b", "in", "zip", "(", "pred", ",", "y", ")", "]", ")", "\n", "\n", "pred", "=", "bert_classifier_on_demo", ".", "measure_batch", "(", "None", ",", "x", ")", "\n", "assert", "all", "(", "[", "a", "==", "b", "for", "a", ",", "b", "in", "zip", "(", "pred", ",", "y", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.gpu_id": [[11, 16], ["torch.cuda.device_count"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "gpu_id", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper": [[18, 31], ["metric.measure_example", "metric.measure_batch", "isinstance", "all", "all", "isinstance", "isinstance", "abs", "isinstance", "isinstance", "abs", "zip"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "metric_test_helper", "(", "metric", ",", "io_pairs", ",", "batched_io_pairs", ",", "eps", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "(", "origin", ",", "paraphrase", ")", ",", "true_output", "in", "io_pairs", ":", "\n", "        ", "value", "=", "metric", ".", "measure_example", "(", "origin", ",", "paraphrase", ",", "**", "kwargs", ")", "\n", "assert", "isinstance", "(", "value", ",", "int", ")", "or", "isinstance", "(", "value", ",", "float", ")", "\n", "assert", "abs", "(", "value", "-", "true_output", ")", "<=", "eps", "\n", "\n", "", "for", "(", "origin", ",", "paraphrase_list", ")", ",", "true_output_list", "in", "batched_io_pairs", ":", "\n", "        ", "values", "=", "metric", ".", "measure_batch", "(", "origin", ",", "paraphrase_list", ",", "**", "kwargs", ")", "\n", "assert", "isinstance", "(", "values", ",", "list", ")", "\n", "assert", "all", "(", "[", "isinstance", "(", "x", ",", "int", ")", "or", "isinstance", "(", "x", ",", "float", ")", "for", "x", "in", "values", "]", ")", "\n", "assert", "all", "(", "[", "abs", "(", "output", "-", "true_output", ")", "<=", "eps", "\n", "for", "output", ",", "true_output", "in", "\n", "zip", "(", "values", ",", "true_output_list", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.test_edit_distance_metric": [[33, 46], ["fibber.metrics.distance.edit_distance_metric.EditDistanceMetric", "test_metrics.metric_test_helper"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper"], ["", "", "def", "test_edit_distance_metric", "(", ")", ":", "\n", "    ", "io_pairs", "=", "[", "\n", "(", "(", "\"aa bb xx dd zz xx ee\"", ",", "\"aa bb xy yz dd xy ee\"", ")", ",", "4", ")", ",", "\n", "(", "(", "\"aa bb cc dd\"", ",", "\"aa bb dd\"", ")", ",", "1", ")", ",", "\n", "(", "(", "\"aa bb cc\"", ",", "\" aa  bb  cc \"", ")", ",", "0", ")", ",", "\n", "(", "(", "\"a. b; c?\"", ",", "\"a1, b& c'\"", ")", ",", "1", ")", "\n", "]", "\n", "batched_io_pairs", "=", "[", "\n", "(", "(", "\"aa bb cc\"", ",", "[", "\"aa bb cc dd\"", ",", "\"aa bb cc\"", ",", "\"aa ee\"", "]", ")", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "]", "\n", "editing_distance_metric", "=", "EditDistanceMetric", "(", "field", "=", "\"text0\"", ")", "\n", "\n", "metric_test_helper", "(", "editing_distance_metric", ",", "io_pairs", ",", "batched_io_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.test_use_semantic_similarity": [[48, 64], ["fibber.metrics.similarity.use_similarity_metric.USESimilarityMetric", "test_metrics.metric_test_helper"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_use_semantic_similarity", "(", "gpu_id", ")", ":", "\n", "    ", "io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week.\"", ",", "\n", "\"Obama was the president of the United State.\"", ")", ",", "0.171", ")", ",", "\n", "(", "(", "\"Sunday is the first day in a week\"", ",", "\n", "\"Saturday is the last day in a week\"", ")", ",", "0.759", ")", "\n", "]", "\n", "batched_io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week\"", ",", "\n", "[", "\"Obama was the president of the United State.\"", ",", "\n", "\"Saturday is the last day in a week\"", "]", ")", ",", "\n", "[", "0.171", ",", "0.759", "]", ")", ",", "\n", "]", "\n", "use_semantic_similarity_metric", "=", "USESimilarityMetric", "(", "use_gpu_id", "=", "gpu_id", ",", "field", "=", "\"text0\"", ")", "\n", "metric_test_helper", "(", "use_semantic_similarity_metric", ",", "io_pairs", ",", "batched_io_pairs", ",", "eps", "=", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.test_ce_semantic_similarity": [[66, 82], ["fibber.metrics.similarity.ce_similarity_metric.CESimilarityMetric", "test_metrics.metric_test_helper"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_ce_semantic_similarity", "(", "gpu_id", ")", ":", "\n", "    ", "io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week.\"", ",", "\n", "\"Obama was the president of the United State.\"", ")", ",", "0.009", ")", ",", "\n", "(", "(", "\"Sunday is the first day in a week\"", ",", "\n", "\"Saturday is the last day in a week\"", ")", ",", "0.291", ")", "\n", "]", "\n", "batched_io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week\"", ",", "\n", "[", "\"Obama was the president of the United State.\"", ",", "\n", "\"Saturday is the last day in a week\"", "]", ")", ",", "\n", "[", "0.009", ",", "0.291", "]", ")", ",", "\n", "]", "\n", "ce_semantic_similarity_metric", "=", "CESimilarityMetric", "(", "ce_gpu_id", "=", "gpu_id", ",", "field", "=", "\"text0\"", ")", "\n", "metric_test_helper", "(", "ce_semantic_similarity_metric", ",", "io_pairs", ",", "batched_io_pairs", ",", "eps", "=", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.test_gpt2_grammar_quality": [[84, 101], ["fibber.metrics.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric", "test_metrics.metric_test_helper"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_gpt2_grammar_quality", "(", "gpu_id", ")", ":", "\n", "    ", "io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week.\"", ",", "\n", "\"Sunday is is is first daay in a week.\"", ")", ",", "14.64", ")", ",", "\n", "(", "(", "\"Sunday is the first day in a week.\"", ",", "\n", "\"Saturday is the last day in a week.\"", ")", ",", "1.10", ")", "\n", "]", "\n", "batched_io_pairs", "=", "[", "\n", "(", "(", "\"Sunday is the first day in a week.\"", ",", "\n", "[", "\"Sunday is is is first daay in a week.\"", ",", "\n", "\"Saturday is the last day in a week.\"", "]", ")", ",", "\n", "[", "14.64", ",", "1.10", "]", ")", ",", "\n", "]", "\n", "gpt2_grammar_quality_metric", "=", "GPT2PerplexityMetric", "(", "gpt2_gpu_id", "=", "gpu_id", ",", "field", "=", "\"text0\"", ")", "\n", "metric_test_helper", "(", "gpt2_grammar_quality_metric", ",", "io_pairs", ",", "batched_io_pairs", ",", "eps", "=", "0.1", ",", "\n", "use_ratio", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.test_glove_semantic_similarity": [[103, 120], ["fibber.metrics.similarity.glove_similarity_metric.GloVeSimilarityMetric", "test_metrics.metric_test_helper"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.test_metrics.metric_test_helper"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_glove_semantic_similarity", "(", ")", ":", "\n", "    ", "io_pairs", "=", "[", "\n", "(", "(", "\"the a the to\"", ",", "\"he him\"", ")", ",", "0.0", ")", ",", "\n", "(", "(", "\"Saturday is the last day in a week.\"", ",", "\n", "\"Sunday is the last day in a week.\"", ")", ",", "0.997", ")", ",", "\n", "(", "(", "\"Saturday is the last day in a week.\"", ",", "\n", "\"Obama was the president of the United State.\"", ")", ",", "0.678", ")", ",", "\n", "]", "\n", "batched_io_pairs", "=", "[", "\n", "(", "(", "\"Saturday is the last day in a week.\"", ",", "\n", "[", "\"Sunday is the last day in a week.\"", ",", "\n", "\"Obama was the president of the United State.\"", "]", ")", ",", "\n", "[", "0.997", ",", "0.678", "]", ")", "\n", "]", "\n", "glove_semantic_similarity_metric", "=", "GloVeSimilarityMetric", "(", "field", "=", "\"text0\"", ")", "\n", "metric_test_helper", "(", "glove_semantic_similarity_metric", ",", "io_pairs", ",", "batched_io_pairs", ",", "eps", "=", "0.01", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.__init__": [[20, 39], ["fibber.metrics.metric_base.MetricBase.__init__", "logger.info", "fibber.metrics.bert_lm_utils.get_lm", "bert_perplexity_metric.BertPerplexityMetric._model.to", "logger.warning", "torch.device", "logger.info", "torch.device"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm"], ["def", "__init__", "(", "self", ",", "dataset_name", ",", "trainset", ",", "bert_ppl_gpu_id", "=", "-", "1", ",", "bert_ppl_filter", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize Bert perplexity model.\"\"\"", "\n", "super", "(", "BertPerplexityMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "bert_ppl_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"BertPerplexityMetric is running on CPU.\"", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"BertPerplexityMetric is running is running on GPU %d.\"", ",", "bert_ppl_gpu_id", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "bert_ppl_gpu_id", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"load bert perplexity model.\"", ")", "\n", "self", ".", "_tokenizer", ",", "self", ".", "_model", "=", "get_lm", "(", "\"ppl\"", ",", "dataset_name", ",", "trainset", ",", "self", ".", "_device", ",", "\n", "filter", "=", "bert_ppl_filter", ",", "select_field", "=", "self", ".", "_field", ")", "\n", "self", ".", "_model", ".", "to", "(", "self", ".", "_device", ")", "\n", "self", ".", "_data_filter", "=", "bert_ppl_filter", "\n", "self", ".", "_name_suffix", "=", "\"\"", "\n", "if", "self", ".", "_data_filter", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_name_suffix", "=", "\"-exclude-\"", "+", "trainset", "[", "\"label_mapping\"", "]", "[", "self", ".", "_data_filter", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.lm_model": [[40, 43], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "lm_model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.__repr__": [[48, 50], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "self", ".", "_name_suffix", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric._get_ppl": [[51, 72], ["bert_perplexity_metric.BertPerplexityMetric._tokenizer", "torch.no_grad", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.gather().squeeze", "torch.exp", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "bert_perplexity_metric.BertPerplexityMetric._model", "torch.tensor", "torch.tensor", "torch.tensor", "torch.gather", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "torch.log_softmax", "torch.tensor().to.sum", "input_ids[].unsqueeze", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["None"], ["", "def", "_get_ppl", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "\"\"\"Compute the perplexity of sentences.\"\"\"", "\n", "batch_input", "=", "self", ".", "_tokenizer", "(", "text", "=", "sentences", ",", "padding", "=", "True", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"input_ids\"", "]", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"attention_mask\"", "]", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"token_type_ids\"", "]", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "logits", "=", "self", ".", "_model", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", "\n", ")", "[", "0", "]", "\n", "logpw", "=", "torch", ".", "gather", "(", "torch", ".", "log_softmax", "(", "logits", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "2", ",", "\n", "index", "=", "input_ids", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "ppl", "=", "torch", ".", "exp", "(", "-", "(", "logpw", "*", "attention_mask", "[", ":", ",", "1", ":", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "/", "(", "attention_mask", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ")", "\n", "ppl", "=", "ppl", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "ppl", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric._measure_batch": [[73, 92], ["bert_perplexity_metric.BertPerplexityMetric._get_ppl", "bert_perplexity_metric.BertPerplexityMetric._get_ppl", "float"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "field", "=", "\"text0\"", ",", "\n", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n            field (str): the field name to paraphrase.\n            use_ratio (bool): whether to return ppl ratio.\n        Returns:\n            (list): a list containing the USE similarity metric for each paraphrase.\n        \"\"\"", "\n", "if", "use_ratio", ":", "\n", "            ", "res", "=", "self", ".", "_get_ppl", "(", "[", "origin", "]", "+", "paraphrase_list", ")", "\n", "res", "=", "res", "[", "1", ":", "]", "/", "res", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "_get_ppl", "(", "paraphrase_list", ")", "\n", "", "return", "[", "float", "(", "x", ")", "for", "x", "in", "res", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric._measure_multiple_examples": [[93, 103], ["len", "len", "bert_perplexity_metric.BertPerplexityMetric._get_ppl", "bert_perplexity_metric.BertPerplexityMetric._get_ppl", "float", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "field", "=", "\"text0\"", ",", "\n", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "if", "use_ratio", ":", "\n", "            ", "ppls", "=", "self", ".", "_get_ppl", "(", "origin_list", "+", "paraphrase_list", ")", "\n", "res", "=", "ppls", "[", "len", "(", "origin_list", ")", ":", "]", "/", "ppls", "[", ":", "len", "(", "origin_list", ")", "]", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "_get_ppl", "(", "paraphrase_list", ")", "\n", "", "return", "[", "float", "(", "x", ")", "for", "x", "in", "res", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric._measure_example": [[104, 114], ["bert_perplexity_metric.BertPerplexityMetric.measure_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the perplexity ratio.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n            use_ratio (bool): whether to return ppl ratio.\n        \"\"\"", "\n", "return", "self", ".", "measure_batch", "(", "origin", ",", "[", "paraphrase", "]", ",", "data_record", ",", "use_ratio", "=", "use_ratio", ")", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric.__init__": [[44, 61], ["fibber.metrics.metric_base.MetricBase.__init__", "logger.info", "transformers.GPT2TokenizerFast.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained().to", "fibber.resources.get_transformers", "logger.warning", "torch.device", "torch.device", "torch.device", "torch.device", "logger.info", "torch.device", "torch.device", "torch.device", "torch.device", "transformers.GPT2LMHeadModel.from_pretrained", "fibber.resources.get_transformers"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["def", "__init__", "(", "self", ",", "gpt2_pretrained_model", "=", "\"gpt2-medium\"", ",", "gpt2_gpu_id", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize GPT2 model.\"\"\"", "\n", "super", "(", "GPT2PerplexityMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "logger", ".", "info", "(", "\"load gpt2 model.\"", ")", "\n", "self", ".", "_tokenizer", "=", "GPT2TokenizerFast", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "gpt2_pretrained_model", ")", ")", "\n", "if", "gpt2_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"GPT2 metric is running on CPU.\"", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"GPT2 metric is running on GPU %d.\"", ",", "gpt2_gpu_id", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "gpt2_gpu_id", ")", "\n", "\n", "", "self", ".", "_model", "=", "GPT2LMHeadModel", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "gpt2_pretrained_model", ")", ")", ".", "to", "(", "\n", "self", ".", "_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl": [[62, 83], ["zip", "gpt2_perplexity_metric.make_batch", "gpt2_perplexity_metric.make_batch", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "gpt2_perplexity_metric.make_input_output_pair", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gpt2_perplexity_metric.GPT2PerplexityMetric._model", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.tensor().to.sum", "torch.tensor().to.sum", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "torch.log_softmax", "torch.log_softmax", "torch.tensor().to.unsqueeze", "torch.tensor().to.unsqueeze", "ppl.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_input_output_pair"], ["", "def", "_get_ppl", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "\"\"\"Compute the perplexity of sentences.\"\"\"", "\n", "input_output", "=", "[", "make_input_output_pair", "(", "self", ".", "_tokenizer", ",", "x", ")", "for", "x", "in", "sentences", "]", "\n", "\n", "input", ",", "output", "=", "zip", "(", "*", "input_output", ")", "\n", "\n", "toks_input", ",", "mask", "=", "make_batch", "(", "input", ")", "\n", "toks_output", ",", "_", "=", "make_batch", "(", "output", ")", "\n", "\n", "mask", "=", "torch", ".", "tensor", "(", "mask", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "toks_input", "=", "torch", ".", "tensor", "(", "toks_input", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "toks_output", "=", "torch", ".", "tensor", "(", "toks_output", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "self", ".", "_model", "(", "toks_input", ",", "attention_mask", "=", "mask", ")", "[", "0", "]", "\n", "\n", "", "logpw", "=", "torch", ".", "gather", "(", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ",", "\n", "index", "=", "toks_output", ".", "unsqueeze", "(", "dim", "=", "2", ")", ")", ".", "squeeze", "(", "dim", "=", "2", ")", "\n", "ppl", "=", "torch", ".", "exp", "(", "-", "(", "logpw", "*", "mask", ")", ".", "sum", "(", "dim", "=", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "1", ")", ")", "\n", "ppl", "=", "ppl", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "ppl", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._measure_batch": [[84, 102], ["gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "float"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n            use_ratio (bool): returns the perplexity ratio.\n\n        Returns:\n            (list): a list containing the USE similarity metric for each paraphrase.\n        \"\"\"", "\n", "if", "use_ratio", ":", "\n", "            ", "ppls", "=", "self", ".", "_get_ppl", "(", "[", "origin", "]", "+", "paraphrase_list", ")", "\n", "res", "=", "ppls", "[", "1", ":", "]", "/", "ppls", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "_get_ppl", "(", "paraphrase_list", ")", "\n", "", "return", "[", "float", "(", "x", ")", "for", "x", "in", "res", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._measure_multiple_examples": [[103, 113], ["print", "len", "len", "gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "float", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "if", "use_ratio", ":", "\n", "            ", "ppls", "=", "self", ".", "_get_ppl", "(", "origin_list", "+", "paraphrase_list", ")", "\n", "res", "=", "ppls", "[", "len", "(", "origin_list", ")", ":", "]", "/", "ppls", "[", ":", "len", "(", "origin_list", ")", "]", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "_get_ppl", "(", "paraphrase_list", ")", "\n", "", "print", "(", "res", ")", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "res", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._measure_example": [[114, 131], ["gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "float", "float", "gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.GPT2PerplexityMetric._get_ppl"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "use_ratio", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the perplexity ratio.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n            use_ratio (bool): returns the perplexity ratio.\n\n        \"\"\"", "\n", "if", "use_ratio", ":", "\n", "            ", "ppl", "=", "self", ".", "_get_ppl", "(", "[", "origin", ",", "paraphrase", "]", ")", "\n", "res", "=", "float", "(", "ppl", "[", "1", "]", "/", "ppl", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "float", "(", "self", ".", "_get_ppl", "(", "[", "paraphrase", "]", ")", "[", "0", "]", ")", "\n", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_input_output_pair": [[18, 22], ["tokenizer.encode"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["def", "make_input_output_pair", "(", "tokenizer", ",", "x", ")", ":", "\n", "    ", "\"\"\"Tokenize the text, then construct input and output for GPT2.\"\"\"", "\n", "toks", "=", "tokenizer", ".", "encode", "(", "x", ",", "add_special_tokens", "=", "True", ")", "\n", "return", "[", "tokenizer", ".", "bos_token_id", "]", "+", "toks", "[", ":", "-", "1", "]", ",", "toks", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.gpt2_perplexity_metric.make_batch": [[24, 37], ["len", "max", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.asarray", "len", "len", "len"], "function", ["None"], ["", "def", "make_batch", "(", "toks_list", ")", ":", "\n", "    ", "\"\"\"Convert multiple text to a batch tensor.\"\"\"", "\n", "n", "=", "len", "(", "toks_list", ")", "\n", "max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "toks_list", "]", ")", "\n", "\n", "ids", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_len", ")", ",", "dtype", "=", "'int'", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_len", ")", ",", "dtype", "=", "'int'", ")", "\n", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "toks_list", ")", ":", "\n", "        ", "ids", "[", "i", ",", ":", "len", "(", "item", ")", "]", "=", "np", ".", "asarray", "(", "item", ")", "\n", "mask", "[", "i", ",", ":", "len", "(", "item", ")", "]", "=", "1", "\n", "\n", "", "return", "ids", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.self_bleu_metric.SelfBleuMetric.__init__": [[16, 19], ["fibber.metrics.metric_base.MetricBase.__init__"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize ce model.\"\"\"", "\n", "super", "(", "SelfBleuMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.self_bleu_metric.SelfBleuMetric._measure_example": [[20, 32], ["nltk.word_tokenize", "nltk.word_tokenize", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.sentence_bleu"], "methods", ["None"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the 4 gram self bleu\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n        \"\"\"", "\n", "ref", "=", "word_tokenize", "(", "origin", ")", "\n", "hypo", "=", "word_tokenize", "(", "paraphrase", ")", "\n", "chencherry", "=", "bleu_score", ".", "SmoothingFunction", "(", ")", "\n", "return", "bleu_score", ".", "sentence_bleu", "(", "[", "ref", "]", ",", "hypo", ",", "smoothing_function", "=", "chencherry", ".", "method1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.edit_distance_metric.EditDistanceMetric.__init__": [[15, 24], ["fibber.metrics.metric_base.MetricBase.__init__"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "editing_distance_ignore_punctuation", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize.\n\n        Args:\n            editing_distance_ignore_punctuation (bool): whether to ignore punctuation when\n                computing editing distance.\n        \"\"\"", "\n", "super", "(", "EditDistanceMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "_no_puctuation", "=", "editing_distance_ignore_punctuation", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.edit_distance_metric.EditDistanceMetric._measure_example": [[25, 57], ["re.sub.split", "re.sub.split", "numpy.zeros", "range", "range", "range", "int", "re.sub", "re.sub", "len", "range", "len", "len", "len", "len", "len", "len", "len", "min", "len", "len", "min", "len", "len"], "methods", ["None"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"compute editing distance between original and parapharse.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n\n        Returns:\n            (int): the editing distance.\n        \"\"\"", "\n", "if", "self", ".", "_no_puctuation", ":", "\n", "            ", "origin", "=", "re", ".", "sub", "(", "r\"[^a-zA-Z0-9]\"", ",", "\" \"", ",", "origin", ")", "\n", "paraphrase", "=", "re", ".", "sub", "(", "r\"[^a-zA-Z0-9]\"", ",", "\" \"", ",", "paraphrase", ")", "\n", "\n", "", "origin", "=", "origin", ".", "split", "(", ")", "\n", "paraphrase", "=", "paraphrase", ".", "split", "(", ")", "\n", "if", "len", "(", "origin", ")", "==", "0", "or", "len", "(", "paraphrase", ")", "==", "0", ":", "\n", "            ", "return", "len", "(", "origin", ")", "+", "len", "(", "paraphrase", ")", "\n", "\n", "", "f", "=", "np", ".", "zeros", "(", "(", "len", "(", "origin", ")", "+", "1", ",", "len", "(", "paraphrase", ")", "+", "1", ")", ",", "dtype", "=", "'int'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "origin", ")", "+", "1", ")", ":", "\n", "            ", "f", "[", "i", ",", "0", "]", "=", "i", "\n", "", "for", "i", "in", "range", "(", "len", "(", "paraphrase", ")", "+", "1", ")", ":", "\n", "            ", "f", "[", "0", ",", "i", "]", "=", "i", "\n", "", "for", "i", "in", "range", "(", "len", "(", "origin", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "paraphrase", ")", ")", ":", "\n", "                ", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "min", "(", "f", "[", "i", ",", "j", "+", "1", "]", "+", "1", ",", "f", "[", "i", "+", "1", ",", "j", "]", "+", "1", ",", "f", "[", "i", ",", "j", "]", "+", "1", ")", "\n", "if", "origin", "[", "i", "]", "==", "paraphrase", "[", "j", "]", ":", "\n", "                    ", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "min", "(", "f", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", ",", "f", "[", "i", "]", "[", "j", "]", ")", "\n", "\n", "", "", "", "return", "int", "(", "f", "[", "len", "(", "origin", ")", "]", "[", "len", "(", "paraphrase", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.ref_bleu_metric.RefBleuMetric.__init__": [[16, 19], ["fibber.metrics.metric_base.MetricBase.__init__"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize ce model.\"\"\"", "\n", "super", "(", "RefBleuMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.distance.ref_bleu_metric.RefBleuMetric._measure_example": [[20, 39], ["nltk.word_tokenize", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.sentence_bleu", "isinstance", "nltk.word_tokenize", "logger.warning"], "methods", ["None"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the 4 gram self bleu\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "ref", "=", "data_record", "[", "\"ref\"", "]", "\n", "if", "not", "isinstance", "(", "ref", ",", "list", ")", ":", "\n", "                ", "ref", "=", "[", "ref", "]", "\n", "", "ref", "=", "[", "word_tokenize", "(", "item", ")", "for", "item", "in", "ref", "]", "\n", "", "except", "BaseException", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Ref not found in data, Ref Blue is set to 0.\"", ")", "\n", "return", "0", "\n", "", "hypo", "=", "word_tokenize", "(", "paraphrase", ")", "\n", "chencherry", "=", "bleu_score", ".", "SmoothingFunction", "(", ")", "\n", "return", "bleu_score", ".", "sentence_bleu", "(", "ref", ",", "hypo", ",", "smoothing_function", "=", "chencherry", ".", "method1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.USESimilarityMetric.__init__": [[42, 53], ["fibber.metrics.metric_base.MetricBase.__init__", "logger.info", "use_similarity_metric.config_tf_gpu", "tensorflow_hub.load", "fibber.log.remove_logger_tf_handler", "logger.warning", "logger.info", "fibber.resources.get_universal_sentence_encoder"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.config_tf_gpu", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_universal_sentence_encoder"], ["def", "__init__", "(", "self", ",", "use_gpu_id", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize universal sentence encoder.\"\"\"", "\n", "super", "(", "USESimilarityMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "logger", ".", "info", "(", "\"load universal sentence encoder\"", ")", "\n", "config_tf_gpu", "(", "use_gpu_id", ")", "\n", "if", "use_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Universal sentence encoder is using CPU.\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Universal sentence encoder metric is using GPU %d.\"", ",", "use_gpu_id", ")", "\n", "", "self", ".", "model", "=", "hub", ".", "load", "(", "resources", ".", "get_universal_sentence_encoder", "(", ")", ")", "\n", "log", ".", "remove_logger_tf_handler", "(", "logger", ")", "# tensorflow_hub mess up the python logging", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.USESimilarityMetric._measure_batch": [[54, 71], ["use_similarity_metric.USESimilarityMetric.model().numpy", "numpy.linalg.norm", "abs", "float", "use_similarity_metric.USESimilarityMetric.model", "numpy.sum"], "methods", ["None"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (list): a list containing the USE similarity metric for each paraphrase.\n        \"\"\"", "\n", "embs", "=", "self", ".", "model", "(", "[", "origin", "]", "+", "paraphrase_list", ")", ".", "numpy", "(", ")", "\n", "\n", "norm", "=", "np", ".", "linalg", ".", "norm", "(", "embs", ",", "axis", "=", "1", ")", "\n", "sim", "=", "np", ".", "sum", "(", "embs", "[", "0", "]", "*", "embs", ",", "axis", "=", "1", ")", "/", "norm", "[", "0", "]", "/", "norm", "\n", "assert", "abs", "(", "sim", "[", "0", "]", "-", "1", ")", "<", "1e-4", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "sim", "[", "1", ":", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.USESimilarityMetric._measure_multiple_examples": [[72, 80], ["use_similarity_metric.USESimilarityMetric.model().numpy", "numpy.linalg.norm", "len", "len", "float", "use_similarity_metric.USESimilarityMetric.model", "len", "len"], "methods", ["None"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "embs", "=", "self", ".", "model", "(", "origin_list", "+", "paraphrase_list", ")", ".", "numpy", "(", ")", "\n", "norm", "=", "np", ".", "linalg", ".", "norm", "(", "embs", ",", "axis", "=", "1", ")", "\n", "embs", "=", "embs", "/", "norm", "[", ":", ",", "None", "]", "\n", "sim", "=", "(", "embs", "[", ":", "len", "(", "origin_list", ")", "]", "*", "embs", "[", "len", "(", "origin_list", ")", ":", "]", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "sim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.USESimilarityMetric._measure_example": [[81, 93], ["use_similarity_metric.USESimilarityMetric.model().numpy", "float", "use_similarity_metric.USESimilarityMetric.model", "numpy.linalg.norm", "numpy.sum", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the cosine similarity between the embedding of original text and paraphrased\n        text.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n            field: ignored.\n        \"\"\"", "\n", "embs", "=", "self", ".", "model", "(", "[", "origin", ",", "paraphrase", "]", ")", ".", "numpy", "(", ")", "\n", "return", "float", "(", "np", ".", "sum", "(", "embs", "[", "0", "]", "*", "embs", "[", "1", "]", ")", "/", "np", ".", "linalg", ".", "norm", "(", "embs", "[", "0", "]", ")", "/", "np", ".", "linalg", ".", "norm", "(", "embs", "[", "1", "]", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.use_similarity_metric.config_tf_gpu": [[18, 36], ["tensorflow.config.list_physical_devices", "tensorflow.config.set_visible_devices", "tensorflow.config.experimental.list_physical_devices", "tensorflow.config.experimental.set_visible_devices", "tensorflow.config.experimental.set_memory_growth", "tensorflow.config.experimental.set_memory_growth", "item.name.endswith", "item.name.endswith"], "function", ["None"], ["def", "config_tf_gpu", "(", "gpu_id", ")", ":", "\n", "    ", "\"\"\"Configure tensorflow to use a specific GPU.\n\n    Args:\n        gpu_id (int): the gpu id. Set -1 to use CPU.\n    \"\"\"", "\n", "if", "tf", ".", "__version__", ">=", "\"2.3.0\"", ":", "\n", "        ", "gpus", "=", "tf", ".", "config", ".", "list_physical_devices", "(", "device_type", "=", "\"GPU\"", ")", "\n", "gpus", "=", "[", "item", "for", "item", "in", "gpus", "if", "item", ".", "name", ".", "endswith", "(", "\"GPU:%d\"", "%", "gpu_id", ")", "]", "\n", "tf", ".", "config", ".", "set_visible_devices", "(", "gpus", ",", "device_type", "=", "\"GPU\"", ")", "\n", "for", "device", "in", "gpus", ":", "\n", "            ", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "device", ",", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "gpus", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "device_type", "=", "\"GPU\"", ")", "\n", "gpus", "=", "[", "item", "for", "item", "in", "gpus", "if", "item", ".", "name", ".", "endswith", "(", "\"GPU:%d\"", "%", "gpu_id", ")", "]", "\n", "tf", ".", "config", ".", "experimental", ".", "set_visible_devices", "(", "gpus", ",", "device_type", "=", "\"GPU\"", ")", "\n", "for", "device", "in", "gpus", ":", "\n", "            ", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "device", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.ce_similarity_metric.CESimilarityMetric.__init__": [[19, 34], ["fibber.metrics.metric_base.MetricBase.__init__", "logger.info", "sentence_transformers.CrossEncoder", "logger.warning", "logger.info", "fibber.resources.get_transformers"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["def", "__init__", "(", "self", ",", "ce_pretrained_model", "=", "\"stsb-roberta-large\"", ",", "ce_gpu_id", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize ce model.\"\"\"", "\n", "super", "(", "CESimilarityMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "ce_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"CE metric is running on CPU.\"", ")", "\n", "device", "=", "\"cpu\"", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"CE metric is running on GPU %d.\"", ",", "ce_gpu_id", ")", "\n", "device", "=", "\"cuda:%d\"", "%", "ce_gpu_id", "\n", "\n", "", "logger", ".", "info", "(", "\"load ce model.\"", ")", "\n", "\n", "self", ".", "_model", "=", "CrossEncoder", "(", "resources", ".", "get_transformers", "(", "ce_pretrained_model", ")", ",", "\n", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.ce_similarity_metric.CESimilarityMetric._get_emb": [[35, 38], ["ce_similarity_metric.CESimilarityMetric._model.encode"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.DefaultTokenizer.encode"], ["", "def", "_get_emb", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "\"\"\"Compute the embedding of sentences.\"\"\"", "\n", "return", "self", ".", "_model", ".", "encode", "(", "sentences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.ce_similarity_metric.CESimilarityMetric._measure_batch": [[39, 52], ["float", "ce_similarity_metric.CESimilarityMetric._model.predict"], "methods", ["None"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Measure the metric on a batch of paraphrase_list.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (list): a list containing the USE similarity metric for each paraphrase.\n        \"\"\"", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "self", ".", "_model", ".", "predict", "(", "\n", "[", "[", "origin", ",", "paraphrase", "]", "for", "paraphrase", "in", "paraphrase_list", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.ce_similarity_metric.CESimilarityMetric._measure_multiple_examples": [[53, 58], ["len", "len", "float", "ce_similarity_metric.CESimilarityMetric._model.predict", "zip"], "methods", ["None"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "origin_list", ")", "==", "len", "(", "paraphrase_list", ")", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "self", ".", "_model", ".", "predict", "(", "\n", "[", "[", "origin", ",", "paraphrase", "]", "for", "origin", ",", "paraphrase", "in", "zip", "(", "origin_list", ",", "paraphrase_list", ")", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.ce_similarity_metric.CESimilarityMetric._measure_example": [[59, 68], ["float", "ce_similarity_metric.CESimilarityMetric._model.predict"], "methods", ["None"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the perplexity ratio.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n        \"\"\"", "\n", "return", "float", "(", "self", ".", "_model", ".", "predict", "(", "[", "[", "origin", ",", "paraphrase", "]", "]", ")", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.GloVeSimilarityMetric.__init__": [[57, 70], ["fibber.metrics.metric_base.MetricBase.__init__", "fibber.resources.get_nltk_data", "fibber.resources.get_glove_emb", "fibber.resources.get_stopwords", "logger.info", "word.lower().strip.lower().strip.lower().strip", "word.lower().strip.lower().strip.lower"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_nltk_data", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_glove_emb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_stopwords"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize, load Glove embeddings.\"\"\"", "\n", "super", "(", "GloVeSimilarityMetric", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "get_nltk_data", "(", ")", "\n", "self", ".", "_glove", "=", "get_glove_emb", "(", ")", "\n", "stopwords", "=", "get_stopwords", "(", ")", "\n", "logger", ".", "info", "(", "\"Glove embeddings and stopwords loaded.\"", ")", "\n", "\n", "for", "word", "in", "stopwords", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "if", "word", "in", "self", ".", "_glove", "[", "\"tok2id\"", "]", ":", "\n", "                ", "self", ".", "_glove", "[", "\"emb_table\"", "]", "[", "self", ".", "_glove", "[", "\"tok2id\"", "]", "[", "word", "]", ",", ":", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.GloVeSimilarityMetric._measure_example": [[71, 81], ["float", "glove_similarity_metric.compute_emb_sim"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.compute_emb_sim"], ["", "", "", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the Glove cosine similarity between two sentences.\n\n        Args:\n            origin (str): original text.\n            paraphrase (str): paraphrased text.\n            data_record: ignored.\n        \"\"\"", "\n", "return", "float", "(", "compute_emb_sim", "(", "self", ".", "_glove", "[", "\"emb_table\"", "]", ",", "self", ".", "_glove", "[", "\"tok2id\"", "]", ",", "\n", "origin", ",", "paraphrase", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.compute_emb": [[15, 32], ["nltk.word_tokenize", "numpy.sum", "item.lower", "embs.append", "item.lower"], "function", ["None"], ["def", "compute_emb", "(", "emb_table", ",", "tok_to_id", ",", "x", ")", ":", "\n", "    ", "\"\"\"Compute the sum of word embeddings for a sentence.\n\n    Args:\n        emb_table (np.array): the glove embedding table.\n        tok_to_id (dict): a dict mapping strs to ints.\n        x (str): text.\n\n    Returns:\n        (np.array): the sum of word embedding.\n    \"\"\"", "\n", "toks", "=", "word_tokenize", "(", "x", ")", "\n", "embs", "=", "[", "]", "\n", "for", "item", "in", "toks", ":", "\n", "        ", "if", "item", ".", "lower", "(", ")", "in", "tok_to_id", ":", "\n", "            ", "embs", ".", "append", "(", "emb_table", "[", "tok_to_id", "[", "item", ".", "lower", "(", ")", "]", "]", ")", "\n", "", "", "return", "np", ".", "sum", "(", "embs", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.compute_emb_sim": [[34, 52], ["glove_similarity_metric.compute_emb", "glove_similarity_metric.compute_emb", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.compute_emb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.similarity.glove_similarity_metric.compute_emb"], ["", "def", "compute_emb_sim", "(", "emb_table", ",", "tok_to_id", ",", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"Compute the cosine similarity between two sentences. The sentence embedding is the sum\n    of word embeddings.\n\n    Args:\n        emb_table (np.array): the glove embedding table.\n        tok_to_id (dict): a dict mapping strs to ints.\n        x (str): text.\n        y (str): text.\n\n    Returns:\n        (float): the cosine similarity.\n    \"\"\"", "\n", "ex", "=", "compute_emb", "(", "emb_table", ",", "tok_to_id", ",", "x", ")", "\n", "ey", "=", "compute_emb", "(", "emb_table", ",", "tok_to_id", ",", "y", ")", "\n", "return", "(", "(", "ex", "*", "ey", ")", ".", "sum", "(", ")", "\n", "/", "(", "np", ".", "linalg", ".", "norm", "(", "ex", ")", "+", "1e-8", ")", "\n", "/", "(", "np", ".", "linalg", ".", "norm", "(", "ey", ")", "+", "1e-8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier.__init__": [[39, 65], ["fibber.metrics.classifier.classifier_base.ClassifierBase.__init__", "os.path.join", "os.makedirs", "os.path.join", "os.path.exists", "fibber.get_root_dir", "fasttext.load_model", "len", "tempfile.gettempdir", "os.path.join", "os.path.join", "fasttext_classifier.change_to_fasttext_format", "fasttext_classifier.change_to_fasttext_format", "fasttext.train_supervised", "fasttext_classifier.FasttextClassifier._model.test", "logger.info", "fasttext_classifier.FasttextClassifier._model.save_model", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.change_to_fasttext_format", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.change_to_fasttext_format"], ["def", "__init__", "(", "self", ",", "dataset_name", ",", "trainset", ",", "testset", ",", "\n", "fasttext_lr", "=", "1.", ",", "fasttext_epoch", "=", "25", ",", "fasttext_ngram", "=", "5", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "FasttextClassifier", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"fasttext_clf\"", ",", "dataset_name", ")", "\n", "os", ".", "makedirs", "(", "model_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "model_dir", ",", "\"fasttext_model_ngram_%d_epoch_%d.bin\"", "%", "(", "fasttext_ngram", ",", "fasttext_epoch", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_filename", ")", ":", "\n", "            ", "self", ".", "_model", "=", "fasttext", ".", "load_model", "(", "model_filename", ")", "\n", "self", ".", "_n_class", "=", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "tmp_dir", "=", "tempfile", ".", "gettempdir", "(", ")", "\n", "fasttext_train_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"%s.train\"", "%", "dataset_name", ")", "\n", "fasttext_test_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"%s.test\"", "%", "dataset_name", ")", "\n", "change_to_fasttext_format", "(", "trainset", ",", "fasttext_train_filename", ")", "\n", "change_to_fasttext_format", "(", "testset", ",", "fasttext_test_filename", ")", "\n", "\n", "self", ".", "_model", "=", "fasttext", ".", "train_supervised", "(", "input", "=", "fasttext_train_filename", ",", "\n", "lr", "=", "fasttext_lr", ",", "\n", "epoch", "=", "fasttext_epoch", ",", "\n", "wordNgrams", "=", "fasttext_ngram", ")", "\n", "_", ",", "precision", ",", "recall", "=", "self", ".", "_model", ".", "test", "(", "fasttext_test_filename", ",", "k", "=", "1", ")", "\n", "logger", ".", "info", "(", "\"Fast Text Precision %f, Recall %f\"", ",", "precision", ",", "recall", ")", "\n", "self", ".", "_model", ".", "save_model", "(", "model_filename", ")", "\n", "self", ".", "_n_class", "=", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier._predict_log_dist_example": [[66, 83], ["fasttext_classifier.FasttextClassifier._model.predict", "numpy.zeros", "zip", "numpy.log", "int", "len"], "methods", ["None"], ["", "", "def", "_predict_log_dist_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict the log-probability distribution over classes for one example.\n\n        Args:\n            origin (str): the original text.\n            paraphrase (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): a numpy array of size ``(num_labels)``.\n        \"\"\"", "\n", "labels", ",", "probs", "=", "self", ".", "_model", ".", "predict", "(", "paraphrase", ",", "k", "=", "self", ".", "_n_class", ")", "\n", "ret", "=", "np", ".", "zeros", "(", "self", ".", "_n_class", ")", "\n", "for", "label", ",", "prob", "in", "zip", "(", "labels", ",", "probs", ")", ":", "\n", "            ", "idx", "=", "int", "(", "label", "[", "len", "(", "\"__label__\"", ")", ":", "]", ")", "\n", "ret", "[", "idx", "]", "=", "prob", "\n", "", "return", "np", ".", "log", "(", "ret", "+", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier.robust_tune_init": [[84, 86], ["None"], "methods", ["None"], ["", "def", "robust_tune_init", "(", "self", ",", "optimizer", ",", "lr", ",", "weight_decay", ",", "steps", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier.robust_tune_step": [[87, 89], ["None"], "methods", ["None"], ["", "def", "robust_tune_step", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier.load_robust_tuned_model": [[90, 92], ["None"], "methods", ["None"], ["", "def", "load_robust_tuned_model", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.FasttextClassifier.save_robust_tuned_model": [[93, 95], ["None"], "methods", ["None"], ["", "def", "save_robust_tuned_model", "(", "self", ",", "load_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.fasttext_classifier.change_to_fasttext_format": [[13, 21], ["open", "print", "logger.error"], "function", ["None"], ["def", "change_to_fasttext_format", "(", "dataset", ",", "filename", ")", ":", "\n", "    ", "\"\"\"Change Fibber's dataset to fast text's format and save to a file.\"\"\"", "\n", "with", "open", "(", "filename", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "item", "in", "dataset", "[", "\"data\"", "]", ":", "\n", "            ", "if", "\"text1\"", "in", "item", ":", "\n", "                ", "logger", ".", "error", "(", "\"FastText does not support text1.\"", ")", "\n", "raise", "RuntimeError", "\n", "", "print", "(", "\"__label__%d\"", "%", "item", "[", "\"label\"", "]", ",", "item", "[", "\"text0\"", "]", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.__init__": [[239, 279], ["fibber.metrics.classifier.classifier_base.ClassifierBase.__init__", "logger.info", "transformers.AutoTokenizer.from_pretrained", "transformer_classifier.load_or_train_transformer_clf", "len", "fibber.resources.get_transformers", "logger.warning", "torch.device", "torch.device", "torch.device", "torch.device", "logger.info", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.load_or_train_transformer_clf", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["def", "__init__", "(", "self", ",", "dataset_name", ",", "trainset", ",", "testset", ",", "transformer_clf_gpu_id", "=", "-", "1", ",", "\n", "transformer_clf_steps", "=", "20000", ",", "transformer_clf_bs", "=", "32", ",", "transformer_clf_lr", "=", "0.00002", ",", "\n", "transformer_clf_optimizer", "=", "\"adamw\"", ",", "transformer_clf_weight_decay", "=", "0.001", ",", "\n", "transformer_clf_period_summary", "=", "100", ",", "transformer_clf_period_val", "=", "500", ",", "\n", "transformer_clf_period_save", "=", "20000", ",", "transformer_clf_val_steps", "=", "10", ",", "\n", "transformer_clf_model_init", "=", "\"bert-base-cased\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransformerClassifier", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "logger", ".", "info", "(", "\"Use %s classifier.\"", ",", "transformer_clf_model_init", ")", "\n", "\n", "self", ".", "_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "transformer_clf_model_init", ")", ")", "\n", "\n", "if", "transformer_clf_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Transformer clf metric is running on CPU.\"", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transformer clf metric is running on GPU %d.\"", ",", "transformer_clf_gpu_id", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "transformer_clf_gpu_id", ")", "\n", "\n", "", "self", ".", "_model_init", "=", "transformer_clf_model_init", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_model", "=", "load_or_train_transformer_clf", "(", "\n", "model_init", "=", "transformer_clf_model_init", ",", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "trainset", "=", "trainset", ",", "\n", "testset", "=", "testset", ",", "\n", "transformer_clf_steps", "=", "transformer_clf_steps", ",", "\n", "transformer_clf_lr", "=", "transformer_clf_lr", ",", "\n", "transformer_clf_bs", "=", "transformer_clf_bs", ",", "\n", "transformer_clf_optimizer", "=", "transformer_clf_optimizer", ",", "\n", "transformer_clf_weight_decay", "=", "transformer_clf_weight_decay", ",", "\n", "transformer_clf_period_summary", "=", "transformer_clf_period_summary", ",", "\n", "transformer_clf_period_val", "=", "transformer_clf_period_val", ",", "\n", "transformer_clf_period_save", "=", "transformer_clf_period_save", ",", "\n", "transformer_clf_val_steps", "=", "transformer_clf_val_steps", ",", "\n", "device", "=", "self", ".", "_device", ")", "\n", "self", ".", "_fine_tune_schedule", "=", "None", "\n", "self", ".", "_fine_tune_opt", "=", "None", "\n", "self", ".", "_ppl_filter_metric", "=", "None", "\n", "self", ".", "_num_labels", "=", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.__repr__": [[280, 282], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model_init", "+", "\"-Classifier\"", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_model_and_tokenizer": [[283, 285], ["None"], "methods", ["None"], ["", "def", "get_model_and_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", ",", "self", ".", "_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_model_init": [[286, 288], ["None"], "methods", ["None"], ["", "def", "get_model_init", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model_init", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.get_device": [[289, 291], ["None"], "methods", ["None"], ["", "def", "get_device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_device", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.enable_ppl_filter": [[292, 294], ["None"], "methods", ["None"], ["", "def", "enable_ppl_filter", "(", "self", ",", "ppl_metric", ")", ":", "\n", "        ", "self", ".", "_ppl_filter_metric", "=", "ppl_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier._predict_log_dist_batch": [[295, 322], ["transformer_classifier.TransformerClassifier._ppl_filter_metric.perplexity_filter", "transformer_classifier.TransformerClassifier._tokenizer().to", "transformer_classifier.TransformerClassifier._tokenizer().to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.log_softmax().detach().cpu().numpy", "torch.log_softmax().detach().cpu().numpy", "transformer_classifier.TransformerClassifier._model", "transformer_classifier.TransformerClassifier._tokenizer", "transformer_classifier.TransformerClassifier._tokenizer", "torch.log_softmax().detach().cpu", "torch.log_softmax().detach().cpu", "torch.log_softmax().detach", "torch.log_softmax().detach", "len", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "_predict_log_dist_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict the log-probability distribution over classes for one batch.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): a numpy array of size ``(batch_size * num_labels)``.\n        \"\"\"", "\n", "if", "self", ".", "_ppl_filter_metric", "is", "not", "None", ":", "\n", "            ", "paraphrase_list", "=", "self", ".", "_ppl_filter_metric", ".", "perplexity_filter", "(", "paraphrase_list", ")", "\n", "\n", "", "if", "self", ".", "_field", "==", "\"text0\"", ":", "\n", "            ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "text", "=", "paraphrase_list", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "_field", "==", "\"text1\"", "\n", "batch_input", "=", "self", ".", "_tokenizer", "(", "text", "=", "[", "data_record", "[", "\"text0\"", "]", "]", "*", "len", "(", "paraphrase_list", ")", ",", "\n", "text_pair", "=", "paraphrase_list", ",", "\n", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "self", ".", "_model", "(", "**", "batch_input", ")", "[", "0", "]", "\n", "res", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier._predict_log_dist_multiple_examples": [[323, 343], ["transformer_classifier.TransformerClassifier._ppl_filter_metric.perplexity_filter", "transformer_classifier.TransformerClassifier._tokenizer().to", "transformer_classifier.TransformerClassifier._tokenizer().to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_classifier.TransformerClassifier._model", "torch.log_softmax().detach().cpu().numpy", "torch.log_softmax().detach().cpu().numpy", "logits.detach().cpu().numpy", "transformer_classifier.TransformerClassifier._tokenizer", "transformer_classifier.TransformerClassifier._tokenizer", "torch.log_softmax().detach().cpu", "torch.log_softmax().detach().cpu", "logits.detach().cpu", "torch.log_softmax().detach", "torch.log_softmax().detach", "logits.detach", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "_predict_log_dist_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "return_raw_logits", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "_ppl_filter_metric", "is", "not", "None", ":", "\n", "            ", "paraphrase_list", "=", "self", ".", "_ppl_filter_metric", ".", "perplexity_filter", "(", "paraphrase_list", ")", "\n", "\n", "", "if", "self", ".", "_field", "==", "\"text0\"", ":", "\n", "            ", "batch_input", "=", "self", ".", "_tokenizer", "(", "\n", "text", "=", "paraphrase_list", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "_field", "==", "\"text1\"", "\n", "batch_input", "=", "self", ".", "_tokenizer", "(", "text", "=", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "data_record_list", "]", ",", "\n", "text_pair", "=", "paraphrase_list", ",", "\n", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "self", ".", "_model", "(", "**", "batch_input", ")", "[", "0", "]", "\n", "if", "not", "return_raw_logits", ":", "\n", "                ", "res", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "res", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier._predict_log_dist_example": [[344, 356], ["transformer_classifier.TransformerClassifier.predict_log_dist_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "_predict_log_dist_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict the log-probability distribution over classes for one example.\n\n        Args:\n            origin (str): the original text.\n            paraphrase (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): a numpy array of size ``(num_labels)``.\n        \"\"\"", "\n", "return", "self", ".", "predict_log_dist_batch", "(", "origin", ",", "[", "paraphrase", "]", ",", "data_record", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.robust_tune_init": [[357, 365], ["transformer_classifier.TransformerClassifier._model.parameters", "transformer_classifier.get_optimizer", "logger.error", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.get_optimizer"], ["", "def", "robust_tune_init", "(", "self", ",", "optimizer", ",", "lr", ",", "weight_decay", ",", "steps", ")", ":", "\n", "        ", "if", "self", ".", "_fine_tune_schedule", "is", "not", "None", "or", "self", ".", "_fine_tune_opt", "is", "not", "None", ":", "\n", "            ", "logger", ".", "error", "(", "\"fine tuning has been initialized.\"", ")", "\n", "raise", "RuntimeError", "(", "\"fine tuning has been initialized.\"", ")", "\n", "\n", "", "params", "=", "self", ".", "_model", ".", "parameters", "(", ")", "\n", "self", ".", "_fine_tune_opt", ",", "self", ".", "_fine_tune_schedule", "=", "get_optimizer", "(", "\n", "optimizer", ",", "lr", ",", "weight_decay", ",", "steps", ",", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.robust_tune_step": [[366, 402], ["transformer_classifier.TransformerClassifier._model.train", "transformer_classifier.TransformerClassifier._tokenizer().to", "transformer_classifier.TransformerClassifier._fine_tune_opt.zero_grad", "loss.backward", "transformer_classifier.TransformerClassifier._fine_tune_opt.step", "transformer_classifier.TransformerClassifier._fine_tune_schedule.step", "transformer_classifier.TransformerClassifier._model.eval", "logger.error", "RuntimeError", "labels.append", "len", "transformer_classifier.TransformerClassifier._model", "logits.argmax().detach().cpu().numpy", "float", "text0_list.append", "text1_list.append", "len", "len", "RuntimeError", "transformer_classifier.TransformerClassifier._tokenizer", "loss.detach().cpu().numpy", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "logits.argmax().detach().cpu", "loss.detach().cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "logits.argmax().detach", "loss.detach", "logits.argmax"], "methods", ["None"], ["", "def", "robust_tune_step", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "if", "self", ".", "_fine_tune_schedule", "is", "None", "or", "self", ".", "_fine_tune_opt", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "\"fine tuning not initialized.\"", ")", "\n", "raise", "RuntimeError", "(", "\"fine tuning not initialized.\"", ")", "\n", "\n", "", "self", ".", "_model", ".", "train", "(", ")", "\n", "text0_list", "=", "[", "]", "\n", "text1_list", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "data_record", "in", "data_record_list", ":", "\n", "            ", "if", "\"text0\"", "in", "data_record", ":", "\n", "                ", "text0_list", ".", "append", "(", "data_record", "[", "\"text0\"", "]", ")", "\n", "", "if", "\"text1\"", "in", "data_record", ":", "\n", "                ", "text1_list", ".", "append", "(", "data_record", "[", "\"text1\"", "]", ")", "\n", "", "labels", ".", "append", "(", "data_record", "[", "\"label\"", "]", ")", "\n", "\n", "", "if", "len", "(", "text1_list", ")", "==", "0", ":", "\n", "            ", "text1_list", "=", "None", "\n", "", "elif", "len", "(", "text1_list", ")", "!=", "len", "(", "text0_list", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"data records are not consistent.\"", ")", "\n", "\n", "", "batch_input", "=", "self", ".", "_tokenizer", "(", "text", "=", "text0_list", ",", "text_pair", "=", "text1_list", ",", "padding", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "\n", "loss", ",", "logits", "=", "self", ".", "_model", "(", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", ".", "to", "(", "self", ".", "_device", ")", ",", "\n", "**", "batch_input", "\n", ")", "[", ":", "2", "]", "\n", "\n", "self", ".", "_fine_tune_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_fine_tune_opt", ".", "step", "(", ")", "\n", "self", ".", "_fine_tune_schedule", ".", "step", "(", ")", "\n", "\n", "self", ".", "_model", ".", "eval", "(", ")", "\n", "return", "logits", ".", "argmax", "(", "axis", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.load_robust_tuned_model": [[403, 410], ["os.path.join", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformer_classifier.TransformerClassifier._model.eval", "transformer_classifier.TransformerClassifier._model.to", "logger.info"], "methods", ["None"], ["", "def", "load_robust_tuned_model", "(", "self", ",", "load_path", ")", ":", "\n", "        ", "model_dir", "=", "os", ".", "path", ".", "join", "(", "load_path", ",", "\"model_ckpt\"", ")", "\n", "self", ".", "_model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_dir", ")", "\n", "\n", "self", ".", "_model", ".", "eval", "(", ")", "\n", "self", ".", "_model", ".", "to", "(", "self", ".", "_device", ")", "\n", "logger", ".", "info", "(", "\"Load transformer-based classifier from %s.\"", ",", "model_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.TransformerClassifier.save_robust_tuned_model": [[411, 415], ["os.path.join", "transformer_classifier.TransformerClassifier._model.save_pretrained", "logger.info"], "methods", ["None"], ["", "def", "save_robust_tuned_model", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "model_dir", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"model_ckpt\"", ")", "\n", "self", ".", "_model", ".", "save_pretrained", "(", "model_dir", ")", "\n", "logger", ".", "info", "(", "\"Transformer-based classifier saved at %s.\"", ",", "model_dir", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.get_optimizer": [[20, 47], ["transformers.get_linear_schedule_with_warmup", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.AdamW", "torch.optim.AdamW", "RuntimeError"], "function", ["None"], ["def", "get_optimizer", "(", "optimizer_name", ",", "lr", ",", "decay", ",", "train_step", ",", "params", ",", "warmup", "=", "1000", ")", ":", "\n", "    ", "\"\"\"Create an optimizer and schedule of learning rate for parameters.\n\n    Args:\n        optimizer_name (str): choose from ``[\"adam\", \"sgd\", \"adamw\"]``.\n        lr (float): learning rate.\n        decay (float): weight decay.\n        train_step (int): number of training steps.\n        params (list): a list of parameters in the model.\n        warmup (int): number of warm up steps.\n\n    Returns:\n        A torch optimizer and a scheduler.\n    \"\"\"", "\n", "if", "optimizer_name", "==", "\"adam\"", ":", "\n", "        ", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "params", "=", "params", ",", "lr", "=", "lr", ",", "weight_decay", "=", "decay", ")", "\n", "", "elif", "optimizer_name", "==", "\"sgd\"", ":", "\n", "        ", "opt", "=", "torch", ".", "optim", ".", "SGD", "(", "params", "=", "params", ",", "lr", "=", "lr", ",", "weight_decay", "=", "decay", ")", "\n", "", "elif", "optimizer_name", "==", "\"adamw\"", ":", "\n", "        ", "opt", "=", "torch", ".", "optim", ".", "AdamW", "(", "params", "=", "params", ",", "lr", "=", "lr", ",", "weight_decay", "=", "decay", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"unknown optimizer\"", ")", "\n", "\n", "", "schedule", "=", "transformers", ".", "get_linear_schedule_with_warmup", "(", "\n", "opt", ",", "num_warmup_steps", "=", "warmup", ",", "num_training_steps", "=", "train_step", ")", "\n", "\n", "return", "opt", ",", "schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.run_evaluate": [[49, 88], ["model.eval", "range", "summary.add_scalar", "summary.add_scalar", "model.train", "next", "seq.to.to", "mask.to.to", "tok_type.to.to", "label.to.to", "numpy.mean", "torch.no_grad", "torch.no_grad", "model_init.startswith", "loss_list.append", "seq.to.size", "logits.argmax().eq().float().sum().detach().cpu().numpy", "model", "model", "loss.detach().cpu().numpy", "logits.argmax().eq().float().sum().detach().cpu", "loss.detach().cpu", "logits.argmax().eq().float().sum().detach", "loss.detach", "logits.argmax().eq().float().sum", "logits.argmax().eq().float", "logits.argmax().eq", "logits.argmax"], "function", ["None"], ["", "def", "run_evaluate", "(", "model", ",", "dataloader_iter", ",", "eval_steps", ",", "summary", ",", "global_step", ",", "device", ",", "model_init", ")", ":", "\n", "    ", "\"\"\"Evaluate a model and add error rate and validation loss to Tensorboard.\n\n    Args:\n        model (transformers.BertForSequenceClassification): a BERT classification model.\n        dataloader_iter (torch.IterableDataset): an iterator of a torch.IterableDataset.\n        eval_steps (int): number of training steps.\n        summary (torch.utils.tensorboard.SummaryWriter): a Tensorboard SummaryWriter object.\n        global_step (int): current training steps.\n        device (torch.Device): the device where the model in running on.\n        model_init (str): a str specifies the pretrained model. used to determine model input.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "correct", ",", "count", "=", "0", ",", "0", "\n", "loss_list", "=", "[", "]", "\n", "\n", "for", "v_step", "in", "range", "(", "eval_steps", ")", ":", "\n", "        ", "seq", ",", "mask", ",", "tok_type", ",", "label", "=", "next", "(", "dataloader_iter", ")", "\n", "seq", "=", "seq", ".", "to", "(", "device", ")", "\n", "mask", "=", "mask", ".", "to", "(", "device", ")", "\n", "tok_type", "=", "tok_type", ".", "to", "(", "device", ")", "\n", "label", "=", "label", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "model_init", ".", "startswith", "(", "\"bert-\"", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "seq", ",", "mask", ",", "tok_type", ",", "labels", "=", "label", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "model", "(", "seq", ",", "mask", ",", "labels", "=", "label", ")", "\n", "", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "loss_list", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "count", "+=", "seq", ".", "size", "(", "0", ")", "\n", "correct", "+=", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "eq", "(", "label", ")", "\n", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "summary", ".", "add_scalar", "(", "\"clf_val/error_rate\"", ",", "1", "-", "correct", "/", "count", ",", "global_step", ")", "\n", "summary", ".", "add_scalar", "(", "\"clf_val/loss\"", ",", "np", ".", "mean", "(", "loss_list", ")", ",", "global_step", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.load_or_train_transformer_clf": [[90, 204], ["os.path.join", "os.path.join", "os.path.exists", "len", "transformers.AutoModelForSequenceClassification.from_pretrained().to", "AutoModelForSequenceClassification.from_pretrained.train", "logger.info", "logger.info", "torch.utils.tensorboard.SummaryWriter", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "iter", "AutoModelForSequenceClassification.from_pretrained.parameters", "transformer_classifier.get_optimizer", "tqdm.tqdm", "AutoModelForSequenceClassification.from_pretrained.eval", "fibber.get_root_dir", "logger.info", "transformers.AutoModelForSequenceClassification.from_pretrained", "AutoModelForSequenceClassification.from_pretrained.eval", "AutoModelForSequenceClassification.from_pretrained.to", "os.path.join", "fibber.datasets.DatasetForTransformers", "fibber.datasets.DatasetForTransformers", "seq.to.to", "mask.to.to", "tok_type.to.to", "label.to.to", "model_init.startswith", "seq.to.size", "logits.argmax().eq().float().sum().detach().cpu().numpy", "opt.zero_grad", "loss.backward", "opt.step", "schedule.step", "transformers.AutoModelForSequenceClassification.from_pretrained", "AutoModelForSequenceClassification.from_pretrained.", "AutoModelForSequenceClassification.from_pretrained.", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "transformer_classifier.run_evaluate", "os.path.join", "AutoModelForSequenceClassification.from_pretrained.save_pretrained", "logger.info", "fibber.resources.get_transformers", "logits.argmax().eq().float().sum().detach().cpu", "logits.argmax().eq().float().sum().detach", "logits.argmax().eq().float().sum", "logits.argmax().eq().float", "logits.argmax().eq", "logits.argmax"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.get_optimizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.run_evaluate", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["", "def", "load_or_train_transformer_clf", "(", "\n", "model_init", ",", "dataset_name", ",", "trainset", ",", "testset", ",", "\n", "transformer_clf_steps", ",", "transformer_clf_bs", ",", "transformer_clf_lr", ",", "transformer_clf_optimizer", ",", "\n", "transformer_clf_weight_decay", ",", "transformer_clf_period_summary", ",", "transformer_clf_period_val", ",", "\n", "transformer_clf_period_save", ",", "transformer_clf_val_steps", ",", "device", ")", ":", "\n", "    ", "\"\"\"Train transformer-based classification model on a dataset.\n\n    The trained model will be stored at ``<fibber_root_dir>/transformer_clf/<dataset_name>/``.\n    If there's a saved model, load and return the model. Otherwise, train the model using the\n    given data.\n\n    Args:\n        model_init (str): pretrained model name. e.g. ``[\"bert-base-cased\",\n            \"bert-base-uncased\", \"bert-large-cased\", \"bert-large-uncased\", \"roberta-large\"]``.\n        dataset_name (str): the name of the dataset. This is also the dir to save trained model.\n        trainset (dict): a fibber dataset.\n        testset (dict): a fibber dataset.\n        transformer_clf_steps (int): steps to train a classifier.\n        transformer_clf_bs (int): the batch size.\n        transformer_clf_lr (float): the learning rate.\n        transformer_clf_optimizer (str): the optimizer name.\n        transformer_clf_weight_decay (float): the weight decay.\n        transformer_clf_period_summary (int): the period in steps to write training summary.\n        transformer_clf_period_val (int): the period in steps to run validation and write\n            validation summary.\n        transformer_clf_period_save (int): the period in steps to save current model.\n        transformer_clf_val_steps (int): number of batched in each validation.\n        device (torch.Device): the device to run the model.\n\n    Returns:\n        a torch transformer model.\n    \"\"\"", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"transformer_clf\"", ",", "dataset_name", ")", "\n", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_init", "+", "\"-%04dk\"", "%", "\n", "(", "transformer_clf_steps", "//", "1000", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Load transformer classifier from %s.\"", ",", "ckpt_path", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "ckpt_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "\n", "", "num_labels", "=", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "resources", ".", "get_transformers", "(", "model_init", ")", ",", "num_labels", "=", "num_labels", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Use %s tokenizer and classifier.\"", ",", "model_init", ")", "\n", "logger", ".", "info", "(", "\"Num labels: %s\"", ",", "num_labels", ")", "\n", "\n", "summary", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"summary\"", ")", ")", "\n", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "DatasetForTransformers", "(", "trainset", ",", "model_init", ",", "transformer_clf_bs", ")", ",", "batch_size", "=", "None", ",", "\n", "num_workers", "=", "0", ")", "\n", "\n", "dataloader_val", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "DatasetForTransformers", "(", "testset", ",", "model_init", ",", "transformer_clf_bs", ")", ",", "batch_size", "=", "None", ",", "\n", "num_workers", "=", "0", ")", "\n", "dataloader_val_iter", "=", "iter", "(", "dataloader_val", ")", "\n", "\n", "params", "=", "model", ".", "parameters", "(", ")", "\n", "\n", "opt", ",", "schedule", "=", "get_optimizer", "(", "\n", "transformer_clf_optimizer", ",", "transformer_clf_lr", ",", "transformer_clf_weight_decay", ",", "\n", "transformer_clf_steps", ",", "params", ")", "\n", "\n", "global_step", "=", "0", "\n", "correct_train", ",", "count_train", "=", "0", ",", "0", "\n", "for", "seq", ",", "mask", ",", "tok_type", ",", "label", "in", "tqdm", ".", "tqdm", "(", "dataloader", ",", "total", "=", "transformer_clf_steps", ")", ":", "\n", "        ", "global_step", "+=", "1", "\n", "seq", "=", "seq", ".", "to", "(", "device", ")", "\n", "mask", "=", "mask", ".", "to", "(", "device", ")", "\n", "tok_type", "=", "tok_type", ".", "to", "(", "device", ")", "\n", "label", "=", "label", ".", "to", "(", "device", ")", "\n", "\n", "if", "model_init", ".", "startswith", "(", "\"bert-\"", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "input_ids", "=", "seq", ",", "attention_mask", "=", "mask", ",", "\n", "token_type_ids", "=", "tok_type", ",", "labels", "=", "label", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "model", "(", "input_ids", "=", "seq", ",", "attention_mask", "=", "mask", ",", "labels", "=", "label", ")", "\n", "\n", "", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "count_train", "+=", "seq", ".", "size", "(", "0", ")", "\n", "correct_train", "+=", "(", "logits", ".", "argmax", "(", "dim", "=", "1", ")", ".", "eq", "(", "label", ")", "\n", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "schedule", ".", "step", "(", ")", "\n", "\n", "if", "global_step", "%", "transformer_clf_period_summary", "==", "0", ":", "\n", "            ", "summary", ".", "add_scalar", "(", "\"clf_train/loss\"", ",", "loss", ",", "global_step", ")", "\n", "summary", ".", "add_scalar", "(", "\"clf_train/error_rate\"", ",", "1", "-", "correct_train", "/", "count_train", ",", "\n", "global_step", ")", "\n", "correct_train", ",", "count_train", "=", "0", ",", "0", "\n", "\n", "", "if", "global_step", "%", "transformer_clf_period_val", "==", "0", ":", "\n", "            ", "run_evaluate", "(", "model", ",", "dataloader_val_iter", ",", "\n", "transformer_clf_val_steps", ",", "summary", ",", "global_step", ",", "device", ",", "model_init", ")", "\n", "\n", "", "if", "global_step", "%", "transformer_clf_period_save", "==", "0", "or", "global_step", "==", "transformer_clf_steps", ":", "\n", "            ", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_init", "+", "\"-%04dk\"", "%", "(", "global_step", "//", "1000", ")", ")", "\n", "model", ".", "save_pretrained", "(", "ckpt_path", ")", "\n", "logger", ".", "info", "(", "\"transformer classifier saved at %s.\"", ",", "ckpt_path", ")", "\n", "\n", "", "if", "global_step", ">=", "transformer_clf_steps", ":", "\n", "            ", "break", "\n", "", "", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.transformer_classifier.trivial_filtering": [[206, 213], ["range", "tokenizer.tokenize", "len", "numpy.argmin", "tokenizer.convert_tokens_to_string"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "trivial_filtering", "(", "sents", ",", "tokenizer", ",", "vocab", ")", ":", "\n", "    ", "tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "sent", ")", "for", "sent", "in", "sents", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sents", ")", ")", ":", "\n", "        ", "trivial_wid", "=", "[", "vocab", "[", "tok", "]", "if", "tok", "in", "vocab", "else", "1e9", "for", "tok", "in", "tokens", "[", "i", "]", "]", "\n", "pos", "=", "np", ".", "argmin", "(", "trivial_wid", ")", "\n", "tokens", "[", "i", "]", "[", "pos", "]", "=", "\"[MASK]\"", "\n", "", "return", "[", "tokenizer", ".", "convert_tokens_to_string", "(", "row", ")", "for", "row", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._predict_log_dist_example": [[24, 27], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "_predict_log_dist_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_example": [[28, 40], ["classifier_base.ClassifierBase._predict_log_dist_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_example"], ["", "def", "predict_log_dist_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict the log-probability distribution over classes for one example.\n\n        Args:\n            origin (str): the original text.\n            paraphrase (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): a numpy array of size ``(num_labels)``.\n        \"\"\"", "\n", "return", "self", ".", "_predict_log_dist_example", "(", "origin", ",", "paraphrase", ",", "data_record", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._predict_log_dist_batch": [[41, 47], ["numpy.asarray", "ret.append", "classifier_base.ClassifierBase.predict_log_dist_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_example"], ["", "def", "_predict_log_dist_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "paraphrase", "in", "paraphrase_list", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "self", ".", "predict_log_dist_example", "(", "origin", ",", "paraphrase", ",", "data_record", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch": [[48, 64], ["range", "numpy.concatenate", "len", "ret.append", "classifier_base.ClassifierBase._predict_log_dist_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_batch"], ["", "def", "predict_log_dist_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict the log-probability distribution over classes for one batch.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): a numpy array of size ``(batch_size * num_labels)``.\n        \"\"\"", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "paraphrase_list", ")", ",", "self", ".", "_bs", ")", ":", "\n", "            ", "ret", ".", "append", "(", "self", ".", "_predict_log_dist_batch", "(", "\n", "origin", ",", "paraphrase_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "data_record", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "ret", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._predict_log_dist_multiple_examples": [[65, 74], ["range", "numpy.asarray", "len", "ret.append", "classifier_base.ClassifierBase.predict_log_dist_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_example"], ["", "def", "_predict_log_dist_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "paraphrase_list", ")", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "self", ".", "predict_log_dist_example", "(", "\n", "None", "if", "origin_list", "is", "None", "else", "origin_list", "[", "i", "]", ",", "paraphrase_list", "[", "i", "]", ",", "\n", "data_record_list", "[", "i", "]", "if", "data_record_list", "is", "not", "None", "else", "None", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples": [[75, 85], ["range", "numpy.concatenate", "len", "ret.append", "classifier_base.ClassifierBase._predict_log_dist_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_multiple_examples"], ["", "def", "predict_log_dist_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "paraphrase_list", ")", ",", "self", ".", "_bs", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "self", ".", "_predict_log_dist_multiple_examples", "(", "\n", "None", "if", "origin_list", "is", "None", "else", "origin_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "\n", "paraphrase_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ",", "\n", "None", "if", "data_record_list", "is", "None", "else", "data_record_list", "[", "i", ":", "i", "+", "self", ".", "_bs", "]", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "ret", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_example": [[86, 99], ["numpy.argmax", "classifier_base.ClassifierBase.predict_log_dist_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_example"], ["", "def", "predict_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict class label for one example.\n\n        Args:\n            origin (str): the original text.\n            paraphrase (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.int): predicted label\n        \"\"\"", "\n", "return", "np", ".", "argmax", "(", "\n", "self", ".", "predict_log_dist_example", "(", "origin", ",", "paraphrase", ",", "data_record", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_batch": [[100, 113], ["numpy.argmax", "classifier_base.ClassifierBase.predict_log_dist_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "predict_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "\"\"\"Predict class label for one example.\n\n        Args:\n            origin (str): the original text.\n            paraphrase_list (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (np.array): predicted label as an numpy array of size ``(batch_size)``.\n        \"\"\"", "\n", "return", "np", ".", "argmax", "(", "\n", "self", ".", "predict_log_dist_batch", "(", "origin", ",", "paraphrase_list", ",", "data_record", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_multiple_examples": [[114, 118], ["numpy.argmax", "classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], ["", "def", "predict_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "data_record_list", "=", "None", ")", ":", "\n", "        ", "return", "np", ".", "argmax", "(", "\n", "self", ".", "predict_log_dist_multiple_examples", "(", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_example": [[119, 133], ["int", "classifier_base.ClassifierBase.predict_example"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_example"], ["", "def", "_measure_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Predict class label for one example.\n\n        Wrapper for ``predict_example``. Return type is changed from numpy.int to int.\n\n        Args:\n            origin (str): the original text.\n            paraphrase (list): a set of paraphrase_list.\n            data_record (dict): the corresponding data record of original text.\n\n        Returns:\n            (int): predicted label\n        \"\"\"", "\n", "return", "int", "(", "self", ".", "predict_example", "(", "origin", ",", "paraphrase", ",", "data_record", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_batch": [[134, 149], ["int", "classifier_base.ClassifierBase.predict_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_batch"], ["", "def", "_measure_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Predict class label for one batch.\n\n         Wrapper for ``predict_batch``. Return type is changed from numpy.array to list of int.\n\n         Args:\n             origin (str): the original text.\n             paraphrase_list (list): a set of paraphrase_list.\n             data_record (dict): the corresponding data record of original text.\n\n         Returns:\n             ([int]): predicted label\n         \"\"\"", "\n", "return", "[", "int", "(", "x", ")", "for", "x", "in", "\n", "self", ".", "predict_batch", "(", "origin", ",", "paraphrase_list", ",", "data_record", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase._measure_multiple_examples": [[150, 154], ["int", "classifier_base.ClassifierBase.predict_multiple_examples"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_multiple_examples"], ["", "def", "_measure_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "[", "int", "(", "x", ")", "for", "x", "in", "self", ".", "predict_multiple_examples", "(", "\n", "origin_list", ",", "paraphrase_list", ",", "data_record_list", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.robust_tune_init": [[155, 157], ["None"], "methods", ["None"], ["", "def", "robust_tune_init", "(", "self", ",", "optimizer", ",", "lr", ",", "weight_decay", ",", "steps", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.robust_tune_step": [[158, 160], ["None"], "methods", ["None"], ["", "def", "robust_tune_step", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.load_robust_tuned_model": [[161, 163], ["None"], "methods", ["None"], ["", "def", "load_robust_tuned_model", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.save_robust_tuned_model": [[164, 166], ["None"], "methods", ["None"], ["", "def", "save_robust_tuned_model", "(", "self", ",", "load_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.__init__": [[19, 30], ["fibber.metrics.classifier.classifier_base.ClassifierBase.__init__", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "original_classifier", ",", "input_manipulation", ",", "name", ",", "agg", "=", "\"hard\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "InputManipulationClassifier", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "agg", "==", "\"hard\"", ":", "\n", "            ", "self", ".", "_agg_fn", "=", "hard_agg", "\n", "", "elif", "agg", "==", "\"soft\"", ":", "\n", "            ", "self", ".", "_agg_fn", "=", "soft_agg", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"agg not supported\"", ")", "\n", "", "self", ".", "_classifier", "=", "original_classifier", "\n", "self", ".", "_input_manipulation", "=", "input_manipulation", "\n", "self", ".", "_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.__str__": [[31, 33], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_name", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_example": [[34, 39], ["input_manipulation_classifier.InputManipulationClassifier._agg_fn", "input_manipulation_classifier.InputManipulationClassifier._input_manipulation", "input_manipulation_classifier.InputManipulationClassifier._classifier.predict_log_dist_batch"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "_predict_log_dist_example", "(", "self", ",", "origin", ",", "paraphrase", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "paraphrase_list", "=", "self", ".", "_input_manipulation", "(", "\n", "[", "paraphrase", "]", ",", "[", "data_record", "]", "if", "data_record", "is", "not", "None", "else", "None", ")", "[", "0", "]", "\n", "return", "self", ".", "_agg_fn", "(", "self", ".", "_classifier", ".", "predict_log_dist_batch", "(", "\n", "origin", ",", "paraphrase_list", ",", "data_record", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_batch": [[40, 61], ["input_manipulation_classifier.InputManipulationClassifier._input_manipulation", "input_manipulation_classifier.InputManipulationClassifier._classifier.predict_log_dist_batch", "numpy.asarray", "logits_reformat.append", "len", "len", "ret.append", "input_manipulation_classifier.InputManipulationClassifier._agg_fn", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_batch"], ["", "def", "_predict_log_dist_batch", "(", "self", ",", "origin", ",", "paraphrase_list", ",", "data_record", "=", "None", ")", ":", "\n", "        ", "paraphrase_list", "=", "self", ".", "_input_manipulation", "(", "\n", "paraphrase_list", ",", "\n", "[", "data_record", "]", "*", "len", "(", "paraphrase_list", ")", "if", "data_record", "is", "not", "None", "else", "None", ")", "\n", "\n", "paraphrase_list_cat", "=", "[", "]", "\n", "for", "item", "in", "paraphrase_list", ":", "\n", "            ", "paraphrase_list_cat", "+=", "item", "\n", "", "logits", "=", "self", ".", "_classifier", ".", "predict_log_dist_batch", "(", "origin", ",", "paraphrase_list_cat", ",", "data_record", ")", "\n", "\n", "p", "=", "0", "\n", "logits_reformat", "=", "[", "]", "\n", "for", "item", "in", "paraphrase_list", ":", "\n", "            ", "logits_reformat", ".", "append", "(", "logits", "[", "p", ":", "p", "+", "len", "(", "item", ")", "]", ")", "\n", "p", "+=", "len", "(", "item", ")", "\n", "", "assert", "p", "==", "len", "(", "logits", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "item", "in", "logits_reformat", ":", "\n", "            ", "ret", ".", "append", "(", "self", ".", "_agg_fn", "(", "item", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier._predict_log_dist_multiple_examples": [[62, 92], ["input_manipulation_classifier.InputManipulationClassifier._input_manipulation", "enumerate", "input_manipulation_classifier.InputManipulationClassifier._classifier.predict_log_dist_multiple_examples", "numpy.asarray", "logits_reformat.append", "len", "len", "ret.append", "input_manipulation_classifier.InputManipulationClassifier._agg_fn", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.classifier_base.ClassifierBase.predict_log_dist_multiple_examples"], ["", "def", "_predict_log_dist_multiple_examples", "(", "self", ",", "origin_list", ",", "paraphrase_list", ",", "\n", "data_record_list", "=", "None", ")", ":", "\n", "        ", "paraphrase_list", "=", "self", ".", "_input_manipulation", "(", "\n", "paraphrase_list", ",", "data_record_list", "if", "data_record_list", "is", "not", "None", "else", "None", ")", "\n", "\n", "paraphrase_list_cat", "=", "[", "]", "\n", "origin_list_cat", "=", "[", "]", "\n", "data_record_list_cat", "=", "[", "]", "\n", "for", "idx", ",", "item", "in", "enumerate", "(", "paraphrase_list", ")", ":", "\n", "            ", "paraphrase_list_cat", "+=", "item", "\n", "if", "origin_list", "is", "not", "None", ":", "\n", "                ", "origin_list_cat", "+=", "[", "origin_list", "[", "idx", "]", "]", "*", "len", "(", "item", ")", "\n", "", "if", "data_record_list", "is", "not", "None", ":", "\n", "                ", "data_record_list_cat", "+=", "[", "data_record_list_cat", "[", "idx", "]", "]", "*", "len", "(", "item", ")", "\n", "", "", "logits", "=", "self", ".", "_classifier", ".", "predict_log_dist_multiple_examples", "(", "\n", "None", "if", "origin_list", "is", "None", "else", "origin_list_cat", ",", "\n", "paraphrase_list_cat", ",", "\n", "None", "if", "data_record_list", "is", "None", "else", "data_record_list_cat", ")", "\n", "\n", "p", "=", "0", "\n", "logits_reformat", "=", "[", "]", "\n", "for", "item", "in", "paraphrase_list", ":", "\n", "            ", "logits_reformat", ".", "append", "(", "logits", "[", "p", ":", "p", "+", "len", "(", "item", ")", "]", ")", "\n", "p", "+=", "len", "(", "item", ")", "\n", "", "assert", "p", "==", "len", "(", "logits", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "item", "in", "logits_reformat", ":", "\n", "            ", "ret", ".", "append", "(", "self", ".", "_agg_fn", "(", "item", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_init": [[93, 95], ["None"], "methods", ["None"], ["", "def", "robust_tune_init", "(", "self", ",", "optimizer", ",", "lr", ",", "weight_decay", ",", "steps", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_step": [[96, 98], ["None"], "methods", ["None"], ["", "def", "robust_tune_step", "(", "self", ",", "data_record_list", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.load_robust_tuned_model": [[99, 101], ["None"], "methods", ["None"], ["", "def", "load_robust_tuned_model", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.save_robust_tuned_model": [[102, 104], ["None"], "methods", ["None"], ["", "def", "save_robust_tuned_model", "(", "self", ",", "load_path", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.hard_agg": [[7, 12], ["numpy.zeros", "numpy.argmax", "scipy.special.log_softmax"], "function", ["None"], ["def", "hard_agg", "(", "x", ")", ":", "\n", "    ", "ret", "=", "np", ".", "zeros", "(", "x", ".", "shape", "[", "1", "]", ")", "\n", "for", "idx", "in", "np", ".", "argmax", "(", "x", ",", "axis", "=", "1", ")", ":", "\n", "        ", "ret", "[", "idx", "]", "+=", "1", "\n", "", "return", "scipy_log_softmax", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.soft_agg": [[14, 16], ["scipy.special.log_softmax", "numpy.mean"], "function", ["None"], ["", "def", "soft_agg", "(", "x", ")", ":", "\n", "    ", "return", "scipy_log_softmax", "(", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.__init__": [[13, 94], ["torch.Module.__init__", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained", "shield_classifier.BertClassifierDARTS.bert_layer.get_input_embeddings", "torch.Dropout", "torch.Dropout", "torch.Dropout", "shield_classifier.BertClassifierDARTS.bert_layer.modules", "shield_classifier.BertClassifierDARTS.to", "fibber.resources.get_transformers", "fibber.resources.get_transformers", "shield_classifier.BertClassifierDARTS.bert_layer.parameters", "isinstance", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.ones().to().float", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "module.weight.data.clone", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "module.weight.size", "shield_classifier.BertClassifierDARTS.embedding_weight.size", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "range", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers", "home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_transformers"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model_type", ",", "\n", "output_dim", "=", "2", ",", "\n", "freeze_bert", "=", "True", ",", "\n", "ensemble", "=", "0", ",", "\n", "N", "=", "5", ",", "\n", "inference", "=", "False", ",", "\n", "is_training", "=", "True", ",", "\n", "temperature", "=", "1.0", ",", "\n", "gumbel", "=", "0", ",", "\n", "scaler", "=", "0", ",", "\n", "darts", "=", "True", ",", "\n", "device", "=", "'cpu'", ")", ":", "\n", "\n", "        ", "super", "(", "BertClassifierDARTS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "model_type", "\n", "self", ".", "scaler", "=", "scaler", "\n", "self", ".", "gumbel", "=", "gumbel", "\n", "self", ".", "embedding_matrix", "=", "[", "]", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_type", ")", ")", "\n", "self", ".", "bert_layer", "=", "AutoModel", ".", "from_pretrained", "(", "resources", ".", "get_transformers", "(", "model_type", ")", ")", "\n", "\n", "if", "freeze_bert", ":", "\n", "            ", "for", "p", "in", "self", ".", "bert_layer", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Classification layer", "\n", "", "", "self", ".", "feature_dim", "=", "768", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "ensemble", "=", "ensemble", "\n", "self", ".", "N", "=", "N", "\n", "self", ".", "inference", "=", "inference", "\n", "self", ".", "flg_training", "=", "is_training", "\n", "self", ".", "emb1", "=", "None", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "embedding", "=", "self", ".", "bert_layer", ".", "get_input_embeddings", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "L", "=", "3", "\n", "self", ".", "sample_wise_training", "=", "True", "\n", "self", ".", "darts", "=", "darts", "\n", "\n", "def", "forward_hook", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "            ", "self", ".", "emb1", "=", "output", "\n", "\n", "", "for", "module", "in", "self", ".", "bert_layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "                ", "if", "module", ".", "weight", ".", "size", "(", ")", "[", "0", "]", ">=", "30000", ":", "\n", "                    ", "self", ".", "embedding_weight", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "self", ".", "embedding_dim", "=", "self", ".", "embedding_weight", ".", "size", "(", ")", "[", "1", "]", "\n", "\n", "", "", "", "if", "self", ".", "ensemble", ":", "\n", "            ", "if", "self", ".", "darts", ":", "\n", "                ", "self", ".", "heads", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "feature_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "feature_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "feature_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ")", ")", ",", "\n", "]", ")", "for", "i", "in", "range", "(", "self", ".", "N", ")", "\n", "]", ")", "\n", "\n", "self", ".", "darts_decision", "=", "nn", ".", "ParameterList", "(", "[", "\n", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "L", ")", ")", "for", "i", "in", "range", "(", "self", ".", "N", ")", "\n", "]", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "heads", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ")", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "N", ")", "]", ")", "\n", "\n", "", "self", ".", "switch", "=", "nn", ".", "Linear", "(", "self", ".", "N", "*", "self", ".", "output_dim", "+", "self", ".", "feature_dim", ",", "self", ".", "N", ")", "\n", "self", ".", "probs", "=", "torch", ".", "ones", "(", "self", ".", "N", ")", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "feature2main", "=", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ")", "\n", "\n", "", "self", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.select_head_gumbel_single": [[95, 104], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "shield_classifier.BertClassifierDARTS.switch().sum", "torch.softmax", "torch.softmax", "torch.softmax", "shield_classifier.BertClassifierDARTS.switch", "shield_classifier.BertClassifierDARTS.add_gumbel"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.add_gumbel"], ["", "def", "select_head_gumbel_single", "(", "self", ",", "base_pred", ",", "pred_heads", ")", ":", "\n", "        ", "pred_heads", "=", "torch", ".", "cat", "(", "(", "pred_heads", ",", "base_pred", ")", ",", "1", ")", "\n", "gumbel_t", "=", "self", ".", "switch", "(", "pred_heads", ")", ".", "sum", "(", "0", ")", "# [N]", "\n", "\n", "if", "self", ".", "gumbel", ">", "0", ":", "\n", "            ", "self", ".", "probs", "=", "F", ".", "softmax", "(", "self", ".", "add_gumbel", "(", "gumbel_t", ")", "*", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "gumbel_t", "=", "gumbel_t", "*", "self", ".", "probs", "\n", "\n", "", "return", "gumbel_t", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.select_head_gumbel": [[105, 116], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "shield_classifier.BertClassifierDARTS.select_head_gumbel_single", "all_gumbel_t.append", "shield_classifier.BertClassifierDARTS.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.select_head_gumbel_single"], ["", "def", "select_head_gumbel", "(", "self", ",", "base_pred", ",", "pred_heads", ")", ":", "\n", "        ", "pred_heads", "=", "torch", ".", "cat", "(", "pred_heads", ",", "1", ")", "# batch size * (N * num_class)", "\n", "all_gumbel_t", "=", "[", "]", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "pred_heads", ")", ")", ":", "\n", "            ", "gumbel_t_single", "=", "self", ".", "select_head_gumbel_single", "(", "base_pred", "[", "j", ":", "j", "+", "1", "]", ",", "\n", "pred_heads", "[", "j", ":", "j", "+", "1", "]", ")", "\n", "all_gumbel_t", ".", "append", "(", "gumbel_t_single", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "gumbel_t", "=", "torch", ".", "cat", "(", "all_gumbel_t", ",", "0", ")", "\n", "\n", "return", "gumbel_t", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.forward_from_embedding": [[117, 157], ["shield_classifier.BertClassifierDARTS.bert_layer", "torch.mean.view", "torch.mean.view", "torch.mean.view", "shield_classifier.BertClassifierDARTS.dropout", "range", "shield_classifier.BertClassifierDARTS.select_head_gumbel", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "shield_classifier.BertClassifierDARTS.feature2main", "len", "torch.mean.view", "torch.mean.view", "torch.mean.view", "shield_classifier.BertClassifierDARTS.pred_heads.append", "shield_classifier.BertClassifierDARTS.pred_heads.append", "torch.softmax", "torch.softmax", "torch.softmax", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softmax", "torch.softmax", "torch.softmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "range", "shield_classifier.BertClassifierDARTS.random_key[].unsqueeze", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.select_head_gumbel"], ["", "def", "forward_from_embedding", "(", "self", ",", "emb", ",", "attn_masks", ")", ":", "\n", "        ", "cont_reps", "=", "self", ".", "bert_layer", "(", "inputs_embeds", "=", "emb", ",", "attention_mask", "=", "attn_masks", ")", "\n", "pred", "=", "cont_reps", ".", "last_hidden_state", "[", ":", ",", "0", "]", "\n", "\n", "pred", "=", "self", ".", "dropout", "(", "pred", ")", "if", "not", "self", ".", "inference", "else", "pred", "\n", "pred", "=", "pred", ".", "view", "(", "-", "1", ",", "self", ".", "feature_dim", ")", "\n", "\n", "if", "self", ".", "ensemble", ">", "0", ":", "\n", "            ", "self", ".", "pred_heads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "heads", ")", ")", ":", "\n", "                ", "layer", "=", "self", ".", "heads", "[", "i", "]", "\n", "if", "self", ".", "darts", ":", "\n", "                    ", "if", "not", "self", ".", "inference", ":", "\n", "                        ", "controls", "=", "F", ".", "softmax", "(", "self", ".", "darts_decision", "[", "i", "]", ",", "dim", "=", "-", "1", ")", "\n", "scores", "=", "[", "(", "layer", "[", "j", "]", "(", "pred", ")", "*", "controls", "[", "j", "]", ")", ".", "unsqueeze", "(", "0", ")", "for", "j", "in", "\n", "range", "(", "len", "(", "layer", ")", ")", "]", "\n", "scores", "=", "torch", ".", "mean", "(", "torch", ".", "cat", "(", "scores", ",", "0", ")", ",", "0", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "controls", "=", "F", ".", "softmax", "(", "self", ".", "darts_decision", "[", "i", "]", ",", "dim", "=", "-", "1", ")", "\n", "idx", "=", "torch", ".", "argmax", "(", "controls", ")", "\n", "scores", "=", "layer", "[", "idx", "]", "(", "pred", ")", "\n", "\n", "", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "output_dim", ")", "\n", "self", ".", "pred_heads", ".", "append", "(", "scores", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "self", ".", "pred_heads", ".", "append", "(", "layer", "[", "0", "]", "(", "pred", ")", ")", "\n", "\n", "", "", "self", ".", "random_key", "=", "self", ".", "select_head_gumbel", "(", "pred", ",", "self", ".", "pred_heads", ")", "\n", "pred", "=", "torch", ".", "cat", "(", "\n", "[", "(", "self", ".", "pred_heads", "[", "i", "]", "*", "self", ".", "random_key", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ")", ".", "unsqueeze", "(", "1", ")", "for", "i", "in", "\n", "range", "(", "len", "(", "self", ".", "pred_heads", ")", ")", "]", ",", "1", ")", "\n", "pred", "=", "torch", ".", "mean", "(", "pred", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "key1", "=", "self", ".", "feature2main", "(", "pred", ")", "\n", "pred", "=", "key1", "\n", "\n", "", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.forward": [[158, 161], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "shield_classifier.BertClassifierDARTS.embedding", "shield_classifier.BertClassifierDARTS.forward_from_embedding"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.forward_from_embedding"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "emb1", "=", "Variable", "(", "self", ".", "embedding", "(", "input_ids", ")", ",", "requires_grad", "=", "True", ")", "\n", "return", "[", "self", ".", "forward_from_embedding", "(", "self", ".", "emb1", ",", "attention_mask", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.add_gumbel": [[162, 170], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "u.to.to.to", "u.to.to.uniform_", "o_t.size", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "add_gumbel", "(", "self", ",", "o_t", ",", "eps", "=", "1e-10", ")", ":", "\n", "        ", "u", "=", "torch", ".", "zeros", "(", "o_t", ".", "size", "(", ")", ")", "\n", "u", "=", "u", ".", "to", "(", "self", ".", "device", ")", "\n", "u", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "g_t", "=", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "u", "+", "eps", ")", "+", "eps", ")", "\n", "gumbel_t", "=", "o_t", "+", "g_t", "\n", "\n", "return", "gumbel_t", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.shield_classifier.BertClassifierDARTS.init_linear": [[171, 175], ["shield_classifier.BertClassifierDARTS.named_parameters", "len", "math.sqrt"], "methods", ["None"], ["", "def", "init_linear", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'heads.'", "in", "name", "and", "param", ".", "requires_grad", "and", "len", "(", "param", ".", "shape", ")", ">", "0", ":", "\n", "                ", "1", "/", "math", ".", "sqrt", "(", "param", ".", "shape", "[", "0", "]", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_style_transfer.Benchmark.__init__": [[31, 128], ["os.makedirs", "fibber.datasets.clip_sentence", "fibber.datasets.clip_sentence", "fibber.metrics.metric_utils.MetricBundle", "fibber.metrics.attack_aggregation_utils.add_sentence_level_adversarial_attack_metrics", "fibber.datasets.get_dataset", "fibber.datasets.verify_dataset", "fibber.datasets.verify_dataset", "fibber.datasets.subsample_dataset", "benchmark_style_transfer.Benchmark._metric_bundle.add_classifier", "benchmark_style_transfer.Benchmark._metric_bundle.set_target_classifier_by_name", "logger.error", "str", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.clip_sentence", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.clip_sentence", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.add_sentence_level_adversarial_attack_metrics", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.subsample_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.set_target_classifier_by_name"], ["def", "__init__", "(", "self", ",", "\n", "output_dir", ",", "dataset_name", ",", "\n", "trainset", "=", "None", ",", "testset", "=", "None", ",", "attack_set", "=", "None", ",", "\n", "subsample_attack_set", "=", "0", ",", "\n", "subsample_offset", "=", "0", ",", "\n", "customized_clf", "=", "None", ",", "\n", "enable_bert_clf", "=", "True", ",", "\n", "use_gpu_id", "=", "-", "1", ",", "\n", "gpt2_gpu_id", "=", "-", "1", ",", "\n", "bert_gpu_id", "=", "-", "1", ",", "\n", "bert_ppl_gpu_id", "=", "-", "1", ",", "\n", "ce_gpu_id", "=", "-", "1", ",", "\n", "bert_clf_steps", "=", "20000", ",", "\n", "bert_clf_bs", "=", "32", ")", ":", "\n", "        ", "\"\"\"Initialize Benchmark framework.\n\n        Args:\n            output_dir (str): the directory to write outputs including model, sentences, metrics\n                and log.\n            dataset_name (str): the name of the dataset.\n            trainset (dict): the training set. If the ``dataset_name`` matches built-in datasets,\n                ``trainset`` should be None.\n            testset (dict): the test set. If the ``dataset_name`` matches built-in datasets,\n                ``testset`` should be None.\n            attack_set (dict or None): the set to run adversarial attack. Use None to attack the\n                ``testset``.\n            subsample_attack_set (int): subsample the attack set. 0 to use the whole attack set.\n            customized_clf (MetricBase): an classifier object.\n            enable_bert_clf (bool): whether to enable bert classifier in metrics. You can disable\n                it when you are attacking your own classifier.\n            use_gpu_id (int): the gpu to run universal sentence encoder to compute metrics.\n                -1 for CPU.\n            gpt2_gpu_id (int): the gpu to run the GPT2-medium language model to compute metrics.\n                -1 for CPU.\n            bert_gpu_id (int): the gpu to run the BERT text classifier, which is the model being\n                attacked. -1 for CPU.\n            bert_clf_steps (int): number of steps to train the BERT text classifier.\n            bert_clf_bs (int): the batch size to train the BERT classifier.\n        \"\"\"", "\n", "# make output dir", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "\n", "# setup dataset", "\n", "if", "dataset_name", "in", "builtin_datasets", ":", "\n", "            ", "if", "trainset", "is", "not", "None", "or", "testset", "is", "not", "None", ":", "\n", "                ", "logger", ".", "error", "(", "(", "\"dataset name %d conflict with builtin dataset. \"", "\n", "\"set trainset and testset to None.\"", ")", "%", "dataset_name", ")", "\n", "raise", "RuntimeError", "\n", "", "trainset", ",", "testset", "=", "get_dataset", "(", "dataset_name", ")", "\n", "", "else", ":", "\n", "            ", "verify_dataset", "(", "trainset", ")", "\n", "verify_dataset", "(", "testset", ")", "\n", "\n", "", "model_init", "=", "\"bert-base-cased\"", "\n", "clip_sentence", "(", "trainset", ",", "model_init", ",", "max_len", "=", "128", ")", "\n", "clip_sentence", "(", "testset", ",", "model_init", ",", "max_len", "=", "128", ")", "\n", "\n", "if", "attack_set", "is", "None", ":", "\n", "            ", "attack_set", "=", "testset", "\n", "\n", "", "if", "subsample_attack_set", "!=", "0", ":", "\n", "            ", "attack_set", "=", "subsample_dataset", "(", "attack_set", ",", "subsample_attack_set", ",", "subsample_offset", ")", "\n", "\n", "", "self", ".", "_trainset", "=", "trainset", "\n", "self", ".", "_testset", "=", "testset", "\n", "self", ".", "_attack_set", "=", "attack_set", "\n", "\n", "# setup metric bundle", "\n", "self", ".", "_metric_bundle", "=", "MetricBundle", "(", "\n", "enable_transformer_classifier", "=", "enable_bert_clf", ",", "\n", "use_gpu_id", "=", "use_gpu_id", ",", "gpt2_gpu_id", "=", "gpt2_gpu_id", ",", "\n", "bert_gpu_id", "=", "bert_gpu_id", ",", "bert_ppl_gpu_id", "=", "bert_ppl_gpu_id", ",", "\n", "dataset_name", "=", "dataset_name", ",", "trainset", "=", "self", ".", "_trainset", ",", "testset", "=", "testset", ",", "\n", "bert_clf_steps", "=", "bert_clf_steps", ",", "\n", "bert_clf_bs", "=", "bert_clf_bs", ",", "\n", "ce_gpu_id", "=", "ce_gpu_id", ",", "\n", "enable_ce_similarity", "=", "False", ",", "\n", "enable_glove_similarity", "=", "False", ",", "\n", "enable_self_bleu", "=", "True", ",", "\n", "enable_ref_bleu", "=", "True", ",", "\n", "enable_bert_perplexity_per_class", "=", "True", ",", "\n", "enable_fasttext_classifier", "=", "False", ",", "\n", "enable_gpt2_perplexity", "=", "False", ",", "\n", "target_clf", "=", "\"bert\"", "\n", ")", "\n", "\n", "if", "customized_clf", ":", "\n", "            ", "self", ".", "_metric_bundle", ".", "add_classifier", "(", "str", "(", "customized_clf", ")", ",", "customized_clf", ")", "\n", "self", ".", "_metric_bundle", ".", "set_target_classifier_by_name", "(", "str", "(", "customized_clf", ")", ")", "\n", "\n", "", "add_sentence_level_adversarial_attack_metrics", "(", "\n", "self", ".", "_metric_bundle", ",", "\n", "clf_agg_type", "=", "\"avg\"", ",", "\n", "best_adv_metric_name", "=", "None", ",", "\n", "best_adv_metric_lower_better", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_style_transfer.Benchmark.run_benchmark": [[129, 204], ["isinstance", "fibber.log.add_file_handler", "fibber.log.remove_logger_tf_handler", "paraphrase_strategy.fit", "os.path.join", "logger.info", "paraphrase_strategy.paraphrase_dataset", "os.path.join", "logger.info", "benchmark_style_transfer.Benchmark._metric_bundle.measure_dataset", "enumerate", "isinstance", "os.path.join", "copy.deepcopy", "suffix.upper.upper.upper", "benchmark_style_transfer.Benchmark._metric_bundle.aggregate_metrics", "fibber.benchmark.benchmark_utils.update_detailed_result", "datetime.datetime.now().strftime", "len", "str", "str", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.add_file_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.measure_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.aggregate_metrics", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_detailed_result"], ["", "def", "run_benchmark", "(", "self", ",", "\n", "paraphrase_strategy", "=", "\"IdentityStrategy\"", ",", "\n", "strategy_gpu_id", "=", "-", "1", ",", "\n", "num_paraphrases_per_text", "=", "50", ",", "\n", "exp_name", "=", "None", ",", "\n", "update_global_results", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run the benchmark.\n\n        Args:\n            paraphrase_strategy (str or StrategyBase): the paraphrase strategy to benchmark.\n                Either the name of a builtin strategy or a customized strategy derived from\n                StrategyBase.\n            strategy_gpu_id (int): the gpu id to run the strategy. -1 for CPU. Ignored when\n                ``paraphrase_strategy`` is an object.\n            num_paraphrases_per_text (int): number of paraphrases for each sentence.\n            exp_name (str or None): the name of current experiment. None for default name. the\n                default name is ``<dataset_name>-<strategy_name>-<date>-<time>``.\n            update_global_results (bool): whether to write results in <fibber_root_dir> or the\n                benchmark output dir.\n\n        Returns:\n            A dict of evaluation results.\n        \"\"\"", "\n", "# setup strategy", "\n", "if", "isinstance", "(", "paraphrase_strategy", ",", "str", ")", ":", "\n", "            ", "if", "paraphrase_strategy", "in", "built_in_paraphrase_strategies", ":", "\n", "                ", "paraphrase_strategy", "=", "built_in_paraphrase_strategies", "[", "paraphrase_strategy", "]", "(", "\n", "{", "}", ",", "self", ".", "_dataset_name", ",", "strategy_gpu_id", ",", "self", ".", "_output_dir", ",", "self", ".", "_metric_bundle", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "paraphrase_strategy", ",", "StrategyBase", ")", "\n", "\n", "# get experiment name", "\n", "", "if", "exp_name", "is", "None", ":", "\n", "            ", "exp_name", "=", "(", "self", ".", "_dataset_name", "+", "\"-\"", "+", "str", "(", "paraphrase_strategy", ")", "+", "\"-\"", "\n", "+", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m%d-%H%M%S-%f\"", ")", ")", "\n", "\n", "", "log", ".", "add_file_handler", "(", "\n", "logger", ",", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"%s.log\"", "%", "exp_name", ")", ")", "\n", "log", ".", "remove_logger_tf_handler", "(", "logger", ")", "\n", "\n", "paraphrase_strategy", ".", "fit", "(", "self", ".", "_trainset", ")", "\n", "tmp_output_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "exp_name", "+", "\"-tmp.json\"", ")", "\n", "logger", ".", "info", "(", "\"Write paraphrase temporary results in %s.\"", ",", "tmp_output_filename", ")", "\n", "results", "=", "paraphrase_strategy", ".", "paraphrase_dataset", "(", "\n", "self", ".", "_attack_set", ",", "num_paraphrases_per_text", ",", "tmp_output_filename", ")", "\n", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "exp_name", "+", "\"-with-metric.json\"", ")", "\n", "logger", ".", "info", "(", "\"Write paraphrase with metrics in %s.\"", ",", "tmp_output_filename", ")", "\n", "\n", "results", "=", "self", ".", "_metric_bundle", ".", "measure_dataset", "(", "\n", "results", "=", "results", ",", "output_filename", "=", "output_filename", ")", "\n", "\n", "for", "label_idx", ",", "label_name", "in", "enumerate", "(", "results", "[", "\"label_mapping\"", "]", ")", ":", "\n", "            ", "sub_results", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "sub_results", "[", "\"data\"", "]", "=", "[", "data_record", "for", "data_record", "in", "sub_results", "[", "\"data\"", "]", "\n", "if", "data_record", "[", "\"label\"", "]", "==", "label_idx", "]", "\n", "\n", "assert", "len", "(", "results", "[", "\"label_mapping\"", "]", ")", "==", "2", "\n", "if", "label_idx", "==", "0", ":", "\n", "                ", "suffix", "=", "\"-%s2%s\"", "%", "(", "results", "[", "\"label_mapping\"", "]", "[", "0", "]", "[", "0", "]", ",", "\n", "results", "[", "\"label_mapping\"", "]", "[", "1", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "suffix", "=", "\"-%s2%s\"", "%", "(", "results", "[", "\"label_mapping\"", "]", "[", "1", "]", "[", "0", "]", ",", "\n", "results", "[", "\"label_mapping\"", "]", "[", "0", "]", "[", "0", "]", ")", "\n", "", "suffix", "=", "suffix", ".", "upper", "(", ")", "\n", "\n", "aggregated_result", "=", "self", ".", "_metric_bundle", ".", "aggregate_metrics", "(", "\n", "self", ".", "_dataset_name", "+", "suffix", ",", "str", "(", "paraphrase_strategy", ")", ",", "exp_name", ",", "sub_results", ")", "\n", "\n", "update_detailed_result", "(", "aggregated_result", ",", "\n", "self", ".", "_output_dir", "if", "not", "update_global_results", "else", "None", ")", "\n", "\n", "", "return", "aggregated_result", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_style_transfer.Benchmark.get_metric_bundle": [[205, 207], ["None"], "methods", ["None"], ["", "def", "get_metric_bundle", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_metric_bundle", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_style_transfer.get_strategy": [[209, 214], ["None"], "function", ["None"], ["", "", "def", "get_strategy", "(", "arg_dict", ",", "dataset_name", ",", "strategy_name", ",", "strategy_gpu_id", ",", "\n", "output_dir", ",", "metric_bundle", ")", ":", "\n", "    ", "\"\"\"Take the strategy name and construct a strategy object.\"\"\"", "\n", "return", "built_in_paraphrase_strategies", "[", "strategy_name", "]", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_style_transfer.main": [[216, 262], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "built_in_paraphrase_strategies.values", "vars", "benchmark_style_transfer.Benchmark", "fibber.log.remove_logger_tf_handler", "benchmark_style_transfer.get_strategy", "benchmark_style_transfer.Benchmark.run_benchmark", "item.add_parser_args", "argparse.ArgumentParser.parse_args", "benchmark_style_transfer.Benchmark.get_metric_bundle"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.get_strategy", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.add_parser_args", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# add experiment args", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"ag\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_paraphrases\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--subsample_testset\"", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "\"--subsample_offset\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy\"", ",", "type", "=", "str", ",", "default", "=", "\"CheatStrategy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "\n", "# metric args", "\n", "parser", ".", "add_argument", "(", "\"--gpt2_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--transformer_clf_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_ppl_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_clf_steps\"", ",", "type", "=", "int", ",", "default", "=", "20000", ")", "\n", "parser", ".", "add_argument", "(", "\"--ce_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "\n", "# add builtin strategies' args to parser.", "\n", "for", "item", "in", "built_in_paraphrase_strategies", ".", "values", "(", ")", ":", "\n", "        ", "item", ".", "add_parser_args", "(", "parser", ")", "\n", "\n", "", "arg_dict", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "assert", "arg_dict", "[", "\"output_dir\"", "]", "is", "not", "None", "\n", "\n", "benchmark", "=", "Benchmark", "(", "arg_dict", "[", "\"output_dir\"", "]", ",", "arg_dict", "[", "\"dataset\"", "]", ",", "\n", "subsample_attack_set", "=", "arg_dict", "[", "\"subsample_testset\"", "]", ",", "\n", "subsample_offset", "=", "arg_dict", "[", "\"subsample_offset\"", "]", ",", "\n", "use_gpu_id", "=", "arg_dict", "[", "\"use_gpu_id\"", "]", ",", "\n", "bert_gpu_id", "=", "arg_dict", "[", "\"transformer_clf_gpu_id\"", "]", ",", "\n", "bert_ppl_gpu_id", "=", "arg_dict", "[", "\"bert_ppl_gpu_id\"", "]", ",", "\n", "gpt2_gpu_id", "=", "arg_dict", "[", "\"gpt2_gpu_id\"", "]", ",", "\n", "bert_clf_steps", "=", "arg_dict", "[", "\"bert_clf_steps\"", "]", ",", "\n", "ce_gpu_id", "=", "arg_dict", "[", "\"ce_gpu_id\"", "]", ",", ")", "\n", "\n", "log", ".", "remove_logger_tf_handler", "(", "logger", ")", "\n", "\n", "# Get paraphrase strategy", "\n", "paraphrase_strategy", "=", "get_strategy", "(", "arg_dict", ",", "arg_dict", "[", "\"dataset\"", "]", ",", "arg_dict", "[", "\"strategy\"", "]", ",", "\n", "arg_dict", "[", "\"strategy_gpu_id\"", "]", ",", "arg_dict", "[", "\"output_dir\"", "]", ",", "\n", "benchmark", ".", "get_metric_bundle", "(", ")", ")", "\n", "\n", "benchmark", ".", "run_benchmark", "(", "paraphrase_strategy", "=", "paraphrase_strategy", ",", "\n", "num_paraphrases_per_text", "=", "arg_dict", "[", "\"max_paraphrases\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.make_overview.make_overview": [[10, 51], ["fibber.benchmark.benchmark_utils.load_detailed_result", "fibber.benchmark.benchmark_utils.load_detailed_result.groupby", "fibber.benchmark.benchmark_utils.load_detailed_result.columns.tolist", "fibber.benchmark.benchmark_utils.load_detailed_result.iterrows", "fibber.benchmark.benchmark_utils.load_detailed_result.groupby", "fibber.benchmark.benchmark_utils.update_overview_result", "col_name.endswith", "col_name.endswith", "group.iterrows", "pandas.DataFrame", "len", "col_for_num_win.append", "col_for_num_win.append", "dict", "group.iterrows", "list", "results.values"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.load_detailed_result", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_overview_result"], ["def", "make_overview", "(", ")", ":", "\n", "    ", "\"\"\"Generate overview table from detailed table.\"\"\"", "\n", "detailed_df", "=", "load_detailed_result", "(", ")", "\n", "\n", "# verify detailed result", "\n", "for", "group_info", ",", "item", "in", "detailed_df", ".", "groupby", "(", "[", "DATASET_NAME_COL", ",", "STRATEGY_NAME_COL", "]", ")", ":", "\n", "        ", "assert", "len", "(", "item", ")", "==", "1", ",", "(", "\n", "\"Detailed results contains multiple runs for %s on %s.\"", "%", "(", "\n", "group_info", "[", "1", "]", ",", "group_info", "[", "0", "]", ")", ")", "\n", "\n", "", "col_for_num_win", "=", "[", "]", "\n", "\n", "for", "col_name", "in", "detailed_df", ".", "columns", ".", "tolist", "(", ")", ":", "\n", "        ", "if", "col_name", ".", "endswith", "(", "DIRECTION_HIGHER_BETTER", ")", ":", "\n", "            ", "col_for_num_win", ".", "append", "(", "(", "col_name", ",", "DIRECTION_HIGHER_BETTER", ")", ")", "\n", "", "if", "col_name", ".", "endswith", "(", "DIRECTION_LOWER_BETTER", ")", ":", "\n", "            ", "col_for_num_win", ".", "append", "(", "(", "col_name", ",", "DIRECTION_LOWER_BETTER", ")", ")", "\n", "\n", "", "", "results", "=", "{", "}", "\n", "for", "rid", ",", "item", "in", "detailed_df", ".", "iterrows", "(", ")", ":", "\n", "        ", "if", "item", "[", "STRATEGY_NAME_COL", "]", "not", "in", "results", ":", "\n", "            ", "model_name", "=", "item", "[", "STRATEGY_NAME_COL", "]", "\n", "tmp", "=", "dict", "(", ")", "\n", "\n", "tmp", "[", "STRATEGY_NAME_COL", "]", "=", "item", "[", "STRATEGY_NAME_COL", "]", "\n", "for", "col_name", ",", "_", "in", "col_for_num_win", ":", "\n", "                ", "tmp", "[", "col_name", "]", "=", "0", "\n", "\n", "", "results", "[", "model_name", "]", "=", "tmp", "\n", "\n", "", "", "for", "group_name", ",", "group", "in", "detailed_df", ".", "groupby", "(", "DATASET_NAME_COL", ")", ":", "\n", "        ", "for", "_", ",", "r1", "in", "group", ".", "iterrows", "(", ")", ":", "\n", "            ", "for", "_", ",", "r2", "in", "group", ".", "iterrows", "(", ")", ":", "\n", "                ", "for", "column_name", ",", "direction", "in", "col_for_num_win", ":", "\n", "                    ", "if", "(", "(", "direction", "==", "DIRECTION_HIGHER_BETTER", "\n", "and", "r1", "[", "column_name", "]", ">", "r2", "[", "column_name", "]", ")", "\n", "or", "(", "direction", "==", "DIRECTION_LOWER_BETTER", "\n", "and", "r1", "[", "column_name", "]", "<", "r2", "[", "column_name", "]", ")", ")", ":", "\n", "                        ", "results", "[", "r1", "[", "STRATEGY_NAME_COL", "]", "]", "[", "column_name", "]", "+=", "1", "\n", "\n", "", "", "", "", "", "update_overview_result", "(", "pd", ".", "DataFrame", "(", "list", "(", "results", ".", "values", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.__init__": [[50, 170], ["os.makedirs", "fibber.datasets.clip_sentence", "fibber.datasets.clip_sentence", "fibber.metrics.metric_utils.MetricBundle", "fibber.metrics.attack_aggregation_utils.add_sentence_level_adversarial_attack_metrics", "fibber.datasets.get_dataset", "fibber.datasets.verify_dataset", "fibber.datasets.verify_dataset", "fibber.datasets.subsample_dataset", "benchmark_adversarial_attack.Benchmark._metric_bundle.add_classifier", "isinstance", "RuntimeError", "logger.error", "RuntimeError", "RuntimeError", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.clip_sentence", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.clip_sentence", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.attack_aggregation_utils.add_sentence_level_adversarial_attack_metrics", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.get_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.verify_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.subsample_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.add_classifier"], ["def", "__init__", "(", "self", ",", "\n", "output_dir", ",", "dataset_name", ",", "\n", "trainset", "=", "None", ",", "testset", "=", "None", ",", "attack_set", "=", "None", ",", "\n", "subsample_attack_set", "=", "0", ",", "\n", "customized_clf", "=", "None", ",", "\n", "enable_transformer_clf", "=", "True", ",", "\n", "enable_fasttext_classifier", "=", "False", ",", "\n", "use_gpu_id", "=", "-", "1", ",", "\n", "bert_ppl_gpu_id", "=", "-", "1", ",", "\n", "transformer_clf_gpu_id", "=", "-", "1", ",", "\n", "transformer_clf_steps", "=", "20000", ",", "\n", "transformer_clf_bs", "=", "32", ",", "\n", "best_adv_metric_name", "=", "\"USESimilarityMetric\"", ",", "\n", "best_adv_metric_lower_better", "=", "False", ",", "\n", "target_classifier", "=", "\"transformer\"", ",", "\n", "transformer_clf_model_init", "=", "\"bert-base-cased\"", ",", "\n", "field", "=", "\"text0\"", ")", ":", "\n", "        ", "\"\"\"Initialize Benchmark framework.\n\n        Args:\n            output_dir (str): the directory to write outputs including model, sentences, metrics\n                and log.\n            dataset_name (str): the name of the dataset.\n            trainset (dict): the training set. If the ``dataset_name`` matches built-in datasets,\n                ``trainset`` should be None.\n            testset (dict): the test set. If the ``dataset_name`` matches built-in datasets,\n                ``testset`` should be None.\n            attack_set (dict or None): the set to run adversarial attack. Use None to attack the\n                ``testset``.\n            subsample_attack_set (int): subsample the attack set. 0 to use the whole attack set.\n            customized_clf (ClassifierBase): an classifier object.\n            enable_transformer_clf (bool): whether to enable transformer classifier in metrics.\n            enable_fasttext_classifier (bool): whether to enable fasttext classifier in metrics.\n            use_gpu_id (int): the gpu to run universal sentence encoder to compute metrics.\n                -1 for CPU.\n            bert_ppl_gpu_id (int): the gpu to run the BERT language model for perplexity.\n                -1 for CPU.\n            transformer_clf_gpu_id (int): the gpu to run the BERT text classifier, which is the\n                model being attacked. -1 for CPU.\n            transformer_clf_steps (int): number of steps to train the BERT text classifier.\n            transformer_clf_bs (int): the batch size to train the BERT classifier.\n            best_adv_metric_name (str): the metric name to identify the best adversarial example\n                if the paraphrase strategy outputs multiple options.\n            best_adv_metric_lower_better (bool): whether the metric is lower better.\n            target_classifier (str): the victim classifier. Choose from [\"transformer\",\n                \"fasttext\", \"customized\"].\n            transformer_clf_model_init (str): the backbone pretrained language model, e.g.,\n                `bert-base-cased`.\n            field (str): attack text field.\n        \"\"\"", "\n", "# make output dir", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_defense_desc", "=", "None", "\n", "self", ".", "_field", "=", "field", "\n", "\n", "# verify correct target classifier", "\n", "if", "target_classifier", "==", "\"customized\"", ":", "\n", "            ", "if", "not", "isinstance", "(", "customized_clf", ",", "ClassifierBase", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"customized_clf is not an instance of ClassifierBase\"", ")", "\n", "", "", "elif", "target_classifier", "==", "\"transformer\"", ":", "\n", "            ", "if", "not", "enable_transformer_clf", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"target classifier is not enabled.\"", ")", "\n", "", "", "elif", "target_classifier", "==", "\"fasttext\"", ":", "\n", "            ", "if", "not", "enable_fasttext_classifier", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"target classifier is not enabled.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Unknown target classifier.\"", ")", "\n", "\n", "# setup dataset", "\n", "", "if", "dataset_name", "in", "builtin_datasets", ":", "\n", "            ", "if", "trainset", "is", "not", "None", "or", "testset", "is", "not", "None", ":", "\n", "                ", "logger", ".", "error", "(", "(", "\"dataset name %d conflict with builtin dataset. \"", "\n", "\"set trainset and testset to None.\"", ")", "%", "dataset_name", ")", "\n", "raise", "RuntimeError", "\n", "", "trainset", ",", "testset", "=", "get_dataset", "(", "dataset_name", ")", "\n", "", "else", ":", "\n", "            ", "verify_dataset", "(", "trainset", ")", "\n", "verify_dataset", "(", "testset", ")", "\n", "\n", "", "clip_sentence", "(", "trainset", ",", "transformer_clf_model_init", ",", "max_len", "=", "128", ")", "\n", "clip_sentence", "(", "testset", ",", "transformer_clf_model_init", ",", "max_len", "=", "128", ")", "\n", "\n", "if", "attack_set", "is", "None", ":", "\n", "            ", "attack_set", "=", "testset", "\n", "\n", "", "if", "subsample_attack_set", "!=", "0", ":", "\n", "            ", "attack_set", "=", "subsample_dataset", "(", "attack_set", ",", "subsample_attack_set", ")", "\n", "\n", "", "self", ".", "_trainset", "=", "trainset", "\n", "self", ".", "_testset", "=", "testset", "\n", "self", ".", "_attack_set", "=", "attack_set", "\n", "\n", "# setup metric bundle", "\n", "self", ".", "_metric_bundle", "=", "MetricBundle", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "trainset", "=", "trainset", ",", "testset", "=", "testset", ",", "\n", "enable_transformer_classifier", "=", "enable_transformer_clf", ",", "\n", "transformer_clf_gpu_id", "=", "transformer_clf_gpu_id", ",", "\n", "transformer_clf_model_init", "=", "transformer_clf_model_init", ",", "\n", "transformer_clf_steps", "=", "transformer_clf_steps", ",", "\n", "transformer_clf_bs", "=", "transformer_clf_bs", ",", "\n", "enable_fasttext_classifier", "=", "enable_fasttext_classifier", ",", "\n", "target_clf", "=", "target_classifier", ",", "\n", "enable_use_similarity", "=", "True", ",", "use_gpu_id", "=", "use_gpu_id", ",", "\n", "enable_bert_perplexity", "=", "True", ",", "bert_ppl_gpu_id", "=", "bert_ppl_gpu_id", ",", "\n", "enable_ce_similarity", "=", "False", ",", "\n", "enable_gpt2_perplexity", "=", "False", ",", "\n", "enable_glove_similarity", "=", "False", ",", "\n", "field", "=", "field", "\n", ")", "\n", "\n", "if", "customized_clf", ":", "\n", "            ", "self", ".", "_metric_bundle", ".", "add_classifier", "(", "customized_clf", ",", "True", ")", "\n", "\n", "", "add_sentence_level_adversarial_attack_metrics", "(", "\n", "self", ".", "_metric_bundle", ",", "\n", "best_adv_metric_name", "=", "best_adv_metric_name", ",", "\n", "best_adv_metric_lower_better", "=", "best_adv_metric_lower_better", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark": [[171, 239], ["isinstance", "fibber.log.add_file_handler", "fibber.log.remove_logger_tf_handler", "paraphrase_strategy.fit", "os.path.join", "logger.info", "paraphrase_strategy.paraphrase_dataset", "os.path.join", "logger.info", "benchmark_adversarial_attack.Benchmark._metric_bundle.measure_dataset", "benchmark_adversarial_attack.Benchmark._metric_bundle.aggregate_metrics", "isinstance", "os.path.join", "str", "fibber.benchmark.benchmark_utils.update_detailed_result", "fibber.benchmark.benchmark_utils.update_attack_robust_result", "datetime.datetime.now().strftime", "str", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.add_file_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.measure_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.aggregate_metrics", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_detailed_result", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_attack_robust_result"], ["", "def", "run_benchmark", "(", "self", ",", "\n", "paraphrase_strategy", "=", "\"IdentityStrategy\"", ",", "\n", "strategy_gpu_id", "=", "-", "1", ",", "\n", "max_paraphrases", "=", "50", ",", "\n", "exp_name", "=", "None", ",", "\n", "update_global_results", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run the benchmark.\n\n        Args:\n            paraphrase_strategy (str or StrategyBase): the paraphrase strategy to benchmark.\n                Either the name of a builtin strategy or a customized strategy derived from\n                StrategyBase.\n            strategy_gpu_id (int): the gpu id to run the strategy. -1 for CPU. Ignored when\n                ``paraphrase_strategy`` is an object.\n            max_paraphrases (int): number of paraphrases for each sentence.\n            exp_name (str or None): the name of current experiment. None for default name. the\n                default name is ``<dataset_name>-<strategy_name>-<date>-<time>``.\n            update_global_results (bool): whether to write results in <fibber_root_dir> or the\n                benchmark output dir.\n\n        Returns:\n            A dict of evaluation results.\n        \"\"\"", "\n", "# setup strategy", "\n", "if", "isinstance", "(", "paraphrase_strategy", ",", "str", ")", ":", "\n", "            ", "if", "paraphrase_strategy", "in", "built_in_paraphrase_strategies", ":", "\n", "                ", "paraphrase_strategy", "=", "built_in_paraphrase_strategies", "[", "paraphrase_strategy", "]", "(", "\n", "{", "}", ",", "self", ".", "_dataset_name", ",", "strategy_gpu_id", ",", "self", ".", "_output_dir", ",", "self", ".", "_metric_bundle", ",", "\n", "field", "=", "self", ".", "_field", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "paraphrase_strategy", ",", "StrategyBase", ")", "\n", "\n", "# get experiment name", "\n", "", "if", "exp_name", "is", "None", ":", "\n", "            ", "exp_name", "=", "(", "self", ".", "_dataset_name", "+", "\"-\"", "+", "str", "(", "paraphrase_strategy", ")", "+", "\"-\"", "\n", "+", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m%d-%H%M%S%f\"", ")", ")", "\n", "\n", "", "log", ".", "add_file_handler", "(", "\n", "logger", ",", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"%s.log\"", "%", "exp_name", ")", ")", "\n", "log", ".", "remove_logger_tf_handler", "(", "logger", ")", "\n", "\n", "paraphrase_strategy", ".", "fit", "(", "self", ".", "_trainset", ")", "\n", "tmp_output_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "exp_name", "+", "\"-tmp.json\"", ")", "\n", "logger", ".", "info", "(", "\"Write paraphrase temporary results in %s.\"", ",", "tmp_output_filename", ")", "\n", "results", "=", "paraphrase_strategy", ".", "paraphrase_dataset", "(", "\n", "self", ".", "_attack_set", ",", "max_paraphrases", ",", "tmp_output_filename", ")", "\n", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_output_dir", ",", "exp_name", "+", "\"-with-metric.json\"", ")", "\n", "logger", ".", "info", "(", "\"Write paraphrase with metrics in %s.\"", ",", "tmp_output_filename", ")", "\n", "\n", "results", "=", "self", ".", "_metric_bundle", ".", "measure_dataset", "(", "\n", "results", "=", "results", ",", "output_filename", "=", "output_filename", ")", "\n", "\n", "aggregated_result", "=", "self", ".", "_metric_bundle", ".", "aggregate_metrics", "(", "\n", "self", ".", "_dataset_name", ",", "str", "(", "paraphrase_strategy", ")", ",", "exp_name", ",", "results", ")", "\n", "\n", "if", "self", ".", "_defense_desc", "is", "None", ":", "\n", "            ", "update_detailed_result", "(", "aggregated_result", ",", "\n", "self", ".", "_output_dir", "if", "not", "update_global_results", "else", "None", ")", "\n", "", "else", ":", "\n", "            ", "update_attack_robust_result", "(", "aggregated_result", ",", "\n", "self", ".", "_defense_desc", ",", "\n", "0", ",", "\n", "self", ".", "_output_dir", "if", "not", "update_global_results", "else", "None", ")", "\n", "\n", "", "return", "aggregated_result", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle": [[240, 242], ["None"], "methods", ["None"], ["", "def", "get_metric_bundle", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_metric_bundle", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.fit_defense": [[243, 246], ["paraphrase_strategy.fit", "defense_strategy.fit"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit"], ["", "def", "fit_defense", "(", "self", ",", "paraphrase_strategy", ",", "defense_strategy", ")", ":", "\n", "        ", "paraphrase_strategy", ".", "fit", "(", "self", ".", "_trainset", ")", "\n", "defense_strategy", ".", "fit", "(", "self", ".", "_trainset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.load_defense": [[247, 250], ["defense_strategy.load", "benchmark_adversarial_attack.Benchmark._metric_bundle.replace_target_classifier"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.replace_target_classifier"], ["", "def", "load_defense", "(", "self", ",", "defense_strategy", ")", ":", "\n", "        ", "clf", "=", "defense_strategy", ".", "load", "(", "self", ".", "_trainset", ")", "\n", "self", ".", "_metric_bundle", ".", "replace_target_classifier", "(", "clf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.get_strategy": [[252, 257], ["None"], "function", ["None"], ["", "", "def", "get_strategy", "(", "arg_dict", ",", "dataset_name", ",", "strategy_name", ",", "strategy_gpu_id", ",", "\n", "output_dir", ",", "metric_bundle", ",", "field", ")", ":", "\n", "    ", "\"\"\"Take the strategy name and construct a strategy object.\"\"\"", "\n", "return", "built_in_paraphrase_strategies", "[", "strategy_name", "]", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "output_dir", ",", "metric_bundle", ",", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.get_defense_strategy": [[259, 265], ["None"], "function", ["None"], ["", "def", "get_defense_strategy", "(", "arg_dict", ",", "dataset_name", ",", "strategy_name", ",", "strategy_gpu_id", ",", "\n", "defense_desc", ",", "metric_bundle", ",", "attack_strategy", ",", "field", ")", ":", "\n", "    ", "\"\"\"Take the strategy name and construct a strategy object.\"\"\"", "\n", "return", "built_in_defense_strategies", "[", "strategy_name", "]", "(", "\n", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "defense_desc", ",", "metric_bundle", ",", "\n", "attack_strategy", ",", "field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.main": [[267, 359], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "built_in_paraphrase_strategies.values", "built_in_defense_strategies.values", "vars", "torch.manual_seed", "numpy.random.seed", "benchmark_adversarial_attack.Benchmark", "fibber.log.remove_logger_tf_handler", "benchmark_adversarial_attack.get_strategy", "item.add_parser_args", "item.add_parser_args", "argparse.ArgumentParser.parse_args", "benchmark_adversarial_attack.Benchmark.get_metric_bundle", "benchmark_adversarial_attack.get_defense_strategy", "benchmark_adversarial_attack.Benchmark.fit_defense", "list", "benchmark_adversarial_attack.Benchmark.get_metric_bundle", "RuntimeError", "benchmark_adversarial_attack.Benchmark.run_benchmark", "RuntimeError", "list", "built_in_paraphrase_strategies.keys", "benchmark_adversarial_attack.Benchmark.load_defense", "built_in_defense_strategies.keys"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.log.remove_logger_tf_handler", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.get_strategy", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.add_parser_args", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.add_parser_args", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.get_defense_strategy", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.fit_defense", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.load_defense"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# target clf", "\n", "parser", ".", "add_argument", "(", "\"--target_classifier\"", ",", "type", "=", "str", ",", "default", "=", "\"bert\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--transformer_clf_model_init\"", ",", "type", "=", "str", ",", "default", "=", "\"bert-base-cased\"", ")", "\n", "\n", "# option on robust defense vs attack", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "choices", "=", "[", "\"defense\"", ",", "\"attack\"", "]", ",", "default", "=", "\"attack\"", ",", "\n", "help", "=", "\"Choose from defending the classifier vs. attack the classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--defense_strategy\"", ",", "\n", "choices", "=", "[", "\"none\"", "]", "+", "list", "(", "built_in_defense_strategies", ".", "keys", "(", ")", ")", ",", "\n", "default", "=", "\"none\"", ",", "help", "=", "\"use `none` to disable defense. \"", ")", "\n", "parser", ".", "add_argument", "(", "\"--defense_desc\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"A name to recognize this defense setup. \"", ")", "\n", "\n", "# add experiment args", "\n", "parser", ".", "add_argument", "(", "\"--exp_name\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"ag\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--field\"", ",", "type", "=", "str", ",", "default", "=", "\"text0\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_paraphrases\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--subsample_testset\"", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy\"", ",", "choices", "=", "list", "(", "built_in_paraphrase_strategies", ".", "keys", "(", ")", ")", ",", "\n", "default", "=", "\"RandomStrategy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ")", "\n", "\n", "# metric args", "\n", "parser", ".", "add_argument", "(", "\"--bert_ppl_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--transformer_clf_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_gpu_id\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--transformer_clf_steps\"", ",", "type", "=", "int", ",", "default", "=", "20000", ")", "\n", "parser", ".", "add_argument", "(", "\"--best_adv_metric_name\"", ",", "type", "=", "str", ",", "default", "=", "\"USESimilarityMetric\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--best_adv_lower_better\"", ",", "type", "=", "str", ",", "default", "=", "\"0\"", ")", "\n", "\n", "# add builtin strategies' args to parser.", "\n", "for", "item", "in", "built_in_paraphrase_strategies", ".", "values", "(", ")", ":", "\n", "        ", "item", ".", "add_parser_args", "(", "parser", ")", "\n", "\n", "", "for", "item", "in", "built_in_defense_strategies", ".", "values", "(", ")", ":", "\n", "        ", "item", ".", "add_parser_args", "(", "parser", ")", "\n", "\n", "", "arg_dict", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "assert", "arg_dict", "[", "\"output_dir\"", "]", "is", "not", "None", "\n", "\n", "torch", ".", "manual_seed", "(", "arg_dict", "[", "\"seed\"", "]", ")", "\n", "np", ".", "random", ".", "seed", "(", "arg_dict", "[", "\"seed\"", "]", ")", "\n", "\n", "benchmark", "=", "Benchmark", "(", "\n", "arg_dict", "[", "\"output_dir\"", "]", ",", "arg_dict", "[", "\"dataset\"", "]", ",", "\n", "subsample_attack_set", "=", "arg_dict", "[", "\"subsample_testset\"", "]", ",", "\n", "use_gpu_id", "=", "arg_dict", "[", "\"use_gpu_id\"", "]", ",", "\n", "transformer_clf_gpu_id", "=", "arg_dict", "[", "\"transformer_clf_gpu_id\"", "]", ",", "\n", "bert_ppl_gpu_id", "=", "arg_dict", "[", "\"bert_ppl_gpu_id\"", "]", ",", "\n", "transformer_clf_steps", "=", "arg_dict", "[", "\"transformer_clf_steps\"", "]", ",", "\n", "best_adv_metric_name", "=", "arg_dict", "[", "\"best_adv_metric_name\"", "]", ",", "\n", "best_adv_metric_lower_better", "=", "(", "arg_dict", "[", "\"best_adv_lower_better\"", "]", "==", "\"1\"", ")", ",", "\n", "target_classifier", "=", "arg_dict", "[", "\"target_classifier\"", "]", ",", "\n", "transformer_clf_model_init", "=", "arg_dict", "[", "\"transformer_clf_model_init\"", "]", ",", "\n", "field", "=", "arg_dict", "[", "\"field\"", "]", ")", "\n", "\n", "log", ".", "remove_logger_tf_handler", "(", "logger", ")", "\n", "\n", "# Get paraphrase strategy", "\n", "paraphrase_strategy", "=", "get_strategy", "(", "arg_dict", ",", "arg_dict", "[", "\"dataset\"", "]", ",", "arg_dict", "[", "\"strategy\"", "]", ",", "\n", "arg_dict", "[", "\"strategy_gpu_id\"", "]", ",", "arg_dict", "[", "\"output_dir\"", "]", ",", "\n", "benchmark", ".", "get_metric_bundle", "(", ")", ",", "field", "=", "arg_dict", "[", "\"field\"", "]", ")", "\n", "\n", "if", "arg_dict", "[", "\"defense_strategy\"", "]", "!=", "\"none\"", ":", "\n", "        ", "defense_strategy", "=", "get_defense_strategy", "(", "\n", "arg_dict", ",", "arg_dict", "[", "\"dataset\"", "]", ",", "arg_dict", "[", "\"defense_strategy\"", "]", ",", "\n", "arg_dict", "[", "\"strategy_gpu_id\"", "]", ",", "arg_dict", "[", "\"defense_desc\"", "]", ",", "benchmark", ".", "get_metric_bundle", "(", ")", ",", "\n", "attack_strategy", "=", "paraphrase_strategy", ",", "field", "=", "arg_dict", "[", "\"field\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "defense_strategy", "=", "None", "\n", "\n", "", "if", "arg_dict", "[", "\"task\"", "]", "==", "\"defense\"", ":", "\n", "        ", "if", "defense_strategy", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Defense strategy is None.\"", ")", "\n", "", "benchmark", ".", "fit_defense", "(", "paraphrase_strategy", "=", "paraphrase_strategy", ",", "\n", "defense_strategy", "=", "defense_strategy", ")", "\n", "\n", "", "elif", "arg_dict", "[", "\"task\"", "]", "==", "\"attack\"", ":", "\n", "        ", "if", "defense_strategy", "is", "not", "None", ":", "\n", "            ", "benchmark", ".", "load_defense", "(", "defense_strategy", "=", "defense_strategy", ")", "\n", "\n", "", "benchmark", ".", "run_benchmark", "(", "paraphrase_strategy", "=", "paraphrase_strategy", ",", "\n", "max_paraphrases", "=", "arg_dict", "[", "\"max_paraphrases\"", "]", ",", "\n", "exp_name", "=", "arg_dict", "[", "\"exp_name\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Unknown task.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.reorder_columns": [[8, 30], ["sorted", "sorted", "sorted", "list", "list", "column.startswith", "list"], "function", ["None"], ["def", "reorder_columns", "(", "results", ")", ":", "\n", "    ", "\"\"\"Reorder columns in the result table.\n\n    Args:\n        results (DataFrame): a result table\n    Returns:\n        DataFrame\n    \"\"\"", "\n", "columns", "=", "[", "\"dataset_name\"", ",", "\"paraphrase_strategy_name\"", ",", "\"experiment_name\"", "]", "\n", "if", "\"robust_tuned_clf_desc\"", "in", "results", ".", "columns", ":", "\n", "        ", "columns", "+=", "[", "\"robust_tuned_clf_desc\"", ",", "\"robust_tuning_steps\"", "]", "\n", "\n", "", "accuracy_columns", "=", "[", "column", "for", "column", "in", "list", "(", "results", ".", "columns", ")", "if", "\"Accuracy\"", "in", "column", "]", "\n", "columns", "+=", "sorted", "(", "accuracy_columns", ")", "\n", "\n", "adv_columns", "=", "[", "column", "for", "column", "in", "list", "(", "results", ".", "columns", ")", "if", "column", ".", "startswith", "(", "\"best_adv\"", ")", "]", "\n", "columns", "+=", "sorted", "(", "adv_columns", ")", "\n", "\n", "other_columns", "=", "[", "column", "for", "column", "in", "list", "(", "results", ".", "columns", ")", "if", "column", "not", "in", "columns", "]", "\n", "columns", "+=", "sorted", "(", "other_columns", ")", "\n", "\n", "return", "results", "[", "columns", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_detailed_result": [[32, 53], ["os.makedirs", "os.path.join", "os.path.exists", "pd.DataFrame.append", "benchmark_utils.reorder_columns", "pd.DataFrame.to_csv", "os.path.join", "pandas.read_csv", "pandas.DataFrame", "fibber.get_root_dir"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.reorder_columns", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["", "def", "update_detailed_result", "(", "aggregated_result", ",", "result_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Read dataset detailed results and add a row to the file. Create a new file if the table\n    does not exist.\n\n    Args:\n        aggregated_result (dict): the aggregated result as a dict.\n        result_dir (str or None): the directory to save results. If None, use\n            ``<fibber_root_dir>/results/``.\n    \"\"\"", "\n", "if", "result_dir", "is", "None", ":", "\n", "        ", "result_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"results\"", ")", "\n", "", "os", ".", "makedirs", "(", "result_dir", ",", "exist_ok", "=", "True", ")", "\n", "result_filename", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"detail.csv\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "result_filename", ")", ":", "\n", "        ", "results", "=", "pd", ".", "read_csv", "(", "result_filename", ")", "\n", "", "else", ":", "\n", "        ", "results", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "", "results", "=", "results", ".", "append", "(", "aggregated_result", ",", "ignore_index", "=", "True", ")", "\n", "results", "=", "reorder_columns", "(", "results", ")", "\n", "results", ".", "to_csv", "(", "result_filename", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_attack_robust_result": [[55, 81], ["os.makedirs", "os.path.join", "os.path.exists", "pd.DataFrame.append", "benchmark_utils.reorder_columns", "pd.DataFrame.to_csv", "os.path.join", "pandas.read_csv", "pandas.DataFrame", "fibber.get_root_dir"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.reorder_columns", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["", "def", "update_attack_robust_result", "(", "aggregated_result", ",", "robust_tuned_clf_desc", ",", "\n", "robust_tuning_steps", ",", "result_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Read results of attacking robust classifiers, and add a row to the file.\n    Create a new file if the table does not exist.\n\n    Args:\n        aggregated_result (dict): the aggregated result as a dict.\n        robust_tuned_clf_desc (str): the robust tuning description.\n        robust_tuning_steps (int): the number of robust tuning steps.\n        result_dir (str or None): the directory to save results. If None, use\n            ``<fibber_root_dir>/results/``.\n    \"\"\"", "\n", "if", "result_dir", "is", "None", ":", "\n", "        ", "result_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"results\"", ")", "\n", "", "os", ".", "makedirs", "(", "result_dir", ",", "exist_ok", "=", "True", ")", "\n", "result_filename", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"robust_detail.csv\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "result_filename", ")", ":", "\n", "        ", "results", "=", "pd", ".", "read_csv", "(", "result_filename", ")", "\n", "", "else", ":", "\n", "        ", "results", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "", "aggregated_result", "[", "\"robust_tuned_clf_desc\"", "]", "=", "robust_tuned_clf_desc", "\n", "aggregated_result", "[", "\"robust_tuning_steps\"", "]", "=", "robust_tuning_steps", "\n", "results", "=", "results", ".", "append", "(", "aggregated_result", ",", "ignore_index", "=", "True", ")", "\n", "results", "=", "reorder_columns", "(", "results", ")", "\n", "results", ".", "to_csv", "(", "result_filename", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.load_detailed_result": [[83, 96], ["os.path.join", "os.path.join", "os.path.exists", "fibber.get_root_dir", "pandas.read_csv", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["", "def", "load_detailed_result", "(", ")", ":", "\n", "    ", "\"\"\"Read detailed results from file.\n\n    Returns:\n        (pandas.DataFrame): the detailed result table. Returns an empty DataFrame if file does not\n        exist.\n    \"\"\"", "\n", "result_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"results\"", ")", "\n", "result_filename", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"detail.csv\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "result_filename", ")", ":", "\n", "        ", "return", "pd", ".", "read_csv", "(", "result_filename", ")", "\n", "", "else", ":", "\n", "        ", "return", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_utils.update_overview_result": [[98, 108], ["os.path.join", "os.makedirs", "os.path.join", "overview_result.to_csv", "fibber.get_root_dir"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["", "", "def", "update_overview_result", "(", "overview_result", ")", ":", "\n", "    ", "\"\"\"write overview result to file.\n\n    Args:\n        overview_result (pandas.DataFrame): the overview result.\n    \"\"\"", "\n", "result_dir", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "\"results\"", ")", "\n", "os", ".", "makedirs", "(", "result_dir", ",", "exist_ok", "=", "True", ")", "\n", "result_filename", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"overview.csv\"", ")", "\n", "overview_result", ".", "to_csv", "(", "result_filename", ",", "index", "=", "None", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.lmag_strategy.LMAgStrategy.fit": [[100, 104], ["fibber.metrics.bert_lm_utils.get_lm", "lmag_strategy.LMAgStrategy._lm.eval().to", "lmag_strategy.LMAgStrategy._lm.eval"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.bert_lm_utils.get_lm"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_tokenizer", ",", "self", ".", "_lm", "=", "get_lm", "(", "\"finetune\"", ",", "self", ".", "_dataset_name", ",", "trainset", ",", "self", ".", "_device", ")", "\n", "self", ".", "_lm", "=", "self", ".", "_lm", ".", "eval", "(", ")", ".", "to", "(", "self", ".", "_device", ")", "\n", "self", ".", "_lmag_repeat", "=", "self", ".", "_strategy_config", "[", "\"reps\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.lmag_strategy.LMAgStrategy.load": [[105, 115], ["lmag_strategy.LMAgStrategy.fit", "fibber.metrics.classifier.input_manipulation_classifier.InputManipulationClassifier", "functools.partial", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit"], ["", "def", "load", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "fit", "(", "trainset", ")", "\n", "return", "InputManipulationClassifier", "(", "\n", "self", ".", "_classifier", ",", "\n", "partial", "(", "lmag_fix_sentences", ",", "tokenizer", "=", "self", ".", "_tokenizer", ",", "lm", "=", "self", ".", "_lm", ",", "\n", "clf", "=", "self", ".", "_classifier", ".", "_model", ",", "device", "=", "self", ".", "_classifier", ".", "_device", ",", "\n", "rep", "=", "self", ".", "_lmag_repeat", ")", ",", "\n", "str", "(", "self", ".", "_classifier", ")", ",", "\n", "field", "=", "self", ".", "_classifier", ".", "_field", ",", "\n", "bs", "=", "self", ".", "_classifier", ".", "_bs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.lmag_strategy.lmag_fix_sentences": [[12, 91], ["range", "len", "min", "tokenizer", "tokenizer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "clf.bert.embeddings", "embeddings.detach().clone.detach().clone", "torch.sum", "torch.sum", "torch.sum.backward", "embeddings.detach().clone.grad.detach", "torch.sum().cpu().numpy", "torch.sum().cpu().numpy", "numpy.sqrt", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "[].argmax().detach().cpu().numpy", "range", "len", "ret_reformat.append", "len", "ret.append", "torch.tensor.to", "torch.tensor.to", "embeddings.detach().clone.detach", "torch.max", "torch.max", "torch.sum().cpu", "torch.sum().cpu", "max", "numpy.sum", "numpy.random.choice", "[].argmax().detach().cpu", "attention_mask[].sum", "tokenizer.decode", "torch.log_softmax", "attention_mask[].sum", "int", "float", "torch.sum", "torch.sum", "[].argmax().detach", "clf", "[].argmax", "torch.tensor.to", "lm", "torch.tensor.to", "torch.tensor.to", "torch.tensor.to"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer"], ["def", "lmag_fix_sentences", "(", "sentences", ",", "data_record_list", ",", "tokenizer", ",", "lm", ",", "clf", ",", "device", ",", "bs", "=", "50", ",", "rep", "=", "10", ")", ":", "\n", "    ", "assert", "bs", "%", "rep", "==", "0", "\n", "\n", "st", "=", "0", "\n", "ret", "=", "[", "]", "\n", "\n", "sentences_t", "=", "sentences", "\n", "sentences", "=", "[", "]", "\n", "for", "item", "in", "sentences_t", ":", "\n", "        ", "sentences", "+=", "[", "item", "]", "*", "rep", "\n", "\n", "", "while", "st", "<", "len", "(", "sentences", ")", ":", "\n", "        ", "ed", "=", "min", "(", "st", "+", "bs", ",", "len", "(", "sentences", ")", ")", "\n", "batch_input_small", "=", "tokenizer", "(", "sentences_t", "[", "st", "//", "rep", ":", "ed", "//", "rep", "]", ",", "padding", "=", "True", ")", "\n", "batch_input", "=", "tokenizer", "(", "sentences", "[", "st", ":", "ed", "]", ",", "padding", "=", "True", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "batch_input_small", "[", "\"input_ids\"", "]", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "batch_input_small", "[", "\"token_type_ids\"", "]", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "batch_input_small", "[", "\"attention_mask\"", "]", ")", "\n", "\n", "embeddings", "=", "clf", ".", "bert", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", ",", "\n", "token_type_ids", "=", "token_type_ids", ".", "to", "(", "device", ")", "\n", ")", "\n", "\n", "embeddings", "=", "embeddings", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "embeddings", ".", "requires_grad", "=", "True", "\n", "\n", "max_prob", "=", "torch", ".", "sum", "(", "torch", ".", "max", "(", "\n", "F", ".", "log_softmax", "(", "clf", "(", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "device", ")", ",", "\n", "inputs_embeds", "=", "embeddings", "\n", ")", "[", "0", "]", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", "[", "0", "]", ")", "\n", "max_prob", ".", "backward", "(", ")", "\n", "\n", "embeddings_grad", "=", "embeddings", ".", "grad", ".", "detach", "(", ")", "\n", "attention_grad", "=", "torch", ".", "sum", "(", "embeddings_grad", "*", "embeddings_grad", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "attention_grad", "=", "np", ".", "sqrt", "(", "attention_grad", ")", "\n", "del", "embeddings", "\n", "del", "max_prob", "\n", "del", "embeddings_grad", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"input_ids\"", "]", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"token_type_ids\"", "]", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "batch_input", "[", "\"attention_mask\"", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "st", ",", "ed", ")", ":", "\n", "            ", "if", "i", "%", "rep", "==", "0", ":", "\n", "                ", "u", "=", "1", "\n", "v", "=", "attention_mask", "[", "i", "-", "st", "]", ".", "sum", "(", ")", "-", "1", "\n", "\n", "n_mask", "=", "max", "(", "1", ",", "int", "(", "(", "v", "-", "u", ")", "*", "0.2", ")", ")", "\n", "prob", "=", "attention_grad", "[", "(", "i", "-", "st", ")", "//", "rep", ",", "u", ":", "v", "]", "\n", "alpha", "=", "0.6", "\n", "prob", "=", "prob", "**", "float", "(", "alpha", ")", "\n", "prob", "/=", "np", ".", "sum", "(", "prob", ")", "\n", "\n", "", "samples", "=", "u", "+", "np", ".", "random", ".", "choice", "(", "v", "-", "u", ",", "p", "=", "prob", ",", "replace", "=", "False", ",", "size", "=", "n_mask", ")", "\n", "for", "p", "in", "samples", ":", "\n", "                ", "input_ids", "[", "i", "-", "st", ",", "p", "]", "=", "tokenizer", ".", "mask_token_id", "\n", "", "", "pred", "=", "lm", "(", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", ",", "\n", "token_type_ids", "=", "token_type_ids", ".", "to", "(", "device", ")", ",", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "device", ")", "\n", ")", "[", "0", "]", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "st", ",", "ed", ")", ":", "\n", "            ", "u", "=", "1", "\n", "v", "=", "attention_mask", "[", "i", "-", "st", "]", ".", "sum", "(", ")", "-", "1", "\n", "\n", "ret", ".", "append", "(", "tokenizer", ".", "decode", "(", "pred", "[", "i", "-", "st", ",", "u", ":", "v", "]", ",", "skip_special_tokens", "=", "True", ")", ")", "\n", "\n", "", "st", "=", "ed", "\n", "\n", "", "ret_reformat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "rep", ")", ":", "\n", "        ", "ret_reformat", ".", "append", "(", "ret", "[", "i", ":", "i", "+", "rep", "]", ")", "\n", "", "return", "ret_reformat", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.__init__": [[17, 78], ["object.__init__", "dict", "str", "os.path.join", "os.makedirs", "defense_strategy_base.DefenseStrategyBase._metric_bundle.get_target_classifier", "logger.warning", "torch.device", "logger.info", "torch.device", "fibber.get_root_dir", "logger.warning", "str", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_utils.MetricBundle.get_target_classifier", "home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.__init__.get_root_dir"], ["def", "__init__", "(", "self", ",", "arg_dict", ",", "dataset_name", ",", "strategy_gpu_id", ",", "defense_desc", ",", "\n", "metric_bundle", ",", "attack_strategy", ",", "field", ")", ":", "\n", "        ", "\"\"\"Initialize the paraphrase_strategies.\n\n        This function initialize the ``self._strategy_config``, ``self._metric_bundle``,\n        ``self._device``, ``self._defense_desc``, ``self._dataset_name``.\n\n        **You should not overwrite this function.**\n\n        * self._strategy_config (dict): a dictionary that stores the strategy name and all\n          hyperparameter values. The dict is also saved to the results.\n        * self._metric_bundle (MetricBundle): the metrics that will be used to evaluate\n          paraphrases. Strategies can compute metrics during paraphrasing.\n        * self._device (torch.Device): any computation that requires a GPU accelerator should\n          use this device.\n        * self._defense_desc (str): the dir name where the defense will save files.\n        * self._dataset_name (str): the dataset name.\n\n        Args:\n            arg_dict (dict): all args load from command line.\n            dataset_name (str): the name of the dataset.\n            strategy_gpu_id (int): the gpu id to run the strategy.\n            metric_bundle (MetricBundle): a MetricBundle object.\n            attack_strategy (ParaphraseStrategyBase or None): the attack strategy. Used in some\n                defense methods.\n            field (str): the field that perturbation can happen.\n        \"\"\"", "\n", "super", "(", "DefenseStrategyBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# paraphrase_strategies config will be saved to the results.", "\n", "self", ".", "_strategy_config", "=", "dict", "(", ")", "\n", "\n", "for", "p_name", ",", "p_type", ",", "p_default", ",", "p_help", "in", "self", ".", "__hyperparameters__", ":", "\n", "            ", "arg_name", "=", "\"%s_%s\"", "%", "(", "self", ".", "__abbr__", ",", "p_name", ")", "\n", "if", "arg_name", "not", "in", "arg_dict", ":", "\n", "                ", "logger", ".", "warning", "(", "\"%s_%s not found in args.\"", ",", "self", ".", "__abbr__", ",", "p_name", ")", "\n", "p_value", "=", "p_default", "\n", "", "else", ":", "\n", "                ", "p_value", "=", "arg_dict", "[", "arg_name", "]", "\n", "\n", "", "assert", "p_name", "not", "in", "self", ".", "_strategy_config", "\n", "self", ".", "_strategy_config", "[", "p_name", "]", "=", "p_value", "\n", "\n", "", "self", ".", "_strategy_config", "[", "\"strategy_name\"", "]", "=", "str", "(", "self", ")", "\n", "\n", "self", ".", "_metric_bundle", "=", "metric_bundle", "\n", "self", ".", "_attack_strategy", "=", "attack_strategy", "\n", "\n", "if", "strategy_gpu_id", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"%s is running on CPU.\"", "%", "str", "(", "self", ")", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s is running on GPU %d.\"", ",", "str", "(", "self", ")", ",", "strategy_gpu_id", ")", "\n", "self", ".", "_device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "strategy_gpu_id", ")", "\n", "\n", "", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_defense_desc", "=", "defense_desc", "\n", "self", ".", "_defense_save_path", "=", "os", ".", "path", ".", "join", "(", "get_root_dir", "(", ")", ",", "self", ".", "_defense_desc", ",", "dataset_name", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "_defense_save_path", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "_classifier", "=", "self", ".", "_metric_bundle", ".", "get_target_classifier", "(", ")", "\n", "self", ".", "_field", "=", "field", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.add_parser_args": [[79, 92], ["logger.info", "len", "parser.add_argument"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_parser_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"create commandline args for all hyperparameters in ``__hyperparameters__``.\n\n        Args:\n            parser: an arg parser.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"%s has %d args to set from command line.\"", ",", "\n", "cls", ".", "__name__", ",", "len", "(", "cls", ".", "__hyperparameters__", ")", ")", "\n", "\n", "for", "p_name", ",", "p_type", ",", "p_default", ",", "p_help", "in", "cls", ".", "__hyperparameters__", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\"--%s_%s\"", "%", "(", "cls", ".", "__abbr__", ",", "p_name", ")", ",", "type", "=", "p_type", ",", "\n", "default", "=", "p_default", ",", "help", "=", "p_help", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.__repr__": [[93, 95], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.fit": [[96, 103], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "\"\"\"Fit the paraphrase strategy on a training set.\n\n        Args:\n            trainset (dict): a fibber dataset.\n        \"\"\"", "\n", "return", "self", ".", "_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.defense_strategy_base.DefenseStrategyBase.load": [[104, 106], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "return", "self", ".", "_classifier", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__init__": [[20, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "output", "=", "None", "\n", "self", ".", "_enable", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.disable": [[24, 27], ["None"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "self", ".", "_enable", "=", "False", "\n", "self", ".", "output", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.enable": [[28, 30], ["None"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "self", ".", "_enable", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.__call__": [[31, 37], ["output_.retain_grad"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "module", ",", "input_", ",", "output_", ")", ":", "\n", "        ", "if", "self", ".", "_enable", ":", "\n", "            ", "self", ".", "output", "=", "output_", "\n", "output_", ".", "retain_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.SAPDStrategy.fit": [[167, 203], ["isinstance", "list", "sorted", "sapd_strategy.get_adv_long_words", "sapd_strategy.SAPDStrategy._classifier.robust_tune_init", "tqdm.trange", "sapd_strategy.SAPDStrategy._classifier.save_robust_tuned_model", "isinstance", "tokenizer.vocab.items", "list", "sapd_strategy.grad_perturb", "sapd_strategy.SAPDStrategy._classifier.robust_tune_step", "isinstance", "numpy.random.choice", "sapd_strategy.random_perturb", "RuntimeError", "sapd_strategy.random_long_word_perturb", "sapd_strategy.special_word"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.get_adv_long_words", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_init", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.save_robust_tuned_model", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.grad_perturb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_step", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.random_perturb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.random_long_word_perturb", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.special_word"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "steps", "=", "self", ".", "_strategy_config", "[", "\"steps\"", "]", "\n", "bs", "=", "self", ".", "_strategy_config", "[", "\"bs\"", "]", "\n", "\n", "if", "isinstance", "(", "self", ".", "_classifier", ".", "_model", ",", "DistilBertForSequenceClassification", ")", ":", "\n", "            ", "lm_model", "=", "self", ".", "_classifier", ".", "_model", ".", "distilbert", "\n", "", "elif", "isinstance", "(", "self", ".", "_classifier", ".", "_model", ",", "BertForSequenceClassification", ")", ":", "\n", "            ", "lm_model", "=", "self", ".", "_classifier", ".", "_model", ".", "bert", "\n", "", "elif", "isinstance", "(", "self", ".", "_classifier", ".", "_model", ",", "RobertaForSequenceClassification", ")", ":", "\n", "            ", "lm_model", "=", "self", ".", "_classifier", ".", "_model", ".", "roberta", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"unknown victim.\"", ")", "\n", "\n", "", "tokenizer", "=", "self", ".", "_classifier", ".", "_tokenizer", "\n", "vocabulary", "=", "list", "(", "tokenizer", ".", "vocab", ".", "items", "(", ")", ")", "\n", "vocabulary", "=", "sorted", "(", "[", "item", "for", "item", "in", "vocabulary", "if", "not", "special_word", "(", "item", "[", "0", "]", ")", "]", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n", "adv_long_words", "=", "get_adv_long_words", "(", "trainset", ",", "tokenizer", ")", "\n", "\n", "self", ".", "_classifier", ".", "robust_tune_init", "(", "optimizer", "=", "\"adamw\"", ",", "lr", "=", "1e-5", ",", "weight_decay", "=", "0.001", ",", "\n", "steps", "=", "steps", ")", "\n", "for", "i", "in", "tqdm", ".", "trange", "(", "steps", ")", ":", "\n", "            ", "batch", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "trainset", "[", "\"data\"", "]", ",", "bs", "//", "2", ")", ")", "\n", "if", "i", "%", "3", "==", "0", ":", "\n", "                ", "batch", "=", "random_perturb", "(", "batch", ",", "tokenizer", ",", "vocabulary", ",", "self", ".", "_field", ")", "\n", "", "elif", "i", "%", "3", "==", "1", ":", "\n", "                ", "batch", "=", "random_long_word_perturb", "(", "batch", ",", "tokenizer", ",", "adv_long_words", ",", "self", ".", "_field", ")", "\n", "", "batch_perturb", "=", "grad_perturb", "(", "\n", "batch", ",", "tokenizer", ",", "vocabulary", ",", "model", "=", "self", ".", "_classifier", ".", "_model", ",", "\n", "lm_model", "=", "lm_model", ",", "device", "=", "self", ".", "_classifier", ".", "_device", ",", "field", "=", "self", ".", "_field", ")", "\n", "\n", "batch_all", "=", "batch", "+", "batch_perturb", "\n", "self", ".", "_classifier", ".", "robust_tune_step", "(", "batch_all", ")", "\n", "\n", "", "self", ".", "_classifier", ".", "save_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.SAPDStrategy.load": [[204, 207], ["sapd_strategy.SAPDStrategy._classifier.load_robust_tuned_model"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.load_robust_tuned_model"], ["", "def", "load", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_classifier", ".", "load_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "return", "self", ".", "_classifier", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.random_perturb": [[39, 48], ["copy.deepcopy", "range", "len", "tokenizer.tokenize", "numpy.random.randint", "tokenizer.convert_tokens_to_string", "len", "numpy.random.randint", "len"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "", "", "def", "random_perturb", "(", "data_record_list", ",", "tokenizer", ",", "vocabulary", ",", "field", ")", ":", "\n", "    ", "data_record_list", "=", "copy", ".", "deepcopy", "(", "data_record_list", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data_record_list", ")", ")", ":", "\n", "        ", "text", "=", "data_record_list", "[", "i", "]", "[", "field", "]", "\n", "toks", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "pos", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "toks", ")", ")", "\n", "toks", "[", "pos", "]", "=", "vocabulary", "[", "np", ".", "random", ".", "randint", "(", "len", "(", "vocabulary", ")", ")", "]", "[", "0", "]", "\n", "data_record_list", "[", "i", "]", "[", "field", "]", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "toks", ")", "\n", "", "return", "data_record_list", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.random_long_word_perturb": [[50, 63], ["copy.deepcopy", "range", "len", "tokenizer.tokenize", "numpy.random.choice", "numpy.random.randint", "tokenizer.convert_tokens_to_string", "len", "len"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "random_long_word_perturb", "(", "data_record_list", ",", "tokenizer", ",", "adv_long_word", ",", "field", ")", ":", "\n", "    ", "data_record_list", "=", "copy", ".", "deepcopy", "(", "data_record_list", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data_record_list", ")", ")", ":", "\n", "        ", "text", "=", "data_record_list", "[", "i", "]", "[", "field", "]", "\n", "label", "=", "data_record_list", "[", "i", "]", "[", "\"label\"", "]", "\n", "sent_toks", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "wid", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "adv_long_word", "[", "label", "]", ")", ")", "\n", "long_word_toks", "=", "adv_long_word", "[", "label", "]", "[", "wid", "]", "\n", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "sent_toks", ")", ")", "\n", "sent_toks", "=", "sent_toks", "[", ":", "pos", "]", "+", "long_word_toks", "+", "sent_toks", "[", "pos", "+", "1", ":", "]", "\n", "data_record_list", "[", "i", "]", "[", "field", "]", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "sent_toks", ")", "\n", "\n", "", "return", "data_record_list", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.grad_perturb": [[65, 116], ["copy.deepcopy", "len", "tokenizer", "torch.tensor", "sapd_strategy.EmbeddingGradHook", "embedding_layer.register_forward_hook", "model", "EmbeddingGradHook.output.grad.clone", "EmbeddingGradHook.output.clone", "range", "torch.no_grad", "sapd_strategy.EmbeddingGradHook.disable", "embedding_layer", "range", "torch.argsort().detach().cpu().numpy", "tokenizer.decode", "seq.to", "mask.to", "torch.tensor.to", "torch.tensor().to", "torch.einsum", "torch.einsum().unsqueeze", "numpy.random.randint", "len", "len", "torch.argsort().detach().cpu", "torch.tensor", "torch.einsum", "mask.to", "torch.argsort().detach", "torch.sum", "torch.sum", "torch.argsort", "weight.reshape"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fluency.bert_perplexity_metric.BertPerplexityMetric.tokenizer", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.EmbeddingGradHook.disable"], ["", "def", "grad_perturb", "(", "data_record_list", ",", "tokenizer", ",", "vocabulary", ",", "model", ",", "lm_model", ",", "device", ",", "field", ",", "topk", "=", "1", ")", ":", "\n", "    ", "data_record_list", "=", "copy", ".", "deepcopy", "(", "data_record_list", ")", "\n", "n", "=", "len", "(", "data_record_list", ")", "\n", "if", "field", "!=", "\"text0\"", ":", "\n", "        ", "raise", "RuntimeError", "\n", "", "if", "\"text1\"", "in", "data_record_list", "[", "0", "]", ":", "\n", "        ", "raise", "RuntimeError", "\n", "\n", "", "batch_input", "=", "tokenizer", "(", "\n", "[", "item", "[", "\"text0\"", "]", "for", "item", "in", "data_record_list", "]", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "padding", "=", "True", ")", "\n", "seq", "=", "batch_input", "[", "\"input_ids\"", "]", "\n", "mask", "=", "batch_input", "[", "\"attention_mask\"", "]", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "item", "[", "\"label\"", "]", "for", "item", "in", "data_record_list", "]", ")", "\n", "\n", "embedding_layer", "=", "lm_model", ".", "embeddings", ".", "word_embeddings", "\n", "hook", "=", "EmbeddingGradHook", "(", ")", "\n", "embedding_layer", ".", "register_forward_hook", "(", "hook", ")", "\n", "\n", "output", "=", "model", "(", "input_ids", "=", "seq", ".", "to", "(", "device", ")", ",", "attention_mask", "=", "mask", ".", "to", "(", "device", ")", ",", "\n", "labels", "=", "label", ".", "to", "(", "device", ")", ",", "return_dict", "=", "True", ")", "\n", "\n", "(", "-", "output", "[", "\"loss\"", "]", ")", ".", "sum", "(", ")", ".", "backward", "(", ")", "\n", "grad", "=", "hook", ".", "output", ".", "grad", ".", "clone", "(", ")", "# batch * L * d", "\n", "emb_output", "=", "hook", ".", "output", ".", "clone", "(", ")", "# batch * L * d", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "hook", ".", "disable", "(", ")", "\n", "embs_all", "=", "embedding_layer", "(", "torch", ".", "tensor", "(", "[", "item", "[", "1", "]", "for", "item", "in", "vocabulary", "]", ")", ".", "to", "(", "device", ")", ")", "\n", "weight", "=", "(", "torch", ".", "einsum", "(", "\"vd,bld->blv\"", ",", "embs_all", ",", "grad", ")", "\n", "-", "torch", ".", "einsum", "(", "\"bld,bld->bl\"", ",", "grad", ",", "emb_output", ")", ".", "unsqueeze", "(", "2", ")", ")", "\n", "weight", "+=", "(", "INFTY", "*", "(", "1", "-", "mask", ".", "to", "(", "device", ")", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "weight", "[", ":", ",", "0", "]", "=", "INFTY", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "weight", "[", "i", ",", "torch", ".", "sum", "(", "mask", "[", "i", "]", ")", "-", "1", "]", "=", "INFTY", "\n", "", "args", "=", "torch", ".", "argsort", "(", "weight", ".", "reshape", "(", "n", ",", "-", "1", ")", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "if", "topk", "==", "1", ":", "\n", "            ", "rand_pos", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_pos", "=", "np", ".", "random", ".", "randint", "(", "topk", ")", "\n", "", "u", "=", "args", "[", "i", "]", "[", "rand_pos", "]", "//", "len", "(", "vocabulary", ")", "\n", "v", "=", "args", "[", "i", "]", "[", "rand_pos", "]", "%", "len", "(", "vocabulary", ")", "\n", "\n", "tmp", "=", "seq", "[", "i", "]", "\n", "tmp", "[", "u", "]", "=", "vocabulary", "[", "v", "]", "[", "1", "]", "\n", "data_record_list", "[", "i", "]", "[", "field", "]", "=", "tokenizer", ".", "decode", "(", "tmp", "[", "1", ":", "torch", ".", "sum", "(", "mask", "[", "i", "]", ")", "-", "1", "]", ")", "\n", "\n", "", "return", "data_record_list", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.get_adv_long_words": [[118, 147], ["len", "tqdm.tqdm", "range", "nltk.tokenize.word_tokenize", "word_counter.items", "ret.append", "numpy.log", "numpy.log", "sorted", "len", "tokenizer.tokenize", "tok_score.append", "numpy.max", "len"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.textattack_strategy.CLFModel.tokenize"], ["", "def", "get_adv_long_words", "(", "trainset", ",", "tokenizer", ")", ":", "\n", "    ", "word_counter", "=", "{", "}", "\n", "n_label", "=", "len", "(", "trainset", "[", "\"label_mapping\"", "]", ")", "\n", "\n", "for", "item", "in", "tqdm", ".", "tqdm", "(", "trainset", "[", "\"data\"", "]", ")", ":", "\n", "        ", "toks", "=", "word_tokenize", "(", "item", "[", "\"text0\"", "]", ")", "\n", "for", "tok", "in", "toks", ":", "\n", "            ", "if", "len", "(", "tok", ")", ">", "20", ":", "\n", "                ", "continue", "\n", "", "try", ":", "\n", "                ", "word_counter", "[", "tok", "]", "[", "item", "[", "\"label\"", "]", "]", "+=", "1", "\n", "", "except", "KeyError", ":", "\n", "                ", "word_counter", "[", "tok", "]", "=", "[", "0", "]", "*", "n_label", "\n", "\n", "", "", "", "ret", "=", "[", "]", "\n", "for", "label", "in", "range", "(", "n_label", ")", ":", "\n", "        ", "tok_score", "=", "[", "]", "\n", "for", "tok", ",", "cnt", "in", "word_counter", ".", "items", "(", ")", ":", "\n", "            ", "n_current", "=", "np", ".", "log", "(", "cnt", "[", "label", "]", "+", "1", ")", "\n", "n_other", "=", "np", ".", "log", "(", "np", ".", "max", "(", "cnt", ")", "+", "1", ")", "\n", "score", "=", "n_other", "-", "n_current", "\n", "if", "score", ">", "1", ":", "\n", "                ", "tmp", "=", "tokenizer", ".", "tokenize", "(", "tok", ")", "\n", "if", "len", "(", "tmp", ")", ">", "5", ":", "\n", "                    ", "continue", "\n", "", "tok_score", ".", "append", "(", "(", "tmp", ",", "score", ")", ")", "\n", "", "", "tok_score", "=", "sorted", "(", "tok_score", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "[", ":", "2000", "]", "\n", "ret", ".", "append", "(", "[", "k", "for", "k", ",", "v", "in", "tok_score", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sapd_strategy.special_word": [[149, 157], ["len"], "function", ["None"], ["", "def", "special_word", "(", "x", ")", ":", "\n", "    ", "if", "len", "(", "x", ")", "==", "0", ":", "\n", "        ", "return", "True", "\n", "", "if", "x", "[", "0", "]", "==", "\"[\"", "and", "x", "[", "-", "1", "]", "==", "\"]\"", ":", "\n", "        ", "return", "True", "\n", "", "if", "x", "[", "0", "]", "==", "\"<\"", "and", "x", "[", "-", "1", "]", "==", "\">\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.advtrain_strategy.AdvTrainStrategy.fit": [[23, 61], ["int", "advtrain_strategy.AdvTrainStrategy._classifier.robust_tune_init", "range", "advtrain_strategy.AdvTrainStrategy._classifier.save_robust_tuned_model", "fibber.datasets.subsample_dataset", "numpy.random.shuffle", "logger.info", "tqdm.tqdm", "logger.info", "numpy.random.shuffle", "range", "advtrain_strategy.AdvTrainStrategy._attack_strategy.paraphrase_example", "advtrain_strategy.AdvTrainStrategy._classifier.measure_batch", "zip", "tqdm.tqdm.update", "tqdm.tqdm.set_postfix", "len", "advtrain_strategy.AdvTrainStrategy._classifier.robust_tune_step", "len", "len", "min", "copy.deepcopy", "adv_list.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_init", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.save_robust_tuned_model", "home.repos.pwc.inspect_result.DAI-Lab_fibber.datasets.dataset_utils.subsample_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.paraphrase_strategies.strategy_base.StrategyBase.paraphrase_example", "home.repos.pwc.inspect_result.DAI-Lab_fibber.metrics.metric_base.MetricBase.measure_batch", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_step"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "n_epoch", "=", "self", ".", "_strategy_config", "[", "\"epoch\"", "]", "\n", "bs", "=", "self", ".", "_strategy_config", "[", "\"bs\"", "]", "\n", "sample", "=", "self", ".", "_strategy_config", "[", "\"sample\"", "]", "\n", "alpha", "=", "self", ".", "_strategy_config", "[", "\"alpha\"", "]", "\n", "\n", "steps_est", "=", "int", "(", "n_epoch", "*", "min", "(", "sample", ",", "len", "(", "trainset", "[", "\"data\"", "]", ")", ")", "*", "(", "1", "+", "alpha", ")", "/", "bs", ")", "\n", "self", ".", "_classifier", ".", "robust_tune_init", "(", "optimizer", "=", "\"adamw\"", ",", "lr", "=", "1e-5", ",", "weight_decay", "=", "0.001", ",", "\n", "steps", "=", "steps_est", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_epoch", ")", ":", "\n", "            ", "trainset_sampled", "=", "subsample_dataset", "(", "trainset", ",", "sample", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "trainset_sampled", "[", "\"data\"", "]", ")", "\n", "\n", "logger", ".", "info", "(", "\"Constructing adversarial examples.\"", ")", "\n", "adv_list", "=", "[", "]", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "trainset_sampled", "[", "\"data\"", "]", ")", ")", "\n", "for", "item", "in", "trainset_sampled", "[", "\"data\"", "]", ":", "\n", "                ", "paraphrase_list", ",", "_", "=", "self", ".", "_attack_strategy", ".", "paraphrase_example", "(", "item", ",", "16", ")", "\n", "pred_list", "=", "self", ".", "_classifier", ".", "measure_batch", "(", "\n", "item", "[", "self", ".", "_field", "]", ",", "paraphrase_list", ",", "item", ")", "\n", "for", "sent", ",", "pred", "in", "zip", "(", "paraphrase_list", ",", "pred_list", ")", ":", "\n", "                    ", "if", "pred", "!=", "item", "[", "\"label\"", "]", ":", "\n", "                        ", "tmp", "=", "copy", ".", "deepcopy", "(", "item", ")", "\n", "tmp", "[", "self", ".", "_field", "]", "=", "sent", "\n", "adv_list", ".", "append", "(", "tmp", ")", "\n", "", "", "pbar", ".", "update", "(", "1", ")", "\n", "pbar", ".", "set_postfix", "(", "{", "\"advs\"", ":", "len", "(", "adv_list", ")", "}", ")", "\n", "if", "len", "(", "adv_list", ")", ">=", "alpha", "*", "len", "(", "trainset_sampled", "[", "\"data\"", "]", ")", ":", "\n", "                    ", "break", "\n", "", "", "trainset_sampled", "[", "\"data\"", "]", "+=", "adv_list", "\n", "\n", "logger", ".", "info", "(", "\"Training.\"", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "trainset_sampled", "[", "\"data\"", "]", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "len", "(", "trainset_sampled", "[", "\"data\"", "]", ")", ",", "bs", ")", ":", "\n", "                ", "self", ".", "_classifier", ".", "robust_tune_step", "(", "trainset_sampled", "[", "\"data\"", "]", "[", "j", ":", "j", "+", "bs", "]", ")", "\n", "\n", "", "", "self", ".", "_classifier", ".", "save_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.advtrain_strategy.AdvTrainStrategy.load": [[62, 65], ["advtrain_strategy.AdvTrainStrategy._classifier.load_robust_tuned_model"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.load_robust_tuned_model"], ["", "def", "load", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_classifier", ".", "load_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "return", "self", ".", "__classifier", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.fit": [[124, 136], ["sem_strategy.load_or_build_sem_wordmap", "sem_strategy.sem_transform_dataset", "sem_strategy.SEMStrategy._classifier.robust_tune_init", "tqdm.tqdm", "sem_strategy.SEMStrategy._classifier.save_robust_tuned_model", "list", "numpy.random.choice", "sem_strategy.SEMStrategy._classifier.robust_tune_step", "range"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.load_or_build_sem_wordmap", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_transform_dataset", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_init", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.save_robust_tuned_model", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.robust_tune_step"], ["def", "fit", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_sem_wordmap", "=", "load_or_build_sem_wordmap", "(", "\n", "self", ".", "_defense_save_path", ",", "trainset", ",", "field", "=", "self", ".", "_field", ",", "device", "=", "self", ".", "_device", ")", "\n", "trainset_transformed", "=", "sem_transform_dataset", "(", "trainset", ",", "self", ".", "_sem_wordmap", ",", "self", ".", "_field", ")", "\n", "\n", "self", ".", "_classifier", ".", "robust_tune_init", "(", "optimizer", "=", "\"adamw\"", ",", "lr", "=", "1e-5", ",", "weight_decay", "=", "0.001", ",", "\n", "steps", "=", "self", ".", "_strategy_config", "[", "\"steps\"", "]", ")", "\n", "\n", "for", "_", "in", "tqdm", ".", "tqdm", "(", "list", "(", "range", "(", "self", ".", "_strategy_config", "[", "\"steps\"", "]", ")", ")", ")", ":", "\n", "            ", "batch", "=", "np", ".", "random", ".", "choice", "(", "trainset_transformed", "[", "\"data\"", "]", ",", "self", ".", "_strategy_config", "[", "\"bs\"", "]", ")", "\n", "self", ".", "_classifier", ".", "robust_tune_step", "(", "batch", ")", "\n", "", "self", ".", "_classifier", ".", "save_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load": [[137, 145], ["sem_strategy.load_or_build_sem_wordmap", "sem_strategy.SEMStrategy._classifier.load_robust_tuned_model", "fibber.metrics.classifier.input_manipulation_classifier.InputManipulationClassifier", "functools.partial", "str"], "methods", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.load_or_build_sem_wordmap", "home.repos.pwc.inspect_result.DAI-Lab_fibber.classifier.input_manipulation_classifier.InputManipulationClassifier.load_robust_tuned_model"], ["", "def", "load", "(", "self", ",", "trainset", ")", ":", "\n", "        ", "self", ".", "_sem_wordmap", "=", "load_or_build_sem_wordmap", "(", "\n", "self", ".", "_defense_save_path", ",", "trainset", ",", "field", "=", "self", ".", "_field", ",", "device", "=", "self", ".", "_device", ")", "\n", "self", ".", "_classifier", ".", "load_robust_tuned_model", "(", "self", ".", "_defense_save_path", ")", "\n", "return", "InputManipulationClassifier", "(", "\n", "self", ".", "_classifier", ",", "\n", "partial", "(", "sem_fix_sentences", ",", "word_map", "=", "self", ".", "_sem_wordmap", ",", "reformat", "=", "True", ")", ",", "\n", "str", "(", "self", ".", "_classifier", ")", ",", "field", "=", "self", ".", "_classifier", ".", "_field", ",", "bs", "=", "self", ".", "_classifier", ".", "_bs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.load_or_build_sem_wordmap": [[17, 80], ["os.path.join", "os.path.exists", "fibber.resources.resource_utils.get_counter_fitted_vector", "collections.Counter", "sorted", "dict", "torch.tensor().float().to", "tqdm.tqdm", "collections.Counter.update", "list", "torch.sum", "dis_t.detach().cpu().numpy.detach().cpu().numpy", "open", "json.dump", "open", "json.load", "nltk.word_tokenize", "collections.Counter.items", "torch.tensor().float", "numpy.argsort", "sem_strategy.load_or_build_sem_wordmap.find_syns"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.resources.resource_utils.get_counter_fitted_vector", "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.SEMStrategy.load"], ["def", "load_or_build_sem_wordmap", "(", "save_path", ",", "trainset", ",", "field", ",", "device", ",", "kk", "=", "10", ",", "delta", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"Load or build the synonym encoding.\n\n     See Natural Language Adversarial Defense through Synonym Encoding\n     (https://arxiv.org/abs/1909.06723)\n\n     Args:\n         dataset_name (str): name of the dataset.\n         trainset (dict): the training set. (used to compute word frequency.)\n         kk (int): maximum synonym considered for each word.\n         delta (float): threshold for synonym.\n     Returns:\n         (dict): a map from word to encoding.\n     \"\"\"", "\n", "wordmap_filename", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"sem_wordmap_k_%d_delta_%f.json\"", "%", "(", "kk", ",", "delta", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "wordmap_filename", ")", ":", "\n", "        ", "with", "open", "(", "wordmap_filename", ")", "as", "f", ":", "\n", "            ", "word_map", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "word_map", "\n", "\n", "", "emb", "=", "get_counter_fitted_vector", "(", ")", "\n", "freq", "=", "Counter", "(", "emb", "[", "\"id2tok\"", "]", ")", "\n", "\n", "for", "item", "in", "trainset", "[", "\"data\"", "]", ":", "\n", "        ", "freq", ".", "update", "(", "word_tokenize", "(", "item", "[", "field", "]", ".", "lower", "(", ")", ")", ")", "\n", "", "word_by_freq", "=", "sorted", "(", "list", "(", "freq", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "word_by_freq", "=", "[", "item", "for", "item", "in", "word_by_freq", "if", "item", "[", "0", "]", "in", "emb", "[", "\"tok2id\"", "]", "]", "\n", "word_map", "=", "dict", "(", "[", "(", "item", "[", "0", "]", ",", "None", ")", "for", "item", "in", "word_by_freq", "]", ")", "\n", "\n", "emb_table_tensor", "=", "torch", ".", "tensor", "(", "emb", "[", "\"emb_table\"", "]", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "def", "find_syns", "(", "word", ")", ":", "\n", "        ", "word_id", "=", "emb", "[", "\"tok2id\"", "]", "[", "word", "]", "\n", "dis_t", "=", "torch", ".", "sum", "(", "(", "emb_table_tensor", "-", "emb_table_tensor", "[", "word_id", "]", ")", "**", "2", ",", "dim", "=", "1", ")", "\n", "dis_t", "=", "dis_t", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "syn_ids", "=", "np", ".", "argsort", "(", "dis_t", ")", "[", ":", "kk", "]", "\n", "tmp", "=", "kk", "\n", "while", "tmp", ">=", "1", "and", "dis_t", "[", "syn_ids", "[", "tmp", "-", "1", "]", "]", ">", "delta", ":", "\n", "            ", "tmp", "-=", "1", "\n", "", "return", "[", "emb", "[", "\"id2tok\"", "]", "[", "syn_id", "]", "for", "syn_id", "in", "syn_ids", "[", ":", "tmp", "]", "]", "\n", "\n", "", "for", "word", ",", "freq", "in", "word_by_freq", "[", ":", "16", "]", ":", "\n", "        ", "word_map", "[", "word", "]", "=", "word", "\n", "\n", "", "for", "word", ",", "freq", "in", "tqdm", ".", "tqdm", "(", "word_by_freq", ")", ":", "\n", "        ", "if", "word_map", "[", "word", "]", "is", "None", ":", "\n", "            ", "syn_list", "=", "find_syns", "(", "word", ")", "\n", "\n", "for", "syn", "in", "syn_list", ":", "\n", "                ", "if", "word_map", "[", "syn", "]", "is", "not", "None", ":", "\n", "                    ", "word_map", "[", "word", "]", "=", "syn", "\n", "break", "\n", "", "", "if", "word_map", "[", "word", "]", "is", "None", ":", "\n", "                ", "word_map", "[", "word", "]", "=", "word", "\n", "\n", "", "for", "syn", "in", "syn_list", ":", "\n", "                ", "if", "word_map", "[", "syn", "]", "is", "None", ":", "\n", "                    ", "word_map", "[", "syn", "]", "=", "word_map", "[", "word", "]", "\n", "\n", "", "", "", "", "with", "open", "(", "wordmap_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "word_map", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "return", "word_map", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_substitute": [[82, 93], ["tok.lower", "tok.lower", "tok.lower.capitalize", "tok.lower.lower"], "function", ["None"], ["", "def", "sem_substitute", "(", "tok", ",", "word_map", ")", ":", "\n", "    ", "if", "tok", ".", "lower", "(", ")", "not", "in", "word_map", ":", "\n", "        ", "return", "None", "\n", "\n", "", "tmp", "=", "tok", ".", "lower", "(", ")", "\n", "while", "tmp", "!=", "word_map", "[", "tmp", "]", ":", "\n", "        ", "tmp", "=", "word_map", "[", "tmp", ".", "lower", "(", ")", "]", "\n", "", "if", "'A'", "<=", "tok", "[", "0", "]", "<=", "'Z'", ":", "\n", "        ", "return", "tmp", ".", "capitalize", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_fix_sentences": [[95, 106], ["nltk.word_tokenize", "sem_strategy.sem_substitute", "ret.append", "ret.append"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_substitute"], ["", "", "def", "sem_fix_sentences", "(", "sentences", ",", "data_record_list", ",", "word_map", ",", "reformat", "=", "False", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "        ", "toks", "=", "word_tokenize", "(", "sentence", ")", "\n", "toks", "=", "[", "sem_substitute", "(", "tok", ",", "word_map", ")", "for", "tok", "in", "toks", "]", "\n", "toks", "=", "[", "tok", "for", "tok", "in", "toks", "if", "tok", "is", "not", "None", "]", "\n", "if", "reformat", ":", "\n", "            ", "ret", ".", "append", "(", "[", "\" \"", ".", "join", "(", "toks", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "ret", ".", "append", "(", "\" \"", ".", "join", "(", "toks", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_transform_dataset": [[108, 114], ["copy.deepcopy", "sem_strategy.sem_fix_sentences"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.defense_strategies.sem_strategy.sem_fix_sentences"], ["", "def", "sem_transform_dataset", "(", "dataset", ",", "word_map", ",", "field", ",", "deepcopy", "=", "True", ")", ":", "\n", "    ", "if", "deepcopy", ":", "\n", "        ", "dataset", "=", "copy", ".", "deepcopy", "(", "dataset", ")", "\n", "", "for", "item", "in", "dataset", "[", "\"data\"", "]", ":", "\n", "        ", "item", "[", "field", "]", "=", "sem_fix_sentences", "(", "[", "item", "[", "field", "]", "]", ",", "None", ",", "word_map", ")", "[", "0", "]", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.adversarial_attack_launcher.to_command": [[174, 181], ["args.items", "ret.append", "ret.append", "str"], "function", ["None"], ["def", "to_command", "(", "args", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ":", "\n", "        ", "ret", ".", "append", "(", "k", ")", "\n", "ret", ".", "append", "(", "str", "(", "v", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.adversarial_attack_launcher.main": [[183, 227], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "adversarial_attack_launcher.to_command", "adversarial_attack_launcher.to_command", "adversarial_attack_launcher.to_command", "adversarial_attack_launcher.to_command", "adversarial_attack_launcher.to_command", "subprocess.call", "adversarial_attack_launcher.to_command", "list", "list", "list", "list", "GPU_CONFIG.keys", "DATASET_CONFIG.keys", "STRATEGY_CONFIG.keys", "DEFENSE_CONFIG.keys"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "choices", "=", "list", "(", "GPU_CONFIG", ".", "keys", "(", ")", ")", ",", "default", "=", "\"gpu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "list", "(", "DATASET_CONFIG", ".", "keys", "(", ")", ")", ",", "default", "=", "\"movie_review\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy\"", ",", "choices", "=", "list", "(", "STRATEGY_CONFIG", ".", "keys", "(", ")", ")", ",", "default", "=", "\"textfooler\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "choices", "=", "[", "\"attack\"", ",", "\"defense\"", "]", ",", "default", "=", "\"attack\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--defense_strategy\"", ",", "choices", "=", "list", "(", "DEFENSE_CONFIG", ".", "keys", "(", ")", ")", ",", "default", "=", "\"none\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--defense_desc\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--subsample_testset\"", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--exp_name\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "type", "=", "str", ",", "default", "=", "\"bert-base-cased\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "COMMON_CONFIG", "[", "\"--task\"", "]", "=", "args", ".", "task", "\n", "COMMON_CONFIG", "[", "\"--subsample_testset\"", "]", "=", "args", ".", "subsample_testset", "\n", "\n", "dataset", "=", "args", ".", "dataset", "\n", "strategy", "=", "args", ".", "strategy", "\n", "\n", "command", "=", "[", "\"python3\"", ",", "\"-m\"", ",", "\"fibber.benchmark.benchmark_adversarial_attack\"", "]", "\n", "\n", "if", "args", ".", "classifier", "==", "\"fasttext\"", ":", "\n", "        ", "COMMON_CONFIG", "[", "\"--target_classifier\"", "]", "=", "\"fasttest\"", "\n", "", "else", ":", "\n", "        ", "COMMON_CONFIG", "[", "\"--transformer_clf_model_init\"", "]", "=", "args", ".", "classifier", "\n", "\n", "", "if", "args", ".", "exp_name", "is", "not", "None", ":", "\n", "        ", "command", "+=", "[", "\"--exp_name\"", ",", "args", ".", "exp_name", "]", "\n", "\n", "", "command", "+=", "to_command", "(", "COMMON_CONFIG", ")", "\n", "command", "+=", "to_command", "(", "GPU_CONFIG", "[", "args", ".", "gpu", "]", ")", "\n", "command", "+=", "to_command", "(", "DATASET_CONFIG", "[", "dataset", "]", ")", "\n", "command", "+=", "to_command", "(", "DEFENSE_CONFIG", "[", "args", ".", "defense_strategy", "]", ")", "\n", "\n", "if", "args", ".", "defense_strategy", "!=", "\"none\"", ":", "\n", "        ", "assert", "args", ".", "defense_desc", "is", "not", "None", "\n", "command", "+=", "to_command", "(", "{", "\"--defense_desc\"", ":", "args", ".", "defense_desc", "}", ")", "\n", "\n", "", "command", "+=", "to_command", "(", "STRATEGY_CONFIG", "[", "strategy", "]", ")", "\n", "\n", "subprocess", ".", "call", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command": [[73, 80], ["args.items", "ret.append", "ret.append", "str"], "function", ["None"], ["def", "to_command", "(", "args", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ":", "\n", "        ", "ret", ".", "append", "(", "k", ")", "\n", "ret", ".", "append", "(", "str", "(", "v", ")", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.main": [[82, 112], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "list", "list", "list", "DATASET_CONFIG.keys", "STRATEGY_CONFIG.keys", "style_transfer_launcher.to_command", "style_transfer_launcher.to_command", "style_transfer_launcher.to_command", "style_transfer_launcher.to_command", "style_transfer_launcher.to_command", "subprocess.call", "GPU_CONFIG.keys", "list", "list", "DATASET_CONFIG.keys", "STRATEGY_CONFIG.keys"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command", "home.repos.pwc.inspect_result.DAI-Lab_fibber.scripts.style_transfer_launcher.to_command"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "choices", "=", "list", "(", "GPU_CONFIG", ".", "keys", "(", ")", ")", ",", "default", "=", "\"single\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "list", "(", "DATASET_CONFIG", ".", "keys", "(", ")", ")", "+", "[", "\"all\"", "]", ",", "default", "=", "\"all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--strategy\"", ",", "choices", "=", "list", "(", "STRATEGY_CONFIG", ".", "keys", "(", ")", ")", "+", "[", "\"all\"", "]", ",", "\n", "default", "=", "\"all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--offset\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "dataset", "==", "\"all\"", ":", "\n", "        ", "dataset_list", "=", "list", "(", "DATASET_CONFIG", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset_list", "=", "[", "args", ".", "dataset", "]", "\n", "\n", "", "if", "args", ".", "strategy", "==", "\"all\"", ":", "\n", "        ", "strategy_list", "=", "list", "(", "STRATEGY_CONFIG", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "strategy_list", "=", "[", "args", ".", "strategy", "]", "\n", "\n", "", "for", "dataset", "in", "dataset_list", ":", "\n", "        ", "for", "strategy", "in", "strategy_list", ":", "\n", "            ", "command", "=", "[", "\"python3\"", ",", "\"-m\"", ",", "\"fibber.benchmark.benchmark_style_transfer\"", "]", "\n", "command", "+=", "to_command", "(", "COMMON_CONFIG", ")", "\n", "command", "+=", "to_command", "(", "GPU_CONFIG", "[", "args", ".", "gpu", "]", ")", "\n", "command", "+=", "to_command", "(", "DATASET_CONFIG", "[", "dataset", "]", ")", "\n", "command", "+=", "to_command", "(", "STRATEGY_CONFIG", "[", "strategy", "]", ")", "\n", "command", "+=", "to_command", "(", "{", "\"--subsample_offset\"", ":", "args", ".", "offset", "}", ")", "\n", "subprocess", ".", "call", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.tests.test_fibber.test_fibber": [[6, 20], ["fibber.fibber.Fibber", "fibber.fibber.Fibber.paraphrase"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.fibber.fibber.Fibber.paraphrase"], ["@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_fibber", "(", ")", ":", "\n", "    ", "arg_dict", "=", "{", "\n", "\"use_gpu_id\"", ":", "0", ",", "\n", "\"transformer_clf_gpu_id\"", ":", "0", ",", "\n", "\"strategy_gpu_id\"", ":", "0", ",", "\n", "\"bert_ppl_gpu_id\"", ":", "0", ",", "\n", "}", "\n", "fibber", "=", "Fibber", "(", "arg_dict", ",", "dataset_name", "=", "\"movie_review\"", ",", "strategy_name", "=", "\"IdentityStrategy\"", ",", "\n", "output_dir", "=", "\"exp-pytest\"", ")", "\n", "text", "=", "\"test text.\"", "\n", "paraphrases", "=", "fibber", ".", "paraphrase", "(", "{", "\"text0\"", ":", "text", "}", ")", "[", "1", "]", "\n", "for", "item", "in", "paraphrases", ":", "\n", "        ", "assert", "item", "==", "text", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.tests.test_integrity.gpu_id": [[8, 13], ["pytest.fixture", "torch.cuda.device_count"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", ")", "\n", "def", "gpu_id", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.tests.test_integrity.test_integrity_identity": [[15, 31], ["torch.cuda.empty_cache", "fibber.benchmark.Benchmark", "fibber.benchmark.Benchmark.run_benchmark"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_integrity_identity", "(", "gpu_id", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "benchmark", "=", "Benchmark", "(", "\n", "output_dir", "=", "\"exp-pytest\"", ",", "\n", "dataset_name", "=", "\"movie_review\"", ",", "\n", "subsample_attack_set", "=", "100", ",", "\n", "use_gpu_id", "=", "gpu_id", ",", "\n", "bert_ppl_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_steps", "=", "5000", ",", "\n", "transformer_clf_bs", "=", "32", "\n", ")", "\n", "\n", "result", "=", "benchmark", ".", "run_benchmark", "(", "paraphrase_strategy", "=", "\"IdentityStrategy\"", ")", "\n", "assert", "result", "[", "\"bert-base-cased-Classifier_Accuracy_targeted(\u2193)\"", "]", ">", "0.85", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.tests.test_integrity.test_integrity_textfooler": [[33, 57], ["torch.cuda.empty_cache", "fibber.benchmark.Benchmark", "fibber.paraphrase_strategies.TextAttackStrategy", "fibber.benchmark.Benchmark.run_benchmark", "fibber.benchmark.Benchmark.get_metric_bundle"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_integrity_textfooler", "(", "gpu_id", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "benchmark", "=", "Benchmark", "(", "\n", "output_dir", "=", "\"exp-pytest\"", ",", "\n", "dataset_name", "=", "\"movie_review\"", ",", "\n", "subsample_attack_set", "=", "100", ",", "\n", "use_gpu_id", "=", "gpu_id", ",", "\n", "bert_ppl_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_steps", "=", "5000", ",", "\n", "transformer_clf_bs", "=", "32", "\n", ")", "\n", "\n", "strategy", "=", "TextAttackStrategy", "(", "\n", "arg_dict", "=", "{", "\"ta_recipe\"", ":", "\"TextFoolerJin2019\"", "}", ",", "\n", "dataset_name", "=", "\"movie_review\"", ",", "\n", "strategy_gpu_id", "=", "gpu_id", ",", "\n", "output_dir", "=", "\"exp-pytest\"", ",", "\n", "metric_bundle", "=", "benchmark", ".", "get_metric_bundle", "(", ")", ",", "\n", "field", "=", "\"text0\"", ")", "\n", "result", "=", "benchmark", ".", "run_benchmark", "(", "paraphrase_strategy", "=", "strategy", ")", "\n", "\n", "assert", "result", "[", "\"bert-base-cased-Classifier_Accuracy_targeted(\u2193)\"", "]", "<", "0.50", "\n", "\n"]], "home.repos.pwc.inspect_result.DAI-Lab_fibber.tests.test_integrity.test_integrity_asrs": [[59, 80], ["torch.cuda.empty_cache", "fibber.benchmark.Benchmark", "fibber.paraphrase_strategies.ASRSStrategy", "fibber.benchmark.Benchmark.run_benchmark", "fibber.benchmark.Benchmark.get_metric_bundle"], "function", ["home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.run_benchmark", "home.repos.pwc.inspect_result.DAI-Lab_fibber.benchmark.benchmark_adversarial_attack.Benchmark.get_metric_bundle"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_integrity_asrs", "(", "gpu_id", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "benchmark", "=", "Benchmark", "(", "\n", "output_dir", "=", "\"exp-pytest\"", ",", "\n", "dataset_name", "=", "\"movie_review\"", ",", "\n", "subsample_attack_set", "=", "1", ",", "\n", "use_gpu_id", "=", "gpu_id", ",", "\n", "bert_ppl_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_gpu_id", "=", "gpu_id", ",", "\n", "transformer_clf_steps", "=", "5000", ",", "\n", "transformer_clf_bs", "=", "32", "\n", ")", "\n", "strategy", "=", "ASRSStrategy", "(", "\n", "arg_dict", "=", "{", "}", ",", "\n", "dataset_name", "=", "\"movie_review\"", ",", "\n", "strategy_gpu_id", "=", "gpu_id", ",", "\n", "output_dir", "=", "\"exp-pytest\"", ",", "\n", "metric_bundle", "=", "benchmark", ".", "get_metric_bundle", "(", ")", ",", "\n", "field", "=", "\"text0\"", ")", "\n", "benchmark", ".", "run_benchmark", "(", "paraphrase_strategy", "=", "strategy", ",", "max_paraphrases", "=", "10", ")", "\n", "", ""]]}