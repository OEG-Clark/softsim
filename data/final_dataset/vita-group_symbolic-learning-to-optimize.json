{"home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.orig_expr_2_shortened_latex": [[68, 107], ["sympy.latex", "sr_test.orig_expr_2_shortened_latex._shorten"], "function", ["None"], ["def", "orig_expr_2_shortened_latex", "(", "expr", ")", ":", "\n", "# \u8f93\u5165\u4e0d\u662f\u5b57\u7b26\u4e32\uff0c\u800c\u662fsympy\u8868\u8fbe\u5f0f", "\n", "\n", "\n", "# print('begin simplify...')", "\n", "# mm = simplify(expr)", "\n", "# print(mm)", "\n", "# print(printing.latex(mm))", "\n", "\n", "\n", "    ", "latex_print", "=", "printing", ".", "latex", "(", "expr", ")", "\n", "\n", "\n", "def", "_shorten", "(", "mystr", ")", ":", "\n", "        ", "def", "find_nums", "(", "mystr", ")", ":", "\n", "            ", "import", "re", "\n", "return", "re", ".", "findall", "(", "r\"\\d+\\.\\d*\"", ",", "mystr", ")", "\n", "", "def", "replace_with", "(", "mystr", ",", "num1", ",", "num2", ")", ":", "\n", "            ", "list_", "=", "mystr", ".", "split", "(", "num1", ")", "\n", "return", "num2", ".", "join", "(", "list_", ")", "\n", "", "def", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "num1_list", ")", ")", ":", "\n", "                ", "mystr", "=", "replace_with", "(", "mystr", ",", "num1_list", "[", "i", "]", ",", "num2_list", "[", "i", "]", ")", "\n", "", "return", "mystr", "\n", "", "def", "cut_short", "(", "num1_list", ")", ":", "\n", "            ", "num2_list", "=", "[", "]", "\n", "for", "num1", "in", "num1_list", ":", "\n", "                ", "num2_list", ".", "append", "(", "num1", "[", ":", "4", "]", ")", "\n", "", "return", "num2_list", "\n", "", "print", "(", "'\\n\\norig:\\n\\n'", ",", "mystr", ")", "\n", "num1_list", "=", "find_nums", "(", "mystr", ")", "\n", "num2_list", "=", "cut_short", "(", "num1_list", ")", "\n", "mystr_short", "=", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", "\n", "print", "(", "'\\n\\ncutted short:\\n\\n'", ",", "mystr_short", ")", "\n", "print", "(", "'\\n\\n'", ")", "\n", "return", "mystr_short", "\n", "\n", "", "shortened_latex", "=", "_shorten", "(", "latex_print", ")", "\n", "return", "shortened_latex", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.remove_nan": [[135, 152], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.surf_3d": [[160, 202], ["matplotlib.pyplot.figure", "plt.figure.gca", "numpy.arange", "numpy.arange", "numpy.meshgrid", "fig.gca.plot_surface", "fig.gca.zaxis.set_major_locator", "fig.gca.zaxis.set_major_formatter", "plt.figure.colorbar", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.show", "time.strftime", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "len", "len", "LinearLocator", "FormatStrFormatter", "time.localtime"], "function", ["None"], ["", "def", "surf_3d", "(", "im", ",", "ttl", ",", "ax_", ",", "ay_", ",", ")", ":", "\n", "# This import registers the 3D projection, but is otherwise unused.", "\n", "    ", "from", "mpl_toolkits", ".", "mplot3d", "import", "Axes3D", "# noqa: F401 unused import", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "matplotlib", "import", "cm", "\n", "from", "matplotlib", ".", "ticker", "import", "LinearLocator", ",", "FormatStrFormatter", "\n", "import", "numpy", "as", "np", "\n", "\"\"\"\n    Parameters\n    ----------\n    im : m - n matrix\n    Returns: None\n    plot and show the 3d surface of input matrix\n    -------\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "gca", "(", "projection", "=", "'3d'", ")", "\n", "# Make data.", "\n", "X", "=", "np", ".", "arange", "(", "len", "(", "im", "[", "0", "]", ")", ")", "\n", "Y", "=", "np", ".", "arange", "(", "len", "(", "im", ")", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "# R = im2", "\n", "Z", "=", "im", "\n", "# Plot the surface.", "\n", "surf", "=", "ax", ".", "plot_surface", "(", "X", ",", "Y", ",", "Z", ",", "cmap", "=", "cm", ".", "coolwarm", ",", "\n", "linewidth", "=", "0", ",", "antialiased", "=", "False", ")", "\n", "# ax.set_zlim(-1e-4,1e-4)", "\n", "# Customize the z axis.", "\n", "# ax.set_zlim(-1.01, 1.01)", "\n", "ax", ".", "zaxis", ".", "set_major_locator", "(", "LinearLocator", "(", "10", ")", ")", "\n", "ax", ".", "zaxis", ".", "set_major_formatter", "(", "FormatStrFormatter", "(", "'%.02f'", ")", ")", "\n", "# Add a color bar which maps values to colors.", "\n", "fig", ".", "colorbar", "(", "surf", ",", "shrink", "=", "0.5", ",", "aspect", "=", "5", ")", "\n", "plt", ".", "title", "(", "ttl", ")", "\n", "plt", ".", "xlabel", "(", "'g1'", ")", "\n", "plt", ".", "ylabel", "(", "'t'", ")", "\n", "ax", ".", "xticks", "=", "ax_", "\n", "ax", ".", "yticks", "=", "ay_", "\n", "plt", ".", "show", "(", ")", "\n", "lt2", "=", "time", ".", "strftime", "(", "\"%Y-%m-%d--%H_%M_%S\"", ",", "time", ".", "localtime", "(", ")", ")", "\n", "plt", ".", "savefig", "(", "\"./___{}.jpg\"", ".", "format", "(", "lt2", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sr_expression": [[203, 212], ["sr_test.sign", "sr_test.sign", "sr_test.greater", "sr_test.Abs", "sr_test.exp", "sr_test.greater", "sr_test.Abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs"], ["", "def", "sr_expression", "(", "x", ",", "y", ")", ":", "\n", "\n", "    ", "g4", "=", "5.e-3", "\n", "t", "=", "x", "\n", "g1", "=", "y", "\n", "res", "=", "g4", "+", "Abs", "(", "t", "-", "1.864943", ")", "**", "exp", "(", "greater", "(", "0.026726894", ",", "t", ")", ")", "*", "sign", "(", "t", "-", "1.864943", ")", "+", "sign", "(", "greater", "(", "t", ",", "0.80258375", "*", "Abs", "(", "g1", ")", "+", "0.0172415", ")", "-", "0.60028476", ")", "\n", "# res = g4 + Abs(t - 1.864943)**exp(greater(0.026726894, t))*sign(t - 1.864943) + sign(greater(t, 0.80258375*Abs(g1) + 0.0172415) - 0.60028476)", "\n", "\n", "return", "res", "\n", "# ax = np.linspace(0,0.2,num=20)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.hasnan": [[223, 229], ["arr.copy().reshape.copy().reshape", "arr.copy().reshape.copy"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy"], ["", "def", "hasnan", "(", "arr", ")", ":", "\n", "    ", "arr", "=", "arr", ".", "copy", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "arr", ":", "\n", "        ", "if", "x", "!=", "x", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.relu": [[229, 231], ["numpy.maximum"], "function", ["None"], ["", "def", "relu", "(", "inX", ")", ":", "\n", "    ", "return", "np", ".", "maximum", "(", "0.", ",", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.greater": [[231, 233], ["numpy.greater().astype", "numpy.greater"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater"], ["", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "greater", "(", "x", ",", "y", ")", ".", "astype", "(", "'float'", ")", "\n", "# return np.maximum(x,y)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.mult": [[234, 236], ["None"], "function", ["None"], ["", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sin": [[236, 238], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "sin", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.cos": [[238, 240], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "cos", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sign": [[240, 242], ["numpy.sign"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "sign", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.plus": [[242, 244], ["None"], "function", ["None"], ["", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.square": [[244, 246], ["None"], "function", ["None"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.cube": [[246, 248], ["None"], "function", ["None"], ["", "def", "cube", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.tanh": [[248, 250], ["numpy.tanh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "def", "tanh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.exp": [[250, 252], ["numpy.exp"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "exp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.pow": [[252, 254], ["numpy.sign", "numpy.power", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "power", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.Abs": [[254, 256], ["abs"], "function", ["None"], ["", "def", "Abs", "(", "x", ")", ":", "\n", "    ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.re": [[256, 258], ["numpy.real"], "function", ["None"], ["", "def", "re", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.div": [[258, 260], ["None"], "function", ["None"], ["", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.erfc": [[260, 262], ["scipy.special.erfc"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc"], ["", "def", "erfc", "(", "x", ")", ":", "\n", "    ", "return", "scipy", ".", "special", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sqrtm": [[262, 264], ["numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "sqrtm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.logm": [[264, 266], ["numpy.log", "numpy.abs"], "function", ["None"], ["", "def", "logm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "log", "(", "np", ".", "abs", "(", "x", ")", "+", "1e-8", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sinh": [[266, 268], ["numpy.sinh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh"], ["", "def", "sinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.asinh": [[268, 270], ["numpy.arcsinh"], "function", ["None"], ["", "def", "asinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "arcsinh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_test.sr_fun_1229": [[322, 333], ["sr_test.mult", "sr_test.pow", "sr_test.relu", "sr_test.plus", "sr_test.mult", "sr_test.asinh", "sr_test.plus", "sr_test.plus", "sr_test.relu", "sr_test.erfc", "sr_test.plus", "sr_test.plus", "sr_test.plus", "abs", "sr_test.tanh", "sr_test.plus", "sr_test.plus", "sr_test.tanh", "sr_test.square", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.relu", "sr_test.mult", "sr_test.plus", "sr_test.plus", "sr_test.plus"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus"], ["", "def", "sr_fun_1229", "(", "g0", ",", "g1", ",", "g2", ",", "g3", ",", "g4", ",", "mean_g", ",", "mean_g2", ",", "t", ")", ":", "\n", "# \u8f93\u5165\u8f93\u51fa\u90fd\u662fflatten\u7684array", "\n", "  ", "t", "/=", "1e4", "\n", "# print('yo')", "\n", "res", "=", "mult", "(", "pow", "(", "relu", "(", "mult", "(", "g0", ",", "-", "0.008472766", ")", ")", ",", "plus", "(", "asinh", "(", "plus", "(", "t", ",", "erfc", "(", "0.37580237", ")", ")", ")", ",", "plus", "(", "relu", "(", "plus", "(", "plus", "(", "plus", "(", "tanh", "(", "plus", "(", "g4", ",", "plus", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "relu", "(", "mult", "(", "plus", "(", "g2", ",", "plus", "(", "plus", "(", "g1", ",", "g3", ")", ",", "0.020662013", ")", ")", ",", "3.0930731", ")", ")", ")", ")", ")", ")", ")", ")", ",", "square", "(", "g0", ")", ")", ")", ")", ",", "mean_g2", ")", ",", "abs", "(", "g0", ")", ")", ",", "mean_g2", ")", ")", ",", "t", ")", ")", ")", ",", "1.320138", ")", "\n", "\n", "\n", "\n", "\n", "\n", "return", "res", "\n", "", "s", "=", "0.03", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_train.me": [[8, 10], ["numpy.sqrt", "numpy.dot", "len"], "function", ["None"], ["def", "me", "(", "y", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "y", ",", "y", ")", "/", "len", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr2.sr_train.remove_nan": [[12, 29], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.sr_train.me": [[8, 10], ["numpy.sqrt", "numpy.dot", "len"], "function", ["None"], ["def", "me", "(", "y", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "y", ",", "y", ")", "/", "len", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.sr_train.remove_nan": [[12, 29], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.remove_nan": [[20, 37], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.surf_3d": [[45, 87], ["matplotlib.pyplot.figure", "plt.figure.gca", "numpy.arange", "numpy.arange", "numpy.meshgrid", "fig.gca.plot_surface", "fig.gca.zaxis.set_major_locator", "fig.gca.zaxis.set_major_formatter", "plt.figure.colorbar", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.show", "time.strftime", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "len", "len", "LinearLocator", "FormatStrFormatter", "time.localtime"], "function", ["None"], ["", "def", "surf_3d", "(", "im", ",", "ttl", ",", "ax_", ",", "ay_", ",", ")", ":", "\n", "# This import registers the 3D projection, but is otherwise unused.", "\n", "    ", "from", "mpl_toolkits", ".", "mplot3d", "import", "Axes3D", "# noqa: F401 unused import", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "matplotlib", "import", "cm", "\n", "from", "matplotlib", ".", "ticker", "import", "LinearLocator", ",", "FormatStrFormatter", "\n", "import", "numpy", "as", "np", "\n", "\"\"\"\n    Parameters\n    ----------\n    im : m - n matrix\n    Returns: None\n    plot and show the 3d surface of input matrix\n    -------\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "gca", "(", "projection", "=", "'3d'", ")", "\n", "# Make data.", "\n", "X", "=", "np", ".", "arange", "(", "len", "(", "im", "[", "0", "]", ")", ")", "\n", "Y", "=", "np", ".", "arange", "(", "len", "(", "im", ")", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "# R = im2", "\n", "Z", "=", "im", "\n", "# Plot the surface.", "\n", "surf", "=", "ax", ".", "plot_surface", "(", "X", ",", "Y", ",", "Z", ",", "cmap", "=", "cm", ".", "coolwarm", ",", "\n", "linewidth", "=", "0", ",", "antialiased", "=", "False", ")", "\n", "# ax.set_zlim(-1e-4,1e-4)", "\n", "# Customize the z axis.", "\n", "# ax.set_zlim(-1.01, 1.01)", "\n", "ax", ".", "zaxis", ".", "set_major_locator", "(", "LinearLocator", "(", "10", ")", ")", "\n", "ax", ".", "zaxis", ".", "set_major_formatter", "(", "FormatStrFormatter", "(", "'%.02f'", ")", ")", "\n", "# Add a color bar which maps values to colors.", "\n", "fig", ".", "colorbar", "(", "surf", ",", "shrink", "=", "0.5", ",", "aspect", "=", "5", ")", "\n", "plt", ".", "title", "(", "ttl", ")", "\n", "plt", ".", "xlabel", "(", "'g1'", ")", "\n", "plt", ".", "ylabel", "(", "'t'", ")", "\n", "ax", ".", "xticks", "=", "ax_", "\n", "ax", ".", "yticks", "=", "ay_", "\n", "plt", ".", "show", "(", ")", "\n", "lt2", "=", "time", ".", "strftime", "(", "\"%Y-%m-%d--%H_%M_%S\"", ",", "time", ".", "localtime", "(", ")", ")", "\n", "plt", ".", "savefig", "(", "\"./___{}.jpg\"", ".", "format", "(", "lt2", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sr_expression": [[88, 97], ["cal_R2.sign", "cal_R2.sign", "cal_R2.greater", "cal_R2.Abs", "cal_R2.exp", "cal_R2.greater", "cal_R2.Abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs"], ["", "def", "sr_expression", "(", "x", ",", "y", ")", ":", "\n", "\n", "    ", "g4", "=", "5.e-3", "\n", "t", "=", "x", "\n", "g1", "=", "y", "\n", "res", "=", "g4", "+", "Abs", "(", "t", "-", "1.864943", ")", "**", "exp", "(", "greater", "(", "0.026726894", ",", "t", ")", ")", "*", "sign", "(", "t", "-", "1.864943", ")", "+", "sign", "(", "greater", "(", "t", ",", "0.80258375", "*", "Abs", "(", "g1", ")", "+", "0.0172415", ")", "-", "0.60028476", ")", "\n", "# res = g4 + Abs(t - 1.864943)**exp(greater(0.026726894, t))*sign(t - 1.864943) + sign(greater(t, 0.80258375*Abs(g1) + 0.0172415) - 0.60028476)", "\n", "\n", "return", "res", "\n", "# ax = np.linspace(0,0.2,num=20)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.hasnan": [[108, 114], ["arr.copy().reshape.copy().reshape", "arr.copy().reshape.copy"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy"], ["", "def", "hasnan", "(", "arr", ")", ":", "\n", "    ", "arr", "=", "arr", ".", "copy", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "arr", ":", "\n", "        ", "if", "x", "!=", "x", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.relu": [[114, 116], ["numpy.maximum"], "function", ["None"], ["", "def", "relu", "(", "inX", ")", ":", "\n", "    ", "return", "np", ".", "maximum", "(", "0.", ",", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.greater": [[116, 118], ["numpy.greater().astype", "numpy.greater"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater"], ["", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "greater", "(", "x", ",", "y", ")", ".", "astype", "(", "'float'", ")", "\n", "# return np.maximum(x,y)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.mult": [[119, 121], ["None"], "function", ["None"], ["", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sin": [[121, 123], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "sin", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.cos": [[123, 125], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "cos", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sign": [[125, 127], ["numpy.sign"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "sign", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.plus": [[127, 129], ["None"], "function", ["None"], ["", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.square": [[129, 131], ["None"], "function", ["None"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.cube": [[131, 133], ["None"], "function", ["None"], ["", "def", "cube", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.tanh": [[133, 135], ["numpy.tanh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "def", "tanh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.exp": [[135, 137], ["numpy.exp"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "exp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.pow": [[137, 139], ["numpy.sign", "numpy.power", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "power", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.Abs": [[139, 141], ["abs"], "function", ["None"], ["", "def", "Abs", "(", "x", ")", ":", "\n", "    ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.re": [[141, 143], ["numpy.real"], "function", ["None"], ["", "def", "re", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.div": [[143, 145], ["None"], "function", ["None"], ["", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.erfc": [[145, 147], ["scipy.special.erfc"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc"], ["", "def", "erfc", "(", "x", ")", ":", "\n", "    ", "return", "scipy", ".", "special", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sqrtm": [[147, 149], ["numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "sqrtm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.logm": [[149, 151], ["numpy.log", "numpy.abs"], "function", ["None"], ["", "def", "logm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "log", "(", "np", ".", "abs", "(", "x", ")", "+", "1e-8", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sinh": [[151, 153], ["numpy.sinh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh"], ["", "def", "sinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.asinh": [[153, 155], ["numpy.arcsinh"], "function", ["None"], ["", "def", "asinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "arcsinh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr1_rnnprop_g_features.cal_R2.sr_fun_1229": [[207, 218], ["cal_R2.mult", "cal_R2.pow", "cal_R2.relu", "cal_R2.plus", "cal_R2.mult", "cal_R2.asinh", "cal_R2.plus", "cal_R2.plus", "cal_R2.relu", "cal_R2.erfc", "cal_R2.plus", "cal_R2.plus", "cal_R2.plus", "abs", "cal_R2.tanh", "cal_R2.plus", "cal_R2.plus", "cal_R2.tanh", "cal_R2.square", "cal_R2.tanh", "cal_R2.tanh", "cal_R2.tanh", "cal_R2.tanh", "cal_R2.tanh", "cal_R2.relu", "cal_R2.mult", "cal_R2.plus", "cal_R2.plus", "cal_R2.plus"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus"], ["", "def", "sr_fun_1229", "(", "g0", ",", "g1", ",", "g2", ",", "g3", ",", "g4", ",", "mean_g", ",", "mean_g2", ",", "t", ")", ":", "\n", "# \u8f93\u5165\u8f93\u51fa\u90fd\u662fflatten\u7684array", "\n", "  ", "t", "/=", "1e4", "\n", "# print('yo')", "\n", "res", "=", "mult", "(", "pow", "(", "relu", "(", "mult", "(", "g0", ",", "-", "0.008472766", ")", ")", ",", "plus", "(", "asinh", "(", "plus", "(", "t", ",", "erfc", "(", "0.37580237", ")", ")", ")", ",", "plus", "(", "relu", "(", "plus", "(", "plus", "(", "plus", "(", "tanh", "(", "plus", "(", "g4", ",", "plus", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "relu", "(", "mult", "(", "plus", "(", "g2", ",", "plus", "(", "plus", "(", "g1", ",", "g3", ")", ",", "0.020662013", ")", ")", ",", "3.0930731", ")", ")", ")", ")", ")", ")", ")", ")", ",", "square", "(", "g0", ")", ")", ")", ")", ",", "mean_g2", ")", ",", "abs", "(", "g0", ")", ")", ",", "mean_g2", ")", ")", ",", "t", ")", ")", ")", ",", "1.320138", ")", "\n", "\n", "\n", "\n", "\n", "\n", "return", "res", "\n", "", "s", "=", "0.03", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.orig_expr_2_shortened_latex": [[68, 107], ["sympy.latex", "sr_test.orig_expr_2_shortened_latex._shorten"], "function", ["None"], ["def", "orig_expr_2_shortened_latex", "(", "expr", ")", ":", "\n", "# \u8f93\u5165\u4e0d\u662f\u5b57\u7b26\u4e32\uff0c\u800c\u662fsympy\u8868\u8fbe\u5f0f", "\n", "\n", "\n", "# print('begin simplify...')", "\n", "# mm = simplify(expr)", "\n", "# print(mm)", "\n", "# print(printing.latex(mm))", "\n", "\n", "\n", "    ", "latex_print", "=", "printing", ".", "latex", "(", "expr", ")", "\n", "\n", "\n", "def", "_shorten", "(", "mystr", ")", ":", "\n", "        ", "def", "find_nums", "(", "mystr", ")", ":", "\n", "            ", "import", "re", "\n", "return", "re", ".", "findall", "(", "r\"\\d+\\.\\d*\"", ",", "mystr", ")", "\n", "", "def", "replace_with", "(", "mystr", ",", "num1", ",", "num2", ")", ":", "\n", "            ", "list_", "=", "mystr", ".", "split", "(", "num1", ")", "\n", "return", "num2", ".", "join", "(", "list_", ")", "\n", "", "def", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "num1_list", ")", ")", ":", "\n", "                ", "mystr", "=", "replace_with", "(", "mystr", ",", "num1_list", "[", "i", "]", ",", "num2_list", "[", "i", "]", ")", "\n", "", "return", "mystr", "\n", "", "def", "cut_short", "(", "num1_list", ")", ":", "\n", "            ", "num2_list", "=", "[", "]", "\n", "for", "num1", "in", "num1_list", ":", "\n", "                ", "num2_list", ".", "append", "(", "num1", "[", ":", "4", "]", ")", "\n", "", "return", "num2_list", "\n", "", "print", "(", "'\\n\\norig:\\n\\n'", ",", "mystr", ")", "\n", "num1_list", "=", "find_nums", "(", "mystr", ")", "\n", "num2_list", "=", "cut_short", "(", "num1_list", ")", "\n", "mystr_short", "=", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", "\n", "print", "(", "'\\n\\ncutted short:\\n\\n'", ",", "mystr_short", ")", "\n", "print", "(", "'\\n\\n'", ")", "\n", "return", "mystr_short", "\n", "\n", "", "shortened_latex", "=", "_shorten", "(", "latex_print", ")", "\n", "return", "shortened_latex", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.remove_nan": [[135, 152], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.surf_3d": [[160, 202], ["matplotlib.pyplot.figure", "plt.figure.gca", "numpy.arange", "numpy.arange", "numpy.meshgrid", "fig.gca.plot_surface", "fig.gca.zaxis.set_major_locator", "fig.gca.zaxis.set_major_formatter", "plt.figure.colorbar", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.show", "time.strftime", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "len", "len", "LinearLocator", "FormatStrFormatter", "time.localtime"], "function", ["None"], ["", "def", "surf_3d", "(", "im", ",", "ttl", ",", "ax_", ",", "ay_", ",", ")", ":", "\n", "# This import registers the 3D projection, but is otherwise unused.", "\n", "    ", "from", "mpl_toolkits", ".", "mplot3d", "import", "Axes3D", "# noqa: F401 unused import", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "matplotlib", "import", "cm", "\n", "from", "matplotlib", ".", "ticker", "import", "LinearLocator", ",", "FormatStrFormatter", "\n", "import", "numpy", "as", "np", "\n", "\"\"\"\n    Parameters\n    ----------\n    im : m - n matrix\n    Returns: None\n    plot and show the 3d surface of input matrix\n    -------\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "gca", "(", "projection", "=", "'3d'", ")", "\n", "# Make data.", "\n", "X", "=", "np", ".", "arange", "(", "len", "(", "im", "[", "0", "]", ")", ")", "\n", "Y", "=", "np", ".", "arange", "(", "len", "(", "im", ")", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "# R = im2", "\n", "Z", "=", "im", "\n", "# Plot the surface.", "\n", "surf", "=", "ax", ".", "plot_surface", "(", "X", ",", "Y", ",", "Z", ",", "cmap", "=", "cm", ".", "coolwarm", ",", "\n", "linewidth", "=", "0", ",", "antialiased", "=", "False", ")", "\n", "# ax.set_zlim(-1e-4,1e-4)", "\n", "# Customize the z axis.", "\n", "# ax.set_zlim(-1.01, 1.01)", "\n", "ax", ".", "zaxis", ".", "set_major_locator", "(", "LinearLocator", "(", "10", ")", ")", "\n", "ax", ".", "zaxis", ".", "set_major_formatter", "(", "FormatStrFormatter", "(", "'%.02f'", ")", ")", "\n", "# Add a color bar which maps values to colors.", "\n", "fig", ".", "colorbar", "(", "surf", ",", "shrink", "=", "0.5", ",", "aspect", "=", "5", ")", "\n", "plt", ".", "title", "(", "ttl", ")", "\n", "plt", ".", "xlabel", "(", "'g1'", ")", "\n", "plt", ".", "ylabel", "(", "'t'", ")", "\n", "ax", ".", "xticks", "=", "ax_", "\n", "ax", ".", "yticks", "=", "ay_", "\n", "plt", ".", "show", "(", ")", "\n", "lt2", "=", "time", ".", "strftime", "(", "\"%Y-%m-%d--%H_%M_%S\"", ",", "time", ".", "localtime", "(", ")", ")", "\n", "plt", ".", "savefig", "(", "\"./___{}.jpg\"", ".", "format", "(", "lt2", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sr_expression": [[203, 212], ["sr_test.sign", "sr_test.sign", "sr_test.greater", "sr_test.Abs", "sr_test.exp", "sr_test.greater", "sr_test.Abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs"], ["", "def", "sr_expression", "(", "x", ",", "y", ")", ":", "\n", "\n", "    ", "g4", "=", "5.e-3", "\n", "t", "=", "x", "\n", "g1", "=", "y", "\n", "res", "=", "g4", "+", "Abs", "(", "t", "-", "1.864943", ")", "**", "exp", "(", "greater", "(", "0.026726894", ",", "t", ")", ")", "*", "sign", "(", "t", "-", "1.864943", ")", "+", "sign", "(", "greater", "(", "t", ",", "0.80258375", "*", "Abs", "(", "g1", ")", "+", "0.0172415", ")", "-", "0.60028476", ")", "\n", "# res = g4 + Abs(t - 1.864943)**exp(greater(0.026726894, t))*sign(t - 1.864943) + sign(greater(t, 0.80258375*Abs(g1) + 0.0172415) - 0.60028476)", "\n", "\n", "return", "res", "\n", "# ax = np.linspace(0,0.2,num=20)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.hasnan": [[223, 229], ["arr.copy().reshape.copy().reshape", "arr.copy().reshape.copy"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy"], ["", "def", "hasnan", "(", "arr", ")", ":", "\n", "    ", "arr", "=", "arr", ".", "copy", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "arr", ":", "\n", "        ", "if", "x", "!=", "x", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.relu": [[229, 231], ["numpy.maximum"], "function", ["None"], ["", "def", "relu", "(", "inX", ")", ":", "\n", "    ", "return", "np", ".", "maximum", "(", "0.", ",", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.greater": [[231, 233], ["numpy.greater().astype", "numpy.greater"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater"], ["", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "greater", "(", "x", ",", "y", ")", ".", "astype", "(", "'float'", ")", "\n", "# return np.maximum(x,y)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.mult": [[234, 236], ["None"], "function", ["None"], ["", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sin": [[236, 238], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "sin", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.cos": [[238, 240], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "cos", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sign": [[240, 242], ["numpy.sign"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "sign", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.plus": [[242, 244], ["None"], "function", ["None"], ["", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.square": [[244, 246], ["None"], "function", ["None"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.cube": [[246, 248], ["None"], "function", ["None"], ["", "def", "cube", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.tanh": [[248, 250], ["numpy.tanh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "def", "tanh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.exp": [[250, 252], ["numpy.exp"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "exp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.pow": [[252, 254], ["numpy.sign", "numpy.power", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "power", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.Abs": [[254, 256], ["abs"], "function", ["None"], ["", "def", "Abs", "(", "x", ")", ":", "\n", "    ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.re": [[256, 258], ["numpy.real"], "function", ["None"], ["", "def", "re", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.div": [[258, 260], ["None"], "function", ["None"], ["", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.erfc": [[260, 262], ["scipy.special.erfc"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc"], ["", "def", "erfc", "(", "x", ")", ":", "\n", "    ", "return", "scipy", ".", "special", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sqrtm": [[262, 264], ["numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "sqrtm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.logm": [[264, 266], ["numpy.log", "numpy.abs"], "function", ["None"], ["", "def", "logm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "log", "(", "np", ".", "abs", "(", "x", ")", "+", "1e-8", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sinh": [[266, 268], ["numpy.sinh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh"], ["", "def", "sinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.asinh": [[268, 270], ["numpy.arcsinh"], "function", ["None"], ["", "def", "asinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "arcsinh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_test.sr_fun_1229": [[322, 333], ["sr_test.mult", "sr_test.pow", "sr_test.relu", "sr_test.plus", "sr_test.mult", "sr_test.asinh", "sr_test.plus", "sr_test.plus", "sr_test.relu", "sr_test.erfc", "sr_test.plus", "sr_test.plus", "sr_test.plus", "abs", "sr_test.tanh", "sr_test.plus", "sr_test.plus", "sr_test.tanh", "sr_test.square", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.tanh", "sr_test.relu", "sr_test.mult", "sr_test.plus", "sr_test.plus", "sr_test.plus"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus"], ["", "def", "sr_fun_1229", "(", "g0", ",", "g1", ",", "g2", ",", "g3", ",", "g4", ",", "mean_g", ",", "mean_g2", ",", "t", ")", ":", "\n", "# \u8f93\u5165\u8f93\u51fa\u90fd\u662fflatten\u7684array", "\n", "  ", "t", "/=", "1e4", "\n", "# print('yo')", "\n", "res", "=", "mult", "(", "pow", "(", "relu", "(", "mult", "(", "g0", ",", "-", "0.008472766", ")", ")", ",", "plus", "(", "asinh", "(", "plus", "(", "t", ",", "erfc", "(", "0.37580237", ")", ")", ")", ",", "plus", "(", "relu", "(", "plus", "(", "plus", "(", "plus", "(", "tanh", "(", "plus", "(", "g4", ",", "plus", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "tanh", "(", "relu", "(", "mult", "(", "plus", "(", "g2", ",", "plus", "(", "plus", "(", "g1", ",", "g3", ")", ",", "0.020662013", ")", ")", ",", "3.0930731", ")", ")", ")", ")", ")", ")", ")", ")", ",", "square", "(", "g0", ")", ")", ")", ")", ",", "mean_g2", ")", ",", "abs", "(", "g0", ")", ")", ",", "mean_g2", ")", ")", ",", "t", ")", ")", ")", ",", "1.320138", ")", "\n", "\n", "\n", "\n", "\n", "\n", "return", "res", "\n", "", "s", "=", "0.03", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_train.me": [[8, 10], ["numpy.sqrt", "numpy.dot", "len"], "function", ["None"], ["def", "me", "(", "y", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "y", ",", "y", ")", "/", "len", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.sr3.sr_train.remove_nan": [[12, 29], ["numpy.concatenate", "print", "numpy.asarray", "print", "res[].reshape", "range", "res[].reshape.reshape", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "remove_nan", "(", "X", ",", "y", ")", ":", "\n", "  ", "SR_Xy", "=", "np", ".", "concatenate", "(", "[", "X", ",", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "'before remove-nan, shape is: '", ",", "SR_Xy", ".", "shape", ")", "\n", "N_samples", ",", "n_features", "=", "SR_Xy", ".", "shape", "\n", "res", "=", "[", "]", "\n", "for", "sp", "in", "SR_Xy", ":", "\n", "    ", "has_nan", "=", "0", "\n", "for", "i_feat", "in", "range", "(", "n_features", ")", ":", "\n", "      ", "if", "sp", "[", "i_feat", "]", "!=", "sp", "[", "i_feat", "]", ":", "\n", "        ", "has_nan", "=", "1", "\n", "", "", "if", "not", "has_nan", ":", "\n", "      ", "res", ".", "append", "(", "sp", ")", "\n", "", "", "res", "=", "np", ".", "asarray", "(", "res", ")", "\n", "print", "(", "'AFTER remove-nan, shape is: '", ",", "res", ".", "shape", ")", "\n", "X", "=", "res", "[", ":", ",", ":", "-", "1", "]", "\n", "y", "=", "res", "[", ":", ",", "-", "1", "]", ".", "reshape", "(", "-", "1", ")", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.__init__": [[229, 256], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_mt", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MetaOptimizer.\n\n    Args:\n      **kwargs: A set of keyword arguments mapping network identifiers (the\n          keys) to parameters that will be passed to networks.Factory (see docs\n          for more info).  These can be used to assign different optimizee\n          parameters to different optimizers (see net_assignments in the\n          meta_loss method).\n    \"\"\"", "\n", "self", ".", "_nets", "=", "None", "\n", "self", ".", "num_mt", "=", "num_mt", "\n", "\n", "if", "not", "kwargs", ":", "\n", "# Use a default coordinatewise network if nothing is given. this allows", "\n", "# for no network spec and no assignments.", "\n", "      ", "self", ".", "_config", "=", "{", "\n", "\"coordinatewise\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", "}", "}", "\n", "", "else", ":", "\n", "      ", "self", ".", "_config", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.save": [[257, 273], ["meta_dm_train.MetaOptimizer._nets.items", "networks.save", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "", "def", "save", "(", "self", ",", "sess", ",", "path", "=", "None", ",", "index", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save meta-optimizer.\"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "if", "path", "is", "None", ":", "\n", "        ", "filename", "=", "None", "\n", "key", "=", "k", "\n", "", "elif", "index", "is", "not", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "key", "=", "filename", "\n", "", "else", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l\"", ".", "format", "(", "k", ")", ")", "\n", "key", "=", "filename", "\n", "", "net_vars", "=", "networks", ".", "save", "(", "net", ",", "sess", ",", "filename", "=", "filename", ")", "\n", "result", "[", "key", "]", "=", "net_vars", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.restorer": [[274, 288], ["meta_dm_train.MetaOptimizer._nets.items", "sonnet.get_variables_in_module", "collections.defaultdict", "collections.defaultdict", "[].split", "tensorflow.placeholder", "tensorflow.assign", "v.get_shape", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "restorer", "(", "self", ")", ":", "\n", "    ", "self", ".", "restore_pl", "=", "{", "}", "\n", "self", ".", "assigns", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "self", ".", "restore_pl", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "self", ".", "assigns", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "placeholder", "(", "name", "=", "\"{}_{}_pl\"", ".", "format", "(", "module_name", ",", "variable_name", ")", ",", "shape", "=", "v", ".", "get_shape", "(", ")", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "assign", "(", "v", ",", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.restore": [[289, 303], ["meta_dm_train.MetaOptimizer._nets.items", "sess.run", "os.path.join", "pickle.load", "sonnet.get_variables_in_module", "open", "[].split", "tensorflow.python.framework.ops.append", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "", "def", "restore", "(", "self", ",", "sess", ",", "path", ",", "index", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "feed", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "data", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "feed", "[", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "]", "=", "data", "[", "module_name", "]", "[", "variable_name", "]", "\n", "ops", ".", "append", "(", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "", "", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "feed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.meta_loss": [[304, 528], ["meta_dm_train._get_variables", "print", "print", "print", "print", "meta_dm_train._make_nets", "print", "print", "tensorflow.TensorArray", "tensorflow.while_loop", "tensorflow.reduce_sum", "len", "range", "sum", "print", "range", "range", "nets.items", "scale.append", "tensorflow.name_scope", "enumerate", "list", "tensorflow.name_scope", "meta_dm_train._make_with_custom_variables", "fx_array.write.write.write", "fx_array.write.write.stack", "state_reshape.append", "mt_labels.append", "mt_inputs.append", "tensorflow.TensorArray", "tensorflow.while_loop", "state_reshape_final.append", "tensorflow.reduce_sum", "tensorflow.name_scope", "tensorflow.name_scope", "print", "print", "MetaLoss", "tensorflow.placeholder_with_default", "zip", "tensorflow.name_scope", "tensorflow.gradients", "tensorflow.name_scope", "zip", "meta_dm_train._nested_tuple", "list", "tensorflow.name_scope", "meta_dm_train._make_with_custom_variables", "fx_array.write.write.write", "tensorflow.name_scope", "zip", "tensorflow.name_scope", "range", "state_reshape_mti.append", "enumerate", "loss_array.write.write.write", "range", "loss_array.write.write.stack", "enumerate", "tensorflow.variables_initializer", "fx_array.write.write.close", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.ones", "tensorflow.name_scope", "state.append", "meta_dm_train.MetaOptimizer.meta_loss.update"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._get_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_nets", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], ["", "def", "meta_loss", "(", "self", ",", "\n", "make_loss", ",", "\n", "len_unroll", ",", "\n", "net_assignments", "=", "None", ",", "\n", "second_derivatives", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns an operator computing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      net_assignments: variable to optimizer mapping. If not None, it should be\n          a list of (k, names) tuples, where k is a valid key in the kwargs\n          passed at at construction time and names is a list of variable names.\n      second_derivatives: Use second derivatives (default is false).\n\n    Returns:\n      namedtuple containing (loss, update, reset, fx, x), ...\n    \"\"\"", "\n", "\n", "# Construct an instance of the problem only to grab the variables. This", "\n", "# loss will never be evaluated.", "\n", "# pdb.set_trace()", "\n", "\n", "x", ",", "constants", "=", "_get_variables", "(", "make_loss", ")", "\n", "\n", "print", "(", "\"Optimizee variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "x", "]", ")", "\n", "print", "(", "\"Problem variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "constants", "]", ")", "\n", "\n", "# create scale placeholder here", "\n", "scale", "=", "[", "]", "\n", "for", "k", "in", "x", ":", "\n", "      ", "scale", ".", "append", "(", "tf", ".", "placeholder_with_default", "(", "tf", ".", "ones", "(", "shape", "=", "k", ".", "shape", ")", ",", "shape", "=", "k", ".", "shape", ",", "name", "=", "k", ".", "name", "[", ":", "-", "2", "]", "+", "\"_scale\"", ")", ")", "\n", "\n", "# Create the optimizer networks and find the subsets of variables to assign", "\n", "# to each optimizer.", "\n", "", "nets", ",", "net_keys", ",", "subsets", "=", "_make_nets", "(", "x", ",", "self", ".", "_config", ",", "net_assignments", ")", "\n", "print", "(", "'nets'", ",", "nets", ")", "\n", "print", "(", "'subsets'", ",", "subsets", ")", "\n", "# Store the networks so we can save them later.", "\n", "self", ".", "_nets", "=", "nets", "\n", "\n", "# Create hidden state for each subset of variables.", "\n", "state", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"states\"", ")", ":", "\n", "      ", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "net", "=", "nets", "[", "key", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"state_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "          ", "state", ".", "append", "(", "_nested_variable", "(", "\n", "[", "net", ".", "initial_state_for_inputs", "(", "x", "[", "j", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "j", "in", "subset", "]", ",", "\n", "name", "=", "\"state\"", ",", "trainable", "=", "False", ")", ")", "\n", "\n", "", "", "", "def", "update", "(", "net", ",", "fx", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"Parameter and RNN state update.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"gradients\"", ")", ":", "\n", "        ", "gradients", "=", "tf", ".", "gradients", "(", "fx", ",", "x", ")", "\n", "\n", "# Stopping the gradient here corresponds to what was done in the", "\n", "# original L2L NIPS submission. However it looks like things like", "\n", "# BatchNorm, etc. don't support second-derivatives so we still need", "\n", "# this term.", "\n", "if", "not", "second_derivatives", ":", "\n", "          ", "gradients", "=", "[", "tf", ".", "stop_gradient", "(", "g", ")", "for", "g", "in", "gradients", "]", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", ",", "state_next", "=", "zip", "(", "*", "[", "net", "(", "g", ",", "s", ")", "for", "g", ",", "s", "in", "zip", "(", "gradients", ",", "state", ")", "]", ")", "\n", "state_next", "=", "_nested_tuple", "(", "state_next", ")", "\n", "state_next", "=", "list", "(", "state_next", ")", "\n", "\n", "", "return", "deltas", ",", "state_next", "\n", "\n", "", "def", "time_step", "(", "t", ",", "fx_array", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"While loop body.\"\"\"", "\n", "x_next", "=", "list", "(", "x", ")", "\n", "state_next", "=", "[", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "        ", "scaled_x", "=", "[", "x", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "t", ",", "fx", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"dx\"", ")", ":", "\n", "        ", "for", "subset", ",", "key", ",", "s_i", "in", "zip", "(", "subsets", ",", "net_keys", ",", "state", ")", ":", "\n", "          ", "x_i", "=", "[", "x", "[", "j", "]", "for", "j", "in", "subset", "]", "\n", "deltas", ",", "s_i_next", "=", "update", "(", "nets", "[", "key", "]", ",", "fx", ",", "x_i", ",", "s_i", ")", "\n", "\n", "for", "idx", ",", "j", "in", "enumerate", "(", "subset", ")", ":", "\n", "            ", "delta", "=", "deltas", "[", "idx", "]", "\n", "x_next", "[", "j", "]", "+=", "delta", "\n", "", "state_next", ".", "append", "(", "s_i_next", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"t_next\"", ")", ":", "\n", "        ", "t_next", "=", "t", "+", "1", "\n", "\n", "", "return", "t_next", ",", "fx_array", ",", "x_next", ",", "state_next", "\n", "\n", "# Define the while loop.", "\n", "", "fx_array", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", "+", "1", ",", "\n", "clear_after_read", "=", "False", ")", "\n", "_", ",", "fx_array", ",", "x_final", ",", "s_final", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "(", "0", ",", "fx_array", ",", "x", ",", "state", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "      ", "scaled_x_final", "=", "[", "x_final", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx_final", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x_final", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "len_unroll", ",", "fx_final", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "fx_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss\"", ")", "\n", "\n", "##################################", "\n", "### multi task learning losses ###", "\n", "##################################", "\n", "# state (num_subsets, num_x, (num_layers, (h,c)))", "\n", "# state_reshape (num_mt, num_subsets, (num_layers, (h, c)))", "\n", "state_reshape", "=", "[", "]", "\n", "num_layers", "=", "len", "(", "state", "[", "0", "]", "[", "0", "]", ")", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "state_reshape_mti", "=", "[", "]", "\n", "for", "state_subset", "in", "state", ":", "\n", "        ", "state_layers", "=", "(", ")", "\n", "for", "li", "in", "range", "(", "num_layers", ")", ":", "\n", "          ", "h", "=", "tf", ".", "concat", "(", "[", "st_x", "[", "li", "]", "[", "0", "]", "for", "st_x", "in", "state_subset", "]", ",", "axis", "=", "0", ")", "\n", "c", "=", "tf", ".", "concat", "(", "[", "st_x", "[", "li", "]", "[", "1", "]", "for", "st_x", "in", "state_subset", "]", ",", "axis", "=", "0", ")", "\n", "h", "=", "tf", ".", "Variable", "(", "h", ",", "name", "=", "\"state_reshape_h\"", ",", "trainable", "=", "False", ")", "\n", "c", "=", "tf", ".", "Variable", "(", "c", ",", "name", "=", "\"state_reshape_c\"", ",", "trainable", "=", "False", ")", "\n", "state_layers", "+=", "(", "(", "h", ",", "c", ")", ",", ")", "\n", "", "state_reshape_mti", ".", "append", "(", "state_layers", ")", "\n", "", "state_reshape", ".", "append", "(", "state_reshape_mti", ")", "\n", "", "if", "self", ".", "num_mt", ">", "0", ":", "\n", "      ", "shapes", "=", "[", "st_subset", "[", "0", "]", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "for", "st_subset", "in", "state_reshape", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "      ", "shapes", "=", "[", "]", "\n", "", "num_params_total", "=", "sum", "(", "shapes", ")", "\n", "print", "(", "\"number of parameters = {}\"", ".", "format", "(", "num_params_total", ")", ")", "\n", "\n", "# placeholder (num_mt, num_subsets, len_unroll, num_params)", "\n", "mt_labels", "=", "[", "]", "\n", "mt_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "mt_labels", ".", "append", "(", "\n", "[", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "len_unroll", ",", "shapes", "[", "j", "]", ")", ",", "\n", "name", "=", "\"mt{}_label_subset{}\"", ".", "format", "(", "i", ",", "j", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "subsets", ")", ")", "]", "\n", ")", "\n", "mt_inputs", ".", "append", "(", "\n", "[", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "len_unroll", ",", "shapes", "[", "j", "]", ")", ",", "\n", "name", "=", "\"mt{}_input_subset{}\"", ".", "format", "(", "i", ",", "j", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "subsets", ")", ")", "]", "\n", ")", "\n", "\n", "# loop", "\n", "", "def", "time_step_mt", "(", "mti", ")", ":", "\n", "      ", "def", "time_step_func", "(", "t", ",", "loss_array", ",", "states", ")", ":", "\n", "        ", "loss_t_sum", "=", "0.0", "\n", "state_next", "=", "[", "]", "\n", "for", "si", ",", "(", "k", ",", "st", ")", "in", "enumerate", "(", "zip", "(", "net_keys", ",", "states", ")", ")", ":", "\n", "          ", "net", "=", "nets", "[", "k", "]", "\n", "g_input", "=", "tf", ".", "gather", "(", "mt_inputs", "[", "mti", "]", "[", "si", "]", ",", "indices", "=", "t", ",", "axis", "=", "0", ")", "\n", "g_label", "=", "tf", ".", "gather", "(", "mt_labels", "[", "mti", "]", "[", "si", "]", ",", "indices", "=", "t", ",", "axis", "=", "0", ")", "\n", "delta", ",", "state_next_si", "=", "net", "(", "g_input", ",", "st", ")", "\n", "loss_t_sum", "+=", "tf", ".", "reduce_sum", "(", "(", "g_label", "-", "delta", ")", "*", "(", "g_label", "-", "delta", ")", ")", "*", "0.5", "\n", "state_next_si", "=", "_nested_tuple", "(", "state_next_si", ")", "\n", "state_next", ".", "append", "(", "state_next_si", ")", "\n", "", "loss_t", "=", "loss_t_sum", "/", "num_params_total", "\n", "loss_array", "=", "loss_array", ".", "write", "(", "t", ",", "loss_t", ")", "\n", "t_next", "=", "t", "+", "1", "\n", "return", "t_next", ",", "loss_array", ",", "state_next", "\n", "\n", "", "return", "time_step_func", "\n", "\n", "", "loss_arrays", "=", "[", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", ",", "clear_after_read", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "state_reshape_final", "=", "[", "]", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "loss_array", "=", "loss_arrays", "[", "mti", "]", "\n", "_", ",", "loss_array", ",", "state_reshape_final_mti", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step_mt", "(", "mti", ")", ",", "\n", "loop_vars", "=", "(", "0", ",", "loss_array", ",", "state_reshape", "[", "mti", "]", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll_mt\"", ")", "\n", "loss_arrays", "[", "mti", "]", "=", "loss_array", "\n", "state_reshape_final", ".", "append", "(", "state_reshape_final_mti", ")", "\n", "\n", "# loss", "\n", "", "loss_mt", "=", "[", "tf", ".", "reduce_sum", "(", "loss_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss_mt{}\"", ".", "format", "(", "i", ")", ")", "\n", "for", "i", ",", "loss_array", "in", "enumerate", "(", "loss_arrays", ")", "]", "\n", "\n", "# Reset the state; should be called at the beginning of an epoch.", "\n", "with", "tf", ".", "name_scope", "(", "\"reset\"", ")", ":", "\n", "      ", "variables", "=", "(", "nest", ".", "flatten", "(", "state", ")", "+", "\n", "x", "+", "constants", ")", "\n", "# Empty array as part of the reset process.", "\n", "reset", "=", "[", "tf", ".", "variables_initializer", "(", "variables", ")", ",", "fx_array", ".", "close", "(", ")", "]", "\n", "\n", "# mt", "\n", "variables_mt", "=", "[", "nest", ".", "flatten", "(", "state_reshape", "[", "mti", "]", ")", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "reset_mt", "=", "[", "[", "tf", ".", "variables_initializer", "(", "variables_mt", "[", "mti", "]", ")", ",", "loss_arrays", "[", "mti", "]", ".", "close", "(", ")", "]", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "\n", "# Operator to update the parameters and the RNN state after our loop, but", "\n", "# during an epoch.", "\n", "", "with", "tf", ".", "name_scope", "(", "\"update\"", ")", ":", "\n", "      ", "update", "=", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "x", ",", "x_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state", ",", "s_final", ")", ")", ")", "\n", "update_mt", "=", "[", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_reshape", "[", "mti", "]", ",", "state_reshape_final", "[", "mti", "]", ")", ")", ")", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "\n", "# Log internal variables.", "\n", "", "for", "k", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "      ", "print", "(", "\"Optimizer '{}' variables\"", ".", "format", "(", "k", ")", ")", "\n", "print", "(", "[", "op", "for", "op", "in", "snt", ".", "get_variables_in_module", "(", "net", ")", "]", ")", "\n", "\n", "", "return", "MetaLoss", "(", "loss", ",", "update", ",", "reset", ",", "fx_final", ",", "x_final", ")", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "loss_mt", ",", "update_mt", ",", "reset_mt", ",", "mt_labels", ",", "mt_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train.MetaOptimizer.meta_minimize": [[529, 559], ["meta_dm_train.MetaOptimizer.meta_loss", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "meta_dm_train.MetaOptimizer.restorer", "optimizer_mt.append", "steps_mt.append", "MetaStep", "tensorflow.train.AdamOptimizer", "optimizer_mt[].minimize"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restorer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "meta_minimize", "(", "self", ",", "make_loss", ",", "len_unroll", ",", "learning_rate", "=", "0.01", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns an operator minimizing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      learning_rate: Learning rate for the Adam optimizer.\n      **kwargs: keyword arguments forwarded to meta_loss.\n\n    Returns:\n      namedtuple containing (step, update, reset, fx, x), ...\n    \"\"\"", "\n", "\n", "info", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "loss_mt", ",", "update_mt", ",", "reset_mt", ",", "mt_labels", ",", "mt_inputs", "=", "self", ".", "meta_loss", "(", "make_loss", ",", "len_unroll", ",", "**", "kwargs", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "step", "=", "optimizer", ".", "minimize", "(", "info", ".", "loss", ")", "\n", "\n", "# mt", "\n", "optimizer_mt", "=", "[", "]", "\n", "steps_mt", "=", "[", "]", "\n", "for", "loss_mti", "in", "loss_mt", ":", "\n", "      ", "optimizer_mt", ".", "append", "(", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", ")", "\n", "steps_mt", ".", "append", "(", "optimizer_mt", "[", "-", "1", "]", ".", "minimize", "(", "loss_mti", ")", ")", "\n", "\n", "", "self", ".", "restorer", "(", ")", "\n", "\n", "return", "MetaStep", "(", "step", ",", "*", "info", "[", "1", ":", "]", ")", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "loss_mt", ",", "steps_mt", ",", "update_mt", ",", "reset_mt", ",", "mt_labels", ",", "mt_inputs", "", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._nested_assign": [[36, 59], ["isinstance", "isinstance", "isinstance", "tensorflow.assign", "len", "len", "ValueError", "meta_dm_train._nested_assign", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_assign"], ["def", "_nested_assign", "(", "ref", ",", "value", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow assign operations.\n\n  Args:\n    ref: Nested collection of TensorFlow variables.\n    value: Values to be assigned to the variables. Must have the same structure\n        as `ref`.\n\n  Returns:\n    Nested collection (same structure as `ref`) of TensorFlow assign operations.\n\n  Raises:\n    ValueError: If `ref` and `values` have different structures.\n  \"\"\"", "\n", "if", "isinstance", "(", "ref", ",", "list", ")", "or", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "    ", "if", "len", "(", "ref", ")", "!=", "len", "(", "value", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"ref and value have different lengths.\"", ")", "\n", "", "result", "=", "[", "_nested_assign", "(", "r", ",", "v", ")", "for", "r", ",", "v", "in", "zip", "(", "ref", ",", "value", ")", "]", "\n", "if", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "assign", "(", "ref", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._nested_variable": [[61, 79], ["isinstance", "isinstance", "isinstance", "tensorflow.Variable", "meta_dm_train._nested_variable", "tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_variable"], ["", "", "def", "_nested_variable", "(", "init", ",", "name", "=", "None", ",", "trainable", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow variables.\n\n  Args:\n    init: Nested collection of TensorFlow initializers.\n    name: Variable name.\n    trainable: Make variables trainable (`False` by default).\n\n  Returns:\n    Nested collection (same structure as `init`) of TensorFlow variables.\n  \"\"\"", "\n", "if", "isinstance", "(", "init", ",", "list", ")", "or", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "[", "_nested_variable", "(", "i", ",", "name", ",", "trainable", ")", "for", "i", "in", "init", "]", "\n", "if", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "Variable", "(", "init", ",", "name", "=", "name", ",", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._nested_tuple": [[81, 87], ["isinstance", "isinstance", "tuple", "meta_dm_train._nested_tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple"], ["", "", "def", "_nested_tuple", "(", "elems", ")", ":", "\n", "  ", "if", "isinstance", "(", "elems", ",", "list", ")", "or", "isinstance", "(", "elems", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "tuple", "(", "[", "_nested_tuple", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "\n", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "elems", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._wrap_variable_creation": [[89, 101], ["hasattr", "original_get_variable", "mock.patch", "func", "AttributeError"], "function", ["None"], ["", "", "def", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", ":", "\n", "  ", "\"\"\"Provides a custom getter for all variable creations.\"\"\"", "\n", "original_get_variable", "=", "tf", ".", "get_variable", "\n", "def", "custom_get_variable", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "hasattr", "(", "kwargs", ",", "\"custom_getter\"", ")", ":", "\n", "      ", "raise", "AttributeError", "(", "\"Custom getters are not supported for optimizee \"", "\n", "\"variables.\"", ")", "\n", "", "return", "original_get_variable", "(", "*", "args", ",", "custom_getter", "=", "custom_getter", ",", "**", "kwargs", ")", "\n", "\n", "# Mock the get_variable method.", "\n", "", "with", "mock", ".", "patch", "(", "\"tensorflow.get_variable\"", ",", "custom_get_variable", ")", ":", "\n", "    ", "return", "func", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._get_variables": [[103, 130], ["getter", "tensorflow.name_scope", "meta_dm_train._wrap_variable_creation", "variables.append", "constants.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "_get_variables", "(", "func", ")", ":", "\n", "  ", "\"\"\"Calls func, returning any variables created, but ignoring its return value.\n\n  Args:\n    func: Function to be called.\n\n  Returns:\n    A tuple (variables, constants) where the first element is a list of\n    trainable variables and the second is the non-trainable variables.\n  \"\"\"", "\n", "variables", "=", "[", "]", "\n", "constants", "=", "[", "]", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "trainable", "=", "kwargs", "[", "\"trainable\"", "]", "\n", "kwargs", "[", "\"trainable\"", "]", "=", "False", "\n", "variable", "=", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "if", "trainable", ":", "\n", "      ", "variables", ".", "append", "(", "variable", ")", "\n", "", "else", ":", "\n", "      ", "constants", ".", "append", "(", "variable", ")", "\n", "", "return", "variable", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"unused_graph\"", ")", ":", "\n", "    ", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n", "", "return", "variables", ",", "constants", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._make_with_custom_variables": [[132, 157], ["collections.deque", "meta_dm_train._wrap_variable_creation", "collections.deque.popleft", "getter"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation"], ["", "def", "_make_with_custom_variables", "(", "func", ",", "variables", ")", ":", "\n", "  ", "\"\"\"Calls func and replaces any trainable variables.\n\n  This returns the output of func, but whenever `get_variable` is called it\n  will replace any trainable variables with the tensors in `variables`, in the\n  same order. Non-trainable variables will re-use any variables already\n  created.\n\n  Args:\n    func: Function to be called.\n    variables: A list of tensors replacing the trainable variables.\n\n  Returns:\n    The return value of func is returned.\n  \"\"\"", "\n", "variables", "=", "collections", ".", "deque", "(", "variables", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "[", "\"trainable\"", "]", ":", "\n", "      ", "return", "variables", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "      ", "kwargs", "[", "\"reuse\"", "]", "=", "True", "\n", "return", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_dm_train._make_nets": [[163, 218], ["dict", "len", "ValueError", "tensorflow.variable_scope", "next", "networks.factory", "range", "tensorflow.variable_scope", "enumerate", "iter", "len", "networks.factory", "keys.append", "subsets.append", "print", "v.name.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "_make_nets", "(", "variables", ",", "config", ",", "net_assignments", ")", ":", "\n", "  ", "\"\"\"Creates the optimizer networks.\n\n  Args:\n    variables: A list of variables to be optimized.\n    config: A dictionary of network configurations, each of which will be\n        passed to networks.Factory to construct a single optimizer net.\n    net_assignments: A list of tuples where each tuple is of the form (netid,\n        variable_names) and is used to assign variables to networks. netid must\n        be a key in config.\n\n  Returns:\n    A tuple (nets, keys, subsets) where nets is a dictionary of created\n    optimizer nets such that the net with key keys[i] should be applied to the\n    subset of variables listed in subsets[i].\n\n  Raises:\n    ValueError: If net_assignments is None and the configuration defines more\n        than one network.\n  \"\"\"", "\n", "# create a dictionary which maps a variable name to its index within the", "\n", "# list of variables.", "\n", "name_to_index", "=", "dict", "(", "(", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ",", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "variables", ")", ")", "\n", "\n", "if", "net_assignments", "is", "None", ":", "\n", "    ", "if", "len", "(", "config", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Default net_assignments can only be used if there is \"", "\n", "\"a single net config.\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "key", "=", "next", "(", "iter", "(", "config", ")", ")", "\n", "kwargs", "=", "config", "[", "key", "]", "\n", "net", "=", "networks", ".", "factory", "(", "**", "kwargs", ")", "\n", "\n", "", "nets", "=", "{", "key", ":", "net", "}", "\n", "keys", "=", "[", "key", "]", "\n", "subsets", "=", "[", "range", "(", "len", "(", "variables", ")", ")", "]", "\n", "", "else", ":", "\n", "    ", "nets", "=", "{", "}", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "for", "key", ",", "names", "in", "net_assignments", ":", "\n", "        ", "if", "key", "in", "nets", ":", "\n", "          ", "raise", "ValueError", "(", "\"Repeated netid in net_assigments.\"", ")", "\n", "", "nets", "[", "key", "]", "=", "networks", ".", "factory", "(", "**", "config", "[", "key", "]", ")", "\n", "subset", "=", "[", "name_to_index", "[", "name", "]", "for", "name", "in", "names", "]", "\n", "keys", ".", "append", "(", "key", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "print", "(", "\"Net: {}, Subset: {}\"", ".", "format", "(", "key", ",", "subset", ")", ")", "\n", "\n", "# subsets should be a list of disjoint subsets (as lists!) of the variables", "\n", "# and nets should be a list of networks to apply to each subset.", "\n", "", "", "", "return", "nets", ",", "keys", ",", "subsets", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.evaluate_rnnprop.main": [[51, 108], ["util.get_config", "tensorflow.ConfigProto", "print", "tensorflow.set_random_seed", "problem", "tensorflow.get_collection", "tensorflow.variables_initializer", "tensorflow.train.AdamOptimizer", "tensorflow.variables_initializer", "meta.MetaOptimizer.minimize", "tensorflow.contrib.learn.python.learn.monitored_session.MonitoredSession", "sess.run", "tensorflow.get_default_graph().finalize", "six.moves.xrange", "util.print_stats", "open", "pickle.dump", "meta.MetaOptimizer.get_slot_names", "meta_rnnprop_eval.MetaOptimizer", "meta.MetaOptimizer.meta_loss", "ValueError", "util.run_eval_epoch", "os.path.exists", "os.mkdir", "logging.warning", "tensorflow.get_default_graph", "sum"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.print_stats", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.run_eval_epoch"], ["def", "main", "(", "_", ")", ":", "\n", "# Configuration.", "\n", "    ", "num_unrolls", "=", "FLAGS", ".", "num_steps", "\n", "if", "FLAGS", ".", "seed", ":", "\n", "        ", "tf", ".", "set_random_seed", "(", "FLAGS", ".", "seed", ")", "\n", "\n", "# Problem.", "\n", "", "problem", ",", "net_config", ",", "net_assignments", "=", "util", ".", "get_config", "(", "FLAGS", ".", "problem", ",", "FLAGS", ".", "path", ",", "net_name", "=", "\"RNNprop\"", ")", "\n", "\n", "# Optimizer setup.", "\n", "if", "FLAGS", ".", "optimizer", "==", "\"Adam\"", ":", "\n", "        ", "cost_op", "=", "problem", "(", ")", "\n", "problem_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "problem_reset", "=", "tf", ".", "variables_initializer", "(", "problem_vars", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "FLAGS", ".", "learning_rate", ")", "\n", "optimizer_reset", "=", "tf", ".", "variables_initializer", "(", "optimizer", ".", "get_slot_names", "(", ")", ")", "\n", "update", "=", "optimizer", ".", "minimize", "(", "cost_op", ")", "\n", "reset", "=", "[", "problem_reset", ",", "optimizer_reset", "]", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "\"L2L\"", ":", "\n", "        ", "if", "FLAGS", ".", "path", "is", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Evaluating untrained L2L optimizer\"", ")", "\n", "", "optimizer", "=", "meta", ".", "MetaOptimizer", "(", "FLAGS", ".", "beta1", ",", "FLAGS", ".", "beta2", ",", "**", "net_config", ")", "\n", "meta_loss", ",", "_", ",", "_", ",", "step", "=", "optimizer", ".", "meta_loss", "(", "problem", ",", "1", ",", "net_assignments", "=", "net_assignments", ")", "\n", "_", ",", "update", ",", "reset", ",", "cost_op", ",", "_", "=", "meta_loss", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"{} is not a valid optimizer\"", ".", "format", "(", "FLAGS", ".", "optimizer", ")", ")", "\n", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "ms", ".", "MonitoredSession", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "reset", ")", "\n", "# Prevent accidental changes to the graph.", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "\n", "total_time", "=", "0", "\n", "total_cost", "=", "0", "\n", "loss_record", "=", "[", "]", "\n", "for", "e", "in", "xrange", "(", "FLAGS", ".", "num_epochs", ")", ":", "\n", "# Training.", "\n", "            ", "time", ",", "cost", "=", "util", ".", "run_eval_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "\n", "num_unrolls", ",", "step", "=", "step", ",", "unroll_len", "=", "1", ")", "\n", "total_time", "+=", "time", "\n", "total_cost", "+=", "sum", "(", "cost", ")", "/", "num_unrolls", "\n", "loss_record", "+=", "cost", "\n", "\n", "# Results.", "\n", "", "util", ".", "print_stats", "(", "\"Epoch {}\"", ".", "format", "(", "FLAGS", ".", "num_epochs", ")", ",", "total_cost", ",", "\n", "total_time", ",", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_path", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "output_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "FLAGS", ".", "output_path", ")", "\n", "", "", "output_file", "=", "'{}/{}_eval_loss_record.pickle-{}'", ".", "format", "(", "FLAGS", ".", "output_path", ",", "FLAGS", ".", "optimizer", ",", "FLAGS", ".", "problem", ")", "\n", "with", "open", "(", "output_file", ",", "'wb'", ")", "as", "l_record", ":", "\n", "        ", "pickle", ".", "dump", "(", "loss_record", ",", "l_record", ")", "\n", "", "print", "(", "\"Saving evaluate loss record {}\"", ".", "format", "(", "output_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.VGG16.__init__": [[46, 50], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "keep_prob", ",", "num_classes", ")", ":", "\n", "\n", "    ", "self", ".", "KEEP_PROB", "=", "keep_prob", "\n", "self", ".", "NUM_CLASSES", "=", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.VGG16._build_model": [[51, 99], ["vgg16.conv_layer", "vgg16.conv_layer", "vgg16.max_pool", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.max_pool", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.max_pool", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.max_pool", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.conv_layer", "vgg16.max_pool", "tensorflow.reshape", "vgg16.fc_layer"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.fc_layer"], ["", "def", "_build_model", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "# Block 1", "\n", "    ", "block1_conv1", "=", "conv_layer", "(", "inputs", ",", "64", ",", "name", "=", "'block1_conv1'", ")", "\n", "block1_conv2", "=", "conv_layer", "(", "block1_conv1", ",", "64", ",", "name", "=", "'block1_conv2'", ")", "\n", "block1_pool", "=", "max_pool", "(", "block1_conv2", ",", "name", "=", "'block1_pool'", ")", "\n", "\n", "# Block 2", "\n", "block2_conv1", "=", "conv_layer", "(", "block1_pool", ",", "128", ",", "name", "=", "'block2_conv1'", ")", "\n", "block2_conv2", "=", "conv_layer", "(", "block2_conv1", ",", "128", ",", "name", "=", "'block2_conv2'", ")", "\n", "block2_pool", "=", "max_pool", "(", "block2_conv2", ",", "name", "=", "'block2_pool'", ")", "\n", "\n", "# Block 3", "\n", "block3_conv1", "=", "conv_layer", "(", "block2_pool", ",", "256", ",", "name", "=", "'block3_conv1'", ")", "\n", "block3_conv2", "=", "conv_layer", "(", "block3_conv1", ",", "256", ",", "name", "=", "'block3_conv2'", ")", "\n", "block3_conv3", "=", "conv_layer", "(", "block3_conv2", ",", "256", ",", "name", "=", "'block3_conv3'", ")", "\n", "block3_pool", "=", "max_pool", "(", "block3_conv3", ",", "name", "=", "'block3_pool'", ")", "\n", "\n", "# Block 4", "\n", "block4_conv1", "=", "conv_layer", "(", "block3_pool", ",", "512", ",", "name", "=", "'block4_conv1'", ")", "\n", "block4_conv2", "=", "conv_layer", "(", "block4_conv1", ",", "512", ",", "name", "=", "'block4_conv2'", ")", "\n", "block4_conv3", "=", "conv_layer", "(", "block4_conv2", ",", "512", ",", "name", "=", "'block4_conv3'", ")", "\n", "block4_pool", "=", "max_pool", "(", "block4_conv3", ",", "name", "=", "'block4_pool'", ")", "\n", "\n", "# Block 5", "\n", "block5_conv1", "=", "conv_layer", "(", "block4_pool", ",", "512", ",", "name", "=", "'block5_conv1'", ")", "\n", "block5_conv2", "=", "conv_layer", "(", "block5_conv1", ",", "512", ",", "name", "=", "'block5_conv2'", ")", "\n", "block5_conv3", "=", "conv_layer", "(", "block5_conv2", ",", "512", ",", "name", "=", "'block5_conv3'", ")", "\n", "block5_pool", "=", "max_pool", "(", "block5_conv3", ",", "name", "=", "'block5_pool'", ")", "\n", "\n", "# Full connection layers", "\n", "\n", "# In the original paper implementaion this will be:", "\n", "#flattened = tf.reshape(block5_pool, [-1, 7*7*512]) ", "\n", "#fc1 = fc_layer(flattened, 7*7*512, 7*7*512, name = 'fc1')", "\n", "flattened", "=", "tf", ".", "reshape", "(", "block5_pool", ",", "[", "-", "1", ",", "1", "*", "1", "*", "512", "]", ")", "\n", "# fc1 = fc_layer(flattened, 1*1*512, 1*1*512, name = 'fc1', activation = 'relu')", "\n", "# dropout1 = dropout(fc1, self.KEEP_PROB)", "\n", "\n", "# In the original paper implementaion this will be:", "\n", "#fc2 = fc_layer(dropout1, 7*7*512, 7*7*512, name = 'fc1')", "\n", "# fc2 = fc_layer(dropout1, 1*1*512, 1*1*512, name = 'fc2', activation = 'relu')", "\n", "# dropout2 = dropout(fc2, self.KEEP_PROB)", "\n", "\n", "# In the original paper implementaion this will be:", "\n", "#self.fc3 = fc_layer(dropout2, 7*7*512, self.NUM_CLASSES, name = 'fc3', relu = False)", "\n", "fc", "=", "fc_layer", "(", "flattened", ",", "1", "*", "1", "*", "512", ",", "self", ".", "NUM_CLASSES", ",", "name", "=", "'fc'", ",", "activation", "=", "'softmax'", ")", "\n", "return", "fc", "", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer": [[2, 17], ["int", "tensorflow.nn.conv2d", "tensorflow.nn.bias_add", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "x.get_shape", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["def", "conv_layer", "(", "x", ",", "num_filters", ",", "name", ",", "filter_height", "=", "3", ",", "filter_width", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "\n", "  ", "input_channels", "=", "int", "(", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "    ", "W", "=", "tf", ".", "get_variable", "(", "'weights'", ",", "shape", "=", "[", "filter_height", ",", "filter_width", ",", "input_channels", ",", "num_filters", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0", ",", "stddev", "=", "0.01", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "shape", "=", "[", "num_filters", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "\n", "z", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "b", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "z", ",", "name", "=", "scope", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.fc_layer": [[18, 35], ["tensorflow.nn.bias_add", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.nn.relu", "tensorflow.nn.softmax", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["", "def", "fc_layer", "(", "x", ",", "input_size", ",", "output_size", ",", "name", ",", "activation", "=", "'relu'", ")", ":", "\n", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "    ", "W", "=", "tf", ".", "get_variable", "(", "'weights'", ",", "shape", "=", "[", "input_size", ",", "output_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0", ",", "stddev", "=", "0.01", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'biases'", ",", "shape", "=", "[", "output_size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "\n", "", "z", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "x", ",", "W", ")", ",", "b", ",", "name", "=", "scope", ".", "name", ")", "\n", "\n", "if", "activation", "==", "'relu'", ":", "\n", "# Apply ReLu non linearity.", "\n", "    ", "return", "tf", ".", "nn", ".", "relu", "(", "z", ",", "name", "=", "scope", ".", "name", ")", "\n", "", "elif", "activation", "==", "'softmax'", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "softmax", "(", "z", ",", "name", "=", "scope", ".", "name", ")", "\n", "", "else", ":", "\n", "    ", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool": [[36, 40], ["tensorflow.nn.max_pool"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool"], ["", "", "def", "max_pool", "(", "x", ",", "name", ",", "filter_height", "=", "2", ",", "filter_width", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ")", ":", "\n", "  ", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "ksize", "=", "[", "1", ",", "filter_height", ",", "filter_width", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.dropout": [[41, 43], ["tensorflow.nn.dropout"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.dropout"], ["", "def", "dropout", "(", "x", ",", "keep_prob", ")", ":", "\n", "  ", "return", "tf", ".", "nn", ".", "dropout", "(", "x", ",", "keep_prob", "=", "keep_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Network.initial_state_for_inputs": [[69, 73], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Initial state given inputs.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.StandardDeepLSTM.__init__": [[157, 206], ["sonnet.RNNCore.__init__", "hasattr", "tensorflow.variable_scope", "enumerate", "sonnet.DeepRNN", "networks._get_layer_initializers", "sonnet.Linear", "tensorflow.variable_scope", "networks._get_layer_initializers", "sonnet.Linear", "getattr", "getattr.", "getattr", "networks._get_layer_initializers", "networks.StandardDeepLSTM._cores.append", "sonnet.LSTM"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_layer_initializers", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_layer_initializers", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_layer_initializers", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "__init__", "(", "self", ",", "output_size", ",", "layers", ",", "preprocess_name", "=", "\"identity\"", ",", "\n", "preprocess_options", "=", "None", ",", "scale", "=", "1.0", ",", "initializer", "=", "None", ",", "\n", "name", "=", "\"deep_lstm\"", ",", "tanh_output", "=", "False", ")", ":", "\n", "    ", "\"\"\"Creates an instance of `StandardDeepLSTM`.\n\n    Args:\n      output_size: Output sizes of the final linear layer.\n      layers: Output sizes of LSTM layers.\n      preprocess_name: Gradient preprocessing class name (in `l2l.preprocess` or\n          tf modules). Default is `tf.identity`.\n      preprocess_options: Gradient preprocessing options.\n      scale: Gradient scaling (default is 1.0).\n      initializer: Variable initializer for linear layer. See `snt.Linear` and\n          `snt.LSTM` docs for more info. This parameter can be a string (e.g.\n          \"zeros\" will be converted to tf.zeros_initializer).\n      name: Module name.\n    \"\"\"", "\n", "super", "(", "StandardDeepLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_scale", "=", "scale", "\n", "self", ".", "_preprocess_name", "=", "preprocess_name", "\n", "\n", "if", "preprocess_name", "==", "'fc'", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "self", ".", "_template", ".", "variable_scope", ")", ":", "\n", "        ", "init", "=", "_get_layer_initializers", "(", "initializer", ",", "\"input_projection\"", ",", "(", "\"w\"", ",", "\"b\"", ")", ")", "\n", "self", ".", "_preprocess", "=", "snt", ".", "Linear", "(", "preprocess_options", "[", "\"dim\"", "]", ",", "name", "=", "\"input_projection\"", ",", "initializers", "=", "init", ")", "\n", "", "", "elif", "hasattr", "(", "preprocess", ",", "preprocess_name", ")", ":", "\n", "      ", "preprocess_class", "=", "getattr", "(", "preprocess", ",", "preprocess_name", ")", "\n", "self", ".", "_preprocess", "=", "preprocess_class", "(", "initializer", ",", "**", "preprocess_options", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_preprocess", "=", "getattr", "(", "tf", ",", "preprocess_name", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_template", ".", "variable_scope", ")", ":", "\n", "\n", "      ", "self", ".", "_cores", "=", "[", "]", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "layers", ",", "start", "=", "1", ")", ":", "\n", "        ", "name", "=", "\"lstm_{}\"", ".", "format", "(", "i", ")", "\n", "init", "=", "_get_layer_initializers", "(", "initializer", ",", "name", ",", "\n", "(", "\"w_gates\"", ",", "\"b_gates\"", ")", ")", "\n", "self", ".", "_cores", ".", "append", "(", "snt", ".", "LSTM", "(", "size", ",", "name", "=", "name", ",", "initializers", "=", "init", ")", ")", "\n", "\n", "", "self", ".", "_rnn", "=", "snt", ".", "DeepRNN", "(", "self", ".", "_cores", ",", "skip_connections", "=", "False", ",", "\n", "name", "=", "\"deep_rnn\"", ")", "\n", "\n", "init", "=", "_get_layer_initializers", "(", "initializer", ",", "\"linear\"", ",", "(", "\"w\"", ",", "\"b\"", ")", ")", "\n", "self", ".", "_linear", "=", "snt", ".", "Linear", "(", "output_size", ",", "name", "=", "\"linear\"", ",", "initializers", "=", "init", ")", "\n", "\n", "self", ".", "tanh_output", "=", "tanh_output", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.StandardDeepLSTM._build": [[207, 233], ["tensorflow.reshape", "networks.StandardDeepLSTM._rnn", "networks.StandardDeepLSTM._linear", "tensorflow.nn.elu", "networks.StandardDeepLSTM._preprocess", "networks.StandardDeepLSTM._preprocess", "tensorflow.expand_dims", "networks.StandardDeepLSTM.get_shape().as_list", "tensorflow.nn.tanh", "networks.StandardDeepLSTM.get_shape"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "", "def", "_build", "(", "self", ",", "inputs", ",", "prev_state", ")", ":", "\n", "    ", "\"\"\"Connects the `StandardDeepLSTM` module into the graph.\n\n    Args:\n      inputs: 2D `Tensor` ([batch_size, input_size]).\n      prev_state: `DeepRNN` state.\n\n    Returns:\n      `Tensor` shaped as `inputs`.\n    \"\"\"", "\n", "# Adds preprocessing dimension and preprocess.", "\n", "if", "self", ".", "_preprocess_name", "==", "\"fc\"", ":", "\n", "      ", "inputs", "=", "tf", ".", "nn", ".", "elu", "(", "self", ".", "_preprocess", "(", "inputs", ")", ")", "\n", "", "else", ":", "\n", "      ", "inputs", "=", "self", ".", "_preprocess", "(", "tf", ".", "expand_dims", "(", "inputs", ",", "-", "1", ")", ")", "\n", "\n", "# Incorporates preprocessing into data dimension.", "\n", "", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "output", ",", "next_state", "=", "self", ".", "_rnn", "(", "inputs", ",", "prev_state", ")", "\n", "\n", "final_output", "=", "self", ".", "_linear", "(", "output", ")", "\n", "\n", "if", "self", ".", "tanh_output", ":", "\n", "      ", "return", "tf", ".", "nn", ".", "tanh", "(", "final_output", ")", "*", "self", ".", "_scale", ",", "next_state", "\n", "", "else", ":", "\n", "      ", "return", "final_output", "*", "self", ".", "_scale", ",", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.StandardDeepLSTM.initial_state_for_inputs": [[234, 237], ["networks.StandardDeepLSTM._rnn.initial_state", "inputs.get_shape().as_list", "inputs.get_shape"], "methods", ["None"], ["", "", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "batch_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "return", "self", ".", "_rnn", ".", "initial_state", "(", "batch_size", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.CoordinateWiseDeepLSTM.__init__": [[242, 250], ["networks.StandardDeepLSTM.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "\"cw_deep_lstm\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates an instance of `CoordinateWiseDeepLSTM`.\n\n    Args:\n      name: Module name.\n      **kwargs: Additional `DeepLSTM` args.\n    \"\"\"", "\n", "super", "(", "CoordinateWiseDeepLSTM", ",", "self", ")", ".", "__init__", "(", "1", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.CoordinateWiseDeepLSTM._reshape_inputs": [[251, 253], ["tensorflow.reshape"], "methods", ["None"], ["", "def", "_reshape_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.CoordinateWiseDeepLSTM._build": [[254, 272], ["inputs.get_shape().as_list", "networks.CoordinateWiseDeepLSTM._reshape_inputs", "build_fn", "tensorflow.reshape", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "prev_state", ")", ":", "\n", "    ", "\"\"\"Connects the CoordinateWiseDeepLSTM module into the graph.\n\n    Args:\n      inputs: Arbitrarily shaped `Tensor`.\n      prev_state: `DeepRNN` state.\n\n    Returns:\n      `Tensor` shaped as `inputs`.\n    \"\"\"", "\n", "input_shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "reshaped_inputs", "=", "self", ".", "_reshape_inputs", "(", "inputs", ")", "\n", "\n", "build_fn", "=", "super", "(", "CoordinateWiseDeepLSTM", ",", "self", ")", ".", "_build", "\n", "output", ",", "next_state", "=", "build_fn", "(", "reshaped_inputs", ",", "prev_state", ")", "\n", "\n", "# Recover original shape.", "\n", "return", "tf", ".", "reshape", "(", "output", ",", "input_shape", ")", ",", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.CoordinateWiseDeepLSTM.initial_state_for_inputs": [[273, 277], ["networks.CoordinateWiseDeepLSTM._reshape_inputs", "networks.StandardDeepLSTM.initial_state_for_inputs"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam.initial_state_for_inputs"], ["", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "reshaped_inputs", "=", "self", ".", "_reshape_inputs", "(", "inputs", ")", "\n", "return", "super", "(", "CoordinateWiseDeepLSTM", ",", "self", ")", ".", "initial_state_for_inputs", "(", "\n", "reshaped_inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.RNNprop.__init__": [[281, 283], ["networks.StandardDeepLSTM.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["  ", "def", "__init__", "(", "self", ",", "name", "=", "\"RNNprop\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", "RNNprop", ",", "self", ")", ".", "__init__", "(", "1", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.RNNprop._reshape_inputs": [[284, 286], ["tensorflow.reshape"], "methods", ["None"], ["", "def", "_reshape_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.RNNprop._build": [[287, 296], ["g.get_shape().as_list", "tensorflow.concat", "networks.RNNprop._reshape_inputs", "build_fn", "tensorflow.reshape", "g.get_shape", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs"], ["", "def", "_build", "(", "self", ",", "m", ",", "g", ",", "prev_state", ")", ":", "\n", "    ", "output_shape", "=", "g", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "inputs", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "m", ",", "-", "1", ")", ",", "tf", ".", "expand_dims", "(", "g", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "reshaped_inputs", "=", "self", ".", "_reshape_inputs", "(", "inputs", ")", "\n", "build_fn", "=", "super", "(", "RNNprop", ",", "self", ")", ".", "_build", "\n", "output", ",", "next_state", "=", "build_fn", "(", "reshaped_inputs", ",", "prev_state", ")", "\n", "\n", "# Recover original shape.", "\n", "return", "tf", ".", "reshape", "(", "output", ",", "output_shape", ")", ",", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.RNNprop.initial_state_for_inputs": [[297, 301], ["tensorflow.reshape", "networks.StandardDeepLSTM.initial_state_for_inputs"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam.initial_state_for_inputs"], ["", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "reshaped_inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "return", "super", "(", "RNNprop", ",", "self", ")", ".", "initial_state_for_inputs", "(", "\n", "reshaped_inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM.__init__": [[311, 322], ["numpy.prod", "networks.StandardDeepLSTM.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "kernel_shape", ",", "name", "=", "\"kernel_deep_lstm\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates an instance of `KernelDeepLSTM`.\n\n    Args:\n      kernel_shape: Kernel shape (2D `tuple`).\n      name: Module name.\n      **kwargs: Additional `DeepLSTM` args.\n    \"\"\"", "\n", "self", ".", "_kernel_shape", "=", "kernel_shape", "\n", "output_size", "=", "np", ".", "prod", "(", "kernel_shape", ")", "\n", "super", "(", "KernelDeepLSTM", ",", "self", ")", ".", "__init__", "(", "output_size", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs": [[323, 326], ["tensorflow.transpose", "tensorflow.reshape"], "methods", ["None"], ["", "def", "_reshape_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "transposed_inputs", "=", "tf", ".", "transpose", "(", "inputs", ",", "perm", "=", "[", "2", ",", "3", ",", "0", ",", "1", "]", ")", "\n", "return", "tf", ".", "reshape", "(", "transposed_inputs", ",", "[", "-", "1", "]", "+", "self", ".", "_kernel_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._build": [[327, 346], ["inputs.get_shape().as_list", "networks.KernelDeepLSTM._reshape_inputs", "build_fn", "tensorflow.transpose", "tensorflow.reshape", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "prev_state", ")", ":", "\n", "    ", "\"\"\"Connects the KernelDeepLSTM module into the graph.\n\n    Args:\n      inputs: 4D `Tensor` (convolutional filter).\n      prev_state: `DeepRNN` state.\n\n    Returns:\n      `Tensor` shaped as `inputs`.\n    \"\"\"", "\n", "input_shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "reshaped_inputs", "=", "self", ".", "_reshape_inputs", "(", "inputs", ")", "\n", "\n", "build_fn", "=", "super", "(", "KernelDeepLSTM", ",", "self", ")", ".", "_build", "\n", "output", ",", "next_state", "=", "build_fn", "(", "reshaped_inputs", ",", "prev_state", ")", "\n", "transposed_output", "=", "tf", ".", "transpose", "(", "output", ",", "[", "1", ",", "0", "]", ")", "\n", "\n", "# Recover original shape.", "\n", "return", "tf", ".", "reshape", "(", "transposed_output", ",", "input_shape", ")", ",", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM.initial_state_for_inputs": [[347, 352], ["networks.KernelDeepLSTM._reshape_inputs", "networks.StandardDeepLSTM.initial_state_for_inputs"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.KernelDeepLSTM._reshape_inputs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam.initial_state_for_inputs"], ["", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Batch size given inputs.\"\"\"", "\n", "reshaped_inputs", "=", "self", ".", "_reshape_inputs", "(", "inputs", ")", "\n", "return", "super", "(", "KernelDeepLSTM", ",", "self", ")", ".", "initial_state_for_inputs", "(", "\n", "reshaped_inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Sgd.__init__": [[357, 366], ["sonnet.RNNCore.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "learning_rate", "=", "0.001", ",", "name", "=", "\"sgd\"", ")", ":", "\n", "    ", "\"\"\"Creates an instance of the Identity optimizer network.\n\n    Args:\n      learning_rate: constant learning rate to use.\n      name: Module name.\n    \"\"\"", "\n", "super", "(", "Sgd", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Sgd._build": [[367, 369], ["None"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "_", ")", ":", "\n", "    ", "return", "-", "self", ".", "_learning_rate", "*", "inputs", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Sgd.initial_state_for_inputs": [[370, 372], ["None"], "methods", ["None"], ["", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam.__init__": [[385, 393], ["sonnet.RNNCore.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "learning_rate", "=", "1e-3", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ",", "\n", "name", "=", "\"adam\"", ")", ":", "\n", "    ", "\"\"\"Creates an instance of Adam.\"\"\"", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_beta1", "=", "beta1", "\n", "self", ".", "_beta2", "=", "beta2", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam._build": [[394, 414], ["tensorflow.reshape.get_shape().as_list", "tensorflow.reshape", "networks._update_adam_estimate", "networks._debias_adam_estimate", "networks._update_adam_estimate", "networks._debias_adam_estimate", "tensorflow.square", "tensorflow.reshape", "tensorflow.reshape.get_shape", "tensorflow.sqrt"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._update_adam_estimate", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._debias_adam_estimate", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._update_adam_estimate", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._debias_adam_estimate", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square"], ["", "def", "_build", "(", "self", ",", "g", ",", "prev_state", ")", ":", "\n", "    ", "\"\"\"Connects the Adam module into the graph.\"\"\"", "\n", "b1", "=", "self", ".", "_beta1", "\n", "b2", "=", "self", ".", "_beta2", "\n", "\n", "g_shape", "=", "g", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "g", "=", "tf", ".", "reshape", "(", "g", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "t", ",", "m", ",", "v", "=", "prev_state", "\n", "\n", "t_next", "=", "t", "+", "1", "\n", "\n", "m_next", "=", "_update_adam_estimate", "(", "m", ",", "g", ",", "b1", ")", "\n", "m_hat", "=", "_debias_adam_estimate", "(", "m_next", ",", "b1", ",", "t_next", ")", "\n", "\n", "v_next", "=", "_update_adam_estimate", "(", "v", ",", "tf", ".", "square", "(", "g", ")", ",", "b2", ")", "\n", "v_hat", "=", "_debias_adam_estimate", "(", "v_next", ",", "b2", ",", "t_next", ")", "\n", "\n", "update", "=", "-", "self", ".", "_learning_rate", "*", "m_hat", "/", "(", "tf", ".", "sqrt", "(", "v_hat", ")", "+", "self", ".", "_epsilon", ")", "\n", "return", "tf", ".", "reshape", "(", "update", ",", "g_shape", ")", ",", "(", "t_next", ",", "m_next", ",", "v_next", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.Adam.initial_state_for_inputs": [[415, 421], ["int", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "numpy.prod", "inputs.get_shape().as_list", "inputs.get_shape"], "methods", ["None"], ["", "def", "initial_state_for_inputs", "(", "self", ",", "inputs", ",", "dtype", "=", "tf", ".", "float32", ",", "**", "kwargs", ")", ":", "\n", "    ", "batch_size", "=", "int", "(", "np", ".", "prod", "(", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "t", "=", "tf", ".", "zeros", "(", "(", ")", ",", "dtype", "=", "dtype", ")", "\n", "m", "=", "tf", ".", "zeros", "(", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "dtype", ")", "\n", "v", "=", "tf", ".", "zeros", "(", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "dtype", ")", "\n", "return", "(", "t", ",", "m", ",", "v", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory": [[34, 45], ["getattr", "dict", "getattr.", "open", "dill.load"], "function", ["None"], ["def", "factory", "(", "net", ",", "net_options", "=", "(", ")", ",", "net_path", "=", "None", ")", ":", "\n", "  ", "\"\"\"Network factory.\"\"\"", "\n", "\n", "net_class", "=", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "net", ")", "\n", "net_options", "=", "dict", "(", "net_options", ")", "\n", "\n", "if", "net_path", ":", "\n", "    ", "with", "open", "(", "net_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "net_options", "[", "\"initializer\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "", "return", "net_class", "(", "**", "net_options", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.save": [[47, 63], ["collections.defaultdict", "sonnet.get_variables_in_module", "[].split", "v.eval", "open", "dill.dump", "v.name.split"], "function", ["None"], ["", "def", "save", "(", "network", ",", "sess", ",", "filename", "=", "None", ")", ":", "\n", "  ", "\"\"\"Save the variables contained by a network to disk.\"\"\"", "\n", "to_save", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "variables", "=", "snt", ".", "get_variables_in_module", "(", "network", ")", "\n", "\n", "for", "v", "in", "variables", ":", "\n", "    ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "to_save", "[", "module_name", "]", "[", "variable_name", "]", "=", "v", ".", "eval", "(", "sess", ")", "\n", "\n", "", "if", "filename", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "to_save", ",", "f", ")", "\n", "\n", "", "", "return", "to_save", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._convert_to_initializer": [[75, 96], ["isinstance", "isinstance", "getattr", "tensorflow.constant_initializer"], "function", ["None"], ["", "", "def", "_convert_to_initializer", "(", "initializer", ")", ":", "\n", "  ", "\"\"\"Returns a TensorFlow initializer.\n\n  * Corresponding TensorFlow initializer when the argument is a string (e.g.\n  \"zeros\" -> `tf.zeros_initializer`).\n  * `tf.constant_initializer` when the argument is a `numpy` `array`.\n  * Identity when the argument is a TensorFlow initializer.\n\n  Args:\n    initializer: `string`, `numpy` `array` or TensorFlow initializer.\n\n  Returns:\n    TensorFlow initializer.\n  \"\"\"", "\n", "\n", "if", "isinstance", "(", "initializer", ",", "str", ")", ":", "\n", "    ", "return", "getattr", "(", "tf", ",", "initializer", "+", "\"_initializer\"", ")", "(", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "isinstance", "(", "initializer", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "return", "tf", ".", "constant_initializer", "(", "initializer", ")", "\n", "", "else", ":", "\n", "    ", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_initializers": [[98, 124], ["isinstance", "networks._convert_to_initializer", "networks._convert_to_initializer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._convert_to_initializer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._convert_to_initializer"], ["", "", "def", "_get_initializers", "(", "initializers", ",", "fields", ")", ":", "\n", "  ", "\"\"\"Produces a nn initialization `dict` (see Linear docs for a example).\n\n  Grabs initializers for relevant fields if the first argument is a `dict` or\n  reuses the same initializer for all fields otherwise. All initializers are\n  processed using `_convert_to_initializer`.\n\n  Args:\n    initializers: Initializer or <variable, initializer> dictionary.\n    fields: Fields nn is expecting for module initialization.\n\n  Returns:\n    nn initialization dictionary.\n  \"\"\"", "\n", "\n", "result", "=", "{", "}", "\n", "for", "f", "in", "fields", ":", "\n", "    ", "if", "isinstance", "(", "initializers", ",", "dict", ")", ":", "\n", "      ", "if", "f", "in", "initializers", ":", "\n", "# Variable-specific initializer.", "\n", "        ", "result", "[", "f", "]", "=", "_convert_to_initializer", "(", "initializers", "[", "f", "]", ")", "\n", "", "", "else", ":", "\n", "# Common initiliazer for all variables.", "\n", "      ", "result", "[", "f", "]", "=", "_convert_to_initializer", "(", "initializers", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_layer_initializers": [[126, 152], ["networks._get_initializers", "isinstance", "networks._get_initializers"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_initializers", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._get_initializers"], ["", "def", "_get_layer_initializers", "(", "initializers", ",", "layer_name", ",", "fields", ")", ":", "\n", "  ", "\"\"\"Produces a nn initialization dictionary for a layer.\n\n  Calls `_get_initializers using initializers[layer_name]` if `layer_name` is a\n  valid key or using initializers otherwise (reuses initializers between\n  layers).\n\n  Args:\n    initializers: Initializer, <variable, initializer> dictionary,\n        <layer, initializer> dictionary.\n    layer_name: Layer name.\n    fields: Fields nn is expecting for module initialization.\n\n  Returns:\n    nn initialization dictionary.\n  \"\"\"", "\n", "\n", "# No initializers specified.", "\n", "if", "initializers", "is", "None", ":", "\n", "    ", "return", "None", "\n", "\n", "# Layer-specific initializer.", "\n", "", "if", "isinstance", "(", "initializers", ",", "dict", ")", "and", "layer_name", "in", "initializers", ":", "\n", "    ", "return", "_get_initializers", "(", "initializers", "[", "layer_name", "]", ",", "fields", ")", "\n", "\n", "", "return", "_get_initializers", "(", "initializers", ",", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._update_adam_estimate": [[374, 376], ["None"], "function", ["None"], ["", "", "def", "_update_adam_estimate", "(", "estimate", ",", "value", ",", "b", ")", ":", "\n", "  ", "return", "(", "b", "*", "estimate", ")", "+", "(", "(", "1", "-", "b", ")", "*", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks._debias_adam_estimate": [[378, 380], ["tensorflow.pow"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow"], ["", "def", "_debias_adam_estimate", "(", "estimate", ",", "b", ",", "t", ")", ":", "\n", "  ", "return", "estimate", "/", "(", "1", "-", "tf", ".", "pow", "(", "b", ",", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.train_rnnprop.main": [[66, 240], ["util.get_config", "meta_rnnprop_train.MetaOptimizer", "meta.MetaOptimizer.meta_minimize", "tensorflow.ConfigProto", "data_generator.data_loader", "p_val_x.append", "tensorflow.assign", "tensorflow.contrib.learn.python.learn.monitored_session.MonitoredSession", "timeit.default_timer", "tensorflow.get_default_graph().finalize", "float", "six.moves.xrange", "print", "int", "os.path.exists", "os.mkdir", "tensorflow.placeholder", "range", "sess.run", "sess.run", "print", "float", "len", "tensorflow.get_default_graph", "util.run_epoch", "data_generator.data_loader.get_data", "util.run_epoch", "six.moves.xrange", "print", "FLAGS.mt_ratios.split", "random.random", "util.run_epoch", "meta.MetaOptimizer.save", "meta.MetaOptimizer.save", "timeit.default_timer", "len", "meta.MetaOptimizer.save", "meta.MetaOptimizer.save", "print", "meta.MetaOptimizer.restore", "six.moves.xrange", "print", "zip", "len", "util.run_epoch", "print"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_minimize", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.get_data", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restore", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch"], ["def", "main", "(", "_", ")", ":", "\n", "# Configuration.", "\n", "    ", "if", "FLAGS", ".", "if_cl", ":", "\n", "        ", "num_steps", "=", "[", "100", ",", "200", ",", "500", ",", "1000", ",", "1500", ",", "2000", ",", "2500", ",", "3000", "]", "\n", "num_unrolls", "=", "[", "int", "(", "ns", "/", "FLAGS", ".", "unroll_length", ")", "for", "ns", "in", "num_steps", "]", "\n", "num_unrolls_eval", "=", "num_unrolls", "[", "1", ":", "]", "\n", "curriculum_idx", "=", "0", "\n", "", "else", ":", "\n", "        ", "num_unrolls", "=", "FLAGS", ".", "num_steps", "//", "FLAGS", ".", "unroll_length", "\n", "\n", "# Output path.", "\n", "", "if", "FLAGS", ".", "save_path", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "save_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "FLAGS", ".", "save_path", ")", "\n", "\n", "# Problem.", "\n", "", "", "problem", ",", "net_config", ",", "net_assignments", "=", "util", ".", "get_config", "(", "FLAGS", ".", "problem", ",", "net_name", "=", "\"RNNprop\"", ")", "\n", "\n", "# Optimizer setup.", "\n", "optimizer", "=", "meta", ".", "MetaOptimizer", "(", "FLAGS", ".", "num_mt", ",", "FLAGS", ".", "beta1", ",", "FLAGS", ".", "beta2", ",", "**", "net_config", ")", "\n", "minimize", ",", "scale", ",", "var_x", ",", "constants", ",", "subsets", ",", "seq_step", ",", "loss_mt", ",", "steps_mt", ",", "update_mt", ",", "reset_mt", ",", "mt_labels", ",", "mt_inputs", "=", "optimizer", ".", "meta_minimize", "(", "\n", "problem", ",", "FLAGS", ".", "unroll_length", ",", "\n", "learning_rate", "=", "FLAGS", ".", "learning_rate", ",", "\n", "net_assignments", "=", "net_assignments", ",", "\n", "second_derivatives", "=", "FLAGS", ".", "second_derivatives", ")", "\n", "step", ",", "update", ",", "reset", ",", "cost_op", ",", "_", "=", "minimize", "\n", "\n", "# Data generator for multi-task learning.", "\n", "if", "FLAGS", ".", "if_mt", ":", "\n", "        ", "data_mt", "=", "data_loader", "(", "problem", ",", "var_x", ",", "constants", ",", "subsets", ",", "scale", ",", "\n", "FLAGS", ".", "optimizers", ",", "FLAGS", ".", "unroll_length", ")", "\n", "if", "FLAGS", ".", "if_cl", ":", "\n", "            ", "mt_ratios", "=", "[", "float", "(", "r", ")", "for", "r", "in", "FLAGS", ".", "mt_ratios", ".", "split", "(", ")", "]", "\n", "\n", "# Assign func.", "\n", "", "", "p_val_x", "=", "[", "]", "\n", "for", "k", "in", "var_x", ":", "\n", "        ", "p_val_x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "k", ".", "shape", ")", ")", "\n", "", "assign_ops", "=", "[", "tf", ".", "assign", "(", "var_x", "[", "k_id", "]", ",", "p_val_x", "[", "k_id", "]", ")", "for", "k_id", "in", "range", "(", "len", "(", "p_val_x", ")", ")", "]", "\n", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "ms", ".", "MonitoredSession", "(", ")", "as", "sess", ":", "\n", "        ", "def", "assign_func", "(", "val_x", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_ops", ",", "feed_dict", "=", "{", "p", ":", "v", "for", "p", ",", "v", "in", "zip", "(", "p_val_x", ",", "val_x", ")", "}", ")", "\n", "\n", "# tf1.14", "\n", "", "for", "rst", "in", "[", "reset", "]", "+", "reset_mt", ":", "\n", "            ", "sess", ".", "run", "(", "rst", ")", "\n", "\n", "# Start.", "\n", "", "start_time", "=", "timer", "(", ")", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "best_evaluation", "=", "float", "(", "\"inf\"", ")", "\n", "num_eval", "=", "0", "\n", "improved", "=", "False", "\n", "mti", "=", "-", "1", "\n", "for", "e", "in", "xrange", "(", "FLAGS", ".", "num_epochs", ")", ":", "\n", "# Pick a task if it's multi-task learning.", "\n", "            ", "if", "FLAGS", ".", "if_mt", ":", "\n", "                ", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "if", "curriculum_idx", ">=", "len", "(", "mt_ratios", ")", ":", "\n", "                        ", "mt_ratio", "=", "mt_ratios", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "mt_ratio", "=", "mt_ratios", "[", "curriculum_idx", "]", "\n", "", "", "else", ":", "\n", "                    ", "mt_ratio", "=", "FLAGS", ".", "mt_ratio", "\n", "", "if", "random", ".", "random", "(", ")", "<", "mt_ratio", ":", "\n", "                    ", "mti", "=", "(", "mti", "+", "1", ")", "%", "FLAGS", ".", "num_mt", "\n", "task_i", "=", "mti", "\n", "", "else", ":", "\n", "                    ", "task_i", "=", "-", "1", "\n", "", "", "else", ":", "\n", "                ", "task_i", "=", "-", "1", "\n", "\n", "# Training.", "\n", "", "if", "FLAGS", ".", "if_cl", ":", "\n", "                ", "num_unrolls_cur", "=", "num_unrolls", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                ", "num_unrolls_cur", "=", "num_unrolls", "\n", "\n", "", "if", "task_i", "==", "-", "1", ":", "\n", "                ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", ",", "step", "]", ",", "reset", ",", "\n", "num_unrolls_cur", ",", "\n", "scale", "=", "scale", ",", "\n", "rd_scale", "=", "FLAGS", ".", "if_scale", ",", "\n", "rd_scale_bound", "=", "FLAGS", ".", "rd_scale_bound", ",", "\n", "assign_func", "=", "assign_func", ",", "\n", "var_x", "=", "var_x", ",", "\n", "step", "=", "seq_step", ",", "\n", "unroll_len", "=", "FLAGS", ".", "unroll_length", ")", "\n", "", "else", ":", "\n", "                ", "data_e", "=", "data_mt", ".", "get_data", "(", "task_i", ",", "sess", ",", "num_unrolls_cur", ",", "assign_func", ",", "FLAGS", ".", "rd_scale_bound", ",", "\n", "if_scale", "=", "FLAGS", ".", "if_scale", ",", "mt_k", "=", "FLAGS", ".", "k", ")", "\n", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "loss_mt", "[", "task_i", "]", ",", "[", "update_mt", "[", "task_i", "]", ",", "steps_mt", "[", "task_i", "]", "]", ",", "reset_mt", "[", "task_i", "]", ",", "\n", "num_unrolls_cur", ",", "\n", "scale", "=", "scale", ",", "\n", "rd_scale", "=", "FLAGS", ".", "if_scale", ",", "\n", "rd_scale_bound", "=", "FLAGS", ".", "rd_scale_bound", ",", "\n", "assign_func", "=", "assign_func", ",", "\n", "var_x", "=", "var_x", ",", "\n", "step", "=", "seq_step", ",", "\n", "unroll_len", "=", "FLAGS", ".", "unroll_length", ",", "\n", "task_i", "=", "task_i", ",", "\n", "data", "=", "data_e", ",", "\n", "label_pl", "=", "mt_labels", "[", "task_i", "]", ",", "\n", "input_pl", "=", "mt_inputs", "[", "task_i", "]", ")", "\n", "", "print", "(", "\"training_loss={}\"", ".", "format", "(", "cost", ")", ")", "\n", "\n", "# Evaluation.", "\n", "if", "(", "e", "+", "1", ")", "%", "FLAGS", ".", "evaluation_period", "==", "0", ":", "\n", "                ", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "num_unrolls_eval_cur", "=", "num_unrolls_eval", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                    ", "num_unrolls_eval_cur", "=", "num_unrolls", "\n", "", "num_eval", "+=", "1", "\n", "\n", "eval_cost", "=", "0", "\n", "for", "_", "in", "xrange", "(", "FLAGS", ".", "evaluation_epochs", ")", ":", "\n", "                    ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "reset", ",", "\n", "num_unrolls_eval_cur", ",", "\n", "step", "=", "seq_step", ",", "\n", "unroll_len", "=", "FLAGS", ".", "unroll_length", ")", "\n", "eval_cost", "+=", "cost", "\n", "\n", "", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "num_steps_cur", "=", "num_steps", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                    ", "num_steps_cur", "=", "FLAGS", ".", "num_steps", "\n", "", "print", "(", "\"epoch={}, num_steps={}, eval_loss={}\"", ".", "format", "(", "\n", "e", ",", "num_steps_cur", ",", "eval_cost", "/", "FLAGS", ".", "evaluation_epochs", ")", ",", "flush", "=", "True", ")", "\n", "\n", "if", "not", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "if", "eval_cost", "<", "best_evaluation", ":", "\n", "                        ", "best_evaluation", "=", "eval_cost", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "e", "+", "1", ")", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "0", ")", "\n", "print", "(", "\"Saving optimizer of epoch {}...\"", ".", "format", "(", "e", "+", "1", ")", ")", "\n", "", "continue", "\n", "\n", "# Curriculum learning.", "\n", "# update curriculum", "\n", "", "if", "eval_cost", "<", "best_evaluation", ":", "\n", "                    ", "best_evaluation", "=", "eval_cost", "\n", "improved", "=", "True", "\n", "# save model", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "curriculum_idx", ")", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "0", ")", "\n", "", "elif", "num_eval", ">=", "FLAGS", ".", "min_num_eval", "and", "improved", ":", "\n", "# restore model", "\n", "                    ", "optimizer", ".", "restore", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "curriculum_idx", ")", "\n", "num_eval", "=", "0", "\n", "improved", "=", "False", "\n", "curriculum_idx", "+=", "1", "\n", "if", "curriculum_idx", ">=", "len", "(", "num_unrolls", ")", ":", "\n", "                        ", "curriculum_idx", "=", "-", "1", "\n", "\n", "# initial evaluation for next curriculum", "\n", "", "eval_cost", "=", "0", "\n", "for", "_", "in", "xrange", "(", "FLAGS", ".", "evaluation_epochs", ")", ":", "\n", "                        ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "reset", ",", "\n", "num_unrolls_eval", "[", "curriculum_idx", "]", ",", "\n", "step", "=", "seq_step", ",", "\n", "unroll_len", "=", "FLAGS", ".", "unroll_length", ")", "\n", "eval_cost", "+=", "cost", "\n", "", "best_evaluation", "=", "eval_cost", "\n", "print", "(", "\"epoch={}, num_steps={}, eval loss={}\"", ".", "format", "(", "\n", "e", ",", "num_steps", "[", "curriculum_idx", "]", ",", "eval_cost", "/", "FLAGS", ".", "evaluation_epochs", ")", ",", "flush", "=", "True", ")", "\n", "", "elif", "num_eval", ">=", "FLAGS", ".", "min_num_eval", "and", "not", "improved", ":", "\n", "                    ", "print", "(", "\"no improve during curriculum {} --> stop\"", ".", "format", "(", "curriculum_idx", ")", ")", "\n", "break", "\n", "\n", "", "", "", "print", "(", "\"total time = {}s...\"", ".", "format", "(", "timer", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.simple": [[41, 54], ["tensorflow.get_variable", "tensorflow.square", "tensorflow.ones_initializer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square"], ["def", "simple", "(", ")", ":", "\n", "  ", "\"\"\"Simple problem: f(x) = x^2.\"\"\"", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "return", "tf", ".", "square", "(", "x", ",", "name", "=", "\"x_squared\"", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.simple_multi_optimizer": [[56, 71], ["tensorflow.get_variable", "tensorflow.concat", "tensorflow.reduce_sum", "problems.simple_multi_optimizer.get_coordinate"], "function", ["None"], ["", "def", "simple_multi_optimizer", "(", "num_dims", "=", "2", ")", ":", "\n", "  ", "\"\"\"Multidimensional simple problem.\"\"\"", "\n", "\n", "def", "get_coordinate", "(", "i", ")", ":", "\n", "    ", "return", "tf", ".", "get_variable", "(", "\"x_{}\"", ".", "format", "(", "i", ")", ",", "\n", "shape", "=", "[", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "\n", "", "def", "build", "(", ")", ":", "\n", "    ", "coordinates", "=", "[", "get_coordinate", "(", "i", ")", "for", "i", "in", "xrange", "(", "num_dims", ")", "]", "\n", "x", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "c", ",", "0", ")", "for", "c", "in", "coordinates", "]", ",", "0", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "x", ",", "name", "=", "\"x_squared\"", ")", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.quadratic": [[73, 102], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.random_normal_initializer", "tensorflow.random_uniform_initializer", "tensorflow.random_uniform_initializer", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "quadratic", "(", "batch_size", "=", "128", ",", "num_dims", "=", "10", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "  ", "\"\"\"Quadratic problem: f(x) = ||Wx - y||.\"\"\"", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "\n", "# Trainable variable.", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "# Non-trainable variables.", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "y", "=", "tf", ".", "get_variable", "(", "\"y\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "product", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "w", ",", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "(", "product", "-", "y", ")", "**", "2", ",", "1", ")", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.lasso": [[103, 135], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.norm", "tensorflow.random_normal_initializer", "tensorflow.random_uniform_initializer", "tensorflow.random_uniform_initializer"], "function", ["None"], ["", "def", "lasso", "(", "batch_size", "=", "128", ",", "num_dims", "=", "10", ",", "stddev", "=", "0.01", ",", "l", "=", "0.005", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "  ", "\"\"\"lasso problem: f(x) = 0.5*||Wx - y||2 + lamada *||x||1.\"\"\"", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "\n", "# Trainable variable.", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "# Non-trainable variables.", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "y", "=", "tf", ".", "get_variable", "(", "\"y\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "product", "=", "tf", ".", "matmul", "(", "w", ",", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", "\n", "left_term", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "(", "product", "-", "y", ")", "**", "2", ",", "1", ")", "\n", "other_term", "=", "l", "*", "tf", ".", "norm", "(", "x", ",", "ord", "=", "1", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "result", "=", "tf", ".", "reduce_mean", "(", "left_term", "+", "other_term", ")", "\n", "return", "result", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.lasso_fixed": [[137, 176], ["print", "print", "print", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.norm", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "function", ["None"], ["", "def", "lasso_fixed", "(", "data_A", ",", "data_b", ",", "stddev", "=", "0.01", ",", "l", "=", "0.005", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "  ", "\"\"\"lasso problem: f(x) = 0.5*||Wx - y||2 + lamada *||x||1.\"\"\"", "\n", "a", "=", "data_A", "\n", "b", "=", "data_b", "\n", "\n", "print", "(", "\"=\"", "*", "100", ")", "\n", "print", "(", "\"LASSO: A_size={} b_size={}\"", ".", "format", "(", "a", ".", "shape", ",", "b", ".", "shape", ")", ")", "\n", "print", "(", "\"=\"", "*", "100", ")", "\n", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "\n", "# Trainable variable.", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "a", ".", "shape", "[", "0", "]", ",", "a", ".", "shape", "[", "2", "]", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "# Non-trainable variables.", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "\n", "shape", "=", "a", ".", "shape", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "a", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "y", "=", "tf", ".", "get_variable", "(", "\"y\"", ",", "\n", "shape", "=", "b", ".", "shape", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "b", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "# product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1)))", "\n", "\n", "product", "=", "tf", ".", "matmul", "(", "w", ",", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", "\n", "left_term", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "(", "product", "-", "y", ")", "**", "2", ",", "1", ")", "\n", "other_term", "=", "l", "*", "tf", ".", "norm", "(", "x", ",", "ord", "=", "1", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "result", "=", "tf", ".", "reduce_mean", "(", "left_term", "+", "other_term", ")", "\n", "return", "result", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.rastrigin": [[177, 214], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.norm", "tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.matmul", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.transpose", "tensorflow.cos"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.cos"], ["", "def", "rastrigin", "(", "batch_size", "=", "128", ",", "num_dims", "=", "10", ",", "alpha", "=", "10", ",", "stddev", "=", "1", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "\n", "  ", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "# Trainable variable.", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", "\n", ")", "\n", "\n", "# Non-trainable variables.", "\n", "A", "=", "tf", ".", "get_variable", "(", "\"A\"", ",", "\n", "dtype", "=", "dtype", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "num_dims", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "B", "=", "tf", ".", "get_variable", "(", "\"B\"", ",", "\n", "dtype", "=", "dtype", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "C", "=", "tf", ".", "get_variable", "(", "\"C\"", ",", "\n", "dtype", "=", "dtype", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "product", "=", "tf", ".", "matmul", "(", "A", ",", "x", ")", "\n", "ras_norm", "=", "tf", ".", "norm", "(", "product", "-", "B", ",", "ord", "=", "2", ",", "axis", "=", "[", "-", "2", ",", "-", "1", "]", ")", "\n", "\n", "cqTcos", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "C", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ",", "tf", ".", "cos", "(", "2", "*", "np", ".", "pi", "*", "x", ")", ")", ")", "\n", "\n", "return", "tf", ".", "reduce_mean", "(", "0.5", "*", "(", "ras_norm", "**", "2", ")", "-", "alpha", "*", "cqTcos", "+", "alpha", "*", "num_dims", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.ensemble": [[215, 246], ["ValueError", "enumerate", "len", "len", "getattr", "tensorflow.variable_scope", "build_fn"], "function", ["None"], ["", "def", "ensemble", "(", "problems", ",", "weights", "=", "None", ")", ":", "\n", "  ", "\"\"\"Ensemble of problems.\n\n  Args:\n    problems: List of problems. Each problem is specified by a dict containing\n        the keys 'name' and 'options'.\n    weights: Optional list of weights for each problem.\n\n  Returns:\n    Sum of (weighted) losses.\n\n  Raises:\n    ValueError: If weights has an incorrect length.\n  \"\"\"", "\n", "if", "weights", "and", "len", "(", "weights", ")", "!=", "len", "(", "problems", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"len(weights) != len(problems)\"", ")", "\n", "\n", "", "build_fns", "=", "[", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "p", "[", "\"name\"", "]", ")", "(", "**", "p", "[", "\"options\"", "]", ")", "\n", "for", "p", "in", "problems", "]", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "loss", "=", "0", "\n", "for", "i", ",", "build_fn", "in", "enumerate", "(", "build_fns", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"problem_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "        ", "loss_p", "=", "build_fn", "(", ")", "\n", "if", "weights", ":", "\n", "          ", "loss_p", "*=", "weights", "[", "i", "]", "\n", "", "loss", "+=", "loss_p", "\n", "", "", "return", "loss", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._xent_loss": [[248, 252], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "_xent_loss", "(", "output", ",", "labels", ")", ":", "\n", "  ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "output", ",", "\n", "labels", "=", "labels", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist": [[254, 289], ["tensorflow.contrib.learn.python.learn.datasets.mnist.load_mnist", "getattr", "tensorflow.constant", "tensorflow.reshape", "tensorflow.constant", "sonnet.nets.MLP", "sonnet.Sequential", "tensorflow.random_uniform", "tensorflow.gather", "tensorflow.gather", "snt.Sequential.", "problems._xent_loss", "ValueError", "list", "sonnet.BatchFlatten"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._xent_loss"], ["", "def", "mnist", "(", "layers", ",", "\n", "activation", "=", "\"sigmoid\"", ",", "\n", "batch_size", "=", "128", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "  ", "\"\"\"Mnist classification with a multi-layer perceptron.\"\"\"", "\n", "initializers", "=", "_nn_initializers", "\n", "\n", "if", "activation", "==", "\"sigmoid\"", ":", "\n", "    ", "activation_op", "=", "tf", ".", "sigmoid", "\n", "", "elif", "activation", "==", "\"relu\"", ":", "\n", "    ", "activation_op", "=", "tf", ".", "nn", ".", "relu", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"{} activation not supported\"", ".", "format", "(", "activation", ")", ")", "\n", "\n", "# Data.", "\n", "", "data", "=", "mnist_dataset", ".", "load_mnist", "(", ")", "\n", "data", "=", "getattr", "(", "data", ",", "mode", ")", "\n", "images", "=", "tf", ".", "constant", "(", "data", ".", "images", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"MNIST_images\"", ")", "\n", "images", "=", "tf", ".", "reshape", "(", "images", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "labels", "=", "tf", ".", "constant", "(", "data", ".", "labels", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"MNIST_labels\"", ")", "\n", "\n", "# Network.", "\n", "mlp", "=", "snt", ".", "nets", ".", "MLP", "(", "list", "(", "layers", ")", "+", "[", "10", "]", ",", "\n", "activation", "=", "activation_op", ",", "\n", "initializers", "=", "initializers", ")", "\n", "network", "=", "snt", ".", "Sequential", "(", "[", "snt", ".", "BatchFlatten", "(", ")", ",", "mlp", "]", ")", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "indices", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", "]", ",", "0", ",", "data", ".", "num_examples", ",", "tf", ".", "int64", ")", "\n", "batch_images", "=", "tf", ".", "gather", "(", "images", ",", "indices", ")", "\n", "batch_labels", "=", "tf", ".", "gather", "(", "labels", ",", "indices", ")", "\n", "output", "=", "network", "(", "batch_images", ")", "\n", "return", "_xent_loss", "(", "output", ",", "batch_labels", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist_conv": [[291, 348], ["tensorflow.contrib.learn.python.learn.datasets.mnist.load_mnist", "getattr", "tensorflow.constant", "tensorflow.reshape", "tensorflow.constant", "conv_layer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer"], ["", "def", "mnist_conv", "(", "batch_norm", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "\n", "# Data.", "\n", "  ", "data", "=", "mnist_dataset", ".", "load_mnist", "(", ")", "\n", "data", "=", "getattr", "(", "data", ",", "mode", ")", "\n", "images", "=", "tf", ".", "constant", "(", "data", ".", "images", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"MNIST_images\"", ")", "\n", "images", "=", "tf", ".", "reshape", "(", "images", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "labels", "=", "tf", ".", "constant", "(", "data", ".", "labels", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"MNIST_labels\"", ")", "\n", "\n", "def", "network", "(", "inputs", ",", "training", "=", "True", ")", ":", "\n", "\n", "      ", "def", "_conv_activation", "(", "x", ")", ":", "\n", "          ", "return", "tf", ".", "nn", ".", "max_pool", "(", "tf", ".", "nn", ".", "relu", "(", "x", ")", ",", "\n", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "\"VALID\"", ")", "\n", "", "def", "conv_layer", "(", "inputs", ",", "strides", ",", "c_h", ",", "c_w", ",", "output_channels", ",", "padding", ",", "name", ")", ":", "\n", "          ", "n_channels", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "              ", "kernel1", "=", "tf", ".", "get_variable", "(", "'weights1'", ",", "\n", "shape", "=", "[", "c_h", ",", "c_w", ",", "n_channels", ",", "output_channels", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", "\n", ")", "\n", "\n", "biases1", "=", "tf", ".", "get_variable", "(", "'biases1'", ",", "[", "output_channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "", "inputs", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "kernel1", ",", "[", "1", ",", "strides", ",", "strides", ",", "1", "]", ",", "padding", ")", "\n", "inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "biases1", ")", "\n", "if", "batch_norm", ":", "\n", "              ", "inputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "inputs", "=", "_conv_activation", "(", "inputs", ")", "\n", "return", "inputs", "\n", "\n", "", "inputs", "=", "conv_layer", "(", "inputs", ",", "1", ",", "3", ",", "3", ",", "16", ",", "\"VALID\"", ",", "'conv_layer1'", ")", "\n", "inputs", "=", "conv_layer", "(", "inputs", ",", "1", ",", "5", ",", "5", ",", "32", ",", "\"VALID\"", ",", "'conv_layer2'", ")", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "fc_shape2", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "weights", "=", "tf", ".", "get_variable", "(", "\"fc_weights\"", ",", "\n", "shape", "=", "[", "fc_shape2", ",", "10", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"fc_bias\"", ",", "\n", "shape", "=", "[", "10", ",", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "inputs", ",", "weights", ")", ",", "bias", ")", ")", "\n", "\n", "", "def", "build", "(", ")", ":", "\n", "    ", "indices", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", "]", ",", "0", ",", "data", ".", "num_examples", ",", "tf", ".", "int64", ")", "\n", "batch_images", "=", "tf", ".", "gather", "(", "images", ",", "indices", ")", "\n", "batch_labels", "=", "tf", ".", "gather", "(", "labels", ",", "indices", ")", "\n", "output", "=", "network", "(", "batch_images", ")", "\n", "return", "_xent_loss", "(", "output", ",", "batch_labels", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._maybe_download_cifar10": [[355, 367], ["os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "print", "os.path.join", "six.moves.urllib.request.urlretrieve", "os.stat", "print", "tarfile.open().extractall", "tarfile.open"], "function", ["None"], ["def", "_maybe_download_cifar10", "(", "path", ")", ":", "\n", "  ", "\"\"\"Download and extract the tarball from Alex's website.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FILE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "    ", "print", "(", "\"Downloading CIFAR10 dataset to {}\"", ".", "format", "(", "filepath", ")", ")", "\n", "url", "=", "os", ".", "path", ".", "join", "(", "CIFAR10_URL", ",", "CIFAR10_FILE", ")", "\n", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "url", ",", "filepath", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "\"Successfully downloaded {} bytes\"", ".", "format", "(", "statinfo", ".", "st_size", ")", ")", "\n", "tarfile", ".", "open", "(", "filepath", ",", "\"r:gz\"", ")", ".", "extractall", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.cifar10": [[369, 459], ["problems._maybe_download_cifar10", "tensorflow.FixedLengthRecordReader", "tf.FixedLengthRecordReader.read", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.slice", "tensorflow.cast", "tensorflow.transpose", "tensorflow.math.divide", "tensorflow.RandomShuffleQueue", "tensorflow.train.add_queue_runner", "tensorflow.train.string_input_producer", "tensorflow.slice", "tensorflow.reshape", "tf.RandomShuffleQueue.enqueue", "tensorflow.train.QueueRunner", "conv_layer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._maybe_download_cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer"], ["", "", "def", "cifar10", "(", "path", ",", "\n", "batch_norm", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "num_threads", "=", "4", ",", "\n", "min_queue_examples", "=", "1000", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "  ", "\"\"\"Cifar10 classification with a convolutional network.\"\"\"", "\n", "\n", "# Data.", "\n", "_maybe_download_cifar10", "(", "path", ")", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"data_batch_{}.bin\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"test_batch.bin\"", ")", "]", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Mode {} not recognised\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "depth", "=", "3", "\n", "height", "=", "32", "\n", "width", "=", "32", "\n", "label_bytes", "=", "1", "\n", "image_bytes", "=", "depth", "*", "height", "*", "width", "\n", "record_bytes", "=", "label_bytes", "+", "image_bytes", "\n", "reader", "=", "tf", ".", "FixedLengthRecordReader", "(", "record_bytes", "=", "record_bytes", ")", "\n", "_", ",", "record", "=", "reader", ".", "read", "(", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", ")", "\n", "record_bytes", "=", "tf", ".", "decode_raw", "(", "record", ",", "tf", ".", "uint8", ")", "\n", "\n", "label", "=", "tf", ".", "cast", "(", "tf", ".", "slice", "(", "record_bytes", ",", "[", "0", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "raw_image", "=", "tf", ".", "slice", "(", "record_bytes", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "raw_image", ",", "[", "depth", ",", "height", ",", "width", "]", ")", ",", "tf", ".", "float32", ")", "\n", "# height x width x depth.", "\n", "image", "=", "tf", ".", "transpose", "(", "image", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image", "=", "tf", ".", "math", ".", "divide", "(", "image", ",", "255", ")", "\n", "\n", "queue", "=", "tf", ".", "RandomShuffleQueue", "(", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ",", "\n", "dtypes", "=", "[", "tf", ".", "float32", ",", "tf", ".", "int32", "]", ",", "\n", "shapes", "=", "[", "image", ".", "get_shape", "(", ")", ",", "label", ".", "get_shape", "(", ")", "]", ")", "\n", "enqueue_ops", "=", "[", "queue", ".", "enqueue", "(", "[", "image", ",", "label", "]", ")", "for", "_", "in", "xrange", "(", "num_threads", ")", "]", "\n", "tf", ".", "train", ".", "add_queue_runner", "(", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "enqueue_ops", ")", ")", "\n", "\n", "def", "network", "(", "inputs", ",", "training", "=", "True", ")", ":", "\n", "\n", "      ", "def", "_conv_activation", "(", "x", ")", ":", "\n", "          ", "return", "tf", ".", "nn", ".", "max_pool", "(", "tf", ".", "nn", ".", "relu", "(", "x", ")", ",", "\n", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "\"VALID\"", ")", "\n", "\n", "", "def", "conv_layer", "(", "inputs", ",", "strides", ",", "c_h", ",", "c_w", ",", "output_channels", ",", "padding", ",", "name", ")", ":", "\n", "          ", "n_channels", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "              ", "kernel1", "=", "tf", ".", "get_variable", "(", "'weights1'", ",", "\n", "shape", "=", "[", "c_h", ",", "c_w", ",", "n_channels", ",", "output_channels", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", "\n", ")", "\n", "\n", "biases1", "=", "tf", ".", "get_variable", "(", "'biases1'", ",", "[", "output_channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "", "inputs", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "kernel1", ",", "[", "1", ",", "strides", ",", "strides", ",", "1", "]", ",", "padding", ")", "\n", "inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "biases1", ")", "\n", "if", "batch_norm", ":", "\n", "              ", "inputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "inputs", "=", "_conv_activation", "(", "inputs", ")", "\n", "return", "inputs", "\n", "\n", "", "inputs", "=", "conv_layer", "(", "inputs", ",", "2", ",", "3", ",", "3", ",", "16", ",", "\"VALID\"", ",", "'conv_layer1'", ")", "\n", "inputs", "=", "conv_layer", "(", "inputs", ",", "2", ",", "5", ",", "5", ",", "32", ",", "\"VALID\"", ",", "'conv_layer2'", ")", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "fc_shape2", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "weights", "=", "tf", ".", "get_variable", "(", "\"fc_weights\"", ",", "\n", "shape", "=", "[", "fc_shape2", ",", "10", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"fc_bias\"", ",", "\n", "shape", "=", "[", "10", ",", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "inputs", ",", "weights", ")", ",", "bias", ")", ")", "\n", "\n", "\n", "", "def", "build", "(", ")", ":", "\n", "    ", "image_batch", ",", "label_batch", "=", "queue", ".", "dequeue_many", "(", "batch_size", ")", "\n", "label_batch", "=", "tf", ".", "reshape", "(", "label_batch", ",", "[", "batch_size", "]", ")", "\n", "output", "=", "network", "(", "image_batch", ")", "\n", "\n", "return", "_xent_loss", "(", "output", ",", "label_batch", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.LeNet": [[461, 538], ["problems._maybe_download_cifar10", "tensorflow.FixedLengthRecordReader", "tf.FixedLengthRecordReader.read", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.slice", "tensorflow.cast", "tensorflow.transpose", "tensorflow.div", "tensorflow.RandomShuffleQueue", "tensorflow.train.add_queue_runner", "sonnet.nets.ConvNet2D", "sonnet.nets.MLP", "sonnet.Sequential", "tensorflow.train.string_input_producer", "tensorflow.slice", "tensorflow.reshape", "tf.RandomShuffleQueue.enqueue", "tensorflow.train.QueueRunner", "tensorflow.nn.max_pool", "tf.RandomShuffleQueue.dequeue_many", "tensorflow.reshape", "snt.Sequential.", "problems._xent_loss", "os.path.join", "ValueError", "six.moves.xrange", "tensorflow.sigmoid", "tensorflow.sigmoid", "list", "sonnet.BatchFlatten", "six.moves.xrange", "os.path.join", "tf.div.get_shape", "tf.cast.get_shape", "sonnet.BatchNorm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._maybe_download_cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.div", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.max_pool", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._xent_loss"], ["", "def", "LeNet", "(", "path", ",", "\n", "conv_channels", "=", "None", ",", "\n", "linear_layers", "=", "None", ",", "\n", "batch_norm", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "num_threads", "=", "4", ",", "\n", "min_queue_examples", "=", "1000", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "\n", "# Data.", "\n", "    ", "_maybe_download_cifar10", "(", "path", ")", "\n", "\n", "# Read images and labels from disk.", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"data_batch_{}.bin\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"test_batch.bin\"", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Mode {} not recognised\"", ".", "format", "(", "mode", ")", ")", "\n", "", "depth", "=", "3", "\n", "height", "=", "32", "\n", "width", "=", "32", "\n", "label_bytes", "=", "1", "\n", "image_bytes", "=", "depth", "*", "height", "*", "width", "\n", "record_bytes", "=", "label_bytes", "+", "image_bytes", "\n", "reader", "=", "tf", ".", "FixedLengthRecordReader", "(", "record_bytes", "=", "record_bytes", ")", "\n", "_", ",", "record", "=", "reader", ".", "read", "(", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", ")", "\n", "record_bytes", "=", "tf", ".", "decode_raw", "(", "record", ",", "tf", ".", "uint8", ")", "\n", "\n", "label", "=", "tf", ".", "cast", "(", "tf", ".", "slice", "(", "record_bytes", ",", "[", "0", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "raw_image", "=", "tf", ".", "slice", "(", "record_bytes", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "raw_image", ",", "[", "depth", ",", "height", ",", "width", "]", ")", ",", "tf", ".", "float32", ")", "\n", "# height x width x depth.", "\n", "image", "=", "tf", ".", "transpose", "(", "image", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image", "=", "tf", ".", "div", "(", "image", ",", "255", ")", "\n", "\n", "queue", "=", "tf", ".", "RandomShuffleQueue", "(", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ",", "\n", "dtypes", "=", "[", "tf", ".", "float32", ",", "tf", ".", "int32", "]", ",", "\n", "shapes", "=", "[", "image", ".", "get_shape", "(", ")", ",", "label", ".", "get_shape", "(", ")", "]", ")", "\n", "enqueue_ops", "=", "[", "queue", ".", "enqueue", "(", "[", "image", ",", "label", "]", ")", "for", "_", "in", "xrange", "(", "num_threads", ")", "]", "\n", "tf", ".", "train", ".", "add_queue_runner", "(", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "enqueue_ops", ")", ")", "\n", "\n", "# Network.", "\n", "def", "_conv_activation", "(", "x", ")", ":", "# pylint: disable=invalid-name", "\n", "        ", "return", "tf", ".", "nn", ".", "max_pool", "(", "tf", ".", "sigmoid", "(", "x", ")", ",", "\n", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "\"VALID\"", ")", "\n", "\n", "", "conv", "=", "snt", ".", "nets", ".", "ConvNet2D", "(", "output_channels", "=", "conv_channels", ",", "\n", "kernel_shapes", "=", "[", "5", "]", ",", "\n", "strides", "=", "[", "1", "]", ",", "\n", "paddings", "=", "[", "snt", ".", "VALID", "]", ",", "\n", "activation", "=", "_conv_activation", ",", "\n", "activate_final", "=", "True", ",", "\n", "initializers", "=", "_nn_initializers", ",", "\n", "use_batch_norm", "=", "batch_norm", ")", "\n", "\n", "if", "batch_norm", ":", "\n", "        ", "linear_activation", "=", "lambda", "x", ":", "tf", ".", "sigmoid", "(", "snt", ".", "BatchNorm", "(", ")", "(", "x", ",", "is_training", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "        ", "linear_activation", "=", "tf", ".", "sigmoid", "\n", "\n", "", "mlp", "=", "snt", ".", "nets", ".", "MLP", "(", "list", "(", "linear_layers", ")", "+", "[", "10", "]", ",", "\n", "activation", "=", "linear_activation", ",", "\n", "initializers", "=", "_nn_initializers", ")", "\n", "network", "=", "snt", ".", "Sequential", "(", "[", "conv", ",", "snt", ".", "BatchFlatten", "(", ")", ",", "mlp", "]", ")", "\n", "\n", "def", "build", "(", ")", ":", "\n", "        ", "image_batch", ",", "label_batch", "=", "queue", ".", "dequeue_many", "(", "batch_size", ")", "\n", "label_batch", "=", "tf", ".", "reshape", "(", "label_batch", ",", "[", "batch_size", "]", ")", "\n", "\n", "output", "=", "network", "(", "image_batch", ")", "\n", "return", "_xent_loss", "(", "output", ",", "label_batch", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.NAS": [[540, 635], ["problems._maybe_download_cifar10", "tensorflow.FixedLengthRecordReader", "tf.FixedLengthRecordReader.read", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.slice", "tensorflow.cast", "tensorflow.transpose", "tensorflow.div", "tensorflow.RandomShuffleQueue", "tensorflow.train.add_queue_runner", "tensorflow.train.string_input_producer", "tensorflow.slice", "tensorflow.reshape", "tf.RandomShuffleQueue.enqueue", "tensorflow.train.QueueRunner", "conv_layer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._maybe_download_cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.div", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.conv_layer"], ["", "def", "NAS", "(", "path", ",", "\n", "batch_norm", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "num_threads", "=", "4", ",", "\n", "min_queue_examples", "=", "1000", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "    ", "\"\"\"Cifar10 classification with a convolutional network.\"\"\"", "\n", "\n", "# Data.", "\n", "_maybe_download_cifar10", "(", "path", ")", "\n", "\n", "# Read images and labels from disk.", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"data_batch_{}.bin\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"test_batch.bin\"", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Mode {} not recognised\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "depth", "=", "3", "\n", "height", "=", "32", "\n", "width", "=", "32", "\n", "label_bytes", "=", "1", "\n", "image_bytes", "=", "depth", "*", "height", "*", "width", "\n", "record_bytes", "=", "label_bytes", "+", "image_bytes", "\n", "reader", "=", "tf", ".", "FixedLengthRecordReader", "(", "record_bytes", "=", "record_bytes", ")", "\n", "_", ",", "record", "=", "reader", ".", "read", "(", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", ")", "\n", "record_bytes", "=", "tf", ".", "decode_raw", "(", "record", ",", "tf", ".", "uint8", ")", "\n", "\n", "label", "=", "tf", ".", "cast", "(", "tf", ".", "slice", "(", "record_bytes", ",", "[", "0", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "raw_image", "=", "tf", ".", "slice", "(", "record_bytes", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "raw_image", ",", "[", "depth", ",", "height", ",", "width", "]", ")", ",", "tf", ".", "float32", ")", "\n", "# height x width x depth.", "\n", "image", "=", "tf", ".", "transpose", "(", "image", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image", "=", "tf", ".", "div", "(", "image", ",", "255", ")", "\n", "\n", "queue", "=", "tf", ".", "RandomShuffleQueue", "(", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ",", "\n", "dtypes", "=", "[", "tf", ".", "float32", ",", "tf", ".", "int32", "]", ",", "\n", "shapes", "=", "[", "image", ".", "get_shape", "(", ")", ",", "label", ".", "get_shape", "(", ")", "]", ")", "\n", "enqueue_ops", "=", "[", "queue", ".", "enqueue", "(", "[", "image", ",", "label", "]", ")", "for", "_", "in", "xrange", "(", "num_threads", ")", "]", "\n", "tf", ".", "train", ".", "add_queue_runner", "(", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "enqueue_ops", ")", ")", "\n", "\n", "# Network", "\n", "def", "network", "(", "inputs", ",", "training", "=", "True", ")", ":", "\n", "        ", "def", "conv_layer", "(", "inputs", ",", "strides", ",", "c_h", ",", "c_w", ",", "output_channels", ",", "padding", ",", "name", ")", ":", "\n", "            ", "n_channels", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "                ", "kernel1", "=", "tf", ".", "get_variable", "(", "'weights1'", ",", "\n", "shape", "=", "[", "c_h", ",", "c_w", ",", "n_channels", ",", "output_channels", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", "\n", ")", "\n", "\n", "biases1", "=", "tf", ".", "get_variable", "(", "'biases1'", ",", "[", "output_channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "", "inputs", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "kernel1", ",", "[", "1", ",", "strides", ",", "strides", ",", "1", "]", ",", "padding", ")", "\n", "inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "biases1", ")", "\n", "if", "batch_norm", ":", "\n", "                ", "inputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "inputs", "=", "tf", ".", "nn", ".", "relu", "(", "inputs", ")", "\n", "return", "inputs", "\n", "\n", "", "def", "_pooling", "(", "x", ")", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "avg_pool", "(", "x", ",", "\n", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "\"SAME\"", ")", "\n", "\n", "", "node0", "=", "conv_layer", "(", "inputs", ",", "1", ",", "3", ",", "3", ",", "16", ",", "\"SAME\"", ",", "'node0'", ")", "\n", "node0_onto_node2", "=", "conv_layer", "(", "node0", ",", "1", ",", "3", ",", "3", ",", "16", ",", "\"SAME\"", ",", "'node0_onto_node2'", ")", "\n", "node1", "=", "conv_layer", "(", "node0", ",", "1", ",", "3", ",", "3", ",", "16", ",", "\"SAME\"", ",", "'node1'", ")", "\n", "node1_onto_node3", "=", "conv_layer", "(", "node1", ",", "1", ",", "3", ",", "3", ",", "16", ",", "\"SAME\"", ",", "'node1_onto_node3'", ")", "\n", "node2", "=", "_pooling", "(", "node1", ")", "+", "node0_onto_node2", "\n", "node3", "=", "node2", "+", "node1_onto_node3", "+", "node0", "\n", "node_final", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reshape", "(", "node3", ",", "[", "batch_size", ",", "-", "1", ",", "16", "]", ")", ",", "axis", "=", "1", ")", "\n", "\n", "fc_shape2", "=", "int", "(", "node_final", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "weights", "=", "tf", ".", "get_variable", "(", "\"fc_weights\"", ",", "\n", "shape", "=", "[", "fc_shape2", ",", "10", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"fc_bias\"", ",", "\n", "shape", "=", "[", "10", ",", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "node_final", ",", "weights", ")", ",", "bias", ")", ")", "\n", "\n", "", "def", "build", "(", ")", ":", "\n", "        ", "image_batch", ",", "label_batch", "=", "queue", ".", "dequeue_many", "(", "batch_size", ")", "\n", "label_batch", "=", "tf", ".", "reshape", "(", "label_batch", ",", "[", "batch_size", "]", ")", "\n", "\n", "output", "=", "network", "(", "image_batch", ")", "\n", "return", "_xent_loss", "(", "output", ",", "label_batch", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.vgg16_cifar10": [[637, 695], ["problems._maybe_download_cifar10", "tensorflow.FixedLengthRecordReader", "tf.FixedLengthRecordReader.read", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.slice", "tensorflow.cast", "tensorflow.transpose", "tensorflow.math.divide", "tensorflow.RandomShuffleQueue", "tensorflow.train.add_queue_runner", "vgg16.VGG16", "tensorflow.train.string_input_producer", "tensorflow.slice", "tensorflow.reshape", "tf.RandomShuffleQueue.enqueue", "tensorflow.train.QueueRunner", "tf.RandomShuffleQueue.dequeue_many", "tensorflow.reshape", "vgg16.VGG16._build_model", "problems._xent_loss", "os.path.join", "ValueError", "six.moves.xrange", "six.moves.xrange", "os.path.join", "tf.math.divide.get_shape", "tf.cast.get_shape"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._maybe_download_cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.vgg16.VGG16._build_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems._xent_loss"], ["", "def", "vgg16_cifar10", "(", "path", ",", "# pylint: disable=invalid-name", "\n", "batch_norm", "=", "False", ",", "\n", "batch_size", "=", "128", ",", "\n", "num_threads", "=", "4", ",", "\n", "min_queue_examples", "=", "1000", ",", "\n", "mode", "=", "\"train\"", ")", ":", "\n", "    ", "\"\"\"Cifar10 classification with a convolutional network.\"\"\"", "\n", "\n", "# Data.", "\n", "_maybe_download_cifar10", "(", "path", ")", "\n", "# pdb.set_trace()", "\n", "# Read images and labels from disk.", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "\n", "CIFAR10_FOLDER", ",", "\n", "\"data_batch_{}.bin\"", ".", "format", "(", "i", ")", ")", "\n", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "is_training", "=", "True", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "        ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "CIFAR10_FOLDER", ",", "\"test_batch.bin\"", ")", "]", "\n", "is_training", "=", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Mode {} not recognised\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "depth", "=", "3", "\n", "height", "=", "32", "\n", "width", "=", "32", "\n", "label_bytes", "=", "1", "\n", "image_bytes", "=", "depth", "*", "height", "*", "width", "\n", "record_bytes", "=", "label_bytes", "+", "image_bytes", "\n", "reader", "=", "tf", ".", "FixedLengthRecordReader", "(", "record_bytes", "=", "record_bytes", ")", "\n", "_", ",", "record", "=", "reader", ".", "read", "(", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", ")", "\n", "record_bytes", "=", "tf", ".", "decode_raw", "(", "record", ",", "tf", ".", "uint8", ")", "\n", "\n", "label", "=", "tf", ".", "cast", "(", "tf", ".", "slice", "(", "record_bytes", ",", "[", "0", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "raw_image", "=", "tf", ".", "slice", "(", "record_bytes", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "raw_image", ",", "[", "depth", ",", "height", ",", "width", "]", ")", ",", "tf", ".", "float32", ")", "\n", "# height x width x depth.", "\n", "image", "=", "tf", ".", "transpose", "(", "image", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image", "=", "tf", ".", "math", ".", "divide", "(", "image", ",", "255", ")", "\n", "\n", "queue", "=", "tf", ".", "RandomShuffleQueue", "(", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ",", "\n", "dtypes", "=", "[", "tf", ".", "float32", ",", "tf", ".", "int32", "]", ",", "\n", "shapes", "=", "[", "image", ".", "get_shape", "(", ")", ",", "label", ".", "get_shape", "(", ")", "]", ")", "\n", "enqueue_ops", "=", "[", "queue", ".", "enqueue", "(", "[", "image", ",", "label", "]", ")", "for", "_", "in", "xrange", "(", "num_threads", ")", "]", "\n", "tf", ".", "train", ".", "add_queue_runner", "(", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "enqueue_ops", ")", ")", "\n", "\n", "vgg", "=", "VGG16", "(", "0.5", ",", "10", ")", "\n", "def", "build", "(", ")", ":", "\n", "        ", "image_batch", ",", "label_batch", "=", "queue", ".", "dequeue_many", "(", "batch_size", ")", "\n", "label_batch", "=", "tf", ".", "reshape", "(", "label_batch", ",", "[", "batch_size", "]", ")", "\n", "# pdb.set_trace()", "\n", "output", "=", "vgg", ".", "_build_model", "(", "image_batch", ")", "\n", "# print(output.shape)", "\n", "return", "_xent_loss", "(", "output", ",", "label_batch", ")", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.confocal_microscopy_3d": [[701, 957], ["range", "tensorflow.add_n", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.reduce_mean", "range", "range", "tensorflow.add_n", "tensorflow.add_n", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_mean", "I_var.append", "x_var.append", "y_var.append", "z_var.append", "sigmaxy_var.append", "sigmaz_var.append", "tensorflow.linspace", "tensorflow.linspace", "tensorflow.linspace", "tensorflow.meshgrid", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.math.reduce_sum", "I_var.append", "x_var.append", "y_var.append", "z_var.append", "sigmaxy_var.append", "sigmaz_var.append", "I_sim.append", "x_sim.append", "tf.add_n.append", "z_sim.append", "sigmaxy_sim.append", "sigmaz_sim.append", "tensorflow.linspace", "tensorflow.linspace", "tensorflow.linspace", "tensorflow.meshgrid", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "priors_list[].quantile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.math.reduce_sum", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tfd.Uniform", "tfd.Uniform", "tfd.Uniform", "tfd.Uniform", "tfd.Uniform", "tfd.Uniform", "float", "float", "float", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "point_spread_function_3d"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "confocal_microscopy_3d", "(", "batch_size", "=", "128", ",", "num_points", "=", "5", ",", "ROI", "=", "[", "28", ",", "28", ",", "28", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float32", ",", "inference", "=", "False", ")", ":", "\n", "  ", "if", "inference", ":", "\n", "    ", "def", "build", "(", ")", ":", "\n", "      ", "\"\"\"Builds loss graph.\"\"\"", "\n", "# Trainable variable.", "\n", "I_var", "=", "[", "]", "\n", "x_var", "=", "[", "]", "\n", "y_var", "=", "[", "]", "\n", "z_var", "=", "[", "]", "\n", "sigmaxy_var", "=", "[", "]", "\n", "sigmaz_var", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_points", ")", ":", "\n", "        ", "I_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"I_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "x_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"x_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "y_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"y_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "z_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"z_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "sigmaxy_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaxy_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "sigmaz_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaz_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "# predict", "\n", "", "def", "point_spread_function_3d", "(", "theta", ")", ":", "\n", "        ", "'''\n        Microscopic fluorescence point spread function\n        Args:\n          theta : Variables in the point spread function, [I0, x0, y0, z0, sigmaxy, sigmaz]\n        Returns:\n          I : fluorescence image, the size is [batch_size, size_x * size_y * sizez]\n        '''", "\n", "priors_list", "=", "[", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "0", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "1", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "2", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "2", ",", "high", "=", "4", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "2", ",", "high", "=", "4", ")", "]", "\n", "xs", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "0", "]", "-", "1", ")", ",", "ROI", "[", "0", "]", ")", "\n", "ys", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "1", "]", "-", "1", ")", ",", "ROI", "[", "1", "]", ")", "\n", "zs", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "2", "]", "-", "1", ")", ",", "ROI", "[", "2", "]", ")", "\n", "X", ",", "Y", ",", "Z", "=", "tf", ".", "meshgrid", "(", "xs", ",", "ys", ",", "zs", ")", "\n", "\n", "I0", "=", "priors_list", "[", "0", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "0", "]", ",", "[", "theta", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "x0", "=", "priors_list", "[", "1", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "1", "]", ",", "[", "theta", "[", "1", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "y0", "=", "priors_list", "[", "2", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "2", "]", ",", "[", "theta", "[", "2", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "z0", "=", "priors_list", "[", "3", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "3", "]", ",", "[", "theta", "[", "3", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "sigmaxy", "=", "priors_list", "[", "4", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "4", "]", ",", "[", "theta", "[", "4", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "sigmaz", "=", "priors_list", "[", "5", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "5", "]", ",", "[", "theta", "[", "5", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "\n", "xk", "=", "tf", ".", "reshape", "(", "X", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "yk", "=", "tf", ".", "reshape", "(", "Y", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "zk", "=", "tf", ".", "reshape", "(", "Z", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "\n", "I", "=", "I0", "*", "(", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "x0", "+", "xk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "x0", "+", "xk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", ")", "*", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "y0", "+", "yk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "y0", "+", "yk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", ")", "*", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "z0", "+", "zk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaz", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "z0", "+", "zk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaz", ")", ")", ")", ")", "/", "8.0", "\n", "return", "I", "\n", "\n", "", "y_pred", "=", "tf", ".", "add_n", "(", "[", "\n", "point_spread_function_3d", "(", "[", "I_var", "[", "i", "]", ",", "x_var", "[", "i", "]", ",", "y_var", "[", "i", "]", ",", "z_var", "[", "i", "]", ",", "sigmaxy_var", "[", "i", "]", ",", "sigmaz_var", "[", "i", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "num_points", ")", "]", ")", "\n", "\n", "bg_var", "=", "tf", ".", "get_variable", "(", "\n", "\"bg_var\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "img_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", ",", "shape", "=", "(", "batch_size", ",", "ROI", "[", "0", "]", "*", "ROI", "[", "1", "]", "*", "ROI", "[", "2", "]", ")", ")", "\n", "obj", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "math", ".", "reduce_sum", "(", "(", "y_pred", "+", "bg_var", "-", "tf", ".", "math", ".", "l2_normalize", "(", "img_placeholder", ",", "axis", "=", "1", ")", ")", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "return", "obj", "\n", "", "", "else", ":", "\n", "    ", "def", "build", "(", ")", ":", "\n", "      ", "\"\"\"Builds loss graph.\"\"\"", "\n", "# Trainable variable.", "\n", "I_var", "=", "[", "]", "\n", "x_var", "=", "[", "]", "\n", "y_var", "=", "[", "]", "\n", "z_var", "=", "[", "]", "\n", "sigmaxy_var", "=", "[", "]", "\n", "sigmaz_var", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_points", ")", ":", "\n", "        ", "I_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"I_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "x_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"x_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "y_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"y_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "z_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"z_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "sigmaxy_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaxy_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "sigmaz_var", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaz_var_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ")", ")", "\n", "\n", "# Non-trainable variables.", "\n", "", "I_sim", "=", "[", "]", "\n", "x_sim", "=", "[", "]", "\n", "y_sim", "=", "[", "]", "\n", "z_sim", "=", "[", "]", "\n", "sigmaxy_sim", "=", "[", "]", "\n", "sigmaz_sim", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_points", ")", ":", "\n", "        ", "I_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"I_sim_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "x_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"x_sim_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "y_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"y_sim%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "z_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"z_sim_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "sigmaxy_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaxy_sim_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "sigmaz_sim", ".", "append", "(", "tf", ".", "get_variable", "(", "\n", "\"sigmaz_sim_%d\"", "%", "i", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", ")", "\n", "\n", "# predict", "\n", "", "def", "point_spread_function_3d", "(", "theta", ")", ":", "\n", "        ", "'''\n        Microscopic fluorescence point spread function\n        Args:\n          theta : Variables in the point spread function, [I0, x0, y0, z0, sigmaxy, sigmaz]\n        Returns:\n          I : fluorescence image, the size is [batch_size, size_x * size_y * sizez]\n        '''", "\n", "priors_list", "=", "[", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "0", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "1", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "0.5", ",", "high", "=", "ROI", "[", "2", "]", "-", "1", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "2", ",", "high", "=", "4", ")", ",", "\n", "tfd", ".", "Uniform", "(", "low", "=", "2", ",", "high", "=", "4", ")", "]", "\n", "xs", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "0", "]", "-", "1", ")", ",", "ROI", "[", "0", "]", ")", "\n", "ys", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "1", "]", "-", "1", ")", ",", "ROI", "[", "1", "]", ")", "\n", "zs", "=", "tf", ".", "linspace", "(", "0.0", ",", "float", "(", "ROI", "[", "2", "]", "-", "1", ")", ",", "ROI", "[", "2", "]", ")", "\n", "X", ",", "Y", ",", "Z", "=", "tf", ".", "meshgrid", "(", "xs", ",", "ys", ",", "zs", ")", "\n", "\n", "I0", "=", "priors_list", "[", "0", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "0", "]", ",", "[", "theta", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "x0", "=", "priors_list", "[", "1", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "1", "]", ",", "[", "theta", "[", "1", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "y0", "=", "priors_list", "[", "2", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "2", "]", ",", "[", "theta", "[", "2", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "z0", "=", "priors_list", "[", "3", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "3", "]", ",", "[", "theta", "[", "3", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "sigmaxy", "=", "priors_list", "[", "4", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "4", "]", ",", "[", "theta", "[", "4", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "sigmaz", "=", "priors_list", "[", "5", "]", ".", "quantile", "(", "tf", ".", "reshape", "(", "theta", "[", "5", "]", ",", "[", "theta", "[", "5", "]", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ")", "\n", "\n", "xk", "=", "tf", ".", "reshape", "(", "X", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "yk", "=", "tf", ".", "reshape", "(", "Y", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "zk", "=", "tf", ".", "reshape", "(", "Z", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "\n", "I", "=", "I0", "*", "(", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "x0", "+", "xk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "x0", "+", "xk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", ")", "*", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "y0", "+", "yk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "y0", "+", "yk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaxy", ")", ")", ")", "*", "(", "-", "tf", ".", "math", ".", "erf", "(", "(", "-", "0.5", "-", "z0", "+", "zk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaz", ")", ")", "+", "tf", ".", "math", ".", "erf", "(", "(", "0.5", "-", "z0", "+", "zk", ")", "/", "(", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "*", "sigmaz", ")", ")", ")", ")", "/", "8.0", "\n", "return", "I", "\n", "\n", "", "y_pred", "=", "tf", ".", "add_n", "(", "[", "\n", "point_spread_function_3d", "(", "[", "I_var", "[", "i", "]", ",", "x_var", "[", "i", "]", ",", "y_var", "[", "i", "]", ",", "z_var", "[", "i", "]", ",", "sigmaxy_var", "[", "i", "]", ",", "sigmaz_var", "[", "i", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "num_points", ")", "]", ")", "\n", "\n", "y_sim", "=", "tf", ".", "add_n", "(", "[", "\n", "point_spread_function_3d", "(", "[", "I_sim", "[", "i", "]", ",", "x_sim", "[", "i", "]", ",", "y_sim", "[", "i", "]", ",", "z_sim", "[", "i", "]", ",", "sigmaxy_sim", "[", "i", "]", ",", "sigmaz_sim", "[", "i", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "num_points", ")", "]", ")", "\n", "\n", "bg_var", "=", "tf", ".", "get_variable", "(", "\n", "\"bg_var\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "bg_sim", "=", "tf", ".", "get_variable", "(", "\n", "\"bg_sim\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "1", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "obj", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "math", ".", "reduce_sum", "(", "(", "y_pred", "+", "bg_var", "-", "tf", ".", "math", ".", "l2_normalize", "(", "y_sim", "+", "bg_sim", ",", "axis", "=", "1", ")", ")", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "return", "obj", "\n", "", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.square_cos": [[959, 996], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.random_normal_initializer", "tensorflow.random_uniform_initializer", "tensorflow.random_uniform_initializer", "tensorflow.random_uniform_initializer", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.math.cos"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.cos"], ["", "def", "square_cos", "(", "batch_size", "=", "128", ",", "num_dims", "=", "10", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "  ", "def", "build", "(", ")", ":", "\n", "    ", "\"\"\"Builds loss graph.\"\"\"", "\n", "\n", "# Trainable variable.", "\n", "x", "=", "tf", ".", "get_variable", "(", "\n", "\"x\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", ")", "\n", "\n", "# Non-trainable variables.", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "y", "=", "tf", ".", "get_variable", "(", "\"y\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "wcos", "=", "tf", ".", "get_variable", "(", "\"wcos\"", ",", "\n", "shape", "=", "[", "batch_size", ",", "num_dims", ",", "num_dims", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "product", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "w", ",", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", ")", "\n", "product2", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "wcos", ",", "tf", ".", "expand_dims", "(", "10", "*", "tf", ".", "math", ".", "cos", "(", "2", "*", "3.1415926", "*", "x", ")", ",", "-", "1", ")", ")", ")", "\n", "product3", "=", "tf", ".", "reduce_sum", "(", "(", "product", "-", "y", ")", "**", "2", ",", "1", ")", "-", "tf", ".", "reduce_sum", "(", "product2", ",", "1", ")", "+", "10", "*", "num_dims", "\n", "\n", "return", "tf", ".", "reduce_mean", "(", "product3", ")", "\n", "# return tf.reduce_mean(tf.reduce_mean(tf.reduce_sum((product - y) ** 2, 1)) - tf.reduce_mean(tf.reduce_sum(product2, 1)) + 10*num_dims)", "\n", "\n", "", "return", "build", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.train_dm.main": [[63, 229], ["util.get_config", "meta_dm_train.MetaOptimizer", "meta.MetaOptimizer.meta_minimize", "tensorflow.ConfigProto", "data_generator.data_loader", "p_val_x.append", "tensorflow.assign", "tensorflow.contrib.learn.python.learn.monitored_session.MonitoredSession", "timeit.default_timer", "tensorflow.get_default_graph().finalize", "float", "six.moves.xrange", "print", "int", "os.path.exists", "os.mkdir", "tensorflow.placeholder", "range", "sess.run", "sess.run", "print", "float", "len", "tensorflow.get_default_graph", "util.run_epoch", "data_generator.data_loader.get_data", "util.run_epoch", "six.moves.xrange", "print", "FLAGS.mt_ratios.split", "random.random", "util.run_epoch", "meta.MetaOptimizer.save", "meta.MetaOptimizer.save", "timeit.default_timer", "len", "meta.MetaOptimizer.save", "meta.MetaOptimizer.save", "print", "meta.MetaOptimizer.restore", "six.moves.xrange", "print", "zip", "len", "util.run_epoch", "print"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_minimize", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.get_data", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restore", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch"], ["def", "main", "(", "_", ")", ":", "\n", "# Configuration.", "\n", "    ", "if", "FLAGS", ".", "if_cl", ":", "\n", "        ", "num_steps", "=", "[", "100", ",", "200", ",", "500", ",", "1000", ",", "1500", ",", "2000", ",", "2500", ",", "3000", "]", "\n", "num_unrolls", "=", "[", "int", "(", "ns", "/", "FLAGS", ".", "unroll_length", ")", "for", "ns", "in", "num_steps", "]", "\n", "num_unrolls_eval", "=", "num_unrolls", "[", "1", ":", "]", "\n", "curriculum_idx", "=", "0", "\n", "", "else", ":", "\n", "        ", "num_unrolls", "=", "FLAGS", ".", "num_steps", "//", "FLAGS", ".", "unroll_length", "\n", "\n", "# Output path.", "\n", "", "if", "FLAGS", ".", "save_path", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "save_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "FLAGS", ".", "save_path", ")", "\n", "\n", "# Problem.", "\n", "", "", "problem", ",", "net_config", ",", "net_assignments", "=", "util", ".", "get_config", "(", "FLAGS", ".", "problem", ")", "\n", "\n", "# Optimizer setup.", "\n", "optimizer", "=", "meta", ".", "MetaOptimizer", "(", "FLAGS", ".", "num_mt", ",", "**", "net_config", ")", "\n", "minimize", ",", "scale", ",", "var_x", ",", "constants", ",", "subsets", ",", "loss_mt", ",", "steps_mt", ",", "update_mt", ",", "reset_mt", ",", "mt_labels", ",", "mt_inputs", "=", "optimizer", ".", "meta_minimize", "(", "\n", "problem", ",", "FLAGS", ".", "unroll_length", ",", "\n", "learning_rate", "=", "FLAGS", ".", "learning_rate", ",", "\n", "net_assignments", "=", "net_assignments", ",", "\n", "second_derivatives", "=", "FLAGS", ".", "second_derivatives", ")", "\n", "step", ",", "update", ",", "reset", ",", "cost_op", ",", "_", "=", "minimize", "\n", "\n", "# Data generator for multi-task learning.", "\n", "if", "FLAGS", ".", "if_mt", ":", "\n", "        ", "data_mt", "=", "data_loader", "(", "problem", ",", "var_x", ",", "constants", ",", "subsets", ",", "scale", ",", "\n", "FLAGS", ".", "optimizers", ",", "FLAGS", ".", "unroll_length", ")", "\n", "if", "FLAGS", ".", "if_cl", ":", "\n", "            ", "mt_ratios", "=", "[", "float", "(", "r", ")", "for", "r", "in", "FLAGS", ".", "mt_ratios", ".", "split", "(", ")", "]", "\n", "\n", "# Assign func.", "\n", "", "", "p_val_x", "=", "[", "]", "\n", "for", "k", "in", "var_x", ":", "\n", "        ", "p_val_x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "k", ".", "shape", ")", ")", "\n", "", "assign_ops", "=", "[", "tf", ".", "assign", "(", "var_x", "[", "k_id", "]", ",", "p_val_x", "[", "k_id", "]", ")", "for", "k_id", "in", "range", "(", "len", "(", "p_val_x", ")", ")", "]", "\n", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "ms", ".", "MonitoredSession", "(", ")", "as", "sess", ":", "\n", "        ", "def", "assign_func", "(", "val_x", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_ops", ",", "feed_dict", "=", "{", "p", ":", "v", "for", "p", ",", "v", "in", "zip", "(", "p_val_x", ",", "val_x", ")", "}", ")", "\n", "\n", "# tf1.14", "\n", "", "for", "rst", "in", "[", "reset", "]", "+", "reset_mt", ":", "\n", "            ", "sess", ".", "run", "(", "rst", ")", "\n", "\n", "# Start.", "\n", "", "start_time", "=", "timer", "(", ")", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "best_evaluation", "=", "float", "(", "\"inf\"", ")", "\n", "num_eval", "=", "0", "\n", "improved", "=", "False", "\n", "mti", "=", "-", "1", "\n", "for", "e", "in", "xrange", "(", "FLAGS", ".", "num_epochs", ")", ":", "\n", "# Pick a task if it's multi-task learning.", "\n", "            ", "if", "FLAGS", ".", "if_mt", ":", "\n", "                ", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "if", "curriculum_idx", ">=", "len", "(", "mt_ratios", ")", ":", "\n", "                        ", "mt_ratio", "=", "mt_ratios", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "mt_ratio", "=", "mt_ratios", "[", "curriculum_idx", "]", "\n", "", "", "else", ":", "\n", "                    ", "mt_ratio", "=", "FLAGS", ".", "mt_ratio", "\n", "", "if", "random", ".", "random", "(", ")", "<", "mt_ratio", ":", "\n", "                    ", "mti", "=", "(", "mti", "+", "1", ")", "%", "FLAGS", ".", "num_mt", "\n", "task_i", "=", "mti", "\n", "", "else", ":", "\n", "                    ", "task_i", "=", "-", "1", "\n", "", "", "else", ":", "\n", "                ", "task_i", "=", "-", "1", "\n", "\n", "# Training.", "\n", "", "if", "FLAGS", ".", "if_cl", ":", "\n", "                ", "num_unrolls_cur", "=", "num_unrolls", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                ", "num_unrolls_cur", "=", "num_unrolls", "\n", "\n", "", "if", "task_i", "==", "-", "1", ":", "\n", "                ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", ",", "step", "]", ",", "reset", ",", "\n", "num_unrolls_cur", ",", "\n", "scale", "=", "scale", ",", "\n", "rd_scale", "=", "FLAGS", ".", "if_scale", ",", "\n", "rd_scale_bound", "=", "FLAGS", ".", "rd_scale_bound", ",", "\n", "assign_func", "=", "assign_func", ",", "\n", "var_x", "=", "var_x", ")", "\n", "", "else", ":", "\n", "                ", "data_e", "=", "data_mt", ".", "get_data", "(", "task_i", ",", "sess", ",", "num_unrolls_cur", ",", "assign_func", ",", "FLAGS", ".", "rd_scale_bound", ",", "\n", "if_scale", "=", "FLAGS", ".", "if_scale", ",", "mt_k", "=", "FLAGS", ".", "k", ")", "\n", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "loss_mt", "[", "task_i", "]", ",", "[", "update_mt", "[", "task_i", "]", ",", "steps_mt", "[", "task_i", "]", "]", ",", "reset_mt", "[", "task_i", "]", ",", "\n", "num_unrolls_cur", ",", "\n", "scale", "=", "scale", ",", "\n", "rd_scale", "=", "FLAGS", ".", "if_scale", ",", "\n", "rd_scale_bound", "=", "FLAGS", ".", "rd_scale_bound", ",", "\n", "assign_func", "=", "assign_func", ",", "\n", "var_x", "=", "var_x", ",", "\n", "task_i", "=", "task_i", ",", "\n", "data", "=", "data_e", ",", "\n", "label_pl", "=", "mt_labels", "[", "task_i", "]", ",", "\n", "input_pl", "=", "mt_inputs", "[", "task_i", "]", ")", "\n", "", "print", "(", "\"training_loss={}\"", ".", "format", "(", "cost", ")", ")", "\n", "\n", "# Evaluation.", "\n", "if", "(", "e", "+", "1", ")", "%", "FLAGS", ".", "evaluation_period", "==", "0", ":", "\n", "                ", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "num_unrolls_eval_cur", "=", "num_unrolls_eval", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                    ", "num_unrolls_eval_cur", "=", "num_unrolls", "\n", "", "num_eval", "+=", "1", "\n", "\n", "eval_cost", "=", "0", "\n", "for", "_", "in", "xrange", "(", "FLAGS", ".", "evaluation_epochs", ")", ":", "\n", "                    ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "reset", ",", "\n", "num_unrolls_eval_cur", ")", "\n", "eval_cost", "+=", "cost", "\n", "\n", "", "if", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "num_steps_cur", "=", "num_steps", "[", "curriculum_idx", "]", "\n", "", "else", ":", "\n", "                    ", "num_steps_cur", "=", "FLAGS", ".", "num_steps", "\n", "", "print", "(", "\"epoch={}, num_steps={}, eval_loss={}\"", ".", "format", "(", "\n", "e", ",", "num_steps_cur", ",", "eval_cost", "/", "FLAGS", ".", "evaluation_epochs", ")", ",", "flush", "=", "True", ")", "\n", "\n", "if", "not", "FLAGS", ".", "if_cl", ":", "\n", "                    ", "if", "eval_cost", "<", "best_evaluation", ":", "\n", "                        ", "best_evaluation", "=", "eval_cost", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "e", "+", "1", ")", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "0", ")", "\n", "print", "(", "\"Saving optimizer of epoch {}...\"", ".", "format", "(", "e", "+", "1", ")", ")", "\n", "", "continue", "\n", "\n", "# Curriculum learning.", "\n", "# update curriculum", "\n", "", "if", "eval_cost", "<", "best_evaluation", ":", "\n", "                    ", "best_evaluation", "=", "eval_cost", "\n", "improved", "=", "True", "\n", "# save model", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "curriculum_idx", ")", "\n", "optimizer", ".", "save", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "0", ")", "\n", "", "elif", "num_eval", ">=", "FLAGS", ".", "min_num_eval", "and", "improved", ":", "\n", "# restore model", "\n", "                    ", "optimizer", ".", "restore", "(", "sess", ",", "FLAGS", ".", "save_path", ",", "curriculum_idx", ")", "\n", "num_eval", "=", "0", "\n", "improved", "=", "False", "\n", "curriculum_idx", "+=", "1", "\n", "if", "curriculum_idx", ">=", "len", "(", "num_unrolls", ")", ":", "\n", "                        ", "curriculum_idx", "=", "-", "1", "\n", "\n", "# initial evaluation for next curriculum", "\n", "", "eval_cost", "=", "0", "\n", "for", "_", "in", "xrange", "(", "FLAGS", ".", "evaluation_epochs", ")", ":", "\n", "                        ", "time", ",", "cost", "=", "util", ".", "run_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "reset", ",", "\n", "num_unrolls_eval", "[", "curriculum_idx", "]", ")", "\n", "eval_cost", "+=", "cost", "\n", "", "best_evaluation", "=", "eval_cost", "\n", "print", "(", "\"epoch={}, num_steps={}, eval loss={}\"", ".", "format", "(", "\n", "e", ",", "num_steps", "[", "curriculum_idx", "]", ",", "eval_cost", "/", "FLAGS", ".", "evaluation_epochs", ")", ",", "flush", "=", "True", ")", "\n", "", "elif", "num_eval", ">=", "FLAGS", ".", "min_num_eval", "and", "not", "improved", ":", "\n", "                    ", "print", "(", "\"no improve during curriculum {} --> stop\"", ".", "format", "(", "curriculum_idx", ")", ")", "\n", "break", "\n", "\n", "", "", "", "print", "(", "\"total time = {}s...\"", ".", "format", "(", "timer", "(", ")", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.__init__": [[230, 258], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_mt", ",", "beta1", ",", "beta2", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MetaOptimizer.\n\n    Args:\n      **kwargs: A set of keyword arguments mapping network identifiers (the\n          keys) to parameters that will be passed to networks.Factory (see docs\n          for more info).  These can be used to assign different optimizee\n          parameters to different optimizers (see net_assignments in the\n          meta_loss method).\n    \"\"\"", "\n", "self", ".", "_nets", "=", "None", "\n", "self", ".", "beta1", "=", "beta1", "\n", "self", ".", "beta2", "=", "beta2", "\n", "self", ".", "num_mt", "=", "num_mt", "\n", "if", "not", "kwargs", ":", "\n", "# Use a default coordinatewise network if nothing is given. this allows", "\n", "# for no network spec and no assignments.", "\n", "      ", "self", ".", "_config", "=", "{", "\n", "\"coordinatewise\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", "}", "}", "\n", "", "else", ":", "\n", "      ", "self", ".", "_config", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.save": [[259, 275], ["meta_rnnprop_train.MetaOptimizer._nets.items", "networks.save", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "", "def", "save", "(", "self", ",", "sess", ",", "path", "=", "None", ",", "index", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save meta-optimizer.\"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "if", "path", "is", "None", ":", "\n", "        ", "filename", "=", "None", "\n", "key", "=", "k", "\n", "", "elif", "index", "is", "not", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "key", "=", "filename", "\n", "", "else", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l\"", ".", "format", "(", "k", ")", ")", "\n", "key", "=", "filename", "\n", "", "net_vars", "=", "networks", ".", "save", "(", "net", ",", "sess", ",", "filename", "=", "filename", ")", "\n", "result", "[", "key", "]", "=", "net_vars", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.restorer": [[276, 290], ["meta_rnnprop_train.MetaOptimizer._nets.items", "sonnet.get_variables_in_module", "collections.defaultdict", "collections.defaultdict", "[].split", "tensorflow.placeholder", "tensorflow.assign", "v.get_shape", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "restorer", "(", "self", ")", ":", "\n", "    ", "self", ".", "restore_pl", "=", "{", "}", "\n", "self", ".", "assigns", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "self", ".", "restore_pl", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "self", ".", "assigns", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "placeholder", "(", "name", "=", "\"{}_{}_pl\"", ".", "format", "(", "module_name", ",", "variable_name", ")", ",", "shape", "=", "v", ".", "get_shape", "(", ")", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "assign", "(", "v", ",", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.restore": [[291, 305], ["meta_rnnprop_train.MetaOptimizer._nets.items", "sess.run", "os.path.join", "pickle.load", "sonnet.get_variables_in_module", "open", "[].split", "tensorflow.python.framework.ops.append", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "", "def", "restore", "(", "self", ",", "sess", ",", "path", ",", "index", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "feed", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "data", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "feed", "[", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "]", "=", "data", "[", "module_name", "]", "[", "variable_name", "]", "\n", "ops", ".", "append", "(", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "", "", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "feed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.meta_loss": [[306, 594], ["meta_rnnprop_train._get_variables", "print", "print", "print", "print", "tensorflow.placeholder", "meta_rnnprop_train._make_nets", "print", "print", "enumerate", "tensorflow.TensorArray", "tensorflow.while_loop", "tensorflow.reduce_sum", "len", "range", "sum", "print", "range", "range", "range", "nets.items", "scale.append", "tensorflow.name_scope", "enumerate", "zip", "state_mt.append", "state_vt.append", "list", "tensorflow.name_scope", "meta_rnnprop_train._make_with_custom_variables", "fx_array.write.write.write", "fx_array.write.write.stack", "state_reshape.append", "enumerate", "state_mt_reshape.append", "state_vt_reshape.append", "mt_labels.append", "mt_inputs.append", "tensorflow.TensorArray", "tensorflow.while_loop", "state_reshape_final.append", "state_mt_reshape_final.append", "state_vt_reshape_final.append", "tensorflow.reduce_sum", "tensorflow.name_scope", "tensorflow.name_scope", "print", "print", "MetaLoss", "tensorflow.placeholder_with_default", "zip", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.name_scope", "tensorflow.gradients", "tensorflow.name_scope", "zip", "meta_rnnprop_train._nested_tuple", "list", "tensorflow.name_scope", "meta_rnnprop_train._make_with_custom_variables", "fx_array.write.write.write", "tensorflow.name_scope", "zip", "tensorflow.name_scope", "range", "state_reshape_mti.append", "zip", "tensorflow.Variable", "tensorflow.Variable", "state_mt_reshape_mti.append", "state_vt_reshape_mti.append", "enumerate", "loss_array.write.write.write", "range", "loss_array.write.write.stack", "enumerate", "tensorflow.assign", "tensorflow.assign", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.ones", "tensorflow.name_scope", "state.append", "tensorflow.zeros", "tensorflow.zeros", "meta_rnnprop_train.MetaOptimizer.meta_loss.update"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._get_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_nets", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], ["", "def", "meta_loss", "(", "self", ",", "\n", "make_loss", ",", "\n", "len_unroll", ",", "\n", "net_assignments", "=", "None", ",", "\n", "second_derivatives", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns an operator computing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      net_assignments: variable to optimizer mapping. If not None, it should be\n          a list of (k, names) tuples, where k is a valid key in the kwargs\n          passed at at construction time and names is a list of variable names.\n      second_derivatives: Use second derivatives (default is false).\n\n    Returns:\n      namedtuple containing (loss, update, reset, fx, x), ...\n    \"\"\"", "\n", "\n", "# Construct an instance of the problem only to grab the variables. This", "\n", "# loss will never be evaluated.", "\n", "# pdb.set_trace()", "\n", "\n", "x", ",", "constants", "=", "_get_variables", "(", "make_loss", ")", "\n", "\n", "print", "(", "\"Optimizee variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "x", "]", ")", "\n", "print", "(", "\"Problem variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "constants", "]", ")", "\n", "\n", "# create scale placeholder here", "\n", "scale", "=", "[", "]", "\n", "for", "k", "in", "x", ":", "\n", "      ", "scale", ".", "append", "(", "tf", ".", "placeholder_with_default", "(", "tf", ".", "ones", "(", "shape", "=", "k", ".", "shape", ")", ",", "shape", "=", "k", ".", "shape", ",", "name", "=", "k", ".", "name", "[", ":", "-", "2", "]", "+", "\"_scale\"", ")", ")", "\n", "", "step", "=", "tf", ".", "placeholder", "(", "shape", "=", "(", ")", ",", "name", "=", "\"step\"", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "# Create the optimizer networks and find the subsets of variables to assign", "\n", "# to each optimizer.", "\n", "nets", ",", "net_keys", ",", "subsets", "=", "_make_nets", "(", "x", ",", "self", ".", "_config", ",", "net_assignments", ")", "\n", "print", "(", "'nets'", ",", "nets", ")", "\n", "print", "(", "'subsets'", ",", "subsets", ")", "\n", "# Store the networks so we can save them later.", "\n", "self", ".", "_nets", "=", "nets", "\n", "\n", "# Create hidden state for each subset of variables.", "\n", "state", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"states\"", ")", ":", "\n", "      ", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "net", "=", "nets", "[", "key", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"state_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "          ", "state", ".", "append", "(", "_nested_variable", "(", "\n", "[", "net", ".", "initial_state_for_inputs", "(", "x", "[", "j", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "j", "in", "subset", "]", ",", "\n", "name", "=", "\"state\"", ",", "trainable", "=", "False", ")", ")", "\n", "# m and v in adam", "\n", "", "", "", "state_mt", "=", "[", "]", "\n", "state_vt", "=", "[", "]", "\n", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "      ", "mt", "=", "[", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "x", "[", "j", "]", ".", "shape", ")", ",", "name", "=", "x", "[", "j", "]", ".", "name", "[", ":", "-", "2", "]", "+", "\"_mt\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "for", "j", "in", "subset", "]", "\n", "vt", "=", "[", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "x", "[", "j", "]", ".", "shape", ")", ",", "name", "=", "x", "[", "j", "]", ".", "name", "[", ":", "-", "2", "]", "+", "\"_vt\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "for", "j", "in", "subset", "]", "\n", "state_mt", ".", "append", "(", "mt", ")", "\n", "state_vt", ".", "append", "(", "vt", ")", "\n", "\n", "", "def", "update", "(", "net", ",", "fx", ",", "x", ",", "state", ",", "mt", ",", "vt", ",", "t", ")", ":", "\n", "      ", "\"\"\"Parameter and RNN state update.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"gradients\"", ")", ":", "\n", "        ", "gradients", "=", "tf", ".", "gradients", "(", "fx", ",", "x", ")", "\n", "\n", "# Stopping the gradient here corresponds to what was done in the", "\n", "# original L2L NIPS submission. However it looks like things like", "\n", "# BatchNorm, etc. don't support second-derivatives so we still need", "\n", "# this term.", "\n", "if", "not", "second_derivatives", ":", "\n", "          ", "gradients", "=", "[", "tf", ".", "stop_gradient", "(", "g", ")", "for", "g", "in", "gradients", "]", "\n", "# update mt and vt", "\n", "", "mt_next", "=", "[", "self", ".", "beta1", "*", "m", "+", "(", "1.0", "-", "self", ".", "beta1", ")", "*", "g", "for", "m", ",", "g", "in", "zip", "(", "mt", ",", "gradients", ")", "]", "\n", "mt_hat", "=", "[", "m", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta1", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "for", "m", "in", "mt_next", "]", "\n", "vt_next", "=", "[", "self", ".", "beta2", "*", "v", "+", "(", "1.0", "-", "self", ".", "beta2", ")", "*", "g", "*", "g", "for", "v", ",", "g", "in", "zip", "(", "vt", ",", "gradients", ")", "]", "\n", "vt_hat", "=", "[", "v", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta2", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "for", "v", "in", "vt_next", "]", "\n", "mt_tilde", "=", "[", "m", "/", "(", "tf", ".", "sqrt", "(", "v", ")", "+", "1e-8", ")", "for", "m", ",", "v", "in", "zip", "(", "mt_hat", ",", "vt_hat", ")", "]", "\n", "gt_tilde", "=", "[", "g", "/", "(", "tf", ".", "sqrt", "(", "v", ")", "+", "1e-8", ")", "for", "g", ",", "v", "in", "zip", "(", "gradients", ",", "vt_hat", ")", "]", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", ",", "state_next", "=", "zip", "(", "*", "[", "net", "(", "m", ",", "g", ",", "s", ")", "for", "m", ",", "g", ",", "s", "in", "zip", "(", "mt_tilde", ",", "gt_tilde", ",", "state", ")", "]", ")", "\n", "state_next", "=", "_nested_tuple", "(", "state_next", ")", "\n", "state_next", "=", "list", "(", "state_next", ")", "\n", "\n", "", "return", "deltas", ",", "state_next", ",", "mt_next", ",", "vt_next", "\n", "\n", "", "def", "time_step", "(", "t", ",", "fx_array", ",", "x", ",", "state", ",", "state_mt", ",", "state_vt", ")", ":", "\n", "      ", "\"\"\"While loop body.\"\"\"", "\n", "x_next", "=", "list", "(", "x", ")", "\n", "state_next", "=", "[", "]", "\n", "state_mt_next", "=", "[", "]", "\n", "state_vt_next", "=", "[", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "        ", "scaled_x", "=", "[", "x", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "t", ",", "fx", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"dx\"", ")", ":", "\n", "        ", "for", "subset", ",", "key", ",", "s_i", ",", "mt", ",", "vt", "in", "zip", "(", "subsets", ",", "net_keys", ",", "state", ",", "state_mt", ",", "state_vt", ")", ":", "\n", "          ", "x_i", "=", "[", "x", "[", "j", "]", "for", "j", "in", "subset", "]", "\n", "deltas", ",", "s_i_next", ",", "mt_i_next", ",", "vt_i_next", "=", "update", "(", "nets", "[", "key", "]", ",", "fx", ",", "x_i", ",", "s_i", ",", "mt", ",", "vt", ",", "t", ")", "\n", "for", "idx", ",", "j", "in", "enumerate", "(", "subset", ")", ":", "\n", "            ", "delta", "=", "deltas", "[", "idx", "]", "\n", "x_next", "[", "j", "]", "+=", "delta", "\n", "", "state_next", ".", "append", "(", "s_i_next", ")", "\n", "state_mt_next", ".", "append", "(", "mt_i_next", ")", "\n", "state_vt_next", ".", "append", "(", "vt_i_next", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"t_next\"", ")", ":", "\n", "        ", "t_next", "=", "t", "+", "1", "\n", "\n", "", "return", "t_next", ",", "fx_array", ",", "x_next", ",", "state_next", ",", "state_mt_next", ",", "state_vt_next", "\n", "\n", "# Define the while loop.", "\n", "", "fx_array", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", "+", "1", ",", "\n", "clear_after_read", "=", "False", ")", "\n", "_", ",", "fx_array", ",", "x_final", ",", "s_final", ",", "mt_final", ",", "vt_final", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "(", "0", ",", "fx_array", ",", "x", ",", "state", ",", "state_mt", ",", "state_vt", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "      ", "scaled_x_final", "=", "[", "x_final", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx_final", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x_final", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "len_unroll", ",", "fx_final", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "fx_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss\"", ")", "\n", "\n", "##################################", "\n", "### multi task learning losses ###", "\n", "##################################", "\n", "# state (num_subsets, num_x, (num_layers, (h,c)))", "\n", "# state_reshape (num_mt, num_subsets, (num_layers, (h, c)))", "\n", "state_reshape", "=", "[", "]", "\n", "num_layers", "=", "len", "(", "state", "[", "0", "]", "[", "0", "]", ")", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "state_reshape_mti", "=", "[", "]", "\n", "for", "state_subset", "in", "state", ":", "\n", "        ", "state_layers", "=", "(", ")", "\n", "for", "li", "in", "range", "(", "num_layers", ")", ":", "\n", "          ", "h", "=", "tf", ".", "concat", "(", "[", "st_x", "[", "li", "]", "[", "0", "]", "for", "st_x", "in", "state_subset", "]", ",", "axis", "=", "0", ")", "\n", "c", "=", "tf", ".", "concat", "(", "[", "st_x", "[", "li", "]", "[", "1", "]", "for", "st_x", "in", "state_subset", "]", ",", "axis", "=", "0", ")", "\n", "h", "=", "tf", ".", "Variable", "(", "h", ",", "name", "=", "\"state_reshape_h\"", ",", "trainable", "=", "False", ")", "\n", "c", "=", "tf", ".", "Variable", "(", "c", ",", "name", "=", "\"state_reshape_c\"", ",", "trainable", "=", "False", ")", "\n", "state_layers", "+=", "(", "(", "h", ",", "c", ")", ",", ")", "\n", "", "state_reshape_mti", ".", "append", "(", "state_layers", ")", "\n", "", "state_reshape", ".", "append", "(", "state_reshape_mti", ")", "\n", "", "if", "self", ".", "num_mt", ">", "0", ":", "\n", "      ", "shapes", "=", "[", "st_subset", "[", "0", "]", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "for", "st_subset", "in", "state_reshape", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "      ", "shapes", "=", "[", "]", "\n", "", "num_params_total", "=", "sum", "(", "shapes", ")", "\n", "print", "(", "\"number of parameters = {}\"", ".", "format", "(", "num_params_total", ")", ")", "\n", "\n", "# m and v in adam", "\n", "# state_reshape (num_subsets, num_x, dim_x)", "\n", "# state_mt_reshape (num_mt, num_subsets, num_params)", "\n", "state_mt_reshape", "=", "[", "]", "\n", "state_vt_reshape", "=", "[", "]", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "state_mt_reshape_mti", "=", "[", "]", "\n", "state_vt_reshape_mti", "=", "[", "]", "\n", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "mt", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "(", "shapes", "[", "i", "]", ",", ")", ")", ",", "name", "=", "\"state_mt_{}_{}\"", ".", "format", "(", "mti", ",", "i", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "vt", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "(", "shapes", "[", "i", "]", ",", ")", ")", ",", "name", "=", "\"state_vt_{}_{}\"", ".", "format", "(", "mti", ",", "i", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "state_mt_reshape_mti", ".", "append", "(", "mt", ")", "\n", "state_vt_reshape_mti", ".", "append", "(", "vt", ")", "\n", "", "state_mt_reshape", ".", "append", "(", "state_mt_reshape_mti", ")", "\n", "state_vt_reshape", ".", "append", "(", "state_vt_reshape_mti", ")", "\n", "\n", "# placeholder (num_mt, num_subsets, len_unroll, num_params)", "\n", "", "mt_labels", "=", "[", "]", "\n", "mt_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "mt_labels", ".", "append", "(", "\n", "[", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "len_unroll", ",", "shapes", "[", "j", "]", ")", ",", "\n", "name", "=", "\"mt{}_label_subset{}\"", ".", "format", "(", "i", ",", "j", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "subsets", ")", ")", "]", "\n", ")", "\n", "mt_inputs", ".", "append", "(", "\n", "[", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "len_unroll", ",", "shapes", "[", "j", "]", ")", ",", "\n", "name", "=", "\"mt{}_input_subset{}\"", ".", "format", "(", "i", ",", "j", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "subsets", ")", ")", "]", "\n", ")", "\n", "\n", "# loop", "\n", "", "def", "time_step_mt", "(", "mti", ")", ":", "\n", "      ", "def", "time_step_func", "(", "t", ",", "loss_array", ",", "states", ",", "state_mt", ",", "state_vt", ")", ":", "\n", "        ", "loss_t_sum", "=", "0.0", "\n", "state_next", "=", "[", "]", "\n", "state_mt_next", "=", "[", "]", "\n", "state_vt_next", "=", "[", "]", "\n", "for", "si", ",", "(", "k", ",", "st", ",", "m", ",", "v", ")", "in", "enumerate", "(", "zip", "(", "net_keys", ",", "states", ",", "state_mt", ",", "state_vt", ")", ")", ":", "\n", "          ", "net", "=", "nets", "[", "k", "]", "\n", "g", "=", "tf", ".", "gather", "(", "mt_inputs", "[", "mti", "]", "[", "si", "]", ",", "indices", "=", "t", ",", "axis", "=", "0", ")", "\n", "g_label", "=", "tf", ".", "gather", "(", "mt_labels", "[", "mti", "]", "[", "si", "]", ",", "indices", "=", "t", ",", "axis", "=", "0", ")", "\n", "\n", "# update mt and vt", "\n", "mt_next", "=", "self", ".", "beta1", "*", "m", "+", "(", "1.0", "-", "self", ".", "beta1", ")", "*", "g", "\n", "mt_hat", "=", "mt_next", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta1", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "\n", "vt_next", "=", "self", ".", "beta2", "*", "v", "+", "(", "1.0", "-", "self", ".", "beta2", ")", "*", "g", "*", "g", "\n", "vt_hat", "=", "vt_next", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta2", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "\n", "mt_tilde", "=", "mt_hat", "/", "(", "tf", ".", "sqrt", "(", "vt_hat", ")", "+", "1e-8", ")", "\n", "gt_tilde", "=", "g", "/", "(", "tf", ".", "sqrt", "(", "vt_hat", ")", "+", "1e-8", ")", "\n", "\n", "# net", "\n", "delta", ",", "state_next_si", "=", "net", "(", "mt_tilde", ",", "gt_tilde", ",", "st", ")", "\n", "loss_t_sum", "+=", "tf", ".", "reduce_sum", "(", "(", "g_label", "-", "delta", ")", "*", "(", "g_label", "-", "delta", ")", ")", "*", "0.5", "\n", "state_next_si", "=", "_nested_tuple", "(", "state_next_si", ")", "\n", "state_next", ".", "append", "(", "state_next_si", ")", "\n", "state_mt_next", ".", "append", "(", "mt_next", ")", "\n", "state_vt_next", ".", "append", "(", "vt_next", ")", "\n", "", "loss_t", "=", "loss_t_sum", "/", "num_params_total", "\n", "loss_array", "=", "loss_array", ".", "write", "(", "t", ",", "loss_t", ")", "\n", "t_next", "=", "t", "+", "1", "\n", "return", "t_next", ",", "loss_array", ",", "state_next", ",", "state_mt_next", ",", "state_vt_next", "\n", "\n", "", "return", "time_step_func", "\n", "\n", "", "loss_arrays", "=", "[", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", ",", "clear_after_read", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "state_reshape_final", "=", "[", "]", "\n", "state_mt_reshape_final", "=", "[", "]", "\n", "state_vt_reshape_final", "=", "[", "]", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", ":", "\n", "      ", "loss_array", "=", "loss_arrays", "[", "mti", "]", "\n", "_", ",", "loss_array", ",", "state_reshape_final_mti", ",", "state_mt_reshape_final_mti", ",", "state_vt_reshape_final_mti", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step_mt", "(", "mti", ")", ",", "\n", "loop_vars", "=", "(", "0", ",", "loss_array", ",", "state_reshape", "[", "mti", "]", ",", "state_mt_reshape", "[", "mti", "]", ",", "state_vt_reshape", "[", "mti", "]", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll_mt_{}\"", ".", "format", "(", "mti", ")", ")", "\n", "loss_arrays", "[", "mti", "]", "=", "loss_array", "\n", "state_reshape_final", ".", "append", "(", "state_reshape_final_mti", ")", "\n", "state_mt_reshape_final", ".", "append", "(", "state_mt_reshape_final_mti", ")", "\n", "state_vt_reshape_final", ".", "append", "(", "state_vt_reshape_final_mti", ")", "\n", "\n", "# loss", "\n", "", "loss_mt", "=", "[", "tf", ".", "reduce_sum", "(", "loss_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss_mt{}\"", ".", "format", "(", "i", ")", ")", "\n", "for", "i", ",", "loss_array", "in", "enumerate", "(", "loss_arrays", ")", "]", "\n", "\n", "\n", "# Reset the state; should be called at the beginning of an epoch.", "\n", "with", "tf", ".", "name_scope", "(", "\"reset\"", ")", ":", "\n", "      ", "variables", "=", "(", "nest", ".", "flatten", "(", "state", ")", "+", "\n", "x", "+", "constants", ")", "\n", "reset_mt", "=", "[", "tf", ".", "assign", "(", "m", ",", "tf", ".", "zeros", "(", "shape", "=", "m", ".", "shape", ")", ")", "for", "mt", "in", "state_mt", "for", "m", "in", "mt", "]", "\n", "reset_vt", "=", "[", "tf", ".", "assign", "(", "v", ",", "tf", ".", "zeros", "(", "shape", "=", "v", ".", "shape", ")", ")", "for", "vt", "in", "state_vt", "for", "v", "in", "vt", "]", "\n", "# Empty array as part of the reset process.", "\n", "reset", "=", "[", "tf", ".", "variables_initializer", "(", "variables", ")", ",", "fx_array", ".", "close", "(", ")", "]", "+", "reset_mt", "+", "reset_vt", "\n", "\n", "# mt", "\n", "variables_mt", "=", "[", "nest", ".", "flatten", "(", "state_reshape", "[", "mti", "]", ")", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "reset_mt_mt", "=", "[", "[", "tf", ".", "assign", "(", "m", ",", "tf", ".", "zeros", "(", "shape", "=", "m", ".", "shape", ")", ")", "for", "m", "in", "mt_mti", "]", "for", "mt_mti", "in", "state_mt_reshape", "]", "\n", "reset_vt_mt", "=", "[", "[", "tf", ".", "assign", "(", "v", ",", "tf", ".", "zeros", "(", "shape", "=", "v", ".", "shape", ")", ")", "for", "v", "in", "vt_mti", "]", "for", "vt_mti", "in", "state_vt_reshape", "]", "\n", "reset_multitask", "=", "[", "[", "tf", ".", "variables_initializer", "(", "variables_mt", "[", "mti", "]", ")", ",", "loss_arrays", "[", "mti", "]", ".", "close", "(", ")", "]", "+", "reset_mt_mt", "[", "mti", "]", "+", "reset_vt_mt", "[", "mti", "]", "\n", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "\n", "# Operator to update the parameters and the RNN state after our loop, but", "\n", "# during an epoch.", "\n", "", "with", "tf", ".", "name_scope", "(", "\"update\"", ")", ":", "\n", "      ", "update", "=", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "x", ",", "x_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state", ",", "s_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_mt", ",", "mt_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_vt", ",", "vt_final", ")", ")", ")", "\n", "# mt", "\n", "update_mt", "=", "[", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_reshape", "[", "mti", "]", ",", "state_reshape_final", "[", "mti", "]", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_mt_reshape", "[", "mti", "]", ",", "state_mt_reshape_final", "[", "mti", "]", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_vt_reshape", "[", "mti", "]", ",", "state_vt_reshape_final", "[", "mti", "]", ")", ")", ")", "for", "mti", "in", "range", "(", "self", ".", "num_mt", ")", "]", "\n", "\n", "\n", "# Log internal variables.", "\n", "", "for", "k", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "      ", "print", "(", "\"Optimizer '{}' variables\"", ".", "format", "(", "k", ")", ")", "\n", "print", "(", "[", "op", "for", "op", "in", "snt", ".", "get_variables_in_module", "(", "net", ")", "]", ")", "\n", "\n", "", "return", "MetaLoss", "(", "loss", ",", "update", ",", "reset", ",", "fx_final", ",", "x_final", ")", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "step", ",", "loss_mt", ",", "update_mt", ",", "reset_multitask", ",", "mt_labels", ",", "mt_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train.MetaOptimizer.meta_minimize": [[595, 625], ["meta_rnnprop_train.MetaOptimizer.meta_loss", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "meta_rnnprop_train.MetaOptimizer.restorer", "optimizer_mt.append", "steps_mt.append", "MetaStep", "tensorflow.train.AdamOptimizer", "optimizer_mt[].minimize"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restorer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "meta_minimize", "(", "self", ",", "make_loss", ",", "len_unroll", ",", "learning_rate", "=", "0.01", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns an operator minimizing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      learning_rate: Learning rate for the Adam optimizer.\n      **kwargs: keyword arguments forwarded to meta_loss.\n\n    Returns:\n      namedtuple containing (step, update, reset, fx, x), ...\n    \"\"\"", "\n", "\n", "info", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "seq_step", ",", "loss_mt", ",", "update_mt", ",", "reset_multitask", ",", "mt_labels", ",", "mt_inputs", "=", "self", ".", "meta_loss", "(", "make_loss", ",", "len_unroll", ",", "**", "kwargs", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "step", "=", "optimizer", ".", "minimize", "(", "info", ".", "loss", ")", "\n", "\n", "# mt", "\n", "optimizer_mt", "=", "[", "]", "\n", "steps_mt", "=", "[", "]", "\n", "for", "loss_mti", "in", "loss_mt", ":", "\n", "      ", "optimizer_mt", ".", "append", "(", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", ")", "\n", "steps_mt", ".", "append", "(", "optimizer_mt", "[", "-", "1", "]", ".", "minimize", "(", "loss_mti", ")", ")", "\n", "\n", "", "self", ".", "restorer", "(", ")", "\n", "\n", "return", "MetaStep", "(", "step", ",", "*", "info", "[", "1", ":", "]", ")", ",", "scale", ",", "x", ",", "constants", ",", "subsets", ",", "seq_step", ",", "loss_mt", ",", "steps_mt", ",", "update_mt", ",", "reset_multitask", ",", "mt_labels", ",", "mt_inputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._nested_assign": [[37, 60], ["isinstance", "isinstance", "isinstance", "tensorflow.assign", "len", "len", "ValueError", "meta_rnnprop_train._nested_assign", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_assign"], ["def", "_nested_assign", "(", "ref", ",", "value", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow assign operations.\n\n  Args:\n    ref: Nested collection of TensorFlow variables.\n    value: Values to be assigned to the variables. Must have the same structure\n        as `ref`.\n\n  Returns:\n    Nested collection (same structure as `ref`) of TensorFlow assign operations.\n\n  Raises:\n    ValueError: If `ref` and `values` have different structures.\n  \"\"\"", "\n", "if", "isinstance", "(", "ref", ",", "list", ")", "or", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "    ", "if", "len", "(", "ref", ")", "!=", "len", "(", "value", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"ref and value have different lengths.\"", ")", "\n", "", "result", "=", "[", "_nested_assign", "(", "r", ",", "v", ")", "for", "r", ",", "v", "in", "zip", "(", "ref", ",", "value", ")", "]", "\n", "if", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "assign", "(", "ref", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._nested_variable": [[62, 80], ["isinstance", "isinstance", "isinstance", "tensorflow.Variable", "meta_rnnprop_train._nested_variable", "tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_variable"], ["", "", "def", "_nested_variable", "(", "init", ",", "name", "=", "None", ",", "trainable", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow variables.\n\n  Args:\n    init: Nested collection of TensorFlow initializers.\n    name: Variable name.\n    trainable: Make variables trainable (`False` by default).\n\n  Returns:\n    Nested collection (same structure as `init`) of TensorFlow variables.\n  \"\"\"", "\n", "if", "isinstance", "(", "init", ",", "list", ")", "or", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "[", "_nested_variable", "(", "i", ",", "name", ",", "trainable", ")", "for", "i", "in", "init", "]", "\n", "if", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "Variable", "(", "init", ",", "name", "=", "name", ",", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._nested_tuple": [[82, 88], ["isinstance", "isinstance", "tuple", "meta_rnnprop_train._nested_tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple"], ["", "", "def", "_nested_tuple", "(", "elems", ")", ":", "\n", "  ", "if", "isinstance", "(", "elems", ",", "list", ")", "or", "isinstance", "(", "elems", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "tuple", "(", "[", "_nested_tuple", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "\n", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "elems", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._wrap_variable_creation": [[90, 102], ["hasattr", "original_get_variable", "mock.patch", "func", "AttributeError"], "function", ["None"], ["", "", "def", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", ":", "\n", "  ", "\"\"\"Provides a custom getter for all variable creations.\"\"\"", "\n", "original_get_variable", "=", "tf", ".", "get_variable", "\n", "def", "custom_get_variable", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "hasattr", "(", "kwargs", ",", "\"custom_getter\"", ")", ":", "\n", "      ", "raise", "AttributeError", "(", "\"Custom getters are not supported for optimizee \"", "\n", "\"variables.\"", ")", "\n", "", "return", "original_get_variable", "(", "*", "args", ",", "custom_getter", "=", "custom_getter", ",", "**", "kwargs", ")", "\n", "\n", "# Mock the get_variable method.", "\n", "", "with", "mock", ".", "patch", "(", "\"tensorflow.get_variable\"", ",", "custom_get_variable", ")", ":", "\n", "    ", "return", "func", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._get_variables": [[104, 131], ["getter", "tensorflow.name_scope", "meta_rnnprop_train._wrap_variable_creation", "variables.append", "constants.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "_get_variables", "(", "func", ")", ":", "\n", "  ", "\"\"\"Calls func, returning any variables created, but ignoring its return value.\n\n  Args:\n    func: Function to be called.\n\n  Returns:\n    A tuple (variables, constants) where the first element is a list of\n    trainable variables and the second is the non-trainable variables.\n  \"\"\"", "\n", "variables", "=", "[", "]", "\n", "constants", "=", "[", "]", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "trainable", "=", "kwargs", "[", "\"trainable\"", "]", "\n", "kwargs", "[", "\"trainable\"", "]", "=", "False", "\n", "variable", "=", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "if", "trainable", ":", "\n", "      ", "variables", ".", "append", "(", "variable", ")", "\n", "", "else", ":", "\n", "      ", "constants", ".", "append", "(", "variable", ")", "\n", "", "return", "variable", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"unused_graph\"", ")", ":", "\n", "    ", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n", "", "return", "variables", ",", "constants", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._make_with_custom_variables": [[133, 158], ["collections.deque", "meta_rnnprop_train._wrap_variable_creation", "collections.deque.popleft", "getter"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation"], ["", "def", "_make_with_custom_variables", "(", "func", ",", "variables", ")", ":", "\n", "  ", "\"\"\"Calls func and replaces any trainable variables.\n\n  This returns the output of func, but whenever `get_variable` is called it\n  will replace any trainable variables with the tensors in `variables`, in the\n  same order. Non-trainable variables will re-use any variables already\n  created.\n\n  Args:\n    func: Function to be called.\n    variables: A list of tensors replacing the trainable variables.\n\n  Returns:\n    The return value of func is returned.\n  \"\"\"", "\n", "variables", "=", "collections", ".", "deque", "(", "variables", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "[", "\"trainable\"", "]", ":", "\n", "      ", "return", "variables", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "      ", "kwargs", "[", "\"reuse\"", "]", "=", "True", "\n", "return", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_train._make_nets": [[164, 219], ["dict", "len", "ValueError", "tensorflow.variable_scope", "next", "networks.factory", "range", "tensorflow.variable_scope", "enumerate", "iter", "len", "networks.factory", "keys.append", "subsets.append", "print", "v.name.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "_make_nets", "(", "variables", ",", "config", ",", "net_assignments", ")", ":", "\n", "  ", "\"\"\"Creates the optimizer networks.\n\n  Args:\n    variables: A list of variables to be optimized.\n    config: A dictionary of network configurations, each of which will be\n        passed to networks.Factory to construct a single optimizer net.\n    net_assignments: A list of tuples where each tuple is of the form (netid,\n        variable_names) and is used to assign variables to networks. netid must\n        be a key in config.\n\n  Returns:\n    A tuple (nets, keys, subsets) where nets is a dictionary of created\n    optimizer nets such that the net with key keys[i] should be applied to the\n    subset of variables listed in subsets[i].\n\n  Raises:\n    ValueError: If net_assignments is None and the configuration defines more\n        than one network.\n  \"\"\"", "\n", "# create a dictionary which maps a variable name to its index within the", "\n", "# list of variables.", "\n", "name_to_index", "=", "dict", "(", "(", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ",", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "variables", ")", ")", "\n", "\n", "if", "net_assignments", "is", "None", ":", "\n", "    ", "if", "len", "(", "config", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Default net_assignments can only be used if there is \"", "\n", "\"a single net config.\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "key", "=", "next", "(", "iter", "(", "config", ")", ")", "\n", "kwargs", "=", "config", "[", "key", "]", "\n", "net", "=", "networks", ".", "factory", "(", "**", "kwargs", ")", "\n", "\n", "", "nets", "=", "{", "key", ":", "net", "}", "\n", "keys", "=", "[", "key", "]", "\n", "subsets", "=", "[", "range", "(", "len", "(", "variables", ")", ")", "]", "\n", "", "else", ":", "\n", "    ", "nets", "=", "{", "}", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "for", "key", ",", "names", "in", "net_assignments", ":", "\n", "        ", "if", "key", "in", "nets", ":", "\n", "          ", "raise", "ValueError", "(", "\"Repeated netid in net_assigments.\"", ")", "\n", "", "nets", "[", "key", "]", "=", "networks", ".", "factory", "(", "**", "config", "[", "key", "]", ")", "\n", "subset", "=", "[", "name_to_index", "[", "name", "]", "for", "name", "in", "names", "]", "\n", "keys", ".", "append", "(", "key", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "print", "(", "\"Net: {}, Subset: {}\"", ".", "format", "(", "key", ",", "subset", ")", ")", "\n", "\n", "# subsets should be a list of disjoint subsets (as lists!) of the variables", "\n", "# and nets should be a list of networks to apply to each subset.", "\n", "", "", "", "return", "nets", ",", "keys", ",", "subsets", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta.MetaOptimizer.__init__": [[228, 254], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MetaOptimizer.\n\n    Args:\n      **kwargs: A set of keyword arguments mapping network identifiers (the\n          keys) to parameters that will be passed to networks.Factory (see docs\n          for more info).  These can be used to assign different optimizee\n          parameters to different optimizers (see net_assignments in the\n          meta_loss method).\n    \"\"\"", "\n", "self", ".", "_nets", "=", "None", "\n", "\n", "if", "not", "kwargs", ":", "\n", "# Use a default coordinatewise network if nothing is given. this allows", "\n", "# for no network spec and no assignments.", "\n", "      ", "self", ".", "_config", "=", "{", "\n", "\"coordinatewise\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", "}", "}", "\n", "", "else", ":", "\n", "      ", "self", ".", "_config", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta.MetaOptimizer.save": [[255, 268], ["meta.MetaOptimizer._nets.items", "networks.save", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "", "def", "save", "(", "self", ",", "sess", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save meta-optimizer.\"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "if", "path", "is", "None", ":", "\n", "        ", "filename", "=", "None", "\n", "key", "=", "k", "\n", "", "else", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l\"", ".", "format", "(", "k", ")", ")", "\n", "key", "=", "filename", "\n", "", "net_vars", "=", "networks", ".", "save", "(", "net", ",", "sess", ",", "filename", "=", "filename", ")", "\n", "result", "[", "key", "]", "=", "net_vars", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta.MetaOptimizer.meta_loss": [[269, 397], ["meta._get_variables", "print", "print", "print", "print", "meta._make_nets", "print", "print", "print", "tensorflow.TensorArray", "tensorflow.while_loop", "tensorflow.reduce_sum", "nets.items", "MetaLoss", "tensorflow.name_scope", "enumerate", "list", "tensorflow.name_scope", "meta._make_with_custom_variables", "fx_array.write.write.write", "fx_array.write.write.stack", "tensorflow.name_scope", "tensorflow.name_scope", "print", "print", "zip", "tensorflow.name_scope", "tensorflow.gradients", "tensorflow.name_scope", "zip", "meta._nested_tuple", "list", "tensorflow.name_scope", "meta._make_with_custom_variables", "fx_array.write.write.write", "tensorflow.name_scope", "zip", "tensorflow.name_scope", "tensorflow.variables_initializer", "fx_array.write.write.close", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.name_scope", "state.append", "meta.MetaOptimizer.meta_loss.update"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._get_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_nets", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], ["", "def", "meta_loss", "(", "self", ",", "\n", "make_loss", ",", "\n", "len_unroll", ",", "\n", "net_assignments", "=", "None", ",", "\n", "second_derivatives", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns an operator computing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      net_assignments: variable to optimizer mapping. If not None, it should be\n          a list of (k, names) tuples, where k is a valid key in the kwargs\n          passed at at construction time and names is a list of variable names.\n      second_derivatives: Use second derivatives (default is false).\n\n    Returns:\n      namedtuple containing (loss, update, reset, fx, x)\n    \"\"\"", "\n", "\n", "# Construct an instance of the problem only to grab the variables. This", "\n", "# loss will never be evaluated.", "\n", "# pdb.set_trace()", "\n", "\n", "x", ",", "constants", "=", "_get_variables", "(", "make_loss", ")", "\n", "\n", "print", "(", "\"Optimizee variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "x", "]", ")", "\n", "print", "(", "\"Problem variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "constants", "]", ")", "\n", "\n", "# Create the optimizer networks and find the subsets of variables to assign", "\n", "# to each optimizer.", "\n", "nets", ",", "net_keys", ",", "subsets", "=", "_make_nets", "(", "x", ",", "self", ".", "_config", ",", "net_assignments", ")", "\n", "print", "(", "'nets'", ",", "nets", ")", "\n", "print", "(", "'subsets'", ",", "subsets", ")", "\n", "# Store the networks so we can save them later.", "\n", "self", ".", "_nets", "=", "nets", "\n", "\n", "# Create hidden state for each subset of variables.", "\n", "state", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"states\"", ")", ":", "\n", "      ", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "net", "=", "nets", "[", "key", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"state_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "          ", "state", ".", "append", "(", "_nested_variable", "(", "\n", "[", "net", ".", "initial_state_for_inputs", "(", "x", "[", "j", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "j", "in", "subset", "]", ",", "\n", "name", "=", "\"state\"", ",", "trainable", "=", "False", ")", ")", "\n", "", "", "", "print", "(", "state", ")", "\n", "def", "update", "(", "net", ",", "fx", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"Parameter and RNN state update.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"gradients\"", ")", ":", "\n", "        ", "gradients", "=", "tf", ".", "gradients", "(", "fx", ",", "x", ")", "\n", "\n", "# Stopping the gradient here corresponds to what was done in the", "\n", "# original L2L NIPS submission. However it looks like things like", "\n", "# BatchNorm, etc. don't support second-derivatives so we still need", "\n", "# this term.", "\n", "if", "not", "second_derivatives", ":", "\n", "          ", "gradients", "=", "[", "tf", ".", "stop_gradient", "(", "g", ")", "for", "g", "in", "gradients", "]", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", ",", "state_next", "=", "zip", "(", "*", "[", "net", "(", "g", ",", "s", ")", "for", "g", ",", "s", "in", "zip", "(", "gradients", ",", "state", ")", "]", ")", "\n", "state_next", "=", "_nested_tuple", "(", "state_next", ")", "\n", "state_next", "=", "list", "(", "state_next", ")", "\n", "\n", "", "return", "deltas", ",", "state_next", "\n", "\n", "", "def", "time_step", "(", "t", ",", "fx_array", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"While loop body.\"\"\"", "\n", "x_next", "=", "list", "(", "x", ")", "\n", "state_next", "=", "[", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "        ", "fx", "=", "_make_with_custom_variables", "(", "make_loss", ",", "x", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "t", ",", "fx", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"dx\"", ")", ":", "\n", "        ", "for", "subset", ",", "key", ",", "s_i", "in", "zip", "(", "subsets", ",", "net_keys", ",", "state", ")", ":", "\n", "          ", "x_i", "=", "[", "x", "[", "j", "]", "for", "j", "in", "subset", "]", "\n", "deltas", ",", "s_i_next", "=", "update", "(", "nets", "[", "key", "]", ",", "fx", ",", "x_i", ",", "s_i", ")", "\n", "\n", "for", "idx", ",", "j", "in", "enumerate", "(", "subset", ")", ":", "\n", "            ", "x_next", "[", "j", "]", "+=", "deltas", "[", "idx", "]", "\n", "", "state_next", ".", "append", "(", "s_i_next", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"t_next\"", ")", ":", "\n", "        ", "t_next", "=", "t", "+", "1", "\n", "\n", "", "return", "t_next", ",", "fx_array", ",", "x_next", ",", "state_next", "\n", "\n", "# Define the while loop.", "\n", "", "fx_array", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", "+", "1", ",", "\n", "clear_after_read", "=", "False", ")", "\n", "_", ",", "fx_array", ",", "x_final", ",", "s_final", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "(", "0", ",", "fx_array", ",", "x", ",", "state", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "      ", "fx_final", "=", "_make_with_custom_variables", "(", "make_loss", ",", "x_final", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "len_unroll", ",", "fx_final", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "fx_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss\"", ")", "\n", "\n", "# Reset the state; should be called at the beginning of an epoch.", "\n", "with", "tf", ".", "name_scope", "(", "\"reset\"", ")", ":", "\n", "      ", "variables", "=", "(", "nest", ".", "flatten", "(", "state", ")", "+", "\n", "x", "+", "constants", ")", "\n", "# Empty array as part of the reset process.", "\n", "reset", "=", "[", "tf", ".", "variables_initializer", "(", "variables", ")", ",", "fx_array", ".", "close", "(", ")", "]", "\n", "\n", "# Operator to update the parameters and the RNN state after our loop, but", "\n", "# during an epoch.", "\n", "", "with", "tf", ".", "name_scope", "(", "\"update\"", ")", ":", "\n", "      ", "update", "=", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "x", ",", "x_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state", ",", "s_final", ")", ")", ")", "\n", "\n", "# Log internal variables.", "\n", "", "for", "k", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "      ", "print", "(", "\"Optimizer '{}' variables\"", ".", "format", "(", "k", ")", ")", "\n", "print", "(", "[", "op", "for", "op", "in", "snt", ".", "get_variables_in_module", "(", "net", ")", "]", ")", "\n", "\n", "", "return", "MetaLoss", "(", "loss", ",", "update", ",", "reset", ",", "fx_final", ",", "x_final", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta.MetaOptimizer.meta_minimize": [[398, 415], ["meta.MetaOptimizer.meta_loss", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "MetaStep"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss"], ["", "def", "meta_minimize", "(", "self", ",", "make_loss", ",", "len_unroll", ",", "learning_rate", "=", "0.01", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns an operator minimizing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      learning_rate: Learning rate for the Adam optimizer.\n      **kwargs: keyword arguments forwarded to meta_loss.\n\n    Returns:\n      namedtuple containing (step, update, reset, fx, x)\n    \"\"\"", "\n", "info", "=", "self", ".", "meta_loss", "(", "make_loss", ",", "len_unroll", ",", "**", "kwargs", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "step", "=", "optimizer", ".", "minimize", "(", "info", ".", "loss", ")", "\n", "return", "MetaStep", "(", "step", ",", "*", "info", "[", "1", ":", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._nested_assign": [[35, 58], ["isinstance", "isinstance", "isinstance", "tensorflow.assign", "len", "len", "ValueError", "meta._nested_assign", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_assign"], ["def", "_nested_assign", "(", "ref", ",", "value", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow assign operations.\n\n  Args:\n    ref: Nested collection of TensorFlow variables.\n    value: Values to be assigned to the variables. Must have the same structure\n        as `ref`.\n\n  Returns:\n    Nested collection (same structure as `ref`) of TensorFlow assign operations.\n\n  Raises:\n    ValueError: If `ref` and `values` have different structures.\n  \"\"\"", "\n", "if", "isinstance", "(", "ref", ",", "list", ")", "or", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "    ", "if", "len", "(", "ref", ")", "!=", "len", "(", "value", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"ref and value have different lengths.\"", ")", "\n", "", "result", "=", "[", "_nested_assign", "(", "r", ",", "v", ")", "for", "r", ",", "v", "in", "zip", "(", "ref", ",", "value", ")", "]", "\n", "if", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "assign", "(", "ref", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._nested_variable": [[60, 78], ["isinstance", "isinstance", "isinstance", "tensorflow.Variable", "meta._nested_variable", "tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_variable"], ["", "", "def", "_nested_variable", "(", "init", ",", "name", "=", "None", ",", "trainable", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow variables.\n\n  Args:\n    init: Nested collection of TensorFlow initializers.\n    name: Variable name.\n    trainable: Make variables trainable (`False` by default).\n\n  Returns:\n    Nested collection (same structure as `init`) of TensorFlow variables.\n  \"\"\"", "\n", "if", "isinstance", "(", "init", ",", "list", ")", "or", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "[", "_nested_variable", "(", "i", ",", "name", ",", "trainable", ")", "for", "i", "in", "init", "]", "\n", "if", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "Variable", "(", "init", ",", "name", "=", "name", ",", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._nested_tuple": [[80, 86], ["isinstance", "isinstance", "tuple", "meta._nested_tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple"], ["", "", "def", "_nested_tuple", "(", "elems", ")", ":", "\n", "  ", "if", "isinstance", "(", "elems", ",", "list", ")", "or", "isinstance", "(", "elems", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "tuple", "(", "[", "_nested_tuple", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "\n", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "elems", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._wrap_variable_creation": [[88, 100], ["hasattr", "original_get_variable", "mock.patch", "func", "AttributeError"], "function", ["None"], ["", "", "def", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", ":", "\n", "  ", "\"\"\"Provides a custom getter for all variable creations.\"\"\"", "\n", "original_get_variable", "=", "tf", ".", "get_variable", "\n", "def", "custom_get_variable", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "hasattr", "(", "kwargs", ",", "\"custom_getter\"", ")", ":", "\n", "      ", "raise", "AttributeError", "(", "\"Custom getters are not supported for optimizee \"", "\n", "\"variables.\"", ")", "\n", "", "return", "original_get_variable", "(", "*", "args", ",", "custom_getter", "=", "custom_getter", ",", "**", "kwargs", ")", "\n", "\n", "# Mock the get_variable method.", "\n", "", "with", "mock", ".", "patch", "(", "\"tensorflow.get_variable\"", ",", "custom_get_variable", ")", ":", "\n", "    ", "return", "func", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._get_variables": [[102, 129], ["getter", "tensorflow.name_scope", "meta._wrap_variable_creation", "variables.append", "constants.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "_get_variables", "(", "func", ")", ":", "\n", "  ", "\"\"\"Calls func, returning any variables created, but ignoring its return value.\n\n  Args:\n    func: Function to be called.\n\n  Returns:\n    A tuple (variables, constants) where the first element is a list of\n    trainable variables and the second is the non-trainable variables.\n  \"\"\"", "\n", "variables", "=", "[", "]", "\n", "constants", "=", "[", "]", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "trainable", "=", "kwargs", "[", "\"trainable\"", "]", "\n", "kwargs", "[", "\"trainable\"", "]", "=", "False", "\n", "variable", "=", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "if", "trainable", ":", "\n", "      ", "variables", ".", "append", "(", "variable", ")", "\n", "", "else", ":", "\n", "      ", "constants", ".", "append", "(", "variable", ")", "\n", "", "return", "variable", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"unused_graph\"", ")", ":", "\n", "    ", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n", "", "return", "variables", ",", "constants", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._make_with_custom_variables": [[131, 156], ["collections.deque", "meta._wrap_variable_creation", "collections.deque.popleft", "getter"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation"], ["", "def", "_make_with_custom_variables", "(", "func", ",", "variables", ")", ":", "\n", "  ", "\"\"\"Calls func and replaces any trainable variables.\n\n  This returns the output of func, but whenever `get_variable` is called it\n  will replace any trainable variables with the tensors in `variables`, in the\n  same order. Non-trainable variables will re-use any variables already\n  created.\n\n  Args:\n    func: Function to be called.\n    variables: A list of tensors replacing the trainable variables.\n\n  Returns:\n    The return value of func is returned.\n  \"\"\"", "\n", "variables", "=", "collections", ".", "deque", "(", "variables", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "[", "\"trainable\"", "]", ":", "\n", "      ", "return", "variables", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "      ", "kwargs", "[", "\"reuse\"", "]", "=", "True", "\n", "return", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta._make_nets": [[162, 217], ["dict", "len", "ValueError", "tensorflow.variable_scope", "next", "networks.factory", "range", "tensorflow.variable_scope", "enumerate", "iter", "len", "networks.factory", "keys.append", "subsets.append", "print", "v.name.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "_make_nets", "(", "variables", ",", "config", ",", "net_assignments", ")", ":", "\n", "  ", "\"\"\"Creates the optimizer networks.\n\n  Args:\n    variables: A list of variables to be optimized.\n    config: A dictionary of network configurations, each of which will be\n        passed to networks.Factory to construct a single optimizer net.\n    net_assignments: A list of tuples where each tuple is of the form (netid,\n        variable_names) and is used to assign variables to networks. netid must\n        be a key in config.\n\n  Returns:\n    A tuple (nets, keys, subsets) where nets is a dictionary of created\n    optimizer nets such that the net with key keys[i] should be applied to the\n    subset of variables listed in subsets[i].\n\n  Raises:\n    ValueError: If net_assignments is None and the configuration defines more\n        than one network.\n  \"\"\"", "\n", "# create a dictionary which maps a variable name to its index within the", "\n", "# list of variables.", "\n", "name_to_index", "=", "dict", "(", "(", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ",", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "variables", ")", ")", "\n", "\n", "if", "net_assignments", "is", "None", ":", "\n", "    ", "if", "len", "(", "config", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Default net_assignments can only be used if there is \"", "\n", "\"a single net config.\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "key", "=", "next", "(", "iter", "(", "config", ")", ")", "\n", "kwargs", "=", "config", "[", "key", "]", "\n", "net", "=", "networks", ".", "factory", "(", "**", "kwargs", ")", "\n", "\n", "", "nets", "=", "{", "key", ":", "net", "}", "\n", "keys", "=", "[", "key", "]", "\n", "subsets", "=", "[", "range", "(", "len", "(", "variables", ")", ")", "]", "\n", "", "else", ":", "\n", "    ", "nets", "=", "{", "}", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "for", "key", ",", "names", "in", "net_assignments", ":", "\n", "        ", "if", "key", "in", "nets", ":", "\n", "          ", "raise", "ValueError", "(", "\"Repeated netid in net_assigments.\"", ")", "\n", "", "nets", "[", "key", "]", "=", "networks", ".", "factory", "(", "**", "config", "[", "key", "]", ")", "\n", "subset", "=", "[", "name_to_index", "[", "name", "]", "for", "name", "in", "names", "]", "\n", "keys", ".", "append", "(", "key", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "print", "(", "\"Net: {}, Subset: {}\"", ".", "format", "(", "key", ",", "subset", ")", ")", "\n", "\n", "# subsets should be a list of disjoint subsets (as lists!) of the variables", "\n", "# and nets should be a list of networks to apply to each subset.", "\n", "", "", "", "return", "nets", ",", "keys", ",", "subsets", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.preprocess.Clamp.__init__": [[28, 32], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["  ", "def", "__init__", "(", "self", ",", "min_value", "=", "None", ",", "max_value", "=", "None", ",", "name", "=", "\"clamp\"", ")", ":", "\n", "    ", "super", "(", "Clamp", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_min", "=", "min_value", "\n", "self", ".", "_max", "=", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.preprocess.Clamp._build": [[33, 40], ["tensorflow.maximum", "tensorflow.minimum"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "output", "=", "inputs", "\n", "if", "self", ".", "_min", "is", "not", "None", ":", "\n", "      ", "output", "=", "tf", ".", "maximum", "(", "output", ",", "self", ".", "_min", ")", "\n", "", "if", "self", ".", "_max", "is", "not", "None", ":", "\n", "      ", "output", "=", "tf", ".", "minimum", "(", "output", ",", "self", ".", "_max", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.preprocess.LogAndSign.__init__": [[48, 51], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "initializer", ",", "k", ",", "name", "=", "\"preprocess_log\"", ")", ":", "\n", "    ", "super", "(", "LogAndSign", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.preprocess.LogAndSign._build": [[52, 71], ["tensorflow.log", "tensorflow.concat", "numpy.finfo", "gradients.get_shape", "preprocess.Clamp", "preprocess.Clamp", "tensorflow.abs", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "_build", "(", "self", ",", "gradients", ")", ":", "\n", "    ", "\"\"\"Connects the LogAndSign module into the graph.\n\n    Args:\n      gradients: `Tensor` of gradients with shape `[d_1, ..., d_n]`.\n\n    Returns:\n      `Tensor` with shape `[d_1, ..., d_n-1, 2 * d_n]`. The first `d_n` elements\n      along the nth dimension correspond to the log output and the remaining\n      `d_n` elements to the sign output.\n    \"\"\"", "\n", "eps", "=", "np", ".", "finfo", "(", "gradients", ".", "dtype", ".", "as_numpy_dtype", ")", ".", "eps", "\n", "ndims", "=", "gradients", ".", "get_shape", "(", ")", ".", "ndims", "\n", "\n", "log", "=", "tf", ".", "log", "(", "tf", ".", "abs", "(", "gradients", ")", "+", "eps", ")", "\n", "clamped_log", "=", "Clamp", "(", "min_value", "=", "-", "1.0", ")", "(", "log", "/", "self", ".", "_k", ")", "# pylint: disable=not-callable", "\n", "sign", "=", "Clamp", "(", "min_value", "=", "-", "1.0", ",", "max_value", "=", "1.0", ")", "(", "gradients", "*", "np", ".", "exp", "(", "self", ".", "_k", ")", ")", "# pylint: disable=not-callable", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "clamped_log", ",", "sign", "]", ",", "ndims", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.__init__": [[230, 257], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta1", ",", "beta2", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MetaOptimizer.\n\n    Args:\n      **kwargs: A set of keyword arguments mapping network identifiers (the\n          keys) to parameters that will be passed to networks.Factory (see docs\n          for more info).  These can be used to assign different optimizee\n          parameters to different optimizers (see net_assignments in the\n          meta_loss method).\n    \"\"\"", "\n", "self", ".", "_nets", "=", "None", "\n", "self", ".", "beta1", "=", "beta1", "\n", "self", ".", "beta2", "=", "beta2", "\n", "if", "not", "kwargs", ":", "\n", "# Use a default coordinatewise network if nothing is given. this allows", "\n", "# for no network spec and no assignments.", "\n", "      ", "self", ".", "_config", "=", "{", "\n", "\"coordinatewise\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", "}", "}", "\n", "", "else", ":", "\n", "      ", "self", ".", "_config", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save": [[258, 274], ["meta_rnnprop_eval.MetaOptimizer._nets.items", "networks.save", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "", "def", "save", "(", "self", ",", "sess", ",", "path", "=", "None", ",", "index", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save meta-optimizer.\"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "if", "path", "is", "None", ":", "\n", "        ", "filename", "=", "None", "\n", "key", "=", "k", "\n", "", "elif", "index", "is", "not", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "key", "=", "filename", "\n", "", "else", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l\"", ".", "format", "(", "k", ")", ")", "\n", "key", "=", "filename", "\n", "", "net_vars", "=", "networks", ".", "save", "(", "net", ",", "sess", ",", "filename", "=", "filename", ")", "\n", "result", "[", "key", "]", "=", "net_vars", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restorer": [[276, 290], ["meta_rnnprop_eval.MetaOptimizer._nets.items", "sonnet.get_variables_in_module", "collections.defaultdict", "collections.defaultdict", "[].split", "tensorflow.placeholder", "tensorflow.assign", "v.get_shape", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "restorer", "(", "self", ")", ":", "\n", "    ", "self", ".", "restore_pl", "=", "{", "}", "\n", "self", ".", "assigns", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "self", ".", "restore_pl", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "self", ".", "assigns", "[", "k", "]", "=", "collections", ".", "defaultdict", "(", "dict", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "placeholder", "(", "name", "=", "\"{}_{}_pl\"", ".", "format", "(", "module_name", ",", "variable_name", ")", ",", "shape", "=", "v", ".", "get_shape", "(", ")", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "=", "tf", ".", "assign", "(", "v", ",", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restore": [[291, 305], ["meta_rnnprop_eval.MetaOptimizer._nets.items", "sess.run", "os.path.join", "pickle.load", "sonnet.get_variables_in_module", "open", "[].split", "tensorflow.python.framework.ops.append", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "", "def", "restore", "(", "self", ",", "sess", ",", "path", ",", "index", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "feed", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l-{}\"", ".", "format", "(", "k", ",", "index", ")", ")", "\n", "data", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "vars", "=", "snt", ".", "get_variables_in_module", "(", "net", ")", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "split", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "\n", "module_name", "=", "split", "[", "-", "2", "]", "\n", "variable_name", "=", "split", "[", "-", "1", "]", "\n", "feed", "[", "self", ".", "restore_pl", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", "]", "=", "data", "[", "module_name", "]", "[", "variable_name", "]", "\n", "ops", ".", "append", "(", "self", ".", "assigns", "[", "k", "]", "[", "module_name", "]", "[", "variable_name", "]", ")", "\n", "", "", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "feed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss": [[306, 467], ["meta_rnnprop_eval._get_variables", "print", "print", "print", "print", "tensorflow.placeholder", "meta_rnnprop_eval._make_nets", "print", "print", "enumerate", "tensorflow.TensorArray", "tensorflow.while_loop", "tensorflow.reduce_sum", "nets.items", "scale.append", "tensorflow.name_scope", "enumerate", "zip", "state_mt.append", "state_vt.append", "list", "tensorflow.name_scope", "meta_rnnprop_eval._make_with_custom_variables", "fx_array.write.write.write", "fx_array.write.write.stack", "tensorflow.name_scope", "tensorflow.name_scope", "print", "print", "MetaLoss", "tensorflow.placeholder_with_default", "zip", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.name_scope", "tensorflow.gradients", "tensorflow.name_scope", "zip", "meta_rnnprop_eval._nested_tuple", "list", "tensorflow.name_scope", "meta_rnnprop_eval._make_with_custom_variables", "fx_array.write.write.write", "tensorflow.name_scope", "zip", "tensorflow.name_scope", "tensorflow.assign", "tensorflow.assign", "tensorflow.python.util.nest.flatten", "tensorflow.ones", "tensorflow.name_scope", "state.append", "tensorflow.zeros", "tensorflow.zeros", "meta_rnnprop_eval.MetaOptimizer.meta_loss.update"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._get_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_nets", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], ["", "def", "meta_loss", "(", "self", ",", "\n", "make_loss", ",", "\n", "len_unroll", ",", "\n", "net_assignments", "=", "None", ",", "\n", "second_derivatives", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns an operator computing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      net_assignments: variable to optimizer mapping. If not None, it should be\n          a list of (k, names) tuples, where k is a valid key in the kwargs\n          passed at at construction time and names is a list of variable names.\n      second_derivatives: Use second derivatives (default is false).\n\n    Returns:\n      namedtuple containing (loss, update, reset, fx, x), ...\n    \"\"\"", "\n", "\n", "# Construct an instance of the problem only to grab the variables. This", "\n", "# loss will never be evaluated.", "\n", "# pdb.set_trace()", "\n", "\n", "x", ",", "constants", "=", "_get_variables", "(", "make_loss", ")", "\n", "\n", "print", "(", "\"Optimizee variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "x", "]", ")", "\n", "print", "(", "\"Problem variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "constants", "]", ")", "\n", "\n", "# create scale placeholder here", "\n", "scale", "=", "[", "]", "\n", "for", "k", "in", "x", ":", "\n", "      ", "scale", ".", "append", "(", "tf", ".", "placeholder_with_default", "(", "tf", ".", "ones", "(", "shape", "=", "k", ".", "shape", ")", ",", "shape", "=", "k", ".", "shape", ",", "name", "=", "k", ".", "name", "[", ":", "-", "2", "]", "+", "\"_scale\"", ")", ")", "\n", "", "step", "=", "tf", ".", "placeholder", "(", "shape", "=", "(", ")", ",", "name", "=", "\"step\"", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "# Create the optimizer networks and find the subsets of variables to assign", "\n", "# to each optimizer.", "\n", "nets", ",", "net_keys", ",", "subsets", "=", "_make_nets", "(", "x", ",", "self", ".", "_config", ",", "net_assignments", ")", "\n", "print", "(", "'nets'", ",", "nets", ")", "\n", "print", "(", "'subsets'", ",", "subsets", ")", "\n", "# Store the networks so we can save them later.", "\n", "self", ".", "_nets", "=", "nets", "\n", "\n", "# Create hidden state for each subset of variables.", "\n", "state", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"states\"", ")", ":", "\n", "      ", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "net", "=", "nets", "[", "key", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"state_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "          ", "state", ".", "append", "(", "_nested_variable", "(", "\n", "[", "net", ".", "initial_state_for_inputs", "(", "x", "[", "j", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "j", "in", "subset", "]", ",", "\n", "name", "=", "\"state\"", ",", "trainable", "=", "False", ")", ")", "\n", "\n", "# m and v in adam", "\n", "", "", "", "state_mt", "=", "[", "]", "\n", "state_vt", "=", "[", "]", "\n", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "      ", "mt", "=", "[", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "x", "[", "j", "]", ".", "shape", ")", ",", "name", "=", "x", "[", "j", "]", ".", "name", "[", ":", "-", "2", "]", "+", "\"_mt\"", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "for", "j", "in", "subset", "]", "\n", "vt", "=", "[", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", "=", "x", "[", "j", "]", ".", "shape", ")", ",", "name", "=", "x", "[", "j", "]", ".", "name", "[", ":", "-", "2", "]", "+", "\"_vt\"", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "for", "j", "in", "subset", "]", "\n", "state_mt", ".", "append", "(", "mt", ")", "\n", "state_vt", ".", "append", "(", "vt", ")", "\n", "\n", "", "def", "update", "(", "net", ",", "fx", ",", "x", ",", "state", ",", "mt", ",", "vt", ",", "t", ")", ":", "\n", "      ", "\"\"\"Parameter and RNN state update.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"gradients\"", ")", ":", "\n", "        ", "gradients", "=", "tf", ".", "gradients", "(", "fx", ",", "x", ")", "\n", "\n", "# Stopping the gradient here corresponds to what was done in the", "\n", "# original L2L NIPS submission. However it looks like things like", "\n", "# BatchNorm, etc. don't support second-derivatives so we still need", "\n", "# this term.", "\n", "if", "not", "second_derivatives", ":", "\n", "          ", "gradients", "=", "[", "tf", ".", "stop_gradient", "(", "g", ")", "for", "g", "in", "gradients", "]", "\n", "# update mt and vt", "\n", "", "mt_next", "=", "[", "self", ".", "beta1", "*", "m", "+", "(", "1.0", "-", "self", ".", "beta1", ")", "*", "g", "for", "m", ",", "g", "in", "zip", "(", "mt", ",", "gradients", ")", "]", "\n", "mt_hat", "=", "[", "m", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta1", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "for", "m", "in", "mt_next", "]", "\n", "vt_next", "=", "[", "self", ".", "beta2", "*", "v", "+", "(", "1.0", "-", "self", ".", "beta2", ")", "*", "g", "*", "g", "for", "v", ",", "g", "in", "zip", "(", "vt", ",", "gradients", ")", "]", "\n", "vt_hat", "=", "[", "v", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta2", ",", "tf", ".", "cast", "(", "step", "+", "t", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ")", "for", "v", "in", "vt_next", "]", "\n", "mt_tilde", "=", "[", "m", "/", "(", "tf", ".", "sqrt", "(", "v", ")", "+", "1e-8", ")", "for", "m", ",", "v", "in", "zip", "(", "mt_hat", ",", "vt_hat", ")", "]", "\n", "gt_tilde", "=", "[", "g", "/", "(", "tf", ".", "sqrt", "(", "v", ")", "+", "1e-8", ")", "for", "g", ",", "v", "in", "zip", "(", "gradients", ",", "vt_hat", ")", "]", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", ",", "state_next", "=", "zip", "(", "*", "[", "net", "(", "m", ",", "g", ",", "s", ")", "for", "m", ",", "g", ",", "s", "in", "zip", "(", "mt_tilde", ",", "gt_tilde", ",", "state", ")", "]", ")", "\n", "state_next", "=", "_nested_tuple", "(", "state_next", ")", "\n", "state_next", "=", "list", "(", "state_next", ")", "\n", "\n", "", "return", "deltas", ",", "state_next", ",", "mt_next", ",", "vt_next", "\n", "\n", "", "def", "time_step", "(", "t", ",", "fx_array", ",", "x", ",", "state", ",", "state_mt", ",", "state_vt", ")", ":", "\n", "      ", "\"\"\"While loop body.\"\"\"", "\n", "x_next", "=", "list", "(", "x", ")", "\n", "state_next", "=", "[", "]", "\n", "state_mt_next", "=", "[", "]", "\n", "state_vt_next", "=", "[", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "        ", "scaled_x", "=", "[", "x", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "t", ",", "fx", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"dx\"", ")", ":", "\n", "        ", "for", "subset", ",", "key", ",", "s_i", ",", "mt", ",", "vt", "in", "zip", "(", "subsets", ",", "net_keys", ",", "state", ",", "state_mt", ",", "state_vt", ")", ":", "\n", "          ", "x_i", "=", "[", "x", "[", "j", "]", "for", "j", "in", "subset", "]", "\n", "deltas", ",", "s_i_next", ",", "mt_i_next", ",", "vt_i_next", "=", "update", "(", "nets", "[", "key", "]", ",", "fx", ",", "x_i", ",", "s_i", ",", "mt", ",", "vt", ",", "t", ")", "\n", "for", "idx", ",", "j", "in", "enumerate", "(", "subset", ")", ":", "\n", "            ", "delta", "=", "deltas", "[", "idx", "]", "\n", "x_next", "[", "j", "]", "+=", "delta", "\n", "", "state_next", ".", "append", "(", "s_i_next", ")", "\n", "state_mt_next", ".", "append", "(", "mt_i_next", ")", "\n", "state_vt_next", ".", "append", "(", "vt_i_next", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"t_next\"", ")", ":", "\n", "        ", "t_next", "=", "t", "+", "1", "\n", "\n", "", "return", "t_next", ",", "fx_array", ",", "x_next", ",", "state_next", ",", "state_mt_next", ",", "state_vt_next", "\n", "\n", "# Define the while loop.", "\n", "", "fx_array", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", "+", "1", ",", "\n", "clear_after_read", "=", "False", ")", "\n", "_", ",", "fx_array", ",", "x_final", ",", "s_final", ",", "mt_final", ",", "vt_final", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "(", "0", ",", "fx_array", ",", "x", ",", "state", ",", "state_mt", ",", "state_vt", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "      ", "scaled_x_final", "=", "[", "x_final", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "fx_final", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x_final", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "len_unroll", ",", "fx_final", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "fx_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss\"", ")", "\n", "\n", "# Reset the state; should be called at the beginning of an epoch.", "\n", "with", "tf", ".", "name_scope", "(", "\"reset\"", ")", ":", "\n", "      ", "variables", "=", "(", "nest", ".", "flatten", "(", "state", ")", "+", "\n", "x", "+", "constants", ")", "\n", "reset_mt", "=", "[", "tf", ".", "assign", "(", "m", ",", "tf", ".", "zeros", "(", "shape", "=", "m", ".", "shape", ")", ")", "for", "mt", "in", "state_mt", "for", "m", "in", "mt", "]", "\n", "reset_vt", "=", "[", "tf", ".", "assign", "(", "v", ",", "tf", ".", "zeros", "(", "shape", "=", "v", ".", "shape", ")", ")", "for", "vt", "in", "state_vt", "for", "v", "in", "vt", "]", "\n", "\n", "# Empty array as part of the reset process.", "\n", "reset", "=", "[", "tf", ".", "variables_initializer", "(", "variables", ")", ",", "fx_array", ".", "close", "(", ")", "]", "+", "reset_mt", "+", "reset_vt", "\n", "\n", "# Operator to update the parameters and the RNN state after our loop, but", "\n", "# during an epoch.", "\n", "", "with", "tf", ".", "name_scope", "(", "\"update\"", ")", ":", "\n", "      ", "update", "=", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "x", ",", "x_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state", ",", "s_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_mt", ",", "mt_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state_vt", ",", "vt_final", ")", ")", ")", "\n", "\n", "# Log internal variables.", "\n", "", "for", "k", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "      ", "print", "(", "\"Optimizer '{}' variables\"", ".", "format", "(", "k", ")", ")", "\n", "print", "(", "[", "op", "for", "op", "in", "snt", ".", "get_variables_in_module", "(", "net", ")", "]", ")", "\n", "\n", "", "return", "MetaLoss", "(", "loss", ",", "update", ",", "reset", ",", "fx_final", ",", "x_final", ")", ",", "scale", ",", "x", ",", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_minimize": [[468, 486], ["meta_rnnprop_eval.MetaOptimizer.meta_loss", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "meta_rnnprop_eval.MetaOptimizer.restorer", "MetaStep"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.restorer"], ["", "def", "meta_minimize", "(", "self", ",", "make_loss", ",", "len_unroll", ",", "learning_rate", "=", "0.01", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns an operator minimizing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      learning_rate: Learning rate for the Adam optimizer.\n      **kwargs: keyword arguments forwarded to meta_loss.\n\n    Returns:\n      namedtuple containing (step, update, reset, fx, x), ...\n    \"\"\"", "\n", "info", ",", "scale", ",", "x", ",", "seq_step", "=", "self", ".", "meta_loss", "(", "make_loss", ",", "len_unroll", ",", "**", "kwargs", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "step", "=", "optimizer", ".", "minimize", "(", "info", ".", "loss", ")", "\n", "self", ".", "restorer", "(", ")", "\n", "return", "MetaStep", "(", "step", ",", "*", "info", "[", "1", ":", "]", ")", ",", "scale", ",", "x", ",", "seq_step", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_assign": [[37, 60], ["isinstance", "isinstance", "isinstance", "tensorflow.assign", "len", "len", "ValueError", "meta_rnnprop_eval._nested_assign", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_assign"], ["def", "_nested_assign", "(", "ref", ",", "value", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow assign operations.\n\n  Args:\n    ref: Nested collection of TensorFlow variables.\n    value: Values to be assigned to the variables. Must have the same structure\n        as `ref`.\n\n  Returns:\n    Nested collection (same structure as `ref`) of TensorFlow assign operations.\n\n  Raises:\n    ValueError: If `ref` and `values` have different structures.\n  \"\"\"", "\n", "if", "isinstance", "(", "ref", ",", "list", ")", "or", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "    ", "if", "len", "(", "ref", ")", "!=", "len", "(", "value", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"ref and value have different lengths.\"", ")", "\n", "", "result", "=", "[", "_nested_assign", "(", "r", ",", "v", ")", "for", "r", ",", "v", "in", "zip", "(", "ref", ",", "value", ")", "]", "\n", "if", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "assign", "(", "ref", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_variable": [[62, 80], ["isinstance", "isinstance", "isinstance", "tensorflow.Variable", "meta_rnnprop_eval._nested_variable", "tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_variable"], ["", "", "def", "_nested_variable", "(", "init", ",", "name", "=", "None", ",", "trainable", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow variables.\n\n  Args:\n    init: Nested collection of TensorFlow initializers.\n    name: Variable name.\n    trainable: Make variables trainable (`False` by default).\n\n  Returns:\n    Nested collection (same structure as `init`) of TensorFlow variables.\n  \"\"\"", "\n", "if", "isinstance", "(", "init", ",", "list", ")", "or", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "[", "_nested_variable", "(", "i", ",", "name", ",", "trainable", ")", "for", "i", "in", "init", "]", "\n", "if", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "Variable", "(", "init", ",", "name", "=", "name", ",", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple": [[82, 88], ["isinstance", "isinstance", "tuple", "meta_rnnprop_eval._nested_tuple"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._nested_tuple"], ["", "", "def", "_nested_tuple", "(", "elems", ")", ":", "\n", "  ", "if", "isinstance", "(", "elems", ",", "list", ")", "or", "isinstance", "(", "elems", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "tuple", "(", "[", "_nested_tuple", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "\n", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "elems", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation": [[90, 102], ["hasattr", "original_get_variable", "mock.patch", "func", "AttributeError"], "function", ["None"], ["", "", "def", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", ":", "\n", "  ", "\"\"\"Provides a custom getter for all variable creations.\"\"\"", "\n", "original_get_variable", "=", "tf", ".", "get_variable", "\n", "def", "custom_get_variable", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "hasattr", "(", "kwargs", ",", "\"custom_getter\"", ")", ":", "\n", "      ", "raise", "AttributeError", "(", "\"Custom getters are not supported for optimizee \"", "\n", "\"variables.\"", ")", "\n", "", "return", "original_get_variable", "(", "*", "args", ",", "custom_getter", "=", "custom_getter", ",", "**", "kwargs", ")", "\n", "\n", "# Mock the get_variable method.", "\n", "", "with", "mock", ".", "patch", "(", "\"tensorflow.get_variable\"", ",", "custom_get_variable", ")", ":", "\n", "    ", "return", "func", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._get_variables": [[104, 131], ["getter", "tensorflow.name_scope", "meta_rnnprop_eval._wrap_variable_creation", "variables.append", "constants.append"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "_get_variables", "(", "func", ")", ":", "\n", "  ", "\"\"\"Calls func, returning any variables created, but ignoring its return value.\n\n  Args:\n    func: Function to be called.\n\n  Returns:\n    A tuple (variables, constants) where the first element is a list of\n    trainable variables and the second is the non-trainable variables.\n  \"\"\"", "\n", "variables", "=", "[", "]", "\n", "constants", "=", "[", "]", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "trainable", "=", "kwargs", "[", "\"trainable\"", "]", "\n", "kwargs", "[", "\"trainable\"", "]", "=", "False", "\n", "variable", "=", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "if", "trainable", ":", "\n", "      ", "variables", ".", "append", "(", "variable", ")", "\n", "", "else", ":", "\n", "      ", "constants", ".", "append", "(", "variable", ")", "\n", "", "return", "variable", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"unused_graph\"", ")", ":", "\n", "    ", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n", "", "return", "variables", ",", "constants", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables": [[133, 158], ["collections.deque", "meta_rnnprop_eval._wrap_variable_creation", "collections.deque.popleft", "getter"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._wrap_variable_creation"], ["", "def", "_make_with_custom_variables", "(", "func", ",", "variables", ")", ":", "\n", "  ", "\"\"\"Calls func and replaces any trainable variables.\n\n  This returns the output of func, but whenever `get_variable` is called it\n  will replace any trainable variables with the tensors in `variables`, in the\n  same order. Non-trainable variables will re-use any variables already\n  created.\n\n  Args:\n    func: Function to be called.\n    variables: A list of tensors replacing the trainable variables.\n\n  Returns:\n    The return value of func is returned.\n  \"\"\"", "\n", "variables", "=", "collections", ".", "deque", "(", "variables", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "[", "\"trainable\"", "]", ":", "\n", "      ", "return", "variables", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "      ", "kwargs", "[", "\"reuse\"", "]", "=", "True", "\n", "return", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_nets": [[164, 219], ["dict", "len", "ValueError", "tensorflow.variable_scope", "next", "networks.factory", "range", "tensorflow.variable_scope", "enumerate", "iter", "len", "networks.factory", "keys.append", "subsets.append", "print", "v.name.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.networks.factory", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "_make_nets", "(", "variables", ",", "config", ",", "net_assignments", ")", ":", "\n", "  ", "\"\"\"Creates the optimizer networks.\n\n  Args:\n    variables: A list of variables to be optimized.\n    config: A dictionary of network configurations, each of which will be\n        passed to networks.Factory to construct a single optimizer net.\n    net_assignments: A list of tuples where each tuple is of the form (netid,\n        variable_names) and is used to assign variables to networks. netid must\n        be a key in config.\n\n  Returns:\n    A tuple (nets, keys, subsets) where nets is a dictionary of created\n    optimizer nets such that the net with key keys[i] should be applied to the\n    subset of variables listed in subsets[i].\n\n  Raises:\n    ValueError: If net_assignments is None and the configuration defines more\n        than one network.\n  \"\"\"", "\n", "# create a dictionary which maps a variable name to its index within the", "\n", "# list of variables.", "\n", "name_to_index", "=", "dict", "(", "(", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ",", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "variables", ")", ")", "\n", "\n", "if", "net_assignments", "is", "None", ":", "\n", "    ", "if", "len", "(", "config", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Default net_assignments can only be used if there is \"", "\n", "\"a single net config.\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "key", "=", "next", "(", "iter", "(", "config", ")", ")", "\n", "kwargs", "=", "config", "[", "key", "]", "\n", "net", "=", "networks", ".", "factory", "(", "**", "kwargs", ")", "\n", "\n", "", "nets", "=", "{", "key", ":", "net", "}", "\n", "keys", "=", "[", "key", "]", "\n", "subsets", "=", "[", "range", "(", "len", "(", "variables", ")", ")", "]", "\n", "", "else", ":", "\n", "    ", "nets", "=", "{", "}", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "for", "key", ",", "names", "in", "net_assignments", ":", "\n", "        ", "if", "key", "in", "nets", ":", "\n", "          ", "raise", "ValueError", "(", "\"Repeated netid in net_assigments.\"", ")", "\n", "", "nets", "[", "key", "]", "=", "networks", ".", "factory", "(", "**", "config", "[", "key", "]", ")", "\n", "subset", "=", "[", "name_to_index", "[", "name", "]", "for", "name", "in", "names", "]", "\n", "keys", ".", "append", "(", "key", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "print", "(", "\"Net: {}, Subset: {}\"", ".", "format", "(", "key", ",", "subset", ")", ")", "\n", "\n", "# subsets should be a list of disjoint subsets (as lists!) of the variables", "\n", "# and nets should be a list of networks to apply to each subset.", "\n", "", "", "", "return", "nets", ",", "keys", ",", "subsets", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.run_epoch": [[31, 76], ["timeit.default_timer", "sess.run", "six.moves.xrange", "six.moves.xrange", "range", "assign_func", "zip", "zip", "timeit.default_timer", "r_scale.append", "len", "sess.run", "k_value_list.append", "sess.run", "sess.run", "numpy.exp", "zip", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["def", "run_epoch", "(", "sess", ",", "cost_op", ",", "ops", ",", "reset", ",", "num_unrolls", ",", "\n", "scale", "=", "None", ",", "rd_scale", "=", "False", ",", "rd_scale_bound", "=", "3.0", ",", "assign_func", "=", "None", ",", "var_x", "=", "None", ",", "\n", "step", "=", "None", ",", "unroll_len", "=", "None", ",", "\n", "task_i", "=", "-", "1", ",", "data", "=", "None", ",", "label_pl", "=", "None", ",", "input_pl", "=", "None", ")", ":", "\n", "  ", "\"\"\"Runs one optimization epoch.\"\"\"", "\n", "start", "=", "timer", "(", ")", "\n", "sess", ".", "run", "(", "reset", ")", "\n", "cost", "=", "None", "\n", "if", "task_i", "==", "-", "1", ":", "\n", "      ", "if", "rd_scale", ":", "\n", "        ", "assert", "scale", "is", "not", "None", "\n", "r_scale", "=", "[", "]", "\n", "for", "k", "in", "scale", ":", "\n", "          ", "r_scale", ".", "append", "(", "np", ".", "exp", "(", "np", ".", "random", ".", "uniform", "(", "-", "rd_scale_bound", ",", "rd_scale_bound", ",", "\n", "size", "=", "k", ".", "shape", ")", ")", ")", "\n", "", "assert", "var_x", "is", "not", "None", "\n", "k_value_list", "=", "[", "]", "\n", "for", "k_id", "in", "range", "(", "len", "(", "var_x", ")", ")", ":", "\n", "          ", "k_value", "=", "sess", ".", "run", "(", "var_x", "[", "k_id", "]", ")", "\n", "k_value", "=", "k_value", "/", "r_scale", "[", "k_id", "]", "\n", "k_value_list", ".", "append", "(", "k_value", ")", "\n", "", "assert", "assign_func", "is", "not", "None", "\n", "assign_func", "(", "k_value_list", ")", "\n", "feed_rs", "=", "{", "p", ":", "v", "for", "p", ",", "v", "in", "zip", "(", "scale", ",", "r_scale", ")", "}", "\n", "", "else", ":", "\n", "        ", "feed_rs", "=", "{", "}", "\n", "", "feed_dict", "=", "feed_rs", "\n", "for", "i", "in", "xrange", "(", "num_unrolls", ")", ":", "\n", "        ", "if", "step", "is", "not", "None", ":", "\n", "            ", "feed_dict", "[", "step", "]", "=", "i", "*", "unroll_len", "+", "1", "\n", "", "cost", "=", "sess", ".", "run", "(", "[", "cost_op", "]", "+", "ops", ",", "feed_dict", "=", "feed_dict", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "      ", "assert", "data", "is", "not", "None", "\n", "assert", "input_pl", "is", "not", "None", "\n", "assert", "label_pl", "is", "not", "None", "\n", "feed_dict", "=", "{", "}", "\n", "for", "ri", "in", "xrange", "(", "num_unrolls", ")", ":", "\n", "          ", "for", "pl", ",", "dat", "in", "zip", "(", "label_pl", ",", "data", "[", "\"labels\"", "]", "[", "ri", "]", ")", ":", "\n", "              ", "feed_dict", "[", "pl", "]", "=", "dat", "\n", "", "for", "pl", ",", "dat", "in", "zip", "(", "input_pl", ",", "data", "[", "\"inputs\"", "]", "[", "ri", "]", ")", ":", "\n", "              ", "feed_dict", "[", "pl", "]", "=", "dat", "\n", "", "if", "step", "is", "not", "None", ":", "\n", "              ", "feed_dict", "[", "step", "]", "=", "ri", "*", "unroll_len", "+", "1", "\n", "", "cost", "=", "sess", ".", "run", "(", "[", "cost_op", "]", "+", "ops", ",", "feed_dict", "=", "feed_dict", ")", "[", "0", "]", "\n", "", "", "return", "timer", "(", ")", "-", "start", ",", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.run_eval_epoch": [[78, 90], ["timeit.default_timer", "six.moves.xrange", "total_cost.append", "sess.run", "timeit.default_timer"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "run_eval_epoch", "(", "sess", ",", "cost_op", ",", "ops", ",", "num_unrolls", ",", "step", "=", "None", ",", "unroll_len", "=", "None", ")", ":", "\n", "  ", "\"\"\"Runs one optimization epoch.\"\"\"", "\n", "start", "=", "timer", "(", ")", "\n", "# sess.run(reset)", "\n", "total_cost", "=", "[", "]", "\n", "feed_dict", "=", "{", "}", "\n", "for", "i", "in", "xrange", "(", "num_unrolls", ")", ":", "\n", "    ", "if", "step", "is", "not", "None", ":", "\n", "        ", "feed_dict", "[", "step", "]", "=", "i", "*", "unroll_len", "+", "1", "\n", "", "cost", "=", "sess", ".", "run", "(", "[", "cost_op", "]", "+", "ops", ",", "feed_dict", "=", "feed_dict", ")", "[", "0", "]", "\n", "total_cost", ".", "append", "(", "cost", ")", "\n", "", "return", "timer", "(", ")", "-", "start", ",", "total_cost", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.print_stats": [[92, 97], ["print", "print", "print", "numpy.log10"], "function", ["None"], ["", "def", "print_stats", "(", "header", ",", "total_error", ",", "total_time", ",", "n", ")", ":", "\n", "  ", "\"\"\"Prints experiment statistics.\"\"\"", "\n", "print", "(", "header", ")", "\n", "print", "(", "\"Log Mean Final Error: {:.2f}\"", ".", "format", "(", "np", ".", "log10", "(", "total_error", "/", "n", ")", ")", ")", "\n", "print", "(", "\"Mean epoch time: {:.2f} s\"", ".", "format", "(", "total_time", "/", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config": [[99, 109], ["None"], "function", ["None"], ["", "def", "get_default_net_config", "(", "path", ")", ":", "\n", "  ", "return", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_config": [[112, 266], ["problems.simple", "problems.simple_multi_optimizer", "problems.quadratic", "problems.mnist", "util.get_default_net_config", "problems.mnist", "util.get_default_net_config", "problems.mnist", "util.get_default_net_config", "problems.mnist_conv", "util.get_default_net_config", "problems.cifar10", "util.get_default_net_config", "problems.LeNet", "util.get_default_net_config", "problems.NAS", "util.get_default_net_config", "problems.vgg16_cifar10", "util.get_default_net_config", "problems.cifar10", "util.get_default_net_config", "util.get_default_net_config", "problems.confocal_microscopy_3d", "six.moves.xrange", "six.moves.xrange", "six.moves.xrange", "six.moves.xrange", "six.moves.xrange", "problems.square_cos", "problems.rastrigin", "problems.lasso", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.simple", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.simple_multi_optimizer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.quadratic", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.mnist_conv", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.LeNet", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.NAS", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.vgg16_cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.cifar10", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_default_net_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.confocal_microscopy_3d", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.square_cos", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.rastrigin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.problems.lasso"], ["", "def", "get_config", "(", "problem_name", ",", "path", "=", "None", ",", "mode", "=", "None", ",", "num_hidden_layer", "=", "None", ",", "net_name", "=", "None", ")", ":", "\n", "  ", "\"\"\"Returns problem configuration.\"\"\"", "\n", "if", "problem_name", "==", "\"simple\"", ":", "\n", "    ", "problem", "=", "problems", ".", "simple", "(", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", ")", ",", "\"initializer\"", ":", "\"zeros\"", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"simple-multi\"", ":", "\n", "    ", "problem", "=", "problems", ".", "simple_multi_optimizer", "(", ")", "\n", "net_config", "=", "{", "\n", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", ")", ",", "\"initializer\"", ":", "\"zeros\"", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", ",", "\n", "\"adam\"", ":", "{", "\n", "\"net\"", ":", "\"Adam\"", ",", "\n", "\"net_options\"", ":", "{", "\"learning_rate\"", ":", "0.01", "}", "\n", "}", "\n", "}", "\n", "net_assignments", "=", "[", "(", "\"cw\"", ",", "[", "\"x_0\"", "]", ")", ",", "(", "\"adam\"", ",", "[", "\"x_1\"", "]", ")", "]", "\n", "", "elif", "problem_name", "==", "\"quadratic\"", ":", "\n", "    ", "problem", "=", "problems", ".", "quadratic", "(", "batch_size", "=", "128", ",", "num_dims", "=", "10", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", "20", ",", "20", ")", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "### our tests", "\n", "", "elif", "problem_name", "==", "\"mnist\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "mnist", "(", "layers", "=", "(", "20", ",", ")", ",", "activation", "=", "\"sigmoid\"", ",", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"mnist_relu\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "mnist", "(", "layers", "=", "(", "20", ",", ")", ",", "activation", "=", "\"relu\"", ",", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"mnist_deeper\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "num_hidden_layer", "=", "2", "\n", "problem", "=", "problems", ".", "mnist", "(", "layers", "=", "(", "20", ",", ")", "*", "num_hidden_layer", ",", "activation", "=", "\"sigmoid\"", ",", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"mnist_conv\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "mnist_conv", "(", "mode", "=", "mode", ",", "batch_norm", "=", "True", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"cifar_conv\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "cifar10", "(", "\"cifar10\"", ",", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"lenet\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "LeNet", "(", "\"cifar10\"", ",", "\n", "conv_channels", "=", "(", "6", ",", "16", ")", ",", "\n", "linear_layers", "=", "(", "120", ",", "84", ")", ",", "\n", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"nas\"", ":", "\n", "    ", "if", "mode", "is", "None", ":", "\n", "        ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "", "problem", "=", "problems", ".", "NAS", "(", "\"cifar10\"", ",", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "###", "\n", "", "elif", "problem_name", "==", "\"vgg16\"", ":", "\n", "    ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "problem", "=", "problems", ".", "vgg16_cifar10", "(", "\"cifar10\"", ",", "\n", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "get_default_net_config", "(", "path", ")", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"cifar-multi\"", ":", "\n", "    ", "mode", "=", "\"train\"", "if", "path", "is", "None", "else", "\"test\"", "\n", "problem", "=", "problems", ".", "cifar10", "(", "\"cifar10\"", ",", "\n", "conv_channels", "=", "(", "16", ",", "16", ",", "16", ")", ",", "\n", "linear_layers", "=", "(", "32", ",", ")", ",", "\n", "mode", "=", "mode", ")", "\n", "net_config", "=", "{", "\n", "\"conv\"", ":", "get_default_net_config", "(", "path", ")", ",", "\n", "\"fc\"", ":", "get_default_net_config", "(", "path", ")", "\n", "}", "\n", "conv_vars", "=", "[", "\"conv_net_2d/conv_2d_{}/w\"", ".", "format", "(", "i", ")", "for", "i", "in", "xrange", "(", "3", ")", "]", "\n", "fc_vars", "=", "[", "\"conv_net_2d/conv_2d_{}/b\"", ".", "format", "(", "i", ")", "for", "i", "in", "xrange", "(", "3", ")", "]", "\n", "fc_vars", "+=", "[", "\"conv_net_2d/batch_norm_{}/beta\"", ".", "format", "(", "i", ")", "for", "i", "in", "xrange", "(", "3", ")", "]", "\n", "fc_vars", "+=", "[", "\"mlp/linear_{}/w\"", ".", "format", "(", "i", ")", "for", "i", "in", "xrange", "(", "2", ")", "]", "\n", "fc_vars", "+=", "[", "\"mlp/linear_{}/b\"", ".", "format", "(", "i", ")", "for", "i", "in", "xrange", "(", "2", ")", "]", "\n", "fc_vars", "+=", "[", "\"mlp/batch_norm/beta\"", "]", "\n", "net_assignments", "=", "[", "(", "\"conv\"", ",", "conv_vars", ")", ",", "(", "\"fc\"", ",", "fc_vars", ")", "]", "\n", "", "elif", "problem_name", "==", "\"confocal_microscopy_3d\"", ":", "\n", "    ", "problem", "=", "problems", ".", "confocal_microscopy_3d", "(", "batch_size", "=", "32", ",", "num_points", "=", "5", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", "20", ",", "20", ")", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"square_cos\"", ":", "\n", "    ", "problem", "=", "problems", ".", "square_cos", "(", "batch_size", "=", "128", ",", "num_dims", "=", "2", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", "20", ",", "20", ")", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"rastrigin\"", ":", "\n", "    ", "problem", "=", "problems", ".", "rastrigin", "(", "batch_size", "=", "128", ",", "num_dims", "=", "2", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", "20", ",", "20", ")", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "", "elif", "problem_name", "==", "\"lasso\"", ":", "\n", "    ", "problem", "=", "problems", ".", "lasso", "(", "batch_size", "=", "128", ",", "num_dims", "=", "2", ")", "\n", "net_config", "=", "{", "\"cw\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\"layers\"", ":", "(", "20", ",", "20", ")", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "}", "\n", "net_assignments", "=", "None", "\n", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"{} is not a valid problem\"", ".", "format", "(", "problem_name", ")", ")", "\n", "\n", "", "if", "net_name", "==", "\"RNNprop\"", ":", "\n", "      ", "default_config", "=", "{", "\n", "\"net\"", ":", "\"RNNprop\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"fc\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"dim\"", ":", "20", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "\"tanh_output\"", ":", "True", "\n", "}", ",", "\n", "\"net_path\"", ":", "path", "\n", "}", "\n", "net_config", "=", "{", "\"rp\"", ":", "default_config", "}", "\n", "\n", "", "return", "problem", ",", "net_config", ",", "net_assignments", "\n", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.__init__": [[36, 62], ["optimizers.split", "len", "meta_rnnprop_train._make_with_custom_variables", "tensorflow.gradients", "tensorflow.variables_initializer", "data_generator.data_loader.flatten_and_concat", "data_generator.data_loader.flatten_and_concat", "tensorflow.train.AdamOptimizer", "data_generator.data_loader.adam.apply_gradients", "data_generator.opt_variables_initializer", "tensorflow.train.RMSPropOptimizer", "data_generator.data_loader.rmsprop.apply_gradients", "data_generator.opt_variables_initializer", "tensorflow.train.MomentumOptimizer", "data_generator.data_loader.nag.apply_gradients", "data_generator.opt_variables_initializer", "range", "zip", "zip", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval._make_with_custom_variables", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.flatten_and_concat", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.flatten_and_concat", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.opt_variables_initializer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.opt_variables_initializer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.opt_variables_initializer"], ["    ", "def", "__init__", "(", "self", ",", "make_loss", ",", "x", ",", "constants", ",", "subsets", ",", "scale", ",", "optimizers", ",", "unroll_len", ")", ":", "\n", "        ", "self", ".", "unroll_len", "=", "unroll_len", "\n", "self", ".", "optimizers", "=", "optimizers", ".", "split", "(", "\",\"", ")", "\n", "self", ".", "num_subsets", "=", "len", "(", "subsets", ")", "\n", "\n", "self", ".", "x", "=", "x", "\n", "self", ".", "x_flat", "=", "[", "self", ".", "flatten_and_concat", "(", "[", "x", "[", "i", "]", "for", "i", "in", "subset", "]", ")", "for", "subset", "in", "subsets", "]", "\n", "self", ".", "scale", "=", "scale", "\n", "scaled_x", "=", "[", "x", "[", "k", "]", "*", "scale", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "scale", ")", ")", "]", "\n", "self", ".", "loss", "=", "_make_with_custom_variables", "(", "make_loss", ",", "scaled_x", ")", "\n", "self", ".", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "x", ")", "\n", "self", ".", "gradients_flat", "=", "[", "self", ".", "flatten_and_concat", "(", "[", "self", ".", "gradients", "[", "i", "]", "for", "i", "in", "subset", "]", ")", "\n", "for", "subset", "in", "subsets", "]", "\n", "self", ".", "reset_x", "=", "tf", ".", "variables_initializer", "(", "x", "+", "constants", ")", "\n", "if", "\"adam\"", "in", "self", ".", "optimizers", ":", "\n", "            ", "self", ".", "adam", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "0.01", ")", "\n", "self", ".", "update_adam", "=", "self", ".", "adam", ".", "apply_gradients", "(", "zip", "(", "self", ".", "gradients", ",", "x", ")", ")", "\n", "self", ".", "reset_adam", "=", "opt_variables_initializer", "(", "self", ".", "adam", ",", "x", ",", "True", ")", "\n", "", "if", "\"rmsprop\"", "in", "self", ".", "optimizers", ":", "\n", "            ", "self", ".", "rmsprop", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "0.01", ")", "\n", "self", ".", "update_rmsprop", "=", "self", ".", "rmsprop", ".", "apply_gradients", "(", "zip", "(", "self", ".", "gradients", ",", "x", ")", ")", "\n", "self", ".", "reset_rmsprop", "=", "opt_variables_initializer", "(", "self", ".", "rmsprop", ",", "x", ")", "\n", "", "if", "\"nag\"", "in", "self", ".", "optimizers", ":", "\n", "            ", "self", ".", "nag", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "0.01", ",", "0.9", ",", "use_nesterov", "=", "True", ")", "\n", "self", ".", "update_nag", "=", "self", ".", "nag", ".", "apply_gradients", "(", "zip", "(", "self", ".", "gradients", ",", "x", ")", ")", "\n", "self", ".", "reset_nag", "=", "opt_variables_initializer", "(", "self", ".", "nag", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.flatten_and_concat": [[63, 70], ["tensorflow.concat", "tensorflow.squeeze", "var_flat.append", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "flatten_and_concat", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "var_flat", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "            ", "var", "=", "tf", ".", "squeeze", "(", "tf", ".", "reshape", "(", "var", ",", "shape", "=", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "var_flat", ".", "append", "(", "var", ")", "\n", "", "var_cat", "=", "tf", ".", "concat", "(", "var_flat", ",", "axis", "=", "0", ")", "\n", "return", "var_cat", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.data_loader.get_data": [[71, 125], ["getattr", "sess.run", "getattr", "sess.run", "sess.run", "range", "range", "assign_func", "range", "range", "data[].append", "data[].append", "r_scale.append", "len", "sess.run", "k_value_list.append", "sess.run", "inputs.append", "range", "sess.run", "labels.append", "numpy.concatenate", "input_subsets.append", "numpy.concatenate", "label_subsets.append", "numpy.exp", "zip", "sess.run", "numpy.random.uniform", "zip"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "get_data", "(", "self", ",", "task_i", ",", "sess", ",", "num_unrolls", ",", "assign_func", ",", "rd_scale_bound", ",", "if_scale", "=", "True", ",", "mt_k", "=", "1", ")", ":", "\n", "        ", "opt_name", "=", "self", ".", "optimizers", "[", "task_i", "]", "\n", "update", "=", "getattr", "(", "self", ",", "\"update_\"", "+", "opt_name", ")", "\n", "\n", "# init", "\n", "sess", ".", "run", "(", "self", ".", "reset_x", ")", "\n", "\n", "# reset", "\n", "opt_reset", "=", "getattr", "(", "self", ",", "\"reset_{}\"", ".", "format", "(", "opt_name", ")", ")", "\n", "sess", ".", "run", "(", "opt_reset", ")", "\n", "\n", "# scale", "\n", "if", "if_scale", ":", "\n", "            ", "r_scale", "=", "[", "]", "\n", "for", "k", "in", "self", ".", "scale", ":", "\n", "                ", "r_scale", ".", "append", "(", "np", ".", "exp", "(", "np", ".", "random", ".", "uniform", "(", "-", "rd_scale_bound", ",", "rd_scale_bound", ",", "\n", "size", "=", "k", ".", "shape", ")", ")", ")", "\n", "", "feed_rs", "=", "{", "p", ":", "v", "for", "p", ",", "v", "in", "zip", "(", "self", ".", "scale", ",", "r_scale", ")", "}", "\n", "k_value_list", "=", "[", "]", "\n", "for", "k_id", "in", "range", "(", "len", "(", "self", ".", "scale", ")", ")", ":", "\n", "                ", "k_value", "=", "sess", ".", "run", "(", "self", ".", "x", "[", "k_id", "]", ")", "\n", "k_value", "=", "k_value", "/", "r_scale", "[", "k_id", "]", "\n", "k_value_list", ".", "append", "(", "k_value", ")", "\n", "", "assert", "assign_func", "is", "not", "None", "\n", "assign_func", "(", "k_value_list", ")", "\n", "", "else", ":", "\n", "            ", "feed_rs", "=", "{", "}", "\n", "\n", "# get updates", "\n", "", "data", "=", "{", "\"inputs\"", ":", "[", "]", ",", "\"labels\"", ":", "[", "]", "}", "\n", "x_prev", "=", "sess", ".", "run", "(", "self", ".", "x_flat", ")", "\n", "\n", "for", "ri", "in", "range", "(", "num_unrolls", ")", ":", "\n", "            ", "inputs", "=", "[", "]", "# (unroll_length, num_subsets, num_params)", "\n", "labels", "=", "[", "]", "\n", "for", "stepi", "in", "range", "(", "self", ".", "unroll_len", ")", ":", "\n", "                ", "*", "gs", ",", "_", "=", "sess", ".", "run", "(", "self", ".", "gradients_flat", "+", "[", "update", "]", ",", "feed_dict", "=", "feed_rs", ")", "\n", "inputs", ".", "append", "(", "gs", ")", "\n", "for", "ki", "in", "range", "(", "mt_k", "-", "1", ")", ":", "\n", "                    ", "sess", ".", "run", "(", "update", ",", "feed_dict", "=", "feed_rs", ")", "\n", "", "x_cur", "=", "sess", ".", "run", "(", "self", ".", "x_flat", ")", "\n", "x_diff", "=", "[", "cur", "-", "prev", "for", "cur", ",", "prev", "in", "zip", "(", "x_cur", ",", "x_prev", ")", "]", "\n", "x_prev", "=", "x_cur", "\n", "labels", ".", "append", "(", "x_diff", ")", "\n", "", "input_subsets", "=", "[", "]", "# (num_subsets, unroll_length, num_params)", "\n", "label_subsets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_subsets", ")", ":", "\n", "                ", "ipt", "=", "np", ".", "concatenate", "(", "[", "ipt", "[", "i", "]", "[", "None", ",", ":", "]", "for", "ipt", "in", "inputs", "]", ",", "axis", "=", "0", ")", "\n", "input_subsets", ".", "append", "(", "ipt", ")", "\n", "lb", "=", "np", ".", "concatenate", "(", "[", "lb", "[", "i", "]", "[", "None", ",", ":", "]", "for", "lb", "in", "labels", "]", ",", "axis", "=", "0", ")", "\n", "label_subsets", ".", "append", "(", "lb", ")", "\n", "", "data", "[", "\"inputs\"", "]", ".", "append", "(", "input_subsets", ")", "\n", "data", "[", "\"labels\"", "]", ".", "append", "(", "label_subsets", ")", "\n", "", "return", "data", "", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.data_generator.opt_variables_initializer": [[26, 33], ["tensorflow.variables_initializer", "opt.get_slot", "vars.extend", "opt.get_slot_names", "list", "opt._get_beta_accumulators"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend"], ["def", "opt_variables_initializer", "(", "opt", ",", "var_list", ",", "if_adam", "=", "False", ")", ":", "\n", "  ", "vars", "=", "[", "opt", ".", "get_slot", "(", "var", ",", "name", ")", "\n", "for", "name", "in", "opt", ".", "get_slot_names", "(", ")", "\n", "for", "var", "in", "var_list", "if", "var", "is", "not", "None", "]", "\n", "if", "if_adam", ":", "\n", "    ", "vars", ".", "extend", "(", "list", "(", "opt", ".", "_get_beta_accumulators", "(", ")", ")", ")", "\n", "", "return", "tf", ".", "variables_initializer", "(", "vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.evaluate_dm.main": [[48, 104], ["util.get_config", "tensorflow.ConfigProto", "print", "tensorflow.set_random_seed", "problem", "tensorflow.get_collection", "tensorflow.variables_initializer", "tensorflow.train.AdamOptimizer", "tensorflow.variables_initializer", "meta.MetaOptimizer.minimize", "tensorflow.contrib.learn.python.learn.monitored_session.MonitoredSession", "sess.run", "tensorflow.get_default_graph().finalize", "six.moves.xrange", "util.print_stats", "open", "pickle.dump", "meta.MetaOptimizer.get_slot_names", "meta.MetaOptimizer", "meta.MetaOptimizer.meta_loss", "ValueError", "util.run_eval_epoch", "os.path.exists", "os.mkdir", "logging.warning", "tensorflow.get_default_graph", "sum"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.get_config", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.print_stats", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.meta_loss", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.util.run_eval_epoch"], ["def", "main", "(", "_", ")", ":", "\n", "# Configuration.", "\n", "    ", "num_unrolls", "=", "FLAGS", ".", "num_steps", "\n", "if", "FLAGS", ".", "seed", ":", "\n", "        ", "tf", ".", "set_random_seed", "(", "FLAGS", ".", "seed", ")", "\n", "\n", "# Problem.", "\n", "", "problem", ",", "net_config", ",", "net_assignments", "=", "util", ".", "get_config", "(", "FLAGS", ".", "problem", ",", "FLAGS", ".", "path", ")", "\n", "\n", "# Optimizer setup.", "\n", "if", "FLAGS", ".", "optimizer", "==", "\"Adam\"", ":", "\n", "        ", "cost_op", "=", "problem", "(", ")", "\n", "problem_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "problem_reset", "=", "tf", ".", "variables_initializer", "(", "problem_vars", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "FLAGS", ".", "learning_rate", ")", "\n", "optimizer_reset", "=", "tf", ".", "variables_initializer", "(", "optimizer", ".", "get_slot_names", "(", ")", ")", "\n", "update", "=", "optimizer", ".", "minimize", "(", "cost_op", ")", "\n", "reset", "=", "[", "problem_reset", ",", "optimizer_reset", "]", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "\"L2L\"", ":", "\n", "        ", "if", "FLAGS", ".", "path", "is", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Evaluating untrained L2L optimizer\"", ")", "\n", "", "optimizer", "=", "meta", ".", "MetaOptimizer", "(", "**", "net_config", ")", "\n", "meta_loss", "=", "optimizer", ".", "meta_loss", "(", "problem", ",", "1", ",", "net_assignments", "=", "net_assignments", ")", "\n", "_", ",", "update", ",", "reset", ",", "cost_op", ",", "_", "=", "meta_loss", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"{} is not a valid optimizer\"", ".", "format", "(", "FLAGS", ".", "optimizer", ")", ")", "\n", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "ms", ".", "MonitoredSession", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "reset", ")", "\n", "# Prevent accidental changes to the graph.", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "\n", "total_time", "=", "0", "\n", "total_cost", "=", "0", "\n", "loss_record", "=", "[", "]", "\n", "for", "e", "in", "xrange", "(", "FLAGS", ".", "num_epochs", ")", ":", "\n", "# Training.", "\n", "            ", "time", ",", "cost", "=", "util", ".", "run_eval_epoch", "(", "sess", ",", "cost_op", ",", "[", "update", "]", ",", "num_unrolls", ")", "\n", "total_time", "+=", "time", "\n", "total_cost", "+=", "sum", "(", "cost", ")", "/", "num_unrolls", "\n", "loss_record", "+=", "cost", "\n", "\n", "# Results.", "\n", "", "util", ".", "print_stats", "(", "\"Epoch {}\"", ".", "format", "(", "FLAGS", ".", "num_epochs", ")", ",", "total_cost", ",", "\n", "total_time", ",", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_path", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "output_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "FLAGS", ".", "output_path", ")", "\n", "", "", "output_file", "=", "'{}/{}_eval_loss_record.pickle-{}'", ".", "format", "(", "FLAGS", ".", "output_path", ",", "FLAGS", ".", "optimizer", ",", "FLAGS", ".", "problem", ")", "\n", "with", "open", "(", "output_file", ",", "'wb'", ")", "as", "l_record", ":", "\n", "        ", "pickle", ".", "dump", "(", "loss_record", ",", "l_record", ")", "\n", "", "print", "(", "\"Saving evaluate loss record {}\"", ".", "format", "(", "output_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.History_Collector.__init__": [[148, 152], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "SR_memlen", ",", "Ngroup_zee", ")", ":", "\n", "        ", "self", ".", "SR_memlen", "=", "SR_memlen", "\n", "self", ".", "Ngroup_zee", "=", "Ngroup_zee", "\n", "self", ".", "past_mems", "=", "[", "]", "\n", "", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.History_Collector.__call__": [[152, 183], ["stage023_resnet.History_Collector.past_mems[].insert", "torch.cat", "stage023_resnet.History_Collector.past_mems.append", "meta.new_detached_var", "torch.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.insert", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.new_detached_var"], ["", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n", "# gfeat shape:      [nNeu_thisLayer, Ngf]", "\n", "# output shape:     [nNeu_thisLayer, N_tf = SR_memlen * Ngf]", "\n", "\n", "        ", "assert", "i_step", ">=", "1", "\n", "if", "i_step", "==", "1", ":", "# i_step is in range(1, run_epoch_len + 1)", "\n", "            ", "self", ".", "past_mems", ".", "append", "(", "None", ")", "\n", "self", ".", "past_mems", "[", "i_group", "]", "=", "[", "new_detached_var", "(", "torch", ".", "zeros", "(", "*", "gfeat", ".", "shape", ",", "device", "=", "DEVICE", ")", ")", "for", "_", "in", "range", "(", "self", ".", "SR_memlen", ")", "]", "\n", "\n", "# del self.past_mems[i_group][0]", "\n", "# self.past_mems[i_group].append(gfeat)", "\n", "", "del", "self", ".", "past_mems", "[", "i_group", "]", "[", "-", "1", "]", "\n", "self", ".", "past_mems", "[", "i_group", "]", ".", "insert", "(", "0", ",", "gfeat", ")", "\n", "\n", "res", "=", "torch", ".", "cat", "(", "self", ".", "past_mems", "[", "i_group", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "# # inspect stats", "\n", "# # MNIST problem: std:", "\n", "# #     mt ~ 0.2", "\n", "# #     gt ~ 1.0", "\n", "# #     g/mom ~ 0.0005", "\n", "# if i_step>self.SR_memlen:", "\n", "#     for i_group in range(len(self.past_mems)):", "\n", "#         ntf = torch.stack(self.past_mems[i_group], dim=1)  # shape = [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "#         calStat_thisLayer(ntf)", "\n", "#     raise", "\n", "\n", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.SRDataset.__init__": [[367, 373], ["SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "which_SR_dataset", ")", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "# data = np.load(SR_dataset_fname)", "\n", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "self", ".", "X", "=", "torch", ".", "tensor", "(", "Xy_fit", ",", "device", "=", "DEVICE", ")", "\n", "self", ".", "N", "=", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.SRDataset.__getitem__": [[374, 377], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "X", "[", "index", "]", "\n", "return", "x", "[", ":", "-", "1", "]", ",", "x", "[", "-", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.SRDataset.__len__": [[378, 380], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.sr_fun_tensor": [[31, 145], ["input_b_tf.reshape", "eval", "eval.reshape", "torch.relu", "torch.sin", "torch.sin", "torch.sign", "torch.tanh", "torch.exp", "abs", "torch.real", "torch.erfc", "torch.sqrt", "torch.log", "torch.sinh", "torch.asinh", "torch.sign", "torch.sign", "torch.pow", "abs", "abs", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow"], ["def", "sr_fun_tensor", "(", "input_b_tf", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ",", "expr_Nvar", ",", "coeff_SRNorm", ",", "**", "w", ")", ":", "\n", "# the SR function predicts the LSTM output, which is NOT multiplied by 0.01", "\n", "# lum is never used in sr study.", "\n", "# any input/output re-scale must be done simultaneously in TWO places:", "\n", "# 1. the sr_prep2, just before outputing results.", "\n", "# 2. this function, just before outputing results.", "\n", "# I/O is a group (batch) ", "\n", "# input shape:      [batch_size, N_tf]", "\n", "# output shape:     [batch_size, 1]", "\n", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# coeff_SRNorm:     [expr_Nvar,]", "\n", "\n", "\n", "# btf: [batch_size, SR_memlen, Ngf]", "\n", "# output tensor is 2-D, shape is [batch_size, 1]", "\n", "\n", "    ", "btf", "=", "input_b_tf", ".", "reshape", "(", "-", "1", ",", "SR_memlen", ",", "Ngf", ")", "\n", "assert", "Ngf", "==", "expr_Nvar", "\n", "btf", "/=", "coeff_SRNorm", "\n", "\n", "\n", "\n", "\n", "def", "expm", "(", "x", ",", "a", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "abs", "(", "x", ")", "**", "a", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n", "        ", "return", "F", ".", "relu", "(", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "(", "x", ">", "y", ")", ".", "float", "(", ")", "\n", "", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "torch", ".", "pow", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n", "        ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sqrt", "(", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "abs", "(", "x", ")", "+", "1e-7", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "asinh", "(", "x", ")", "\n", "\n", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "        ", "mt_0", "=", "btf", "[", ":", ",", "0", ",", "0", "]", "\n", "mt_1", "=", "btf", "[", ":", ",", "1", ",", "0", "]", "\n", "mt_2", "=", "btf", "[", ":", ",", "2", ",", "0", "]", "\n", "mt_3", "=", "btf", "[", ":", ",", "3", ",", "0", "]", "\n", "mt_4", "=", "btf", "[", ":", ",", "4", ",", "0", "]", "\n", "mt_5", "=", "btf", "[", ":", ",", "5", ",", "0", "]", "\n", "\n", "", "except", "IndexError", ":", "\n", "        ", "pass", "\n", "\n", "\n", "", "gt_0", "=", "btf", "[", ":", ",", "0", ",", "1", "]", "\n", "gt_1", "=", "btf", "[", ":", ",", "1", ",", "1", "]", "\n", "gt_2", "=", "btf", "[", ":", ",", "2", ",", "1", "]", "\n", "gt_3", "=", "btf", "[", ":", ",", "3", ",", "1", "]", "\n", "gt_4", "=", "btf", "[", ":", ",", "4", ",", "1", "]", "\n", "gt_5", "=", "btf", "[", ":", ",", "5", ",", "1", "]", "\n", "\n", "\n", "\n", "g_0", "=", "btf", "[", ":", ",", "0", ",", "2", "]", "\n", "g_1", "=", "btf", "[", ":", ",", "1", ",", "2", "]", "\n", "g_2", "=", "btf", "[", ":", ",", "2", ",", "2", "]", "\n", "g_3", "=", "btf", "[", ":", ",", "3", ",", "2", "]", "\n", "g_4", "=", "btf", "[", ":", ",", "4", ",", "2", "]", "\n", "g_5", "=", "btf", "[", ":", ",", "5", ",", "2", "]", "\n", "\n", "mom5_0", "=", "btf", "[", ":", ",", "0", ",", "3", "]", "\n", "mom5_1", "=", "btf", "[", ":", ",", "1", ",", "3", "]", "\n", "mom5_2", "=", "btf", "[", ":", ",", "2", ",", "3", "]", "\n", "mom5_3", "=", "btf", "[", ":", ",", "3", ",", "3", "]", "\n", "mom5_4", "=", "btf", "[", ":", ",", "4", ",", "3", "]", "\n", "mom5_5", "=", "btf", "[", ":", ",", "5", ",", "3", "]", "\n", "\n", "\n", "expr", "=", "eval", "(", "expr", ")", "\n", "\n", "b1", "=", "expr", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "\n", "return", "b1", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.calStat_thisLayer": [[186, 195], ["np.zeros", "range", "print", "ntf[].reshape", "torch.mean", "torch.std"], "function", ["None"], ["", "", "def", "calStat_thisLayer", "(", "ntf", ")", ":", "\n", "# input shape: [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "    ", "F", "=", "ntf", ".", "shape", "[", "-", "1", "]", "\n", "mv", "=", "np", ".", "zeros", "(", "(", "F", ",", "2", ")", ")", "\n", "for", "f", "in", "range", "(", "F", ")", ":", "\n", "        ", "this", "=", "ntf", "[", ":", ",", ":", ",", "f", "]", ".", "reshape", "(", "-", "1", ")", "\n", "mv", "[", "f", "]", "=", "[", "torch", ".", "mean", "(", "this", ")", ",", "torch", ".", "std", "(", "this", ")", "]", "\n", "", "print", "(", "f'mean & std at this layer (feat x m/std):\\n{mv}'", ")", "\n", "return", "mv", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.eva_sr_trainingPerform": [[206, 225], ["print", "OPT().to", "zip", "np.save", "np.asarray", "np.mean", "np.mean", "meta.wzRec", "stage023_resnet.run_epoch_sr", "np.sum", "OPT", "range"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr"], ["", "def", "eva_sr_trainingPerform", "(", "args", ",", "eva_epoch_len", "=", "None", ",", "OPT", "=", "None", ",", "n_tests", "=", "None", ",", "want_save_eva_loss", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "print", "(", "'TODO: add no grad to eva'", ")", "\n", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "\n", "res", "=", "[", "run_epoch_sr", "(", "args", ",", "eva_epoch_len", ",", "should_train", "=", "False", ",", "**", "args", ")", "for", "_", "in", "range", "(", "n_tests", ")", "]", "\n", "\n", "losses", ",", "coeffs", "=", "zip", "(", "*", "res", ")", "\n", "\n", "np", ".", "save", "(", "'coeffs_fake_eva.npy'", ",", "coeffs", ")", "\n", "\n", "all_losses", "=", "np", ".", "asarray", "(", "losses", ")", "\n", "avg_eva_sum_loss", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "all_losses", ",", "1", ")", ",", "0", ")", "\n", "avg_eva_last_loss", "=", "np", ".", "mean", "(", "all_losses", "[", ":", ",", "-", "1", "]", ",", "0", ")", "\n", "\n", "wzRec", "(", "all_losses", ",", "'Eva-SR-loss'", ",", "Target_Optimizee", ".", "name", ",", "want_save", "=", "want_save_eva_loss", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.fine_tune_SR": [[227, 264], ["coeff_SR.detach().cpu().data.numpy().round", "print", "OPT_META_SR", "OPT().to", "range", "coeff_SR.detach().cpu().data.numpy().round", "print", "stage023_resnet.eva_sr_trainingPerform", "itertools.chain.from_iterable", "stage023_resnet.run_epoch_sr", "coeffs_allEP.append", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "print", "np.save", "np.save", "coeff_SR.detach().cpu().data.numpy", "OPT", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach().cpu().data.numpy", "stage023_resnet.eva_sr_trainingPerform", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform"], ["", "def", "fine_tune_SR", "(", "args", ",", "coeff_SR", "=", "None", ",", "OPT", "=", "None", ",", "epoch_len_tuneSR", "=", "None", ",", "n_epochs_tuneSR", "=", "20", ",", "srFineTune_want_eva_in_train", "=", "None", ",", "OPT_META_SR", "=", "None", ",", "lr_meta_tuneSR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# this function will not build new SR coeffs (in-place tuning)", "\n", "# but really DOES initialize a new meta-opt", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "\n", "\n", "args", "[", "'opt_meta_SR'", "]", "=", "OPT_META_SR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_meta_tuneSR", ",", "momentum", "=", "0.9", ")", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "coeffs_allEP", "=", "[", "]", "\n", "\n", "\n", "# for iepoch in tqdm(range(n_epochs_tuneSR), 'Fine tuning SR'):", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_tuneSR", ")", ":", "\n", "\n", "        ", "losses_1epoch", ",", "coeffs", "=", "run_epoch_sr", "(", "args", ",", "epoch_len_tuneSR", ",", "should_train", "=", "True", ",", "**", "args", ")", "\n", "coeffs_allEP", ".", "append", "(", "coeffs", ")", "\n", "\n", "wzRec", "(", "losses_1epoch", ",", "'tuneSR-train-loss, epoch-{}'", ".", "format", "(", "iepoch", ")", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "np", ".", "save", "(", "'coeff_SR.npy'", ",", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_allEP.npy'", ",", "coeffs_allEP", ")", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "if", "srFineTune_want_eva_in_train", ":", "\n", "                ", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "\n", "\n", "", "", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'final coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.run_epoch_sr": [[268, 362], ["bool", "Target_DataGen", "Target_Optimizee().to", "meta.wIni", "l2oShell_4SR_featPrep.reset", "tqdm", "stage023_resnet.History_Collector", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "type", "Target_Optimizee().to.parameters", "opt_meta_SR.zero_grad", "range", "tqdm", "range", "Target_Optimizee().to.", "losses_1epoch.append", "optimizee.backward", "enumerate", "Target_Optimizee", "range", "optimizee.data.cpu().numpy", "Target_Optimizee().to.named_parameters", "int", "meta.detach_var", "l2oShell_4SR_featPrep.grad2features", "History_Collector.", "stage023_resnet.sr_fun_tensor", "result_params[].retain_grad", "Target_Optimizee().to", "meta.wIni", "Target_Optimizee().to.load_state_dict", "Target_Optimizee().to.zero_grad", "Target_Optimizee().to.named_parameters", "Target_Optimizee().to.cal_test_acc", "coeff_SR.detach().cpu().data.numpy", "np.prod", "p.grad.view", "sr_fun_tensor.view", "opt_meta_SR.zero_grad", "Target_Optimizee().to.", "all_losses.backward", "opt_meta_SR.step", "bool", "coeff_SR.detach().cpu().data.numpy().round", "print", "meta.rsetattr", "optimizee.data.cpu", "p.size", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "Target_Optimizee", "p.size", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.reset", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.grad2features", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.cResNet.cal_test_acc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "def", "run_epoch_sr", "(", "args", ",", "run_epoch_len", ",", "should_train", ",", "rec_SR", "=", "True", ",", "coeff_SR", "=", "None", ",", "opt_meta_SR", "=", "None", ",", "l2oShell_4SR_featPrep", "=", "None", ",", "Target_DataGen", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "unroll_tuneSR", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "expr", "=", "None", ",", "Ngf", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "not", "should_train", ":", "\n", "        ", "unroll_tuneSR", "=", "1", "\n", "", "if", "bool", "(", "rec_SR", ")", ":", "\n", "        ", "args", "[", "'rec_SR'", "]", "=", "[", "]", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "\n", "", "target", "=", "Target_DataGen", "(", "training", "=", "should_train", ",", "**", "args", ")", "\n", "if", "type", "(", "target", ")", "is", "Cifar_f", ":", "\n", "        ", "round1", "=", "391", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "optimizee", "=", "Target_Optimizee", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "\n", "l2oShell_4SR_featPrep", ".", "reset", "(", "optimizee", ".", "parameters", "(", ")", ")", "\n", "\n", "losses_1epoch", ",", "all_losses", "=", "[", "]", ",", "None", "\n", "if", "should_train", ":", "\n", "        ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "iterator", "=", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ",", "'Eva: '", ")", "\n", "", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ")", "\n", "\n", "history_collector", "=", "History_Collector", "(", "SR_memlen", ",", "Ngroup_zee", ")", "\n", "for", "i_step", "in", "iterator", ":", "\n", "\n", "\n", "        ", "loss", "=", "optimizee", "(", "target", ")", "\n", "all_losses", "=", "loss", "if", "all_losses", "is", "None", "else", "all_losses", "+", "loss", "\n", "\n", "losses_1epoch", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "should_train", ")", "\n", "\n", "offset", "=", "0", "\n", "result_params", "=", "{", "}", "\n", "\n", "for", "i_group", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "optimizee", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "cur_sz", "=", "int", "(", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "\n", "gradients", "=", "detach_var", "(", "p", ".", "grad", ".", "view", "(", "cur_sz", ",", "1", ")", ")", "\n", "sr_features_cur", "=", "l2oShell_4SR_featPrep", ".", "grad2features", "(", "gradients", ",", "i_group", ",", "i_step", ")", "\n", "sr_inputs", "=", "history_collector", "(", "sr_features_cur", ",", "i_step", ",", "i_group", ")", "\n", "updates", "=", "sr_fun_tensor", "(", "sr_inputs", ",", "**", "args", ")", "\n", "\n", "updates", "=", "updates", "*", "0.01", "\n", "\n", "result_params", "[", "name", "]", "=", "p", "+", "updates", ".", "view", "(", "*", "p", ".", "size", "(", ")", ")", "\n", "result_params", "[", "name", "]", ".", "retain_grad", "(", ")", "\n", "\n", "offset", "+=", "cur_sz", "\n", "\n", "\n", "", "if", "i_step", "%", "unroll_tuneSR", "==", "0", ":", "\n", "            ", "if", "should_train", ":", "\n", "\n", "\n", "                ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "all_losses", "+=", "optimizee", "(", "target", ")", "\n", "all_losses", ".", "backward", "(", ")", "\n", "opt_meta_SR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "if", "bool", "(", "rec_SR", ")", ":", "\n", "                    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "\n", "\n", "", "all_losses", "=", "None", "\n", "optimizee", "=", "Target_Optimizee", "(", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "optimizee", ".", "load_state_dict", "(", "result_params", ")", "\n", "# updateDict_skip_running(optimizee,result_params)", "\n", "\n", "optimizee", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "p", "in", "optimizee", ".", "named_parameters", "(", ")", ":", "\n", "                ", "rsetattr", "(", "optimizee", ",", "name", ",", "result_params", "[", "name", "]", ")", "\n", "\n", "", "", "if", "i_step", "%", "round1", "==", "0", ":", "\n", "            ", "acc", "=", "optimizee", ".", "cal_test_acc", "(", "target", ".", "testloater", ")", "\n", "\n", "", "", "return", "losses_1epoch", ",", "args", "[", "'rec_SR'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.fit_SR": [[385, 431], ["coeff_SR.detach().cpu().data.numpy().round", "print", "OPT_fitSR", "nn.MSELoss", "stage023_resnet.SRDataset", "utils.get_infinite_iter", "range", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "print", "np.save", "itertools.chain.from_iterable", "utils.get_infinite_iter.sample", "stage023_resnet.sr_fun_tensor", "nn.MSELoss.", "OPT_fitSR.zero_grad", "mse.backward", "OPT_fitSR.step", "coeff_SR.detach().cpu().data.numpy", "stage023_resnet.evaSR_R2", "eva_r2s.append", "utils.progress_bar", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach().cpu().data.numpy().round.tolist", "coeff_SR.detach().cpu", "x.detach().cpu().data.item", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "x.detach().cpu", "x.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.evaSR_R2", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.progress_bar"], ["", "", "def", "fit_SR", "(", "args", ",", "lr_fitSR", "=", "None", ",", "expr", "=", "None", ",", "n_epochs_fit_SR", "=", "20", ",", "OPT_fitSR", "=", "None", ",", "l2o_net", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# need to un-comment 'step-0-prep' in order to have correct l2o_net name", "\n", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "\n", "\n", "opt_fitSR", "=", "OPT_fitSR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_fitSR", ")", "\n", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "dataset_train", "=", "SRDataset", "(", "which_SR_dataset", ")", "\n", "srIter", "=", "get_infinite_iter", "(", "dataset_train", ",", "shuffle", "=", "True", ",", "sampler", "=", "None", ",", "**", "args", ")", "\n", "\n", "\n", "eva_r2s", "=", "[", "]", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_fit_SR", ")", ":", "\n", "\n", "        ", "l2o_input_slices", ",", "l2o_output", "=", "srIter", ".", "sample", "(", ")", "# parallel working.", "\n", "\n", "sr_pred", "=", "sr_fun_tensor", "(", "l2o_input_slices", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "\n", "loss", "=", "mse", "(", "sr_pred", ",", "l2o_output", ")", "\n", "\n", "\n", "opt_fitSR", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt_fitSR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "eva_r2", "=", "evaSR_R2", "(", "args", ",", "**", "args", ")", "\n", "coeff_disp", "=", "[", "f'{x.detach().cpu().data.item():.4f}'", "for", "x", "in", "coeff_SR", "]", "\n", "\n", "# print(f'current coeff_SR: {coeff_disp}')", "\n", "eva_r2s", ".", "append", "(", "eva_r2", ")", "\n", "progress_bar", "(", "iepoch", ",", "n_epochs_fit_SR", ",", "f'loss={loss} , eva_r2={eva_r2} , coeff_SR={coeff_disp}'", ")", "\n", "\n", "", "", "wzRec", "(", "eva_r2s", ",", "'fit SR, eva_r2'", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "print", "(", "f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}'", ")", "\n", "np", ".", "save", "(", "'wz_saved_models/fitted SR ~ of ~ {l2o_net.name}.npy'", ",", "coeff_SR_list", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.evaSR_R2": [[434, 447], ["torch.no_grad", "SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "stage023_resnet.sr_fun_tensor", "sr_fun_tensor.detach().cpu().data.numpy", "sklearn.metrics.r2_score", "print", "sr_fun_tensor.detach().cpu", "sr_fun_tensor.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaSR_R2", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "**", "w", ")", ":", "\n", "# dataset_test = np.load(which_SR_dataset)", "\n", "    ", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "x", "=", "torch", ".", "tensor", "(", "Xy_test", "[", ":", ",", ":", "-", "1", "]", ",", "device", "=", "DEVICE", ")", "\n", "y_true", "=", "Xy_test", "[", ":", ",", "-", "1", "]", "\n", "pred_tensor", "=", "sr_fun_tensor", "(", "x", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "pred", "=", "pred_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "r2", "=", "r2_score", "(", "y_true", ",", "pred", ")", "\n", "\n", "print", "(", "f'\\n\\nR2 = {r2:.5f}\\n\\n'", ")", "\n", "\n", "return", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.viz_grad_seq": [[452, 479], ["to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "plt.close", "range", "print", "plt.subplot", "plt.plot", "plt.plot", "plt.legend", "np.random.choice", "list", "len", "len", "len", "print", "range", "range", "plt.plot"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "def", "viz_grad_seq", "(", "sr_r_t_n_f", ")", ":", "\n", "\n", "# [run, time, neuron/layer, feat]", "\n", "    ", "n_neuron", "=", "sr_r_t_n_f", ".", "shape", "[", "1", "]", "\n", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "layerIidx", "=", "[", "np", ".", "random", ".", "choice", "(", "n", ",", "1", ")", ",", "(", "0", ",", "1", ",", "-", "2", ",", "-", "1", ")", ",", "list", "(", "range", "(", "n", ")", ")", "]", "[", "-", "1", "]", "\n", "\n", "to_viz_r_t_n_f", "=", "sr_r_t_n_f", "[", ":", ",", ":", ",", "layerIidx", ",", ":", "]", "\n", "grad_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "update_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "gfeat_rt_n_f", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "1", ":", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", ",", "f", "-", "2", "]", ")", "\n", "if", "f", "==", "2", ":", "\n", "        ", "print", "(", "'viz for DM-opt'", ")", "\n", "", "elif", "f", ">", "2", ":", "\n", "        ", "print", "(", "'viz for RP-opt'", ")", "\n", "", "else", ":", "raise", "ValueError", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "for", "ilayer", "in", "range", "(", "n", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "2", ",", "n", "//", "2", ",", "ilayer", "+", "1", ")", "\n", "plt", ".", "plot", "(", "grad_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-x'", ",", "label", "=", "f'grad @ layer {ilayer}'", ")", "# len(layerIidx) \u6761\u6570\u636e", "\n", "plt", ".", "plot", "(", "update_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-o'", ",", "label", "=", "f'update @ layer {ilayer}'", ")", "\n", "def", "plot_feat", "(", ")", ":", "\n", "            ", "for", "i_f", "in", "range", "(", "f", "-", "2", ")", ":", "\n", "                ", "feati_rt_n", "=", "gfeat_rt_n_f", "[", ":", ",", ":", ",", "i_f", "]", "\n", "plt", ".", "plot", "(", "feati_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-1'", ",", "label", "=", "f'the {i_f}-th gfeat @ layer {ilayer}'", ")", "\n", "# if f>2:  plot_feat()", "\n", "", "", "plt", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.sr_prep1": [[482, 499], ["len", "print", "list", "int"], "function", ["None"], ["", "", "def", "sr_prep1", "(", "args", ",", "SR_memlen", ",", "num_Xyitems_SR", ",", "eva_epoch_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "Ngroup_zee", "=", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "tSample_1epoch", "=", "eva_epoch_len", "//", "SR_memlen", "-", "2", "\n", "assert", "tSample_1epoch", ">", "0", ",", "f'eva_epoch_len={eva_epoch_len}, should > SR_memlen*2 = {SR_memlen}*2 = {SR_memlen*2}'", "\n", "\n", "what_we_get_1epoch", "=", "tSample_1epoch", "*", "Ngroup_zee", "\n", "\n", "epochs_needed", "=", "int", "(", "num_Xyitems_SR", "/", "what_we_get_1epoch", "/", "10", "*", "1.6", ")", "+", "1", "\n", "args", "[", "'n_tests'", "]", "=", "epochs_needed", "\n", "args", "[", "'tSample_1epoch'", "]", "=", "tSample_1epoch", "\n", "args", "[", "'available_Interval'", "]", "=", "eva_epoch_len", "-", "tSample_1epoch", "*", "SR_memlen", "-", "2", "# -2 is for safety", "\n", "args", "[", "'SR_memlen'", "]", "=", "SR_memlen", "\n", "args", "[", "'num_Xyitems_SR'", "]", "=", "num_Xyitems_SR", "\n", "print", "(", "f'\\n\\n----------\\nSR prep:\\n\\tepochs_needed = {epochs_needed}\\n\\ttSample_1epoch = {tSample_1epoch}\\n\\tSR_memlen = {SR_memlen}\\n\\teva_epoch_len = {eva_epoch_len} > tSample_1epoch*SR_memlen = {tSample_1epoch}*{SR_memlen} = {tSample_1epoch*SR_memlen}\\n\\tNgroup_zee = {Ngroup_zee}\\n\\nTarget_DataGen = {Target_DataGen}\\nTarget_Optimizee = {Target_Optimizee}\\n----------\\n'", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.sr_prep2": [[501, 557], ["np.random.rand", "stage023_resnet.sr_prep2.interv_to_int"], "function", ["None"], ["", "def", "sr_prep2", "(", "sr_r_t_n_f", ",", "args", ",", "available_Interval", "=", "None", ",", "tSample_1epoch", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "num_Xyitems_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# returned SR_Xy_rn_tf shape:", "\n", "#     [N_sample , SR_memlen * Ngf+1 ] ; the last column is label", "\n", "\n", "# sr_gfu shape: [eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "# sr_r_t_n_f shape: ", "\n", "#     [which run (r) , which time step (t) , which neuron (n) , grad/feature/update (f) ]", "\n", "#     shape: [n_tests, eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "    ", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "f_true", "=", "f", "-", "2", "if", "f", ">", "2", "else", "f", "-", "1", "# RP or DM", "\n", "SR_XY_rtn_f", "=", "[", "]", "\n", "tSelect_r_n", "=", "np", ".", "random", ".", "rand", "(", "r", ",", "n", ",", "tSample_1epoch", "+", "1", ")", "\n", "def", "interv_to_int", "(", "tSelect_r_n", ")", ":", "\n", "# guarantee the randomness in sampling", "\n", "        ", "sum_", "=", "np", ".", "sum", "(", "tSelect_r_n", ",", "axis", "=", "2", ")", "\n", "tSelect_r_n", "=", "tSelect_r_n", "/", "sum_", "[", ":", ",", ":", ",", "None", "]", "*", "available_Interval", "\n", "tSelect_r_n", "=", "tSelect_r_n", ".", "astype", "(", "int", ")", "\n", "return", "tSelect_r_n", "\n", "", "tSelect_r_n", "=", "interv_to_int", "(", "tSelect_r_n", ")", "# shape is [r,n,tSample_1epoch+1], every [_r, _n] dimension, when sumed up along axis 'tSample_1epoch+1', is no more than available_Interval", "\n", "\n", "# the [_r, _n] position means the starting t for this sample of sequence", "\n", "\n", "rn_t_f", "=", "[", "]", "# when t&f are viewed together, this one means to be collection of t_f sequences (along t axis)", "\n", "for", "_r", "in", "range", "(", "r", ")", ":", "\n", "        ", "for", "_n", "in", "range", "(", "n", ")", ":", "\n", "                ", "tSelect", "=", "tSelect_r_n", "[", "_r", ",", "_n", "]", "# a 1-D array of length tSample_1epoch+1, meaning the 'interval', rather than starging point.", "\n", "for", "ith_selection", "in", "range", "(", "tSample_1epoch", ")", ":", "\n", "                    ", "starting_point", "=", "sum", "(", "tSelect", "[", ":", "ith_selection", "+", "1", "]", ")", "+", "SR_memlen", "*", "ith_selection", "\n", "cur_item_t_f", "=", "sr_r_t_n_f", "[", "_r", ",", "starting_point", ":", "starting_point", "+", "SR_memlen", ",", "_n", ",", ":", "]", "# is an 2-D array", "\n", "if", "cur_item_t_f", "[", "SR_memlen", "//", "4", "*", "3", "-", "1", ",", "0", "]", "!=", "0.0", ":", "\n", "# only append items that grad is not 0 at this ramdomly selected location", "\n", "                        ", "rn_t_f", ".", "append", "(", "cur_item_t_f", ")", "\n", "# after for loop, rn_t_f is a 3-D, indexed by [rn, t, f] (somehow transposed)", "\n", "", "", "", "", "rn_t_f", "=", "np", ".", "asarray", "(", "rn_t_f", ")", "\n", "def", "extract_features_labels", "(", "rn_t_f", ")", ":", "\n", "        ", "if", "f", ">", "2", ":", "# RP model, remove original grad feature", "\n", "            ", "rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "", "features_rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", ":", "-", "1", "]", "# 3-D, remove update column", "\n", "_", ",", "N_pre", ",", "_", "=", "features_rn_t_f", ".", "shape", "\n", "rev_idx", "=", "np", ".", "arange", "(", "N_pre", ")", "[", ":", ":", "-", "1", "]", "\n", "features_rn_t_f_rev", "=", "features_rn_t_f", "[", ":", ",", "rev_idx", ",", ":", "]", "\n", "feat_reversed", "=", "features_rn_t_f_rev", ".", "reshape", "(", "[", "-", "1", ",", "SR_memlen", "*", "f_true", "]", ")", "# 2-D array", "\n", "labels_rn_1", "=", "rn_t_f", "[", ":", ",", "-", "1", ",", "-", "1", "]", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "# 1-D array, size = |rn|, reshaped to column", "\n", "SR_Xy_rn_tf", "=", "np", ".", "concatenate", "(", "[", "feat_reversed", ",", "labels_rn_1", "]", ",", "axis", "=", "1", ")", "\n", "return", "SR_Xy_rn_tf", "\n", "", "SR_Xy_rn_tf", "=", "extract_features_labels", "(", "rn_t_f", ")", "\n", "\n", "# at this point, we have a 2-D array, which is exactly the expected shape", "\n", "np", ".", "random", ".", "shuffle", "(", "SR_Xy_rn_tf", ")", "\n", "\n", "desc", "=", "f'#samples={SR_Xy_rn_tf.shape[0]}, #memlen={SR_memlen}, #feat={f_true}'", "\n", "print", "(", "f\"\\n=============\\nPost proc: randomly select time sub-sequences and re-formulate into Xy-samples for SR.\\n\\t Input shape:\\t\\t sr_r_t_n_f.shape = {sr_r_t_n_f.shape}\\n\\t Input samples:\\t r*(tSample_1epoch*Ngroup_zee) = {r}*{tSample_1epoch}*{Ngroup_zee} = {r*tSample_1epoch*Ngroup_zee}\\n\\t SR feature+label dim:\\t\\t SR_memlen*L2O_features = {SR_memlen}*{f_true}={SR_memlen*f_true}\\n\\t which L2O:\\t\\t \\t{args['l2o_net'].name}\\n\\t feature dim is: [1(grad) + {f-2} + 1(update)]\\n\\t Obtained SR_Xy shape:\\t\\t {SR_Xy_rn_tf.shape}\\n\\t However, desired n_sample is:\\t\\t {num_Xyitems_SR}\\n desc:\\n\\t {desc}\\n=============\\n\\n\"", ")", "\n", "return", "SR_Xy_rn_tf", ",", "desc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.comma_paren": [[561, 581], ["enumerate"], "function", ["None"], ["", "def", "comma_paren", "(", "expr", ",", "loc", ")", ":", "\n", "# given string expr, return the position of mathing ')' and the ','", "\n", "# assume expr has fun(A,B) structure after loc", "\n", "    ", "substr", "=", "expr", "[", "loc", ":", "]", "\n", "comma_", "=", "0", "\n", "cnt_left", "=", "0", "\n", "seen", "=", "False", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "expr", "[", "loc", ":", "]", ")", ":", "\n", "        ", "if", "s", "==", "','", ":", "\n", "            ", "comma_", "=", "i", "\n", "", "elif", "s", "==", "'('", ":", "\n", "            ", "cnt_left", "+=", "1", "\n", "seen", "=", "True", "\n", "", "elif", "s", "==", "')'", ":", "\n", "            ", "cnt_left", "-=", "1", "\n", "\n", "", "if", "seen", "and", "cnt_left", "==", "0", ":", "\n", "            ", "paren_", "=", "i", "\n", "break", "\n", "", "", "return", "loc", "+", "comma_", ",", "loc", "+", "paren_", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.find_ith": [[585, 593], ["s.find", "s.find"], "function", ["None"], ["", "def", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", ":", "\n", "    ", "i", "=", "0", "\n", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "# for i in range(ith):", "\n", "while", "i", "<", "ith", "and", "loc", "!=", "-", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ",", "loc", "+", "1", ")", "\n", "i", "+=", "1", "\n", "", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.find_random_subs": [[594, 607], ["s.count", "s.find", "np.random.choice", "stage023_resnet.find_ith"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_ith"], ["", "def", "find_random_subs", "(", "s", ",", "sub", ")", ":", "\n", "# given a string s and a sub string, if sub is a substring of s, then return the location of a randomly selected sub in s (if multiple sub in s)", "\n", "# if sub not present, return -1", "\n", "    ", "cnt", "=", "s", ".", "count", "(", "sub", ")", "\n", "if", "cnt", "==", "0", ":", "# not present", "\n", "        ", "return", "-", "1", "\n", "", "elif", "cnt", "==", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "return", "loc", "\n", "", "else", ":", "\n", "        ", "ith", "=", "np", ".", "random", ".", "choice", "(", "cnt", ")", "\n", "loc", "=", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", "\n", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.mutate_expr": [[620, 632], ["np.random.rand", "add_term", "add_term", "stage023_resnet.mutExpm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.mutExpm"], ["", "", "def", "mutate_expr", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "w", ")", ":", "\n", "    ", "p", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "\n", "if", "'expm'", "in", "expr", ":", "\n", "        ", "probs", "=", "[", "0.3", ",", "1.1", "]", "\n", "if", "p", "<", "probs", "[", "0", "]", ":", "\n", "            ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "elif", "p", "<", "probs", "[", "1", "]", ":", "\n", "            ", "expr", "=", "mutExpm", "(", "expr", ")", "\n", "", "", "else", ":", "\n", "        ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.mutExpm": [[636, 662], ["stage023_resnet.find_expm_a", "float", "stage023_resnet.mutExpm.is_single"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_expm_a"], ["", "def", "mutExpm", "(", "expr", ")", ":", "\n", "    ", "loc", ",", "comma", ",", "paren", "=", "find_expm_a", "(", "expr", ")", "\n", "\n", "before", "=", "expr", "[", ":", "loc", "]", "\n", "after", "=", "expr", "[", "paren", "+", "1", ":", "]", "\n", "part1", "=", "expr", "[", "loc", ":", "comma", "+", "1", "]", "\n", "part3", "=", "expr", "[", "paren", ":", "paren", "+", "1", "]", "# ')'", "\n", "a", "=", "float", "(", "expr", "[", "comma", "+", "1", ":", "paren", "]", ")", "\n", "\n", "def", "is_single", "(", "s", ",", "start", ",", "end", ")", ":", "\n", "# judge if input is completely wraped in '()'", "\n", "        ", "i1", ",", "i2", "=", "start", ",", "end", "\n", "while", "i1", ">=", "0", ":", "\n", "            ", "if", "s", "[", "i1", "]", "==", "' '", ":", "i1", "-=", "1", "\n", "elif", "s", "[", "i1", "]", "!=", "'('", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "while", "i2", "<", "len", "(", "s", ")", ":", "\n", "            ", "if", "s", "[", "i2", "]", "==", "' '", ":", "i2", "+=", "1", "\n", "elif", "s", "[", "i2", "]", "!=", "')'", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "return", "True", "\n", "\n", "", "single", "=", "is_single", "(", "expr", ",", "loc", "-", "1", ",", "paren", "+", "1", ")", "\n", "if", "single", ":", "\n", "        ", "expr", "=", "before", "# -wz", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.find_expm_a": [[667, 691], ["stage023_resnet.find_random_subs", "stage023_resnet.comma_paren"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_random_subs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.comma_paren"], ["", "", "def", "find_expm_a", "(", "expr", ")", ":", "\n", "# given an string expr, find the location and value of the 'a' in x**a.", "\n", "# if multiple results, return an randomly selected one", "\n", "# eg: expr = \"tanh(tanh( coeff_SR[0] + sinh(expm( coeff_SR[1] * mt_0, 3))))\"  then \u203a\u203a a=3", "\n", "    ", "assert", "'expm'", "in", "expr", "\n", "loc", "=", "find_random_subs", "(", "expr", ",", "'expm'", ")", "\n", "comma", ",", "paren", "=", "comma_paren", "(", "expr", ",", "loc", ")", "\n", "\n", "# full_expm = expr[loc:paren+1]", "\n", "# before = expr[:loc]", "\n", "# part1 = expr[loc:comma+1]", "\n", "# a = float(expr[comma+1:paren])", "\n", "# part3 = expr[paren:paren+1]  # ')'", "\n", "# after = expr[paren+1:]", "\n", "\n", "# print(expr)", "\n", "# print(before)", "\n", "# print(part1)", "\n", "# print(a)", "\n", "# print(part3)", "\n", "# print(after)", "\n", "\n", "# raise", "\n", "return", "loc", ",", "comma", ",", "paren", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.plot_sin": [[815, 829], ["np.linspace", "sum", "utils.plot", "plt.title", "range", "stage023_resnet.plot_sin.trm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["def", "plot_sin", "(", ")", ":", "\n", "\n", "    ", "N", "=", "10", "\n", "L", "=", "N", "\n", "\n", "\n", "\n", "def", "trm", "(", "x", ",", "n", ")", ":", "\n", "        ", "return", "(", "-", "1", ")", "**", "(", "(", "n", "-", "1", ")", "//", "2", ")", "*", "1", "/", "np", ".", "math", ".", "factorial", "(", "n", ")", "*", "x", "**", "n", "\n", "", "x", "=", "np", ".", "linspace", "(", "-", "L", ",", "L", ",", "100", ")", "\n", "ords", "=", "[", "2", "*", "i", "+", "1", "for", "i", "in", "range", "(", "N", ")", "]", "\n", "sinx", "=", "sum", "(", "[", "trm", "(", "x", ",", "i", ")", "for", "i", "in", "ords", "]", ")", "\n", "plot", "(", "x", ",", "sinx", ")", "\n", "plt", ".", "title", "(", "f'highest order = {N}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExpVTO_split": [[840, 859], ["None"], "function", ["None"], ["", "def", "genExpVTO_split", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ":", "\n", "# indecies: var,t,io,twin", "\n", "# order = io+1", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "\n", "\n", "    ", "want_twin", "=", "1", "\n", "v2i", "=", "{", "'mt'", ":", "0", ",", "'gt'", ":", "1", ",", "'g'", ":", "2", ",", "'mom5'", ":", "3", "}", "\n", "\n", "\n", "if", "want_twin", ":", "\n", "        ", "iv", "=", "v2i", "[", "vname", "]", "\n", "\n", "thisv", "=", "f'{vname}_{t}'", "\n", "res1", "=", "f'coeff_SR[{iv},{t},{io},0] * expm({thisv}, {io+1}+coeff_SR[{iv},{t},{io},2])'", "\n", "res2", "=", "f'coeff_SR[{iv},{t},{io},1] * expm({thisv}, {io+1}-coeff_SR[{iv},{t},{io},2])'", "\n", "\n", "return", "res1", "+", "' + '", "+", "res2", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExpVTO": [[861, 880], ["None"], "function", ["None"], ["", "", "def", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ":", "\n", "# indecies: var,t,io,twin", "\n", "# order = io+1", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "\n", "\n", "    ", "want_twin", "=", "1", "\n", "v2i", "=", "{", "'mt'", ":", "0", ",", "'gt'", ":", "1", ",", "'g'", ":", "2", ",", "'mom5'", ":", "3", "}", "\n", "\n", "\n", "if", "want_twin", ":", "\n", "        ", "iv", "=", "v2i", "[", "vname", "]", "\n", "\n", "thisv", "=", "f'{vname}_{t}'", "\n", "# res1 = f'coeff_SR[{iv},{t},{io},0] * expm({thisv}, {io+1})'", "\n", "res1", "=", "f'coeff_SR[{iv},{t},{io},0] * {thisv}'", "\n", "\n", "return", "res1", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExp": [[883, 906], ["range", "range", "res.append", "stage023_resnet.genExpVTO"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExpVTO"], ["", "", "def", "genExp", "(", "expr_vname_list", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "expr_vname_list", "=", "[", "'mt'", ",", "'gt'", ",", "'g'", ",", "'mom5'", ",", "]", "\n", "expr_vname_list", "=", "[", "'mt'", ",", "'gt'", ",", "]", "\n", "expr_vname_list", "=", "[", "'mt'", ",", "'g'", ",", "]", "\n", "\n", "\n", "expr_memlen", "=", "2", "\n", "expr_maxOrd", "=", "1", "\n", "\n", "\n", "\n", "for", "vname", "in", "expr_vname_list", ":", "\n", "        ", "for", "t", "in", "range", "(", "expr_memlen", ")", ":", "\n", "            ", "for", "io", "in", "range", "(", "expr_maxOrd", ")", ":", "\n", "                ", "res", ".", "append", "(", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ")", "\n", "\n", "# res = '\\ \\n+'.join(res)", "\n", "# print(res); raise", "\n", "# print(res)", "\n", "# raise", "\n", "", "", "", "res", "=", "'+'", ".", "join", "(", "res", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.do_with_expr": [[912, 959], ["stage023_resnet.do_with_expr.coeff_SR_ini"], "function", ["None"], ["", "def", "do_with_expr", "(", "args", ",", "coeff_SR_dic", "=", "None", ",", "**", "w", ")", ":", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# norm is to devide, denorm is to multiply (var's std)", "\n", "\n", "    ", "def", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "# std: MNIST task:", "\n", "#     mt ~ 0.2", "\n", "#     gt ~ 1.0", "\n", "#     g/mom ~ 0.0005", "\n", "\n", "\n", "\n", "\n", "        ", "coeff_SRNorm", "=", "np", ".", "array", "(", "[", "0.2", ",", "1", ",", "0.0005", ",", "0.0005", "]", ")", "*", "1", "\n", "\n", "k_scalar_ini_abs", "=", "0.001", "\n", "alpha_ini", "=", "0.05", "\n", "assert", "expr_group_len", "==", "3", "\n", "coeff_SR", "=", "np", ".", "zeros", "(", "(", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ")", ")", "\n", "\n", "k_ini", "=", "-", "k_scalar_ini_abs", "**", "(", "np", ".", "arange", "(", "expr_maxOrd", ")", "+", "1", ")", ".", "reshape", "(", "(", "expr_maxOrd", ",", "1", ")", ")", ".", "repeat", "(", "2", ",", "axis", "=", "1", ")", "\n", "coeff_SR", "[", "...", ",", "0", ":", "2", "]", "=", "k_ini", "\n", "coeff_SR", "[", "...", ",", "2", "]", "=", "alpha_ini", "\n", "\n", "if", "coeff_SR_dic", "is", "not", "None", ":", "\n", "            ", "for", "k", ",", "v", "in", "coeff_SR_dic", ".", "items", "(", ")", ":", "\n", "                ", "coeff_SR", "[", "k", "]", "=", "v", "\n", "\n", "\n", "", "", "return", "coeff_SR", ",", "coeff_SRNorm", "\n", "\n", "\n", "", "coeff_SR", ",", "coeff_SRNorm", "=", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "**", "args", ")", "\n", "\n", "\n", "\n", "args", "[", "'expr'", "]", "=", "genExp", "(", "**", "args", ")", "\n", "# print(genExp(**args))", "\n", "# raise", "\n", "\n", "args", "[", "'coeff_SR'", "]", "=", "torch", ".", "tensor", "(", "coeff_SR", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "args", "[", "'coeff_SR'", "]", ".", "requires_grad", "=", "True", "\n", "args", "[", "'coeff_SRNorm'", "]", "=", "torch", ".", "tensor", "(", "coeff_SRNorm", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.run_resnet.use_model": [[27, 46], ["print", "print", "resnet_meta.resnet50.to", "load_model", "resnet_meta.resnet18", "resnet_meta.resnet50"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.load_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet18", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet50"], ["def", "use_model", "(", "net_desc", "=", "'r18'", ",", "cwd", "=", "'No pretrained cwd'", ")", ":", "\n", "    ", "print", "(", "'==> Building model..'", ")", "\n", "\n", "print", "(", "f'\\n\\nUsing: {net_desc}\\n\\n'", ")", "\n", "\n", "if", "net_desc", "==", "'r18'", ":", "\n", "\n", "        ", "net", "=", "resnet_meta", ".", "resnet18", "(", ")", "\n", "\n", "", "elif", "net_desc", "==", "'r50'", ":", "\n", "        ", "net", "=", "resnet_meta", ".", "resnet50", "(", ")", "\n", "\n", "", "net", "=", "net", ".", "to", "(", "DEVICE", ")", "\n", "\n", "\n", "\n", "load_model", "(", "net", ",", "cwd", ")", "\n", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.run_resnet.getArgs": [[53, 93], ["transforms.Compose", "transforms.Compose", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "run_resnet.use_model", "nn.CrossEntropyLoss", "transforms.RandomCrop", "transforms.RandomHorizontalFlip", "transforms.ToTensor", "transforms.Normalize", "transforms.ToTensor", "transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.run_resnet.use_model"], ["", "def", "getArgs", "(", "net_desc", "=", "'r'", ",", "cwd", "=", "'No pretrained cwd'", ")", ":", "\n", "    ", "args", "=", "{", "\n", "'num_workers'", ":", "2", ",", "\n", "'resume'", ":", "0", ",", "\n", "'lr'", ":", "0.1", ",", "\n", "'cwd'", ":", "''", ",", "\n", "'n_epochs'", ":", "200", ",", "\n", "'pin_memory'", ":", "True", ",", "\n", "'criterion'", ":", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "\n", "\n", "}", "\n", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "trainset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "'./datasets'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "trainset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "True", ",", "num_workers", "=", "args", "[", "'num_workers'", "]", ",", "pin_memory", "=", "args", "[", "'pin_memory'", "]", ")", "\n", "\n", "testset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "'./datasets'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transform_test", ")", "\n", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "testset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "args", "[", "'num_workers'", "]", ",", "pin_memory", "=", "args", "[", "'pin_memory'", "]", ")", "\n", "\n", "args", "[", "'trainloader'", "]", "=", "trainloader", "\n", "args", "[", "'testloader'", "]", "=", "testloader", "\n", "args", "[", "'net'", "]", "=", "use_model", "(", "net_desc", ",", "cwd", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.run_resnet.trainNN_zoo": [[97, 153], ["optim.SGD", "torch.optim.lr_scheduler.CosineAnnealingLR", "range", "np.array", "wzRec", "wzRec", "wzRec", "wzRec", "net.parameters", "net.train", "print", "run_resnet.trainNN_zoo.train_1epoch"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["", "def", "trainNN_zoo", "(", "num_workers", "=", "None", ",", "resume", "=", "None", ",", "lr", "=", "None", ",", "cwd", "=", "''", ",", "n_epochs", "=", "None", ",", "trainloader", "=", "None", ",", "testloader", "=", "None", ",", "net", "=", "None", ",", "criterion", "=", "None", ",", "**", "w", ")", ":", "\n", "\n", "    ", "best_acc", "=", "0", "\n", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "net", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "200", ")", "\n", "\n", "def", "train_1epoch", "(", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "if", "CUDA", ":", "\n", "# iterator = enumerate(trainloader) ", "\n", "            ", "iterator", "=", "enumerate", "(", "tqdm", "(", "trainloader", ")", ")", "\n", "", "else", ":", "\n", "            ", "iterator", "=", "enumerate", "(", "tqdm", "(", "trainloader", ")", ")", "\n", "\n", "\n", "", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "iterator", ":", "\n", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "DEVICE", ")", ",", "targets", ".", "to", "(", "DEVICE", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "net", ".", "_forward_impl", "(", "inputs", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "avg_loss", "=", "train_loss", "/", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# if CUDA: progress_bar(batch_idx, len(trainloader), f'Loss: {avg_loss:.3f} | Train Acc: {acc:>5.2f} | lr: {optimizer.param_groups[0][\"lr\"]:.3f}')", "\n", "\n", "", "return", "acc", ",", "avg_loss", "\n", "\n", "", "rec", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "print", "(", "f'\\n\\t Epoch: < {epoch}/{n_epochs} >'", ")", "\n", "train_acc", ",", "train_loss", "=", "train_1epoch", "(", ")", "\n", "# test()", "\n", "test_acc", ",", "best_acc", "=", "eva_net", "(", "net", ",", "testloader", ",", "trainloader", ",", "best_acc", ",", "criterion", ")", "\n", "rec", ".", "append", "(", "[", "train_acc", ",", "train_loss", ",", "test_acc", ",", "best_acc", "]", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "", "rec", "=", "np", ".", "array", "(", "rec", ")", "\n", "wzRec", "(", "rec", "[", ":", ",", "0", "]", ",", "ttl", "=", "'train_acc'", ",", "want_save", "=", "True", ")", "\n", "wzRec", "(", "rec", "[", ":", ",", "1", "]", ",", "ttl", "=", "'train_loss'", ",", "want_save", "=", "True", ")", "\n", "wzRec", "(", "rec", "[", ":", ",", "2", "]", ",", "ttl", "=", "'test_acc'", ",", "want_save", "=", "True", ")", "\n", "wzRec", "(", "rec", "[", ":", ",", "3", "]", ",", "ttl", "=", "'best_acc'", ",", "want_save", "=", "True", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.run_resnet.eva_net": [[159, 194], ["torch.no_grad", "net.eval", "enumerate", "print", "tqdm", "net._forward_impl", "criterion", "criterion.item", "net._forward_impl.max", "targets.size", "predicted.eq().sum().item", "save_model", "inputs.to", "targets.to", "predicted.eq().sum", "net._get_name", "predicted.eq"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._forward_impl", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "eva_net", "(", "net", ",", "testloader", ",", "trainloader", ",", "best_acc", "=", "101.", ",", "criterion", "=", "None", ",", "**", "w", ")", ":", "\n", "# nonlocal best_acc", "\n", "\n", "\n", "# testloader = trainloader", "\n", "\n", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "tqdm", "(", "testloader", ")", ")", ":", "\n", "        ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "DEVICE", ")", ",", "targets", ".", "to", "(", "DEVICE", ")", "\n", "outputs", "=", "net", ".", "_forward_impl", "(", "inputs", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "avg_loss", "=", "test_loss", "/", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# progress_bar(batch_idx, len(testloader), f'Loss: {avg_loss:.3f} | Test Acc: {acc:>5.2f}')", "\n", "", "desc", "=", "f'\\n\\n  Final test acc is:  {acc:.2f}\\n  avg_loss is: {avg_loss} \\n'", "\n", "print", "(", "desc", ")", "\n", "net", ".", "test_acc", "=", "acc", "\n", "if", "acc", ">", "best_acc", ":", "\n", "        ", "save_model", "(", "net", ",", "f'./wz_saved_models/{net._get_name()}.pth'", ")", "\n", "best_acc", "=", "acc", "\n", "net", ".", "best_acc", "=", "best_acc", "\n", "\n", "", "return", "acc", ",", "best_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.LUM.__init__": [[163, 181], ["torch.Module.__init__", "MLP", "OneHotEncoder", "numpy.arange().reshape", "enc.fit.fit.fit", "enc.fit.fit.transform", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["  ", "\"\"\"Creates the optimizer networks.\n\n  Args:\n    variables: A list of variables to be optimized.\n    config: A dictionary of network configurations, each of which will be\n        passed to networks.Factory to construct a single optimizer net.\n    net_assignments: A list of tuples where each tuple is of the form (netid,\n        variable_names) and is used to assign variables to networks. netid must\n        be a key in config.\n\n  Returns:\n    A tuple (nets, keys, subsets) where nets is a dictionary of created\n    optimizer nets such that the net with key keys[i] should be applied to the\n    subset of variables listed in subsets[i].\n\n  Raises:\n    ValueError: If net_assignments is None and the configuration defines more\n        than one network.\n  \"\"\"", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.LUM.forward": [[182, 191], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "meta.LUM.mlp().flatten", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "meta.LUM.mlp"], "methods", ["None"], ["# create a dictionary which maps a variable name to its index within the", "\n", "# list of variables.", "\n", "name_to_index", "=", "dict", "(", "(", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ",", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "variables", ")", ")", "\n", "\n", "if", "net_assignments", "is", "None", ":", "\n", "    ", "if", "len", "(", "config", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Default net_assignments can only be used if there is \"", "\n", "\"a single net config.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.__init__": [[579, 627], ["torch.Module.__init__", "hidden_layers_zer.copy", "len", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "grad_features.split", "len", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "print", "len", "print", "nn_list.extend", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "meta.RPOptimizer.recurs.append", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "max", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ELU", "torch.ELU", "torch.ELU", "torch.ELU", "torch.ELU", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.reset": [[629, 668], ["enumerate", "enumerate", "numpy.prod", "meta.RPOptimizer.layer_wise_n_neuron.append", "int", "meta.RPOptimizer.mt.append", "meta.RPOptimizer.vt.append", "sets.append", "numpy.prod", "meta.RPOptimizer.layer_wise_n_neuron.append", "int", "meta.RPOptimizer.mt.append", "range", "sets.append", "p.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "meta.RPOptimizer.mom5.append", "meta.RPOptimizer.mom9.append", "meta.RPOptimizer.mom99.append", "range", "p.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "len", "meta.RPOptimizer.vt[].append", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "len", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.grad2features": [[669, 753], ["meta.detach_var", "range", "meta.detach_var", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "tensors_to_cat.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mt_tilde.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.tensor().repeat", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.forward": [[756, 776], ["meta.RPOptimizer.grad2features", "torch.tanh.detach().cpu().data.numpy", "torch.tanh.detach().cpu().data.numpy", "torch.tanh.detach().cpu().data.numpy", "torch.tanh.detach().cpu().data.numpy", "torch.tanh.detach().cpu().data.numpy", "meta.RPOptimizer.preprocNet", "range", "new_hidden.append", "new_cell.append", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "meta.RPOptimizer.output", "torch.tanh.detach().cpu", "torch.tanh.detach().cpu", "torch.tanh.detach().cpu", "torch.tanh.detach().cpu", "torch.tanh.detach().cpu", "meta.RPOptimizer.output", "torch.tanh.detach", "torch.tanh.detach", "torch.tanh.detach", "torch.tanh.detach", "torch.tanh.detach"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.grad2features", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.argsPrinter": [[50, 137], ["OPT", "print", "os.getpid", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "args.get", "Target_Optimizee", "Target_Optimizee", "Target_Optimizee"], "function", ["None"], ["    ", "if", "len", "(", "ref", ")", "!=", "len", "(", "value", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"ref and value have different lengths.\"", ")", "\n", "", "result", "=", "[", "_nested_assign", "(", "r", ",", "v", ")", "for", "r", ",", "v", "in", "zip", "(", "ref", ",", "value", ")", "]", "\n", "if", "isinstance", "(", "ref", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "assign", "(", "ref", ",", "value", ")", "\n", "\n", "\n", "", "", "def", "_nested_variable", "(", "init", ",", "name", "=", "None", ",", "trainable", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a nested collection of TensorFlow variables.\n\n  Args:\n    init: Nested collection of TensorFlow initializers.\n    name: Variable name.\n    trainable: Make variables trainable (`False` by default).\n\n  Returns:\n    Nested collection (same structure as `init`) of TensorFlow variables.\n  \"\"\"", "\n", "if", "isinstance", "(", "init", ",", "list", ")", "or", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "[", "_nested_variable", "(", "i", ",", "name", ",", "trainable", ")", "for", "i", "in", "init", "]", "\n", "if", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "result", ")", "\n", "", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "Variable", "(", "init", ",", "name", "=", "name", ",", "trainable", "=", "trainable", ")", "\n", "\n", "\n", "", "", "def", "_nested_tuple", "(", "elems", ")", ":", "\n", "  ", "if", "isinstance", "(", "elems", ",", "list", ")", "or", "isinstance", "(", "elems", ",", "tuple", ")", ":", "\n", "    ", "result", "=", "tuple", "(", "[", "_nested_tuple", "(", "x", ")", "for", "x", "in", "elems", "]", ")", "\n", "return", "result", "\n", "", "else", ":", "\n", "    ", "return", "elems", "\n", "\n", "\n", "", "", "def", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", ":", "\n", "  ", "\"\"\"Provides a custom getter for all variable creations.\"\"\"", "\n", "original_get_variable", "=", "tf", ".", "get_variable", "\n", "def", "custom_get_variable", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "hasattr", "(", "kwargs", ",", "\"custom_getter\"", ")", ":", "\n", "      ", "raise", "AttributeError", "(", "\"Custom getters are not supported for optimizee \"", "\n", "\"variables.\"", ")", "\n", "", "return", "original_get_variable", "(", "*", "args", ",", "custom_getter", "=", "custom_getter", ",", "**", "kwargs", ")", "\n", "\n", "# Mock the get_variable method.", "\n", "", "with", "mock", ".", "patch", "(", "\"tensorflow.get_variable\"", ",", "custom_get_variable", ")", ":", "\n", "    ", "return", "func", "(", ")", "\n", "\n", "\n", "", "", "def", "_get_variables", "(", "func", ")", ":", "\n", "  ", "\"\"\"Calls func, returning any variables created, but ignoring its return value.\n\n  Args:\n    func: Function to be called.\n\n  Returns:\n    A tuple (variables, constants) where the first element is a list of\n    trainable variables and the second is the non-trainable variables.\n  \"\"\"", "\n", "variables", "=", "[", "]", "\n", "constants", "=", "[", "]", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "trainable", "=", "kwargs", "[", "\"trainable\"", "]", "\n", "kwargs", "[", "\"trainable\"", "]", "=", "False", "\n", "variable", "=", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "if", "trainable", ":", "\n", "      ", "variables", ".", "append", "(", "variable", ")", "\n", "", "else", ":", "\n", "      ", "constants", ".", "append", "(", "variable", ")", "\n", "", "return", "variable", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"unused_graph\"", ")", ":", "\n", "    ", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n", "\n", "", "return", "variables", ",", "constants", "\n", "\n", "\n", "", "def", "_make_with_custom_variables", "(", "func", ",", "variables", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.fit_optimizer_from_scratch": [[140, 155], ["OPT().to", "kwargs.get", "kwargs.get", "torch.Adam", "meta.train_optimizer", "itertools.chain", "OPT().to.parameters", "itertools.chain", "OPT", "OPT().to.parameters", "kwargs[].parameters"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.train_optimizer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["\n", "variables", "=", "collections", ".", "deque", "(", "variables", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "name", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "[", "\"trainable\"", "]", ":", "\n", "      ", "return", "variables", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "      ", "kwargs", "[", "\"reuse\"", "]", "=", "True", "\n", "return", "getter", "(", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "_wrap_variable_creation", "(", "func", ",", "custom_getter", ")", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.normal_train": [[194, 226], ["Target_DataGen", "Target_Optimizee", "OPT_normal_train", "tqdm.tqdm", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "Target_Optimizee.parameters", "range", "OPT_normal_train.zero_grad", "Target_Optimizee.", "net.backward", "OPT_normal_train.step", "Target_Optimizee.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "Target_Optimizee.state_dict"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["kwargs", "=", "config", "[", "key", "]", "\n", "net", "=", "networks", ".", "factory", "(", "**", "kwargs", ")", "\n", "\n", "", "nets", "=", "{", "key", ":", "net", "}", "\n", "keys", "=", "[", "key", "]", "\n", "subsets", "=", "[", "range", "(", "len", "(", "variables", ")", ")", "]", "\n", "", "else", ":", "\n", "    ", "nets", "=", "{", "}", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"vars_optimizer\"", ")", ":", "\n", "      ", "for", "key", ",", "names", "in", "net_assignments", ":", "\n", "        ", "if", "key", "in", "nets", ":", "\n", "          ", "raise", "ValueError", "(", "\"Repeated netid in net_assigments.\"", ")", "\n", "", "nets", "[", "key", "]", "=", "networks", ".", "factory", "(", "**", "config", "[", "key", "]", ")", "\n", "subset", "=", "[", "name_to_index", "[", "name", "]", "for", "name", "in", "names", "]", "\n", "keys", ".", "append", "(", "key", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "print", "(", "\"Net: {}, Subset: {}\"", ".", "format", "(", "key", ",", "subset", ")", ")", "\n", "\n", "# subsets should be a list of disjoint subsets (as lists!) of the variables", "\n", "# and nets should be a list of networks to apply to each subset.", "\n", "", "", "", "return", "nets", ",", "keys", ",", "subsets", "\n", "\n", "\n", "", "class", "MetaOptimizer", "(", "object", ")", ":", "\n", "  ", "\"\"\"Learning to learn (meta) optimizer.\n\n  Optimizer which has an internal RNN which takes as input, at each iteration,\n  the gradient of the function being minimized and returns a step direction.\n  This optimizer can then itself be optimized to learn optimization on a set of\n  tasks.\n  \"\"\"", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.train_optimizer": [[231, 280], ["meta.argsPrinter", "tqdm.tqdm", "meta.save_model", "kwargs.get", "float", "range", "time.time", "meta.run_epoch", "time.time", "meta.wzRec", "time.time", "copy.deepcopy", "kwargs.get", "OPT().to", "OPT().to.load_state_dict", "kwargs.get", "meta.save_model", "kwargs.get", "meta.save_model", "kwargs.get", "meta.eva_l2o_optimizer", "print", "OPT().to.state_dict", "copy.deepcopy", "kwargs[].load_state_dict", "Target_Optimizee", "meta.save_model", "meta.eva_l2o_optimizer", "copy.deepcopy", "kwargs.get", "kwargs[].state_dict", "OPT", "OPT().to.state_dict", "copy.deepcopy", "kwargs[].state_dict"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.argsPrinter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.eva_l2o_optimizer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.eva_l2o_optimizer"], ["\n", "self", ".", "_nets", "=", "None", "\n", "\n", "if", "not", "kwargs", ":", "\n", "# Use a default coordinatewise network if nothing is given. this allows", "\n", "# for no network spec and no assignments.", "\n", "      ", "self", ".", "_config", "=", "{", "\n", "\"coordinatewise\"", ":", "{", "\n", "\"net\"", ":", "\"CoordinateWiseDeepLSTM\"", ",", "\n", "\"net_options\"", ":", "{", "\n", "\"layers\"", ":", "(", "20", ",", "20", ")", ",", "\n", "\"preprocess_name\"", ":", "\"LogAndSign\"", ",", "\n", "\"preprocess_options\"", ":", "{", "\"k\"", ":", "5", "}", ",", "\n", "\"scale\"", ":", "0.01", ",", "\n", "}", "}", "}", "\n", "", "else", ":", "\n", "      ", "self", ".", "_config", "=", "kwargs", "\n", "\n", "", "", "def", "save", "(", "self", ",", "sess", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save meta-optimizer.\"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "net", "in", "self", ".", "_nets", ".", "items", "(", ")", ":", "\n", "      ", "if", "path", "is", "None", ":", "\n", "        ", "filename", "=", "None", "\n", "key", "=", "k", "\n", "", "else", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.l2l\"", ".", "format", "(", "k", ")", ")", "\n", "key", "=", "filename", "\n", "", "net_vars", "=", "networks", ".", "save", "(", "net", ",", "sess", ",", "filename", "=", "filename", ")", "\n", "result", "[", "key", "]", "=", "net_vars", "\n", "", "return", "result", "\n", "\n", "", "def", "meta_loss", "(", "self", ",", "\n", "make_loss", ",", "\n", "len_unroll", ",", "\n", "net_assignments", "=", "None", ",", "\n", "second_derivatives", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.eva_l2o_traditional": [[286, 302], ["meta.argsPrinter", "numpy.asarray", "numpy.save", "meta.wzRec", "print", "meta.run_epoch_traditional", "tqdm.tqdm", "range"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.argsPrinter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch_traditional"], ["\n", "\n", "# Construct an instance of the problem only to grab the variables. This", "\n", "# loss will never be evaluated.", "\n", "# pdb.set_trace()", "\n", "\n", "x", ",", "constants", "=", "_get_variables", "(", "make_loss", ")", "\n", "\n", "print", "(", "\"Optimizee variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "x", "]", ")", "\n", "print", "(", "\"Problem variables\"", ")", "\n", "print", "(", "[", "op", ".", "name", "for", "op", "in", "constants", "]", ")", "\n", "\n", "# Create the optimizer networks and find the subsets of variables to assign", "\n", "# to each optimizer.", "\n", "nets", ",", "net_keys", ",", "subsets", "=", "_make_nets", "(", "x", ",", "self", ".", "_config", ",", "net_assignments", ")", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch_traditional": [[304, 349], ["Target_DataGen", "Target_Optimizee().to", "print", "print", "tqdm.tqdm", "meta.wIni", "torch.Adam", "range", "Target_Optimizee().to.", "losses_1epoch.append", "optimizee.backward", "optim.SGD.step", "Target_Optimizee", "Target_Optimizee().to.parameters", "torch.SGD", "optimizee.data.cpu().numpy", "Target_Optimizee().to.parameters", "optimizee.data.cpu"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["print", "(", "'subsets'", ",", "subsets", ")", "\n", "# Store the networks so we can save them later.", "\n", "self", ".", "_nets", "=", "nets", "\n", "\n", "# Create hidden state for each subset of variables.", "\n", "state", "=", "[", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"states\"", ")", ":", "\n", "      ", "for", "i", ",", "(", "subset", ",", "key", ")", "in", "enumerate", "(", "zip", "(", "subsets", ",", "net_keys", ")", ")", ":", "\n", "        ", "net", "=", "nets", "[", "key", "]", "\n", "with", "tf", ".", "name_scope", "(", "\"state_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "          ", "state", ".", "append", "(", "_nested_variable", "(", "\n", "[", "net", ".", "initial_state_for_inputs", "(", "x", "[", "j", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "j", "in", "subset", "]", ",", "\n", "name", "=", "\"state\"", ",", "trainable", "=", "False", ")", ")", "\n", "", "", "", "print", "(", "state", ")", "\n", "def", "update", "(", "net", ",", "fx", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"Parameter and RNN state update.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"gradients\"", ")", ":", "\n", "        ", "gradients", "=", "tf", ".", "gradients", "(", "fx", ",", "x", ")", "\n", "\n", "# Stopping the gradient here corresponds to what was done in the", "\n", "# original L2L NIPS submission. However it looks like things like", "\n", "# BatchNorm, etc. don't support second-derivatives so we still need", "\n", "# this term.", "\n", "if", "not", "second_derivatives", ":", "\n", "          ", "gradients", "=", "[", "tf", ".", "stop_gradient", "(", "g", ")", "for", "g", "in", "gradients", "]", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", ",", "state_next", "=", "zip", "(", "*", "[", "net", "(", "g", ",", "s", ")", "for", "g", ",", "s", "in", "zip", "(", "gradients", ",", "state", ")", "]", ")", "\n", "state_next", "=", "_nested_tuple", "(", "state_next", ")", "\n", "state_next", "=", "list", "(", "state_next", ")", "\n", "\n", "", "return", "deltas", ",", "state_next", "\n", "\n", "", "def", "time_step", "(", "t", ",", "fx_array", ",", "x", ",", "state", ")", ":", "\n", "      ", "\"\"\"While loop body.\"\"\"", "\n", "x_next", "=", "list", "(", "x", ")", "\n", "state_next", "=", "[", "]", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "        ", "fx", "=", "_make_with_custom_variables", "(", "make_loss", ",", "x", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "t", ",", "fx", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"dx\"", ")", ":", "\n", "        ", "for", "subset", ",", "key", ",", "s_i", "in", "zip", "(", "subsets", ",", "net_keys", ",", "state", ")", ":", "\n", "          ", "x_i", "=", "[", "x", "[", "j", "]", "for", "j", "in", "subset", "]", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch": [[358, 518], ["time.time", "kwargs.get", "Target_DataGen", "Target_Optimizee().to", "l2o_net.reset", "time.time", "numpy.asarray", "l2o_net.train", "l2o_net.eval", "meta.load_model", "meta.wIni", "Target_Optimizee().to.parameters", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "meta_opt.zero_grad", "range", "tqdm.tqdm", "kwargs.get", "l3.append", "Target_Optimizee().to.", "l4.append", "losses_1epoch.append", "l5.append", "optimizee.backward", "l6.append", "l7.append", "enumerate", "l8.append", "sr_t_n_f.reshape.append", "sr_t_n_f.reshape.reshape", "kwargs.get.train", "kwargs.get.eval", "Target_Optimizee", "range", "range", "range", "numpy.random.choice", "Target_Optimizee().to.named_parameters", "Target_Optimizee().to.load_state_dict", "time.time", "time.time", "optimizee.data.cpu().numpy", "time.time", "time.time", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "kwargs.get.", "time.time", "Target_Optimizee().to.named_parameters", "int", "meta.detach_var", "l2o_net", "range", "result_params[].retain_grad", "time.time", "l9.append", "l10.append", "Target_Optimizee().to", "meta.wIni", "Target_Optimizee().to.load_state_dict", "Target_Optimizee().to.zero_grad", "l11.append", "l12.append", "Target_Optimizee().to.named_parameters", "len", "l13.append", "torch.autograd.Variable", "torch.autograd.Variable", "range", "range", "numpy.prod", "p.grad.view", "float", "gradients[].detach().cpu().data.numpy", "updates[].detach().cpu().data.numpy", "len", "len", "updates.view", "time.time", "meta_opt.zero_grad", "Target_Optimizee().to.", "all_losses.backward", "meta_opt.step", "time.time", "meta.detach_var", "meta.detach_var", "time.time", "time.time", "meta.rsetattr", "list", "time.time", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "optimizee.data.cpu", "torch.autograd.Variable", "torch.autograd.Variable", "p.size", "sr_nf.append", "sr_nf.append", "Target_Optimizee", "Target_Optimizee().to.named_parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.concatenate", "numpy.concatenate", "p.size", "gradients[].detach().cpu", "updates[].detach().cpu", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "gradients[].detach", "updates[].detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.reset", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.load_model", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters"], ["\n", "", "return", "t_next", ",", "fx_array", ",", "x_next", ",", "state_next", "\n", "\n", "# Define the while loop.", "\n", "", "fx_array", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "size", "=", "len_unroll", "+", "1", ",", "\n", "clear_after_read", "=", "False", ")", "\n", "_", ",", "fx_array", ",", "x_final", ",", "s_final", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "t", ",", "*", "_", ":", "t", "<", "len_unroll", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "(", "0", ",", "fx_array", ",", "x", ",", "state", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "\"unroll\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"fx\"", ")", ":", "\n", "      ", "fx_final", "=", "_make_with_custom_variables", "(", "make_loss", ",", "x_final", ")", "\n", "fx_array", "=", "fx_array", ".", "write", "(", "len_unroll", ",", "fx_final", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "fx_array", ".", "stack", "(", ")", ",", "name", "=", "\"loss\"", ")", "\n", "\n", "# Reset the state; should be called at the beginning of an epoch.", "\n", "with", "tf", ".", "name_scope", "(", "\"reset\"", ")", ":", "\n", "      ", "variables", "=", "(", "nest", ".", "flatten", "(", "state", ")", "+", "\n", "x", "+", "constants", ")", "\n", "# Empty array as part of the reset process.", "\n", "reset", "=", "[", "tf", ".", "variables_initializer", "(", "variables", ")", ",", "fx_array", ".", "close", "(", ")", "]", "\n", "\n", "# Operator to update the parameters and the RNN state after our loop, but", "\n", "# during an epoch.", "\n", "", "with", "tf", ".", "name_scope", "(", "\"update\"", ")", ":", "\n", "      ", "update", "=", "(", "nest", ".", "flatten", "(", "_nested_assign", "(", "x", ",", "x_final", ")", ")", "+", "\n", "nest", ".", "flatten", "(", "_nested_assign", "(", "state", ",", "s_final", ")", ")", ")", "\n", "\n", "# Log internal variables.", "\n", "", "for", "k", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "      ", "print", "(", "\"Optimizer '{}' variables\"", ".", "format", "(", "k", ")", ")", "\n", "print", "(", "[", "op", "for", "op", "in", "snt", ".", "get_variables_in_module", "(", "net", ")", "]", ")", "\n", "\n", "", "return", "MetaLoss", "(", "loss", ",", "update", ",", "reset", ",", "fx_final", ",", "x_final", ")", "\n", "\n", "", "def", "meta_minimize", "(", "self", ",", "make_loss", ",", "len_unroll", ",", "learning_rate", "=", "0.01", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Returns an operator minimizing the meta-loss.\n\n    Args:\n      make_loss: Callable which returns the optimizee loss; note that this\n          should create its ops in the default graph.\n      len_unroll: Number of steps to unroll.\n      learning_rate: Learning rate for the Adam optimizer.\n      **kwargs: keyword arguments forwarded to meta_loss.\n\n    Returns:\n      namedtuple containing (step, update, reset, fx, x)\n    \"\"\"", "\n", "info", "=", "self", ".", "meta_loss", "(", "make_loss", ",", "len_unroll", ",", "**", "kwargs", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "step", "=", "optimizer", ".", "minimize", "(", "info", ".", "loss", ")", "\n", "return", "MetaStep", "(", "step", ",", "*", "info", "[", "1", ":", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.eva_l2o_optimizer": [[520, 539], ["meta.argsPrinter", "zip", "numpy.asarray", "numpy.asarray", "numpy.mean", "numpy.mean", "meta.wzRec", "print", "meta.run_epoch", "numpy.sum", "print", "tqdm.tqdm", "range"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.argsPrinter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.run_epoch"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec": [[541, 574], ["numpy.asarray", "matplotlib.close", "matplotlib.figure", "time.strftime", "time.time.strftime", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.show", "os.makedirs", "numpy.save", "len", "min", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "time.localtime", "time.time.localtime", "len", "numpy.min", "numpy.mean", "numpy.std", "meta.plot_ci", "ValueError"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.plot_ci"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni": [[784, 791], ["net.state_dict", "net.state_dict.items", "net.load_state_dict", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var": [[792, 796], ["torch.autograd.Variable().to", "Variable().to.retain_grad", "torch.autograd.Variable"], "function", ["None"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.new_detached_var": [[797, 801], ["torch.autograd.Variable().to", "Variable().to.retain_grad", "torch.autograd.Variable"], "function", ["None"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr": [[803, 806], ["attr.rpartition", "setattr", "meta.rgetattr"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rgetattr"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rgetattr": [[807, 811], ["functools.reduce", "getattr", "attr.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.updateDict_skip_running": [[815, 823], ["net.state_dict().items", "dic.update", "net.load_state_dict", "net.state_dict"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.getMLP": [[827, 838], ["range", "nn_list.append", "torch.Sequential", "len", "nn_list.extend", "torch.Linear", "torch.Linear", "activation"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.load_model": [[841, 850], ["os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "network.load_state_dict", "meta.load_model.load_torch_file"], "function", ["None"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.save_model": [[851, 854], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "net.state_dict"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.plot_ci": [[857, 887], ["numpy.asarray", "numpy.mean", "matplotlib.fill_between", "matplotlib.xlabel", "matplotlib.ylabel", "list", "matplotlib.title", "len", "arr.reshape.reshape", "matplotlib.get_cmap", "numpy.random.rand", "numpy.std", "numpy.min", "numpy.max", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.arange", "matplotlib.semilogy", "matplotlib.plot", "matplotlib.xticks", "len"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], []], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.pow": [[18, 20], ["Pow"], "function", ["None"], ["def", "pow", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "Pow", "(", "x", ",", "y", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.plus": [[20, 22], ["Add"], "function", ["None"], ["", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "Add", "(", "x", ",", "y", ")", "\n", "", "def", "mult", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.mult": [[22, 24], ["Mul"], "function", ["None"], ["", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "Mul", "(", "x", ",", "y", ")", "\n", "", "def", "square", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.square": [[24, 26], ["None"], "function", ["None"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "2", "\n", "", "def", "relu", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.relu": [[38, 40], ["tanh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "def", "relu", "(", "x", ")", ":", "\n", "    ", "return", "tanh", "(", "x", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.greater": [[28, 30], ["None"], "function", ["None"], ["", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "None", "\n", "", "def", "cube", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.cube": [[30, 32], ["None"], "function", ["None"], ["", "def", "cube", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "3", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.div": [[32, 34], ["None"], "function", ["None"], ["", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "/", "y", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.sqrtm": [[34, 36], ["sqrt"], "function", ["None"], ["", "def", "sqrtm", "(", "x", ")", ":", "\n", "    ", "return", "sqrt", "(", "x", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.logm": [[36, 38], ["log"], "function", ["None"], ["", "def", "logm", "(", "x", ")", ":", "\n", "    ", "return", "log", "(", "x", ")", "\n", "", "def", "relu", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.sr_test_get_latex.orig_expr_2_shortened_latex": [[56, 94], ["print", "sympy.latex", "sr_test_get_latex.orig_expr_2_shortened_latex._shorten"], "function", ["None"], ["", "", "def", "orig_expr_2_shortened_latex", "(", "expr", ")", ":", "\n", "\n", "\n", "\n", "    ", "print", "(", "'begin simplify...'", ")", "\n", "# mm = simplify(expr)", "\n", "# print(mm)", "\n", "# print(printing.latex(mm))", "\n", "\n", "latex_print", "=", "printing", ".", "latex", "(", "expr", ")", "\n", "\n", "\n", "def", "_shorten", "(", "mystr", ")", ":", "\n", "        ", "def", "find_nums", "(", "mystr", ")", ":", "\n", "            ", "import", "re", "\n", "return", "re", ".", "findall", "(", "r\"\\d+\\.\\d*\"", ",", "mystr", ")", "\n", "", "def", "replace_with", "(", "mystr", ",", "num1", ",", "num2", ")", ":", "\n", "            ", "list_", "=", "mystr", ".", "split", "(", "num1", ")", "\n", "return", "num2", ".", "join", "(", "list_", ")", "\n", "", "def", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "num1_list", ")", ")", ":", "\n", "                ", "mystr", "=", "replace_with", "(", "mystr", ",", "num1_list", "[", "i", "]", ",", "num2_list", "[", "i", "]", ")", "\n", "", "return", "mystr", "\n", "", "def", "cut_short", "(", "num1_list", ")", ":", "\n", "            ", "num2_list", "=", "[", "]", "\n", "for", "num1", "in", "num1_list", ":", "\n", "                ", "num2_list", ".", "append", "(", "num1", "[", ":", "4", "]", ")", "\n", "", "return", "num2_list", "\n", "", "print", "(", "'\\n\\norig:\\n\\n'", ",", "mystr", ")", "\n", "num1_list", "=", "find_nums", "(", "mystr", ")", "\n", "num2_list", "=", "cut_short", "(", "num1_list", ")", "\n", "mystr_short", "=", "replace_all_num", "(", "mystr", ",", "num1_list", ",", "num2_list", ")", "\n", "print", "(", "'\\n\\ncutted short:\\n\\n'", ",", "mystr_short", ")", "\n", "print", "(", "'\\n\\n'", ")", "\n", "return", "mystr_short", "\n", "\n", "", "shortened_latex", "=", "_shorten", "(", "latex_print", ")", "\n", "return", "shortened_latex", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.History_Collector.__init__": [[153, 157], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "SR_memlen", ",", "Ngroup_zee", ")", ":", "\n", "        ", "self", ".", "SR_memlen", "=", "SR_memlen", "\n", "self", ".", "Ngroup_zee", "=", "Ngroup_zee", "\n", "self", ".", "past_mems", "=", "[", "]", "\n", "", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.History_Collector.__call__": [[157, 188], ["stage023_autopt.History_Collector.past_mems[].insert", "torch.cat", "stage023_autopt.History_Collector.past_mems.append", "meta.new_detached_var", "torch.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.insert", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.new_detached_var"], ["", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n", "# gfeat shape:      [nNeu_thisLayer, Ngf]", "\n", "# output shape:     [nNeu_thisLayer, N_tf = SR_memlen * Ngf]", "\n", "\n", "        ", "assert", "i_step", ">=", "1", "\n", "if", "i_step", "==", "1", ":", "# i_step is in range(1, run_epoch_len + 1)", "\n", "            ", "self", ".", "past_mems", ".", "append", "(", "None", ")", "\n", "self", ".", "past_mems", "[", "i_group", "]", "=", "[", "new_detached_var", "(", "torch", ".", "zeros", "(", "*", "gfeat", ".", "shape", ",", "device", "=", "DEVICE", ")", ")", "for", "_", "in", "range", "(", "self", ".", "SR_memlen", ")", "]", "\n", "\n", "# del self.past_mems[i_group][0]", "\n", "# self.past_mems[i_group].append(gfeat)", "\n", "", "del", "self", ".", "past_mems", "[", "i_group", "]", "[", "-", "1", "]", "\n", "self", ".", "past_mems", "[", "i_group", "]", ".", "insert", "(", "0", ",", "gfeat", ")", "\n", "\n", "res", "=", "torch", ".", "cat", "(", "self", ".", "past_mems", "[", "i_group", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "# # inspect stats", "\n", "# # MNIST problem: std:", "\n", "# #     mt ~ 0.2", "\n", "# #     gt ~ 1.0", "\n", "# #     g/mom ~ 0.0005", "\n", "# if i_step>self.SR_memlen:", "\n", "#     for i_group in range(len(self.past_mems)):", "\n", "#         ntf = torch.stack(self.past_mems[i_group], dim=1)  # shape = [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "#         calStat_thisLayer(ntf)", "\n", "#     raise", "\n", "\n", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.SRDataset.__init__": [[354, 360], ["SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "which_SR_dataset", ")", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "# data = np.load(SR_dataset_fname)", "\n", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "self", ".", "X", "=", "torch", ".", "tensor", "(", "Xy_fit", ",", "device", "=", "DEVICE", ")", "\n", "self", ".", "N", "=", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.SRDataset.__getitem__": [[361, 364], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "X", "[", "index", "]", "\n", "return", "x", "[", ":", "-", "1", "]", ",", "x", "[", "-", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.SRDataset.__len__": [[365, 367], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.sr_fun_tensor": [[23, 150], ["input_b_tf.reshape", "eval", "eval.reshape", "torch.relu", "torch.sin", "torch.sin", "torch.sign", "torch.tanh", "torch.exp", "abs", "torch.real", "torch.erfc", "torch.sqrt", "torch.log", "torch.sinh", "torch.asinh", "torch.sign", "torch.sign", "torch.pow", "abs", "abs", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow"], ["def", "sr_fun_tensor", "(", "input_b_tf", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ",", "expr_Nvar", ",", "expr", "=", "''", ",", "coeff_SRNorm", "=", "None", ",", "**", "w", ")", ":", "\n", "# the SR function predicts the LSTM output, which is NOT multiplied by 0.01", "\n", "# lum is never used in sr study.", "\n", "# any input/output re-scale must be done simultaneously in TWO places:", "\n", "# 1. the sr_prep2, just before outputing results.", "\n", "# 2. this function, just before outputing results.", "\n", "# I/O is a group (batch) ", "\n", "# input shape:      [batch_size, N_tf]", "\n", "# output shape:     [batch_size, 1]", "\n", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# coeff_SRNorm:     [expr_Nvar,]", "\n", "\n", "\n", "# btf: [batch_size, SR_memlen, Ngf]", "\n", "# output tensor is 2-D, shape is [batch_size, 1]", "\n", "\n", "    ", "btf", "=", "input_b_tf", ".", "reshape", "(", "-", "1", ",", "SR_memlen", ",", "Ngf", ")", "\n", "\n", "if", "coeff_SRNorm", "is", "not", "None", ":", "\n", "        ", "assert", "Ngf", "==", "expr_Nvar", "\n", "btf", "/=", "coeff_SRNorm", "\n", "\n", "\n", "\n", "\n", "", "def", "expm", "(", "x", ",", "a", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "abs", "(", "x", ")", "**", "a", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n", "        ", "return", "F", ".", "relu", "(", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "(", "x", ">", "y", ")", ".", "float", "(", ")", "\n", "", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "torch", ".", "pow", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n", "        ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sqrt", "(", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "abs", "(", "x", ")", "+", "1e-7", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "asinh", "(", "x", ")", "\n", "\n", "\n", "\n", "# ==== applicable to genEmpExp_April ====", "\n", "# try:", "\n", "\n", "#     mt_0 = btf[:,0,0]", "\n", "#     mt_1 = btf[:,1,0]", "\n", "#     mt_2 = btf[:,2,0]", "\n", "#     mt_3 = btf[:,3,0]", "\n", "#     mt_4 = btf[:,4,0]", "\n", "#     mt_5 = btf[:,5,0]", "\n", "\n", "# except IndexError:", "\n", "#     pass", "\n", "\n", "\n", "# gt_0 = btf[:,0,1] ", "\n", "# gt_1 = btf[:,1,1]", "\n", "# gt_2 = btf[:,2,1]", "\n", "# gt_3 = btf[:,3,1]", "\n", "# gt_4 = btf[:,4,1]", "\n", "# gt_5 = btf[:,5,1]", "\n", "\n", "\n", "\n", "# g_0 = btf[:,0,2]    ", "\n", "# g_1 = btf[:,1,2]", "\n", "# g_2 = btf[:,2,2]", "\n", "# g_3 = btf[:,3,2]", "\n", "# g_4 = btf[:,4,2]", "\n", "# g_5 = btf[:,5,2]", "\n", "\n", "# mom5_0 = btf[:,0,3]    ", "\n", "# mom5_1 = btf[:,1,3]", "\n", "# mom5_2 = btf[:,2,3]", "\n", "# mom5_3 = btf[:,3,3]", "\n", "# mom5_4 = btf[:,4,3]", "\n", "# mom5_5 = btf[:,5,3]", "\n", "\n", "# expr = eval(expr)", "\n", "\n", "\n", "\n", "\n", "# ==== applicable to June impl ====", "\n", "\n", "# coeff_SR: [lamb, weight-decay, momentum, lr, ]", "\n", "", "adamup", "=", "btf", "[", ":", ",", "0", ",", "0", "]", "\n", "adamdn", "=", "btf", "[", ":", ",", "0", ",", "1", "]", "\n", "lamb", "=", "coeff_SR", "[", "0", "]", "\n", "# expr = adamup/(1-lamb + lamb * adamdn)", "\n", "expr", "=", "eval", "(", "expr", ")", "\n", "b1", "=", "expr", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "\n", "\n", "return", "b1", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.calStat_thisLayer": [[191, 200], ["np.zeros", "range", "print", "ntf[].reshape", "torch.mean", "torch.std"], "function", ["None"], ["", "", "def", "calStat_thisLayer", "(", "ntf", ")", ":", "\n", "# input shape: [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "    ", "F", "=", "ntf", ".", "shape", "[", "-", "1", "]", "\n", "mv", "=", "np", ".", "zeros", "(", "(", "F", ",", "2", ")", ")", "\n", "for", "f", "in", "range", "(", "F", ")", ":", "\n", "        ", "this", "=", "ntf", "[", ":", ",", ":", ",", "f", "]", ".", "reshape", "(", "-", "1", ")", "\n", "mv", "[", "f", "]", "=", "[", "torch", ".", "mean", "(", "this", ")", ",", "torch", ".", "std", "(", "this", ")", "]", "\n", "", "print", "(", "f'mean & std at this layer (feat x m/std):\\n{mv}'", ")", "\n", "return", "mv", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.eva_sr_trainingPerform": [[203, 222], ["print", "OPT().to", "zip", "np.save", "np.asarray", "np.mean", "np.mean", "meta.wzRec", "stage023_autopt.run_epoch_sr", "np.sum", "OPT", "range"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr"], ["", "def", "eva_sr_trainingPerform", "(", "args", ",", "eva_epoch_len", "=", "None", ",", "OPT", "=", "None", ",", "n_tests", "=", "None", ",", "want_save_eva_loss", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "print", "(", "'TODO: add no grad to eva'", ")", "\n", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "\n", "res", "=", "[", "run_epoch_sr", "(", "args", ",", "eva_epoch_len", ",", "should_train", "=", "False", ",", "**", "args", ")", "for", "_", "in", "range", "(", "n_tests", ")", "]", "\n", "\n", "losses", ",", "coeffs", "=", "zip", "(", "*", "res", ")", "\n", "\n", "np", ".", "save", "(", "'coeffs_fake_eva.npy'", ",", "coeffs", ")", "\n", "\n", "all_losses", "=", "np", ".", "asarray", "(", "losses", ")", "\n", "avg_eva_sum_loss", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "all_losses", ",", "1", ")", ",", "0", ")", "\n", "avg_eva_last_loss", "=", "np", ".", "mean", "(", "all_losses", "[", ":", ",", "-", "1", "]", ",", "0", ")", "\n", "\n", "wzRec", "(", "all_losses", ",", "'Eva-SR-loss'", ",", "Target_Optimizee", ".", "name", ",", "want_save", "=", "want_save_eva_loss", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.fine_tune_SR": [[224, 261], ["coeff_SR.detach().cpu().data.numpy().round", "OPT_META_SR", "OPT().to", "range", "coeff_SR.detach().cpu().data.numpy().round", "stage023_autopt.eva_sr_trainingPerform", "itertools.chain.from_iterable", "stage023_autopt.run_epoch_sr", "coeffs_allEP.append", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "np.save", "np.save", "coeff_SR.detach().cpu().data.numpy", "OPT", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu().data.numpy", "stage023_autopt.eva_sr_trainingPerform", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform"], ["", "def", "fine_tune_SR", "(", "args", ",", "coeff_SR", "=", "None", ",", "OPT", "=", "None", ",", "epoch_len_tuneSR", "=", "None", ",", "n_epochs_tuneSR", "=", "20", ",", "srFineTune_want_eva_in_train", "=", "None", ",", "OPT_META_SR", "=", "None", ",", "lr_meta_tuneSR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# this function will not build new SR coeffs (in-place tuning)", "\n", "# but really DOES initialize a new meta-opt", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "\n", "args", "[", "'opt_meta_SR'", "]", "=", "OPT_META_SR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_meta_tuneSR", ",", "momentum", "=", "0.9", ")", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "coeffs_allEP", "=", "[", "]", "\n", "\n", "\n", "# for iepoch in tqdm(range(n_epochs_tuneSR), 'Fine tuning SR'):", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_tuneSR", ")", ":", "\n", "\n", "        ", "losses_1epoch", ",", "coeffs", "=", "run_epoch_sr", "(", "args", ",", "epoch_len_tuneSR", ",", "should_train", "=", "True", ",", "**", "args", ")", "\n", "coeffs_allEP", ".", "append", "(", "coeffs", ")", "\n", "\n", "wzRec", "(", "losses_1epoch", ",", "'tuneSR-train-loss, epoch-{}'", ".", "format", "(", "iepoch", ")", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "np", ".", "save", "(", "'coeff_SR.npy'", ",", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_allEP.npy'", ",", "coeffs_allEP", ")", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "if", "srFineTune_want_eva_in_train", ":", "\n", "                ", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "\n", "\n", "", "", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'final coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.run_epoch_sr": [[265, 351], ["bool", "Target_DataGen", "Target_Optimizee().to", "meta.wIni", "l2oShell_4SR_featPrep.reset", "tqdm", "stage023_autopt.History_Collector", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "Target_Optimizee().to.parameters", "opt_meta_SR.zero_grad", "range", "tqdm", "range", "Target_Optimizee().to.", "losses_1epoch.append", "optimizee.backward", "enumerate", "Target_Optimizee", "range", "optimizee.data.cpu().numpy", "Target_Optimizee().to.named_parameters", "int", "meta.detach_var", "l2oShell_4SR_featPrep.grad2features", "History_Collector.", "stage023_autopt.sr_fun_tensor", "result_params[].retain_grad", "Target_Optimizee().to", "meta.wIni", "Target_Optimizee().to.load_state_dict", "Target_Optimizee().to.zero_grad", "Target_Optimizee().to.named_parameters", "coeff_SR.detach().cpu().data.numpy", "np.prod", "p.grad.view", "sr_fun_tensor.view", "opt_meta_SR.zero_grad", "Target_Optimizee().to.", "all_losses.backward", "opt_meta_SR.step", "bool", "coeff_SR.detach().cpu().data.numpy().round", "meta.rsetattr", "optimizee.data.cpu", "p.size", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "Target_Optimizee", "p.size", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.reset", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.grad2features", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "def", "run_epoch_sr", "(", "args", ",", "run_epoch_len", ",", "should_train", ",", "rec_SR", "=", "True", ",", "coeff_SR", "=", "None", ",", "opt_meta_SR", "=", "None", ",", "l2oShell_4SR_featPrep", "=", "None", ",", "Target_DataGen", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "unroll_tuneSR", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "expr", "=", "None", ",", "Ngf", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "not", "should_train", ":", "\n", "        ", "unroll_tuneSR", "=", "1", "\n", "", "if", "bool", "(", "rec_SR", ")", ":", "\n", "        ", "args", "[", "'rec_SR'", "]", "=", "[", "]", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "\n", "", "target", "=", "Target_DataGen", "(", "training", "=", "should_train", ",", "**", "args", ")", "\n", "optimizee", "=", "Target_Optimizee", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "\n", "l2oShell_4SR_featPrep", ".", "reset", "(", "optimizee", ".", "parameters", "(", ")", ")", "\n", "\n", "losses_1epoch", ",", "all_losses", "=", "[", "]", ",", "None", "\n", "if", "should_train", ":", "\n", "        ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "iterator", "=", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ",", "'Eva: '", ")", "\n", "", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ")", "\n", "\n", "history_collector", "=", "History_Collector", "(", "SR_memlen", ",", "Ngroup_zee", ")", "\n", "for", "i_step", "in", "iterator", ":", "\n", "\n", "\n", "        ", "loss", "=", "optimizee", "(", "target", ")", "\n", "all_losses", "=", "loss", "if", "all_losses", "is", "None", "else", "all_losses", "+", "loss", "\n", "\n", "losses_1epoch", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "should_train", ")", "\n", "\n", "offset", "=", "0", "\n", "result_params", "=", "{", "}", "\n", "\n", "for", "i_group", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "optimizee", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "cur_sz", "=", "int", "(", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "\n", "gradients", "=", "detach_var", "(", "p", ".", "grad", ".", "view", "(", "cur_sz", ",", "1", ")", ")", "\n", "sr_features_cur", "=", "l2oShell_4SR_featPrep", ".", "grad2features", "(", "gradients", ",", "i_group", ",", "i_step", ")", "\n", "sr_inputs", "=", "history_collector", "(", "sr_features_cur", ",", "i_step", ",", "i_group", ")", "\n", "updates", "=", "sr_fun_tensor", "(", "sr_inputs", ",", "**", "args", ")", "\n", "\n", "updates", "=", "updates", "*", "0.01", "\n", "\n", "result_params", "[", "name", "]", "=", "p", "+", "updates", ".", "view", "(", "*", "p", ".", "size", "(", ")", ")", "\n", "result_params", "[", "name", "]", ".", "retain_grad", "(", ")", "\n", "\n", "offset", "+=", "cur_sz", "\n", "# print(args['coeff_SR']) #-wz", "\n", "\n", "\n", "", "if", "i_step", "%", "unroll_tuneSR", "==", "0", ":", "\n", "            ", "if", "should_train", ":", "\n", "\n", "\n", "                ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "all_losses", "+=", "optimizee", "(", "target", ")", "\n", "all_losses", ".", "backward", "(", ")", "\n", "opt_meta_SR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "if", "bool", "(", "rec_SR", ")", ":", "\n", "                    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "", "all_losses", "=", "None", "\n", "optimizee", "=", "Target_Optimizee", "(", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "optimizee", ".", "load_state_dict", "(", "result_params", ")", "\n", "# updateDict_skip_running(optimizee,result_params)", "\n", "\n", "optimizee", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "p", "in", "optimizee", ".", "named_parameters", "(", ")", ":", "\n", "                ", "rsetattr", "(", "optimizee", ",", "name", ",", "result_params", "[", "name", "]", ")", "\n", "\n", "", "", "", "return", "losses_1epoch", ",", "args", "[", "'rec_SR'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.fit_SR": [[370, 416], ["coeff_SR.detach().cpu().data.numpy().round", "OPT_fitSR", "nn.MSELoss", "stage023_autopt.SRDataset", "utils.get_infinite_iter", "range", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "np.save", "itertools.chain.from_iterable", "utils.get_infinite_iter.sample", "stage023_autopt.sr_fun_tensor", "nn.MSELoss.", "OPT_fitSR.zero_grad", "mse.backward", "OPT_fitSR.step", "coeff_SR.detach().cpu().data.numpy", "stage023_autopt.evaSR_R2", "eva_r2s.append", "utils.progress_bar", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu", "x.detach().cpu().data.item", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "x.detach().cpu", "x.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.evaSR_R2", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.progress_bar"], ["", "", "def", "fit_SR", "(", "args", ",", "lr_fitSR", "=", "None", ",", "expr", "=", "None", ",", "n_epochs_fit_SR", "=", "20", ",", "OPT_fitSR", "=", "None", ",", "l2o_net", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# need to un-comment 'step-0-prep' in order to have correct l2o_net name", "\n", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "\n", "opt_fitSR", "=", "OPT_fitSR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_fitSR", ")", "\n", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "dataset_train", "=", "SRDataset", "(", "which_SR_dataset", ")", "\n", "srIter", "=", "get_infinite_iter", "(", "dataset_train", ",", "shuffle", "=", "True", ",", "sampler", "=", "None", ",", "**", "args", ")", "\n", "\n", "\n", "eva_r2s", "=", "[", "]", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_fit_SR", ")", ":", "\n", "\n", "        ", "l2o_input_slices", ",", "l2o_output", "=", "srIter", ".", "sample", "(", ")", "# parallel working.", "\n", "\n", "sr_pred", "=", "sr_fun_tensor", "(", "l2o_input_slices", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "\n", "loss", "=", "mse", "(", "sr_pred", ",", "l2o_output", ")", "\n", "\n", "\n", "opt_fitSR", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt_fitSR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "eva_r2", "=", "evaSR_R2", "(", "args", ",", "**", "args", ")", "\n", "coeff_disp", "=", "[", "f'{x.detach().cpu().data.item():.4f}'", "for", "x", "in", "coeff_SR", "]", "\n", "\n", "# print(f'current coeff_SR: {coeff_disp}')", "\n", "eva_r2s", ".", "append", "(", "eva_r2", ")", "\n", "progress_bar", "(", "iepoch", ",", "n_epochs_fit_SR", ",", "f'loss={loss} , eva_r2={eva_r2} , coeff_SR={coeff_disp}'", ")", "\n", "\n", "", "", "wzRec", "(", "eva_r2s", ",", "'fit SR, eva_r2'", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "np", ".", "save", "(", "'wz_saved_models/fitted SR ~ of ~ {l2o_net.name}.npy'", ",", "coeff_SR_list", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.evaSR_R2": [[419, 432], ["torch.no_grad", "SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "stage023_autopt.sr_fun_tensor", "sr_fun_tensor.detach().cpu().data.numpy", "sklearn.metrics.r2_score", "print", "sr_fun_tensor.detach().cpu", "sr_fun_tensor.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaSR_R2", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "**", "w", ")", ":", "\n", "# dataset_test = np.load(which_SR_dataset)", "\n", "    ", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "x", "=", "torch", ".", "tensor", "(", "Xy_test", "[", ":", ",", ":", "-", "1", "]", ",", "device", "=", "DEVICE", ")", "\n", "y_true", "=", "Xy_test", "[", ":", ",", "-", "1", "]", "\n", "pred_tensor", "=", "sr_fun_tensor", "(", "x", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "pred", "=", "pred_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "r2", "=", "r2_score", "(", "y_true", ",", "pred", ")", "\n", "\n", "print", "(", "f'\\n\\nR2 = {r2:.5f}\\n\\n'", ")", "\n", "\n", "return", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.viz_grad_seq": [[434, 461], ["to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "plt.close", "range", "print", "plt.subplot", "plt.plot", "plt.plot", "plt.legend", "np.random.choice", "list", "len", "len", "len", "print", "range", "range", "plt.plot"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "def", "viz_grad_seq", "(", "sr_r_t_n_f", ")", ":", "\n", "# the visualization function for certain neuron values.", "\n", "# [run, time, neuron/layer, feat]", "\n", "    ", "n_neuron", "=", "sr_r_t_n_f", ".", "shape", "[", "1", "]", "\n", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "layerIidx", "=", "[", "np", ".", "random", ".", "choice", "(", "n", ",", "1", ")", ",", "(", "0", ",", "1", ",", "-", "2", ",", "-", "1", ")", ",", "list", "(", "range", "(", "n", ")", ")", "]", "[", "-", "1", "]", "\n", "\n", "to_viz_r_t_n_f", "=", "sr_r_t_n_f", "[", ":", ",", ":", ",", "layerIidx", ",", ":", "]", "\n", "grad_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "update_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "gfeat_rt_n_f", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "1", ":", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", ",", "f", "-", "2", "]", ")", "\n", "if", "f", "==", "2", ":", "\n", "        ", "print", "(", "'viz for DM-opt'", ")", "\n", "", "elif", "f", ">", "2", ":", "\n", "        ", "print", "(", "'viz for RP-opt'", ")", "\n", "", "else", ":", "raise", "ValueError", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "for", "ilayer", "in", "range", "(", "n", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "2", ",", "n", "//", "2", ",", "ilayer", "+", "1", ")", "\n", "plt", ".", "plot", "(", "grad_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-x'", ",", "label", "=", "f'grad @ layer {ilayer}'", ")", "# len(layerIidx) \u6761\u6570\u636e", "\n", "plt", ".", "plot", "(", "update_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-o'", ",", "label", "=", "f'update @ layer {ilayer}'", ")", "\n", "def", "plot_feat", "(", ")", ":", "\n", "            ", "for", "i_f", "in", "range", "(", "f", "-", "2", ")", ":", "\n", "                ", "feati_rt_n", "=", "gfeat_rt_n_f", "[", ":", ",", ":", ",", "i_f", "]", "\n", "plt", ".", "plot", "(", "feati_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-1'", ",", "label", "=", "f'the {i_f}-th gfeat @ layer {ilayer}'", ")", "\n", "# if f>2:  plot_feat()", "\n", "", "", "plt", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.sr_prep1": [[464, 483], ["len", "list", "int"], "function", ["None"], ["", "", "def", "sr_prep1", "(", "args", ",", "SR_memlen", ",", "num_Xyitems_SR", ",", "eva_epoch_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# this function will change some configs related to SR, for the sole purpose of configuring generation of offline SR database", "\n", "\n", "    ", "Ngroup_zee", "=", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "tSample_1epoch", "=", "eva_epoch_len", "//", "SR_memlen", "-", "2", "\n", "\n", "assert", "tSample_1epoch", ">", "0", ",", "f'eva_epoch_len={eva_epoch_len}, should > SR_memlen*2 = {SR_memlen}*2 = {SR_memlen*2}'", "\n", "\n", "what_we_get_1epoch", "=", "tSample_1epoch", "*", "Ngroup_zee", "\n", "\n", "epochs_needed", "=", "int", "(", "num_Xyitems_SR", "/", "what_we_get_1epoch", "/", "10", "*", "1.6", ")", "+", "1", "\n", "args", "[", "'n_tests'", "]", "=", "epochs_needed", "\n", "args", "[", "'tSample_1epoch'", "]", "=", "tSample_1epoch", "\n", "args", "[", "'available_Interval'", "]", "=", "eva_epoch_len", "-", "tSample_1epoch", "*", "SR_memlen", "-", "2", "# -2 is for safety", "\n", "args", "[", "'SR_memlen'", "]", "=", "SR_memlen", "\n", "args", "[", "'num_Xyitems_SR'", "]", "=", "num_Xyitems_SR", "\n", "# print(f'\\n\\n----------\\nSR prep:\\n\\tepochs_needed = {epochs_needed}\\n\\ttSample_1epoch = {tSample_1epoch}\\n\\tSR_memlen = {SR_memlen}\\n\\teva_epoch_len = {eva_epoch_len} > tSample_1epoch*SR_memlen = {tSample_1epoch}*{SR_memlen} = {tSample_1epoch*SR_memlen}\\n\\tNgroup_zee = {Ngroup_zee}\\n\\nTarget_DataGen = {Target_DataGen}\\nTarget_Optimizee = {Target_Optimizee}\\n----------\\n')", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.sr_prep2": [[485, 541], ["np.random.rand", "stage023_autopt.sr_prep2.interv_to_int"], "function", ["None"], ["", "def", "sr_prep2", "(", "sr_r_t_n_f", ",", "args", ",", "available_Interval", "=", "None", ",", "tSample_1epoch", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "num_Xyitems_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# returned SR_Xy_rn_tf shape:", "\n", "#     [N_sample , SR_memlen * Ngf+1 ] ; the last column is label", "\n", "\n", "# sr_gfu shape: [eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "# sr_r_t_n_f shape: ", "\n", "#     [which run (r) , which time step (t) , which neuron (n) , grad/feature/update (f) ]", "\n", "#     shape: [n_tests, eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "    ", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "f_true", "=", "f", "-", "2", "if", "f", ">", "2", "else", "f", "-", "1", "# RP or DM", "\n", "SR_XY_rtn_f", "=", "[", "]", "\n", "tSelect_r_n", "=", "np", ".", "random", ".", "rand", "(", "r", ",", "n", ",", "tSample_1epoch", "+", "1", ")", "\n", "def", "interv_to_int", "(", "tSelect_r_n", ")", ":", "\n", "# guarantee the randomness in sampling", "\n", "        ", "sum_", "=", "np", ".", "sum", "(", "tSelect_r_n", ",", "axis", "=", "2", ")", "\n", "tSelect_r_n", "=", "tSelect_r_n", "/", "sum_", "[", ":", ",", ":", ",", "None", "]", "*", "available_Interval", "\n", "tSelect_r_n", "=", "tSelect_r_n", ".", "astype", "(", "int", ")", "\n", "return", "tSelect_r_n", "\n", "", "tSelect_r_n", "=", "interv_to_int", "(", "tSelect_r_n", ")", "# shape is [r,n,tSample_1epoch+1], every [_r, _n] dimension, when sumed up along axis 'tSample_1epoch+1', is no more than available_Interval", "\n", "\n", "# the [_r, _n] position means the starting t for this sample of sequence", "\n", "\n", "rn_t_f", "=", "[", "]", "# when t&f are viewed together, this one means to be collection of t_f sequences (along t axis)", "\n", "for", "_r", "in", "range", "(", "r", ")", ":", "\n", "        ", "for", "_n", "in", "range", "(", "n", ")", ":", "\n", "                ", "tSelect", "=", "tSelect_r_n", "[", "_r", ",", "_n", "]", "# a 1-D array of length tSample_1epoch+1, meaning the 'interval', rather than starging point.", "\n", "for", "ith_selection", "in", "range", "(", "tSample_1epoch", ")", ":", "\n", "                    ", "starting_point", "=", "sum", "(", "tSelect", "[", ":", "ith_selection", "+", "1", "]", ")", "+", "SR_memlen", "*", "ith_selection", "\n", "cur_item_t_f", "=", "sr_r_t_n_f", "[", "_r", ",", "starting_point", ":", "starting_point", "+", "SR_memlen", ",", "_n", ",", ":", "]", "# is an 2-D array", "\n", "if", "cur_item_t_f", "[", "SR_memlen", "//", "4", "*", "3", "-", "1", ",", "0", "]", "!=", "0.0", ":", "\n", "# only append items that grad is not 0 at this ramdomly selected location", "\n", "                        ", "rn_t_f", ".", "append", "(", "cur_item_t_f", ")", "\n", "# after for loop, rn_t_f is a 3-D, indexed by [rn, t, f] (somehow transposed)", "\n", "", "", "", "", "rn_t_f", "=", "np", ".", "asarray", "(", "rn_t_f", ")", "\n", "def", "extract_features_labels", "(", "rn_t_f", ")", ":", "\n", "        ", "if", "f", ">", "2", ":", "# RP model, remove original grad feature", "\n", "            ", "rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "", "features_rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", ":", "-", "1", "]", "# 3-D, remove update column", "\n", "_", ",", "N_pre", ",", "_", "=", "features_rn_t_f", ".", "shape", "\n", "rev_idx", "=", "np", ".", "arange", "(", "N_pre", ")", "[", ":", ":", "-", "1", "]", "\n", "features_rn_t_f_rev", "=", "features_rn_t_f", "[", ":", ",", "rev_idx", ",", ":", "]", "\n", "feat_reversed", "=", "features_rn_t_f_rev", ".", "reshape", "(", "[", "-", "1", ",", "SR_memlen", "*", "f_true", "]", ")", "# 2-D array", "\n", "labels_rn_1", "=", "rn_t_f", "[", ":", ",", "-", "1", ",", "-", "1", "]", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "# 1-D array, size = |rn|, reshaped to column", "\n", "SR_Xy_rn_tf", "=", "np", ".", "concatenate", "(", "[", "feat_reversed", ",", "labels_rn_1", "]", ",", "axis", "=", "1", ")", "\n", "return", "SR_Xy_rn_tf", "\n", "", "SR_Xy_rn_tf", "=", "extract_features_labels", "(", "rn_t_f", ")", "\n", "\n", "# at this point, we have a 2-D array, which is exactly the expected shape", "\n", "np", ".", "random", ".", "shuffle", "(", "SR_Xy_rn_tf", ")", "\n", "\n", "desc", "=", "f'#samples={SR_Xy_rn_tf.shape[0]}, #memlen={SR_memlen}, #feat={f_true}'", "\n", "print", "(", "f\"\\n=============\\nPost proc: randomly select time sub-sequences and re-formulate into Xy-samples for SR.\\n\\t Input shape:\\t\\t sr_r_t_n_f.shape = {sr_r_t_n_f.shape}\\n\\t Input samples:\\t r*(tSample_1epoch*Ngroup_zee) = {r}*{tSample_1epoch}*{Ngroup_zee} = {r*tSample_1epoch*Ngroup_zee}\\n\\t SR feature+label dim:\\t\\t SR_memlen*L2O_features = {SR_memlen}*{f_true}={SR_memlen*f_true}\\n\\t which L2O:\\t\\t \\t{args['l2o_net'].name}\\n\\t feature dim is: [1(grad) + {f-2} + 1(update)]\\n\\t Obtained SR_Xy shape:\\t\\t {SR_Xy_rn_tf.shape}\\n\\t However, desired n_sample is:\\t\\t {num_Xyitems_SR}\\n desc:\\n\\t {desc}\\n=============\\n\\n\"", ")", "\n", "return", "SR_Xy_rn_tf", ",", "desc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.comma_paren": [[545, 565], ["enumerate"], "function", ["None"], ["", "def", "comma_paren", "(", "expr", ",", "loc", ")", ":", "\n", "# given string expr, return the position of mathing ')' and the ','", "\n", "# assume expr has fun(A,B) structure after loc", "\n", "    ", "substr", "=", "expr", "[", "loc", ":", "]", "\n", "comma_", "=", "0", "\n", "cnt_left", "=", "0", "\n", "seen", "=", "False", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "expr", "[", "loc", ":", "]", ")", ":", "\n", "        ", "if", "s", "==", "','", ":", "\n", "            ", "comma_", "=", "i", "\n", "", "elif", "s", "==", "'('", ":", "\n", "            ", "cnt_left", "+=", "1", "\n", "seen", "=", "True", "\n", "", "elif", "s", "==", "')'", ":", "\n", "            ", "cnt_left", "-=", "1", "\n", "\n", "", "if", "seen", "and", "cnt_left", "==", "0", ":", "\n", "            ", "paren_", "=", "i", "\n", "break", "\n", "", "", "return", "loc", "+", "comma_", ",", "loc", "+", "paren_", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.find_ith": [[569, 577], ["s.find", "s.find"], "function", ["None"], ["", "def", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", ":", "\n", "    ", "i", "=", "0", "\n", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "# for i in range(ith):", "\n", "while", "i", "<", "ith", "and", "loc", "!=", "-", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ",", "loc", "+", "1", ")", "\n", "i", "+=", "1", "\n", "", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.find_random_subs": [[578, 591], ["s.count", "s.find", "np.random.choice", "stage023_autopt.find_ith"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_ith"], ["", "def", "find_random_subs", "(", "s", ",", "sub", ")", ":", "\n", "# given a string s and a sub string, if sub is a substring of s, then return the location of a randomly selected sub in s (if multiple sub in s)", "\n", "# if sub not present, return -1", "\n", "    ", "cnt", "=", "s", ".", "count", "(", "sub", ")", "\n", "if", "cnt", "==", "0", ":", "# not present", "\n", "        ", "return", "-", "1", "\n", "", "elif", "cnt", "==", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "return", "loc", "\n", "", "else", ":", "\n", "        ", "ith", "=", "np", ".", "random", ".", "choice", "(", "cnt", ")", "\n", "loc", "=", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", "\n", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.mutate_expr": [[593, 605], ["np.random.rand", "add_term", "add_term", "stage023_autopt.mutExpm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.mutExpm"], ["", "", "def", "mutate_expr", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "w", ")", ":", "\n", "    ", "p", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "\n", "if", "'expm'", "in", "expr", ":", "\n", "        ", "probs", "=", "[", "0.3", ",", "1.1", "]", "\n", "if", "p", "<", "probs", "[", "0", "]", ":", "\n", "            ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "elif", "p", "<", "probs", "[", "1", "]", ":", "\n", "            ", "expr", "=", "mutExpm", "(", "expr", ")", "\n", "", "", "else", ":", "\n", "        ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.mutExpm": [[609, 635], ["stage023_autopt.find_expm_a", "float", "stage023_autopt.mutExpm.is_single"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_expm_a"], ["", "def", "mutExpm", "(", "expr", ")", ":", "\n", "    ", "loc", ",", "comma", ",", "paren", "=", "find_expm_a", "(", "expr", ")", "\n", "\n", "before", "=", "expr", "[", ":", "loc", "]", "\n", "after", "=", "expr", "[", "paren", "+", "1", ":", "]", "\n", "part1", "=", "expr", "[", "loc", ":", "comma", "+", "1", "]", "\n", "part3", "=", "expr", "[", "paren", ":", "paren", "+", "1", "]", "# ')'", "\n", "a", "=", "float", "(", "expr", "[", "comma", "+", "1", ":", "paren", "]", ")", "\n", "\n", "def", "is_single", "(", "s", ",", "start", ",", "end", ")", ":", "\n", "# judge if input is completely wraped in '()'", "\n", "        ", "i1", ",", "i2", "=", "start", ",", "end", "\n", "while", "i1", ">=", "0", ":", "\n", "            ", "if", "s", "[", "i1", "]", "==", "' '", ":", "i1", "-=", "1", "\n", "elif", "s", "[", "i1", "]", "!=", "'('", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "while", "i2", "<", "len", "(", "s", ")", ":", "\n", "            ", "if", "s", "[", "i2", "]", "==", "' '", ":", "i2", "+=", "1", "\n", "elif", "s", "[", "i2", "]", "!=", "')'", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "return", "True", "\n", "\n", "", "single", "=", "is_single", "(", "expr", ",", "loc", "-", "1", ",", "paren", "+", "1", ")", "\n", "if", "single", ":", "\n", "        ", "expr", "=", "before", "# -wz", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.find_expm_a": [[640, 664], ["stage023_autopt.find_random_subs", "stage023_autopt.comma_paren"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_random_subs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.comma_paren"], ["", "", "def", "find_expm_a", "(", "expr", ")", ":", "\n", "# given an string expr, find the location and value of the 'a' in x**a.", "\n", "# if multiple results, return an randomly selected one", "\n", "# eg: expr = \"tanh(tanh( coeff_SR[0] + sinh(expm( coeff_SR[1] * mt_0, 3))))\"  then \u203a\u203a a=3", "\n", "    ", "assert", "'expm'", "in", "expr", "\n", "loc", "=", "find_random_subs", "(", "expr", ",", "'expm'", ")", "\n", "comma", ",", "paren", "=", "comma_paren", "(", "expr", ",", "loc", ")", "\n", "\n", "# full_expm = expr[loc:paren+1]", "\n", "# before = expr[:loc]", "\n", "# part1 = expr[loc:comma+1]", "\n", "# a = float(expr[comma+1:paren])", "\n", "# part3 = expr[paren:paren+1]  # ')'", "\n", "# after = expr[paren+1:]", "\n", "\n", "# print(expr)", "\n", "# print(before)", "\n", "# print(part1)", "\n", "# print(a)", "\n", "# print(part3)", "\n", "# print(after)", "\n", "\n", "# raise", "\n", "return", "loc", ",", "comma", ",", "paren", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.plot_sin": [[676, 688], ["np.linspace", "sum", "utils.plot", "plt.title", "range", "stage023_autopt.plot_sin.trm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "def", "plot_sin", "(", ")", ":", "\n", "\n", "    ", "N", "=", "10", "\n", "L", "=", "N", "\n", "\n", "def", "trm", "(", "x", ",", "n", ")", ":", "\n", "        ", "return", "(", "-", "1", ")", "**", "(", "(", "n", "-", "1", ")", "//", "2", ")", "*", "1", "/", "np", ".", "math", ".", "factorial", "(", "n", ")", "*", "x", "**", "n", "\n", "", "x", "=", "np", ".", "linspace", "(", "-", "L", ",", "L", ",", "100", ")", "\n", "ords", "=", "[", "2", "*", "i", "+", "1", "for", "i", "in", "range", "(", "N", ")", "]", "\n", "sinx", "=", "sum", "(", "[", "trm", "(", "x", ",", "i", ")", "for", "i", "in", "ords", "]", ")", "\n", "plot", "(", "x", ",", "sinx", ")", "\n", "plt", ".", "title", "(", "f'highest order = {N}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.idx_k": [[690, 694], ["np.arange"], "function", ["None"], ["", "def", "idx_k", "(", "coeff_SR", ",", "expr_group_len", ")", ":", "\n", "# output the index (1-D) for the k1 in coeff_SR", "\n", "    ", "_", ",", "_", ",", "o3", "=", "coeff_SR", ".", "shape", "\n", "return", "np", ".", "arange", "(", "o3", "//", "3", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.genEmpExp_April": [[696, 725], ["range", "range", "res.append", "stage023_autopt.genEmpExp_April.genExpVTO"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExpVTO"], ["", "def", "genEmpExp_April", "(", "expr_vname_list", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "\n", "    ", "def", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ":", "\n", "# indecies: var,t,io,twin", "\n", "# order = io+1", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "\n", "        ", "v2i", "=", "{", "'mt'", ":", "0", ",", "'gt'", ":", "1", ",", "'g'", ":", "2", ",", "'mom5'", ":", "3", "}", "\n", "iv", "=", "v2i", "[", "vname", "]", "\n", "\n", "thisv", "=", "f'{vname}_{t}'", "\n", "res1", "=", "f'coeff_SR[{iv},{t},{io},0] * expm({thisv}, {io+1}+coeff_SR[{iv},{t},{io},2])'", "\n", "res2", "=", "f'coeff_SR[{iv},{t},{io},1] * expm({thisv}, {io+1}-coeff_SR[{iv},{t},{io},2])'", "\n", "\n", "return", "res1", "+", "' + '", "+", "res2", "\n", "\n", "", "res", "=", "[", "]", "\n", "expr_vname_list", "=", "[", "'mt'", ",", "'gt'", ",", "'g'", ",", "'mom5'", ",", "]", "\n", "# expr_vname_list = ['mt', 'gt', ]", "\n", "\n", "for", "vname", "in", "expr_vname_list", ":", "\n", "        ", "for", "t", "in", "range", "(", "expr_memlen", ")", ":", "\n", "            ", "for", "io", "in", "range", "(", "expr_maxOrd", ")", ":", "\n", "                ", "res", ".", "append", "(", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ")", "\n", "# res_viz = '\\ \\n+'.join(res); print(res_viz)", "\n", "\n", "", "", "", "res_ret", "=", "'+'", ".", "join", "(", "res", ")", "\n", "return", "res_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.do_with_expr": [[727, 765], ["stage023_autopt.do_with_expr.coeff_SR_ini"], "function", ["None"], ["", "def", "do_with_expr", "(", "args", ",", "coeff_SR_dic", "=", "None", ",", "**", "w", ")", ":", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# norm is to devide, denorm is to multiply (var's std)", "\n", "\n", "    ", "def", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "# std: MNIST task:", "\n", "#     mt ~ 0.2", "\n", "#     gt ~ 1.0", "\n", "#     g/mom ~ 0.0005", "\n", "\n", "        ", "coeff_SRNorm", "=", "np", ".", "array", "(", "[", "0.2", ",", "1", ",", "0.0005", ",", "0.0005", "]", ")", "*", "1", "\n", "\n", "k_scalar_ini_abs", "=", "0.001", "\n", "alpha_ini", "=", "0.05", "\n", "\n", "assert", "expr_group_len", "==", "3", "\n", "coeff_SR", "=", "np", ".", "zeros", "(", "(", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ")", ")", "\n", "\n", "k_ini", "=", "-", "k_scalar_ini_abs", "**", "(", "np", ".", "arange", "(", "expr_maxOrd", ")", "+", "1", ")", ".", "reshape", "(", "(", "expr_maxOrd", ",", "1", ")", ")", ".", "repeat", "(", "2", ",", "axis", "=", "1", ")", "\n", "coeff_SR", "[", "...", ",", "0", ":", "2", "]", "=", "k_ini", "\n", "coeff_SR", "[", "...", ",", "2", "]", "=", "alpha_ini", "\n", "\n", "if", "coeff_SR_dic", "is", "not", "None", ":", "\n", "            ", "for", "k", ",", "v", "in", "coeff_SR_dic", ".", "items", "(", ")", ":", "\n", "                ", "coeff_SR", "[", "k", "]", "=", "v", "\n", "\n", "", "", "return", "coeff_SR", ",", "coeff_SRNorm", "\n", "\n", "\n", "", "coeff_SR", ",", "coeff_SRNorm", "=", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "**", "args", ")", "\n", "\n", "args", "[", "'expr'", "]", "=", "genEmpExp", "(", "**", "args", ")", "\n", "args", "[", "'coeff_SR'", "]", "=", "torch", ".", "tensor", "(", "coeff_SR", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "args", "[", "'coeff_SR'", "]", ".", "requires_grad", "=", "True", "\n", "args", "[", "'coeff_SRNorm'", "]", "=", "torch", ".", "tensor", "(", "coeff_SRNorm", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_autopt.main_June": [[776, 935], ["args.get", "len", "stage023_autopt.sr_prep1", "torch.tensor", "stage023_autopt.fine_tune_SR", "torch.cuda.is_available", "int", "OPT_META_L2O", "print", "list", "args[].parameters"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_prep1", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.fine_tune_SR", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["", "def", "main_June", "(", ")", ":", "\n", "\n", "# ===================== initializations ... =====================", "\n", "\n", "# which_DataGen = 0", "\n", "# Target_DataGen = [MNISTLoss_f, Cifar_half_f][which_DataGen]", "\n", "# AB=1", "\n", "# cifar_root  = ['datasets/cifar10-A', 'datasets/cifar10-B'][AB]", "\n", "\n", "# Target_Optimizee = [MLP_MNIST,MLP_MNIST2,resnet18][0]", "\n", "\n", "\n", "    ", "SERVER", "=", "2", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "0", "\n", "\n", "\n", "args", "=", "{", "\n", "# Training", "\n", "\n", "'n_epochs'", ":", "[", "1", ",", "2", ",", "100", "]", "[", "SERVER", "]", ",", "\n", "'epoch_len'", ":", "[", "5", ",", "200", ",", "800", ",", "]", "[", "SERVER", "]", ",", "\n", "'unroll'", ":", "[", "2", ",", "1", ",", "20", ",", "]", "[", "SERVER", "]", ",", "\n", "'random_scale'", ":", "0.", ",", "\n", "# 'Target_DataGen': Target_DataGen,", "\n", "'only_want_last'", ":", "1", ",", "\n", "'want_save_eva_loss'", ":", "False", ",", "\n", "# Model", "\n", "'OPT'", ":", "RPOptimizer", ",", "\n", "'preproc'", ":", "[", "6", ",", "]", ",", "\n", "'hidden_layers_zer'", ":", "[", "7", ",", "]", ",", "\n", "# 'Ngf': 2,", "\n", "'beta1'", ":", "0.95", ",", "\n", "'beta2'", ":", "0.95", ",", "\n", "'pre_tahn_scale'", ":", "None", ",", "\n", "'LUM'", ":", "[", "LUM", ",", "None", "]", "[", "1", "]", ",", "\n", "\n", "# 'lum_layers': [len(list(optimizee_train().parameters())), 20, 1],", "\n", "\n", "\n", "# l2oShell_4SR_featPrep", "\n", "# 'grad_features': 'mt+gt+g+mom5',", "\n", "'grad_features'", ":", "'AdamUp_unNorm+AdamDn_Norm'", ",", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# SR stage 0: Generate SR database", "\n", "'want_sr'", ":", "1", ",", "\n", "'eva_epoch_len'", ":", "[", "80", ",", "900", ",", "500", "]", "[", "SERVER", "]", ",", "\n", "'n_tests'", ":", "[", "2", ",", "2", ",", "10", "]", "[", "SERVER", "]", ",", "# will be overwritten if want_sr", "\n", "# 'Target_Optimizee': Target_Optimizee,", "\n", "\n", "# 'expr': \"tanh(tanh( coeff_SR[0] + sinh(cube( coeff_SR[1] * mt_0))))\",", "\n", "# 'coeff_SR': torch.tensor([0.024803324, -1.9923366],device=DEVICE),", "\n", "\n", "'OPT_fitSR'", ":", "[", "optim", ".", "Adam", ",", "optim", ".", "SGD", "]", "[", "1", "]", ",", "\n", "'lr_fitSR'", ":", "0.001", ",", "\n", "'n_epochs_fit_SR'", ":", "int", "(", "1e4", ")", ",", "\n", "\n", "# SR: stage 3: fine tune SR", "\n", "'which_SR_dataset'", ":", "[", "None", ",", "'RP_s'", ",", "'RP_s_i'", ",", "'RP'", ",", "'DM'", "]", "[", "1", "]", ",", "\n", "'lr_meta_tuneSR'", ":", "0.01", ",", "\n", "'OPT_META_SR'", ":", "[", "optim", ".", "Adam", ",", "optim", ".", "SGD", "]", "[", "1", "]", ",", "\n", "'epoch_len_tuneSR'", ":", "[", "5", ",", "200", ",", "800", ",", "]", "[", "SERVER", "]", ",", "\n", "'unroll_tuneSR'", ":", "20", ",", "\n", "'n_epochs_tuneSR'", ":", "[", "2", ",", "100", ",", "20", "]", "[", "SERVER", "]", ",", "\n", "'srFineTune_want_eva_in_train'", ":", "0", ",", "\n", "\n", "\n", "# train expr", "\n", "'expr_vname_list'", ":", "[", "'mt'", ",", "'gt'", ",", "'g'", ",", "'mom5'", ",", "]", ",", "\n", "'expr_Nvar'", ":", "4", ",", "\n", "'expr_memlen'", ":", "3", ",", "\n", "'expr_maxOrd'", ":", "3", ",", "\n", "'expr_group_len'", ":", "3", ",", "# k1,k2,alpha", "\n", "\n", "\n", "# MLP_MNIST optimizee", "\n", "# 'pixels':  [28*28,  3*32*32][which_DataGen],", "\n", "\n", "# cifar", "\n", "'num_workers'", ":", "2", ",", "\n", "'batch_size'", ":", "128", ",", "\n", "'cifarAB'", ":", "'A'", ",", "\n", "\n", "# useless but must-have", "\n", "'META_OPT_LR'", ":", "0.001", ",", "\n", "'pin_memory'", ":", "False", ",", "\n", "'mode'", ":", "None", ",", "\n", "\n", "}", "\n", "\n", "\n", "problem_comb", "=", "{", "'mni'", ":", "[", "MNISTLoss_f", ",", "MLP_MNIST", "]", ",", "\n", "'mni2'", ":", "[", "MNISTLoss_f", ",", "MLP_MNIST2", "]", ",", "\n", "'cnn'", ":", "[", "Cifar_half_f", ",", "SMALL_CNN", "]", ",", "\n", "'r18h'", ":", "[", "Cifar_half_f", ",", "resnet18", "]", ",", "\n", "'r18'", ":", "[", "Cifar_f", ",", "resnet18", "]", ",", "\n", "'r50'", ":", "[", "Cifar_f", ",", "resnet50", "]", ",", "\n", "}", "\n", "\n", "Target_DataGen", ",", "Target_Optimizee", "=", "problem_comb", "[", "'mni'", "]", "\n", "\n", "args", "[", "'Target_DataGen'", "]", "=", "Target_DataGen", "\n", "if", "Target_DataGen", "in", "[", "MNISTLoss_f", ",", "MNISTLoss", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "28", "*", "28", "\n", "", "elif", "Target_DataGen", "in", "[", "Cifar_half", ",", "Cifar_half_f", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "3", "*", "32", "*", "32", "\n", "\n", "", "args", "[", "'Target_Optimizee'", "]", "=", "Target_Optimizee", "\n", "if", "args", ".", "get", "(", "'l2o_net'", ")", ":", "\n", "        ", "choose_meta_opt", "=", "[", "optim", ".", "Adam", ",", "]", ";", "which_meta_opt", "=", "0", "\n", "OPT_META_L2O", "=", "choose_meta_opt", "[", "which_meta_opt", "]", "\n", "args", "[", "'meta_opt'", "]", "=", "OPT_META_L2O", "(", "args", "[", "'l2o_net'", "]", ".", "parameters", "(", ")", ",", "lr", "=", "META_OPT_LR", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'\\n\\nL2O model not initialized before, planing to train L2O model from scratch...\\n Should NOT see this if: \\n\\t fine-tune L2O \\n\\t evaluation\\n\\t SR Gen Data\\n OK to see if:\\n\\t Train L2O from scratch \\n\\t Fitting SR\\n\\t fine-tune SR \\n\\t Evaluate SR performance \\n\\t normal Train resnet \\n\\n'", ")", "\n", "\n", "# if n_epochs is not None: args['n_epochs'] = n_epochs", "\n", "# if epoch_len is not None: args['epoch_len'] = epoch_len", "\n", "# if unroll is not None: args['unroll'] = unroll", "\n", "# if eva_epoch_len is not None: args['eva_epoch_len'] = eva_epoch_len", "\n", "# if n_tests is not None: args['n_tests'] = n_tests", "\n", "\n", "# args.update(other_configs)", "\n", "\n", "\n", "", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "sr_prep1", "(", "args", ",", "\n", "SR_memlen", "=", "1", ",", "\n", "num_Xyitems_SR", "=", "580", ",", "\n", "**", "args", ")", "\n", "\n", "args", "[", "'n_tests'", "]", "=", "2", "\n", "args", "[", "'eva_epoch_len'", "]", "=", "800", "\n", "\n", "args", "[", "'n_epochs_tuneSR'", "]", "=", "100", "\n", "args", "[", "'epoch_len_tuneSR'", "]", "=", "4000", "\n", "args", "[", "'unroll_tuneSR'", "]", "=", "10", "\n", "args", "[", "'lr_meta_tuneSR'", "]", "=", "0.005", "\n", "\n", "\n", "# do_with_expr(args, coeff_SR_dic, **args)", "\n", "args", "[", "'rec_SR'", "]", "=", "1", "\n", "\n", "args", "[", "'coeff_SR'", "]", "=", "torch", ".", "tensor", "(", "[", "0.8", ",", "]", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "args", "[", "'coeff_SR'", "]", ".", "requires_grad", "=", "True", "\n", "\n", "\n", "\n", "\n", "args", "[", "'expr'", "]", "=", "'adamup/(1-lamb + lamb * adamdn)'", "\n", "# ===================== finish initialization =====================", "\n", "fine_tune_SR", "(", "args", ",", "**", "args", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu": [[10, 12], ["numpy.maximum"], "function", ["None"], ["def", "relu", "(", "inX", ")", ":", "\n", "    ", "return", "np", ".", "maximum", "(", "0.", ",", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater": [[12, 14], ["numpy.greater().astype", "numpy.greater"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.greater"], ["", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "greater", "(", "x", ",", "y", ")", ".", "astype", "(", "'float'", ")", "\n", "# return np.maximum(x,y)", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.mult": [[15, 17], ["None"], "function", ["None"], ["", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin": [[17, 19], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "sin", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.cos": [[19, 21], ["numpy.sin"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin"], ["", "def", "cos", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign": [[21, 23], ["numpy.sign"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "sign", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.plus": [[23, 25], ["None"], "function", ["None"], ["", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.square": [[25, 27], ["None"], "function", ["None"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.cube": [[27, 29], ["None"], "function", ["None"], ["", "def", "cube", "(", "x", ")", ":", "\n", "    ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh": [[29, 31], ["numpy.tanh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh"], ["", "def", "tanh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp": [[31, 33], ["numpy.exp"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "exp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow": [[33, 35], ["numpy.sign", "numpy.power", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign"], ["", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "power", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.Abs": [[35, 37], ["abs"], "function", ["None"], ["", "def", "Abs", "(", "x", ")", ":", "\n", "    ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.re": [[37, 39], ["numpy.real"], "function", ["None"], ["", "def", "re", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.div": [[39, 41], ["None"], "function", ["None"], ["", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc": [[41, 43], ["scipy.special.erfc"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc"], ["", "def", "erfc", "(", "x", ")", ":", "\n", "    ", "return", "scipy", ".", "special", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sqrtm": [[43, 45], ["numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "sqrtm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.logm": [[45, 47], ["numpy.log", "numpy.abs"], "function", ["None"], ["", "def", "logm", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "log", "(", "np", ".", "abs", "(", "x", ")", "+", "1e-8", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh": [[47, 49], ["numpy.sinh"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh"], ["", "def", "sinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh": [[49, 51], ["numpy.arcsinh"], "function", ["None"], ["", "def", "asinh", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "arcsinh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.srTrain": [[56, 93], ["print", "print", "print", "pysr.pysr", "pysr.best", "print", "numpy.asarray().reshape", "numpy.asarray", "numpy.asarray", "list", "numpy.std", "itertools.chain", "numpy.asarray", "range", "len"], "function", ["None"], ["", "def", "srTrain", "(", "X", ",", "y", "=", "None", ",", "variable_names", "=", "None", ")", ":", "\n", "    ", "if", "y", "is", "not", "None", ":", "\n", "        ", "y", "=", "np", ".", "asarray", "(", "y", ")", ".", "reshape", "(", "-", "1", ")", "\n", "X", "=", "np", ".", "asarray", "(", "X", ")", "\n", "", "else", ":", "\n", "        ", "X", "=", "np", ".", "asarray", "(", "X", ")", "\n", "X", ",", "y", "=", "X", "[", ":", ",", ":", "-", "1", "]", ",", "X", "[", ":", ",", "-", "1", "]", "\n", "", "print", "(", "f'\\n\\n===\\n\\t shapes:\\n\\t\\t{X.shape}\\n\\t\\t{y.shape}\\n==='", ")", "\n", "\n", "\n", "if", "variable_names", "is", "None", ":", "\n", "\n", "        ", "variable_names", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "[", "f'x_{t}'", "]", "for", "t", "in", "range", "(", "len", "(", "X", "[", "0", "]", ")", ")", "]", ")", ")", "\n", "\n", "", "print", "(", "'variable_names: '", ",", "variable_names", ")", "\n", "# raise", "\n", "print", "(", "'Variable STD:\\n'", ",", "np", ".", "std", "(", "X", ",", "axis", "=", "0", ")", ")", "\n", "\n", "equations", "=", "pysr", "(", "X", ",", "y", ",", "\n", "niterations", "=", "300", ",", "# default = 100", "\n", "ncyclesperiteration", "=", "900", ",", "# default=300, increases diversity", "\n", "populations", "=", "8", ",", "# increases diversity, maybe better if > procs=4", "\n", "binary_operators", "=", "[", "\"plus\"", ",", "\"mult\"", ",", "\"pow\"", ",", "\"greater\"", ",", "\"div\"", "]", ",", "\n", "# binary_operators=[\"plus\", \"mult\", \"pow\"],", "\n", "# extra_sympy_mappings={ },", "\n", "unary_operators", "=", "[", "\"relu\"", ",", "\"exp\"", ",", "\"tanh\"", ",", "\"sinh\"", ",", "\"asinh\"", ",", "\"erfc\"", ",", "\"square\"", ",", "\"cube\"", ",", "\"abs\"", ",", "\"sign\"", ",", "\"logm\"", ",", "\"sqrtm\"", "]", ",", "\n", "# unary_operators=[ \"square\", \"cube\", \"abs\", \"sin\", \"cos\" ],", "\n", "\n", "maxsize", "=", "200", ",", "# default=20", "\n", "# maxdepth = 1000,  # default=None", "\n", "# batching = False,  #   batchSize = 50,  # make evolution faster for large datasets", "\n", "variable_names", "=", "variable_names", ",", "\n", ")", "\n", "\n", "bsym", "=", "best", "(", "equations", ")", "\n", "print", "(", "'best:   '", ",", "bsym", ")", "\n", "return", "\n", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.BasicBlock.__init__": [[29, 44], ["meta_module.MetaModule.__init__", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "meta_module.MetaSequential", "meta_module.MetaSequential", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "MetaConv2d", "(", "\n", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "MetaBatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "MetaConv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "MetaBatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "MetaSequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "MetaSequential", "(", "\n", "MetaConv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "MetaBatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.BasicBlock.forward": [[46, 52], ["F.relu", "resnet_meta.BasicBlock.bn2", "resnet_meta.BasicBlock.shortcut", "F.relu", "resnet_meta.BasicBlock.bn1", "resnet_meta.BasicBlock.conv2", "resnet_meta.BasicBlock.conv1"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.Bottleneck.__init__": [[57, 74], ["meta_module.MetaModule.__init__", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "meta_module.MetaSequential", "meta_module.MetaSequential", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "MetaConv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "MetaBatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "MetaConv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "MetaBatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "MetaConv2d", "(", "planes", ",", "self", ".", "expansion", "*", "\n", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "MetaBatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "MetaSequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "MetaSequential", "(", "\n", "MetaConv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "MetaBatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.Bottleneck.forward": [[76, 83], ["F.relu", "F.relu", "resnet_meta.Bottleneck.bn3", "resnet_meta.Bottleneck.shortcut", "F.relu", "resnet_meta.Bottleneck.bn1", "resnet_meta.Bottleneck.bn2", "resnet_meta.Bottleneck.conv3", "resnet_meta.Bottleneck.conv1", "resnet_meta.Bottleneck.conv2"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet.__init__": [[86, 101], ["meta_module.MetaModule.__init__", "meta_module.MetaConv2d", "meta_module.MetaBatchNorm2d", "resnet_meta.ResNet._make_layer", "resnet_meta.ResNet._make_layer", "resnet_meta.ResNet._make_layer", "resnet_meta.ResNet._make_layer", "meta_module.MetaLinear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._make_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._make_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._make_layer", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "num_classes", "=", "10", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "64", "\n", "\n", "# print('happy!!!')", "\n", "# raise", "\n", "\n", "self", ".", "conv1", "=", "MetaConv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "MetaBatchNorm2d", "(", "64", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "linear", "=", "MetaLinear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._make_layer": [[102, 109], ["meta_module.MetaSequential", "layers.append", "block"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "MetaSequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._forward_impl": [[110, 121], ["F.relu", "resnet_meta.ResNet.layer1", "resnet_meta.ResNet.layer2", "resnet_meta.ResNet.layer3", "resnet_meta.ResNet.layer4", "F.avg_pool2d", "resnet_meta.ResNet.view", "resnet_meta.ResNet.linear", "resnet_meta.ResNet.bn1", "resnet_meta.ResNet.size", "resnet_meta.ResNet.conv1"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["", "def", "_forward_impl", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "4", ")", "# (input, kernal_size)", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet.forward": [[122, 124], ["resnet_meta.ResNet._forward_impl"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._forward_impl"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_forward_impl", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.cResNet.__init__": [[137, 141], ["resnet_meta.ResNet.__init__", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "arch", ",", "block", ",", "layers", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "cResNet", ",", "self", ")", ".", "__init__", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "self", ".", "name", "=", "arch", "\n", "self", ".", "loss", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "# self.", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.cResNet.forward": [[145, 161], ["loss.sample", "F.log_softmax", "resnet_meta.cResNet.loss", "resnet_meta.cResNet._forward_impl"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._forward_impl"], ["", "def", "forward", "(", "self", ",", "loss", ")", ":", "\n", "\n", "        ", "inp", ",", "out", "=", "loss", ".", "sample", "(", ")", "\n", "# inp = Variable(inp.view(inp.size()[0], 32*32*3)).to(DEVICE)", "\n", "# inp = inp.to(self.DEVICE)", "\n", "# out = Variable(out).to(self.DEVICE)", "\n", "\n", "# cur_layer = 0", "\n", "# while f'mat_{cur_layer}' in self.layers:", "\n", "#     inp = self.activation(self.layers[f'mat_{cur_layer}'](inp))", "\n", "#     cur_layer += 1", "\n", "\n", "\n", "pred", "=", "F", ".", "log_softmax", "(", "self", ".", "_forward_impl", "(", "inp", ")", ",", "dim", "=", "1", ")", "\n", "l", "=", "self", ".", "loss", "(", "pred", ",", "out", ")", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.cResNet.cal_test_acc": [[162, 183], ["print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "resnet_meta.cResNet._forward_impl", "torch.max", "torch.max", "torch.max", "torch.max", "labels.size", "images.to", "labels.to"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.ResNet._forward_impl"], ["", "def", "cal_test_acc", "(", "self", ",", "testloader", ")", ":", "\n", "\n", "        ", "correct", "=", "0", "\n", "total", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "data", "in", "enumerate", "(", "testloader", ")", ":", "\n", "\n", "                ", "images", ",", "labels", "=", "data", "\n", "images", ",", "labels", "=", "images", ".", "to", "(", "DEVICE", ")", ",", "labels", ".", "to", "(", "DEVICE", ")", "\n", "\n", "outputs", "=", "self", ".", "_forward_impl", "(", "images", ")", "\n", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "correct", "+=", "(", "predicted", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "", "acc", "=", "100", "*", "correct", "/", "total", "\n", "\n", "print", "(", "f'\\ntest acc is: {acc}\\n'", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet": [[191, 199], ["cResNet().to", "load_state_dict_from_url", "cResNet().to.load_state_dict", "resnet_meta.cResNet"], "function", ["None"], ["", "", "def", "_resnet", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", ":", "\n", "# model = ResNet(block, layers, **kwargs)", "\n", "    ", "model", "=", "cResNet", "(", "arch", ",", "block", ",", "layers", ",", "**", "kwargs", ")", ".", "to", "(", "DEVICE", ")", "#-wz", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet18": [[201, 211], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnet18", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet18'", ",", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet34": [[213, 223], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet34'", ",", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet50": [[225, 235], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet50'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet101": [[237, 247], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet101'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnet152": [[249, 259], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnext50_32x4d": [[261, 273], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnext50_32x4d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "4", "\n", "return", "_resnet", "(", "'resnext50_32x4d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.resnext101_32x8d": [[275, 287], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "resnext101_32x8d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.wide_resnet50_2": [[289, 305], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "wide_resnet50_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet50_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta.wide_resnet101_2": [[307, 323], ["resnet_meta._resnet"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.resnet_meta._resnet"], ["", "def", "wide_resnet101_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet101_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wSGD.__init__": [[18, 32], ["dict", "Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1.0", ",", "momentum", "=", "0", ",", "dampening", "=", "0", ",", "\n", "weight_decay", "=", "0", ",", "nesterov", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "momentum", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid momentum value: {}\"", ".", "format", "(", "momentum", ")", ")", "\n", "", "if", "weight_decay", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid weight_decay value: {}\"", ".", "format", "(", "weight_decay", ")", ")", "\n", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "dampening", "=", "dampening", ",", "\n", "weight_decay", "=", "weight_decay", ",", "nesterov", "=", "nesterov", ")", "\n", "if", "nesterov", "and", "(", "momentum", "<=", "0", "or", "dampening", "!=", "0", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Nesterov momentum requires a momentum and zero dampening\"", ")", "\n", "", "super", "(", "wSGD", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wSGD.__setstate__": [[33, 37], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "SGD", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'nesterov'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wSGD.step": [[39, 85], ["enumerate", "len", "pnew.retain_grad", "d_p.add.add.add", "torch.clone().detach", "torch.clone().detach.mul_().add_", "d_p.add.add.add", "meta.detach_var", "torch.clone", "torch.clone().detach.mul_"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var"], ["", "", "def", "step", "(", "self", ",", "named_params", ",", "lumv", ")", ":", "\n", "\n", "# self.param_groups[0].keys() have 6 keys, including 'params' ", "\n", "# self.param_groups[0]['params'] len=num param group list", "\n", "# self.param_groups[0]['params'][i]  are tensors", "\n", "# for CNN, the shape above is [out_channel, in_channel, kernal_sz1, kernal_sz2]", "\n", "\n", "        ", "result_params", "=", "{", "}", "\n", "assert", "len", "(", "self", ".", "param_groups", ")", "==", "1", "\n", "\n", "group", "=", "self", ".", "param_groups", "[", "0", "]", "\n", "weight_decay", "=", "group", "[", "'weight_decay'", "]", "\n", "momentum", "=", "group", "[", "'momentum'", "]", "\n", "dampening", "=", "group", "[", "'dampening'", "]", "\n", "nesterov", "=", "group", "[", "'nesterov'", "]", "\n", "\n", "for", "i", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "named_params", ")", ":", "\n", "# print(name)", "\n", "# print( self.param_groups[0]['params'][1].grad)", "\n", "            ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                ", "continue", "\n", "", "d_p", "=", "p", ".", "grad", "\n", "if", "weight_decay", "!=", "0", ":", "\n", "                ", "d_p", "=", "d_p", ".", "add", "(", "p", ",", "alpha", "=", "weight_decay", ")", "\n", "", "if", "momentum", "!=", "0", ":", "\n", "                ", "param_state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "'momentum_buffer'", "not", "in", "param_state", ":", "\n", "                    ", "buf", "=", "param_state", "[", "'momentum_buffer'", "]", "=", "torch", ".", "clone", "(", "d_p", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                    ", "buf", "=", "param_state", "[", "'momentum_buffer'", "]", "\n", "buf", ".", "mul_", "(", "momentum", ")", ".", "add_", "(", "d_p", ",", "alpha", "=", "1", "-", "dampening", ")", "\n", "", "if", "nesterov", ":", "\n", "                    ", "d_p", "=", "d_p", ".", "add", "(", "buf", ",", "alpha", "=", "momentum", ")", "\n", "", "else", ":", "\n", "                    ", "d_p", "=", "buf", "\n", "", "", "lr", "=", "group", "[", "'lr'", "]", "*", "lumv", "[", "i", "]", "if", "lumv", "is", "not", "None", "else", "group", "[", "'lr'", "]", "\n", "# p.add_(d_p, alpha=-lr)", "\n", "# p = torch.add(p, -lr*d_p)", "\n", "\n", "# pnew = p - lr*detach_var(d_p)", "\n", "pnew", "=", "p", "-", "lr", "*", "detach_var", "(", "d_p", ")", "\n", "pnew", ".", "retain_grad", "(", ")", "\n", "result_params", "[", "name", "]", "=", "pnew", "\n", "\n", "\n", "", "return", "result_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.__init__": [[88, 103], ["dict", "Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1.0", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "weight_decay", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid weight_decay value: {}\"", ".", "format", "(", "weight_decay", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "wAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.__setstate__": [[104, 108], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "Adam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step": [[110, 174], ["utils.wz_FO_adam", "names.append", "params_with_grad.append", "grads.append", "exp_avgs.append", "exp_avg_sqs.append", "state_steps.append", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "max_exp_avg_sqs.append", "range", "torch.zeros_like", "len"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.wz_FO_adam", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "", "def", "step", "(", "self", ",", "named_params", ",", "lumv", ")", ":", "\n", "\n", "        ", "names", "=", "[", "]", "\n", "params_with_grad", "=", "[", "]", "\n", "grads", "=", "[", "]", "\n", "exp_avgs", "=", "[", "]", "\n", "exp_avg_sqs", "=", "[", "]", "\n", "state_sums", "=", "[", "]", "\n", "max_exp_avg_sqs", "=", "[", "]", "\n", "state_steps", "=", "[", "]", "\n", "group", "=", "self", ".", "param_groups", "[", "0", "]", "\n", "for", "name", ",", "p", "in", "named_params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "names", ".", "append", "(", "name", ")", "\n", "params_with_grad", ".", "append", "(", "p", ")", "\n", "if", "p", ".", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "", "grads", ".", "append", "(", "p", ".", "grad", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "# Lazy state initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ",", "memory_format", "=", "torch", ".", "preserve_format", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ",", "memory_format", "=", "torch", ".", "preserve_format", ")", "\n", "if", "group", "[", "'amsgrad'", "]", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ",", "memory_format", "=", "torch", ".", "preserve_format", ")", "\n", "\n", "", "", "exp_avgs", ".", "append", "(", "state", "[", "'exp_avg'", "]", ")", "\n", "exp_avg_sqs", ".", "append", "(", "state", "[", "'exp_avg_sq'", "]", ")", "\n", "\n", "if", "group", "[", "'amsgrad'", "]", ":", "\n", "                    ", "max_exp_avg_sqs", ".", "append", "(", "state", "[", "'max_exp_avg_sq'", "]", ")", "\n", "\n", "# update the steps for each param group update", "\n", "", "state", "[", "'step'", "]", "+=", "1", "\n", "# record the step after step update", "\n", "state_steps", ".", "append", "(", "state", "[", "'step'", "]", ")", "\n", "\n", "", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "if", "lumv", "is", "not", "None", ":", "\n", "            ", "lrs", "=", "lumv", "*", "group", "[", "'lr'", "]", "# [lv * group['lr'] for it in lumv]", "\n", "\n", "", "else", ":", "\n", "            ", "lrs", "=", "[", "group", "[", "'lr'", "]", "for", "_", "in", "range", "(", "len", "(", "params_with_grad", ")", ")", "]", "\n", "\n", "", "result_params", "=", "wz_FO_adam", "(", "names", ",", "params_with_grad", ",", "\n", "grads", ",", "\n", "exp_avgs", ",", "\n", "exp_avg_sqs", ",", "\n", "max_exp_avg_sqs", ",", "\n", "state_steps", ",", "\n", "group", "[", "'amsgrad'", "]", ",", "\n", "beta1", ",", "\n", "beta2", ",", "\n", "lrs", ",", "\n", "group", "[", "'weight_decay'", "]", ",", "\n", "group", "[", "'eps'", "]", "\n", ")", "\n", "return", "result_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.train_lumv_scratch": [[186, 224], ["Target_Optimizee().to", "LOWER_OPT", "len", "torch.tensor", "OPT_META_LUM", "tqdm", "torch.tensor.cpu().data.numpy().tolist", "print", "Target_Optimizee().to.parameters", "list", "itertools.chain.from_iterable", "range", "study_lum.run_epoch_lum", "meta.wzRec", "Target_Optimizee", "Target_Optimizee().to.parameters", "np.ones", "print", "x.cpu", "torch.tensor.cpu().data.numpy", "meta.eva_l2o_optimizer", "torch.tensor.cpu", "x.cpu"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.run_epoch_lum", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.eva_l2o_optimizer"], ["", "", "def", "train_lumv_scratch", "(", "args", ",", "LOWER_OPT", "=", "None", ",", "OPT_META_LUM", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "lumv_ini", "=", "None", ",", "n_epochs", "=", "20", ",", "lr_meta", "=", "None", ",", "studyLum_want_eva_in_training", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "optimizee", "=", "Target_Optimizee", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "\n", "# -- !!! DO NOT FEED **args INTO THIS !!! --", "\n", "lower_opt", "=", "LOWER_OPT", "(", "optimizee", ".", "parameters", "(", ")", ")", "\n", "\n", "N", "=", "len", "(", "list", "(", "optimizee", ".", "parameters", "(", ")", ")", ")", "\n", "# lumv = [torch.tensor(lumv_ini,requires_grad=True) for _ in range(N)]", "\n", "\n", "lumv", "=", "torch", ".", "tensor", "(", "np", ".", "ones", "(", "N", ",", "dtype", "=", "np", ".", "float32", ")", "*", "lumv_ini", ",", "requires_grad", "=", "True", ",", "device", "=", "DEVICE", ")", "\n", "# lumv = torch.tensor(np.ones(N)*lumv_ini,requires_grad=False)", "\n", "# aa=itertools.chain.from_iterable([[lumv]],)", "\n", "# for x in aa: print('????,',x)", "\n", "\n", "# lumv_cat = torch.cat([torch.unsqueeze(x,0) for x in lumv]).to(DEVICE)", "\n", "# lumv_cat.requires_grad=True", "\n", "meta_opt", "=", "OPT_META_LUM", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "lumv", ",", "]", "]", ")", ",", "lr", "=", "lr_meta", ")", "\n", "# lumv_cat.requires_grad=True", "\n", "\n", "\n", "\n", "for", "iepoch", "in", "tqdm", "(", "range", "(", "n_epochs", ")", ",", "'Meta training LUM'", ")", ":", "\n", "\n", "        ", "losses_1epoch", "=", "run_epoch_lum", "(", "args", ",", "lower_opt", ",", "lumv", ",", "meta_opt", ",", "**", "args", ")", "\n", "\n", "wzRec", "(", "losses_1epoch", ",", "'train-lumv-loss, epoch-{}'", ".", "format", "(", "iepoch", ")", ")", "\n", "\n", "\n", "if", "(", "iepoch", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "f'current lum:\\n     {[x.cpu().data for x in lumv]}'", ")", "\n", "if", "studyLum_want_eva_in_training", ":", "\n", "                ", "eva_l2o_optimizer", "(", "args", ",", "**", "args", ")", "\n", "\n", "", "", "", "lumv_list", "=", "[", "x", ".", "cpu", "(", ")", ".", "data", "for", "x", "in", "lumv", "]", "\n", "lumv_list", "=", "lumv", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "f'finished, lumv = \\n\\t {lumv_list}'", ")", "\n", "return", "lumv", ",", "lumv_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.run_epoch_lum": [[227, 285], ["Target_DataGen", "Target_Optimizee().to", "meta_opt.zero_grad", "range", "tqdm", "Target_Optimizee().to.", "losses_1epoch.append", "optimizee.backward", "lower_opt.step", "Target_Optimizee", "range", "optimizee.data.cpu().numpy", "Target_Optimizee().to.named_parameters", "Target_Optimizee().to", "meta.updateDict_skip_running", "Target_Optimizee().to.zero_grad", "Target_Optimizee().to.named_parameters", "meta_opt.zero_grad", "Target_Optimizee().to.", "all_losses.backward", "meta_opt.step", "meta.rsetattr", "optimizee.data.cpu", "Target_Optimizee"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.updateDict_skip_running", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr"], ["", "def", "run_epoch_lum", "(", "args", ",", "lower_opt", ",", "lumv", ",", "meta_opt", ",", "Target_DataGen", ",", "Target_Optimizee", ",", "epoch_len", ",", "should_train", "=", "False", ",", "unroll", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "not", "should_train", ":", "\n", "        ", "unroll", "=", "1", "\n", "\n", "", "target", "=", "Target_DataGen", "(", "**", "args", ")", "\n", "optimizee", "=", "Target_Optimizee", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "# viz(optimizee,'optimizee')", "\n", "\n", "\n", "# n_params = 0", "\n", "# sets = []", "\n", "# for i, p in enumerate(params):", "\n", "#     N_this = np.prod(p.size())", "\n", "#     n_params += int(N_this)", "\n", "#     sets.append(i)", "\n", "\n", "\n", "\n", "losses_1epoch", ",", "all_losses", "=", "[", "]", ",", "None", "\n", "\n", "if", "should_train", ":", "\n", "        ", "meta_opt", ".", "zero_grad", "(", ")", "\n", "iterator", "=", "range", "(", "1", ",", "epoch_len", "+", "1", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "epoch_len", "+", "1", ")", ",", "'Eva: '", ")", "\n", "\n", "\n", "", "for", "iteration", "in", "iterator", ":", "\n", "\n", "# cal loss", "\n", "        ", "loss", "=", "optimizee", "(", "target", ")", "\n", "all_losses", "=", "loss", "if", "all_losses", "is", "None", "else", "all_losses", "+", "loss", "\n", "\n", "losses_1epoch", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "should_train", ")", "\n", "result_params", "=", "lower_opt", ".", "step", "(", "optimizee", ".", "named_parameters", "(", ")", ",", "lumv", ")", "\n", "\n", "\n", "if", "iteration", "%", "unroll", "==", "0", ":", "\n", "\n", "            ", "if", "should_train", ":", "\n", "                ", "meta_opt", ".", "zero_grad", "(", ")", "\n", "all_losses", "+=", "optimizee", "(", "target", ")", "\n", "all_losses", ".", "backward", "(", ")", "\n", "meta_opt", ".", "step", "(", ")", "\n", "\n", "", "all_losses", "=", "None", "\n", "optimizee", "=", "Target_Optimizee", "(", ")", ".", "to", "(", "DEVICE", ")", "\n", "# optimizee.load_state_dict(result_params)", "\n", "updateDict_skip_running", "(", "optimizee", ",", "result_params", ")", "\n", "\n", "optimizee", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "p", "in", "optimizee", ".", "named_parameters", "(", ")", ":", "\n", "                ", "rsetattr", "(", "optimizee", ",", "name", ",", "result_params", "[", "name", "]", ")", "\n", "\n", "", "", "", "return", "losses_1epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters": [[19, 22], ["meta_module.MetaModule.named_params"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params"], ["    ", "def", "parameters", "(", "self", ")", ":", "\n", "       ", "for", "name", ",", "param", "in", "self", ".", "named_params", "(", "self", ")", ":", "\n", "            ", "yield", "param", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters": [[23, 26], ["meta_module.MetaModule.named_params"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params"], ["", "", "def", "named_parameters", "(", "self", ")", ":", "\n", "       ", "for", "name", ",", "param", "in", "self", ".", "named_params", "(", "self", ")", ":", "\n", "            ", "yield", "name", ",", "param", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_leaves": [[27, 29], ["None"], "methods", ["None"], ["", "", "def", "named_leaves", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_submodules": [[30, 32], ["None"], "methods", ["None"], ["", "def", "named_submodules", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params": [[33, 52], ["hasattr", "curr_module.named_children", "set", "curr_module.named_leaves", "curr_module._parameters.items", "meta_module.MetaModule.named_params", "set.add", "set.add"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaBatchNorm2d.named_leaves", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params"], ["", "def", "named_params", "(", "self", ",", "curr_module", "=", "None", ",", "memo", "=", "None", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "if", "memo", "is", "None", ":", "\n", "            ", "memo", "=", "set", "(", ")", "\n", "\n", "", "if", "hasattr", "(", "curr_module", ",", "'named_leaves'", ")", ":", "\n", "            ", "for", "name", ",", "p", "in", "curr_module", ".", "named_leaves", "(", ")", ":", "\n", "                ", "if", "p", "is", "not", "None", "and", "p", "not", "in", "memo", ":", "\n", "                    ", "memo", ".", "add", "(", "p", ")", "\n", "yield", "prefix", "+", "(", "'.'", "if", "prefix", "else", "''", ")", "+", "name", ",", "p", "\n", "", "", "", "else", ":", "\n", "            ", "for", "name", ",", "p", "in", "curr_module", ".", "_parameters", ".", "items", "(", ")", ":", "\n", "                ", "if", "p", "is", "not", "None", "and", "p", "not", "in", "memo", ":", "\n", "                    ", "memo", ".", "add", "(", "p", ")", "\n", "yield", "prefix", "+", "(", "'.'", "if", "prefix", "else", "''", ")", "+", "name", ",", "p", "\n", "\n", "", "", "", "for", "mname", ",", "module", "in", "curr_module", ".", "named_children", "(", ")", ":", "\n", "            ", "submodule_prefix", "=", "prefix", "+", "(", "'.'", "if", "prefix", "else", "''", ")", "+", "mname", "\n", "for", "name", ",", "p", "in", "self", ".", "named_params", "(", "module", ",", "memo", ",", "submodule_prefix", ")", ":", "\n", "                ", "yield", "name", ",", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.update_params": [[53, 76], ["zip", "meta_module.MetaModule.named_params", "meta_module.MetaModule.named_params", "meta_module.MetaModule.set_param", "meta_module.to_var", "meta_module.MetaModule.set_param", "param.detach_.detach_.detach_", "meta_module.MetaModule.set_param", "meta_module.to_var", "to_var.detach", "to_var.detach"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["", "", "", "def", "update_params", "(", "self", ",", "lr_inner", ",", "first_order", "=", "False", ",", "source_params", "=", "None", ",", "detach", "=", "False", ")", ":", "\n", "        ", "if", "source_params", "is", "not", "None", ":", "\n", "            ", "for", "tgt", ",", "src", "in", "zip", "(", "self", ".", "named_params", "(", "self", ")", ",", "source_params", ")", ":", "\n", "                ", "name_t", ",", "param_t", "=", "tgt", "\n", "# name_s, param_s = src", "\n", "# grad = param_s.grad", "\n", "# name_s, param_s = src", "\n", "grad", "=", "src", "\n", "if", "first_order", ":", "\n", "                    ", "grad", "=", "to_var", "(", "grad", ".", "detach", "(", ")", ".", "data", ")", "\n", "", "tmp", "=", "param_t", "-", "lr_inner", "*", "grad", "\n", "self", ".", "set_param", "(", "self", ",", "name_t", ",", "tmp", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "name", ",", "param", "in", "self", ".", "named_params", "(", "self", ")", ":", "\n", "                ", "if", "not", "detach", ":", "\n", "                    ", "grad", "=", "param", ".", "grad", "\n", "if", "first_order", ":", "\n", "                        ", "grad", "=", "to_var", "(", "grad", ".", "detach", "(", ")", ".", "data", ")", "\n", "", "tmp", "=", "param", "-", "lr_inner", "*", "grad", "\n", "self", ".", "set_param", "(", "self", ",", "name", ",", "tmp", ")", "\n", "", "else", ":", "\n", "                    ", "param", "=", "param", ".", "detach_", "(", ")", "\n", "self", ".", "set_param", "(", "self", ",", "name", ",", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param": [[77, 88], ["name.split", "curr_mod.named_children", "setattr", "meta_module.MetaModule.set_param"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param"], ["", "", "", "", "def", "set_param", "(", "self", ",", "curr_mod", ",", "name", ",", "param", ")", ":", "\n", "        ", "if", "'.'", "in", "name", ":", "\n", "            ", "n", "=", "name", ".", "split", "(", "'.'", ")", "\n", "module_name", "=", "n", "[", "0", "]", "\n", "rest", "=", "'.'", ".", "join", "(", "n", "[", "1", ":", "]", ")", "\n", "for", "name", ",", "mod", "in", "curr_mod", ".", "named_children", "(", ")", ":", "\n", "                ", "if", "module_name", "==", "name", ":", "\n", "                    ", "self", ".", "set_param", "(", "mod", ",", "rest", ",", "param", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "setattr", "(", "curr_mod", ",", "name", ",", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.detach_params": [[89, 92], ["meta_module.MetaModule.named_params", "meta_module.MetaModule.set_param", "param.detach"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param"], ["", "", "def", "detach_params", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "self", ".", "named_params", "(", "self", ")", ":", "\n", "            ", "self", ".", "set_param", "(", "self", ",", "name", ",", "param", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy": [[93, 98], ["other.named_params", "meta_module.MetaModule.set_param", "meta_module.to_var", "to_var.data.clone"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_params", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.set_param", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["", "", "def", "copy", "(", "self", ",", "other", ",", "same_var", "=", "False", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "other", ".", "named_params", "(", ")", ":", "\n", "            ", "if", "not", "same_var", ":", "\n", "                ", "param", "=", "to_var", "(", "param", ".", "data", ".", "clone", "(", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "set_param", "(", "name", ",", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaLinear.__init__": [[101, 109], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "meta_module.MetaLinear.register_buffer", "meta_module.MetaLinear.register_buffer", "torch.Linear.weight.size", "torch.Linear.weight.size", "meta_module.to_var", "meta_module.to_var"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "ignore", "=", "nn", ".", "Linear", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'weight'", ",", "to_var", "(", "ignore", ".", "weight", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "register_buffer", "(", "'bias'", ",", "to_var", "(", "ignore", ".", "bias", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "in_features", "=", "ignore", ".", "weight", ".", "size", "(", "1", ")", "\n", "self", ".", "out_features", "=", "ignore", ".", "weight", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaLinear.forward": [[110, 112], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaLinear.named_leaves": [[113, 115], ["None"], "methods", ["None"], ["", "def", "named_leaves", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "'weight'", ",", "self", ".", "weight", ")", ",", "(", "'bias'", ",", "self", ".", "bias", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConv2d.__init__": [[117, 132], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "meta_module.MetaConv2d.register_buffer", "meta_module.to_var", "meta_module.MetaConv2d.register_buffer", "meta_module.MetaConv2d.register_buffer", "meta_module.to_var"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "ignore", "=", "nn", ".", "Conv2d", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "stride", "=", "ignore", ".", "stride", "\n", "self", ".", "padding", "=", "ignore", ".", "padding", "\n", "self", ".", "dilation", "=", "ignore", ".", "dilation", "\n", "self", ".", "groups", "=", "ignore", ".", "groups", "\n", "\n", "self", ".", "register_buffer", "(", "'weight'", ",", "to_var", "(", "ignore", ".", "weight", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "if", "ignore", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'bias'", ",", "to_var", "(", "ignore", ".", "bias", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'bias'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConv2d.forward": [[133, 135], ["torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "conv2d", "(", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConv2d.named_leaves": [[136, 138], ["None"], "methods", ["None"], ["", "def", "named_leaves", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "'weight'", ",", "self", ".", "weight", ")", ",", "(", "'bias'", ",", "self", ".", "bias", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConvTranspose2d.__init__": [[140, 155], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "meta_module.MetaConvTranspose2d.register_buffer", "meta_module.to_var", "meta_module.MetaConvTranspose2d.register_buffer", "meta_module.MetaConvTranspose2d.register_buffer", "meta_module.to_var"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "ignore", "=", "nn", ".", "ConvTranspose2d", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "stride", "=", "ignore", ".", "stride", "\n", "self", ".", "padding", "=", "ignore", ".", "padding", "\n", "self", ".", "dilation", "=", "ignore", ".", "dilation", "\n", "self", ".", "groups", "=", "ignore", ".", "groups", "\n", "\n", "self", ".", "register_buffer", "(", "'weight'", ",", "to_var", "(", "ignore", ".", "weight", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "if", "ignore", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'bias'", ",", "to_var", "(", "ignore", ".", "bias", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'bias'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConvTranspose2d.forward": [[156, 160], ["meta_module.MetaConvTranspose2d._output_padding", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "output_size", "=", "None", ")", ":", "\n", "        ", "output_padding", "=", "self", ".", "_output_padding", "(", "x", ",", "output_size", ")", "\n", "return", "F", ".", "conv_transpose2d", "(", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "\n", "output_padding", ",", "self", ".", "groups", ",", "self", ".", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaConvTranspose2d.named_leaves": [[161, 163], ["None"], "methods", ["None"], ["", "def", "named_leaves", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "'weight'", ",", "self", ".", "weight", ")", ",", "(", "'bias'", ",", "self", ".", "bias", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaBatchNorm2d.__init__": [[165, 185], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "meta_module.MetaBatchNorm2d.register_buffer", "meta_module.MetaBatchNorm2d.register_buffer", "meta_module.MetaBatchNorm2d.register_buffer", "meta_module.MetaBatchNorm2d.register_buffer", "meta_module.MetaBatchNorm2d.register_parameter", "meta_module.MetaBatchNorm2d.register_parameter", "meta_module.to_var", "meta_module.to_var", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "ignore", "=", "nn", ".", "BatchNorm2d", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "num_features", "=", "ignore", ".", "num_features", "\n", "self", ".", "eps", "=", "ignore", ".", "eps", "\n", "self", ".", "momentum", "=", "ignore", ".", "momentum", "\n", "self", ".", "affine", "=", "ignore", ".", "affine", "\n", "self", ".", "track_running_stats", "=", "ignore", ".", "track_running_stats", "\n", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'weight'", ",", "to_var", "(", "ignore", ".", "weight", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "register_buffer", "(", "'bias'", ",", "to_var", "(", "ignore", ".", "bias", ".", "data", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "", "if", "self", ".", "track_running_stats", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "self", ".", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "self", ".", "num_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'running_mean'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'running_var'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaBatchNorm2d.forward": [[187, 190], ["torch.batch_norm", "torch.batch_norm", "torch.batch_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "batch_norm", "(", "x", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "\n", "self", ".", "training", "or", "not", "self", ".", "track_running_stats", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaBatchNorm2d.named_leaves": [[191, 193], ["None"], "methods", ["None"], ["", "def", "named_leaves", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "'weight'", ",", "self", ".", "weight", ")", ",", "(", "'bias'", ",", "self", ".", "bias", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__init__": [[219, 227], ["torch.Module.__init__", "isinstance", "args[].items", "enumerate", "len", "meta_module.MetaSequential.add_module", "meta_module.MetaSequential.add_module", "str"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "MetaSequential", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "len", "(", "args", ")", "==", "1", "and", "isinstance", "(", "args", "[", "0", "]", ",", "OrderedDict", ")", ":", "\n", "            ", "for", "key", ",", "module", "in", "args", "[", "0", "]", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "key", ",", "module", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "idx", ",", "module", "in", "enumerate", "(", "args", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "str", "(", "idx", ")", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential._get_item_by_idx": [[228, 236], ["len", "operator.index", "next", "IndexError", "itertools.islice"], "methods", ["None"], ["", "", "", "def", "_get_item_by_idx", "(", "self", ",", "iterator", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get the idx-th item of the iterator\"\"\"", "\n", "size", "=", "len", "(", "self", ")", "\n", "idx", "=", "operator", ".", "index", "(", "idx", ")", "\n", "if", "not", "-", "size", "<=", "idx", "<", "size", ":", "\n", "            ", "raise", "IndexError", "(", "'index {} is out of range'", ".", "format", "(", "idx", ")", ")", "\n", "", "idx", "%=", "size", "\n", "return", "next", "(", "islice", "(", "iterator", ",", "idx", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__getitem__": [[237, 242], ["isinstance", "meta_module.MetaSequential.__class__", "meta_module.MetaSequential._get_item_by_idx", "collections.OrderedDict", "meta_module.MetaSequential._modules.values", "list", "meta_module.MetaSequential._modules.items"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential._get_item_by_idx", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "return", "self", ".", "__class__", "(", "OrderedDict", "(", "list", "(", "self", ".", "_modules", ".", "items", "(", ")", ")", "[", "idx", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_get_item_by_idx", "(", "self", ".", "_modules", ".", "values", "(", ")", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__setitem__": [[243, 246], ["meta_module.MetaSequential._get_item_by_idx", "setattr", "meta_module.MetaSequential._modules.keys"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential._get_item_by_idx", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.keys"], ["", "", "def", "__setitem__", "(", "self", ",", "idx", ",", "module", ")", ":", "\n", "        ", "key", "=", "self", ".", "_get_item_by_idx", "(", "self", ".", "_modules", ".", "keys", "(", ")", ",", "idx", ")", "\n", "return", "setattr", "(", "self", ",", "key", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__delitem__": [[247, 254], ["isinstance", "meta_module.MetaSequential._get_item_by_idx", "delattr", "list", "delattr", "meta_module.MetaSequential._modules.keys", "meta_module.MetaSequential._modules.keys"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential._get_item_by_idx", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.keys", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.keys"], ["", "def", "__delitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "for", "key", "in", "list", "(", "self", ".", "_modules", ".", "keys", "(", ")", ")", "[", "idx", "]", ":", "\n", "                ", "delattr", "(", "self", ",", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "_get_item_by_idx", "(", "self", ".", "_modules", ".", "keys", "(", ")", ",", "idx", ")", "\n", "delattr", "(", "self", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__len__": [[255, 257], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.__dir__": [[258, 262], ["torch.Module.__dir__", "key.isdigit"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__dir__"], ["", "def", "__dir__", "(", "self", ")", ":", "\n", "        ", "keys", "=", "super", "(", "Sequential", ",", "self", ")", ".", "__dir__", "(", ")", "\n", "keys", "=", "[", "key", "for", "key", "in", "keys", "if", "not", "key", ".", "isdigit", "(", ")", "]", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaSequential.forward": [[263, 267], ["meta_module.MetaSequential._modules.values", "module"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "for", "module", "in", "self", ".", "_modules", ".", "values", "(", ")", ":", "\n", "            ", "input", "=", "module", "(", "input", ")", "\n", "", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__init__": [[293, 297], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "modules", "=", "None", ")", ":", "\n", "        ", "super", "(", "MetaModuleList", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "modules", "is", "not", "None", ":", "\n", "            ", "self", "+=", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList._get_abs_string_index": [[298, 306], ["operator.index", "str", "IndexError", "len", "len", "len"], "methods", ["None"], ["", "", "def", "_get_abs_string_index", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get the absolute index for the list of modules\"\"\"", "\n", "idx", "=", "operator", ".", "index", "(", "idx", ")", "\n", "if", "not", "(", "-", "len", "(", "self", ")", "<=", "idx", "<", "len", "(", "self", ")", ")", ":", "\n", "            ", "raise", "IndexError", "(", "'index {} is out of range'", ".", "format", "(", "idx", ")", ")", "\n", "", "if", "idx", "<", "0", ":", "\n", "            ", "idx", "+=", "len", "(", "self", ")", "\n", "", "return", "str", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__getitem__": [[307, 312], ["isinstance", "meta_module.MetaModuleList.__class__", "list", "meta_module.MetaModuleList._get_abs_string_index", "meta_module.MetaModuleList._modules.values"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList._get_abs_string_index", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "return", "self", ".", "__class__", "(", "list", "(", "self", ".", "_modules", ".", "values", "(", ")", ")", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_modules", "[", "self", ".", "_get_abs_string_index", "(", "idx", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__setitem__": [[313, 316], ["meta_module.MetaModuleList._get_abs_string_index", "setattr", "str"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList._get_abs_string_index"], ["", "", "def", "__setitem__", "(", "self", ",", "idx", ",", "module", ")", ":", "\n", "        ", "idx", "=", "self", ".", "_get_abs_string_index", "(", "idx", ")", "\n", "return", "setattr", "(", "self", ",", "str", "(", "idx", ")", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__delitem__": [[317, 326], ["isinstance", "collections.OrderedDict", "delattr", "str", "list", "range", "delattr", "meta_module.MetaModuleList._get_abs_string_index", "range", "zip", "len", "str", "len", "meta_module.MetaModuleList._modules.values"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList._get_abs_string_index", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values"], ["", "def", "__delitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "self", ".", "_modules", ")", ")", "[", "idx", "]", ":", "\n", "                ", "delattr", "(", "self", ",", "str", "(", "k", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "delattr", "(", "self", ",", "self", ".", "_get_abs_string_index", "(", "idx", ")", ")", "\n", "# To preserve numbering, self._modules is being reconstructed with modules after deletion", "\n", "", "str_indices", "=", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_modules", ")", ")", "]", "\n", "self", ".", "_modules", "=", "OrderedDict", "(", "list", "(", "zip", "(", "str_indices", ",", "self", ".", "_modules", ".", "values", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__len__": [[327, 329], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__iter__": [[330, 332], ["iter", "meta_module.MetaModuleList._modules.values"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "_modules", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__iadd__": [[333, 335], ["meta_module.MetaModuleList.extend"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend"], ["", "def", "__iadd__", "(", "self", ",", "modules", ")", ":", "\n", "        ", "return", "self", ".", "extend", "(", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__dir__": [[336, 340], ["torch.Module.__dir__", "key.isdigit"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.__dir__"], ["", "def", "__dir__", "(", "self", ")", ":", "\n", "        ", "keys", "=", "super", "(", "ModuleList", ",", "self", ")", ".", "__dir__", "(", ")", "\n", "keys", "=", "[", "key", "for", "key", "in", "keys", "if", "not", "key", ".", "isdigit", "(", ")", "]", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.insert": [[341, 351], ["range", "len", "str", "str", "str"], "methods", ["None"], ["", "def", "insert", "(", "self", ",", "index", ",", "module", ")", ":", "\n", "        ", "r\"\"\"Insert a given module before a given index in the list.\n\n        Arguments:\n            index (int): index to insert.\n            module (MetaModule): module to insert\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_modules", ")", ",", "index", ",", "-", "1", ")", ":", "\n", "            ", "self", ".", "_modules", "[", "str", "(", "i", ")", "]", "=", "self", ".", "_modules", "[", "str", "(", "i", "-", "1", ")", "]", "\n", "", "self", ".", "_modules", "[", "str", "(", "index", ")", "]", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append": [[353, 361], ["meta_module.MetaModuleList.add_module", "str", "len"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "module", ")", ":", "\n", "        ", "r\"\"\"Appends a given module to the end of the list.\n\n        Arguments:\n            module (MetaModule): module to append\n        \"\"\"", "\n", "self", ".", "add_module", "(", "str", "(", "len", "(", "self", ")", ")", ",", "module", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend": [[363, 376], ["len", "enumerate", "isinstance", "TypeError", "meta_module.MetaModuleList.add_module", "str", "type"], "methods", ["None"], ["", "def", "extend", "(", "self", ",", "modules", ")", ":", "\n", "        ", "r\"\"\"Appends modules from a Python iterable to the end of the list.\n\n        Arguments:\n            modules (iterable): iterable of modules to append\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "modules", ",", "container_abcs", ".", "Iterable", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"ModuleList.extend should be called with an \"", "\n", "\"iterable, but got \"", "+", "type", "(", "modules", ")", ".", "__name__", ")", "\n", "", "offset", "=", "len", "(", "self", ")", "\n", "for", "i", ",", "module", "in", "enumerate", "(", "modules", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "str", "(", "offset", "+", "i", ")", ",", "module", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__init__": [[421, 425], ["torch.Module.__init__", "meta_module.ModuleDict.update"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update"], ["def", "__init__", "(", "self", ",", "modules", "=", "None", ")", ":", "\n", "        ", "super", "(", "MetaModuleDict", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "modules", "is", "not", "None", ":", "\n", "            ", "self", ".", "update", "(", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__getitem__": [[426, 428], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_modules", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__setitem__": [[429, 431], ["meta_module.ModuleDict.add_module"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "module", ")", ":", "\n", "        ", "self", ".", "add_module", "(", "key", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__delitem__": [[432, 434], ["None"], "methods", ["None"], ["", "def", "__delitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "del", "self", ".", "_modules", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__len__": [[435, 437], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__iter__": [[438, 440], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__contains__": [[441, 443], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "key", "in", "self", ".", "_modules", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.clear": [[444, 448], ["meta_module.ModuleDict._modules.clear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "\"\"\"Remove all items from the ModuleDict.\n        \"\"\"", "\n", "self", ".", "_modules", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.pop": [[450, 459], ["None"], "methods", ["None"], ["", "def", "pop", "(", "self", ",", "key", ")", ":", "\n", "        ", "r\"\"\"Remove key from the ModuleDict and return its module.\n\n        Arguments:\n            key (string): key to pop from the ModuleDict\n        \"\"\"", "\n", "v", "=", "self", "[", "key", "]", "\n", "del", "self", "[", "key", "]", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.keys": [[461, 465], ["meta_module.ModuleDict._modules.keys"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Return an iterable of the ModuleDict keys.\n        \"\"\"", "\n", "return", "self", ".", "_modules", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items": [[467, 471], ["meta_module.ModuleDict._modules.items"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Return an iterable of the ModuleDict key/value pairs.\n        \"\"\"", "\n", "return", "self", ".", "_modules", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values": [[473, 477], ["meta_module.ModuleDict._modules.values"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.values"], ["", "def", "values", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Return an iterable of the ModuleDict values.\n        \"\"\"", "\n", "return", "self", ".", "_modules", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update": [[479, 514], ["isinstance", "isinstance", "TypeError", "isinstance", "enumerate", "modules.items", "sorted", "modules.items", "isinstance", "TypeError", "ValueError", "type", "len", "type", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.items"], ["", "def", "update", "(", "self", ",", "modules", ")", ":", "\n", "        ", "r\"\"\"Update the :class:`~MetaModuleDict` with the key-value pairs from a\n        mapping or an iterable, overwriting existing keys.\n\n        .. note::\n            If :attr:`modules` is an ``OrderedDict``, a :class:`~MetaModuleDict`, or\n            an iterable of key-value pairs, the order of new elements in it is preserved.\n\n        Arguments:\n            modules (iterable): a mapping (dictionary) from string to :class:`~MetaModule`,\n                or an iterable of key-value pairs of type (string, :class:`~MetaModule`)\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "modules", ",", "container_abcs", ".", "Iterable", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"ModuleDict.update should be called with an \"", "\n", "\"iterable of key/value pairs, but got \"", "+", "\n", "type", "(", "modules", ")", ".", "__name__", ")", "\n", "\n", "", "if", "isinstance", "(", "modules", ",", "container_abcs", ".", "Mapping", ")", ":", "\n", "            ", "if", "isinstance", "(", "modules", ",", "(", "OrderedDict", ",", "ModuleDict", ")", ")", ":", "\n", "                ", "for", "key", ",", "module", "in", "modules", ".", "items", "(", ")", ":", "\n", "                    ", "self", "[", "key", "]", "=", "module", "\n", "", "", "else", ":", "\n", "                ", "for", "key", ",", "module", "in", "sorted", "(", "modules", ".", "items", "(", ")", ")", ":", "\n", "                    ", "self", "[", "key", "]", "=", "module", "\n", "", "", "", "else", ":", "\n", "            ", "for", "j", ",", "m", "in", "enumerate", "(", "modules", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "m", ",", "container_abcs", ".", "Iterable", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "\"ModuleDict update sequence element \"", "\n", "\"#\"", "+", "str", "(", "j", ")", "+", "\" should be Iterable; is\"", "+", "\n", "type", "(", "m", ")", ".", "__name__", ")", "\n", "", "if", "not", "len", "(", "m", ")", "==", "2", ":", "\n", "                    ", "raise", "ValueError", "(", "\"ModuleDict update sequence element \"", "\n", "\"#\"", "+", "str", "(", "j", ")", "+", "\" has length \"", "+", "str", "(", "len", "(", "m", ")", ")", "+", "\n", "\"; 2 is required\"", ")", "\n", "", "self", "[", "m", "[", "0", "]", "]", "=", "m", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.forward": [[515, 517], ["NotImplementedError"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.LeNet.__init__": [[521, 544], ["torch.Module.__init__", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "layers.append", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "meta_module.MetaConv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "meta_module.MetaConv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "meta_module.MetaConv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "meta_module.MetaLinear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "meta_module.MetaLinear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["    ", "def", "__init__", "(", "self", ",", "n_out", ")", ":", "\n", "        ", "super", "(", "LeNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "MetaConv2d", "(", "1", ",", "6", ",", "kernel_size", "=", "5", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ")", "\n", "\n", "layers", ".", "append", "(", "MetaConv2d", "(", "6", ",", "16", ",", "kernel_size", "=", "5", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ")", "\n", "\n", "layers", ".", "append", "(", "MetaConv2d", "(", "16", ",", "120", ",", "kernel_size", "=", "5", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "MetaLinear", "(", "120", ",", "84", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "MetaLinear", "(", "84", ",", "n_out", ")", ")", "\n", "\n", "self", ".", "fc_layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.LeNet.forward": [[545, 549], ["meta_module.LeNet.main", "x.view.view.view", "meta_module.LeNet.fc_layers().squeeze", "meta_module.LeNet.fc_layers"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.evaluate_dm.main"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "main", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "120", ")", "\n", "return", "self", ".", "fc_layers", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.to_var": [[12, 16], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.autograd.Variable", "x.cuda.cuda"], "function", ["None"], ["def", "to_var", "(", "x", ",", "requires_grad", "=", "True", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "", "return", "Variable", "(", "x", ",", "requires_grad", "=", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MNISTLoss.__init__": [[223, 241], ["torchvision.transforms.Compose", "datasets.MNIST", "list", "np.random.RandomState().shuffle", "torch.utils.data.DataLoader", "range", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "len", "np.random.RandomState", "torch.utils.data.sampler.SubsetRandomSampler", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "training", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "trans", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ",", "torchvision", ".", "transforms", ".", "Normalize", "(", "(", "0.5", ",", ")", ",", "(", "1.0", ",", ")", ")", "]", ")", "\n", "dataset", "=", "datasets", ".", "MNIST", "(", "\n", "'./datasets'", ",", "train", "=", "True", ",", "download", "=", "False", ",", "\n", "transform", "=", "trans", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "np", ".", "random", ".", "RandomState", "(", "10", ")", ".", "shuffle", "(", "indices", ")", "\n", "if", "training", ":", "\n", "            ", "indices", "=", "indices", "[", ":", "len", "(", "indices", ")", "//", "2", "]", "\n", "", "else", ":", "\n", "            ", "indices", "=", "indices", "[", "len", "(", "indices", ")", "//", "2", ":", "]", "\n", "\n", "", "self", ".", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "128", ",", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SubsetRandomSampler", "(", "indices", ")", ")", "\n", "\n", "self", ".", "batches", "=", "[", "]", "\n", "self", ".", "cur_batch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MNISTLoss.sample": [[242, 255], ["len", "print", "print", "utils.MNISTLoss.batches.append"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cur_batch", ">=", "len", "(", "self", ".", "batches", ")", ":", "\n", "            ", "print", "(", "'\\nnew sample!!!\\n'", ")", "\n", "self", ".", "batches", "=", "[", "]", "\n", "self", ".", "cur_batch", "=", "0", "\n", "for", "b", "in", "self", ".", "loader", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "b", ")", "\n", "", "print", "(", "'\\nnew sample ,  DONE. !!!\\n'", ")", "\n", "", "batch", "=", "self", ".", "batches", "[", "self", ".", "cur_batch", "]", "\n", "self", ".", "cur_batch", "+=", "1", "\n", "# print(batch.shape)", "\n", "# raise", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_half.__init__": [[258, 271], ["transforms.Compose", "utils.CIFAR10_halfLabel", "torch.utils.data.DataLoader", "transforms.ToTensor", "transforms.Normalize", "bool", "bool"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cifarAB", "=", "'A'", ",", "training", "=", "True", ",", "shuffle_cifar", "=", "True", ",", "num_workers", "=", "2", ",", "batch_size", "=", "128", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "cifar_roots", "=", "{", "'A'", ":", "'datasets/cifar10-A'", ",", "\n", "'B'", ":", "'datasets/cifar10-B'", "}", "\n", "root", "=", "cifar_roots", "[", "cifarAB", "]", "\n", "self", ".", "cifarAB", "=", "cifarAB", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "dataset", "=", "CIFAR10_halfLabel", "(", "root", "=", "root", ",", "train", "=", "bool", "(", "training", ")", ",", "transform", "=", "transform", ")", "\n", "self", ".", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "bool", "(", "shuffle_cifar", ")", ",", "num_workers", "=", "num_workers", ")", "\n", "\n", "self", ".", "batches", "=", "[", "]", "\n", "self", ".", "cur_batch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_half.sample": [[273, 284], ["len", "print", "print", "utils.Cifar_half.batches.append"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cur_batch", ">=", "len", "(", "self", ".", "batches", ")", ":", "\n", "            ", "print", "(", "'\\nnew sample!!!\\n'", ")", "\n", "self", ".", "batches", "=", "[", "]", "\n", "self", ".", "cur_batch", "=", "0", "\n", "for", "b", "in", "self", ".", "loader", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "b", ")", "\n", "", "print", "(", "'\\nnew sample ,  DONE. !!!\\n'", ")", "\n", "", "batch", "=", "self", ".", "batches", "[", "self", ".", "cur_batch", "]", "\n", "self", ".", "cur_batch", "+=", "1", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MNISTLoss_f.__init__": [[286, 302], ["torchvision.transforms.Compose", "datasets.MNIST", "list", "np.random.RandomState().shuffle", "utils.get_infinite_iter", "range", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "len", "np.random.RandomState", "torch.utils.data.sampler.SubsetRandomSampler", "len", "len"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter"], ["    ", "def", "__init__", "(", "self", ",", "training", "=", "True", ",", "num_workers", "=", "2", ",", "batch_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "trans", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ",", "torchvision", ".", "transforms", ".", "Normalize", "(", "(", "0.5", ",", ")", ",", "(", "1.0", ",", ")", ")", "]", ")", "\n", "\n", "dataset", "=", "datasets", ".", "MNIST", "(", "\n", "'./datasets'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "trans", ")", "\n", "\n", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", "# len = 60000", "\n", "np", ".", "random", ".", "RandomState", "(", "10", ")", ".", "shuffle", "(", "indices", ")", "\n", "if", "training", ":", "\n", "            ", "indices", "=", "indices", "[", ":", "len", "(", "indices", ")", "//", "2", "]", "\n", "", "else", ":", "\n", "            ", "indices", "=", "indices", "[", "len", "(", "indices", ")", "//", "2", ":", "]", "\n", "\n", "", "self", ".", "infIter", "=", "get_infinite_iter", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SubsetRandomSampler", "(", "indices", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MNISTLoss_f.sample": [[303, 319], ["utils.MNISTLoss_f.infIter.sample"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "\n", "\n", "\n", "        ", "samp", "=", "self", ".", "infIter", ".", "sample", "(", ")", "\n", "# print(f'''\\n\\n\\n{(", "\n", "#     )}\\n\\n\\n''');", "\n", "# print(samp[0].shape)", "\n", "# from w import viz_imgs", "\n", "# plt.imshow(samp[0][33,0,...])", "\n", "# print(samp[0][33,0,...].shape)", "\n", "# viz_imgs(samp[0][:10,...])", "\n", "# print(samp[1])", "\n", "\n", "# raise", "\n", "return", "samp", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_half_f.__init__": [[322, 333], ["transforms.Compose", "utils.CIFAR10_halfLabel", "utils.get_infinite_iter", "transforms.ToTensor", "transforms.Normalize", "bool"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter"], ["    ", "def", "__init__", "(", "self", ",", "cifarAB", "=", "'A'", ",", "training", "=", "True", ",", "shuffle_cifar", "=", "True", ",", "num_workers", "=", "2", ",", "batch_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "cifar_roots", "=", "{", "'A'", ":", "'datasets/cifar10-A'", ",", "\n", "'B'", ":", "'datasets/cifar10-B'", "}", "\n", "root", "=", "cifar_roots", "[", "cifarAB", "]", "\n", "self", ".", "cifarAB", "=", "cifarAB", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "dataset", "=", "CIFAR10_halfLabel", "(", "root", "=", "root", ",", "train", "=", "bool", "(", "training", ")", ",", "transform", "=", "transform", ")", "\n", "\n", "self", ".", "infIter", "=", "get_infinite_iter", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_half_f.sample": [[335, 337], ["utils.Cifar_half_f.infIter.sample"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "infIter", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.__init__": [[346, 372], ["transforms.Compose", "torchvision.datasets.CIFAR10", "utils.get_infinite_iter", "transforms.Compose", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "transforms.RandomCrop", "transforms.RandomHorizontalFlip", "transforms.ToTensor", "transforms.Normalize", "transforms.ToTensor", "transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter"], ["    ", "def", "__init__", "(", "self", ",", "cifarAB", "=", "'A'", ",", "training", "=", "True", ",", "shuffle_cifar", "=", "True", ",", "num_workers", "=", "2", ",", "batch_size", "=", "None", ",", "pin_memory", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "\n", "        ", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "trainset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "'./datasets'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "\n", "self", ".", "infIter", "=", "get_infinite_iter", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "testset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "'./datasets'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transform_test", ")", "\n", "self", ".", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "testset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "pin_memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample": [[374, 376], ["utils.Cifar_f.infIter.sample"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "infIter", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MLP_MNIST.__init__": [[381, 399], ["MetaModule.__init__", "range", "MetaLinear().float", "nn.ModuleDict", "activation", "nn.NLLLoss", "len", "MetaLinear().float", "MetaLinear", "MetaLinear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "pixels", "=", "[", "28", "*", "28", ",", "3", "*", "32", "*", "32", "]", "[", "0", "]", ",", "hidden_layers_zee", "=", "[", "[", "30", ",", "20", ",", "]", ",", "[", "50", ",", "20", "]", "]", "[", "0", "]", ",", "activation", "=", "[", "nn", ".", "Sigmoid", ",", "nn", ".", "ReLU", "]", "[", "1", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_layers_zee", "=", "hidden_layers_zee", "\n", "self", ".", "pixels", "=", "pixels", "\n", "\n", "self", ".", "layers", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "hidden_layers_zee", ")", ")", ":", "\n", "            ", "self", ".", "layers", "[", "f'mat_{i}'", "]", "=", "MetaLinear", "(", "pixels", ",", "hidden_layers_zee", "[", "i", "]", ")", ".", "float", "(", ")", "\n", "pixels", "=", "hidden_layers_zee", "[", "i", "]", "\n", "\n", "", "self", ".", "layers", "[", "'final_mat'", "]", "=", "MetaLinear", "(", "pixels", ",", "10", ")", ".", "float", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleDict", "(", "self", ".", "layers", ")", "\n", "\n", "# print(f'optimizee 111 .device={self.layers.device}')", "\n", "\n", "\n", "self", ".", "activation", "=", "activation", "(", ")", "\n", "self", ".", "loss", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MLP_MNIST.forward": [[404, 418], ["loss.sample", "Variable().to", "Variable().to", "F.log_softmax", "utils.MLP_MNIST.loss", "utils.MLP_MNIST.activation", "Variable", "Variable", "utils.MLP_MNIST.view", "utils.MLP_MNIST.size"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample"], ["", "def", "forward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "inp", ",", "out", "=", "loss", ".", "sample", "(", ")", "\n", "# print(inp.shape)", "\n", "inp", "=", "Variable", "(", "inp", ".", "view", "(", "inp", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "pixels", ")", ")", ".", "to", "(", "DEVICE", ")", "\n", "out", "=", "Variable", "(", "out", ")", ".", "to", "(", "DEVICE", ")", "\n", "\n", "cur_layer", "=", "0", "\n", "while", "f'mat_{cur_layer}'", "in", "self", ".", "layers", ":", "\n", "            ", "inp", "=", "self", ".", "activation", "(", "self", ".", "layers", "[", "f'mat_{cur_layer}'", "]", "(", "inp", ")", ")", "\n", "cur_layer", "+=", "1", "\n", "\n", "", "inp", "=", "F", ".", "log_softmax", "(", "self", ".", "layers", "[", "'final_mat'", "]", "(", "inp", ")", ",", "dim", "=", "1", ")", "\n", "l", "=", "self", ".", "loss", "(", "inp", ",", "out", ")", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.MLP_MNIST2.__init__": [[422, 424], ["utils.MLP_MNIST.__init__"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "hidden_layers_zee", "=", "[", "50", ",", "20", ",", "20", ",", "12", ",", "]", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.SMALL_CNN.__init__": [[428, 447], ["MetaModule.__init__", "len", "activation", "range", "nn.ModuleDict", "nn.MaxPool2d", "nn.NLLLoss", "len", "MetaConv2d().float", "MetaLinear().float", "MetaConv2d", "MetaLinear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["def", "__init__", "(", "self", ",", "pixels", "=", "[", "28", "*", "28", ",", "3", "*", "32", "*", "32", "]", "[", "1", "]", ",", "hidden_layers_zee", "=", "[", "(", "'conv'", ",", "3", ",", "6", ",", "3", ")", ",", "(", "'conv'", ",", "6", ",", "12", ",", "3", ")", ",", "(", "'fc'", ",", "12", "*", "6", "*", "6", ",", "5", ")", ",", "]", ",", "activation", "=", "[", "nn", ".", "Sigmoid", ",", "nn", ".", "ReLU", "]", "[", "1", "]", ",", "**", "kwargs", ")", ":", "\n", "# used for cifar-AB, where output has 5 labels", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_layers_zee", "=", "hidden_layers_zee", "\n", "self", ".", "N_layers", "=", "len", "(", "hidden_layers_zee", ")", "\n", "self", ".", "activation", "=", "activation", "(", ")", "\n", "\n", "self", ".", "layers", "=", "{", "}", "\n", "for", "il", "in", "range", "(", "len", "(", "hidden_layers_zee", ")", ")", ":", "\n", "            ", "if", "hidden_layers_zee", "[", "il", "]", "[", "0", "]", "==", "'conv'", ":", "\n", "                ", "self", ".", "layers", "[", "f'conv_{il}'", "]", "=", "MetaConv2d", "(", "*", "hidden_layers_zee", "[", "il", "]", "[", "1", ":", "]", ")", ".", "float", "(", ")", "\n", "", "elif", "hidden_layers_zee", "[", "il", "]", "[", "0", "]", "==", "'fc'", ":", "\n", "                ", "self", ".", "layers", "[", "f'fc_{il}'", "]", "=", "MetaLinear", "(", "*", "hidden_layers_zee", "[", "il", "]", "[", "1", ":", "]", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "self", ".", "layers", "=", "nn", ".", "ModuleDict", "(", "self", ".", "layers", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "loss", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.SMALL_CNN.forward": [[448, 471], ["loss.sample", "Variable().to", "Variable().to", "range", "F.log_softmax", "utils.SMALL_CNN.loss", "Variable", "Variable", "utils.SMALL_CNN.pool", "utils.SMALL_CNN.activation", "utils.SMALL_CNN.view", "utils.SMALL_CNN.activation"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample"], ["", "def", "forward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "x", ",", "label", "=", "loss", ".", "sample", "(", ")", "\n", "\n", "x", "=", "Variable", "(", "x", ")", ".", "to", "(", "DEVICE", ")", "\n", "label", "=", "Variable", "(", "label", ")", ".", "to", "(", "DEVICE", ")", "\n", "\n", "\n", "for", "il", "in", "range", "(", "self", ".", "N_layers", ")", ":", "\n", "            ", "if", "self", ".", "hidden_layers_zee", "[", "il", "]", "[", "0", "]", "==", "'conv'", ":", "\n", "                ", "x", "=", "self", ".", "pool", "(", "self", ".", "activation", "(", "self", ".", "layers", "[", "f'conv_{il}'", "]", "(", "x", ")", ")", ")", "\n", "", "elif", "self", ".", "hidden_layers_zee", "[", "il", "]", "[", "0", "]", "==", "'fc'", ":", "\n", "                ", "if", "self", ".", "hidden_layers_zee", "[", "il", "-", "1", "]", "[", "0", "]", "==", "'conv'", ":", "\n", "# print(x.shape)", "\n", "                    ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_layers_zee", "[", "il", "]", "[", "1", "]", ")", "\n", "", "x", "=", "self", ".", "layers", "[", "f'fc_{il}'", "]", "(", "x", ")", "\n", "if", "il", "<", "self", ".", "N_layers", "-", "1", ":", "\n", "                    ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "\n", "", "", "", "pred", "=", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "l", "=", "self", ".", "loss", "(", "pred", ",", "label", ")", "\n", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.CNN_official_tutorial.__init__": [[482, 490], ["nn.Module.__init__", "nn.Conv2d", "nn.MaxPool2d", "nn.Conv2d", "nn.Linear", "nn.Linear", "nn.Linear"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "6", ",", "5", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "16", "*", "5", "*", "5", ",", "120", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "120", ",", "84", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "84", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.CNN_official_tutorial.forward": [[491, 499], ["utils.CNN_official_tutorial.pool", "utils.CNN_official_tutorial.pool", "utils.CNN_official_tutorial.view", "F.relu", "F.relu", "utils.CNN_official_tutorial.fc3", "F.relu", "F.relu", "utils.CNN_official_tutorial.fc1", "utils.CNN_official_tutorial.fc2", "utils.CNN_official_tutorial.conv1", "utils.CNN_official_tutorial.conv2"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "16", "*", "5", "*", "5", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.__init__": [[505, 522], ["nn.Module.__init__", "hidden_layers_zer.copy", "len", "nn.LSTMCell", "nn.Linear", "np.exp", "nn.LSTMCell", "nn.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.copy", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["    ", "def", "__init__", "(", "self", ",", "preproc", "=", "False", ",", "hidden_layers_zer", "=", "[", "20", ",", "20", "]", ",", "preproc_factor", "=", "10.0", ",", "**", "w", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# assert len(hidden_layers_zer)==2", "\n", "hidden_layers_zer", "=", "[", "20", ",", "20", "]", "\n", "preproc", "=", "False", "\n", "self", ".", "hidden_layers_zer", "=", "hidden_layers_zer", ".", "copy", "(", ")", "\n", "self", ".", "n_hidden", "=", "len", "(", "self", ".", "hidden_layers_zer", ")", "\n", "if", "preproc", ":", "\n", "            ", "self", ".", "recurs", "=", "nn", ".", "LSTMCell", "(", "2", ",", "hidden_layers_zer", "[", "0", "]", ")", "# gf (input_size, hidden_size, bias=True)", "\n", "", "else", ":", "\n", "            ", "self", ".", "recurs", "=", "nn", ".", "LSTMCell", "(", "1", ",", "hidden_layers_zer", "[", "0", "]", ")", "\n", "", "self", ".", "recurs2", "=", "nn", ".", "LSTMCell", "(", "hidden_layers_zer", "[", "0", "]", ",", "hidden_layers_zer", "[", "1", "]", ")", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "hidden_layers_zer", "[", "1", "]", ",", "1", ")", "\n", "self", ".", "preproc", "=", "preproc", "\n", "self", ".", "preproc_factor", "=", "preproc_factor", "\n", "self", ".", "preproc_threshold", "=", "np", ".", "exp", "(", "-", "preproc_factor", ")", "\n", "self", ".", "name", "=", "'DM_{}'", ".", "format", "(", "hidden_layers_zer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.reset": [[523, 531], ["enumerate", "int", "sets.append", "np.prod", "p.size"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "reset", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "last_g_features", "=", "[", "]", "\n", "n_params", "=", "0", "\n", "sets", "=", "[", "]", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "params", ")", ":", "\n", "            ", "n_params", "+=", "int", "(", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "sets", ".", "append", "(", "i", ")", "\n", "", "return", "n_params", ",", "sets", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.forward": [[533, 549], ["utils.DMOptimizer.recurs", "utils.DMOptimizer.recurs2", "torch.zeros().to", "torch.sign().squeeze", "Variable().to", "utils.DMOptimizer.output", "torch.zeros", "torch.sign", "Variable", "torch.abs", "torch.log", "float", "Variable().to.size", "np.exp", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp"], ["", "def", "forward", "(", "self", ",", "grads", ",", "hidden", ",", "cell", ",", "*", "args", ")", ":", "\n", "# grads shape: [cur_sz, 1]", "\n", "# hidden shape: len(self.hidden_layers_zer) x [cur_sz, self.hidden_layers_zer[i]]", "\n", "        ", "if", "self", ".", "preproc", ":", "\n", "            ", "grads", "=", "grads", ".", "data", "\n", "inp2", "=", "torch", ".", "zeros", "(", "grads", ".", "size", "(", ")", "[", "0", "]", ",", "2", ")", ".", "to", "(", "DEVICE", ")", "\n", "keep_grads", "=", "(", "torch", ".", "abs", "(", "grads", ")", ">=", "self", ".", "preproc_threshold", ")", ".", "squeeze", "(", ")", "\n", "inp2", "[", ":", ",", "0", "]", "[", "keep_grads", "]", "=", "(", "torch", ".", "log", "(", "torch", ".", "abs", "(", "grads", "[", "kfit_optimizereep_grads", "]", ")", "+", "1e-8", ")", "/", "self", ".", "preproc_factor", ")", ".", "squeeze", "(", ")", "\n", "inp2", "[", ":", ",", "1", "]", "[", "keep_grads", "]", "=", "torch", ".", "sign", "(", "grads", "[", "keep_grads", "]", ")", ".", "squeeze", "(", ")", "\n", "\n", "inp2", "[", ":", ",", "0", "]", "[", "~", "keep_grads", "]", "=", "-", "1", "\n", "inp2", "[", ":", ",", "1", "]", "[", "~", "keep_grads", "]", "=", "(", "float", "(", "np", ".", "exp", "(", "self", ".", "preproc_factor", ")", ")", "*", "grads", "[", "~", "keep_grads", "]", ")", ".", "squeeze", "(", ")", "\n", "grads", "=", "Variable", "(", "inp2", ")", ".", "to", "(", "DEVICE", ")", "\n", "", "hidden0", ",", "cell0", "=", "self", ".", "recurs", "(", "grads", ",", "(", "hidden", "[", "0", "]", ",", "cell", "[", "0", "]", ")", ")", "\n", "hidden1", ",", "cell1", "=", "self", ".", "recurs2", "(", "hidden0", ",", "(", "hidden", "[", "1", "]", ",", "cell", "[", "1", "]", ")", ")", "\n", "return", "self", ".", "output", "(", "hidden1", ")", ",", "(", "hidden0", ",", "hidden1", ")", ",", "(", "cell0", ",", "cell1", ")", "\n", "# hidden_sz -> hidden_layers_zer", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.CIFAR10_halfLabel.__init__": [[760, 785], ["VisionDataset.__init__", "np.vstack().reshape", "utils.CIFAR10_halfLabel.data.transpose", "os.path.join", "open", "pickle.load", "utils.CIFAR10_halfLabel.data.append", "utils.CIFAR10_halfLabel.targets.extend", "np.vstack"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.extend"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "CIFAR10_halfLabel", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "data", ":", "Any", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "train_list", "\n", "", "else", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "test_list", "\n", "\n", "", "for", "file_name", ",", "checksum", "in", "downloaded_list", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "file_name", ")", "\n", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", "\n", "self", ".", "data", ".", "append", "(", "entry", "[", "b'data'", "]", ")", "\n", "self", ".", "targets", ".", "extend", "(", "entry", "[", "b'labels'", "]", ")", "\n", "", "", "self", ".", "data", "=", "np", ".", "vstack", "(", "self", ".", "data", ")", ".", "reshape", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.CIFAR10_halfLabel.__getitem__": [[786, 792], ["Image.fromarray", "utils.CIFAR10_halfLabel.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "//", "2", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.CIFAR10_halfLabel.__len__": [[793, 795], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.do_with_pretrained": [[94, 135], ["args.update", "meta.load_model", "print", "type", "print"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.load_model"], ["def", "do_with_pretrained", "(", "idx", ",", "args", ",", "is_zee", "=", "False", ")", ":", "\n", "# cwd = __WELL_TRAINED__[idx][0]", "\n", "# config = __WELL_TRAINED__[idx][1]", "\n", "# if idx is None:", "\n", "#     print('\\n\\n\\ndid not load pretrained!!!\\n\\n\\n')", "\n", "#     return", "\n", "\n", "    ", "if", "not", "is_zee", ":", "# load optimizer", "\n", "\n", "        ", "if", "type", "(", "idx", ")", "is", "tuple", ":", "\n", "            ", "print", "(", "f'loading default L2O'", ")", "\n", "RP_config", "=", "idx", "\n", "Ngf", ",", "preproc", ",", "hidden_layers_zer", ",", "grad_features", "=", "RP_config", "\n", "\n", "# cwd = get_newest_file(\"wz_saved_models\")", "\n", "\n", "cwd", "=", "'xxxxx'", "\n", "\n", "\n", "config", "=", "{", "'Ngf'", ":", "Ngf", ",", "'preproc'", ":", "preproc", ",", "'hidden_layers_zer'", ":", "hidden_layers_zer", ",", "'grad_features'", ":", "grad_features", ",", "}", "\n", "OPT", "=", "RPOptimizer", "\n", "", "else", ":", "\n", "            ", "cwd", ",", "config", ",", "OPT", ",", "desc", "=", "__WELL_TRAINED__", "[", "idx", "]", "\n", "\n", "\n", "", "args", ".", "update", "(", "config", ")", ";", "args", "[", "'OPT'", "]", "=", "OPT", "\n", "l2o_net", "=", "args", "[", "'OPT'", "]", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "load_model", "(", "l2o_net", ",", "cwd", ")", "\n", "args", "[", "'l2o_net'", "]", "=", "l2o_net", "\n", "\n", "\n", "", "else", ":", "# load optimizee", "\n", "        ", "print", "(", "'\\n\\n !!!! loading pre_zee, the problem is resnet18 !!!!'", ")", "\n", "cwd", ",", "assigned_zee", ",", "desc", "=", "__WELL_TRAINED__", "[", "idx", "]", "\n", "\n", "args", "[", "'problem_is_transfer_learn'", "]", "=", "True", "\n", "args", "[", "'optimizee_load_cwd'", "]", "=", "cwd", "\n", "args", "[", "'assigned_zee'", "]", "=", "assigned_zee", "\n", "args", "[", "'cifarAB'", "]", "=", "'B'", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.do_with_problem": [[137, 163], ["args.get", "args.update", "OPT_META_L2O", "print", "args[].parameters"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.update", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["", "def", "do_with_problem", "(", "args", ",", "Target_DataGen", ",", "Target_Optimizee", ",", "n_epochs", "=", "None", ",", "epoch_len", "=", "None", ",", "unroll", "=", "None", ",", "eva_epoch_len", "=", "None", ",", "n_tests", "=", "None", ",", "META_OPT_LR", "=", "None", ",", "**", "other_configs", ")", ":", "\n", "\n", "\n", "    ", "args", "[", "'Target_DataGen'", "]", "=", "Target_DataGen", "\n", "if", "Target_DataGen", "in", "[", "MNISTLoss_f", ",", "MNISTLoss", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "28", "*", "28", "\n", "", "elif", "Target_DataGen", "in", "[", "Cifar_half", ",", "Cifar_half_f", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "3", "*", "32", "*", "32", "\n", "\n", "", "args", "[", "'Target_Optimizee'", "]", "=", "Target_Optimizee", "\n", "if", "args", ".", "get", "(", "'l2o_net'", ")", ":", "\n", "        ", "choose_meta_opt", "=", "[", "optim", ".", "Adam", ",", "]", ";", "which_meta_opt", "=", "0", "\n", "OPT_META_L2O", "=", "choose_meta_opt", "[", "which_meta_opt", "]", "\n", "args", "[", "'meta_opt'", "]", "=", "OPT_META_L2O", "(", "args", "[", "'l2o_net'", "]", ".", "parameters", "(", ")", ",", "lr", "=", "META_OPT_LR", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'\\n\\nL2O model not initialized before, planing to train L2O model from scratch...\\n Should NOT see this if: \\n\\t fine-tune L2O \\n\\t evaluation\\n\\t SR Gen Data\\n OK to see if:\\n\\t Train L2O from scratch \\n\\t Fitting SR\\n\\t fine-tune SR \\n\\t Evaluate SR performance \\n\\t normal Train resnet \\n\\n'", ")", "\n", "", "if", "n_epochs", "is", "not", "None", ":", "args", "[", "'n_epochs'", "]", "=", "n_epochs", "\n", "if", "epoch_len", "is", "not", "None", ":", "args", "[", "'epoch_len'", "]", "=", "epoch_len", "\n", "if", "unroll", "is", "not", "None", ":", "args", "[", "'unroll'", "]", "=", "unroll", "\n", "\n", "if", "eva_epoch_len", "is", "not", "None", ":", "args", "[", "'eva_epoch_len'", "]", "=", "eva_epoch_len", "\n", "if", "n_tests", "is", "not", "None", ":", "args", "[", "'n_tests'", "]", "=", "n_tests", "\n", "\n", "args", ".", "update", "(", "other_configs", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter": [[183, 219], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader.__iter__", "InfIter", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.SequentialSampler", "super().__init__", "utils..__next__", "list", "list", "super().__next__", "data_batch.to", "label_batch.to", "range", "range", "utils.._reset", "super().__next__", "len", "len"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.ModuleDict.__iter__", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__"], ["", "def", "get_infinite_iter", "(", "dataset", ",", "batch_size", "=", "1", ",", "num_workers", "=", "2", ",", "shuffle", "=", "True", ",", "sampler", "=", "None", ",", "pin_memory", "=", "None", ",", "**", "args", ")", ":", "\n", "    ", "if", "sampler", "is", "None", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "list", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "list", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", ")", "\n", "\n", "", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "# shuffle=True,", "\n", "num_workers", "=", "num_workers", ",", "\n", "persistent_workers", "=", "True", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "# collate_fn=dataset.collate_fn,", "\n", ")", "\n", "\n", "dataloaderIter", "=", "dataloader", ".", "__iter__", "(", ")", "\n", "\n", "class", "InfIter", "(", "dataloaderIter", ".", "__class__", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "loader", ")", "\n", "self", ".", "loader", "=", "loader", "\n", "", "def", "__next__", "(", "self", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "super", "(", ")", ".", "__next__", "(", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "_reset", "(", "self", ".", "loader", ")", "\n", "return", "super", "(", ")", ".", "__next__", "(", ")", "\n", "", "", "def", "sample", "(", "self", ")", ":", "\n", "            ", "data_batch", ",", "label_batch", "=", "self", ".", "__next__", "(", ")", "\n", "return", "data_batch", ".", "to", "(", "DEVICE", ")", ",", "label_batch", ".", "to", "(", "DEVICE", ")", "\n", "\n", "", "", "infIter", "=", "InfIter", "(", "dataloader", ")", "\n", "return", "infIter", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot": [[565, 574], ["plt.close", "plt.plot", "plt.show", "plt.figure", "plt.plot"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "", "def", "plot", "(", "*", "x", ",", "**", "w", ")", ":", "\n", "    ", "close", "=", "0", "\n", "if", "close", ":", "\n", "        ", "plt", ".", "close", "(", "'all'", ")", "\n", "plt", ".", "plot", "(", "*", "x", ",", "**", "w", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "figure", "(", "998", ")", "\n", "plt", ".", "plot", "(", "*", "x", ",", "**", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.progress_bar": [[582, 627], ["os.popen().read().split", "int", "int", "sys.stdout.write", "range", "sys.stdout.write", "range", "sys.stdout.write", "time.time", "sys.stdout.write", "range", "range", "sys.stdout.write", "sys.stdout.flush", "time.time", "int", "sys.stdout.write", "sys.stdout.write", "L.append", "sys.stdout.write", "sys.stdout.write", "sys.stdout.write", "sys.stdout.write", "os.popen().read", "len", "int", "os.popen", "int"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["def", "progress_bar", "(", "current", ",", "total", ",", "msg", "=", "None", ")", ":", "\n", "    ", "_", ",", "term_width", "=", "os", ".", "popen", "(", "'stty size'", ",", "'r'", ")", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "term_width", "=", "int", "(", "term_width", ")", "\n", "TOTAL_BAR_LENGTH", "=", "65.", "\n", "global", "last_time", ",", "begin_time", "\n", "if", "current", "==", "0", ":", "\n", "        ", "begin_time", "=", "time", ".", "time", "(", ")", "# Reset for new bar.", "\n", "\n", "", "cur_len", "=", "int", "(", "TOTAL_BAR_LENGTH", "*", "current", "/", "total", ")", "\n", "rest_len", "=", "int", "(", "TOTAL_BAR_LENGTH", "-", "cur_len", ")", "-", "1", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "' ['", ")", "\n", "for", "i", "in", "range", "(", "cur_len", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'='", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "'>'", ")", "\n", "for", "i", "in", "range", "(", "rest_len", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'.'", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "']'", ")", "\n", "\n", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "step_time", "=", "cur_time", "-", "last_time", "\n", "last_time", "=", "cur_time", "\n", "tot_time", "=", "cur_time", "-", "begin_time", "\n", "\n", "L", "=", "[", "]", "\n", "# L.append('  Step: %s' % format_time(step_time))", "\n", "# L.append(' | Tot: %s' % format_time(tot_time))", "\n", "if", "msg", ":", "\n", "        ", "L", ".", "append", "(", "' | '", "+", "msg", ")", "\n", "\n", "", "msg", "=", "''", ".", "join", "(", "L", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "msg", ")", "\n", "for", "i", "in", "range", "(", "term_width", "-", "int", "(", "TOTAL_BAR_LENGTH", ")", "-", "len", "(", "msg", ")", "-", "3", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "' '", ")", "\n", "\n", "# Go back to the center of the bar.", "\n", "", "for", "i", "in", "range", "(", "term_width", "-", "int", "(", "TOTAL_BAR_LENGTH", "/", "2", ")", "+", "2", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\b'", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "' %d/%d '", "%", "(", "current", "+", "1", ",", "total", ")", ")", "\n", "\n", "if", "current", "<", "total", "-", "1", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\r'", ")", "\n", "", "else", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\n'", ")", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.format_time": [[628, 659], ["int", "int", "int", "int", "int", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "format_time", "(", "seconds", ")", ":", "\n", "    ", "days", "=", "int", "(", "seconds", "/", "3600", "/", "24", ")", "\n", "seconds", "=", "seconds", "-", "days", "*", "3600", "*", "24", "\n", "hours", "=", "int", "(", "seconds", "/", "3600", ")", "\n", "seconds", "=", "seconds", "-", "hours", "*", "3600", "\n", "minutes", "=", "int", "(", "seconds", "/", "60", ")", "\n", "seconds", "=", "seconds", "-", "minutes", "*", "60", "\n", "secondsf", "=", "int", "(", "seconds", ")", "\n", "seconds", "=", "seconds", "-", "secondsf", "\n", "millis", "=", "int", "(", "seconds", "*", "1000", ")", "\n", "\n", "f", "=", "''", "\n", "i", "=", "1", "\n", "if", "days", ">", "0", ":", "\n", "        ", "f", "+=", "str", "(", "days", ")", "+", "'D'", "\n", "i", "+=", "1", "\n", "", "if", "hours", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "hours", ")", "+", "'h'", "\n", "i", "+=", "1", "\n", "", "if", "minutes", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "minutes", ")", "+", "'m'", "\n", "i", "+=", "1", "\n", "", "if", "secondsf", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "secondsf", ")", "+", "'s'", "\n", "i", "+=", "1", "\n", "", "if", "millis", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "millis", ")", "+", "'ms'", "\n", "i", "+=", "1", "\n", "", "if", "f", "==", "''", ":", "\n", "        ", "f", "=", "'0ms'", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_newest_file": [[663, 690], ["os.listdir", "os.listdir.sort", "os.path.join", "os.path.dirname", "print", "os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.getmtime", "print", "os.path.isdir", "os.path.join", "os.path.join", "len", "len"], "function", ["None"], ["", "def", "get_newest_file", "(", "file_dir", "=", "'.'", ",", "filter", "=", "'file'", ")", ":", "\n", "# os.getcwd()", "\n", "    ", "if", "file_dir", "==", "'.'", ":", "file_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "\n", "files", "=", "os", ".", "listdir", "(", "file_dir", ")", "\n", "files", ".", "sort", "(", "key", "=", "lambda", "fn", ":", "os", ".", "path", ".", "getmtime", "(", "os", ".", "path", ".", "join", "(", "file_dir", ",", "fn", ")", ")", "if", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "file_dir", ",", "fn", ")", ")", "else", "0", ")", "\n", "\n", "newest", "=", "files", "[", "0", "]", "\n", "# prt(files)", "\n", "for", "x", "in", "files", ":", "\n", "        ", "if", "filter", "==", "'file'", ":", "\n", "            ", "print", "(", "os", ".", "path", ".", "isdir", "(", "x", ")", ",", "x", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "x", ")", ":", "\n", "                ", "newest", "=", "x", "\n", "", "", "elif", "filter", "==", "'dir'", ":", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "x", ")", ":", "\n", "                ", "newest", "=", "x", "\n", "", "", "elif", "filter", "!=", "''", ":", "\n", "\n", "            ", "print", "(", "x", "[", "-", "len", "(", "filter", ")", ":", "]", "==", "filter", ",", "x", ")", "\n", "if", "x", "[", "-", "len", "(", "filter", ")", ":", "]", "==", "filter", ":", "\n", "                ", "newest", "=", "x", "\n", "", "", "else", ":", "# filter==''", "\n", "            ", "newest", "=", "x", "\n", "\n", "# newest = files[-1]", "\n", "", "", "return", "os", ".", "path", ".", "join", "(", "file_dir", ",", "newest", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.viz": [[695, 706], ["net.named_parameters", "print", "prt", "viz_.append", "viz_.append", "len", "list", "list", "p.size", "p.size"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "viz", "(", "net", ",", "ttl", "=", "''", ",", "print_device", "=", "False", ")", ":", "\n", "    ", "viz_", "=", "[", "]", "\n", "for", "name", ",", "p", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "print_device", ":", "\n", "            ", "viz_", ".", "append", "(", "(", "name", ",", "p", ".", "device", ",", "list", "(", "p", ".", "size", "(", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "viz_", ".", "append", "(", "(", "name", ",", "list", "(", "p", ".", "size", "(", ")", ")", ")", ")", "\n", "# print(f'\\nparams of: {ttl}\\nlength = {len(viz_)}\\n{viz_}')", "\n", "", "", "print", "(", "f'\\nparams of: {ttl}\\nN_groups = {len(viz_)}'", ")", "\n", "prt", "(", "viz_", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.imshowcifar": [[709, 716], ["img.numpy", "plt.imshow", "plt.show", "print", "np.transpose"], "function", ["None"], ["", "def", "imshowcifar", "(", "img", ",", "labels", "=", "''", ")", ":", "\n", "    ", "img", "=", "img", "/", "2", "+", "0.5", "# unnormalize", "\n", "npimg", "=", "img", ".", "numpy", "(", ")", "\n", "# print(np.transpose(npimg, (1, 2, 0)).shape)", "\n", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "npimg", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "print", "(", "f'labels are: < {labels} >'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.viz_dataset": [[717, 735], ["utils.CIFAR10_halfLabel", "torch.utils.data.DataLoader", "iter", "iter.next", "print", "print", "utils.imshowcifar", "torchvision.utils.make_grid", "transforms.Compose", "range", "transforms.ToTensor", "transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.imshowcifar"], ["", "def", "viz_dataset", "(", "AB", ")", ":", "\n", "    ", "batch_size", "=", "4", "\n", "root", "=", "[", "'datasets/cifar10-A'", ",", "'datasets/cifar10-B'", "]", "[", "AB", "]", "\n", "classes", "=", "(", "'plane'", ",", "'car'", ",", "'bird'", ",", "'cat'", ",", "'deer'", ",", "'dog'", ",", "'frog'", ",", "'horse'", ",", "'ship'", ",", "'truck'", ")", "\n", "classesA", "=", "(", "'plane'", ",", "'bird'", ",", "'deer'", ",", "'frog'", ",", "'ship'", ",", ")", "\n", "classesB", "=", "(", "'car'", ",", "'cat'", ",", "'dog'", ",", "'horse'", ",", "'truck'", ")", "\n", "\n", "trainset", "=", "CIFAR10_halfLabel", "(", "root", "=", "root", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", ")", "\n", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "dataiter", "=", "iter", "(", "trainloader", ")", "\n", "images", ",", "labels", "=", "dataiter", ".", "next", "(", ")", "\n", "\n", "\n", "print", "(", "images", ".", "shape", ")", "\n", "print", "(", "labels", ")", "\n", "\n", "lbstr", "=", "' '", ".", "join", "(", "'%5s'", "%", "[", "classesA", ",", "classesB", "]", "[", "AB", "]", "[", "labels", "[", "j", "]", "]", "for", "j", "in", "range", "(", "batch_size", ")", ")", "\n", "imshowcifar", "(", "torchvision", ".", "utils", ".", "make_grid", "(", "images", ")", ",", "lbstr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.wz_FO_adam": [[799, 849], ["enumerate", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "pnew.retain_grad", "grad.add.add", "torch.maximum", "exp_avg.mul_", "exp_avg_sq.mul_", "meta.detach_var", "max_exp_avg_sq.sqrt", "math.sqrt", "exp_avg_sq.sqrt", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var"], ["", "", "def", "wz_FO_adam", "(", "names", ",", "params", ",", "# FO is for some 'functional' in torch", "\n", "grads", ",", "\n", "exp_avgs", ",", "\n", "exp_avg_sqs", ",", "\n", "max_exp_avg_sqs", ",", "\n", "state_steps", ",", "\n", "amsgrad", ",", "\n", "beta1", ",", "\n", "beta2", ",", "\n", "lr", ",", "\n", "weight_decay", ",", "\n", "eps", ")", ":", "\n", "    ", "r\"\"\"Functional API that performs Adam algorithm computation.\n\n    See :class:`~torch.optim.Adam` for details.\n    \"\"\"", "\n", "result_params", "=", "{", "}", "\n", "for", "i", ",", "param", "in", "enumerate", "(", "params", ")", ":", "\n", "        ", "name", "=", "names", "[", "i", "]", "\n", "grad", "=", "grads", "[", "i", "]", "\n", "exp_avg", "=", "exp_avgs", "[", "i", "]", "\n", "exp_avg_sq", "=", "exp_avg_sqs", "[", "i", "]", "\n", "step", "=", "state_steps", "[", "i", "]", "\n", "if", "amsgrad", ":", "\n", "            ", "max_exp_avg_sq", "=", "max_exp_avg_sqs", "[", "i", "]", "\n", "\n", "", "bias_correction1", "=", "1", "-", "beta1", "**", "step", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "step", "\n", "\n", "if", "weight_decay", "!=", "0", ":", "\n", "            ", "grad", "=", "grad", ".", "add", "(", "param", ",", "alpha", "=", "weight_decay", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1", "-", "beta1", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1", "-", "beta2", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "            ", "torch", ".", "maximum", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "(", "max_exp_avg_sq", ".", "sqrt", "(", ")", "/", "math", ".", "sqrt", "(", "bias_correction2", ")", ")", ".", "add_", "(", "eps", ")", "\n", "", "else", ":", "\n", "            ", "denom", "=", "(", "exp_avg_sq", ".", "sqrt", "(", ")", "/", "math", ".", "sqrt", "(", "bias_correction2", ")", ")", ".", "add_", "(", "eps", ")", "\n", "\n", "", "step_size", "=", "lr", "[", "i", "]", "/", "bias_correction1", "\n", "\n", "# param.addcdiv_(exp_avg, denom, value=-step_size)", "\n", "pnew", "=", "param", "-", "step_size", "*", "detach_var", "(", "exp_avg", "/", "denom", ")", "\n", "pnew", ".", "retain_grad", "(", ")", "\n", "result_params", "[", "name", "]", "=", "pnew", "\n", "", "return", "result_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.bestGPU": [[856, 875], ["GPUtil.getGPUs", "enumerate", "np.argmin", "np.argmin", "int", "mems.append", "loads.append", "print", "print"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append"], ["", "def", "bestGPU", "(", "gpu_verbose", "=", "True", ",", "is_bestMem", "=", "True", ",", "**", "w", ")", ":", "\n", "\n", "    ", "import", "GPUtil", "\n", "Gpus", "=", "GPUtil", ".", "getGPUs", "(", ")", "\n", "Ngpu", "=", "4", "\n", "mems", ",", "loads", "=", "[", "]", ",", "[", "]", "\n", "for", "ig", ",", "gpu", "in", "enumerate", "(", "Gpus", ")", ":", "\n", "        ", "memUtil", "=", "gpu", ".", "memoryUtil", "*", "100", "\n", "load", "=", "gpu", ".", "load", "*", "100", "\n", "mems", ".", "append", "(", "memUtil", ")", "\n", "loads", ".", "append", "(", "load", ")", "\n", "if", "gpu_verbose", ":", "print", "(", "f'gpu-{ig}:   Memory: {memUtil:.2f}%   |   load: {load:.2f}% '", ")", "\n", "", "bestMem", "=", "np", ".", "argmin", "(", "mems", ")", "\n", "bestLoad", "=", "np", ".", "argmin", "(", "loads", ")", "\n", "best", "=", "bestMem", "if", "is_bestMem", "else", "bestLoad", "\n", "if", "gpu_verbose", ":", "print", "(", "f'//////   Will Use GPU - {best}  //////'", ")", "\n", "# print(type(best))", "\n", "\n", "return", "int", "(", "best", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.History_Collector.__init__": [[162, 166], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "SR_memlen", ",", "Ngroup_zee", ")", ":", "\n", "        ", "self", ".", "SR_memlen", "=", "SR_memlen", "\n", "self", ".", "Ngroup_zee", "=", "Ngroup_zee", "\n", "self", ".", "past_mems", "=", "[", "]", "\n", "", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.History_Collector.__call__": [[166, 197], ["stage023_mid2021_update.History_Collector.past_mems[].insert", "torch.cat", "stage023_mid2021_update.History_Collector.past_mems.append", "meta.new_detached_var", "torch.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.insert", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.new_detached_var"], ["", "def", "__call__", "(", "self", ",", "gfeat", ",", "i_step", ",", "i_group", ")", ":", "\n", "# gfeat shape:      [nNeu_thisLayer, Ngf]", "\n", "# output shape:     [nNeu_thisLayer, N_tf = SR_memlen * Ngf]", "\n", "\n", "        ", "assert", "i_step", ">=", "1", "\n", "if", "i_step", "==", "1", ":", "# i_step is in range(1, run_epoch_len + 1)", "\n", "            ", "self", ".", "past_mems", ".", "append", "(", "None", ")", "\n", "self", ".", "past_mems", "[", "i_group", "]", "=", "[", "new_detached_var", "(", "torch", ".", "zeros", "(", "*", "gfeat", ".", "shape", ",", "device", "=", "DEVICE", ")", ")", "for", "_", "in", "range", "(", "self", ".", "SR_memlen", ")", "]", "\n", "\n", "# del self.past_mems[i_group][0]", "\n", "# self.past_mems[i_group].append(gfeat)", "\n", "", "del", "self", ".", "past_mems", "[", "i_group", "]", "[", "-", "1", "]", "\n", "self", ".", "past_mems", "[", "i_group", "]", ".", "insert", "(", "0", ",", "gfeat", ")", "\n", "\n", "res", "=", "torch", ".", "cat", "(", "self", ".", "past_mems", "[", "i_group", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "# # inspect stats", "\n", "# # MNIST problem: std:", "\n", "# #     mt ~ 0.2", "\n", "# #     gt ~ 1.0", "\n", "# #     g/mom ~ 0.0005", "\n", "# if i_step>self.SR_memlen:", "\n", "#     for i_group in range(len(self.past_mems)):", "\n", "#         ntf = torch.stack(self.past_mems[i_group], dim=1)  # shape = [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "#         calStat_thisLayer(ntf)", "\n", "#     raise", "\n", "\n", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__init__": [[377, 383], ["SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "which_SR_dataset", ")", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "# data = np.load(SR_dataset_fname)", "\n", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "self", ".", "X", "=", "torch", ".", "tensor", "(", "Xy_fit", ",", "device", "=", "DEVICE", ")", "\n", "self", ".", "N", "=", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__getitem__": [[384, 387], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "X", "[", "index", "]", "\n", "return", "x", "[", ":", "-", "1", "]", ",", "x", "[", "-", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.SRDataset.__len__": [[388, 390], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor": [[32, 159], ["input_b_tf.reshape", "eval", "eval.reshape", "torch.relu", "torch.sin", "torch.sin", "torch.sign", "torch.tanh", "torch.exp", "abs", "torch.real", "torch.erfc", "torch.sqrt", "torch.log", "torch.sinh", "torch.asinh", "torch.sign", "torch.sign", "torch.pow", "abs", "abs", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.relu", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sin", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.tanh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.exp", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.erfc", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.asinh", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.sign", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.srUtils.pow"], ["def", "sr_fun_tensor", "(", "input_b_tf", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ",", "expr_Nvar", ",", "expr", "=", "''", ",", "coeff_SRNorm", "=", "None", ",", "**", "w", ")", ":", "\n", "# the SR function predicts the LSTM output, which is NOT multiplied by 0.01", "\n", "# lum is never used in sr study.", "\n", "# any input/output re-scale must be done simultaneously in TWO places:", "\n", "# 1. the sr_prep2, just before outputing results.", "\n", "# 2. this function, just before outputing results.", "\n", "# I/O is a group (batch) ", "\n", "# input shape:      [batch_size, N_tf]", "\n", "# output shape:     [batch_size, 1]", "\n", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# coeff_SRNorm:     [expr_Nvar,]", "\n", "\n", "\n", "# btf: [batch_size, SR_memlen, Ngf]", "\n", "# output tensor is 2-D, shape is [batch_size, 1]", "\n", "\n", "    ", "btf", "=", "input_b_tf", ".", "reshape", "(", "-", "1", ",", "SR_memlen", ",", "Ngf", ")", "\n", "\n", "if", "coeff_SRNorm", "is", "not", "None", ":", "\n", "        ", "assert", "Ngf", "==", "expr_Nvar", "\n", "btf", "/=", "coeff_SRNorm", "\n", "\n", "\n", "\n", "\n", "", "def", "expm", "(", "x", ",", "a", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "abs", "(", "x", ")", "**", "a", "\n", "", "def", "relu", "(", "inX", ")", ":", "\n", "        ", "return", "F", ".", "relu", "(", "inX", ")", "\n", "", "def", "greater", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "(", "x", ">", "y", ")", ".", "float", "(", ")", "\n", "", "def", "mult", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "*", "y", "\n", "", "def", "sin", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "cos", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sin", "(", "x", ")", "\n", "", "def", "sign", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "\n", "", "def", "plus", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "+", "y", "\n", "", "def", "square", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "2", "\n", "", "def", "cube", "(", "x", ")", ":", "\n", "        ", "return", "x", "**", "3", "\n", "", "def", "tanh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "tanh", "(", "x", ")", "\n", "", "def", "exp", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "exp", "(", "x", ")", "\n", "", "def", "pow", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "torch", ".", "sign", "(", "x", ")", "*", "torch", ".", "pow", "(", "abs", "(", "x", ")", ",", "y", ")", "\n", "", "def", "Abs", "(", "x", ")", ":", "\n", "        ", "return", "abs", "(", "x", ")", "\n", "", "def", "re", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "real", "(", "x", ")", "\n", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "x", "/", "y", "\n", "", "def", "erfc", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "erfc", "(", "x", ")", "\n", "", "def", "sqrtm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sqrt", "(", "abs", "(", "x", ")", ")", "\n", "", "def", "logm", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "abs", "(", "x", ")", "+", "1e-7", ")", "\n", "", "def", "sinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "sinh", "(", "x", ")", "\n", "", "def", "asinh", "(", "x", ")", ":", "\n", "        ", "return", "torch", ".", "asinh", "(", "x", ")", "\n", "\n", "\n", "\n", "# ==== applicable to genEmpExp_April ====", "\n", "# try:", "\n", "\n", "#     mt_0 = btf[:,0,0]", "\n", "#     mt_1 = btf[:,1,0]", "\n", "#     mt_2 = btf[:,2,0]", "\n", "#     mt_3 = btf[:,3,0]", "\n", "#     mt_4 = btf[:,4,0]", "\n", "#     mt_5 = btf[:,5,0]", "\n", "\n", "# except IndexError:", "\n", "#     pass", "\n", "\n", "\n", "# gt_0 = btf[:,0,1] ", "\n", "# gt_1 = btf[:,1,1]", "\n", "# gt_2 = btf[:,2,1]", "\n", "# gt_3 = btf[:,3,1]", "\n", "# gt_4 = btf[:,4,1]", "\n", "# gt_5 = btf[:,5,1]", "\n", "\n", "\n", "\n", "# g_0 = btf[:,0,2]    ", "\n", "# g_1 = btf[:,1,2]", "\n", "# g_2 = btf[:,2,2]", "\n", "# g_3 = btf[:,3,2]", "\n", "# g_4 = btf[:,4,2]", "\n", "# g_5 = btf[:,5,2]", "\n", "\n", "# mom5_0 = btf[:,0,3]    ", "\n", "# mom5_1 = btf[:,1,3]", "\n", "# mom5_2 = btf[:,2,3]", "\n", "# mom5_3 = btf[:,3,3]", "\n", "# mom5_4 = btf[:,4,3]", "\n", "# mom5_5 = btf[:,5,3]", "\n", "\n", "# expr = eval(expr)", "\n", "\n", "\n", "\n", "\n", "# ==== applicable to June impl ====", "\n", "\n", "# coeff_SR: [lamb, weight-decay, momentum, lr, ]", "\n", "", "adamup", "=", "btf", "[", ":", ",", "0", ",", "0", "]", "\n", "adamdn", "=", "btf", "[", ":", ",", "0", ",", "1", "]", "\n", "lamb", "=", "coeff_SR", "[", "0", "]", "\n", "# expr = adamup/(1-lamb + lamb * adamdn)", "\n", "expr", "=", "eval", "(", "expr", ")", "\n", "b1", "=", "expr", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "\n", "\n", "return", "b1", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.calStat_thisLayer": [[200, 209], ["np.zeros", "range", "print", "ntf[].reshape", "torch.mean", "torch.std"], "function", ["None"], ["", "", "def", "calStat_thisLayer", "(", "ntf", ")", ":", "\n", "# input shape: [nNeu_thisLayer, SR_memlen, Ngf]", "\n", "    ", "F", "=", "ntf", ".", "shape", "[", "-", "1", "]", "\n", "mv", "=", "np", ".", "zeros", "(", "(", "F", ",", "2", ")", ")", "\n", "for", "f", "in", "range", "(", "F", ")", ":", "\n", "        ", "this", "=", "ntf", "[", ":", ",", ":", ",", "f", "]", ".", "reshape", "(", "-", "1", ")", "\n", "mv", "[", "f", "]", "=", "[", "torch", ".", "mean", "(", "this", ")", ",", "torch", ".", "std", "(", "this", ")", "]", "\n", "", "print", "(", "f'mean & std at this layer (feat x m/std):\\n{mv}'", ")", "\n", "return", "mv", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform": [[220, 239], ["print", "OPT().to", "zip", "np.save", "np.asarray", "np.mean", "np.mean", "meta.wzRec", "stage023_mid2021_update.run_epoch_sr", "np.sum", "OPT", "range"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr"], ["", "def", "eva_sr_trainingPerform", "(", "args", ",", "eva_epoch_len", "=", "None", ",", "OPT", "=", "None", ",", "n_tests", "=", "None", ",", "want_save_eva_loss", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "print", "(", "'TODO: add no grad to eva'", ")", "\n", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "\n", "res", "=", "[", "run_epoch_sr", "(", "args", ",", "eva_epoch_len", ",", "should_train", "=", "False", ",", "**", "args", ")", "for", "_", "in", "range", "(", "n_tests", ")", "]", "\n", "\n", "losses", ",", "coeffs", "=", "zip", "(", "*", "res", ")", "\n", "\n", "np", ".", "save", "(", "'coeffs_fake_eva.npy'", ",", "coeffs", ")", "\n", "\n", "all_losses", "=", "np", ".", "asarray", "(", "losses", ")", "\n", "avg_eva_sum_loss", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "all_losses", ",", "1", ")", ",", "0", ")", "\n", "avg_eva_last_loss", "=", "np", ".", "mean", "(", "all_losses", "[", ":", ",", "-", "1", "]", ",", "0", ")", "\n", "\n", "wzRec", "(", "all_losses", ",", "'Eva-SR-loss'", ",", "Target_Optimizee", ".", "name", ",", "want_save", "=", "want_save_eva_loss", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.fine_tune_SR": [[241, 278], ["coeff_SR.detach().cpu().data.numpy().round", "OPT_META_SR", "OPT().to", "range", "coeff_SR.detach().cpu().data.numpy().round", "stage023_mid2021_update.eva_sr_trainingPerform", "itertools.chain.from_iterable", "stage023_mid2021_update.run_epoch_sr", "coeffs_allEP.append", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "np.save", "np.save", "coeff_SR.detach().cpu().data.numpy", "OPT", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu().data.numpy", "stage023_mid2021_update.eva_sr_trainingPerform", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.eva_sr_trainingPerform"], ["", "def", "fine_tune_SR", "(", "args", ",", "coeff_SR", "=", "None", ",", "OPT", "=", "None", ",", "epoch_len_tuneSR", "=", "None", ",", "n_epochs_tuneSR", "=", "20", ",", "srFineTune_want_eva_in_train", "=", "None", ",", "OPT_META_SR", "=", "None", ",", "lr_meta_tuneSR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# this function will not build new SR coeffs (in-place tuning)", "\n", "# but really DOES initialize a new meta-opt", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "\n", "args", "[", "'opt_meta_SR'", "]", "=", "OPT_META_SR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_meta_tuneSR", ",", "momentum", "=", "0.9", ")", "\n", "args", "[", "'l2oShell_4SR_featPrep'", "]", "=", "OPT", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "args", "[", "'Ngf'", "]", "=", "args", "[", "'l2oShell_4SR_featPrep'", "]", ".", "Ngf", "\n", "coeffs_allEP", "=", "[", "]", "\n", "\n", "\n", "# for iepoch in tqdm(range(n_epochs_tuneSR), 'Fine tuning SR'):", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_tuneSR", ")", ":", "\n", "\n", "        ", "losses_1epoch", ",", "coeffs", "=", "run_epoch_sr", "(", "args", ",", "epoch_len_tuneSR", ",", "should_train", "=", "True", ",", "**", "args", ")", "\n", "coeffs_allEP", ".", "append", "(", "coeffs", ")", "\n", "\n", "wzRec", "(", "losses_1epoch", ",", "'tuneSR-train-loss, epoch-{}'", ".", "format", "(", "iepoch", ")", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "np", ".", "save", "(", "'coeff_SR.npy'", ",", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_allEP.npy'", ",", "coeffs_allEP", ")", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "if", "srFineTune_want_eva_in_train", ":", "\n", "                ", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "\n", "\n", "", "", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'final coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "eva_sr_trainingPerform", "(", "args", ",", "**", "args", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.run_epoch_sr": [[282, 372], ["bool", "Target_DataGen", "Target_Optimizee().to", "meta.wIni", "l2oShell_4SR_featPrep.reset", "tqdm", "stage023_mid2021_update.History_Collector", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "Target_Optimizee().to.parameters", "opt_meta_SR.zero_grad", "range", "tqdm", "range", "Target_Optimizee().to.", "losses_1epoch.append", "optimizee.backward", "enumerate", "Target_Optimizee", "range", "optimizee.data.cpu().numpy", "Target_Optimizee().to.named_parameters", "int", "meta.detach_var", "l2oShell_4SR_featPrep.grad2features", "History_Collector.", "stage023_mid2021_update.sr_fun_tensor", "result_params[].retain_grad", "Target_Optimizee().to", "meta.wIni", "Target_Optimizee().to.load_state_dict", "Target_Optimizee().to.zero_grad", "Target_Optimizee().to.named_parameters", "coeff_SR.detach().cpu().data.numpy", "np.prod", "p.grad.view", "sr_fun_tensor.view", "opt_meta_SR.zero_grad", "Target_Optimizee().to.", "all_losses.backward", "opt_meta_SR.step", "bool", "coeff_SR.detach().cpu().data.numpy().round", "meta.rsetattr", "optimizee.data.cpu", "p.size", "coeff_SR.detach().cpu().data.numpy().round", "args[].append", "np.save", "Target_Optimizee", "p.size", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach", "coeff_SR.detach().cpu", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.DMOptimizer.reset", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.detach_var", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.RPOptimizer.grad2features", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wIni", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.named_parameters", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.rsetattr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save"], ["", "def", "run_epoch_sr", "(", "args", ",", "run_epoch_len", ",", "should_train", ",", "rec_SR", "=", "True", ",", "coeff_SR", "=", "None", ",", "opt_meta_SR", "=", "None", ",", "l2oShell_4SR_featPrep", "=", "None", ",", "Target_DataGen", "=", "None", ",", "Target_Optimizee", "=", "None", ",", "unroll_tuneSR", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "expr", "=", "None", ",", "Ngf", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "if", "not", "should_train", ":", "\n", "        ", "unroll_tuneSR", "=", "1", "\n", "", "if", "bool", "(", "rec_SR", ")", ":", "\n", "        ", "args", "[", "'rec_SR'", "]", "=", "[", "]", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "\n", "", "target", "=", "Target_DataGen", "(", "training", "=", "should_train", ",", "**", "args", ")", "\n", "optimizee", "=", "Target_Optimizee", "(", "**", "args", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "\n", "l2oShell_4SR_featPrep", ".", "reset", "(", "optimizee", ".", "parameters", "(", ")", ")", "\n", "\n", "losses_1epoch", ",", "all_losses", "=", "[", "]", ",", "None", "\n", "if", "should_train", ":", "\n", "        ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "iterator", "=", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ",", "'Eva: '", ")", "\n", "", "iterator", "=", "tqdm", "(", "range", "(", "1", ",", "run_epoch_len", "+", "1", ")", ")", "\n", "\n", "history_collector", "=", "History_Collector", "(", "SR_memlen", ",", "Ngroup_zee", ")", "\n", "for", "i_step", "in", "iterator", ":", "\n", "\n", "\n", "        ", "loss", "=", "optimizee", "(", "target", ")", "\n", "all_losses", "=", "loss", "if", "all_losses", "is", "None", "else", "all_losses", "+", "loss", "\n", "\n", "losses_1epoch", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "should_train", ")", "\n", "\n", "offset", "=", "0", "\n", "result_params", "=", "{", "}", "\n", "\n", "for", "i_group", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "optimizee", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "cur_sz", "=", "int", "(", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "\n", "gradients", "=", "detach_var", "(", "p", ".", "grad", ".", "view", "(", "cur_sz", ",", "1", ")", ")", "\n", "sr_features_cur", "=", "l2oShell_4SR_featPrep", ".", "grad2features", "(", "gradients", ",", "i_group", ",", "i_step", ")", "\n", "sr_inputs", "=", "history_collector", "(", "sr_features_cur", ",", "i_step", ",", "i_group", ")", "\n", "updates", "=", "sr_fun_tensor", "(", "sr_inputs", ",", "**", "args", ")", "\n", "\n", "updates", "=", "updates", "*", "0.01", "\n", "\n", "result_params", "[", "name", "]", "=", "p", "+", "updates", ".", "view", "(", "*", "p", ".", "size", "(", ")", ")", "\n", "result_params", "[", "name", "]", ".", "retain_grad", "(", ")", "\n", "\n", "offset", "+=", "cur_sz", "\n", "# print(args['coeff_SR']) #-wz", "\n", "\n", "\n", "", "if", "i_step", "%", "unroll_tuneSR", "==", "0", ":", "\n", "            ", "if", "should_train", ":", "\n", "\n", "\n", "                ", "opt_meta_SR", ".", "zero_grad", "(", ")", "\n", "all_losses", "+=", "optimizee", "(", "target", ")", "\n", "all_losses", ".", "backward", "(", ")", "\n", "opt_meta_SR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "if", "bool", "(", "rec_SR", ")", ":", "\n", "                    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "args", "[", "'rec_SR'", "]", ".", "append", "(", "coeff_SR_list", ")", "\n", "np", ".", "save", "(", "'coeffs_train_1EP.npy'", ",", "args", "[", "'rec_SR'", "]", ")", "\n", "\n", "", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'current coeff_SR:\\n{coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "\n", "\n", "\n", "\n", "", "all_losses", "=", "None", "\n", "optimizee", "=", "Target_Optimizee", "(", ")", ".", "to", "(", "DEVICE", ")", "\n", "wIni", "(", "optimizee", ")", "\n", "optimizee", ".", "load_state_dict", "(", "result_params", ")", "\n", "# updateDict_skip_running(optimizee,result_params)", "\n", "\n", "optimizee", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "p", "in", "optimizee", ".", "named_parameters", "(", ")", ":", "\n", "                ", "rsetattr", "(", "optimizee", ",", "name", ",", "result_params", "[", "name", "]", ")", "\n", "\n", "", "", "", "return", "losses_1epoch", ",", "args", "[", "'rec_SR'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.fit_SR": [[395, 441], ["coeff_SR.detach().cpu().data.numpy().round", "OPT_fitSR", "nn.MSELoss", "stage023_mid2021_update.SRDataset", "utils.get_infinite_iter", "range", "meta.wzRec", "coeff_SR.detach().cpu().data.numpy().round", "np.save", "itertools.chain.from_iterable", "utils.get_infinite_iter.sample", "stage023_mid2021_update.sr_fun_tensor", "nn.MSELoss.", "OPT_fitSR.zero_grad", "mse.backward", "OPT_fitSR.step", "coeff_SR.detach().cpu().data.numpy", "stage023_mid2021_update.evaSR_R2", "eva_r2s.append", "utils.progress_bar", "coeff_SR.detach().cpu().data.numpy", "coeff_SR.detach().cpu", "x.detach().cpu().data.item", "coeff_SR.detach().cpu", "coeff_SR.detach", "coeff_SR.detach", "x.detach().cpu", "x.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.get_infinite_iter", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta.wzRec", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.tensorflow-implementation.meta_rnnprop_eval.MetaOptimizer.save", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.Cifar_f.sample", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.study_lum.wAdam.step", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.evaSR_R2", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.progress_bar"], ["", "", "def", "fit_SR", "(", "args", ",", "lr_fitSR", "=", "None", ",", "expr", "=", "None", ",", "n_epochs_fit_SR", "=", "20", ",", "OPT_fitSR", "=", "None", ",", "l2o_net", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# need to un-comment 'step-0-prep' in order to have correct l2o_net name", "\n", "\n", "    ", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "\n", "\n", "opt_fitSR", "=", "OPT_fitSR", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "[", "coeff_SR", ",", "]", "]", ")", ",", "lr", "=", "lr_fitSR", ")", "\n", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "dataset_train", "=", "SRDataset", "(", "which_SR_dataset", ")", "\n", "srIter", "=", "get_infinite_iter", "(", "dataset_train", ",", "shuffle", "=", "True", ",", "sampler", "=", "None", ",", "**", "args", ")", "\n", "\n", "\n", "eva_r2s", "=", "[", "]", "\n", "for", "iepoch", "in", "range", "(", "n_epochs_fit_SR", ")", ":", "\n", "\n", "        ", "l2o_input_slices", ",", "l2o_output", "=", "srIter", ".", "sample", "(", ")", "# parallel working.", "\n", "\n", "sr_pred", "=", "sr_fun_tensor", "(", "l2o_input_slices", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "\n", "loss", "=", "mse", "(", "sr_pred", ",", "l2o_output", ")", "\n", "\n", "\n", "opt_fitSR", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt_fitSR", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "\n", "if", "(", "iepoch", ")", "%", "100", "==", "0", ":", "\n", "            ", "eva_r2", "=", "evaSR_R2", "(", "args", ",", "**", "args", ")", "\n", "coeff_disp", "=", "[", "f'{x.detach().cpu().data.item():.4f}'", "for", "x", "in", "coeff_SR", "]", "\n", "\n", "# print(f'current coeff_SR: {coeff_disp}')", "\n", "eva_r2s", ".", "append", "(", "eva_r2", ")", "\n", "progress_bar", "(", "iepoch", ",", "n_epochs_fit_SR", ",", "f'loss={loss} , eva_r2={eva_r2} , coeff_SR={coeff_disp}'", ")", "\n", "\n", "", "", "wzRec", "(", "eva_r2s", ",", "'fit SR, eva_r2'", ")", "\n", "\n", "coeff_SR_list", "=", "coeff_SR", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "round", "(", "5", ")", "\n", "# print(f'finished, coeff_SR = \\n\\t {coeff_SR_list}\\n{coeff_SR_list.tolist()}')", "\n", "np", ".", "save", "(", "'wz_saved_models/fitted SR ~ of ~ {l2o_net.name}.npy'", ",", "coeff_SR_list", ")", "\n", "return", "coeff_SR", ",", "coeff_SR_list", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.evaSR_R2": [[444, 457], ["torch.no_grad", "SR_data.SR_exp_rec.load_SR_dataset", "torch.tensor", "stage023_mid2021_update.sr_fun_tensor", "sr_fun_tensor.detach().cpu().data.numpy", "sklearn.metrics.r2_score", "print", "sr_fun_tensor.detach().cpu", "sr_fun_tensor.detach"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_fun_tensor"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaSR_R2", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "which_SR_dataset", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngf", "=", "None", ",", "**", "w", ")", ":", "\n", "# dataset_test = np.load(which_SR_dataset)", "\n", "    ", "Xy_train", ",", "Xy_test", ",", "Xy_fit", ",", "feature_names", ",", "l2o_num_grad_features", ",", "N_pre", "=", "load_SR_dataset", "(", "which_SR_dataset", ")", "\n", "x", "=", "torch", ".", "tensor", "(", "Xy_test", "[", ":", ",", ":", "-", "1", "]", ",", "device", "=", "DEVICE", ")", "\n", "y_true", "=", "Xy_test", "[", ":", ",", "-", "1", "]", "\n", "pred_tensor", "=", "sr_fun_tensor", "(", "x", ",", "expr", ",", "coeff_SR", ",", "SR_memlen", ",", "Ngf", ")", "\n", "pred", "=", "pred_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "r2", "=", "r2_score", "(", "y_true", ",", "pred", ")", "\n", "\n", "print", "(", "f'\\n\\nR2 = {r2:.5f}\\n\\n'", ")", "\n", "\n", "return", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.viz_grad_seq": [[462, 488], ["to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "to_viz_r_t_n_f[].reshape", "plt.close", "range", "print", "plt.subplot", "plt.plot", "plt.plot", "plt.legend", "np.random.choice", "list", "len", "len", "len", "print", "range", "range", "plt.plot"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "def", "viz_grad_seq", "(", "sr_r_t_n_f", ")", ":", "\n", "# [run, time, neuron/layer, feat]", "\n", "    ", "n_neuron", "=", "sr_r_t_n_f", ".", "shape", "[", "1", "]", "\n", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "layerIidx", "=", "[", "np", ".", "random", ".", "choice", "(", "n", ",", "1", ")", ",", "(", "0", ",", "1", ",", "-", "2", ",", "-", "1", ")", ",", "list", "(", "range", "(", "n", ")", ")", "]", "[", "-", "1", "]", "\n", "\n", "to_viz_r_t_n_f", "=", "sr_r_t_n_f", "[", ":", ",", ":", ",", "layerIidx", ",", ":", "]", "\n", "grad_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "update_rt_n", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", "]", ")", "\n", "gfeat_rt_n_f", "=", "to_viz_r_t_n_f", "[", ":", ",", ":", ",", ":", ",", "1", ":", "-", "1", "]", ".", "reshape", "(", "[", "r", "*", "t", ",", "len", "(", "layerIidx", ")", ",", "f", "-", "2", "]", ")", "\n", "if", "f", "==", "2", ":", "\n", "        ", "print", "(", "'viz for DM-opt'", ")", "\n", "", "elif", "f", ">", "2", ":", "\n", "        ", "print", "(", "'viz for RP-opt'", ")", "\n", "", "else", ":", "raise", "ValueError", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "for", "ilayer", "in", "range", "(", "n", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "2", ",", "n", "//", "2", ",", "ilayer", "+", "1", ")", "\n", "plt", ".", "plot", "(", "grad_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-x'", ",", "label", "=", "f'grad @ layer {ilayer}'", ")", "# len(layerIidx) \u6761\u6570\u636e", "\n", "plt", ".", "plot", "(", "update_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-o'", ",", "label", "=", "f'update @ layer {ilayer}'", ")", "\n", "def", "plot_feat", "(", ")", ":", "\n", "            ", "for", "i_f", "in", "range", "(", "f", "-", "2", ")", ":", "\n", "                ", "feati_rt_n", "=", "gfeat_rt_n_f", "[", ":", ",", ":", ",", "i_f", "]", "\n", "plt", ".", "plot", "(", "feati_rt_n", "[", ":", ",", "ilayer", "]", ",", "'-1'", ",", "label", "=", "f'the {i_f}-th gfeat @ layer {ilayer}'", ")", "\n", "# if f>2:  plot_feat()", "\n", "", "", "plt", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_prep1": [[491, 509], ["len", "list", "int"], "function", ["None"], ["", "", "def", "sr_prep1", "(", "args", ",", "SR_memlen", ",", "num_Xyitems_SR", ",", "eva_epoch_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# this function will change some configs related to SR, for the sole purpose of configuring generation of offline SR database", "\n", "\n", "    ", "Ngroup_zee", "=", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "tSample_1epoch", "=", "eva_epoch_len", "//", "SR_memlen", "-", "2", "# \u8bbe\u7f6e\u7684\u8d8a\u5c0f\uff0ct\u8f74\u91c7\u6837\u4e4b\u95f4\u7684\u201c\u7a7a\u683c\u201d\u5c31\u8d8a\u5927", "\n", "assert", "tSample_1epoch", ">", "0", ",", "f'eva_epoch_len={eva_epoch_len}, should > SR_memlen*2 = {SR_memlen}*2 = {SR_memlen*2}'", "\n", "\n", "what_we_get_1epoch", "=", "tSample_1epoch", "*", "Ngroup_zee", "\n", "\n", "epochs_needed", "=", "int", "(", "num_Xyitems_SR", "/", "what_we_get_1epoch", "/", "10", "*", "1.6", ")", "+", "1", "\n", "args", "[", "'n_tests'", "]", "=", "epochs_needed", "\n", "args", "[", "'tSample_1epoch'", "]", "=", "tSample_1epoch", "\n", "args", "[", "'available_Interval'", "]", "=", "eva_epoch_len", "-", "tSample_1epoch", "*", "SR_memlen", "-", "2", "# -2 is for safety", "\n", "args", "[", "'SR_memlen'", "]", "=", "SR_memlen", "\n", "args", "[", "'num_Xyitems_SR'", "]", "=", "num_Xyitems_SR", "\n", "# print(f'\\n\\n----------\\nSR prep:\\n\\tepochs_needed = {epochs_needed}\\n\\ttSample_1epoch = {tSample_1epoch}\\n\\tSR_memlen = {SR_memlen}\\n\\teva_epoch_len = {eva_epoch_len} > tSample_1epoch*SR_memlen = {tSample_1epoch}*{SR_memlen} = {tSample_1epoch*SR_memlen}\\n\\tNgroup_zee = {Ngroup_zee}\\n\\nTarget_DataGen = {Target_DataGen}\\nTarget_Optimizee = {Target_Optimizee}\\n----------\\n')", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_prep2": [[511, 567], ["np.random.rand", "stage023_mid2021_update.sr_prep2.interv_to_int"], "function", ["None"], ["", "def", "sr_prep2", "(", "sr_r_t_n_f", ",", "args", ",", "available_Interval", "=", "None", ",", "tSample_1epoch", "=", "None", ",", "SR_memlen", "=", "None", ",", "Ngroup_zee", "=", "None", ",", "num_Xyitems_SR", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# returned SR_Xy_rn_tf shape:", "\n", "#     [N_sample , SR_memlen * Ngf+1 ] ; the last column is label", "\n", "\n", "# sr_gfu shape: [eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "# sr_r_t_n_f shape: ", "\n", "#     [which run (r) , which time step (t) , which neuron (n) , grad/feature/update (f) ]", "\n", "#     shape: [n_tests, eva_epoch_len, Ngroup_zee, 1+l2o_net.Ngf+1]", "\n", "\n", "    ", "r", ",", "t", ",", "n", ",", "f", "=", "sr_r_t_n_f", ".", "shape", "\n", "f_true", "=", "f", "-", "2", "if", "f", ">", "2", "else", "f", "-", "1", "# RP or DM", "\n", "SR_XY_rtn_f", "=", "[", "]", "\n", "tSelect_r_n", "=", "np", ".", "random", ".", "rand", "(", "r", ",", "n", ",", "tSample_1epoch", "+", "1", ")", "\n", "def", "interv_to_int", "(", "tSelect_r_n", ")", ":", "\n", "# guarantee the randomness in sampling", "\n", "        ", "sum_", "=", "np", ".", "sum", "(", "tSelect_r_n", ",", "axis", "=", "2", ")", "\n", "tSelect_r_n", "=", "tSelect_r_n", "/", "sum_", "[", ":", ",", ":", ",", "None", "]", "*", "available_Interval", "\n", "tSelect_r_n", "=", "tSelect_r_n", ".", "astype", "(", "int", ")", "\n", "return", "tSelect_r_n", "\n", "", "tSelect_r_n", "=", "interv_to_int", "(", "tSelect_r_n", ")", "# shape is [r,n,tSample_1epoch+1], every [_r, _n] dimension, when sumed up along axis 'tSample_1epoch+1', is no more than available_Interval", "\n", "\n", "# the [_r, _n] position means the starting t for this sample of sequence", "\n", "\n", "rn_t_f", "=", "[", "]", "# when t&f are viewed together, this one means to be collection of t_f sequences (along t axis)", "\n", "for", "_r", "in", "range", "(", "r", ")", ":", "\n", "        ", "for", "_n", "in", "range", "(", "n", ")", ":", "\n", "                ", "tSelect", "=", "tSelect_r_n", "[", "_r", ",", "_n", "]", "# a 1-D array of length tSample_1epoch+1, meaning the 'interval', rather than starging point.", "\n", "for", "ith_selection", "in", "range", "(", "tSample_1epoch", ")", ":", "\n", "                    ", "starting_point", "=", "sum", "(", "tSelect", "[", ":", "ith_selection", "+", "1", "]", ")", "+", "SR_memlen", "*", "ith_selection", "\n", "cur_item_t_f", "=", "sr_r_t_n_f", "[", "_r", ",", "starting_point", ":", "starting_point", "+", "SR_memlen", ",", "_n", ",", ":", "]", "# is an 2-D array", "\n", "if", "cur_item_t_f", "[", "SR_memlen", "//", "4", "*", "3", "-", "1", ",", "0", "]", "!=", "0.0", ":", "\n", "# only append items that grad is not 0 at this ramdomly selected location", "\n", "                        ", "rn_t_f", ".", "append", "(", "cur_item_t_f", ")", "\n", "# after for loop, rn_t_f is a 3-D, indexed by [rn, t, f] (somehow transposed)", "\n", "", "", "", "", "rn_t_f", "=", "np", ".", "asarray", "(", "rn_t_f", ")", "\n", "def", "extract_features_labels", "(", "rn_t_f", ")", ":", "\n", "        ", "if", "f", ">", "2", ":", "# RP model, remove original grad feature", "\n", "            ", "rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "", "features_rn_t_f", "=", "rn_t_f", "[", ":", ",", ":", ",", ":", "-", "1", "]", "# 3-D, remove update column", "\n", "_", ",", "N_pre", ",", "_", "=", "features_rn_t_f", ".", "shape", "\n", "rev_idx", "=", "np", ".", "arange", "(", "N_pre", ")", "[", ":", ":", "-", "1", "]", "\n", "features_rn_t_f_rev", "=", "features_rn_t_f", "[", ":", ",", "rev_idx", ",", ":", "]", "\n", "feat_reversed", "=", "features_rn_t_f_rev", ".", "reshape", "(", "[", "-", "1", ",", "SR_memlen", "*", "f_true", "]", ")", "# 2-D array", "\n", "labels_rn_1", "=", "rn_t_f", "[", ":", ",", "-", "1", ",", "-", "1", "]", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "# 1-D array, size = |rn|, reshaped to column", "\n", "SR_Xy_rn_tf", "=", "np", ".", "concatenate", "(", "[", "feat_reversed", ",", "labels_rn_1", "]", ",", "axis", "=", "1", ")", "\n", "return", "SR_Xy_rn_tf", "\n", "", "SR_Xy_rn_tf", "=", "extract_features_labels", "(", "rn_t_f", ")", "\n", "\n", "# at this point, we have a 2-D array, which is exactly the expected shape", "\n", "np", ".", "random", ".", "shuffle", "(", "SR_Xy_rn_tf", ")", "\n", "\n", "desc", "=", "f'#samples={SR_Xy_rn_tf.shape[0]}, #memlen={SR_memlen}, #feat={f_true}'", "\n", "print", "(", "f\"\\n=============\\nPost proc: randomly select time sub-sequences and re-formulate into Xy-samples for SR.\\n\\t Input shape:\\t\\t sr_r_t_n_f.shape = {sr_r_t_n_f.shape}\\n\\t Input samples:\\t r*(tSample_1epoch*Ngroup_zee) = {r}*{tSample_1epoch}*{Ngroup_zee} = {r*tSample_1epoch*Ngroup_zee}\\n\\t SR feature+label dim:\\t\\t SR_memlen*L2O_features = {SR_memlen}*{f_true}={SR_memlen*f_true}\\n\\t which L2O:\\t\\t \\t{args['l2o_net'].name}\\n\\t feature dim is: [1(grad) + {f-2} + 1(update)]\\n\\t Obtained SR_Xy shape:\\t\\t {SR_Xy_rn_tf.shape}\\n\\t However, desired n_sample is:\\t\\t {num_Xyitems_SR}\\n desc:\\n\\t {desc}\\n=============\\n\\n\"", ")", "\n", "return", "SR_Xy_rn_tf", ",", "desc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.comma_paren": [[571, 591], ["enumerate"], "function", ["None"], ["", "def", "comma_paren", "(", "expr", ",", "loc", ")", ":", "\n", "# given string expr, return the position of mathing ')' and the ','", "\n", "# assume expr has fun(A,B) structure after loc", "\n", "    ", "substr", "=", "expr", "[", "loc", ":", "]", "\n", "comma_", "=", "0", "\n", "cnt_left", "=", "0", "\n", "seen", "=", "False", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "expr", "[", "loc", ":", "]", ")", ":", "\n", "        ", "if", "s", "==", "','", ":", "\n", "            ", "comma_", "=", "i", "\n", "", "elif", "s", "==", "'('", ":", "\n", "            ", "cnt_left", "+=", "1", "\n", "seen", "=", "True", "\n", "", "elif", "s", "==", "')'", ":", "\n", "            ", "cnt_left", "-=", "1", "\n", "\n", "", "if", "seen", "and", "cnt_left", "==", "0", ":", "\n", "            ", "paren_", "=", "i", "\n", "break", "\n", "", "", "return", "loc", "+", "comma_", ",", "loc", "+", "paren_", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_ith": [[595, 603], ["s.find", "s.find"], "function", ["None"], ["", "def", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", ":", "\n", "    ", "i", "=", "0", "\n", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "# for i in range(ith):", "\n", "while", "i", "<", "ith", "and", "loc", "!=", "-", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ",", "loc", "+", "1", ")", "\n", "i", "+=", "1", "\n", "", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_random_subs": [[604, 617], ["s.count", "s.find", "np.random.choice", "stage023_mid2021_update.find_ith"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_ith"], ["", "def", "find_random_subs", "(", "s", ",", "sub", ")", ":", "\n", "# given a string s and a sub string, if sub is a substring of s, then return the location of a randomly selected sub in s (if multiple sub in s)", "\n", "# if sub not present, return -1", "\n", "    ", "cnt", "=", "s", ".", "count", "(", "sub", ")", "\n", "if", "cnt", "==", "0", ":", "# not present", "\n", "        ", "return", "-", "1", "\n", "", "elif", "cnt", "==", "1", ":", "\n", "        ", "loc", "=", "s", ".", "find", "(", "sub", ")", "\n", "return", "loc", "\n", "", "else", ":", "\n", "        ", "ith", "=", "np", ".", "random", ".", "choice", "(", "cnt", ")", "\n", "loc", "=", "find_ith", "(", "s", ",", "sub", ",", "ith", ")", "\n", "return", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.mutate_expr": [[630, 642], ["np.random.rand", "add_term", "add_term", "stage023_mid2021_update.mutExpm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.mutExpm"], ["", "", "def", "mutate_expr", "(", "args", ",", "expr", "=", "None", ",", "coeff_SR", "=", "None", ",", "**", "w", ")", ":", "\n", "    ", "p", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "\n", "if", "'expm'", "in", "expr", ":", "\n", "        ", "probs", "=", "[", "0.3", ",", "1.1", "]", "\n", "if", "p", "<", "probs", "[", "0", "]", ":", "\n", "            ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "elif", "p", "<", "probs", "[", "1", "]", ":", "\n", "            ", "expr", "=", "mutExpm", "(", "expr", ")", "\n", "", "", "else", ":", "\n", "        ", "add_term", "(", "args", ",", "**", "args", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.mutExpm": [[646, 672], ["stage023_mid2021_update.find_expm_a", "float", "stage023_mid2021_update.mutExpm.is_single"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_expm_a"], ["", "def", "mutExpm", "(", "expr", ")", ":", "\n", "    ", "loc", ",", "comma", ",", "paren", "=", "find_expm_a", "(", "expr", ")", "\n", "\n", "before", "=", "expr", "[", ":", "loc", "]", "\n", "after", "=", "expr", "[", "paren", "+", "1", ":", "]", "\n", "part1", "=", "expr", "[", "loc", ":", "comma", "+", "1", "]", "\n", "part3", "=", "expr", "[", "paren", ":", "paren", "+", "1", "]", "# ')'", "\n", "a", "=", "float", "(", "expr", "[", "comma", "+", "1", ":", "paren", "]", ")", "\n", "\n", "def", "is_single", "(", "s", ",", "start", ",", "end", ")", ":", "\n", "# judge if input is completely wraped in '()'", "\n", "        ", "i1", ",", "i2", "=", "start", ",", "end", "\n", "while", "i1", ">=", "0", ":", "\n", "            ", "if", "s", "[", "i1", "]", "==", "' '", ":", "i1", "-=", "1", "\n", "elif", "s", "[", "i1", "]", "!=", "'('", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "while", "i2", "<", "len", "(", "s", ")", ":", "\n", "            ", "if", "s", "[", "i2", "]", "==", "' '", ":", "i2", "+=", "1", "\n", "elif", "s", "[", "i2", "]", "!=", "')'", ":", "return", "False", "\n", "else", ":", "break", "\n", "", "return", "True", "\n", "\n", "", "single", "=", "is_single", "(", "expr", ",", "loc", "-", "1", ",", "paren", "+", "1", ")", "\n", "if", "single", ":", "\n", "        ", "expr", "=", "before", "# -wz", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_expm_a": [[677, 701], ["stage023_mid2021_update.find_random_subs", "stage023_mid2021_update.comma_paren"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.find_random_subs", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.comma_paren"], ["", "", "def", "find_expm_a", "(", "expr", ")", ":", "\n", "# given an string expr, find the location and value of the 'a' in x**a.", "\n", "# if multiple results, return an randomly selected one", "\n", "# eg: expr = \"tanh(tanh( coeff_SR[0] + sinh(expm( coeff_SR[1] * mt_0, 3))))\"  then \u203a\u203a a=3", "\n", "    ", "assert", "'expm'", "in", "expr", "\n", "loc", "=", "find_random_subs", "(", "expr", ",", "'expm'", ")", "\n", "comma", ",", "paren", "=", "comma_paren", "(", "expr", ",", "loc", ")", "\n", "\n", "# full_expm = expr[loc:paren+1]", "\n", "# before = expr[:loc]", "\n", "# part1 = expr[loc:comma+1]", "\n", "# a = float(expr[comma+1:paren])", "\n", "# part3 = expr[paren:paren+1]  # ')'", "\n", "# after = expr[paren+1:]", "\n", "\n", "# print(expr)", "\n", "# print(before)", "\n", "# print(part1)", "\n", "# print(a)", "\n", "# print(part3)", "\n", "# print(after)", "\n", "\n", "# raise", "\n", "return", "loc", ",", "comma", ",", "paren", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.plot_sin": [[713, 727], ["np.linspace", "sum", "utils.plot", "plt.title", "range", "stage023_mid2021_update.plot_sin.trm"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.plot"], ["", "def", "plot_sin", "(", ")", ":", "\n", "\n", "    ", "N", "=", "10", "\n", "L", "=", "N", "\n", "\n", "\n", "\n", "def", "trm", "(", "x", ",", "n", ")", ":", "\n", "        ", "return", "(", "-", "1", ")", "**", "(", "(", "n", "-", "1", ")", "//", "2", ")", "*", "1", "/", "np", ".", "math", ".", "factorial", "(", "n", ")", "*", "x", "**", "n", "\n", "", "x", "=", "np", ".", "linspace", "(", "-", "L", ",", "L", ",", "100", ")", "\n", "ords", "=", "[", "2", "*", "i", "+", "1", "for", "i", "in", "range", "(", "N", ")", "]", "\n", "sinx", "=", "sum", "(", "[", "trm", "(", "x", ",", "i", ")", "for", "i", "in", "ords", "]", ")", "\n", "plot", "(", "x", ",", "sinx", ")", "\n", "plt", ".", "title", "(", "f'highest order = {N}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.genEmpExp_April": [[742, 771], ["range", "range", "res.append", "stage023_mid2021_update.genEmpExp_April.genExpVTO"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModuleList.append", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_resnet.genExpVTO"], ["", "def", "genEmpExp_April", "(", "expr_vname_list", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "\n", "    ", "def", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ":", "\n", "# indecies: var,t,io,twin", "\n", "# order = io+1", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "\n", "        ", "v2i", "=", "{", "'mt'", ":", "0", ",", "'gt'", ":", "1", ",", "'g'", ":", "2", ",", "'mom5'", ":", "3", "}", "\n", "iv", "=", "v2i", "[", "vname", "]", "\n", "\n", "thisv", "=", "f'{vname}_{t}'", "\n", "res1", "=", "f'coeff_SR[{iv},{t},{io},0] * expm({thisv}, {io+1}+coeff_SR[{iv},{t},{io},2])'", "\n", "res2", "=", "f'coeff_SR[{iv},{t},{io},1] * expm({thisv}, {io+1}-coeff_SR[{iv},{t},{io},2])'", "\n", "\n", "return", "res1", "+", "' + '", "+", "res2", "\n", "\n", "", "res", "=", "[", "]", "\n", "expr_vname_list", "=", "[", "'mt'", ",", "'gt'", ",", "'g'", ",", "'mom5'", ",", "]", "\n", "# expr_vname_list = ['mt', 'gt', ]", "\n", "\n", "for", "vname", "in", "expr_vname_list", ":", "\n", "        ", "for", "t", "in", "range", "(", "expr_memlen", ")", ":", "\n", "            ", "for", "io", "in", "range", "(", "expr_maxOrd", ")", ":", "\n", "                ", "res", ".", "append", "(", "genExpVTO", "(", "vname", ",", "t", ",", "io", ",", "expr_group_len", ")", ")", "\n", "# res_viz = '\\ \\n+'.join(res); print(res_viz)", "\n", "\n", "", "", "", "res_ret", "=", "'+'", ".", "join", "(", "res", ")", "\n", "return", "res_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.do_with_expr": [[773, 820], ["stage023_mid2021_update.do_with_expr.coeff_SR_ini"], "function", ["None"], ["", "def", "do_with_expr", "(", "args", ",", "coeff_SR_dic", "=", "None", ",", "**", "w", ")", ":", "\n", "# coeff_SR: [ivar, it, order_i, (k1_order_i, k2_order_i, alpha_order_i) ]", "\n", "# coeff_SR shape: [expr_Nvar, expr_memlen, expr_maxOrd, expr_group_len ]", "\n", "# norm is to devide, denorm is to multiply (var's std)", "\n", "\n", "    ", "def", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ",", "**", "w", ")", ":", "\n", "# std: MNIST task:", "\n", "#     mt ~ 0.2", "\n", "#     gt ~ 1.0", "\n", "#     g/mom ~ 0.0005", "\n", "\n", "\n", "\n", "\n", "        ", "coeff_SRNorm", "=", "np", ".", "array", "(", "[", "0.2", ",", "1", ",", "0.0005", ",", "0.0005", "]", ")", "*", "1", "\n", "\n", "k_scalar_ini_abs", "=", "0.001", "\n", "alpha_ini", "=", "0.05", "\n", "\n", "\n", "\n", "\n", "assert", "expr_group_len", "==", "3", "\n", "coeff_SR", "=", "np", ".", "zeros", "(", "(", "expr_Nvar", ",", "expr_memlen", ",", "expr_maxOrd", ",", "expr_group_len", ")", ")", "\n", "\n", "k_ini", "=", "-", "k_scalar_ini_abs", "**", "(", "np", ".", "arange", "(", "expr_maxOrd", ")", "+", "1", ")", ".", "reshape", "(", "(", "expr_maxOrd", ",", "1", ")", ")", ".", "repeat", "(", "2", ",", "axis", "=", "1", ")", "\n", "coeff_SR", "[", "...", ",", "0", ":", "2", "]", "=", "k_ini", "\n", "coeff_SR", "[", "...", ",", "2", "]", "=", "alpha_ini", "\n", "\n", "if", "coeff_SR_dic", "is", "not", "None", ":", "\n", "            ", "for", "k", ",", "v", "in", "coeff_SR_dic", ".", "items", "(", ")", ":", "\n", "                ", "coeff_SR", "[", "k", "]", "=", "v", "\n", "\n", "\n", "", "", "return", "coeff_SR", ",", "coeff_SRNorm", "\n", "\n", "\n", "", "coeff_SR", ",", "coeff_SRNorm", "=", "coeff_SR_ini", "(", "coeff_SR_dic", ",", "**", "args", ")", "\n", "\n", "\n", "args", "[", "'expr'", "]", "=", "genEmpExp", "(", "**", "args", ")", "\n", "args", "[", "'coeff_SR'", "]", "=", "torch", ".", "tensor", "(", "coeff_SR", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "args", "[", "'coeff_SR'", "]", ".", "requires_grad", "=", "True", "\n", "args", "[", "'coeff_SRNorm'", "]", "=", "torch", ".", "tensor", "(", "coeff_SRNorm", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", ")", "\n", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.main_April": [[830, 935], ["utils.do_with_problem", "stage023_mid2021_update.do_with_expr", "len", "stage023_mid2021_update.sr_prep1", "print", "stage023_mid2021_update.do_with_expr", "stage023_mid2021_update.do_with_expr", "stage023_mid2021_update.fine_tune_SR", "list"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.utils.do_with_problem", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.do_with_expr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_prep1", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.do_with_expr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.do_with_expr", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.fine_tune_SR"], ["", "def", "main_April", "(", ")", ":", "\n", "\n", "\n", "\n", "# # =========== stage 0: check if converge ===========", "\n", "\n", "# do_with_pretrained(0, args)", "\n", "# do_with_problem(args, ", "\n", "#                 MNISTLoss_f, ", "\n", "#                 MLP_MNIST, ", "\n", "#                 eva_epoch_len=250,", "\n", "#                 n_tests=3,", "\n", "#                 )", "\n", "# _, _, _, sr_r_t_n_f = eva_l2o_optimizer(args, **args)", "\n", "\n", "\n", "# =========== stage 0: Prep <Always Keep Uncomment> ===========", "\n", "\n", "# do_with_pretrained(0, args)", "\n", "    ", "do_with_problem", "(", "args", ",", "*", "problem_comb", "[", "'mni'", "]", ",", "**", "args", ")", "\n", "do_with_expr", "(", "args", ")", "\n", "\n", "\n", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "sr_prep1", "(", "args", ",", "\n", "SR_memlen", "=", "10", ",", "\n", "num_Xyitems_SR", "=", "580", ",", "\n", "**", "args", ")", "\n", "\n", "args", "[", "'n_tests'", "]", "=", "2", "\n", "args", "[", "'eva_epoch_len'", "]", "=", "800", "\n", "\n", "\n", "# raise", "\n", "\n", "\n", "\n", "# # =========== stage 0: Gen Data ===========", "\n", "\n", "# _, _, _, sr_r_t_n_f = eva_l2o_optimizer(args, **args)", "\n", "# # viz_grad_seq(sr_r_t_n_f)", "\n", "# # raise", "\n", "\n", "\n", "\n", "# # =========== stage 0: Save npy ===========", "\n", "\n", "# SR_Xy, desc = sr_prep2(sr_r_t_n_f, args, **args)", "\n", "# lt2 = time.strftime(\"%Y-%m-%d--%H_%M_%S\", time.localtime())", "\n", "# fname_tosave = f\"SR_data/SR_Xy ~ {desc} ~ of ~ {args['l2o_net'].name} ~ on ~ {args['Target_Optimizee'].name}.npy\"", "\n", "# np.save(fname_tosave, SR_Xy)", "\n", "# print(f'\\n=========\\n\\n  Database saved @:  {fname_tosave}\\n=========')", "\n", "# raise", "\n", "\n", "\n", "\n", "# =====================================================", "\n", "# ============== stage 2.5: Fine tune SR ==============", "\n", "\n", "print", "(", "'\\n\\n         rfrf       \\n\\n'", ")", "\n", "\n", "\n", "\n", "\n", "coeff_SR_dic", "=", "{", "\n", "(", "0", ",", "0", ",", "2", ",", "0", ")", ":", "-", "1.98", "*", "0.2", "**", "3", ",", "\n", "}", "\n", "\n", "do_with_expr", "(", "args", ",", "coeff_SR_dic", ",", "**", "args", ")", "\n", "\n", "\n", "\n", "args", "[", "'n_epochs_tuneSR'", "]", "=", "100", "\n", "args", "[", "'epoch_len_tuneSR'", "]", "=", "4000", "\n", "args", "[", "'unroll_tuneSR'", "]", "=", "10", "\n", "args", "[", "'lr_meta_tuneSR'", "]", "=", "0.005", "\n", "\n", "\n", "do_with_expr", "(", "args", ",", "coeff_SR_dic", ",", "**", "args", ")", "\n", "args", "[", "'rec_SR'", "]", "=", "1", "\n", "fine_tune_SR", "(", "args", ",", "**", "args", ")", "\n", "\n", "\n", "# ===================================================", "\n", "# =========== stage 3: Eva SR performance ===========", "\n", "\n", "\n", "\n", "# print('\\n\\n         45tyj       \\n\\n')", "\n", "\n", "# coeff_SR_dic = {", "\n", "\n", "#                 (0,0,2,0): -1.98 * 0.2**3 ,", "\n", "\n", "#                 }", "\n", "\n", "\n", "\n", "\n", "# args['n_tests']=2", "\n", "# args['eva_epoch_len']=8", "\n", "\n", "# do_with_expr(args, coeff_SR_dic, **args)", "\n", "# eva_sr_trainingPerform(args, **args)", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.main_June": [[937, 1102], ["args.get", "len", "stage023_mid2021_update.sr_prep1", "torch.tensor", "stage023_mid2021_update.fine_tune_SR", "torch.cuda.is_available", "int", "OPT_META_L2O", "print", "list", "args[].parameters"], "function", ["home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.sr_prep1", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.stage023_mid2021_update.fine_tune_SR", "home.repos.pwc.inspect_result.vita-group_symbolic-learning-to-optimize.torch-implementation.meta_module.MetaModule.parameters"], ["", "def", "main_June", "(", ")", ":", "\n", "\n", "# ===================== initializations ... =====================", "\n", "\n", "\n", "# which_DataGen = 0", "\n", "# Target_DataGen = [MNISTLoss_f, Cifar_half_f][which_DataGen]", "\n", "# AB=1", "\n", "# cifar_root  = ['datasets/cifar10-A', 'datasets/cifar10-B'][AB]", "\n", "\n", "# Target_Optimizee = [MLP_MNIST,MLP_MNIST2,resnet18][0]", "\n", "\n", "\n", "\n", "\n", "    ", "SERVER", "=", "2", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "0", "\n", "\n", "\n", "args", "=", "{", "\n", "# Training", "\n", "\n", "'n_epochs'", ":", "[", "1", ",", "2", ",", "100", "]", "[", "SERVER", "]", ",", "\n", "'epoch_len'", ":", "[", "5", ",", "200", ",", "800", ",", "]", "[", "SERVER", "]", ",", "\n", "'unroll'", ":", "[", "2", ",", "1", ",", "20", ",", "]", "[", "SERVER", "]", ",", "\n", "'random_scale'", ":", "0.", ",", "\n", "# 'Target_DataGen': Target_DataGen,", "\n", "'only_want_last'", ":", "1", ",", "\n", "'want_save_eva_loss'", ":", "False", ",", "\n", "# Model", "\n", "'OPT'", ":", "RPOptimizer", ",", "\n", "'preproc'", ":", "[", "6", ",", "]", ",", "\n", "'hidden_layers_zer'", ":", "[", "7", ",", "]", ",", "\n", "# 'Ngf': 2,", "\n", "'beta1'", ":", "0.95", ",", "\n", "'beta2'", ":", "0.95", ",", "\n", "'pre_tahn_scale'", ":", "None", ",", "\n", "'LUM'", ":", "[", "LUM", ",", "None", "]", "[", "1", "]", ",", "\n", "\n", "# 'lum_layers': [len(list(optimizee_train().parameters())), 20, 1],", "\n", "\n", "\n", "\n", "\n", "\n", "# l2oShell_4SR_featPrep", "\n", "# 'grad_features': 'mt+gt+g+mom5',", "\n", "'grad_features'", ":", "'AdamUp_unNorm+AdamDn_Norm'", ",", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# SR stage 0: Generate SR database", "\n", "'want_sr'", ":", "1", ",", "\n", "'eva_epoch_len'", ":", "[", "80", ",", "900", ",", "500", "]", "[", "SERVER", "]", ",", "\n", "'n_tests'", ":", "[", "2", ",", "2", ",", "10", "]", "[", "SERVER", "]", ",", "# will be overwritten if want_sr", "\n", "# 'Target_Optimizee': Target_Optimizee,", "\n", "\n", "# 'expr': \"tanh(tanh( coeff_SR[0] + sinh(cube( coeff_SR[1] * mt_0))))\",", "\n", "# 'coeff_SR': torch.tensor([0.024803324, -1.9923366],device=DEVICE),", "\n", "\n", "'OPT_fitSR'", ":", "[", "optim", ".", "Adam", ",", "optim", ".", "SGD", "]", "[", "1", "]", ",", "\n", "'lr_fitSR'", ":", "0.001", ",", "\n", "'n_epochs_fit_SR'", ":", "int", "(", "1e4", ")", ",", "\n", "\n", "# SR: stage 3: fine tune SR", "\n", "'which_SR_dataset'", ":", "[", "None", ",", "'RP_s'", ",", "'RP_s_i'", ",", "'RP'", ",", "'DM'", "]", "[", "1", "]", ",", "\n", "'lr_meta_tuneSR'", ":", "0.01", ",", "\n", "'OPT_META_SR'", ":", "[", "optim", ".", "Adam", ",", "optim", ".", "SGD", "]", "[", "1", "]", ",", "\n", "'epoch_len_tuneSR'", ":", "[", "5", ",", "200", ",", "800", ",", "]", "[", "SERVER", "]", ",", "\n", "'unroll_tuneSR'", ":", "20", ",", "\n", "'n_epochs_tuneSR'", ":", "[", "2", ",", "100", ",", "20", "]", "[", "SERVER", "]", ",", "\n", "'srFineTune_want_eva_in_train'", ":", "0", ",", "\n", "\n", "\n", "# train expr", "\n", "'expr_vname_list'", ":", "[", "'mt'", ",", "'gt'", ",", "'g'", ",", "'mom5'", ",", "]", ",", "\n", "'expr_Nvar'", ":", "4", ",", "\n", "'expr_memlen'", ":", "3", ",", "\n", "'expr_maxOrd'", ":", "3", ",", "\n", "'expr_group_len'", ":", "3", ",", "# k1,k2,alpha", "\n", "\n", "\n", "# MLP_MNIST optimizee", "\n", "# 'pixels':  [28*28,  3*32*32][which_DataGen],", "\n", "\n", "# cifar", "\n", "'num_workers'", ":", "2", ",", "\n", "'batch_size'", ":", "128", ",", "\n", "'cifarAB'", ":", "'A'", ",", "\n", "\n", "# useless but must-have", "\n", "'META_OPT_LR'", ":", "0.001", ",", "\n", "'pin_memory'", ":", "False", ",", "\n", "'mode'", ":", "None", ",", "\n", "\n", "}", "\n", "\n", "\n", "problem_comb", "=", "{", "'mni'", ":", "[", "MNISTLoss_f", ",", "MLP_MNIST", "]", ",", "\n", "'mni2'", ":", "[", "MNISTLoss_f", ",", "MLP_MNIST2", "]", ",", "\n", "'cnn'", ":", "[", "Cifar_half_f", ",", "SMALL_CNN", "]", ",", "\n", "'r18h'", ":", "[", "Cifar_half_f", ",", "resnet18", "]", ",", "\n", "'r18'", ":", "[", "Cifar_f", ",", "resnet18", "]", ",", "\n", "'r50'", ":", "[", "Cifar_f", ",", "resnet50", "]", ",", "\n", "}", "\n", "\n", "Target_DataGen", ",", "Target_Optimizee", "=", "problem_comb", "[", "'mni'", "]", "\n", "\n", "args", "[", "'Target_DataGen'", "]", "=", "Target_DataGen", "\n", "if", "Target_DataGen", "in", "[", "MNISTLoss_f", ",", "MNISTLoss", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "28", "*", "28", "\n", "", "elif", "Target_DataGen", "in", "[", "Cifar_half", ",", "Cifar_half_f", "]", ":", "\n", "        ", "args", "[", "'pixels'", "]", "=", "3", "*", "32", "*", "32", "\n", "\n", "", "args", "[", "'Target_Optimizee'", "]", "=", "Target_Optimizee", "\n", "if", "args", ".", "get", "(", "'l2o_net'", ")", ":", "\n", "        ", "choose_meta_opt", "=", "[", "optim", ".", "Adam", ",", "]", ";", "which_meta_opt", "=", "0", "\n", "OPT_META_L2O", "=", "choose_meta_opt", "[", "which_meta_opt", "]", "\n", "args", "[", "'meta_opt'", "]", "=", "OPT_META_L2O", "(", "args", "[", "'l2o_net'", "]", ".", "parameters", "(", ")", ",", "lr", "=", "META_OPT_LR", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'\\n\\nL2O model not initialized before, planing to train L2O model from scratch...\\n Should NOT see this if: \\n\\t fine-tune L2O \\n\\t evaluation\\n\\t SR Gen Data\\n OK to see if:\\n\\t Train L2O from scratch \\n\\t Fitting SR\\n\\t fine-tune SR \\n\\t Evaluate SR performance \\n\\t normal Train resnet \\n\\n'", ")", "\n", "\n", "# if n_epochs is not None: args['n_epochs'] = n_epochs", "\n", "# if epoch_len is not None: args['epoch_len'] = epoch_len", "\n", "# if unroll is not None: args['unroll'] = unroll", "\n", "# if eva_epoch_len is not None: args['eva_epoch_len'] = eva_epoch_len", "\n", "# if n_tests is not None: args['n_tests'] = n_tests", "\n", "\n", "# args.update(other_configs)", "\n", "\n", "\n", "", "args", "[", "'Ngroup_zee'", "]", "=", "len", "(", "list", "(", "args", "[", "'Target_Optimizee'", "]", "(", ")", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "sr_prep1", "(", "args", ",", "\n", "SR_memlen", "=", "1", ",", "\n", "num_Xyitems_SR", "=", "580", ",", "\n", "**", "args", ")", "\n", "\n", "args", "[", "'n_tests'", "]", "=", "2", "\n", "args", "[", "'eva_epoch_len'", "]", "=", "800", "\n", "\n", "args", "[", "'n_epochs_tuneSR'", "]", "=", "100", "\n", "args", "[", "'epoch_len_tuneSR'", "]", "=", "4000", "\n", "args", "[", "'unroll_tuneSR'", "]", "=", "10", "\n", "args", "[", "'lr_meta_tuneSR'", "]", "=", "0.005", "\n", "\n", "\n", "# do_with_expr(args, coeff_SR_dic, **args)", "\n", "args", "[", "'rec_SR'", "]", "=", "1", "\n", "\n", "args", "[", "'coeff_SR'", "]", "=", "torch", ".", "tensor", "(", "[", "0.8", ",", "]", ",", "device", "=", "DEVICE", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "args", "[", "'coeff_SR'", "]", ".", "requires_grad", "=", "True", "\n", "\n", "\n", "\n", "\n", "args", "[", "'expr'", "]", "=", "'adamup/(1-lamb + lamb * adamdn)'", "\n", "# ===================== finish initialization =====================", "\n", "fine_tune_SR", "(", "args", ",", "**", "args", ")", "\n", "\n", "return", "\n", "\n"]]}